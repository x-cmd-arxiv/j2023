{"id":"2305.17506","submitter":"Weisong Sun","authors":"Weisong Sun, Yuchen Chen, Guanhong Tao, Chunrong Fang, Xiangyu Zhang,\n  Quanjun Zhang, Bin Luo","title":"Backdooring Neural Code Search","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reusing off-the-shelf code snippets from online repositories is a common\npractice, which significantly enhances the productivity of software developers.\nTo find desired code snippets, developers resort to code search engines through\nnatural language queries. Neural code search models are hence behind many such\nengines. These models are based on deep learning and gain substantial attention\ndue to their impressive performance. However, the security aspect of these\nmodels is rarely studied. Particularly, an adversary can inject a backdoor in\nneural code search models, which return buggy or even vulnerable code with\nsecurity/privacy issues. This may impact the downstream software (e.g., stock\ntrading systems and autonomous driving) and cause financial loss and/or\nlife-threatening incidents. In this paper, we demonstrate such attacks are\nfeasible and can be quite stealthy. By simply modifying one variable/function\nname, the attacker can make buggy/vulnerable code rank in the top 11%. Our\nattack BADCODE features a special trigger generation and injection procedure,\nmaking the attack more effective and stealthy. The evaluation is conducted on\ntwo neural code search models and the results show our attack outperforms\nbaselines by 60%. Our user study demonstrates that our attack is more stealthy\nthan the baseline by two times based on the F1 score.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:00:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17507","submitter":"Bryce Gadway","authors":"Sai Naga Manoj Paladugu, Tao Chen, Fangzhao Alex An, Bo Yan, and Bryce\n  Gadway","title":"Spectroscopy of momentum state lattices","comments":"9 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas physics.atom-ph quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore a technique for probing energy spectra in synthetic lattices that\nis analogous to scanning tunneling microscopy. Using one-dimensional synthetic\nlattices of coupled atomic momentum states, we explore this spectroscopic\ntechnique and observe qualitative agreement between the measured and simulated\nenergy spectra for small two- and three-site lattices as well as a uniform\nmany-site lattice. Finally, through simulations, we show that this technique\nshould allow for the exploration of the topological bands and the fractal\nenergy spectrum of the Hofstadter model as realized in synthetic lattices.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:03:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17508","submitter":"Mancho Manev","authors":"Mancho Manev","title":"Pairs of associated Yamabe almost solitons with vertical potential on\n  almost contact complex Riemannian manifolds","comments":"13 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Almost contact complex Riemannian manifolds, known also as almost contact\nB-metric manifolds, are in principle equipped with a pair of mutually\nassociated pseudo-Riemannian metrics. Each of these metrics is specialized here\nas a Yamabe almost soliton with a potential collinear to the Reeb vector field.\nThe resulting manifolds are then investigated in two important cases with\ngeometric significance. The first is when the manifold is of Sasaki-like type,\ni.e. its complex cone is a holomorphic complex Riemannian manifold (also called\na K\\\"ahler--Norden manifold). The second case is when the soliton potential is\ntorse-forming, i.e. it satisfies a certain recurrence condition for its\ncovariant derivative with respect to the Levi-Civita connection of the\ncorresponding metric. The studied solitons are characterized. In the\nthree-dimensional case, an explicit example is constructed and the properties\nobtained in the theoretical part are confirmed.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:04:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17509","submitter":"Loring W. Tu","authors":"Loring W. Tu","title":"Gysin formulas and equivariant cohomology","comments":"To be published in \"Group Actions and Equivariant Cohomology\",\n  Contemporary Mathematics, AMS","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Under Poincar\\'e duality, a smooth map of compact oriented manifolds induces\na pushforward map in cohomology, called the \"Gysin map.\" It plays an important\nrole in enumerative geometry. Using the equivariant localization formula, the\nauthor gave in 2017 a general formula for the Gysin map of a fiber bundle with\nequivariantly formal fibers. Equivariantly formal manifolds include all\nmanifolds with cohomology in only even degrees such as complex projective\nspaces, Grassmannians, and flag manifolds as well as $G/H$, where $G$ is a\ncompact Lie group and $H$ is a closed subgroup of maximal rank. This article is\na simplified exposition using the example of a projective bundle to illustrate\nthe algorithm.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:07:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17510","submitter":"Hongyi Pan Dr.","authors":"Hongyi Pan, Xin Zhu, Salih Atici, Ahmet Enis Cetin","title":"A Hybrid Quantum-Classical Approach based on the Hadamard Transform for\n  the Convolutional Layer","comments":"To be presented at International Conference on Machine Learning\n  (ICML), 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we propose a novel Hadamard Transform (HT)-based neural\nnetwork layer for hybrid quantum-classical computing. It implements the regular\nconvolutional layers in the Hadamard transform domain. The idea is based on the\nHT convolution theorem which states that the dyadic convolution between two\nvectors is equivalent to the element-wise multiplication of their HT\nrepresentation. Computing the HT is simply the application of a Hadamard gate\nto each qubit individually, so the HT computations of our proposed layer can be\nimplemented on a quantum computer. Compared to the regular Conv2D layer, the\nproposed HT-perceptron layer is computationally more efficient. Compared to a\nCNN with the same number of trainable parameters and 99.26\\% test accuracy, our\nHT network reaches 99.31\\% test accuracy with 57.1\\% MACs reduced in the MNIST\ndataset; and in our ImageNet-1K experiments, our HT-based ResNet-50 exceeds the\naccuracy of the baseline ResNet-50 by 0.59\\% center-crop top-1 accuracy using\n11.5\\% fewer parameters with 12.6\\% fewer MACs.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:11:48 GMT"},{"version":"v2","created":"Wed, 31 May 2023 17:20:48 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17511","submitter":"Eli Temanson","authors":"Eli Temanson, Jessica Baker, Sean Kuvin, Ken Hanselman, Gordon W.\n  McCann, Lagy T. Baby, Alexander Volya, Peter H\\\"oflich, Ingo Wiedenh\\\"over","title":"Measurement of the $\\mathrm{^{25}Al(d,n)^{26}Si}$ reaction and impact on\n  the $\\mathrm{^{25}Al(p,\\gamma)^{26}Si}$ reaction rate","comments":"8 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The $\\mathrm{^{25}Al(p,\\gamma)^{26}Si}$ reaction is part of a reaction\nnetwork with impact on the observed galactic $^{26}$Al abundance. A new\ndetermination of the proton strength of the lowest $\\ell=0$ proton-resonance in\n$^{26}$Si is required to more precisely calculate the thermal reaction rate. To\nthis end, the $\\mathrm{^{25}Al(d,n)^{26}Si}$ proton-transfer reaction is\nmeasured in inverse kinematics using an in-flight radioactive beam at the\nRESOLUT facility. Excitation energies of the lowest $^{26}$Si proton resonances\nare measured and cross sections are determined for the lowest $\\ell=0$\nresonance associated with the $3^{+}_{3}$ state at 5.92(2) MeV. Coupled\nreaction channels (CRC) calculations using FRESCO are performed to extract the\n$\\ell=0$ spectroscopic factor for the $3^{+}_{3}$ state. The proton width for\nthe $3^{+}_{3}$ state in $^{26}$Si is determined to be $\\Gamma_{p}$=2.19(45) eV\nand the $(p,\\gamma)$ resonance strength for the $3^{+}_{3}$ state is extracted\nas 26(10) meV. This resonance dominates the $\\mathrm{^{25}Al(p,\\gamma)^{26}Si}$\nreaction rate above 0.2 GK.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:11:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17512","submitter":"Juseung Oh","authors":"Wontaek Kim, Gyouil Jeong, Juseung Oh, Jihun Kim, Kenji Watanabe,\n  Takashi Taniguchi, Sunmin Ryu","title":"Exciton-Sensitized Second-Harmonic Generation in 2D Heterostructures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The efficient optical second-harmonic generation (SHG) of two-dimensional\n(2D) crystals, coupled with their atomic thickness that circumvents the\nphase-match problem, has garnered considerable attention. While various 2D\nheterostructures have shown promising applications in photodetectors, switching\nelectronics, and photovoltaics, the modulation of nonlinear optical properties\nin such hetero-systems remains unexplored. In this study, we investigate\nexciton sensitized SHG in heterobilayers of transition metal dichalcogenides\n(TMDs), where photoexcitation of one donor layer enhances the SHG response of\nthe other as an acceptor. We utilize polarization-resolved interferometry to\ndetect the SHG intensity and phase of each individual layer, revealing the\nenergetic match between the excitonic resonances of donors and the SHG\nenhancement of acceptors for four TMD combinations. Our results also uncover\nthe dynamic nature of interlayer coupling, as evidenced by the dependence of\nsensitization on interlayer gap spacing and the average power of the\nfundamental beam. This work provides insights into how interlayer coupling of\ntwo different layers can modify nonlinear optical phenomena in 2D\nheterostructures.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:14:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17513","submitter":"Vasilis Oikonomou","authors":"Sergei D. Odintsov, V.K. Oikonomou, German S. Sharov","title":"Early Dark Energy with Power-law F(R) Gravity","comments":"PLB Accepted","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a power-law $F(R)$ gravity with an early dark energy term, that can\ndescribe both the early-time and the late-time acceleration of the Universe. We\nconfront this scenario with recent observational data including the Pantheon\nType Ia supernovae, measurements of the Hubble parameter $H(z)$ (Cosmic\nChronometers), data from Baryon Acoustic Oscillations and standard rulers data\nfrom the Cosmic Microwave Background (CMB) radiation. The model demonstrates\nsome achievements in confronting with these observations and can be compared\nwith the $\\Lambda$-Cold-Dark-Matter model. In particular, in both models we\nobtain very close estimates for the Hubble constant $H_0$, but it is not true\nfor $\\Omega_m^0$. The early dark energy term supports viability of the\nconsidered $F(R)$ gravity model.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:17:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17514","submitter":"Nithya Muraleedharan","authors":"Shyam S. Kamath and Nithya Muraleedharan","title":"Some new generalizations of Domination using restrictions on degrees of\n  vertices","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  A set $D$ of vertices in a graph $G=(V,E)$ is a degree restricted dominating\nset for $G$ if each vertex $v_i$ in $D$ is dominating atmost $g(d_i)$ vertices\nof $V-D$, where $g$ is a function restricting the degree value $d_i$ with\nrespect to the given function value $k_i$ for a natural valued function $f$\nfrom the vertex set of the graph. We define three different types of Degree\nRestricted Domination by varying the way how the restricted function $g(v_i)$\nis defined. If $g(d_i)=\\big\\lceil \\frac{d_i}{k_i}\\big\\rceil$, the corresponding\ndomination is called the ceil degree restricted domination, in short, $CDRD$,\nand the dominating set obtained in this manner is the $CDRD$-set. If\n$g(d_i)=\\big\\lfloor\\frac{d_i}{k_i}\\big\\rfloor$ or $g(d_i)=d_i-k_i+1$, then the\ncorresponding dominations are respectively called the floor degree restricted\ndomination, in short $FDRD$, or the translate degree restricted domination,\n$TDRD$. The dominating sets obtained in this manner are the $FDRD$-set and the\n$TDRD$-set respectively. In this paper, we introduce these new generalizations\nof the domination number in line with the different $DRD$-sets and study these\ntypes of domination for some classes of graphs like complete graphs,\ncaterpillar graphs etc. Degree restricted domination has a vital role in\nretaining the efficiency of nodes in a network and has many interesting\napplications.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:21:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17515","submitter":"Xuetao Lu","authors":"Xuetao Lu, J. Jack Lee","title":"Overlapping Indices for Dynamic Information Borrowing in Bayesian\n  Hierarchical Modeling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayesian hierarchical model (BHM) has been widely used in synthesizing\ninformation across subgroups. Identifying heterogeneity in the data and\ndetermining proper strength of borrow have long been central goals pursued by\nresearchers. Because these two goals are interconnected, we must consider them\ntogether. This joint consideration presents two fundamental challenges: (1) How\ncan we balance the trade-off between homogeneity within the cluster and\ninformation gain through borrowing? (2) How can we determine the borrowing\nstrength dynamically in different clusters? To tackle challenges, first, we\ndevelop a theoretical framework for heterogeneity identification and dynamic\ninformation borrowing in BHM. Then, we propose two novel overlapping indices:\nthe overlapping clustering index (OCI) for identifying the optimal clustering\nresult and the overlapping borrowing index (OBI) for assigning proper borrowing\nstrength to clusters. By incorporating these indices, we develop a new method\nBHMOI (Bayesian hierarchical model with overlapping indices). BHMOI includes a\nnovel weighted K-Means clustering algorithm by maximizing OCI to obtain optimal\nclustering results, and embedding OBI into BHM for dynamically borrowing within\nclusters. BHMOI can achieve efficient and robust information borrowing with\ndesirable properties. Examples and simulation studies are provided to\ndemonstrate the effectiveness of BHMOI in heterogeneity identification and\ndynamic information borrowing.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:21:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17516","submitter":"Jordan Berthoumieu","authors":"Jordan Berthoumieu","title":"Minimizing travelling waves for the one-dimensional nonlinear\n  Schr\\\"odinger equation with non-zero condition at infinity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper deals with the existence of travelling wave solutions for a\ngeneral one-dimensional nonlinear Schr\\\"odinger equation. We construct these\nsolutions by minimizing the energy under the constraint of fixed momentum. We\nalso prove that the family of minimizers is stable. Our method is based on\nrecent articles about the orbital stability for the classical and non-local\nGross-Pitaevskii equations [3, 10]. It relies on a concentration-compactness\ntheorem, which provides some compactness for the minimizing sequences and thus\nthe convergence (up to a subsequence) towards a travelling wave solution.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:23:47 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17517","submitter":"Iaroslav Kriuchkov","authors":"Iaroslav Kriuchkov, Timo Kuosmanen","title":"Stochastic Nonparametric Estimation of the Fundamental Diagram","comments":"Submitted to Transportation Research Part B: Methodological","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The fundamental diagram serves as the foundation of traffic flow modeling for\nalmost a century. With the increasing availability of road sensor data,\ndeterministic parametric models have proved inadequate in describing the\nvariability of real-world data, especially in congested area of the\ndensity-flow diagram. In this paper we estimate the stochastic density-flow\nrelation introducing a nonparametric method called convex quantile regression.\nThe proposed method does not depend on any prior functional form assumptions,\nbut thanks to the concavity constraints, the estimated function satisfies the\ntheoretical properties of the fundamental diagram. The second contribution is\nto develop the new convex quantile regression with bags (CQRb) approach to\nfacilitate practical implementation of CQR to the real-world data. We\nillustrate the CQRb estimation process using the road sensor data from Finland\nin years 2016-2018. Our third contribution is to demonstrate the excellent\nout-of-sample predictive power of the proposed CQRb method in comparison to the\nstandard parametric deterministic approach.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:24:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17518","submitter":"Adish Singla","authors":"Alperen Tercan, Ahana Ghosh, Hasan Ferit Eniser, Maria Christakis,\n  Adish Singla","title":"Synthesizing a Progression of Subtasks for Block-Based Visual\n  Programming Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Block-based visual programming environments play an increasingly important\nrole in introducing computing concepts to K-12 students. In recent years, they\nhave also gained popularity in neuro-symbolic AI, serving as a benchmark to\nevaluate general problem-solving and logical reasoning skills. The open-ended\nand conceptual nature of these visual programming tasks make them challenging,\nboth for state-of-the-art AI agents as well as for novice programmers. A\nnatural approach to providing assistance for problem-solving is breaking down a\ncomplex task into a progression of simpler subtasks; however, this is not\ntrivial given that the solution codes are typically nested and have non-linear\nexecution behavior. In this paper, we formalize the problem of synthesizing\nsuch a progression for a given reference block-based visual programming task.\nWe propose a novel synthesis algorithm that generates a progression of subtasks\nthat are high-quality, well-spaced in terms of their complexity, and solving\nthis progression leads to solving the reference task. We show the utility of\nour synthesis algorithm in improving the efficacy of AI agents (in this case,\nneural program synthesizers) for solving tasks in the Karel programming\nenvironment. Then, we conduct a user study to demonstrate that our synthesized\nprogression of subtasks can assist a novice programmer in solving tasks in the\nHour of Code: Maze Challenge by Code-dot-org.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:24:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17519","submitter":"Vishnu Murali","authors":"Vishnu Murali, Ashutosh Trivedi, Majid Zamani","title":"Closure Certificates","comments":"23 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A barrier certificate, defined over the states of a dynamical system, is a\nreal-valued function whose zero level set characterizes an inductively\nverifiable state invariant separating reachable states from unsafe ones. When\ncombined with powerful decision procedures such as sum-of-squares programming\n(SOS) or satisfiability-modulo-theory solvers (SMT) barrier certificates enable\nan automated deductive verification approach to safety. The barrier certificate\napproach has been extended to refute omega-regular specifications by separating\nconsecutive transitions of omega-automata in the hope of denying all accepting\nruns. Unsurprisingly, such tactics are bound to be conservative as refutation\nof recurrence properties requires reasoning about the well-foundedness of the\ntransitive closure of the transition relation. This paper introduces the notion\nof closure certificates as a natural extension of barrier certificates from\nstate invariants to transition invariants. We provide SOS and SMT based\ncharacterization for automating the search of closure certificates and\ndemonstrate their effectiveness via a paradigmatic case study.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:29:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17520","submitter":"Uddeshya Upadhyay","authors":"Vikrant Rangnekar, Uddeshya Upadhyay, Zeynep Akata, Biplab Banerjee","title":"USIM-DAL: Uncertainty-aware Statistical Image Modeling-based Dense\n  Active Learning for Super-resolution","comments":"Accepted at UAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dense regression is a widely used approach in computer vision for tasks such\nas image super-resolution, enhancement, depth estimation, etc. However, the\nhigh cost of annotation and labeling makes it challenging to achieve accurate\nresults. We propose incorporating active learning into dense regression models\nto address this problem. Active learning allows models to select the most\ninformative samples for labeling, reducing the overall annotation cost while\nimproving performance. Despite its potential, active learning has not been\nwidely explored in high-dimensional computer vision regression tasks like\nsuper-resolution. We address this research gap and propose a new framework\ncalled USIM-DAL that leverages the statistical properties of colour images to\nlearn informative priors using probabilistic deep neural networks that model\nthe heteroscedastic predictive distribution allowing uncertainty\nquantification. Moreover, the aleatoric uncertainty from the network serves as\na proxy for error that is used for active learning. Our experiments on a wide\nvariety of datasets spanning applications in natural images (visual genome,\nBSD100), medical imaging (histopathology slides), and remote sensing (satellite\nimages) demonstrate the efficacy of the newly proposed USIM-DAL and superiority\nover several dense regression active learning methods.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:33:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17521","submitter":"Jianbing Ni","authors":"Jianxiang Zhao, Xiangman Li, Jianbing Ni","title":"Privacy-Preserving Model Aggregation for Asynchronous Federated Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a novel privacy-preserving model aggregation for asynchronous\nfederated learning, named PPA-AFL that removes the restriction of synchronous\naggregation of local model updates in federated learning, while enabling the\nprotection of the local model updates against the server. In PPA-AFL, clients\ncan proactive decide when to engage in the training process, and sends local\nmodel updates to the server when the updates are available. Thus, it is not\nnecessary to keep synchronicity with other clients. To safeguard client updates\nand facilitate local model aggregation, we employ Paillier encryption for local\nupdate encryption and support homomorphic aggregation. Furthermore, secret\nsharing is utilized to enable the sharing of decryption keys and facilitate\nprivacy-preserving asynchronous aggregation. As a result, the server remains\nunable to gain any information about the local updates while asynchronously\naggregating to produce the global model. We demonstrate the efficacy of our\nproposed PPA-AFL framework through comprehensive complexity analysis and\nextensive experiments on a prototype implementation, highlighting its potential\nfor practical adoption in privacy-sensitive asynchronous federated learning\nscenarios.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:36:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17522","submitter":"Hailin Li","authors":"Hailin Li and Raghavendra Ramachandra","title":"Deep Learning based Fingerprint Presentation Attack Detection: A\n  Comprehensive Survey","comments":"29 pages, submitted to ACM computing survey journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The vulnerabilities of fingerprint authentication systems have raised\nsecurity concerns when adapting them to highly secure access-control\napplications. Therefore, Fingerprint Presentation Attack Detection (FPAD)\nmethods are essential for ensuring reliable fingerprint authentication. Owing\nto the lack of generation capacity of traditional handcrafted based approaches,\ndeep learning-based FPAD has become mainstream and has achieved remarkable\nperformance in the past decade. Existing reviews have focused more on\nhand-cratfed rather than deep learning-based methods, which are outdated. To\nstimulate future research, we will concentrate only on recent\ndeep-learning-based FPAD methods. In this paper, we first briefly introduce the\nmost common Presentation Attack Instruments (PAIs) and publicly available\nfingerprint Presentation Attack (PA) datasets. We then describe the existing\ndeep-learning FPAD by categorizing them into contact, contactless, and\nsmartphone-based approaches. Finally, we conclude the paper by discussing the\nopen challenges at the current stage and emphasizing the potential future\nperspective.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:37:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17523","submitter":"Jaydip Sen Prof","authors":"Jaydip Sen, Aditya Jaiswal, Anshuman Pathak, Atish Kumar Majee,\n  Kushagra Kumar, Manas Kumar Sarkar, and Soubhik Maji","title":"A Comparative Analysis of Portfolio Optimization Using Mean-Variance,\n  Hierarchical Risk Parity, and Reinforcement Learning Approaches on the Indian\n  Stock Market","comments":"The report is 52 pages long. It is based on the capstone project done\n  in the post graduate course of data science in Praxis Business School,\n  Kolkata, India, of the Autumn Batch, 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG q-fin.PM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a comparative analysis of the performances of three\nportfolio optimization approaches. Three approaches of portfolio optimization\nthat are considered in this work are the mean-variance portfolio (MVP),\nhierarchical risk parity (HRP) portfolio, and reinforcement learning-based\nportfolio. The portfolios are trained and tested over several stock data and\ntheir performances are compared on their annual returns, annual risks, and\nSharpe ratios. In the reinforcement learning-based portfolio design approach,\nthe deep Q learning technique has been utilized. Due to the large number of\npossible states, the construction of the Q-table is done using a deep neural\nnetwork. The historical prices of the 50 premier stocks from the Indian stock\nmarket, known as the NIFTY50 stocks, and several stocks from 10 important\nsectors of the Indian stock market are used to create the environment for\ntraining the agent.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:38:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17524","submitter":"Jianbing Ni","authors":"Xiangman Li, Miao He, Jianbing Ni","title":"Secure and Privacy-preserving Network Slicing in 3GPP 5G System\n  Architecture","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Network slicing in 3GPP 5G system architecture has introduced significant\nimprovements in the flexibility and efficiency of mobile communication.\nHowever, this new functionality poses challenges in maintaining the privacy of\nmobile users, especially in multi-hop environments. In this paper, we propose a\nsecure and privacy-preserving network slicing protocol (SPNS) that combines 5G\nnetwork slicing and onion routing to address these challenges and provide\nsecure and efficient communication. Our approach enables mobile users to select\nnetwork slices while incorporating measures to prevent curious RAN nodes or\nexternal attackers from accessing full slice information. Additionally, we\nensure that the 5G core network can authenticate all RANs, while avoiding\nreliance on a single RAN for service provision. Besides, SPNS implements\nend-to-end encryption for data transmission within the network slices,\nproviding an extra layer of privacy and security. Finally, we conducted\nextensive experiments to evaluate the time cost of establishing network slice\nlinks under varying conditions. SPNS provides a promising solution for\nenhancing the privacy and security of communication in 5G networks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:39:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17525","submitter":"Jahanfar Abouie","authors":"J. Abouie, and M. H. Zarei","title":"Partially topological phase in a quantum loop gas model with tension and\n  pressure","comments":"9 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Enhancing robustness of topological orders against perturbations is one of\nthe main goals in topological quantum computing. Since the kinetic of\nexcitations is in conflict with the robustness of topological orders, any\nmechanism that reduces the mobility of excitations will be in favor of\nrobustness. A strategy in this direction is adding frustration to topological\nsystems. In this paper we consider a frustrated toric code on a kagome lattice,\nand show that although increasing the strength of perturbation reduces the\ntopological order of the system, it cannot destroy it completely. Our\nfrustrated toric code is indeed a quantum loop gas model with string tension\nand pressure which their competition leads to a partially topological phase\n(PTP) in which the excitations are restricted to move in particular\nsublattices. In this phase the ground state is a product of many copies of\nfluctuating loop states corresponding to quasi one dimensional ladders. By\ndefining a non-local matrix order parameter and studying the behavior of ground\nstate global entanglement (GE), we distinguish the PTP from the standard\ntopological phase. The partial mobility of excitations in our system is a\nreminiscent of fracton codes with restricted mobility, and therefore our\nresults propose an alternative way for making such a restriction in three\ndimension.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:51:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17526","submitter":"Rustem Takhanov","authors":"Rustem Takhanov","title":"Computing a partition function of a generalized pattern-based energy\n  over a semiring","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Valued constraint satisfaction problems with ordered variables (VCSPO) are a\nspecial case of Valued CSPs in which variables are totally ordered and soft\nconstraints are imposed on tuples of variables that do not violate the order.\nWe study a restriction of VCSPO, in which soft constraints are imposed on a\nsegment of adjacent variables and a constraint language $\\Gamma$ consists of\n$\\{0,1\\}$-valued characteristic functions of predicates. This kind of\npotentials generalizes the so-called pattern-based potentials, which were\napplied in many tasks of structured prediction.\n  For a constraint language $\\Gamma$ we introduce a closure operator, $\n\\overline{\\Gamma^{\\cap}}\\supseteq \\Gamma$, and give examples of constraint\nlanguages for which $|\\overline{\\Gamma^{\\cap}}|$ is small. If all predicates in\n$\\Gamma$ are cartesian products, we show that the minimization of a generalized\npattern-based potential (or, the computation of its partition function) can be\nmade in ${\\mathcal O}(|V|\\cdot |D|^2 \\cdot |\\overline{\\Gamma^{\\cap}}|^2 )$\ntime, where $V$ is a set of variables, $D$ is a domain set. If, additionally,\nonly non-positive weights of constraints are allowed, the complexity of the\nminimization task drops to ${\\mathcal O}(|V|\\cdot |\\overline{\\Gamma^{\\cap}}|\n\\cdot |D| \\cdot \\max_{\\rho\\in \\Gamma}\\|\\rho\\|^2 )$ where $\\|\\rho\\|$ is the\narity of $\\rho\\in \\Gamma$. For a general language $\\Gamma$ and non-positive\nweights, the minimization task can be carried out in ${\\mathcal O}(|V|\\cdot\n|\\overline{\\Gamma^{\\cap}}|^2)$ time.\n  We argue that in many natural cases $\\overline{\\Gamma^{\\cap}}$ is of moderate\nsize, though in the worst case $|\\overline{\\Gamma^{\\cap}}|$ can blow up and\ndepend exponentially on $\\max_{\\rho\\in \\Gamma}\\|\\rho\\|$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:53:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17527","submitter":"Valentin Hartmann","authors":"Valentin N. Hartmann, Marc Toussaint","title":"Towards computing low-makespan solutions for multi-arm multi-task\n  planning problems","comments":"Workshop for Planning and Robotics (PlanRob), International\n  Conference on Automated Planning and Scheduling (ICAPS), 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose an approach to find low-makespan solutions to multi-robot\nmulti-task planning problems in environments where robots block each other from\ncompleting tasks simultaneously. We introduce a formulation of the problem that\nallows for an approach based on greedy descent with random restarts for\ngeneration of the task assignment and task sequence. We then use a multi-agent\npath planner to evaluate the makespan of a given assignment and sequence. The\nplanner decomposes the problem into multiple simple subproblems that only\ncontain a single robots and a single task, and can thus be solved quickly to\nproduce a solution for a fixed task sequence. The solutions to the subproblems\nare then combined to form a valid solution to the original problem. We showcase\nthe approach on robotic stippling and robotic bin picking with up to 4 robot\narms. The makespan of the solutions found by our algorithm are up to 30% lower\ncompared to a greedy approach.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:59:13 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 20:04:12 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17528","submitter":"Nils Palumbo","authors":"Nils Palumbo, Yang Guo, Xi Wu, Jiefeng Chen, Yingyu Liang, Somesh Jha","title":"Two Heads are Better than One: Towards Better Adversarial Robustness by\n  Combining Transduction and Rejection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Both transduction and rejection have emerged as important techniques for\ndefending against adversarial perturbations. A recent work by Tram\\`er showed\nthat, in the rejection-only case (no transduction), a strong rejection-solution\ncan be turned into a strong (but computationally inefficient) non-rejection\nsolution. This detector-to-classifier reduction has been mostly applied to give\nevidence that certain claims of strong selective-model solutions are\nsusceptible, leaving the benefits of rejection unclear. On the other hand, a\nrecent work by Goldwasser et al. showed that rejection combined with\ntransduction can give provable guarantees (for certain problems) that cannot be\nachieved otherwise. Nevertheless, under recent strong adversarial attacks\n(GMSA, which has been shown to be much more effective than AutoAttack against\ntransduction), Goldwasser et al.'s work was shown to have low performance in a\npractical deep-learning setting. In this paper, we take a step towards\nrealizing the promise of transduction+rejection in more realistic scenarios.\nTheoretically, we show that a novel application of Tram\\`er's\nclassifier-to-detector technique in the transductive setting can give\nsignificantly improved sample-complexity for robust generalization. While our\ntheoretical construction is computationally inefficient, it guides us to\nidentify an efficient transductive algorithm to learn a selective model.\nExtensive experiments using state of the art attacks (AutoAttack, GMSA) show\nthat our solutions provide significantly better robust accuracy.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:06:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17529","submitter":"Fei Liu","authors":"Yebowen Hu and Tim Ganter and Hanieh Deilamsalehy and Franck\n  Dernoncourt and Hassan Foroosh and Fei Liu","title":"MeetingBank: A Benchmark Dataset for Meeting Summarization","comments":"ACL 2023 Long Paper","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As the number of recorded meetings increases, it becomes increasingly\nimportant to utilize summarization technology to create useful summaries of\nthese recordings. However, there is a crucial lack of annotated meeting corpora\nfor developing this technology, as it can be hard to collect meetings,\nespecially when the topics discussed are confidential. Furthermore, meeting\nsummaries written by experienced writers are scarce, making it hard for\nabstractive summarizers to produce sensible output without a reliable\nreference. This lack of annotated corpora has hindered the development of\nmeeting summarization technology. In this paper, we present MeetingBank, a new\nbenchmark dataset of city council meetings over the past decade. MeetingBank is\nunique among other meeting corpora due to its divide-and-conquer approach,\nwhich involves dividing professionally written meeting minutes into shorter\npassages and aligning them with specific segments of the meeting. This breaks\ndown the process of summarizing a lengthy meeting into smaller, more manageable\ntasks. The dataset provides a new testbed of various meeting summarization\nsystems and also allows the public to gain insight into how council decisions\nare made. We make the collection, including meeting video links, transcripts,\nreference summaries, agenda, and other metadata, publicly available to\nfacilitate the development of better meeting summarization techniques. Our\ndataset can be accessed at: https://meetingbank.github.io\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:09:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17530","submitter":"Qingqing Cao","authors":"Qingqing Cao, Bhargavi Paranjape, Hannaneh Hajishirzi","title":"PuMer: Pruning and Merging Tokens for Efficient Vision Language Models","comments":"Accepted to ACL 2023 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large-scale vision language (VL) models use Transformers to perform\ncross-modal interactions between the input text and image. These cross-modal\ninteractions are computationally expensive and memory-intensive due to the\nquadratic complexity of processing the input image and text. We present PuMer:\na token reduction framework that uses text-informed Pruning and modality-aware\nMerging strategies to progressively reduce the tokens of input image and text,\nimproving model inference speed and reducing memory footprint. PuMer learns to\nkeep salient image tokens related to the input text and merges similar textual\nand visual tokens by adding lightweight token reducer modules at several\ncross-modal layers in the VL model. Training PuMer is mostly the same as\nfinetuning the original VL model but faster. Our evaluation for two vision\nlanguage models on four downstream VL tasks shows PuMer increases inference\nthroughput by up to 2x and reduces memory footprint by over 50% while incurring\nless than a 1% accuracy drop.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:16:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17531","submitter":"Senwei Liang","authors":"Senwei Liang, Aditya N. Singh, Yuanran Zhu, David T. Limmer, Chao Yang","title":"Probing reaction channels via reinforcement learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph cs.AI cs.LG cs.NA math.NA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a reinforcement learning based method to identify important\nconfigurations that connect reactant and product states along chemical reaction\npaths. By shooting multiple trajectories from these configurations, we can\ngenerate an ensemble of configurations that concentrate on the transition path\nensemble. This configuration ensemble can be effectively employed in a neural\nnetwork-based partial differential equation solver to obtain an approximation\nsolution of a restricted Backward Kolmogorov equation, even when the dimension\nof the problem is very high. The resulting solution, known as the committor\nfunction, encodes mechanistic information for the reaction and can in turn be\nused to evaluate reaction rates.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:22:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17532","submitter":"Steven Dale Cutkosky","authors":"Steven Dale Cutkosky and Parangama Sarkar","title":"Epsilon multiplicity and analytic spread of filtrations","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We extend the epsilon multiplicity of ideals defined by Ulrich and Validashti\nto epsilon multiplicity of filtrations, and show that under mild assumptions\nthis multiplicity exists as a limit. We show that in rather general rings, the\nepsilon multiplicity of a Q-divisorial filtration is positive if and only if\nthe analytic spread of the filtration is maximal (equal to the dimension of the\nring). The condition that filtrations $\\mathcal J\\subset \\mathcal I$ have the\nsame epsilon multiplicity is considered, and we find conditions ensuring that\nthe filtrations have the same integral closure.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:26:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17533","submitter":"Lukas K\\\"obbing","authors":"Lukas K\\\"obbing, Arnulf Latz, Birger Horstmann","title":"Voltage Hysteresis of Silicon Nanoparticles: Chemo-Mechanical\n  Particle-SEI Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Silicon is a promising anode material for next-generation lithium-ion\nbatteries. However, the volume change and the voltage hysteresis during\nlithiation and delithiation are two substantial drawbacks for their lifetime\nand performance. We investigate the reason for the voltage hysteresis in\namorphous silicon nanoparticles covered by a solid-electrolyte interphase\n(SEI). Concentration gradients inside the nanoscale silicon can not produce the\nmassive stresses necessary to cause the voltage hysteresis. Our\nchemo-mechanical model shows that plastic deformation of the stiff, inorganic\nSEI during lithiation and delithiation reproduces the observed silicon\nopen-circuit voltage hysteresis. Additionally, the viscous behavior of the SEI\nexplains the difference between the voltage hysteresis observed at low currents\nand after relaxation. We conclude that the visco-elastoplastic behavior of the\nSEI is the origin of the voltage hysteresis in silicon nanoparticle anodes.\nThus, consideration of the SEI mechanics is crucial for further improvements.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:34:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17534","submitter":"Adam Storek","authors":"Adam Storek, Melanie Subbiah, Kathleen McKeown","title":"Unsupervised Selective Rationalization with Noise Injection","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A major issue with using deep learning models in sensitive applications is\nthat they provide no explanation for their output. To address this problem,\nunsupervised selective rationalization produces rationales alongside\npredictions by chaining two jointly-trained components, a rationale generator\nand a predictor. Although this architecture guarantees that the prediction\nrelies solely on the rationale, it does not ensure that the rationale contains\na plausible explanation for the prediction. We introduce a novel training\ntechnique that effectively limits generation of implausible rationales by\ninjecting noise between the generator and the predictor. Furthermore, we\npropose a new benchmark for evaluating unsupervised selective rationalization\nmodels using movie reviews from existing datasets. We achieve sizeable\nimprovements in rationale plausibility and task accuracy over the\nstate-of-the-art across a variety of tasks, including our new benchmark, while\nmaintaining or improving model faithfulness.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:34:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17535","submitter":"Samuel M\\\"uller","authors":"Samuel M\\\"uller, Matthias Feurer, Noah Hollmann, Frank Hutter","title":"PFNs4BO: In-Context Learning for Bayesian Optimization","comments":"Accepted at ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible\nsurrogate for Bayesian Optimization (BO). PFNs are neural processes that are\ntrained to approximate the posterior predictive distribution (PPD) through\nin-context learning on any prior distribution that can be efficiently sampled\nfrom. We describe how this flexibility can be exploited for surrogate modeling\nin BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and\na Bayesian Neural Network (BNN). In addition, we show how to incorporate\nfurther information into the prior, such as allowing hints about the position\nof optima (user priors), ignoring irrelevant dimensions, and performing\nnon-myopic BO by learning the acquisition function. The flexibility underlying\nthese extensions opens up vast possibilities for using PFNs for BO. We\ndemonstrate the usefulness of PFNs for BO in a large-scale evaluation on\nartificial GP samples and three different hyperparameter optimization testbeds:\nHPO-B, Bayesmark, and PD1. We publish code alongside trained models at\nhttps://github.com/automl/PFNs4BO.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:35:01 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 17:05:51 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17536","submitter":"Vinod Reddy I","authors":"Sriram Bhyravarapu, Swati Kumari, I. Vinod Reddy","title":"On Locally Identifying Coloring of Cartesian Product and Tensor Product\n  of Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For a positive integer $k$, a proper $k$-coloring of a graph $G$ is a mapping\n$f: V(G) \\rightarrow \\{1,2, \\ldots, k\\}$ such that $f(u) \\neq f(v)$ for each\nedge $uv \\in E(G)$. The smallest integer $k$ for which there is a proper\n$k$-coloring of $G$ is called chromatic number of $G$, denoted by $\\chi(G)$.\n  A \\emph{locally identifying coloring} (for short, lid-coloring) of a graph\n$G$\n  is a proper $k$-coloring of $G$ such that every pair of adjacent vertices\nwith distinct closed neighborhoods has distinct set of colors in their closed\nneighborhoods.\n  The smallest integer $k$ such that $G$ has a lid-coloring with $k$ colors is\ncalled\n  \\emph{locally identifying chromatic number}\n  (for short, \\emph{lid-chromatic number}) of $G$, denoted by $\\chi_{lid}(G)$.\n  In this paper, we study lid-coloring of Cartesian product and tensor product\nof two graphs. We prove that if $G$ and $H$ are two connected graphs having at\nleast two vertices then (a) $\\chi_{lid}(G \\square H) \\leq \\chi(G) \\chi(H)-1$\nand (b) $\\chi_{lid}(G \\times H) \\leq \\chi(G) \\chi(H)$. Here $G \\square H$ and\n$G \\times H$ denote the Cartesian and tensor products of $G$ and $H$\nrespectively. We also give exact values of lid-chromatic number of Cartesian\nproduct (resp. tensor product) of two paths, a cycle and a path, and two\ncycles.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:35:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17537","submitter":"Andrey Kurenkov","authors":"Andrey Kurenkov, Michael Lingelbach, Tanmay Agarwal, Chengshu Li,\n  Emily Jin, Ruohan Zhang, Fei-Fei Li, Jiajun Wu, Silvio Savarese, Roberto\n  Mart\\'in-Mart\\'in","title":"Modeling Dynamic Environments with Scene Graph Memory","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Embodied AI agents that search for objects in large environments such as\nhouseholds often need to make efficient decisions by predicting object\nlocations based on partial information. We pose this as a new type of link\nprediction problem: link prediction on partially observable dynamic graphs. Our\ngraph is a representation of a scene in which rooms and objects are nodes, and\ntheir relationships are encoded in the edges; only parts of the changing graph\nare known to the agent at each timestep. This partial observability poses a\nchallenge to existing link prediction approaches, which we address. We propose\na novel state representation -- Scene Graph Memory (SGM) -- with captures the\nagent's accumulated set of observations, as well as a neural net architecture\ncalled a Node Edge Predictor (NEP) that extracts information from the SGM to\nsearch efficiently. We evaluate our method in the Dynamic House Simulator, a\nnew benchmark that creates diverse dynamic graphs following the semantic\npatterns typically seen at homes, and show that NEP can be trained to predict\nthe locations of objects in a variety of environments with diverse object\nmovement dynamics, outperforming baselines both in terms of new scene\nadaptability and overall accuracy. The codebase and more can be found at\nhttps://www.scenegraphmemory.com.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:39:38 GMT"},{"version":"v2","created":"Wed, 31 May 2023 10:33:11 GMT"},{"version":"v3","created":"Fri, 2 Jun 2023 21:49:22 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17538","submitter":"Gabriel Grime","authors":"Gabriel C. Grime, Marisa Roberto, Ricardo L. Viana, Yves Elskens,\n  Iber\\^e L. Caldas","title":"Shearless curve breakup in the biquadratic nontwist map","comments":"12 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.CD math.DS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Nontwist area-preserving maps violate the twist condition along shearless\ninvariant curves, which act as transport barriers in phase space. Recently,\nsome plasma models have presented multiple shearless curves in phase space and\nthese curves can break up independently. In this paper, we describe the\ndifferent shearless curve breakup scenarios of the so-called biquadratic\nnontwist map, a recently proposed area-preserving map derived from a plasma\nmodel, that captures the essential behavior of systems with multiple shearless\ncurves. Three different scenarios are found and their dependence on the system\nparameters is analyzed. The results indicate a relation between shearless curve\nbreakup and periodic orbit reconnection-collision sequences. In addition, even\nafter a shearless curve breakup, the remaining curves inhibit global transport.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:49:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17539","submitter":"Soheil Karimi Aghda","authors":"Soheil Karimi Aghda, Dimitri Bogdanovski, Lukas Loefler, Heng Han Sua,\n  Lena Patterer, Damian M. Holzapfel, Arnaud le Febvrier, Marcus Hans, Daniel\n  Primetzhofer, and Jochen M. Schneider","title":"Valence electron concentration- and N vacancy-induced elasticity in\n  cubic early transition metal nitrides","comments":"30 pages, 8 figures in the manuscript, 1 figure in supplementary\n  materials","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Motivated by frequently reported deviations from stoichiometry in cubic\ntransition metal nitride (TMNx) thin films, the effect of N-vacancy\nconcentration on the elastic properties of cubic TiNx, ZrNx, VNx, NbNx, and\nMoNx (0.72<x<1.00) is systematically studied by density functional theory (DFT)\ncalculations. The predictions are validated experimentally for VNx\n(0.77<x<0.97). The DFT results indicate that the elastic behavior of the TMNx\ndepends on both the N-vacancy concentration and the valence electron\nconcentration (VEC) of the transition metal: While TiNx and ZrNx exhibit\nvacancy-induced reductions in elastic modulus, VNx and NbNx show an increase.\nThese trends can be rationalized by considering vacancy-induced changes in\nelastic anisotropy and bonding. While introduction of N-vacancies in TiNx\nresults in a significant reduction of elastic modulus along all directions and\na lower average bond strength of Ti-N, the vacancy-induced reduction in [001]\ndirection of VNx is overcompensated by the higher stiffness along [011] and\n[111] directions, resulting in a higher average bond strength of V-N. To\nvalidate the predicted vacancy-induced changes in elasticity experimentally,\nclose-to-single-crystal VNx (0.77<x<0.97) are grown on MgO(001) substrates. As\nthe N-content is reduced, the relaxed lattice parameter a0, as probed by X-ray\ndiffraction, decreases from 4.128 A to 4.096 A. This reduction in lattice\nparameter is accompanied by an anomalous 11% increase in elastic modulus, as\ndetermined by nanoindentation. As the experimental data agree with the\npredictions, the elasticity enhancement in VNx upon N-vacancy formation can be\nunderstood based on the concomitant changes in elastic anisotropy and bonding.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:56:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17540","submitter":"Hammad Ayyubi","authors":"Hammad A. Ayyubi, Rahul Lokesh, Alireza Zareian, Bo Wu, Shih-Fu Chang","title":"Learning from Children: Improving Image-Caption Pretraining via\n  Curriculum","comments":"ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Image-caption pretraining has been quite successfully used for downstream\nvision tasks like zero-shot image classification and object detection. However,\nimage-caption pretraining is still a hard problem -- it requires multiple\nconcepts (nouns) from captions to be aligned to several objects in images. To\ntackle this problem, we go to the roots -- the best learner, children. We take\ninspiration from cognitive science studies dealing with children's language\nlearning to propose a curriculum learning framework. The learning begins with\neasy-to-align image caption pairs containing one concept per caption. The\ndifficulty is progressively increased with each new phase by adding one more\nconcept per caption. Correspondingly, the knowledge acquired in each learning\nphase is utilized in subsequent phases to effectively constrain the learning\nproblem to aligning one new concept-object pair in each phase. We show that\nthis learning strategy improves over vanilla image-caption training in various\nsettings -- pretraining from scratch, using a pretrained image or/and\npretrained text encoder, low data regime etc.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:59:54 GMT"},{"version":"v2","created":"Tue, 30 May 2023 15:43:50 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17541","submitter":"Todd Bichoupan","authors":"Todd Bichoupan","title":"Minimal Posets with Prescribed Maximal Chain Cardinalities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Given a nonempty finite multiset $S$ of positive integers, we wish to find a\npartially ordered set $P$ of minimal cardinality such that the multiset of\ncardinalities of all maximal chains in $P$ equals $S$. This paper establishes\nupper and lower bounds on the size of $P$: $\\max(S) + \\lceil \\log_2 |S| \\rceil\n<= |P| <= \\max(S) + |S| - 1$, and both bounds are tight.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:06:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17542","submitter":"Yu Zhou","authors":"Yu Zhou, Sha Li, Manling Li, Xudong Lin, Shih-Fu Chang, Mohit Bansal\n  and Heng Ji","title":"Non-Sequential Graph Script Induction via Multimedia Grounding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.MM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Online resources such as WikiHow compile a wide range of scripts for\nperforming everyday tasks, which can assist models in learning to reason about\nprocedures. However, the scripts are always presented in a linear manner, which\ndoes not reflect the flexibility displayed by people executing tasks in real\nlife. For example, in the CrossTask Dataset, 64.5% of consecutive step pairs\nare also observed in the reverse order, suggesting their ordering is not fixed.\nIn addition, each step has an average of 2.56 frequent next steps,\ndemonstrating \"branching\". In this paper, we propose the new challenging task\nof non-sequential graph script induction, aiming to capture optional and\ninterchangeable steps in procedural planning. To automate the induction of such\ngraph scripts for given tasks, we propose to take advantage of loosely aligned\nvideos of people performing the tasks. In particular, we design a multimodal\nframework to ground procedural videos to WikiHow textual steps and thus\ntransform each video into an observed step path on the latent ground truth\ngraph script. This key transformation enables us to train a script knowledge\nmodel capable of both generating explicit graph scripts for learnt tasks and\npredicting future steps given a partial step sequence. Our best model\noutperforms the strongest pure text/vision baselines by 17.52% absolute gains\non F1@3 for next step prediction and 13.8% absolute gains on Acc@1 for partial\nsequence completion. Human evaluation shows our model outperforming the WikiHow\nlinear baseline by 48.76% absolute gains in capturing sequential and\nnon-sequential step relationships.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:13:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17543","submitter":"Shashank Kanade","authors":"Shashank Kanade","title":"Characters of logarithmic vertex operator algebras and coloured\n  invariants of torus links","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA math-ph math.GT math.MP math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the characters of $\\mathfrak{sl}_r$ versions of the $(1,p)$\nsinglet and the $(1,p)$ triplet VOAs arise as limits of appropriately coloured\n$\\mathfrak{sl}_r$ Jones invariants of certain torus links.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:15:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17544","submitter":"Guanghui Wang","authors":"Guanghui Wang, Zihao Hu, Vidya Muthukumar, Jacob Abernethy","title":"Faster Margin Maximization Rates for Generic Optimization Methods","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  First-order optimization methods tend to inherently favor certain solutions\nover others when minimizing a given training objective with multiple local\noptima. This phenomenon, known as implicit bias, plays a critical role in\nunderstanding the generalization capabilities of optimization algorithms.\nRecent research has revealed that gradient-descent-based methods exhibit an\nimplicit bias for the $\\ell_2$-maximal margin classifier in the context of\nseparable binary classification. In contrast, generic optimization methods,\nsuch as mirror descent and steepest descent, have been shown to converge to\nmaximal margin classifiers defined by alternative geometries. However, while\ngradient-descent-based algorithms demonstrate fast implicit bias rates, the\nimplicit bias rates of generic optimization methods have been relatively slow.\nTo address this limitation, in this paper, we present a series of\nstate-of-the-art implicit bias rates for mirror descent and steepest descent\nalgorithms. Our primary technique involves transforming a generic optimization\nalgorithm into an online learning dynamic that solves a regularized bilinear\ngame, providing a unified framework for analyzing the implicit bias of various\noptimization methods. The accelerated rates are derived leveraging the regret\nbounds of online learning algorithms within this game framework.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:16:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17545","submitter":"Smarajit Karmakar Dr.","authors":"Rishabh Sharma and Smarajit Karmakar","title":"Activity-Induced Annealing leads to Ductile-to-Brittle Transition in\n  Amorphous Solids","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft cond-mat.dis-nn cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Investigating the behavior of amorphous solids under various external loading\nconditions continues to be an intriguing area of research with significant\npractical implications. In this study, we demonstrate the utilization of\nself-motility as a means to anneal glasses and use that as a means to fine-tune\nthe failure mode of the system under uniaxial tensile deformation. We begin by\nhighlighting the annealing effects of activity and draw parallels with other\nwell-known mechanical annealing processes, such as oscillatory shearing (both\nuni- and multi-directional). Furthermore, we explore the annealing effects in\nthe presence of open boundaries, observing enhanced surface relaxations due to\nactivity. By implementing various activity-induced annealing protocols, we\nsuccessfully induce a transition in the failure mode from ductile to brittle.\nThis is demonstrated via performing tensile tests on the glass samples\nresulting from the active-annealing process. The intricate effects of geometry\non the formation of shear bands are also examined. We find that samples having\nan aspect ratio greater than one fail via shear band formation, owing to their\nformation angle of $45\\degree$ from the strain axis. In conclusion, we\nintroduce a novel method for producing well-annealed glasses in silico and\nestablish a correspondence between sheared and actively driven glasses.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:26:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17546","submitter":"Girsh Blumberg","authors":"A. Lee, H.-H. Kung, Xueyun Wang, S.-W. Cheong, and G. Blumberg","title":"Electronic and Vibrational Excitations on the Surface of the\n  Three-Dimensional Topological Insulator Bi$_2$Te$_{3-x}$Se$_{x}$ (x = 0, 2,\n  3)","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study surface states in the three-dimensional topological insulators\nBi$_2$Te$_{3-x}$Se$_{x}$ (x = 0, 2, 3) by polarization resolved resonant Raman\nspectroscopy. By tracking the spectral intensity of the surface phonon modes\nwith respect to the incident photon energy, we show that the surface phonons\nare qualitatively similar to their bulk counterparts. Using the resonant Raman\nexcitation profile, we estimated the binding energy of the surface conduction\nbands relative to bulk conduction bands. In addition, by analyzing the Fano\ninteraction between the electronic continuum and the surface phonons as a\nfunction of incident photon energy, we determined the spectral properties of\nthe electronic continuum excitations between surface and bulk states in\nBi$_2$Se$_3$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:27:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17547","submitter":"Eliya Nachmani","authors":"Eliya Nachmani, Alon Levkovitch, Yifan Ding, Chulayuth Asawaroengchai,\n  Heiga Zen, Michelle Tadmor Ramanovich","title":"Translatotron 3: Speech to Speech Translation with Monolingual Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents Translatotron 3, a novel approach to train a direct\nspeech-to-speech translation model from monolingual speech-text datasets only\nin a fully unsupervised manner. Translatotron 3 combines masked autoencoder,\nunsupervised embedding mapping, and back-translation to achieve this goal.\nExperimental results in speech-to-speech translation tasks between Spanish and\nEnglish show that Translatotron 3 outperforms a baseline cascade system,\nreporting 18.14 BLEU points improvement on the synthesized\nUnpaired-Conversational dataset. In contrast to supervised approaches that\nnecessitate real paired data, which is unavailable, or specialized modeling to\nreplicate para-/non-linguistic information, Translatotron 3 showcases its\ncapability to retain para-/non-linguistic such as pauses, speaking rates, and\nspeaker identity. Audio samples can be found in our website\nhttp://google-research.github.io/lingvo-lab/translatotron3\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:30:54 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 08:01:16 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17548","submitter":"Elena Fantino Dr","authors":"Elena Fantino, Burhani M. Burhani, Roberto Flores, Elisa Maria Alessi,\n  Fernando Solano, Manuel Sanjurjo-Rivo","title":"A novel trajectory concept for a mission to the Inner Large Moons of\n  Saturn","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a novel concept for a small mission to the four inner large\nsatellites of Saturn. Leveraging the high efficiency of electric propulsion,\nthe concept enables orbit insertion around each of the moons, for arbitrarily\nlong close observation periods. The mission starts with a EVVES interplanetary\nsegment, where a combination of multiple gravity assist and deep space low\nthrust enables reduced relative arrival velocity at Saturn. As a result, an\nunpowered capture via a sequence of resonant flybys with Titan is possible. The\ntransfers between moons use a low-thrust control law that connects unstable and\nstable branches of the invariant manifolds of planar Lyapunov orbits from the\ncircular restricted three-body problem of each moon and Saturn. The exploration\nof the moons relies on homoclinic and heteroclinic connections of the Lyapunov\norbits around the L$_1$ and L$_2$ equilibrium points. These science orbits can\nbe extended for arbitrary lengths of time with negligible propellant usage. The\nstrategy enables a comprehensive scientific exploration of the inner large\nmoons, located deep inside the gravitational well of Saturn, which is\nunfeasible with conventional impulsive maneuvers due to excessive fuel\nconsumption.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:35:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17549","submitter":"Benjamin Frandsen","authors":"Raju Baral, Milinda Abeykoon, Branton J. Campbell, Benjamin A.\n  Frandsen","title":"Giant spontaneous magnetostriction in MnTe driven by a novel\n  magnetostructural coupling mechanism","comments":"Submitted May 11, 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a comprehensive x-ray scattering study of spontaneous\nmagnetostriction in hexagonal MnTe, an antiferromagnetic semiconductor with a\nNeel temperature of $T_{\\mathrm{N}} = 307$ K. We observe the largest\nspontaneous magnetovolume effect known for an antiferromagnet, reaching a\nvolume contraction of $|\\Delta V/V| > 7 \\times 10^{-3}$. This can be justified\nsemiquantitatively by considering bulk material properties, the spatial\ndependence of the superexchange interaction, and the geometrical arrangement of\nmagnetic moments in MnTe. The highly unusual linear scaling of the\nmagnetovolume effect with the short-range magnetic correlations, beginning in\nthe paramagnetic state well above $T_{\\mathrm{N}}$, points to a novel physical\nmechanism, which we explain in terms of a trilinear coupling of the elastic\nstrain with superposed distinct domains of the antiferromagnetic order\nparameter. This novel mechanism for coupling lattice strain to robust\nshort-range magnetic order casts new light on magnetostrictive phenomena and\nalso provides a template by which the exceptional magnetostrictive properties\nof MnTe might be realized in a wide range of other functional materials.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:40:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17550","submitter":"Dennis Bonatsos","authors":"Dennis Bonatsos, Andriana Martinou, S.K. Peroulis, T.J. Mertzimekis,\n  and N. Minkov","title":"Signatures for shape coexistence and shape/phase transitions in\n  even-even nuclei","comments":"13 pages, 4 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Systematics of B(E2) transition rates connecting the first excited 0+ state\nto the first excited 2+ state of the ground state band in even-even nuclei\nindicates that shape coexistence of the ground state band and the first excited\nK=0 band should be expected in nuclei lying within the stripes of nucleon\nnumbers 7-8, 17-20, 34-40, 59-70, 96-112 predicted by the dual shell mechanism\nof the proxy-SU(3) model, avoiding their junctions, within which high\ndeformation is expected. Systematics of the excitation energies of the first\nexcited 0+ states in even-even nuclei show that shape coexistence due to\nproton-induced neutron particle-hole excitations is related to a first-order\nshape/phase transition from spherical to deformed shapes, while shape\ncoexistence due to neutron-induced proton particle-hole excitations is observed\nalong major proton shell closures.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:51:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17551","submitter":"Elena Fantino Dr","authors":"Roberto Flores, Mauro Pontani, Elena Fantino","title":"Statistical Study of Uncontrolled Geostationary Satellites Near an\n  Unstable Equilibrium Point","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The growth of the population of space debris in the geostationary ring and\nthe resulting threat to active satellites require insight into the dynamics of\nuncontrolled objects in the region. A Monte Carlo simulation analyzed the\nsensitivity to initial conditions of the long-term evolution of geostationary\nspacecraft near an unstable point of the geopotential, where irregular behavior\n(e.g., transitions between long libration and continuous circulation) occurs. A\nstatistical analysis unveiled sudden transitions from order to disorder,\ninterspersed with intervals of smooth evolution. There is a periodicity of\napproximately half a century in the episodes of disorder, suggesting a\nconnection with the precession of the orbital plane, due to Earth's oblateness\nand lunisolar perturbations. The third-degree harmonics of the geopotential\nalso play a vital role. They introduce an asymmetry between the unstable\nequilibrium points, enabling the long libration mode. The unpredictability\noccurs just in a small fraction of the precession cycle, when the inclination\nis close to zero. A simplified model, including only gravity harmonics up to\ndegree 3 and the Earth and Moon in circular coplanar orbits is capable of\nreproducing most features of the high-fidelity simulation.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:58:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17552","submitter":"Elad Hazan","authors":"Udaya Ghai, Arushi Gupta, Wenhan Xia, Karan Singh, Elad Hazan","title":"Online Nonstochastic Model-Free Reinforcement Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we explore robust model-free reinforcement learning algorithms\nfor environments that may be dynamic or even adversarial. Conventional\nstate-based policies fail to accommodate the challenge imposed by the presence\nof unmodeled disturbances in such settings. Additionally, optimizing linear\nstate-based policies pose obstacle for efficient optimization, leading to\nnonconvex objectives even in benign environments like linear dynamical systems.\n  Drawing inspiration from recent advancements in model-based control, we\nintroduce a novel class of policies centered on disturbance signals. We define\nseveral categories of these signals, referred to as pseudo-disturbances, and\ncorresponding policy classes based on them. We provide efficient and practical\nalgorithms for optimizing these policies.\n  Next, we examine the task of online adaptation of reinforcement learning\nagents to adversarial disturbances. Our methods can be integrated with any\nblack-box model-free approach, resulting in provable regret guarantees if the\nunderlying dynamics is linear. We evaluate our method over different standard\nRL benchmarks and demonstrate improved robustness.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:02:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17553","submitter":"Jason Hoelscher-Obermaier","authors":"Jason Hoelscher-Obermaier, Julia Persson, Esben Kran, Ioannis Konstas\n  and Fazl Barez","title":"Detecting Edit Failures In Large Language Models: An Improved\n  Specificity Benchmark","comments":"To be published in ACL Findings 2023; for code see\n  https://github.com/apartresearch/specificityplus; for a homepage see\n  https://specificityplus.apartresearch.com/; updated Figures to uniform style","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent model editing techniques promise to mitigate the problem of memorizing\nfalse or outdated associations during LLM training. However, we show that these\ntechniques can introduce large unwanted side effects which are not detected by\nexisting specificity benchmarks. We extend the existing CounterFact benchmark\nto include a dynamic component and dub our benchmark CounterFact+.\nAdditionally, we extend the metrics used for measuring specificity by a\nprincipled KL divergence-based metric. We use this improved benchmark to\nevaluate recent model editing techniques and find that they suffer from low\nspecificity. Our findings highlight the need for improved specificity\nbenchmarks that identify and prevent unwanted side effects.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:08:04 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 08:01:11 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17554","submitter":"Fulvio Paleari","authors":"Matteo Zanfrognini and Alexandre Plaud and Ingrid Stenger and\n  Fr\\'ed\\'eric Fossard and Lorenzo Sponza and L\\'eonard Schu\\'e and Fulvio\n  Paleari and Elisa Molinari and Daniele Varsano and Ludger Wirtz and\n  Fran\\c{c}ois Ducastelle and Annick Loiseau and Julien Barjon","title":"Distinguishing different stackings in layered materials via luminescence\n  spectroscopy","comments":"Main: 6 pages and 4 figures, Supplementary: 6 pages and 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite its simple crystal structure, layered boron nitride features a\nsurprisingly complex variety of phonon-assisted luminescence peaks. We present\na combined experimental and theoretical study on ultraviolet-light emission in\nhexagonal and rhombohedral bulk boron nitride crystals. Emission spectra of\nhigh-quality samples are measured via cathodoluminescence spectroscopy,\ndisplaying characteristic differences between the two polytypes. These\ndifferences are explained using a fully first-principles computational\ntechnique that takes into account radiative emission from ``indirect'',\nfinite-momentum, excitons via coupling to finite-momentum phonons. We show that\nthe differences in peak positions, number of peaks and relative intensities can\nbe qualitatively and quantitatively explained, once a full integration over all\nrelevant momenta of excitons and phonons is performed.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:09:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17555","submitter":"Tung Le","authors":"Tung Le, Khai Nguyen, Shanlin Sun, Kun Han, Nhat Ho, Xiaohui Xie","title":"Diffeomorphic Deformation via Sliced Wasserstein Distance Optimization\n  for Cortical Surface Reconstruction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mesh deformation is a core task for 3D mesh reconstruction, but defining an\nefficient discrepancy between predicted and target meshes remains an open\nproblem. A prevalent approach in current deep learning is the set-based\napproach which measures the discrepancy between two surfaces by comparing two\nrandomly sampled point-clouds from the two meshes with Chamfer pseudo-distance.\nNevertheless, the set-based approach still has limitations such as lacking a\ntheoretical guarantee for choosing the number of points in sampled\npoint-clouds, and the pseudo-metricity and the quadratic complexity of the\nChamfer divergence. To address these issues, we propose a novel metric for\nlearning mesh deformation. The metric is defined by sliced Wasserstein distance\non meshes represented as probability measures that generalize the set-based\napproach. By leveraging probability measure space, we gain flexibility in\nencoding meshes using diverse forms of probability measures, such as\ncontinuous, empirical, and discrete measures via \\textit{varifold}\nrepresentation. After having encoded probability measures, we can compare\nmeshes by using the sliced Wasserstein distance which is an effective optimal\ntransport distance with linear computational complexity and can provide a fast\nstatistical rate for approximating the surface of meshes. Furthermore, we\nemploy a neural ordinary differential equation (ODE) to deform the input\nsurface into the target shape by modeling the trajectories of the points on the\nsurface. Our experiments on cortical surface reconstruction demonstrate that\nour approach surpasses other competing methods in multiple datasets and\nmetrics.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:10:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17556","submitter":"Huijun Wang","authors":"Huijun Wang and Oliver Sinnen","title":"Scheduling Fork-Join Task Graphs to Heterogeneous Processors","comments":"14 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The scheduling of task graphs with communication delays has been extensively\nstudied. Recently, new results for the common sub-case of fork-join shaped task\ngraphs were published, including an EPTAS and polynomial algorithms for special\ncases. These new results modelled the target architecture to consist of\nhomogeneous processors. However, forms of heterogeneity become more and more\ncommon in contemporary parallel systems, such as CPU--accelerator systems, with\ntheir two types of resources. In this work, we study the scheduling of\nfork-join task graphs with communication delays, which is representative of\nhighly parallel workloads, onto heterogeneous systems of related processors. We\npresent an EPAS, and some polynomial time algorithms for special cases, such as\nwith equal processing costs or unlimited resources. Lastly, we briefly look at\nthe above described case of two resource-types and its implications. It is\ninteresting to note, that all results here also apply to scheduling independent\ntasks with release times and deadlines.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:14:48 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 16:45:55 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17557","submitter":"Abhisek Chakraborty","authors":"Abhisek Chakraborty, Anirban Bhattacharya, Debdeep Pati","title":"Fair Clustering via Hierarchical Fair-Dirichlet Process","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.CY cs.LG","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The advent of ML-driven decision-making and policy formation has led to an\nincreasing focus on algorithmic fairness. As clustering is one of the most\ncommonly used unsupervised machine learning approaches, there has naturally\nbeen a proliferation of literature on {\\em fair clustering}. A popular notion\nof fairness in clustering mandates the clusters to be {\\em balanced}, i.e.,\neach level of a protected attribute must be approximately equally represented\nin each cluster. Building upon the original framework, this literature has\nrapidly expanded in various aspects. In this article, we offer a novel\nmodel-based formulation of fair clustering, complementing the existing\nliterature which is almost exclusively based on optimizing appropriate\nobjective functions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:16:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17558","submitter":"Aniket Das","authors":"Aniket Das and Dheeraj Nagaraj","title":"Provably Fast Finite Particle Variants of SVGD via Virtual Particle\n  Stochastic Approximation","comments":"34 Pages, 2 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Stein Variational Gradient Descent (SVGD) is a popular variational inference\nalgorithm which simulates an interacting particle system to approximately\nsample from a target distribution, with impressive empirical performance across\nvarious domains. Theoretically, its population (i.e, infinite-particle) limit\ndynamics is well studied but the behavior of SVGD in the finite-particle regime\nis much less understood. In this work, we design two computationally efficient\nvariants of SVGD, namely VP-SVGD (which is conceptually elegant) and GB-SVGD\n(which is empirically effective), with provably fast finite-particle\nconvergence rates. We introduce the notion of \\emph{virtual particles} and\ndevelop novel stochastic approximations of population-limit SVGD dynamics in\nthe space of probability measures, which are exactly implementable using a\nfinite number of particles. Our algorithms can be viewed as specific\nrandom-batch approximations of SVGD, which are computationally more efficient\nthan ordinary SVGD. We show that the $n$ particles output by VP-SVGD and\nGB-SVGD, run for $T$ steps with batch-size $K$, are at-least as good as i.i.d\nsamples from a distribution whose Kernel Stein Discrepancy to the target is at\nmost $O\\left(\\tfrac{d^{1/3}}{(KT)^{1/6}}\\right)$ under standard assumptions.\nOur results also hold under a mild growth condition on the potential function,\nwhich is much weaker than the isoperimetric (e.g. Poincare Inequality) or\ninformation-transport conditions (e.g. Talagrand's Inequality $\\mathsf{T}_1$)\ngenerally considered in prior works. As a corollary, we consider the\nconvergence of the empirical measure (of the particles output by VP-SVGD and\nGB-SVGD) to the target distribution and demonstrate a \\emph{double exponential\nimprovement} over the best known finite-particle analysis of SVGD.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:21:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17559","submitter":"Noga Bar","authors":"Noga Bar and Raja Giryes","title":"Pruning at Initialization -- A Sketching Perspective","comments":"20 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The lottery ticket hypothesis (LTH) has increased attention to pruning neural\nnetworks at initialization. We study this problem in the linear setting. We\nshow that finding a sparse mask at initialization is equivalent to the\nsketching problem introduced for efficient matrix multiplication. This gives us\ntools to analyze the LTH problem and gain insights into it. Specifically, using\nthe mask found at initialization, we bound the approximation error of the\npruned linear model at the end of training. We theoretically justify previous\nempirical evidence that the search for sparse networks may be data independent.\nBy using the sketching perspective, we suggest a generic improvement to\nexisting algorithms for pruning at initialization, which we show to be\nbeneficial in the data-independent case.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:22:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17560","submitter":"Li Zijie","authors":"Zijie Li, Dule Shu, Amir Barati Farimani","title":"Scalable Transformer for PDE Surrogate Modeling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Transformer has shown state-of-the-art performance on various applications\nand has recently emerged as a promising tool for surrogate modeling of partial\ndifferential equations (PDEs). Despite the introduction of linear-complexity\nvariant, applying attention to a large number of grid points can result in\ninstability and is still expensive to compute. In this work, we propose\nFactorized Transformer(FactFormer), which is based on an axial factorized\nkernel integral. Concretely, we introduce a learnable projection operator that\ndecomposes the input function into multiple sub-functions with one-dimensional\ndomain. These sub-functions are then evaluated and used to compute the\ninstance-based kernel with an axial factorized scheme. We showcase that the\nproposed model is able to simulate 2D Kolmogorov flow on a 256 by 256 grid and\n3D smoke buoyancy on a 64 by 64 by 64 grid with good accuracy and efficiency.\nIn addition, we find out that with the factorization scheme, the attention\nmatrices enjoy a more compact spectrum than full softmax-free attention\nmatrices.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:23:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17561","submitter":"Sandeep Soni","authors":"Sandeep Soni, Amanpreet Sihra, Elizabeth F. Evans, Matthew Wilkens,\n  David Bamman","title":"Grounding Characters and Places in Narrative Texts","comments":"12 pages, 4 figures, 5 tables; to appear in the proceedings of ACL\n  2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Tracking characters and locations throughout a story can help improve the\nunderstanding of its plot structure. Prior research has analyzed characters and\nlocations from text independently without grounding characters to their\nlocations in narrative time. Here, we address this gap by proposing a new\nspatial relationship categorization task. The objective of the task is to\nassign a spatial relationship category for every character and location\nco-mention within a window of text, taking into consideration linguistic\ncontext, narrative tense, and temporal scope. To this end, we annotate spatial\nrelationships in approximately 2500 book excerpts and train a model using\ncontextual embeddings as features to predict these relationships. When applied\nto a set of books, this model allows us to test several hypotheses on mobility\nand domestic space, revealing that protagonists are more mobile than\nnon-central characters and that women as characters tend to occupy more\ninterior space than men. Overall, our work is the first step towards joint\nmodeling and analysis of characters and places in narrative text.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:31:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17562","submitter":"Radoslav Harman","authors":"Radoslav Harman and Samuel Rosa","title":"Mixed-integer linear programming for computing optimal experimental\n  designs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the optimal exact design of experiment on a finite design space\ncan be computed via mixed-integer linear programming (MILP) for a wide class of\noptimality criteria, including the criteria of A-, I-, G- and MV-optimality.\nThe key idea of the MILP formulation is the McCormick relaxation, which\ncritically depends on finite interval bounds for the elements of the covariance\nmatrix corresponding to an optimal exact design. We provide both analytic and\nalgorithmic constructions of such bounds. Finally, we demonstrate some unique\nadvantages of the MILP approach and illustrate its performance in selected\nexperimental design settings.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:46:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17563","submitter":"Zikai Xu","authors":"Zikai Xu and John W. Pierre","title":"Solving Cramer-Rao Lower Bound in Single PMU Channel for Forced\n  Oscillations in Power Systems","comments":"conference","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Forced oscillations threaten the reliability of widearea power systems, and\ndifferent approaches to estimate forced oscillation have been explored over the\npast several years. Though these efforts provide powerful tools to estimate a\nforced oscillation's amplitude, frequency, and phase, a benchmark for\nestimation accuracy has not been available.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:49:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17564","submitter":"Charles Lu","authors":"Charles Lu, Yaodong Yu, Sai Praneeth Karimireddy, Michael I. Jordan,\n  Ramesh Raskar","title":"Federated Conformal Predictors for Distributed Uncertainty\n  Quantification","comments":"23 pages, 18 figures, accepted to International Conference on Machine\n  Learning (ICML 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Conformal prediction is emerging as a popular paradigm for providing rigorous\nuncertainty quantification in machine learning since it can be easily applied\nas a post-processing step to already trained models. In this paper, we extend\nconformal prediction to the federated learning setting. The main challenge we\nface is data heterogeneity across the clients - this violates the fundamental\ntenet of exchangeability required for conformal prediction. We propose a weaker\nnotion of partial exchangeability, better suited to the FL setting, and use it\nto develop the Federated Conformal Prediction (FCP) framework. We show FCP\nenjoys rigorous theoretical guarantees and excellent empirical performance on\nseveral computer vision and medical imaging datasets. Our results demonstrate a\npractical approach to incorporating meaningful uncertainty quantification in\ndistributed and heterogeneous environments. We provide code used in our\nexperiments https://github.com/clu5/federated-conformal.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:57:27 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 17:30:15 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17565","submitter":"Liquan Wang","authors":"Liquan Wang, Nikita Dvornik, Rafael Dubeau, Mayank Mittal, Animesh\n  Garg","title":"Self-Supervised Learning of Action Affordances as Interaction Modes","comments":null,"journal-ref":"2023 International Conference on Robotics and Automation","doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  When humans perform a task with an articulated object, they interact with the\nobject only in a handful of ways, while the space of all possible interactions\nis nearly endless. This is because humans have prior knowledge about what\ninteractions are likely to be successful, i.e., to open a new door we first try\nthe handle. While learning such priors without supervision is easy for humans,\nit is notoriously hard for machines. In this work, we tackle unsupervised\nlearning of priors of useful interactions with articulated objects, which we\ncall interaction modes. In contrast to the prior art, we use no supervision or\nprivileged information; we only assume access to the depth sensor in the\nsimulator to learn the interaction modes. More precisely, we define a\nsuccessful interaction as the one changing the visual environment substantially\nand learn a generative model of such interactions, that can be conditioned on\nthe desired goal state of the object. In our experiments, we show that our\nmodel covers most of the human interaction modes, outperforms existing\nstate-of-the-art methods for affordance learning, and can generalize to objects\nnever seen during training. Additionally, we show promising results in the\ngoal-conditional setup, where our model can be quickly fine-tuned to perform a\ngiven task. We show in the experiments that such affordance learning predicts\ninteraction which covers most modes of interaction for the querying articulated\nobject and can be fine-tuned to a goal-conditional model. For supplementary:\nhttps://actaim.github.io.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:58:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17566","submitter":"Chenkun Zhou","authors":"Chenkun Zhou, Di Wang, Francisco Lagunas, Benjamin Atterberry, Ming\n  Lei, Huicheng Hu, Zirui Zhou, Alexander S. Filatov, De-en Jiang, Aaron J.\n  Rossini, Robert F. Klie, Dmitri V. Talapin","title":"Hybrid organic-inorganic two-dimensional metal carbide MXenes with\n  amido- and imido-terminated surfaces","comments":"10 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Two-dimensional (2D) transition-metal carbides and nitrides (MXenes) show\nimpressive performance in applications, such as supercapacitors, batteries,\nelectromagnetic interference shielding, or electrocatalysis. These materials\ncombine the electronic and mechanical properties of 2D inorganic crystals with\nchemically modifiable surfaces, and surface-engineered MXenes represent an\nideal platform for fundamental and applied studies of interfaces in 2D\nfunctional materials. A natural step in structural engineering of MXene\ncompounds is the development and understanding of MXenes with various organic\nfunctional groups covalently bound to inorganic 2D sheets. Such hybrid\nstructures have the potential to unite the tailorability of organic molecules\nwith the unique electronic properties of inorganic 2D solids. Here, we\nintroduce a new family of hybrid MXenes (h-MXenes) with amido- and\nimido-bonding between organic and inorganic parts. The description of h-MXene\nstructure requires an intricate mix of concepts from the fields of coordination\nchemistry, self-assembled monolayers (SAMs) and surface science. The optical\nproperties of h-MXenes reveal coherent coupling between the organic and\ninorganic components. h-MXenes also show superior stability against hydrolysis\nin aqueous solutions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:06:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17567","submitter":"Mengzi Amy Guo","authors":"Mengzi Amy Guo, Donghao Ying, Javad Lavaei, Zuo-Jun Max Shen","title":"No-Regret Learning in Dynamic Competition with Reference Effects Under\n  Logit Demand","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT math.OC","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  This work is dedicated to the algorithm design in a competitive framework,\nwith the primary goal of learning a stable equilibrium. We consider the dynamic\nprice competition between two firms operating within an opaque marketplace,\nwhere each firm lacks information about its competitor. The demand follows the\nmultinomial logit (MNL) choice model, which depends on the consumers' observed\nprice and their reference price, and consecutive periods in the repeated games\nare connected by reference price updates. We use the notion of stationary Nash\nequilibrium (SNE), defined as the fixed point of the equilibrium pricing policy\nfor the single-period game, to simultaneously capture the long-run market\nequilibrium and stability. We propose the online projected gradient ascent\nalgorithm (OPGA), where the firms adjust prices using the first-order\nderivatives of their log-revenues that can be obtained from the market feedback\nmechanism. Despite the absence of typical properties required for the\nconvergence of online games, such as strong monotonicity and variational\nstability, we demonstrate that under diminishing step-sizes, the price and\nreference price paths generated by OPGA converge to the unique SNE, thereby\nachieving the no-regret learning and a stable market. Moreover, with\nappropriate step-sizes, we prove that this convergence exhibits a rate of\n$\\mathcal{O}(1/t)$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:08:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17568","submitter":"Donghao Ying","authors":"Donghao Ying, Yunkai Zhang, Yuhao Ding, Alec Koppel, Javad Lavaei","title":"Scalable Primal-Dual Actor-Critic Method for Safe Multi-Agent RL with\n  General Utilities","comments":"50 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We investigate safe multi-agent reinforcement learning, where agents seek to\ncollectively maximize an aggregate sum of local objectives while satisfying\ntheir own safety constraints. The objective and constraints are described by\n{\\it general utilities}, i.e., nonlinear functions of the long-term\nstate-action occupancy measure, which encompass broader decision-making goals\nsuch as risk, exploration, or imitations. The exponential growth of the\nstate-action space size with the number of agents presents challenges for\nglobal observability, further exacerbated by the global coupling arising from\nagents' safety constraints. To tackle this issue, we propose a primal-dual\nmethod utilizing shadow reward and $\\kappa$-hop neighbor truncation under a\nform of correlation decay property, where $\\kappa$ is the communication radius.\nIn the exact setting, our algorithm converges to a first-order stationary point\n(FOSP) at the rate of $\\mathcal{O}\\left(T^{-2/3}\\right)$. In the sample-based\nsetting, we demonstrate that, with high probability, our algorithm requires\n$\\widetilde{\\mathcal{O}}\\left(\\epsilon^{-3.5}\\right)$ samples to achieve an\n$\\epsilon$-FOSP with an approximation error of $\\mathcal{O}(\\phi_0^{2\\kappa})$,\nwhere $\\phi_0\\in (0,1)$. Finally, we demonstrate the effectiveness of our model\nthrough extensive numerical experiments.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:08:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17569","submitter":"Shuyue Lan","authors":"Shuyue Lan, Zhilu Wang, Ermin Wei, Amit K. Roy-Chowdhury and Qi Zhu","title":"Collaborative Multi-Agent Video Fast-Forwarding","comments":"IEEE Transactions on Multimedia, 2023. arXiv admin note: text overlap\n  with arXiv:2008.04437","journal-ref":null,"doi":"10.1109/TMM.2023.3275853","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-agent applications have recently gained significant popularity. In many\ncomputer vision tasks, a network of agents, such as a team of robots with\ncameras, could work collaboratively to perceive the environment for efficient\nand accurate situation awareness. However, these agents often have limited\ncomputation, communication, and storage resources. Thus, reducing resource\nconsumption while still providing an accurate perception of the environment\nbecomes an important goal when deploying multi-agent systems. To achieve this\ngoal, we identify and leverage the overlap among different camera views in\nmulti-agent systems for reducing the processing, transmission and storage of\nredundant/unimportant video frames. Specifically, we have developed two\ncollaborative multi-agent video fast-forwarding frameworks in distributed and\ncentralized settings, respectively. In these frameworks, each individual agent\ncan selectively process or skip video frames at adjustable paces based on\nmultiple strategies via reinforcement learning. Multiple agents then\ncollaboratively sense the environment via either 1) a consensus-based\ndistributed framework called DMVF that periodically updates the fast-forwarding\nstrategies of agents by establishing communication and consensus among\nconnected neighbors, or 2) a centralized framework called MFFNet that utilizes\na central controller to decide the fast-forwarding strategies for agents based\non collected data. We demonstrate the efficacy and efficiency of our proposed\nframeworks on a real-world surveillance video dataset VideoWeb and a new\nsimulated driving dataset CarlaSim, through extensive simulations and\ndeployment on an embedded platform with TCP communication. We show that\ncompared with other approaches in the literature, our frameworks achieve better\ncoverage of important frames, while significantly reducing the number of frames\nprocessed at each agent.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:12:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17570","submitter":"Ben Chugg","authors":"Ben Chugg, Santiago Cortes-Gomez, Bryan Wilder, Aaditya Ramdas","title":"Auditing Fairness by Betting","comments":"24 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.AI cs.CY cs.LG stat.AP stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We provide practical, efficient, and nonparametric methods for auditing the\nfairness of deployed classification and regression models. Whereas previous\nwork relies on a fixed-sample size, our methods are sequential and allow for\nthe continuous monitoring of incoming data, making them highly amenable to\ntracking the fairness of real-world systems. We also allow the data to be\ncollected by a probabilistic policy as opposed to sampled uniformly from the\npopulation. This enables auditing to be conducted on data gathered for another\npurpose. Moreover, this policy may change over time and different policies may\nbe used on different subpopulations. Finally, our methods can handle\ndistribution shift resulting from either changes to the model or changes in the\nunderlying population. Our approach is based on recent progress in\nanytime-valid inference and game-theoretic statistics-the \"testing by betting\"\nframework in particular. These connections ensure that our methods are\ninterpretable, fast, and easy to implement. We demonstrate the efficacy of our\nmethods on several benchmark fairness datasets.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:14:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17571","submitter":"Jesus Cuevas","authors":"F. Martin-Vergara, J. Cuevas-Maraver, P.E. Farrell, F.R. Villatoro,\n  P.G. Kevrekidis","title":"Discrete Breathers in Klein-Gordon Lattices: a Deflation-Based Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.PS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deflation is an efficient numerical technique for identifying new branches of\nsteady state solutions to nonlinear partial differential equations. Here, we\ndemonstrate how to extend deflation to discover new periodic orbits in\nnonlinear dynamical lattices. We employ our extension to identify discrete\nbreathers, which are generic exponentially localized, time-periodic solutions\nof such lattices. We compare different approaches to using deflation for\nperiodic orbits, including ones based on a Fourier decomposition of the\nsolution, as well as ones based on the solution's energy density profile. We\ndemonstrate the ability of the method to obtain a wide variety of multibreather\nsolutions without prior knowledge about their spatial profile.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:19:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17572","submitter":"Ahmed Ghatasheh","authors":"Ahmed Ghatasheh","title":"L'Hospital's Rule for Regulated Functions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We extend L'Hospital's rule to quotients of two regulated functions. This\nextension allows us to have a unified approach to both, the discrete case\nrepresented by the Stolz-Cesaro theorem and the continuous case represented by\nL'Hospital's rule. We show that our extension works for two examples that can\nnot be treated using L'Hospital's rule; one of them includes a sequence of\npoints at which the one-sided derivatives vanish, not at the same time, and the\nother example includes a sequence of points at which the tangent line is\nvertical.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:20:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17573","submitter":"Achim Zeileis","authors":"Achim Zeileis, Roger Bivand, Dirk Eddelbuettel, Kurt Hornik, Nathalie\n  Vialaneix","title":"CRAN Task Views: The Next Generation","comments":"8 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  CRAN Task Views have been available on the Comprehensive R Archive Network\nsince 2005. They provide guidance about which CRAN packages are relevant for\ntasks related to a certain topic, and can also facilitate automatic\ninstallation of all corresponding packages. Motivated by challenges from the\ngrowth of CRAN and the R community as a whole since 2005, all of the task views\ninfrastructure and workflows were rethought and relaunched in 2021/22 in order\nto facilitate maintenance and to foster deeper interactions with the R\ncommunity. The redesign encompasses the establishment of a group of CRAN Task\nView Editors, moving all task view sources to dedicated GitHub repositories,\nadopting well-documented workflows with a code of conduct, and leveraging\nR/Markdown files (rather than XML) for the content of the task views.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:23:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17574","submitter":"Eric Strobl","authors":"Eric V. Strobl","title":"Counterfactual Formulation of Patient-Specific Root Causes of Disease","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG q-bio.QM stat.AP stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Root causes of disease intuitively correspond to root vertices that increase\nthe likelihood of a diagnosis. This description of a root cause nevertheless\nlacks the rigorous mathematical formulation needed for the development of\ncomputer algorithms designed to automatically detect root causes from data.\nPrior work defined patient-specific root causes of disease using an\ninterventionalist account that only climbs to the second rung of Pearl's Ladder\nof Causation. In this theoretical piece, we climb to the third rung by\nproposing a counterfactual definition matching clinical intuition based on\nfixed factual data alone. We then show how to assign a root causal contribution\nscore to each variable using Shapley values from explainable artificial\nintelligence. The proposed counterfactual formulation of patient-specific root\ncauses of disease accounts for noisy labels, adapts to disease prevalence and\nadmits fast computation without the need for counterfactual simulation.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:24:27 GMT"},{"version":"v2","created":"Wed, 31 May 2023 22:16:20 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17575","submitter":"Levent Guvenc","authors":"Sukru Yaren Gelbal, Mustafa Ridvan Cantas, Bilin Aksun Guvenc, and\n  Levent Guvenc, Gopichandra Surnilla, Hao Zhang","title":"Mobile Safety Application for Pedestrians","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Vulnerable Road User (VRU) safety has been an important issue throughout the\nyears as corresponding fatality numbers in traffic have been increasing each\nyear. With the developments in connected vehicle technology, there are new and\neasier ways of implementing Vehicle to Everything (V2X) communication which can\nbe utilized to provide safety and early warning benefits for VRUs. Mobile\nphones are one important point of interest with their sensors being increased\nin quantity and quality and improved in terms of accuracy. Bluetooth and\nextended Bluetooth technology in mobile phones has enhanced support to carry\nlarger chunks of information to longer distances. The work we discuss in this\npaper is related to a mobile application that utilizes the mobile phone sensors\nand Bluetooth communication to implement Personal Safety Message (PSM)\nbroadcast using the SAE J2735 standard to create a Pedestrian to Vehicle (P2V)\nbased safety warning structure. This implementation allows the drivers to\nreceive a warning on their mobile phones and be more careful about the\npedestrian intending to cross the street. As a result, the driver has much more\ntime to safely slow down and stop at the intersection. Most importantly, thanks\nto the wireless nature of Bluetooth connection and long-range mode in Bluetooth\n5.0, most dangerous cases such as reduced visibility or No-Line-of-Sight (NLOS)\nconditions can be remedied.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:30:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17576","submitter":"Lutz Warnke","authors":"Erlang Surya, Lutz Warnke","title":"Lagrange Inversion Formula by Induction","comments":"5 pages; to appear in The American Mathematical Monthly","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a simple inductive proof of the Lagrange Inversion Formula.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:31:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17577","submitter":"Julio Deride","authors":"J.Deride and A.Jofr\\'e and R.T. Rockafellar","title":"Reaching an equilibrium of prices and holdings of goods through direct\n  buying and selling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC econ.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Walras approach to equilibrium focuses on the existence of market prices\nat which the total demands for goods are matched by the total supplies. Trading\nactivities that might identify such prices by bringing agents together as\npotential buyers and sellers of a good are characteristically absent, however.\nAnyway, there is no money to pass from one to the other as ordinarily\nenvisioned in buying and selling. Here a different approach to equilibrium --\nwhat it should mean and how it may be achieved -- is offered as a constructive\nalternative.\n  Agents operate in an economic environment where adjustments to holdings have\nbeen needed in the past, will be needed again in a changed future, and money is\nfamiliar for its role in facilitating that. Marginal utility provides relative\nvalues of goods for guidance in making incremental adjustments, and with money\nincorporated into utility and taken as num\\`eraire, those values give money\nprice thresholds at which an agent will be willing to buy or sell. Agents in\npairs can then look at such individualized thresholds to see whether a trade of\nsome amount of a good for some amount of money may be mutually advantageous in\nleading to higher levels of utility. Iterative bilateral trades in this most\nbasic sense, if they keep bringing all goods and agents into play, are\nguaranteed in the limit to reach an equilibrium state in which the agents all\nagree on prices and, under those prices, have no interest in further adjusting\ntheir holdings. The results of computer simulations are provided to illustrate\nhow this works.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:32:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17578","submitter":"Stanley Cheung","authors":"Stanley Cheung, Di Liang, Yuan Yuan, Yiwei Peng, Yingtao Hu, Geza\n  Kurczveil, and Raymond G. Beausoleil","title":"Non-volatile heterogeneous III-V/Si photonics via optical charge-trap\n  memory","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We demonstrate, for the first time, non-volatile charge-trap flash memory\n(CTM) co-located with heterogeneous III-V/Si photonics. The wafer-bonded\nIII-V/Si CTM cell facilitates non-volatile optical functionality for a variety\nof devices such as Mach-Zehnder Interferometers (MZIs), asymmetric MZI lattice\nfilters, and ring resonator filters. The MZI CTM exhibits full write/erase\noperation (100 cycles with 500 states) with wavelength shifts of\n$\\Delta\\lambda_{non-volatile} = 1.16 nm$ ($\\Delta n_{eff,non-volatile} ~ 2.5\n\\times 10^{-4}$) and a dynamic power consumption $<$ 20 pW (limited by\nmeasurement). Multi-bit write operation (2 bits) is also demonstrated and\nverified over a time duration of 24 hours and most likely beyond. The cascaded\n2nd order ring resonator CTM filter exhibited an improved ER of ~ 7.11 dB\ncompared to the MZI and wavelength shifts of $\\Delta\\lambda_{non-volatile} =\n0.041 nm$ ($\\Delta n_{eff, non-volatile} = 1.5 \\times 10^{-4}$) with similar\npW-level dynamic power consumption as the MZI CTM. The ability to co-locate\nphotonic computing elements and non-volatile memory provides an attractive path\ntowards eliminating the von-Neumann bottleneck.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:37:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17579","submitter":"Max Mornev","authors":"M. Mornev","title":"Local monodromy of Drinfeld modules","comments":"31 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Compared with algebraic varieties the local monodromy of Drinfeld modules\nappears to be hopelessly complex: The image of the wild inertia subgroup under\nTate module representations is infinite save for the case of potential good\nreduction.\n  Nonetheless we show that Tate modules of Drinfeld modules are ramified in a\nlimited way: The image of a sufficiently deep ramification subgroup is trivial.\nThis leads to a new invariant, the local conductor of a Drinfeld module. We\nestablish an upper bound on the conductor in terms of the volume of the local\nperiod lattice.\n  As an intermediate step we develop a theory of normed lattices in function\nfield arithmetic including the notion of volume. We relate normed lattices to\nvector bundles on projective curves. An estimate on Castelnuovo-Mumford\nregularity of such bundles gives a volume bound on norms of lattice generators,\nand the conductor inequality follows.\n  Last but not least we describe the image of inertia for Drinfeld modules of\nlarge stable rank. Just as in the theory of local $\\ell$-adic Galois\nrepresentations this image is commensurable with a commutative unipotent\nalgebraic subgroup. However in the case of Drinfeld modules such a subgroup may\nbe a product of several copies of $\\mathbb{G}_a$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:58:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17580","submitter":"Maha Jarallah Althobaiti","authors":"Maha Jarallah Althobaiti","title":"ArPanEmo: An Open-Source Dataset for Fine-Grained Emotion Recognition in\n  Arabic Online Content during COVID-19 Pandemic","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Emotion recognition is a crucial task in Natural Language Processing (NLP)\nthat enables machines to comprehend the feelings conveyed in the text. The\napplications of emotion recognition are diverse, including mental health\ndiagnosis, student support, and the detection of online suspicious behavior.\nDespite the substantial amount of literature available on emotion recognition\nin various languages, Arabic emotion recognition has received relatively little\nattention, leading to a scarcity of emotion-annotated corpora. This paper\npresents the ArPanEmo dataset, a novel dataset for fine-grained emotion\nrecognition of online posts in Arabic. The dataset comprises 11,128 online\nposts manually labeled for ten emotion categories or neutral, with Fleiss'\nkappa of 0.71. It targets a specific Arabic dialect and addresses topics\nrelated to the COVID-19 pandemic, making it the first and largest of its kind.\nPython's packages were utilized to collect online posts related to the COVID-19\npandemic from three sources: Twitter, YouTube, and online newspaper comments\nbetween March 2020 and March 2022. Upon collection of the online posts, each\none underwent a semi-automatic classification process using a lexicon of\nemotion-related terms to determine whether it belonged to the neutral or\nemotional category. Subsequently, manual labeling was conducted to further\ncategorize the emotional data into fine-grained emotion categories.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:04:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17581","submitter":"Mher Safaryan","authors":"Mher Safaryan and Alexandra Peste and Dan Alistarh","title":"Knowledge Distillation Performs Partial Variance Reduction","comments":"36 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge distillation is a popular approach for enhancing the performance of\n``student'' models, with lower representational capacity, by taking advantage\nof more powerful ``teacher'' models. Despite its apparent simplicity and\nwidespread use, the underlying mechanics behind knowledge distillation (KD) are\nstill not fully understood. In this work, we shed new light on the inner\nworkings of this method, by examining it from an optimization perspective. We\nshow that, in the context of linear and deep linear models, KD can be\ninterpreted as a novel type of stochastic variance reduction mechanism. We\nprovide a detailed convergence analysis of the resulting dynamics, which hold\nunder standard assumptions for both strongly-convex and non-convex losses,\nshowing that KD acts as a form of \\emph{partial variance reduction}, which can\nreduce the stochastic gradient noise, but may not eliminate it completely,\ndepending on the properties of the ``teacher'' model. Our analysis puts further\nemphasis on the need for careful parametrization of KD, in particular w.r.t.\nthe weighting of the distillation loss, and is validated empirically on both\nlinear models and deep neural networks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:25:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17582","submitter":"Yuri Shtanov","authors":"Yuri Shtanov","title":"Electroweak symmetry breaking by gravity","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph gr-qc hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show that a simple scale-invariant action coupling the Higgs field to the\nmetric scalar curvature $R$ and containing an $R^2$ term exhibits dynamical\nbreaking of scale invariance and electroweak symmetry. The coefficient of the\n$R^2$ term in this case determines the self-coupling of the Higgs boson in the\nEinstein frame, and the scalaron becomes a dilaton weakly coupled to the Higgs\nboson. Majorana mass terms for right-handed neutrinos can be generated in a\nscale-invariant manner by using the Higgs-field invariant; in this case, the\nexisting experimental limits on the Higgs-boson total width rule out Majorana\nmass values in a certain range. The model inherits the naturalness issues of\ngeneral relativity connected with the smallness of the gravitational and\ncosmological constants.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:31:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17583","submitter":"Boyao Li","authors":"Boyao Li, Alexandar J. Thomson, Matthew M. Engelhard, David Page","title":"On Neural Networks as Infinite Tree-Structured Probabilistic Graphical\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deep neural networks (DNNs) lack the precise semantics and definitive\nprobabilistic interpretation of probabilistic graphical models (PGMs). In this\npaper, we propose an innovative solution by constructing infinite\ntree-structured PGMs that correspond exactly to neural networks. Our research\nreveals that DNNs, during forward propagation, indeed perform approximations of\nPGM inference that are precise in this alternative PGM structure. Not only does\nour research complement existing studies that describe neural networks as\nkernel machines or infinite-sized Gaussian processes, it also elucidates a more\ndirect approximation that DNNs make to exact inference in PGMs. Potential\nbenefits include improved pedagogy and interpretation of DNNs, and algorithms\nthat can merge the strengths of PGMs and DNNs.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:32:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17584","submitter":"Stanley P. Gudder","authors":"Stanley Gudder","title":"A Theory of Quantum Instruments","comments":"29 pages","journal-ref":"Quanta 2023; 12: 27-40","doi":"10.12743/quanta.v12i1.233","report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Until recently, a quantum instrument was defined to be a completely positive\noperation-valued measure from the set of states on a Hilbert space to itself.\nIn the last few years, this definition has been generalized to such measures\nbetween sets of states from different Hilbert spaces called the input and\noutput Hilbert spaces. This article presents a theory of such instruments.Ways\nthat instruments can be combined such as convex combinations, post-processing,\nsequential products, tensor products and conditioning are studied. We also\nconsider marginal, reduced instruments and how these are used to define\ncoexistence (compatibility) of instruments. Finally, we present a brief\nintroduction to quantum measurement models where the generalization of\ninstruments is essential. Many of the concepts of the theory are illustrated by\nexamples. In particular, we discuss Holevo and Kraus instruments.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:38:50 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.17585","submitter":"Christophe Vignat","authors":"C. Vignat and M. Milgram","title":"Curious multisection identities by index factorization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This manuscript introduces a general multisection identity expressed\nequivalently in terms of infinite double products and/or infinite double\nseries, from which several new product or summation identities involving\nspecial functions including Gamma, hyperbolic trigonometric, polygamma, zeta\nand Jacobi theta functions, are derived. It is shown that a parameterized\nversion of this multisection identity exists, a specialization of which\ncoincides with the standard multisection identity.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:54:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17586","submitter":"Michele Stecconi","authors":"Louis Gass and Michele Stecconi","title":"The number of critical points of a Gaussian field: finiteness of moments","comments":"24 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $f$ be a Gaussian random field on $\\mathbb{R}^d$ and let $X$ be the\nnumber of critical points of $f$ contained in a compact subset. A long-standing\nconjecture is that, under mild regularity and non-degeneracy conditions on $f$,\nthe random variable $X$ has finite moments. So far, this has been established\nonly for moments of order lower than three. In this paper, we prove the\nconjecture. Precisely, we show that $X$ has finite moment of order $p$, as soon\nas, at any given point, the Taylor polynomial of order $p+1$ of $f$ is\nnon-degenerate. We present a simple and general approach that is not specific\nto critical points and we provide various applications. In particular, we show\nthe finiteness of moments of the nodal volumes and the number of critical\npoints of a large class of smooth, or holomorphic, Gaussian fields, including\nthe Bargmann-Fock ensemble.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 21:54:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17587","submitter":"Jos\\'e Mar\\'ia Cantarero L\\'opez","authors":"Jos\\'e Cantarero and Jorge Gaspar-Lara","title":"Fusion-invariant representations for symmetric groups","comments":"27 pages. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For a prime $p$, we show that uniqueness of factorization into irreducible\n$\\Sigma_{p^2}$-invariant representations of $\\mathbb{Z}/p \\wr \\mathbb{Z}/p$\nholds if and only if $p=2$. We also show nonuniqueness of factorization for\n$\\Sigma_8$-invariant representations of $D_8 \\wr \\mathbb{Z}/2$. The\nrepresentation ring of $\\Sigma_{p^2}$-invariant representations of\n$\\mathbb{Z}/p \\wr \\mathbb{Z}/p$ is determined completely when $p$ equals two or\nthree.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:07:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17588","submitter":"Aliyah Hsu","authors":"Aliyah R. Hsu, Yeshwanth Cherapanamjeri, Briton Park, Tristan Naumann,\n  Anobel Y. Odisho, Bin Yu","title":"An Investigation into the Effects of Pre-training Data Distributions for\n  Pathology Report Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Pre-trained transformer models have demonstrated success across many natural\nlanguage processing (NLP) tasks. In applying these models to the clinical\ndomain, a prevailing assumption is that pre-training language models from\nscratch on large-scale biomedical data results in substantial improvements. We\ntest this assumption with 4 pathology classification tasks on a corpus of 2907\nprostate cancer pathology reports. We evaluate 5 transformer pre-trained models\nthat are the same size but differ in pre-training corpora. Specifically, we\nanalyze 3 categories of models: 1)General-domain: BERT and Turing Natural\nLanguage Representation (TNLR) models, which use general corpora for\npre-training, 2)Mixed-domain: BioBERT which is obtained from BERT by including\nPubMed abstracts in pre-training and Clinical BioBERT which additionally\nincludes MIMIC-III clinical notes and 3)Domain-specific: PubMedBERT which is\npre-trained from scratch on PubMed abstracts. We find the mixed-domain and\ndomain-specific models exhibit faster feature disambiguation during\nfine-tuning. However, the domain-specific model, PubMedBERT, can overfit to\nminority classes when presented with class imbalance, a common scenario in\npathology report data. At the same time, the mixed-domain models are more\nresistant to overfitting. Our findings indicate that the use of general natural\nlanguage and domain-specific corpora in pre-training serve complementary\npurposes for pathology report classification. The first enables resistance to\noverfitting when fine-tuning on an imbalanced dataset while the second allows\nfor more accurate modelling of the fine-tuning domain. An expert evaluation is\nalso conducted to reveal common outlier modes of each model. Our results could\ninform better fine-tuning practices in the clinical domain, to possibly\nleverage the benefits of mixed-domain models for imbalanced downstream\ndatasets.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:15:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17589","submitter":"Liheng Ma","authors":"Liheng Ma, Chen Lin, Derek Lim, Adriana Romero-Soriano, Puneet K.\n  Dokania, Mark Coates, Philip Torr, Ser-Nam Lim","title":"Graph Inductive Biases in Transformers without Message Passing","comments":"Published as a conference paper at ICML 2023; 17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transformers for graph data are increasingly widely studied and successful in\nnumerous learning tasks. Graph inductive biases are crucial for Graph\nTransformers, and previous works incorporate them using message-passing modules\nand/or positional encodings. However, Graph Transformers that use\nmessage-passing inherit known issues of message-passing, and differ\nsignificantly from Transformers used in other domains, thus making transfer of\nresearch advances more difficult. On the other hand, Graph Transformers without\nmessage-passing often perform poorly on smaller datasets, where inductive\nbiases are more crucial. To bridge this gap, we propose the Graph Inductive\nbias Transformer (GRIT) -- a new Graph Transformer that incorporates graph\ninductive biases without using message passing. GRIT is based on several\narchitectural changes that are each theoretically and empirically justified,\nincluding: learned relative positional encodings initialized with random walk\nprobabilities, a flexible attention mechanism that updates node and node-pair\nrepresentations, and injection of degree information in each layer. We prove\nthat GRIT is expressive -- it can express shortest path distances and various\ngraph propagation matrices. GRIT achieves state-of-the-art empirical\nperformance across a variety of graph datasets, thus showing the power that\nGraph Transformers without message-passing can deliver.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:26:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17590","submitter":"Yan Ding","authors":"Yan Ding, Xiaohan Zhang, Saeid Amiri, Nieqing Cao, Hao Yang, Andy\n  Kaminski, Chad Esselink, Shiqi Zhang","title":"Integrating Action Knowledge and LLMs for Task Planning and Situation\n  Handling in Open Worlds","comments":"arXiv admin note: substantial text overlap with arXiv:2210.01287","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Task planning systems have been developed to help robots use human knowledge\n(about actions) to complete long-horizon tasks. Most of them have been\ndeveloped for \"closed worlds\" while assuming the robot is provided with\ncomplete world knowledge. However, the real world is generally open, and the\nrobots frequently encounter unforeseen situations that can potentially break\nthe planner's completeness. Could we leverage the recent advances on\npre-trained Large Language Models (LLMs) to enable classical planning systems\nto deal with novel situations?\n  This paper introduces a novel framework, called COWP, for open-world task\nplanning and situation handling. COWP dynamically augments the robot's action\nknowledge, including the preconditions and effects of actions, with\ntask-oriented commonsense knowledge. COWP embraces the openness from LLMs, and\nis grounded to specific domains via action knowledge. For systematic\nevaluations, we collected a dataset that includes 1,085 execution-time\nsituations. Each situation corresponds to a state instance wherein a robot is\npotentially unable to complete a task using a solution that normally works.\nExperimental results show that our approach outperforms competitive baselines\nfrom the literature in the success rate of service tasks. Additionally, we have\ndemonstrated COWP using a mobile manipulator. Supplementary materials are\navailable at: https://cowplanning.github.io/\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:30:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17591","submitter":"Austyn Simpson","authors":"Thomas Polstra, Austyn Simpson, Kevin Tucker","title":"On $F$-pure inversion of adjunction","comments":"21 pages, comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyze adjunction and inversion of adjunction for the $F$-purity of\ndivisor pairs in characteristic $p > 0$. In this vein, we give a complete\nanswer for principal divisors under $\\mathbb{Q}$-Gorenstein assumptions but\nwithout divisibility restrictions on the index. We also give a detailed\nanalysis relating the $F$-purity of the pairs $(R,\\Delta + D)$ and that of\n$(R_D, \\text{Diff}_D(\\Delta))$ motivated by Kawakita's log canonical inversion\nof adjunction via reduction to prime characteristic.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:49:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17592","submitter":"Shubhendu Trivedi","authors":"Mircea Petrache, Shubhendu Trivedi","title":"Approximation-Generalization Trade-offs under (Approximate) Group\n  Equivariance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The explicit incorporation of task-specific inductive biases through symmetry\nhas emerged as a general design precept in the development of high-performance\nmachine learning models. For example, group equivariant neural networks have\ndemonstrated impressive performance across various domains and applications\nsuch as protein and drug design. A prevalent intuition about such models is\nthat the integration of relevant symmetry results in enhanced generalization.\nMoreover, it is posited that when the data and/or the model may only exhibit\n$\\textit{approximate}$ or $\\textit{partial}$ symmetry, the optimal or\nbest-performing model is one where the model symmetry aligns with the data\nsymmetry. In this paper, we conduct a formal unified investigation of these\nintuitions. To begin, we present general quantitative bounds that demonstrate\nhow models capturing task-specific symmetries lead to improved generalization.\nIn fact, our results do not require the transformations to be finite or even\nform a group and can work with partial or approximate equivariance. Utilizing\nthis quantification, we examine the more general question of model\nmis-specification i.e. when the model symmetries don't align with the data\nsymmetries. We establish, for a given symmetry group, a quantitative comparison\nbetween the approximate/partial equivariance of the model and that of the data\ndistribution, precisely connecting model equivariance error and data\nequivariance error. Our result delineates conditions under which the model\nequivariance error is optimal, thereby yielding the best-performing model for\nthe given task and data.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:53:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17593","submitter":"Ferdinando Fioretto","authors":"Cuong Tran and Ferdinando Fioretto","title":"Data Minimization at Inference Time","comments":"arXiv admin note: substantial text overlap with arXiv:2302.00077","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In domains with high stakes such as law, recruitment, and healthcare,\nlearning models frequently rely on sensitive user data for inference,\nnecessitating the complete set of features. This not only poses significant\nprivacy risks for individuals but also demands substantial human effort from\norganizations to verify information accuracy. This paper asks whether it is\nnecessary to use \\emph{all} input features for accurate predictions at\ninference time. The paper demonstrates that, in a personalized setting,\nindividuals may only need to disclose a small subset of their features without\ncompromising decision-making accuracy. The paper also provides an efficient\nsequential algorithm to determine the appropriate attributes for each\nindividual to provide. Evaluations across various learning tasks show that\nindividuals can potentially report as little as 10\\% of their information while\nmaintaining the same accuracy level as a model that employs the full set of\nuser information.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:03:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17594","submitter":"Sizhen Bian","authors":"Sizhen Bian, Alexander Rupp, Michele Magno","title":"Fully Automatic Gym Exercises Recording: An IoT Solution","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In recent years, working out in the gym has gotten increasingly more\ndata-focused and many gym enthusiasts are recording their exercises to have a\nbetter overview of their historical gym activities and to make a better\nexercise plan for the future. As a side effect, this recording process has led\nto a lot of time spent painstakingly operating these apps by plugging in used\ntypes of equipment and repetitions. This project aims to automate this process\nusing an Internet of Things (IoT) approach. Specifically, beacons with embedded\nultra-low-power inertial measurement units (IMUs) are attached to the types of\nequipment to recognize the usage and transmit the information to gym-goers and\nmanagers. We have created a small ecosystem composed of beacons, a gateway,\nsmartwatches, android/iPhone applications, a firebase cloud server, and a\ndashboard, all communicating over a mixture of Bluetooth and Wifi to distribute\ncollected data from machines to users and gym managers in a compact and\nmeaningful way. The system we have implemented is a working prototype of a\nbigger end goal and is supposed to initialize progress toward a smarter, more\nefficient, and still privacy-respect gym environment in the future. A\nsmall-scale real-life test shows 94.6\\% accuracy in user gym session recording,\nwhich can reach up to 100\\% easily with a more suitable assembling of the\nbeacons. This promising result shows the potential of a fully automatic\nexercise recording system, which enables comprehensive monitoring and analysis\nof the exercise sessions and frees the user from manual recording. The\nestimated battery life of the beacon is 400 days with a 210 mAh coin battery.\nWe also discussed the shortcoming of the current demonstration system and the\nfuture work for a reliable and ready-to-deploy automatic gym workout recording\nsystem.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:12:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17595","submitter":"Shuhei Watanabe","authors":"Shuhei Watanabe","title":"Python Wrapper for Simulating Multi-Fidelity Optimization on HPO\n  Benchmarks without Any Wait","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hyperparameter (HP) optimization of deep learning (DL) is essential for high\nperformance. As DL often requires several hours to days for its training, HP\noptimization (HPO) of DL is often prohibitively expensive. This boosted the\nemergence of tabular or surrogate benchmarks, which enable querying the\n(predictive) performance of DL with a specific HP configuration in a fraction.\nHowever, since actual runtimes of a DL training are significantly different\nfrom query response times, in a naive implementation, simulators of an\nasynchronous HPO, e.g. multi-fidelity optimization, must wait for the actual\nruntimes at each iteration; otherwise, the evaluation order in the simulator\ndoes not match with the real experiment. To ease this issue, we develop a\nPython wrapper to force each worker to wait in order to match the evaluation\norder with the real experiment and describe the usage. Our implementation\nreduces the waiting time to 0.01 seconds and it is available at\nhttps://github.com/nabenabe0928/mfhpo-simulator/.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:28:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17596","submitter":"Inigo Incer","authors":"Inigo Incer, Albert Benveniste, Richard M. Murray, Alberto\n  Sangiovanni-Vincentelli, Sanjit A. Seshia","title":"Context-Aided Variable Elimination for Requirement Engineering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deriving system-level specifications from component specifications usually\ninvolves the elimination of variables that are not part of the interface of the\ntop-level system. This paper presents algorithms for eliminating variables from\nformulas by computing refinements or relaxations of these formulas in a\ncontext. We discuss a connection between this problem and optimization and give\nefficient algorithms to compute refinements and relaxations of linear\ninequality constraints.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:46:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17597","submitter":"David T. Nguyen","authors":"David T. Nguyen","title":"On Ramanujan-Fourier expansions","comments":"six pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We heuristically study the shifted convolution $\\sum_{n\\le X} \\tau_k(n)\n\\tau_\\ell(n+h)$ using a normalized version of Ramanujan-Fourier expansions for\n$\\tau_k(n)$ and verify they produce the expected answer.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 00:00:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17598","submitter":"Alex Crane","authors":"Alex Crane, Brian Lavallee, Blair D. Sullivan, and Nate Veldt","title":"Overlapping and Robust Edge-Colored Clustering in Hypergraphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A recent trend in data mining has explored (hyper)graph clustering algorithms\nfor data with categorical relationship types. Such algorithms have applications\nin the analysis of social, co-authorship, and protein interaction networks, to\nname a few. Many such applications naturally have some overlap between\nclusters, a nuance which is missing from current combinatorial models.\nAdditionally, existing models lack a mechanism for handling noise in datasets.\nWe address these concerns by generalizing Edge-Colored Clustering, a recent\nframework for categorical clustering of hypergraphs. Our generalizations allow\nfor a budgeted number of either (a) overlapping cluster assignments or (b) node\ndeletions. For each new model we present a greedy algorithm which approximately\nminimizes an edge mistake objective, as well as bicriteria approximations where\nthe second approximation factor is on the budget. Additionally, we address the\nparameterized complexity of each problem, providing FPT algorithms and hardness\nresults.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 00:25:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17599","submitter":"Xiaowen Zhu","authors":"Jiranan Kerdboon, Xiaowen Zhu","title":"Anderson Localization for Schr\\\"odinger Operators with Monotone\n  Potentials over Circle Homeomorphisms","comments":"17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.DS math.MP math.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we prove pure point spectrum for a large class of\nSchr\\\"odinger operators over circle maps with conditions on the rotation number\ngoing beyond the Diophantine. More specifically, we develop the scheme to\nobtain pure point spectrum for Schr\\\"odinger operators with monotone\nbi-Lipschitz potentials over orientation-preserving circle homeomorphisms with\nDiophantine or weakly Liouville rotation number. The localization is uniform\nwhen the coupling constant is large enough.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 00:35:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17600","submitter":"Justin Lidard","authors":"Justin Lidard, Oswin So, Yanxia Zhang, Jonathan DeCastro, Xiongyi Cui,\n  Xin Huang, Yen-Ling Kuo, John Leonard, Avinash Balachandran, Naomi Leonard,\n  Guy Rosman","title":"GAME-UP: Game-Aware Mode Enumeration and Understanding for Trajectory\n  Prediction","comments":"10 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV cs.GT cs.RO math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Interactions between road agents present a significant challenge in\ntrajectory prediction, especially in cases involving multiple agents. Because\nexisting diversity-aware predictors do not account for the interactive nature\nof multi-agent predictions, they may miss these important interaction outcomes.\nIn this paper, we propose GAME-UP, a framework for trajectory prediction that\nleverages game-theoretic inverse reinforcement learning to improve coverage of\nmulti-modal predictions. We use a training-time game-theoretic numerical\nanalysis as an auxiliary loss resulting in improved coverage and accuracy\nwithout presuming a taxonomy of actions for the agents. We demonstrate our\napproach on the interactive subset of Waymo Open Motion Dataset, including\nthree subsets involving scenarios with high interaction complexity. Experiment\nresults show that our predictor produces accurate predictions while covering\ntwice as many possible interactions versus a baseline model.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 00:41:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17601","submitter":"Johannes Treutlein","authors":"Caspar Oesterheld, Johannes Treutlein, Emery Cooper, Rubi Hudson","title":"Incentivizing honest performative predictions with proper scoring rules","comments":"Accepted for the 39th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Proper scoring rules incentivize experts to accurately report beliefs,\nassuming predictions cannot influence outcomes. We relax this assumption and\ninvestigate incentives when predictions are performative, i.e., when they can\ninfluence the outcome of the prediction, such as when making public predictions\nabout the stock market. We say a prediction is a fixed point if it accurately\nreflects the expert's beliefs after that prediction has been made. We show that\nin this setting, reports maximizing expected score generally do not reflect an\nexpert's beliefs, and we give bounds on the inaccuracy of such reports. We show\nthat, for binary predictions, if the influence of the expert's prediction on\noutcomes is bounded, it is possible to define scoring rules under which optimal\nreports are arbitrarily close to fixed points. However, this is impossible for\npredictions over more than two outcomes. We also perform numerical simulations\nin a toy setting, showing that our bounds are tight in some situations and that\nprediction error is often substantial (greater than 5-10%). Lastly, we discuss\nalternative notions of optimality, including performative stability, and show\nthat they incentivize reporting fixed points.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 00:53:26 GMT"},{"version":"v2","created":"Tue, 30 May 2023 17:20:13 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17602","submitter":"Zhengye Zhou","authors":"Jeffrey Kuan and Zhengye Zhou","title":"Dualities of Dynamic Stochastic Higher Spin Vertex Models through\n  Drinfeld Twister","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math-ph math.MP math.QA","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We introduce a new, algebraic method to construct duality functions for\nintegrable dynamic models. This method will be implemented on dynamic\nstochastic higher spin vertex models, where we prove the duality functions are\nthe $_3\\varphi_2$ functions. The method involves using the universal twister of\n$\\mathcal{U}_q(\\mathfrak{sl}_2)$, viewed as a quasi--triangular,\nquasi--$^*$--Hopf algebra. The algebraic method is presented very generally and\nis expected to produce duality functions for other dynamic integrable models.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 01:12:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17603","submitter":"Catie LeDesma","authors":"Catie LeDesma, Kendall Mehling, Jieqiu Shao, John Drew Wilson, Penina\n  Axelrad, Marco M. Nicotra, Murray Holland, and Dana Z. Anderson","title":"A Machine-Designed Optical Lattice Atom Interferometer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph physics.atom-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Performing interferometry in an optical lattice formed by standing waves of\nlight offers potential advantages over its free-space equivalents since the\natoms can be confined and manipulated by the optical potential. We demonstrate\nsuch an interferometer in a one dimensional lattice and show the ability to\ncontrol the atoms by imaging and reconstructing the wavefunction at many stages\nduring its cycle. An acceleration signal is applied and the resulting\nperformance is seen to be close to the optimum possible for the time-space area\nenclosed according to quantum theory. Our methodology of machine design enables\nthe sensor to be reconfigurable on the fly, and when scaled up, offers the\npotential to make state-of-the art inertial and gravitational sensors that will\nhave a wide range of potential applications.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 01:16:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17604","submitter":"Anya Katsevich","authors":"Anya Katsevich","title":"Tight Dimension Dependence of the Laplace Approximation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In Bayesian inference, a widespread technique to approximately sample from\nand compute statistics of a high-dimensional posterior is to use the Laplace\napproximation, a Gaussian proxy to the posterior. The Laplace approximation\naccuracy improves as sample size grows, but the question of how fast dimension\n$d$ can grow with sample size $n$ has not been fully resolved. Prior works have\nshown that $d^3\\ll n$ is a sufficient condition for accuracy of the\napproximation. But by deriving the leading order contribution to the TV error,\nwe show that $d^2\\ll n$ is sufficient. We show for a logistic regression\nposterior that this growth condition is necessary.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 01:32:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17605","submitter":"Adwait Godbole","authors":"Parosh Aziz Abdulla, Mohamed Faouzi Atig, Adwait Godbole,\n  Shankaranarayanan Krishna, Mihir Vahanwala","title":"Overcoming Memory Weakness with Unified Fairness","comments":"32 pages. To appear in Proc. 35th International Conference on\n  Computer Aided Verification (CAV) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.LO","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We consider the verification of liveness properties for concurrent programs\nrunning on weak memory models. To that end, we identify notions of fairness\nthat preclude demonic non-determinism, are motivated by practical observations,\nand are amenable to algorithmic techniques. We provide both logical and\nstochastic definitions of our fairness notions and prove that they are\nequivalent in the context of liveness verification. In particular, we show that\nour fairness allows us to reduce the liveness problem (repeated control state\nreachability) to the problem of simple control state reachability. We show that\nthis is a general phenomenon by developing a uniform framework which serves as\nthe formal foundation of our fairness definition and can be instantiated to a\nwide landscape of memory models. These models include SC, TSO, PSO,\n(Strong/Weak) Release-Acquire, Strong Coherence, FIFO-consistency, and RMO.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 01:49:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17606","submitter":"Yu Shi","authors":"Shan-Chang Tang, Yu Shi","title":"Nonhermitian adiabatic perturbation theory of topological quantization\n  of the average velocity of a magnetic skyrmion under thermal fluctuations","comments":"32 pages, preprint format","journal-ref":"Phys. Rev. B 105, 214415 (2022)","doi":"10.1103/PhysRevB.105.214415","report-no":null,"categories":"cond-mat.mes-hall cond-mat.other","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the two-dimensional motion of a magnetic skyrmion driven by a\nratchetlike polarized electric current that is periodic in both space and time.\nSome general cases are considered, in each of which,in the low temperature and\nadiabatic limit, regardless of the details of the driving current, the time and\nstatistical average velocity along any direction is topologically quantized as\na Chern number, multiplied by a basic unit. We make two approaches, one based\non identifying the drift direction, and the other based on the nonhermitian\nadiabatic perturbation theory developed for the Fokker-Planck operator. Both\napproach applies in the case of periodicity along the direction of the driving\ncurrent and homogeneity in the transverse direction, for which the analytical\nresult is confirmed by our numerical simulation on the constituent spins,and a\nconvenient experiment is proposed.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 01:51:56 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.17607","submitter":"Quzhe Huang","authors":"Quzhe Huang, Yutong Hu, Shengqi Zhu, Yansong Feng, Chang Liu, Dongyan\n  Zhao","title":"More than Classification: A Unified Framework for Event Temporal\n  Relation Extraction","comments":null,"journal-ref":"ACL 2023 Main Conference","doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Event temporal relation extraction~(ETRE) is usually formulated as a\nmulti-label classification task, where each type of relation is simply treated\nas a one-hot label. This formulation ignores the meaning of relations and wipes\nout their intrinsic dependency. After examining the relation definitions in\nvarious ETRE tasks, we observe that all relations can be interpreted using the\nstart and end time points of events. For example, relation \\textit{Includes}\ncould be interpreted as event 1 starting no later than event 2 and ending no\nearlier than event 2. In this paper, we propose a unified event temporal\nrelation extraction framework, which transforms temporal relations into logical\nexpressions of time points and completes the ETRE by predicting the relations\nbetween certain time point pairs. Experiments on TB-Dense and MATRES show\nsignificant improvements over a strong baseline and outperform the\nstate-of-the-art model by 0.3\\% on both datasets. By representing all relations\nin a unified framework, we can leverage the relations with sufficient data to\nassist the learning of other relations, thus achieving stable improvement in\nlow-data scenarios. When the relation definitions are changed, our method can\nquickly adapt to the new ones by simply modifying the logic expressions that\nmap time points to new event relations. The code is released at\n\\url{https://github.com/AndrewZhe/A-Unified-Framework-for-ETRE}.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:09:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17608","submitter":"Weijie J. Su","authors":"Ziang Song, Tianle Cai, Jason D. Lee, Weijie J. Su","title":"Reward Collapse in Aligning Large Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL math.OC stat.ML","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The extraordinary capabilities of large language models (LLMs) such as\nChatGPT and GPT-4 are in part unleashed by aligning them with reward models\nthat are trained on human preferences, which are often represented as rankings\nof responses to prompts. In this paper, we document the phenomenon of\n\\textit{reward collapse}, an empirical observation where the prevailing\nranking-based approach results in an \\textit{identical} reward distribution\n\\textit{regardless} of the prompts during the terminal phase of training. This\noutcome is undesirable as open-ended prompts like ``write a short story about\nyour best friend'' should yield a continuous range of rewards for their\ncompletions, while specific prompts like ``what is the capital of New Zealand''\nshould generate either high or low rewards. Our theoretical investigation\nreveals that reward collapse is primarily due to the insufficiency of the\nranking-based objective function to incorporate prompt-related information\nduring optimization. This insight allows us to derive closed-form expressions\nfor the reward distribution associated with a set of utility functions in an\nasymptotic regime. To overcome reward collapse, we introduce a prompt-aware\noptimization scheme that provably admits a prompt-dependent reward distribution\nwithin the interpolating regime. Our experimental results suggest that our\nproposed prompt-aware utility functions significantly alleviate reward collapse\nduring the training of reward models.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:12:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17609","submitter":"I-Chao Shen","authors":"I-Chao Shen, Fu-Yin Cherng, Takeo Igarashi, Wen-Chieh Lin, Bing-Yu\n  Chen","title":"EvIcon: Designing High-Usability Icon with Human-in-the-loop Exploration\n  and IconCLIP","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GR cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Interface icons are prevalent in various digital applications. Due to limited\ntime and budgets, many designers rely on informal evaluation, which often\nresults in poor usability icons. In this paper, we propose a unique\nhuman-in-the-loop framework that allows our target users, i.e., novice and\nprofessional UI designers, to improve the usability of interface icons\nefficiently. We formulate several usability criteria into a perceptual\nusability function and enable users to iteratively revise an icon set with an\ninteractive design tool, EvIcon. We take a large-scale pre-trained joint\nimage-text embedding (CLIP) and fine-tune it to embed icon visuals with icon\ntags in the same embedding space (IconCLIP). During the revision process, our\ndesign tool provides two types of instant perceptual usability feedback. First,\nwe provide perceptual usability feedback modeled by deep learning models\ntrained on IconCLIP embeddings and crowdsourced perceptual ratings. Second, we\nuse the embedding space of IconCLIP to assist users in improving icons' visual\ndistinguishability among icons within the user-prepared icon set. To provide\nthe perceptual prediction, we compiled IconCEPT10K, the first large-scale\ndataset of perceptual usability ratings over $10,000$ interface icons, by\nconducting a crowdsourcing study. We demonstrated that our framework could\nbenefit UI designers' interface icon revision process with a wide range of\nprofessional experience. Moreover, the interface icons designed using our\nframework achieved better semantic distance and familiarity, verified by an\nadditional online user study.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:16:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17610","submitter":"Saijun Wu","authors":"Liyang Qiu, Haidong Yuan and Saijun Wu","title":"Composite Biased Rotations for Precise Raman Control of Spinor\n  Matterwaves","comments":"11 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.atom-ph quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Precise control of hyperfine matterwaves via Raman excitations is\ninstrumental to a class of atom-based quantum technology. We investigate the\nRaman spinor control technique for alkaline atoms in an intermediate regime of\nsingle-photon detuning where a choice can be made to balance the Raman\nexcitation power efficiency with the control speed, excited-state adiabatic\nelimination, and spontaneous emission suppression requirements. Within the\nregime, rotations of atomic spinors by the Raman coupling are biased by\nsubstantial light shifts. Taking advantage of the fixed bias angle, we show\nthat composite biased rotations can be optimized to enable precise ensemble\nspinor matterwave control within nanoseconds, even for multiple Zeeman\npseudo-spins defined on the hyperfine ground states and when the laser\nillumination is strongly inhomogeneous. Our scheme fills a technical gap in\nlight pulse atom interferometry, for achieving high speed Raman spinor\nmatterwave control with moderate laser power.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:21:41 GMT"},{"version":"v2","created":"Tue, 30 May 2023 00:30:45 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17611","submitter":"Syed Mohammad Asjad","authors":"Syed Asjad, Aniket Gupta, Hanumant Singh","title":"Bayesian Decision Making to Localize Visual Queries in 2D","comments":"Report for the EGO4D 2023 Visual Query 2D Localization Challenge","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This report describes our approach for the EGO4D 2023 Visual Query 2D\nLocalization Challenge. Our method aims to reduce the number of False Positives\n(FP) that occur because of high similarity between the visual crop and the\nproposed bounding boxes from the baseline's Region Proposal Network (RPN). Our\nmethod uses a transformer to determine similarity in higher dimensions which is\nused as our prior belief. The results are then combined together with the\nsimilarity in lower dimensions from the Siamese Head, acting as our\nmeasurement, to generate a posterior which is then used to determine the final\nsimilarity of the visual crop with the proposed bounding box. Our code is\npublicly available $\\href{https://github.com/s-m-asjad/EGO4D_VQ2D}{here}$.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:38:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17612","submitter":"Nguyen Mau Nam","authors":"Nguyen Mau Nam, Gary Sandine, Nguyen Nang Thieu, Nguyen Dong Yen","title":"Fenchel Conjugate of Set-Valued Mappings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present a novel concept of the Fenchel conjugate for\nset-valued mappings and investigate its properties in finite and infinite\ndimensions. After establishing the fundamental properties of the Fenchel\nconjugate for set-valued mappings, we derive its main calculus rules in various\nsettings. Our approach is geometric and draws inspiration from the successful\napplication of this method by B.~S.~Mordukhovich and coauthors in variational\nand convex analysis. Subsequently, we demonstrate that our new findings for the\nFenchel conjugate of set-valued mappings can be utilized to obtain many\nestablished calculus rules of convex generalized differentiation in both finite\nand infinite dimensions.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:41:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17613","submitter":"Edesiri Bridget Nkemnole","authors":"Edesiri Bridget Nkemnole and Victor Adoghe","title":"A Comparison Between Long Short-Term Memory and Hidden Markov Model to\n  Predict Productivity of Maize in Nigeria","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Due to population increase and import constraints, maize, a key cereal crop\nin Africa, is experiencing a boom in demand. Given this, the study's focus is\non determining how maize output in Nigeria interacts with various climatic\nfactors, particularly rainfall and temperature. The Hidden Markov Model (HMM)\nand the Long Short-Term Memory neural network (LSTM) are compared in this\ncontext to assess their performance. A variety of performance indicators, such\nas correlation, mean absolute percentage error (MAPE), standard error of the\nmean (SEM), and mean square error (MSE), are used to evaluate the models. The\noutcomes show that the HMM performs better than the LSTM, with an RMSE of 1.21\nand a MAPE of 12.98 demonstrating greater performance. Based on this result,\nthe HMM is then used to forecast maize yield while taking the effects of\ntemperature and rainfall into account. The estimates highlight the possibility\nfor increasing local output by demonstrating a favorable environment for maize\nplanting in Nigeria. In order to help the Nigerian government in its efforts to\nincrease maize production domestically, these studies offer useful insights.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 02:48:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17614","submitter":"Rahul Arun","authors":"Rahul Arun and Tim Colonius","title":"Efficient simulation and characterization of a head-on vortex ring\n  collision","comments":"34 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We simulate and analyze the head-on collision between vortex rings at\n$Re_{\\Gamma_0} =$ 4,000. We utilize an adaptive, multi-resolution solver, based\non the lattice Green's function, whose fidelity is established with integral\nmetrics representing symmetries and discretization errors. Using the velocity\ngradient tensor and structural features of local streamlines, we characterize\nthe evolution of the flow with a particular focus on its transition and\nturbulent decay. Transition is excited by the development of the elliptic\ninstability, which grows during the mutual interaction of the rings as they\nexpand radially at the collision plane. The development of antiparallel\nsecondary vortex filaments along the circumference mediates the proliferation\nof small-scale turbulence. During turbulent decay, the partitioning of the\nvelocity gradients approaches an equilibrium that is dominated by shearing and\nagrees well with previous results for forced isotropic turbulence. We also\nintroduce new phase spaces for the velocity gradients that reflect the\ninterplay between shearing and rigid rotation and highlight geometric features\nof local streamlines. In conjunction with our visualizations, these phase\nspaces suggest that, while the elliptic instability is the predominant\nmechanism driving the initial transition, its interplay with other mechanisms,\nparticularly the Crow instability, becomes more important during turbulent\ndecay. Our analysis suggests that the geometry-based phase space may be\npromising for identifying the effects of the elliptic instability and other\nmechanisms using the structure of local streamlines. Moving forward,\ncharacterizing the organization of these mechanisms within vortices and\nuniversal features of velocity gradients may aid in modeling the turbulent\ncascade.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:00:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17615","submitter":"Lei Wang","authors":"Lei Wang","title":"Bridging TSLS and JIVE","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.EM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Economists often implement TSLS to handle endogeneity. The bias of TSLS is\nsevere when the number of instruments is large. Hence, JIVE has been proposed\nto reduce bias of over-identified TSLS. However, both methods have critical\ndrawbacks. While over-identified TSLS has a large bias with a large degree of\noveridentification, JIVE is unstable. In this paper, I bridge the optimization\nproblems of TSLS and JIVE, solve the connected problem and propose a new\nestimator TSJI. TSJI has a user-defined parameter $\\lambda$. By approximating\nthe bias of the TSJI up to op(1/N), I find a $\\lambda$ value that produces\napproximately unbiased TSJI. TSJI with the selected $\\lambda$ value not only\nhas the same first order distribution as TSLS when the number of first-stage\nand second-stage regressors are fixed, but also is consistent and\nasymptotically normal under many-instrument asymptotics. Under three different\nsimulation settings, I test TSJI against TSLS and JIVE with instruments of\ndifferent strengths. TSJI clearly outperforms TSLS and JIVE in simulations. I\napply TSJI to two empirical studies. TSJI mostly agrees with TSLS and JIVE, but\nit also gives different conclusions from TSLS and JIVE for specific cases.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:04:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17616","submitter":"Ashadul Halder","authors":"Ashadul Halder, Shashank Shekhar Pandey, A. S. Majumdar","title":"Future evolution due to backreaction in a Universe with multiple\n  inhomogeneous domains","comments":"12 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We formulate a model of spacetime with inhomogeneous matter distribution in\nmultiple domains. In the context of the backreaction framework using Buchert's\naveraging procedure, we evaluate the effect of backreaction due to the\ninhomogeneities on the late time global evolution of the Universe. Examining\nthe future evolution of this universe, we find that it can transit from the\npresently accelerating phase to undergo future deceleration. The future\ndeceleration is governed by our model parameters. We constrain the model\nparameters using observational analysis of the Union 2.1 supernova Ia data\nemploying the Markov Chain Monte Carlo method.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:12:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17617","submitter":"Milton  Javier Cardenas  Mendez","authors":"Milton Javier Cardenas Mendez and Armando Mauro Vasquez Corro","title":"Generalized Ribaucour-type surfaces","comments":"arXiv admin note: substantial text overlap with arXiv:2303.03228","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work we generalize the surfaces studied in [8], we define the\ngeneralization of Ribaucour-type surfaces (in short, GRT-surfaces). We obtain\npresent a representation for GRT-surfaces with prescribed Gauss map which\ndepends on two holomorphic functions and a real function l. We give explicit\nexamples of GRT-surfaces. Also, we use this representation to classify the\nGRT-surfaces of rotation.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:17:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17618","submitter":"Julian Gutierrez","authors":"Diogo Gomes, Julian Gutierrez, and Mathieu Lauri\\`ere","title":"Machine Learning architectures for price formation models with common\n  noise","comments":"6 pages, 3 figures, conference paper","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a machine learning method to solve a mean-field game price\nformation model with common noise. This involves determining the price of a\ncommodity traded among rational agents subject to a market clearing condition\nimposed by random supply, which presents additional challenges compared to the\ndeterministic counterpart. Our approach uses a dual recurrent neural network\narchitecture encoding noise dependence and a particle approximation of the\nmean-field model with a single loss function optimized by adversarial training.\nWe provide a posteriori estimates for convergence and illustrate our method\nthrough numerical experiments.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:27:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17619","submitter":"Md Tahmid Rahman Laskar","authors":"Md Tahmid Rahman Laskar, Cheng Chen, Xue-Yong Fu, Mahsa Azizi, Shashi\n  Bhushan, Simon Corston-Oliver","title":"AI Coach Assist: An Automated Approach for Call Recommendation in\n  Contact Centers for Agent Coaching","comments":"ACL 2023 Industry Track","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In recent years, the utilization of Artificial Intelligence (AI) in the\ncontact center industry is on the rise. One area where AI can have a\nsignificant impact is in the coaching of contact center agents. By analyzing\ncall transcripts using Natural Language Processing (NLP) techniques, it would\nbe possible to quickly determine which calls are most relevant for coaching\npurposes. In this paper, we present AI Coach Assist, which leverages the\npre-trained transformer-based language models to determine whether a given call\nis coachable or not based on the quality assurance (QA) questions asked by the\ncontact center managers or supervisors. The system was trained and evaluated on\na large dataset collected from real-world contact centers and provides an\neffective way to recommend calls to the contact center managers that are more\nlikely to contain coachable moments. Our experimental findings demonstrate the\npotential of AI Coach Assist to improve the coaching process, resulting in\nenhancing the performance of contact center agents.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:29:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17620","submitter":"Hao Zhang","authors":"Wenwen Zhang, Hao Zhang","title":"Probing Ring Resonator Sensor Based on Vernier Effect","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics eess.SP physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Vernier effect has seen extensive application in optical structures,\nserving to augment the free spectral range (FSR). A substantial FSR is vital in\na myriad of applications including multiplexers, enabling a broad, clear band\ncomparable to the C-band to accommodate a maximum number of channels.\nNevertheless, a large FSR often conflicts with bending loss, as it necessitates\na smaller resonator radius, thus increase the insertion loss in the bending\nportion. To facilitate FSR expansion without amplifying bending loss, we\nemployed cascaded and parallel racetrack resonators and ring resonators of\nvarying radius that demonstrate the Vernier effect. In this study, we designed,\nfabricated, and tested multiple types of racetrack resonators to validate the\nVernier effect and its FSR extension capabilities. Our investigations\nsubstantiate that the Vernier effect, based on cascaded and series-coupled\nmicro-ring resonator (MRR) sensors, can efficiently mitigate intra-channel\ncross-talk at higher data rates. This is achieved by providing larger\ninput-to-through suppression, thus paving the way for future applications.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:39:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17621","submitter":"Sekhar Baishya","authors":"Sekhar Jyoti Baishya","title":"On groups with same number of centralizers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, among other results, we give some sufficient conditions for\nevery non-abelian subgroup of a group to be isoclinic with the group itself. It\nis also seen that under certain conditions, two groups have same number of\nelement centralizers implies they are isoclinic. We prove that if $G$ is any\ngroup having $4, 5, 7$ or $9$ element centralizers and $H$ is any non-abelian\nsubgroup of $G$, then $\\mid \\Cent(G)\\mid=\\mid \\Cent(H)\\mid$ and $ G' \\cong H'\n\\cong C_2, C_3, C_5$ or $C_7$ respectively. Furthermore, it is proved that if\n$G$ is any group having $n \\in \\lbrace 4, 5, 6, 7, 9 \\rbrace$ element\ncentralizers, then $\\mid G' \\mid=n-2$.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:45:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17622","submitter":"Yuji Shi","authors":"Yu-Ji Shi, Ye Xing and Zhi-Peng Xing","title":"Semi-inclusive decays of $B$ meson into a dark anti-baryon and baryons","comments":"17 pages, 4 figures and 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Using the recently developed $B$-Mesogenesis scenario, we studied the\nsemi-inclusive decays of $B$ meson into a dark anti-baryon $\\psi$ plus any\npossible states $X$ containing $u/c$ and $d/s$ quarks with unit baryon number.\nThe two types of effective Lagrangians proposed by the scenario are both\nconsidered in the study. The semi-inclusive decay branching fractions of $B\\to\nX \\psi$ are calculated by the method of heavy quark expansion, where the\nnon-perturbative contributions from the matrix elements of dimension-5\noperators are included. We obtained the branching fractions as functions of the\ndark anti-baryon mass. Using the experimental upper limits of the branching\nfractions, we presented the constraints of the coupling constants in the\n$B$-Mesogenesis scenario.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:57:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17623","submitter":"Kang Xu","authors":"Kang Xu, Chenjia Bai, Shuang Qiu, Haoran He, Bin Zhao, Zhen Wang, Wei\n  Li, Xuelong Li","title":"On the Value of Myopic Behavior in Policy Reuse","comments":"28 pages, 25 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Leveraging learned strategies in unfamiliar scenarios is fundamental to human\nintelligence. In reinforcement learning, rationally reusing the policies\nacquired from other tasks or human experts is critical for tackling problems\nthat are difficult to learn from scratch. In this work, we present a framework\ncalled Selective Myopic bEhavior Control~(SMEC), which results from the insight\nthat the short-term behaviors of prior policies are sharable across tasks. By\nevaluating the behaviors of prior policies via a hybrid value function\narchitecture, SMEC adaptively aggregates the sharable short-term behaviors of\nprior policies and the long-term behaviors of the task policy, leading to\ncoordinated decisions. Empirical results on a collection of manipulation and\nlocomotion tasks demonstrate that SMEC outperforms existing methods, and\nvalidate the ability of SMEC to leverage related prior policies.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 03:59:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17624","submitter":"Chuong Huynh","authors":"Chuong Huynh, Yuqian Zhou, Zhe Lin, Connelly Barnes, Eli Shechtman,\n  Sohrab Amirghodsi, Abhinav Shrivastava","title":"SimpSON: Simplifying Photo Cleanup with Single-Click Distracting Object\n  Segmentation Network","comments":"CVPR 2023. Project link: https://simpson-cvpr23.github.io","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In photo editing, it is common practice to remove visual distractions to\nimprove the overall image quality and highlight the primary subject. However,\nmanually selecting and removing these small and dense distracting regions can\nbe a laborious and time-consuming task. In this paper, we propose an\ninteractive distractor selection method that is optimized to achieve the task\nwith just a single click. Our method surpasses the precision and recall\nachieved by the traditional method of running panoptic segmentation and then\nselecting the segments containing the clicks. We also showcase how a\ntransformer-based module can be used to identify more distracting regions\nsimilar to the user's click position. Our experiments demonstrate that the\nmodel can effectively and accurately segment unknown distracting objects\ninteractively and in groups. By significantly simplifying the photo cleaning\nand retouching process, our proposed model provides inspiration for exploring\nrare object segmentation and group selection with a single click.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:05:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17625","submitter":"Kang Xu","authors":"Kang Xu, Chenjia Bai, Xiaoteng Ma, Dong Wang, Bin Zhao, Zhen Wang,\n  Xuelong Li, Wei Li","title":"Cross-Domain Policy Adaptation via Value-Guided Data Filtering","comments":"27 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generalizing policies across different domains with dynamics mismatch poses a\nsignificant challenge in reinforcement learning. For example, a robot learns\nthe policy in a simulator, but when it is deployed in the real world, the\ndynamics of the environment may be different. Given the source and target\ndomain with dynamics mismatch, we consider the online dynamics adaptation\nproblem, in which case the agent can access sufficient source domain data while\nonline interactions with the target domain are limited. Existing research has\nattempted to solve the problem from the dynamics discrepancy perspective. In\nthis work, we reveal the limitations of these methods and explore the problem\nfrom the value difference perspective via a novel insight on the value\nconsistency across domains. Specifically, we present the Value-Guided Data\nFiltering (VGDF) algorithm, which selectively shares transitions from the\nsource domain based on the proximity of paired value targets across the two\ndomains. Empirical results on various environments with kinematic and\nmorphology shifts demonstrate that our method achieves superior performance\ncompared to prior approaches.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:08:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17626","submitter":"Xiaoyang Hu","authors":"Xiaoyang Hu, Shane Storks, Richard L. Lewis, Joyce Chai","title":"In-Context Analogical Reasoning with Pre-Trained Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Analogical reasoning is a fundamental capacity of human cognition that allows\nus to reason abstractly about novel situations by relating them to past\nexperiences. While it is thought to be essential for robust reasoning in AI\nsystems, conventional approaches require significant training and/or\nhard-coding of domain knowledge to be applied to benchmark tasks. Inspired by\ncognitive science research that has found connections between human language\nand analogy-making, we explore the use of intuitive language-based abstractions\nto support analogy in AI systems. Specifically, we apply large pre-trained\nlanguage models (PLMs) to visual Raven's Progressive Matrices (RPM), a common\nrelational reasoning test. By simply encoding the perceptual features of the\nproblem into language form, we find that PLMs exhibit a striking capacity for\nzero-shot relational reasoning, exceeding human performance and nearing\nsupervised vision-based methods. We explore different encodings that vary the\nlevel of abstraction over task features, finding that higher-level abstractions\nfurther strengthen PLMs' analogical reasoning. Our detailed analysis reveals\ninsights on the role of model complexity, in-context learning, and prior\nknowledge in solving RPM tasks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:22:26 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 06:57:29 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17627","submitter":"Fei Wang","authors":"Fei Wang, James Y. Huang, Tianyi Yan, Wenxuan Zhou, Muhao Chen","title":"Robust Natural Language Understanding with Residual Attention Debiasing","comments":"ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Natural language understanding (NLU) models often suffer from unintended\ndataset biases. Among bias mitigation methods, ensemble-based debiasing\nmethods, especially product-of-experts (PoE), have stood out for their\nimpressive empirical success. However, previous ensemble-based debiasing\nmethods typically apply debiasing on top-level logits without directly\naddressing biased attention patterns. Attention serves as the main media of\nfeature interaction and aggregation in PLMs and plays a crucial role in\nproviding robust prediction. In this paper, we propose REsidual Attention\nDebiasing (READ), an end-to-end debiasing method that mitigates unintended\nbiases from attention. Experiments on three NLU tasks show that READ\nsignificantly improves the performance of BERT-based models on OOD data with\nshortcuts removed, including +12.9% accuracy on HANS, +11.0% accuracy on\nFEVER-Symmetric, and +2.7% F1 on PAWS. Detailed analyses demonstrate the\ncrucial role of unbiased attention in robust NLU models and that READ\neffectively mitigates biases in attention. Code is available at\nhttps://github.com/luka-group/READ.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:25:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17628","submitter":"Boris Houska","authors":"Boris Houska","title":"Convex operator-theoretic methods in stochastic control","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper is about operator-theoretic methods for solving nonlinear\nstochastic optimal control problems to global optimality. These methods\nleverage on the convex duality between optimally controlled diffusion processes\nand Hamilton-Jacobi-Bellman (HJB) equations for nonlinear systems in an ergodic\nHilbert-Sobolev space. In detail, a generalized Bakry-Emery condition is\nintroduced under which one can establish the global exponential stabilizability\nof a large class of nonlinear systems. It is shown that this condition is\nsufficient to ensure the existence of solutions of the ergodic HJB for\nstochastic optimal control problems on infinite time horizons. Moreover, a\nnovel dynamic programming recursion for bounded linear operators is introduced,\nwhich can be used to numerically solve HJB equations by a Galerkin projection.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:26:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17629","submitter":"Xilin Liu","authors":"Yuhan Hou, Jack Ji, Yi Zhu, Thomas Dell, and Xilin Liu","title":"Multi-Modal Wireless Flexible Gel-Free Sensors with Edge Deep Learning\n  for Detecting and Alerting Freezing of Gait in Parkinson's Patients","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Freezing of gait (FoG) is a debilitating symptom of Parkinson's disease (PD).\nThis work develops flexible wearable sensors that can detect FoG and alert\npatients and companions to help prevent falls. FoG is detected on the sensors\nusing a deep learning (DL) model with multi-modal sensory inputs collected from\ndistributed wireless sensors. Two types of wireless sensors are developed,\nincluding: (1) a C-shape central node placed around the patient's ears, which\ncollects electroencephalogram (EEG), detects FoG using an on-device DL model,\nand generates auditory alerts when FoG is detected; (2) a stretchable\npatch-type sensor attached to the patient's legs, which collects\nelectromyography (EMG) and movement information from accelerometers. The\npatch-type sensors wirelessly send collected data to the central node through\nlow-power ultra-wideband (UWB) transceivers. All sensors are fabricated on\nflexible printed circuit boards. Adhesive gel-free acetylene carbon black and\npolydimethylsiloxane electrodes are fabricated on the flexible substrate to\nallow conformal wear over the long term. Custom integrated circuits (IC) are\ndeveloped in 180 nm CMOS technology and used in both types of sensors for\nsignal acquisition, digitization, and wireless communication. A novel\nlightweight DL model is trained using multi-modal sensory data. The inference\nof the DL model is performed on a low-power microcontroller in the central\nnode. The DL model achieves a high detection sensitivity of 0.81 and a\nspecificity of 0.88. The developed wearable sensors are ready for clinical\nexperiments and hold great promise in improving the quality of life of patients\nwith PD. The proposed design methodologies can be used in wearable medical\ndevices for the monitoring and treatment of a wide range of neurodegenerative\ndiseases.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:28:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17630","submitter":"Jieqiu Shao","authors":"Jieqiu Shao, Mantas Naris, John Hauser and Marco M. Nicotra","title":"How to solve Quantum Optimal Control Problems using Projection\n  Operator-based Newton Steps","comments":"10 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Quantum PRojection Operator-based Newton method for Trajectory\nOptimization, a.k.a. Q-PRONTO, is a numerical method for solving quantum\noptimal control problems. This paper significantly improves prior versions of\nthe quantum projection operator by introducing a regulator that stabilizes the\nsolution estimate at every iteration. This modification is shown to not only\nimprove the convergence rate of the algorithm, but also steer the solver\ntowards better local minima compared to the un-regulated case. Numerical\nexamples showcase Q-PRONTO can be used to solve multi-input quantum optimal\ncontrol problems featuring time-varying costs and undesirable populations that\nought to be avoided during the transient.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:30:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17631","submitter":"Ana Carolina Da Cruz","authors":"Ana Carolina da Cruz and Camila P. E. de Souza","title":"A Bayesian Approach for Clustering Constant-wise Change-point Data","comments":"30 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Change-point models deal with ordered data sequences. Their primary goal is\nto infer the locations where an aspect of the data sequence changes. In this\npaper, we propose and implement a nonparametric Bayesian model for clustering\nobservations based on their constant-wise change-point profiles via Gibbs\nsampler. Our model incorporates a Dirichlet Process on the constant-wise\nchange-point structures to cluster observations while performing change-point\nestimation simultaneously. Additionally, our approach controls the number of\nclusters in the model, not requiring the specification of the number of\nclusters a priori. Our method's performance is evaluated on simulated data\nunder various scenarios and on a publicly available single-cell copy-number\ndataset.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:41:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17632","submitter":"Sunkyu Yu","authors":"Xianji Piao, Sunkyu Yu, and Namkyoo Park","title":"Programmable photonic time circuits for highly scalable universal\n  unitaries","comments":"46 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Programmable photonic circuits (PPCs) have garnered substantial interest in\nachieving deep learning accelerations and universal quantum computations.\nAlthough photonic computation using PPCs offers critical advantages, including\nultrafast operation, energy-efficient matrix calculation and room-temperature\nquantum states, its poor scalability impedes the integration required for\nindustrial applications. This challenge arises from the temporally one-shot\noperation using propagating light in conventional PPCs, which leads to the\nlight-speed increase of device footprints. Here we propose a concept of\nprogrammable photonic time circuits, which employ time-cycle-based computations\nanalogous to the gate cycling in the von Neumann architecture and quantum\ncomputation. As a building block, we develop a reconfigurable SU(2) time gate\ncomposed of two resonators, which have tunable resonances and are coupled\nthrough time-coded dual-channel gauge fields. We demonstrate universal U(N)\noperations with high fidelity using the systematic assembly of the SU(2) time\ngates, achieving improved scalability from O(N^2) to O(N) in both the footprint\nand gate number. This result opens a pathway to industrial-level PPC\nimplementation in very large-scale integration.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:56:58 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 00:43:46 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.17633","submitter":"Youlong Ding","authors":"Youlong Ding, Xueyang Wu, Hao Wang and Weike Pan","title":"DPFormer: Learning Differentially Private Transformer on Long-Tailed\n  Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Transformer has emerged as a versatile and effective architecture with\nbroad applications. However, it still remains an open problem how to\nefficiently train a Transformer model of high utility with differential privacy\nguarantees. In this paper, we identify two key challenges in learning\ndifferentially private Transformers, i.e., heavy computation overhead due to\nper-sample gradient clipping and unintentional attention distraction within the\nattention mechanism. In response, we propose DPFormer, equipped with Phantom\nClipping and Re-Attention Mechanism, to address these challenges. Our\ntheoretical analysis shows that DPFormer can reduce computational costs during\ngradient clipping and effectively mitigate attention distraction (which could\nobstruct the training process and lead to a significant performance drop,\nespecially in the presence of long-tailed data). Such analysis is further\ncorroborated by empirical results on two real-world datasets, demonstrating the\nefficiency and effectiveness of the proposed DPFormer.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:00:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17634","submitter":"Pasin Manurangsi","authors":"Badih Ghazi, Ravi Kumar, Pasin Manurangsi","title":"Pure-DP Aggregation in the Shuffle Model: Error-Optimal and\n  Communication-Efficient","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We obtain a new protocol for binary counting in the $\\varepsilon$-shuffle-DP\nmodel with error $O(1/\\varepsilon)$ and expected communication\n$\\tilde{O}\\left(\\frac{\\log n}{\\varepsilon}\\right)$ messages per user. Previous\nprotocols incur either an error of $O(1/\\varepsilon^{1.5})$ with\n$O_\\varepsilon(\\log{n})$ messages per user (Ghazi et al., ITC 2020) or an error\nof $O(1/\\varepsilon)$ with $O_\\varepsilon(n^{2.5})$ messages per user (Cheu and\nYan, TPDP 2022). Using the new protocol, we obtained improved\n$\\varepsilon$-shuffle-DP protocols for real summation and histograms.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:10:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17635","submitter":"Christian Fronsdal","authors":"Christian Fronsdal","title":"Theory of sounds in He II","comments":"15 pages, 2 figures","journal-ref":"Fiz. Nizk. Temp. 49, Nr 2, 167-173 (2023)","doi":"10.1063/10.0016839","report-no":null,"categories":"physics.gen-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A dynamical model for Landau's original approach to superfluid Helium is\npresented, with two velocities but only one mass density. Second sound is an\nadiabatic perturbation that involves the temperature and the roton, aka the\nnotoph. The action incorporates all the conservation laws, including the\nequation of continuity. With only 4 canonical variables it has a higher power\nof prediction than Landau's later, more complicated model, with its 8 degrees\nof freedom. The roton is identified with the massless notoph. This theory gives\na very satisfactory account of second and fourth sounds.\n  Second sound is an adiabatic oscillation of the temperature and both vector\nfields, with no net material motion. Fourth sound involves the roton, the\ntemperature and the density. With the experimental confirmation of\ngravitational waves the relations between Hydrodynamics and Relativity and\nparticle physics have become more clear, and urgent. The appearance of the\nNewtonian potential in irrotational hydrodynamics comes directly from\nEinstein's equations for the metric. The density factor $\\rho$ is essential; it\nis time to acknowledge the role that it plays in particle theory.\n  To complete the 2-vector theory we include the massless roton mode. Although\nthis mode too is affected by the mass density, it turns out that the wave\nfunction of the unique notoph propagating mode $\\mathcal{N}$ satisfies the\nnormal massless wave equation $\\Box\\mathcal{N}$ = 0; the roton propagates as a\nfree particle in the bulk of the superfluid without meeting resistance. In this\ncircumstance we may have discovered the mechanism that lies behind the flow of\nHe-II through very thin pores.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:16:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17636","submitter":"Manas Patra","authors":"Manas K Patra","title":"Entangling capacity of operators","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a unitary operator $U$ acting on a composite quantum system what is the\nentangling capacity of $U$? This question is investigated using a geometric\napproach. The entangling capacity, defined via metrics on the unitary groups,\nleads to a \\emph{minimax} problem. The dual, a \\emph{maximin} problem, is\ninvestigated in parallel and yields some familiar entanglement measures. A\nclass of entangling operators, called generalized control operators is defined.\nThe entangling capacities and other properties for this class of operators is\nstudied.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:34:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17637","submitter":"Tapas Sahoo","authors":"Tapas Sahoo and Gautam Gongopadhyay","title":"Effect of neighbouring molecules on ground-state properties of many-body\n  polar linear rotor systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A path integral ground state approach has been used to estimate the\nground-state energy and structural properties of hydrogen fluoride molecules\npinned to a one-dimensional lattice. In the simulations, the molecules are\nassumed to be rigid, and only the continuous rotational degrees of freedom are\nconsidered. The constituents of a many-body system interact through the\ndipole-dipole interaction because the molecules have a permanent dipole moment.\nThe workability of our approach has been demonstrated by estimating the\nground-state energy, order parameter and nearest neighbour correlation for the\nsystems of 2 and 3 HF molecules using quantum Monte Carlo simulations based on\nthe path integral ground state methodology. The results agree satisfactorily\nwith those obtained from exact Hamiltonian matrix diagonalization. In addition,\nthe effect of neighbours on the ground state properties has been investigated\nfor larger systems. The converged ground-state energy per neighbour as a\nfunction of inter-nuclear separation is considered to be the equation of state\nfor the system.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:42:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17638","submitter":"Takuro Mochizuki","authors":"Takuro Mochizuki","title":"Asymptotic behaviour of the Hitchin metric on the moduli space of Higgs\n  bundles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG math.AG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The moduli space of stable Higgs bundles of degree $0$ is equipped with the\nhyperk\\\"ahler metric, called the Hitchin metric. On the locus where the Hitchin\nfibration is smooth, there is the hyperk\\\"ahler metric called the semi-flat\nmetric, associated with the algebraic integrable systems with the Hitchin\nsection. We prove the exponentially rapid decay of the difference between the\nHitchin metric and the semi-flat metric along the ray $(E,t\\theta)$ as\n$t\\to\\infty$.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:46:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17639","submitter":"Jan Thorbecke","authors":"Jan Thorbecke, Mohammed Almobarak, Johno van IJsseldijk, Joeri\n  Brackenhoff, Giovanni Meles, Kees Wapenaar","title":"Design, implementation and application of the Marchenko Plane-wave\n  algorithm","comments":"20 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Marchenko algorithm can eliminate internal multiples in seismic\nreflection data. To achieve this a set of coupled equations with four unknowns\nis solved. These coupled equations are separated into a set of two equations\nwith two unknowns by means of a time-window. The two unknown focusing functions\ncan be solved by an iterative or direct method. These focusing functions, when\napplied to the reflection data, create virtual point-sources inside the medium.\nCombining individual virtual point-sources into a plane-wave leads to an\nefficient computation of images without internal multiples. To use the\nMarchenko algorithm with plane-wave focusing functions, the time-window that\nseparates the unknowns must be adapted. In this paper the design of the\nplane-wave Marchenko algorithm is explained and illustrated with numerically\nmodeled and measured reflection data.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:51:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17640","submitter":"Binod Sreenivasan","authors":"Debarshi Majumder, Binod Sreenivasan and Gaurav Maurya","title":"Self-similarity of the dipole-multipole transition in rapidly rotating\n  dynamos","comments":"27 pages, 17 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The dipole-multipole transition in rapidly rotating dynamos is investigated\nthrough the analysis of forced magnetohydrodynamic waves in an unstably\nstratified fluid. The focus of this study is on the inertia-free limit\napplicable to planetary cores, where the Rossby number is small not only on the\ncore depth but also on the length scale of columnar convection. By\nprogressively increasing the buoyant forcing in a linear magnetoconvection\nmodel, the slow Magnetic-Archimedean-Coriolis (MAC) waves are significantly\nattenuated so that their kinetic helicity decreases to zero; the fast MAC wave\nhelicity, on the other hand, is practically unaffected. In turn, polarity\nreversals in low-inertia spherical dynamos are shown to occur when the slow MAC\nwaves disappear under strong forcing. Two dynamically similar regimes are\nidentified -- the suppression of slow waves in a strongly forced dynamo and the\nexcitation of slow waves in a moderately forced dynamo starting from a small\nseed field. While the former regime results in polarity reversals, the latter\nregime produces the axial dipole from a chaotic multipolar state. For either\npolarity transition, a local Rayleigh number based on the mean wavenumber of\nthe energy-containing scales bears the same linear relationship with the square\nof the peak magnetic field measured at the transition. The self-similarity of\nthe dipole-multipole transition can place a constraint on the Rayleigh number\nfor polarity reversals in the Earth.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:53:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17641","submitter":"Boran Yesilyurt","authors":"R. P. Woodard, B. Yesilyurt","title":"Remembrance of Things Past","comments":"13 pages, 5 figures, uses LaTeX 2e","journal-ref":null,"doi":null,"report-no":"UFIFT-QG-23-05","categories":"gr-qc hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Nonlinear sigma models on de Sitter background have proved a useful prototype\nfor quantum gravity in summing the large logarithms which arise from loop\ncorrections. We consider a model whose evolution is described, at leading\nlogarithm order, by the trace of the coincident, doubly differentiated scalar\npropagator. An analytic approximation for this quantity on an arbitrary\nexpansion history is applied to generalize the resummed de Sitter result to any\ncosmological background which has experienced primordial inflation. In addition\nto analytic expressions, we present explicit numerical results for the\nevolution in a plausible expansion history. The large scales of primordial\ninflation are transmitted to late times.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:59:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17642","submitter":"Binh Bui","authors":"Binh T. Bui","title":"Geomechanics in unconventional resource development","comments":"16 pages, 7 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph physics.pop-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  To economically produce from very low permeability shale formations,\nhydraulic fracturing stimulation is typically used to improve their\nconductivity. This process deforms and breaks the rock, hence requires the\ngeomechanics data and calculation. The development of unconventional reservoirs\nrequires large geomechanical data, and geomechanics has involved in all\ncalculations of the unconventional reservoir projects. Geomechanics has\nnumerous contributions to the development of unconventional reservoirs from\nreservoir characterization and well construction to hydraulic fracturing and\nreservoir modeling as well as environmental aspect. This paper reviews and\nhighlights some important aspects of geomechanics on the successful development\nof unconventional reservoirs as well as outlines the recent development in\nunconventional reservoir geomechanics. The main objective is to emphasize the\nimportance of geomechanical data and geomechanics and how they are being used\nin in all aspects of unconventional reservoir projects.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:00:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17643","submitter":"Sizhu Lu","authors":"Sizhu Lu and Peng Ding","title":"Flexible sensitivity analysis for causal inference in observational\n  studies subject to unmeasured confounding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Causal inference with observational studies often suffers from unmeasured\nconfounding, yielding biased estimators based on the unconfoundedness\nassumption. Sensitivity analysis assesses how the causal conclusions change\nwith respect to different degrees of unmeasured confounding. Most existing\nsensitivity analysis methods work well for specific types of estimation or\ntesting strategies. We propose a flexible sensitivity analysis framework that\ncan deal with commonly-used inverse probability weighting, outcome regression,\nand doubly robust estimators simultaneously. It is based on the well-known\nparametrization of the selection bias as comparisons of the observed and\ncounterfactual outcomes conditional on observed covariates. It is attractive\nfor practical use because it only requires simple modifications of the standard\nestimators. Moreover, it naturally extends to many other causal inference\nsettings, including the average treatment effect on the treated units and\nstudies with survival outcomes. We also develop an R package saci that\nimplements our sensitivity analysis estimators.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:01:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17644","submitter":"Jin Sun","authors":"Jin Sun, Xiaoshuang Shi, Zhiyuan Weng, Kaidi Xu, Heng Tao Shen and\n  Xiaofeng Zhu","title":"Using Caterpillar to Nibble Small-Scale Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently, MLP-based models have become popular and attained significant\nperformance on medium-scale datasets (e.g., ImageNet-1k). However, their direct\napplications to small-scale images remain limited. To address this issue, we\ndesign a new MLP-based network, namely Caterpillar, by proposing a key module\nof Shifted-Pillars-Concatenation (SPC) for exploiting the inductive bias of\nlocality. SPC consists of two processes: (1) Pillars-Shift, which is to shift\nall pillars within an image along different directions to generate copies, and\n(2) Pillars-Concatenation, which is to capture the local information from\ndiscrete shift neighborhoods of the shifted copies. Extensive experiments\ndemonstrate its strong scalability and superior performance on popular\nsmall-scale datasets, and the competitive performance on ImageNet-1K to recent\nstate-of-the-art methods.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:19:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17645","submitter":"Su Yao","authors":"Su Yao and S. Komossa","title":"Multiwavelength variability of gamma-ray emitting narrow-line Seyfert 1\n  galaxies","comments":"12 pages, 10 figures. Published in MNRAS, 2023, Volume 523, Pages\n  441-452","journal-ref":null,"doi":"10.1093/mnras/stad1415","report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As one of the drivers of feedback in active galactic nuclei (AGNs), the jets\nlaunched from supermassive black holes (SMBHs) are important for understanding\nthe co-evolution of SMBHs and their host galaxies. However, the formation of\nAGN jets is far from clear. The discovery of gamma-ray narrow-line Seyfert 1\n(NLS1) galaxies during the past two decades has provided us with a new means of\nstudying the link between jets and accretion processes and the formation of\njets. Here, we explore the coupling of jet and accretion discs in seven bright\ngamma-ray NLS1 galaxies by studying simultaneous optical/ultraviolet and X-ray\nobservations of these systems taken by Swift. The results show that, except for\n1H 0323+342 in which the X-rays are significantly contributed from the\naccretion disc, the observed X-ray emission of the other sources is dominated\nby the jet, and accretion process makes little contribution if not absent.\nAlthough the origin of the X-ray emission is different, the broad-band spectral\nshape characterized by alpha_ox and the X-ray flux is found to follow the same\nevolutionary trend in 1H 0323+342, PMN J0948+0022, and PKS 1502+036. For the\nremaining sources, the trend is not observed or the sampling is not dense\nenough.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:34:45 GMT"},{"version":"v2","created":"Tue, 30 May 2023 04:01:13 GMT"},{"version":"v3","created":"Mon, 5 Jun 2023 05:49:41 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17646","submitter":"Kareem Elgindy","authors":"Kareem T. Elgindy and Hareth M. Refat","title":"Direct Integral Pseudospectral and Integral Spectral Methods for Solving\n  a Class of Infinite Horizon Optimal Output Feedback Control Problems Using\n  Rational and Exponential Gegenbauer Polynomials","comments":"27 pages, 24 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study is concerned with the numerical solution of a class of\ninfinite-horizon linear regulation problems with state equality constraints and\noutput feedback control. We propose two numerical methods to convert the\noptimal control problem into nonlinear programming problems (NLPs) using\ncollocations in a semi-infinite domain based on rational Gegenbauer (RG) and\nexponential Gegenbauer (EG) basis functions. We introduce new properties of\nthese basis functions and derive their quadratures and associated truncation\nerrors. A rigorous stability analysis of the RG and EG interpolations is also\npresented. The effects of various parameters on the accuracy and efficiency of\nthe proposed methods are investigated. The performance of the developed\nintegral spectral method is demonstrated using two benchmark test problems\nrelated to a simple model of a divert control system and the lateral dynamics\nof an F-16 aircraft. Comparisons of the results of the current study with\navailable numerical solutions show that the developed numerical scheme is\nefficient and exhibits faster convergence rates and higher accuracy.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:35:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17647","submitter":"Karen Kheruntsyan","authors":"S. A. Simmons, J. C. Pillay, and K. V. Kheruntsyan","title":"The fate of the \"vacuum point'' and of grey solitons in dispersive\n  quantum shock waves in a one-dimensional Bose gas","comments":"20 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas nlin.PS quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We continue the study of dispersive quantum shock waves in a one-dimensional\nBose gas beyond the mean-field approximation. In a recent work by Simmons et\nal. [Phys. Rev. Let. 125, 180401 (2020)], the oscillatory shock wave train\ndeveloping in this system from an initial localized density bump on a uniform\nbackground was interpreted as a result of quantum mechanical self-interference,\nwherein the interference contrast would diminish with the loss of matter-wave\nphase coherence. Such loss of coherence, relative to the mean-field\nGross-Pitaevskii description, occurs due to either quantum or thermal\nfluctuations, as well as in the strongly interacting regime. In this work, we\nextend the analysis of dispersive quantum shock waves in this context to other\ndynamical scenarios. More specifically, the scenarios studied include evolution\nof a sufficiently high density bump, known to lead to the so-called ``vacuum\npoint'' in the mean-field description, and evolution of an initial density dip,\nknown to shed a train of grey solitons in the same mean-field approximation. We\nstudy the fate of these nonlinear wave structures in the presence of quantum\nand thermal fluctuations, as well as at intermediate and strong interactions,\nand show that both the vacuum point and grey solitons cease to manifest\nthemselves beyond the mean-field approach. On the other hand, we find that a\nvacuum point can occur in an ideal (noninteracting) Bose gas evolving from a\nground state of a localized dimple potential. Due to the ubiquity of dispersive\nshock waves in nature, our results should provide useful insights and\nperspectives for a variety of other physical systems known to display nonlinear\nwave phenomena.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:39:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17648","submitter":"Kim Tran","authors":"Kim Hoang Tran, Tien-Phat Nguyen, Anh Duy Le Dinh, Pha Nguyen, Thinh\n  Phan, Khoa Luu, Donald Adjeroh, Ngan Hoang Le","title":"Z-GMOT: Zero-shot Generic Multiple Object Tracking","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite the significant progress made in recent years, Multi-Object Tracking\n(MOT) approaches still suffer from several limitations, including their\nreliance on prior knowledge of tracking targets, which necessitates the costly\nannotation of large labeled datasets. As a result, existing MOT methods are\nlimited to a small set of predefined categories, and they struggle with unseen\nobjects in the real world. To address these issues, Generic Multiple Object\nTracking (GMOT) has been proposed, which requires less prior information about\nthe targets. However, all existing GMOT approaches follow a one-shot paradigm,\nrelying mainly on the initial bounding box and thus struggling to handle\nvariants e.g., viewpoint, lighting, occlusion, scale, and etc. In this paper,\nwe introduce a novel approach to address the limitations of existing MOT and\nGMOT methods. Specifically, we propose a zero-shot GMOT (Z-GMOT) algorithm that\ncan track never-seen object categories with zero training examples, without the\nneed for predefined categories or an initial bounding box. To achieve this, we\npropose iGLIP, an improved version of Grounded language-image pretraining\n(GLIP), which can detect unseen objects while minimizing false positives. We\nevaluate our Z-GMOT thoroughly on the GMOT-40 dataset, AnimalTrack testset,\nDanceTrack testset. The results of these evaluations demonstrate a significant\nimprovement over existing methods. For instance, on the GMOT-40 dataset, the\nZ-GMOT outperforms one-shot GMOT with OC-SORT by 27.79 points HOTA and 44.37\npoints MOTA. On the AnimalTrack dataset, it surpasses fully-supervised methods\nwith DeepSORT by 12.55 points HOTA and 8.97 points MOTA. To facilitate further\nresearch, we will make our code and models publicly available upon acceptance\nof this paper.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:44:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17649","submitter":"Saar Beck","authors":"Saar Beck, Ronen Weiss, Nir Barnea","title":"The asymptotic behaviour of the many-body coupled cluster amplitudes","comments":null,"journal-ref":null,"doi":null,"report-no":"LA-UR-23-24947","categories":"nucl-th nucl-ex","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We analyze the asymptotic behaviour of the coupled cluster many-body\nwave-function in the limit of highly excited two- and three-particles states.\nWe find that in this limit the different coupled cluster amplitudes exhibit a\nrecurring behaviour, factorizing into a common asymptotic two- or three-body\nterm. These asymptotic terms depend on the potential and in general are system\nspecific. We also suggest that the knowledge of the asymptotic behaviour can\npotentially help solving the coupled cluster equations in a more efficient way.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:46:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17650","submitter":"Sijie Cheng","authors":"Guan Wang, Yuhao Sun, Sijie Cheng, Sen Song","title":"Evolving Connectivity for Recurrent Spiking Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recurrent spiking neural networks (RSNNs) hold great potential for advancing\nartificial general intelligence, as they draw inspiration from the biological\nnervous system and show promise in modeling complex dynamics. However, the\nwidely-used surrogate gradient-based training methods for RSNNs are inherently\ninaccurate and unfriendly to neuromorphic hardware. To address these\nlimitations, we propose the evolving connectivity (EC) framework, an\ninference-only method for training RSNNs. The EC framework reformulates\nweight-tuning as a search into parameterized connection probability\ndistributions, and employs Natural Evolution Strategies (NES) for optimizing\nthese distributions. Our EC framework circumvents the need for gradients and\nfeatures hardware-friendly characteristics, including sparse boolean\nconnections and high scalability. We evaluate EC on a series of standard\nrobotic locomotion tasks, where it achieves comparable performance with deep\nneural networks and outperforms gradient-trained RSNNs, even solving the\ncomplex 17-DoF humanoid task. Additionally, the EC framework demonstrates a two\nto three fold speedup in efficiency compared to directly evolving parameters.\nBy providing a performant and hardware-friendly alternative, the EC framework\nlays the groundwork for further energy-efficient applications of RSNNs and\nadvances the development of neuromorphic devices.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:08:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17651","submitter":"Yifan Peng","authors":"Yifan Peng, Yui Sudo, Shakeel Muhammad, Shinji Watanabe","title":"DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech\n  Models","comments":"Accepted at INTERSPEECH 2023. Code will be available at:\n  https://github.com/pyf98/DPHuBERT","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Self-supervised learning (SSL) has achieved notable success in many speech\nprocessing tasks, but the large model size and heavy computational cost hinder\nthe deployment. Knowledge distillation trains a small student model to mimic\nthe behavior of a large teacher model. However, the student architecture\nusually needs to be manually designed and will remain fixed during training,\nwhich requires prior knowledge and can lead to suboptimal performance. Inspired\nby recent success of task-specific structured pruning, we propose DPHuBERT, a\nnovel task-agnostic compression method for speech SSL based on joint\ndistillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms\npure distillation methods in almost all tasks. Moreover, DPHuBERT requires\nlittle training time and performs well with limited training data, making it\nsuitable for resource-constrained applications. Our method can also be applied\nto various speech SSL models. Our code and models will be publicly available.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:09:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17652","submitter":"Jiapeng Wang","authors":"Jiapeng Wang, Chengyu Wang, Xiaodan Wang, Jun Huang, Lianwen Jin","title":"ConaCLIP: Exploring Distillation of Fully-Connected Knowledge\n  Interaction Graph for Lightweight Text-Image Retrieval","comments":"ACL 2023 Industry Track","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large-scale pre-trained text-image models with dual-encoder architectures\n(such as CLIP) are typically adopted for various vision-language applications,\nincluding text-image retrieval. However,these models are still less practical\non edge devices or for real-time situations, due to the substantial indexing\nand inference time and the large consumption of computational resources.\nAlthough knowledge distillation techniques have been widely utilized for\nuni-modal model compression, how to expand them to the situation when the\nnumbers of modalities and teachers/students are doubled has been rarely\nstudied. In this paper, we conduct comprehensive experiments on this topic and\npropose the fully-Connected knowledge interaction graph (Cona) technique for\ncross-modal pre-training distillation. Based on our findings, the resulting\nConaCLIP achieves SOTA performances on the widely-used Flickr30K and MSCOCO\nbenchmarks under the lightweight setting. An industry application of our method\non an e-commercial platform further demonstrates the significant effectiveness\nof ConaCLIP.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:16:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17653","submitter":"Sijie Cheng","authors":"Zhicheng Guo, Sijie Cheng, Yile Wang, Peng Li, Yang Liu","title":"Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Retrieval-augmented methods have received increasing attention to support\ndownstream tasks by leveraging useful information from external resources.\nRecent studies mainly focus on exploring retrieval to solve knowledge-intensive\n(KI) tasks. However, the potential of retrieval for most\nnon-knowledge-intensive (NKI) tasks remains under-explored. There are two main\nchallenges to leveraging retrieval-augmented methods for NKI tasks: 1) the\ndemand for diverse relevance score functions and 2) the dilemma between\ntraining cost and task performance. To address these challenges, we propose a\ntwo-stage framework for NKI tasks, named PGRA. In the first stage, we adopt a\ntask-agnostic retriever to build a shared static index and select candidate\nevidence efficiently. In the second stage, we design a prompt-guided reranker\nto rerank the nearest evidence according to task-specific relevance for the\nreader. Experimental results show that PGRA outperforms other state-of-the-art\nretrieval-augmented methods. Our analyses further investigate the influence\nfactors to model performance and demonstrate the generality of PGRA. Codes are\navailable at https://github.com/THUNLP-MT/PGRA.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:27:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17654","submitter":"Qian Xiong","authors":"LiPing Lu, Qian Xiong, DuanFeng Chu, BingRong Xu","title":"MixDehazeNet : Mix Structure Block For Image Dehazing Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Image dehazing is a typical task in the low-level vision field. Previous\nstudies verified the effectiveness of the large convolutional kernel and\nattention mechanism in dehazing. However, there are two drawbacks: the\nmulti-scale properties of an image are readily ignored when a large\nconvolutional kernel is introduced, and the standard series connection of an\nattention module does not sufficiently consider an uneven hazy distribution. In\nthis paper, we propose a novel framework named Mix Structure Image Dehazing\nNetwork (MixDehazeNet), which solves two issues mentioned above. Specifically,\nit mainly consists of two parts: the multi-scale parallel large convolution\nkernel module and the enhanced parallel attention module. Compared with a\nsingle large kernel, parallel large kernels with multi-scale are more capable\nof taking partial texture into account during the dehazing phase. In addition,\nan enhanced parallel attention module is developed, in which parallel\nconnections of attention perform better at dehazing uneven hazy distribution.\nExtensive experiments on three benchmarks demonstrate the effectiveness of our\nproposed methods. For example, compared with the previous state-of-the-art\nmethods, MixDehazeNet achieves a significant improvement (42.62dB PSNR) on the\nSOTS indoor dataset. The code is released in\nhttps://github.com/AmeryXiong/MixDehazeNet.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:41:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17655","submitter":"Johnnatan Messias","authors":"Johnnatan Messias and Vabuk Pahari and Balakrishnan Chandrasekaran and\n  Krishna P. Gummadi and Patrick Loiseau","title":"Understanding Blockchain Governance: Analyzing Decentralized Voting to\n  Amend DeFi Smart Contracts","comments":"We have submitted this work for publication and are currently\n  awaiting a decision","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Smart contracts are contractual agreements between participants of a\nblockchain, who cannot implicitly trust one another. They are software programs\nthat run on top of a blockchain, and we may need to change them from time to\ntime (e.g., to fix bugs or address new use cases). Governance protocols define\nthe means for amending or changing these smart contracts without any\ncentralized authority. They distribute instead the decision-making power to\nevery user of the smart contract: Users vote on accepting or rejecting every\nchange. The focus of this work is to evaluate whether, how, and to what extent\nthese protocols ensure decentralized governance, the fundamental tenet of\nblockchains, in practice. This evaluation is crucial as smart contracts\ncontinue to transform our key, traditional, centralized institutions,\nparticularly banking and finance.\n  In this work, we review and characterize decentralized governance in\npractice, using Compound -- one of the widely used governance protocols -- as a\ncase study. We reveal a high concentration of voting power in Compound: 10\nvoters hold together 57.86% of the voting power. Although proposals to change\nor amend the protocol (or, essentially, the application they support) receive,\non average, a substantial number of votes (i.e., 89.39%) in favor, they require\nfewer than three voters to obtain 50% or more votes. We show that voting on\nCompound governance proposals can be unfairly expensive for small token\nholders, and also discover voting coalitions that can further marginalize these\nusers. We plan on publishing our scripts and data set on GitHub to support\nreproducible research.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:45:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17656","submitter":"Ken Chen","authors":"Ken Chen, Jia-Hao L\\\"u, Xin Zhu, Hao-Long Zhang, Wen Ning, Zhen-Biao\n  Yang, and Shi-Biao Zheng","title":"Dynamical critical quantum sensing with a single parametrically-driven\n  nonlinear resonator","comments":"6 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Critical phenomena of quantum systems are useful for enhancement of quantum\nsensing. We here investigate the performance of a sensing scheme, where the\nsignal is encoded in the dynamically-evolving state of an oscillator, featuring\na competition of the Kerr nonlinearity and parametric driving. We calculate the\nquantum Fisher information, and perform a simulation, which confirms the\ncriticality-enabled enhancement. We further detail the response of one of the\nquadratures to the variation of the control parameter. The numerical results\nreveal that its inverted variance exhibits a diverging behavior at the critical\npoint.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:45:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17657","submitter":"Pintu Bhunia","authors":"Pintu Bhunia","title":"Power numerical radius inequalities from an extension of Buzano's\n  inequality","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Several numerical radius inequalities are studied by developing an extension\nof the Buzano's inequality. It is shown that if $T$ is a bounded linear\noperator on a complex Hilbert space, then\n  \\begin{eqnarray*}\n  w^n(T) &\\leq& \\frac{1}{2^{n-1}} w(T^n)+ \\sum_{k=1}^{n-1} \\frac{1}{2^{k}}\n\\left\\|T^k \\right\\| \\left\\|T \\right\\|^{n-k}, \\end{eqnarray*} for every positive\ninteger $n\\geq 2.$ This is a non-trivial improvement of the classical\ninequality $w(T)\\leq \\|T\\|.$ The above inequality gives an estimation for the\nnumerical radius of the nilpotent operators, i.e., if $T^n=0$ for some least\npositive integer $n\\geq 2$, then \\begin{eqnarray*}\n  w(T) &\\leq& \\left(\\sum_{k=1}^{n-1} \\frac{1}{2^{k}} \\left\\|T^k \\right\\|\n\\left\\|T \\right\\|^{n-k}\\right)^{1/n}\n  \\leq \\left( 1- \\frac{1}{2^{n-1}}\\right)^{1/n} \\|T\\|. \\end{eqnarray*}\n  Also, we deduce a reverse inequality for the numerical radius power\ninequality $w(T^n)\\leq w^n(T)$. We show that if $\\|T\\|\\leq 1$, then\n  \\begin{eqnarray*}\n  w^n(T) &\\leq& \\frac{1}{2^{n-1}} w(T^n)+ 1- \\frac{1}{2^{n-1}},\n  \\end{eqnarray*}\n  for every positive integer $n\\geq 2.$ This inequality is sharp.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:47:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17658","submitter":"Ciro Ciliberto","authors":"Ciro Ciliberto, Alessandro Verra, Francesco Zucconi","title":"On deformations of the surfaces of bitangents to smooth quartic surfaces\n  in $\\mP^3$","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that the surface $S(X)$ of bitangent lines of a general smooth\nquartic surface $X$ in $\\mP^3$ has unobstructed deformations of dimension\n$20=h^1(S(X), T_{S(X)})$. In addition, we show that the space of infinitesimal\nembedded deformations of $X$ injects into the one of $S(X)$. Finally we prove\nthat there is a natural birational map from the 20--dimensional moduli space of\n(polarised) double coverings of EPW--sextics to the moduli space of regular\nsurfaces $S$ with $p_g=45$ and $K_S^2=360$ polarised with a very ample line\nbundle $H$ such that $H^2=40$, $h^0(S, H)=6$: the map sends a double covering\nof a EPW--sextic in $\\mP^5$ to the surface of double points of the EPW--sextic.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:50:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17659","submitter":"Kai Du","authors":"Tian Chen, Kai Du, Zongyuan Huang, Zhen Wu","title":"A maximum principle for progressive optimal control of mean-filed\n  forward-backward stochastic system involving random jumps and impulse\n  controls","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we study an optimal control problem of a mean-field\nforward-backward stochastic system with random jumps in progressive structure,\nwhere both regular and singular controls are considered in our formula. In\nvirtue of the variational technology, the related stochastic maximum principle\n(SMP) has been obtained, and it is essentially different from that in the\nclassical predictable structure. Specifically, there are three parts in our\nSMP, i.e. continuous part, jump part and impulse part, and they are\nrespectively used to characterize the characteristics of the optimal controls\nat continuous time, jump time and impulse time. This shows that the progressive\nstructure can more accurately describe the characteristics of the optimal\ncontrol at the jump time. We also give two linear-quadratic (LQ) examples to\nshow the significance of our results.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 07:53:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17660","submitter":"Chaojun Xiao","authors":"Chaojun Xiao, Zhengyan Zhang, Xu Han, Chi-Min Chan, Yankai Lin,\n  Zhiyuan Liu, Xiangyang Li, Zhonghua Li, Zhao Cao, Maosong Sun","title":"Plug-and-Play Document Modules for Pre-trained Models","comments":"Accepted by ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large-scale pre-trained models (PTMs) have been widely used in\ndocument-oriented NLP tasks, such as question answering. However, the\nencoding-task coupling requirement results in the repeated encoding of the same\ndocuments for different tasks and queries, which is highly computationally\ninefficient. To this end, we target to decouple document encoding from\ndownstream tasks, and propose to represent each document as a plug-and-play\ndocument module, i.e., a document plugin, for PTMs (PlugD). By inserting\ndocument plugins into the backbone PTM for downstream tasks, we can encode a\ndocument one time to handle multiple tasks, which is more efficient than\nconventional encoding-task coupling methods that simultaneously encode\ndocuments and input queries using task-specific encoders. Extensive experiments\non 8 datasets of 4 typical NLP tasks show that PlugD enables models to encode\ndocuments once and for all across different scenarios. Especially, PlugD can\nsave $69\\%$ computational costs while achieving comparable performance to\nstate-of-the-art encoding-task coupling methods. Additionally, we show that\nPlugD can serve as an effective post-processing way to inject knowledge into\ntask-specific models, improving model performance without any additional model\ntraining.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:01:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17661","submitter":"Mohamed Ghattassi","authors":"Mohamed Ghattassi and Xiaokai Huo and Nader Masmoudi","title":"Diffusive limits of the steady state radiative heat transfer system:\n  Curvature effects","comments":"43 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper is devoted to the diffusive limit of the nonlinear radiative heat\ntransfer system with curved boundary domain (\\textit{two dimensional disk}).\nThe solution constructed in \\cite{ghattassi2022convergence} by the leading\norder interior solution and the boundary layer corrections fails here to\napproximate the solutions in $L^\\infty$ sense for the diffusive limit. The\npresent paper aims to construct a geometric correction to the boundary layer\nproblem and obtain a valid approximate solution in $L^\\infty$ sense. The main\ntools to overcome the convergence problem, are to use matched asymptotic\nexpansion techniques, fixed-point theorems, linear and nonlinear stability\nanalysis of the boundary layer problem. In particular, the spectral assumption\non the leading order interior solution, which was proposed for the flat case in\n\\cite{Bounadrylayer2019GHM2}, is shown to be still valid which guarantee the\nstability of the boundary layer expansion with geometric corrections. Moreover,\nthe convergence result established in \\cite[Lemma 10]{ghattassi2022convergence}\nremain applicable for the approximate solution with geometric corrections.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:04:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17662","submitter":"Zhuowei Sun","authors":"Congmin Liu, Zhuowei Sun and Hongyuan Cao","title":"Regression analysis of mixed sparse synchronous and asynchronous\n  longitudinal covariates with varying-coefficient models","comments":"57 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider varying-coefficient models for mixed synchronous and asynchronous\nlongitudinal covariates, where asynchronicity refers to the misalignment of\nlongitudinal measurement times within an individual. We propose three different\nmethods of parameter estimation and inference. The first method is a one-step\napproach that estimates non-parametric regression functions for synchronous and\nasynchronous longitudinal covariates simultaneously. The second method is a\ntwo-step approach in which synchronous longitudinal covariates are regressed\nwith the longitudinal response by centering the synchronous longitudinal\ncovariates first and, in the second step, the residuals from the first step are\nregressed with asynchronous longitudinal covariates. The third method is the\nsame as the second method except that in the first step, we omit the\nasynchronous longitudinal covariate and include a non-parametric intercept in\nthe regression analysis of synchronous longitudinal covariates and the\nlongitudinal response. We further construct simultaneous confidence bands for\nthe non-parametric regression functions to quantify the overall magnitude of\nvariation. Extensive simulation studies provide numerical support for the\ntheoretical findings. The practical utility of the methods is illustrated on a\ndataset from the ADNI study.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:17:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17663","submitter":"Po-Ya Angela Wang","authors":"Po-Ya Angela Wang, Pin-Er Chen, Hsin-Yu Chou, Yu-Hsiang Tseng, Shu-Kai\n  Hsieh","title":"Lexical Retrieval Hypothesis in Multimodal Context","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multimodal corpora have become an essential language resource for language\nscience and grounded natural language processing (NLP) systems due to the\ngrowing need to understand and interpret human communication across various\nchannels. In this paper, we first present our efforts in building the first\nMultimodal Corpus for Languages in Taiwan (MultiMoco). Based on the corpus, we\nconduct a case study investigating the Lexical Retrieval Hypothesis (LRH),\nspecifically examining whether the hand gestures co-occurring with speech\nconstants facilitate lexical retrieval or serve other discourse functions. With\ndetailed annotations on eight parliamentary interpellations in Taiwan Mandarin,\nwe explore the co-occurrence between speech constants and non-verbal features\n(i.e., head movement, face movement, hand gesture, and function of hand\ngesture). Our findings suggest that while hand gestures do serve as\nfacilitators for lexical retrieval in some cases, they also serve the purpose\nof information emphasis. This study highlights the potential of the MultiMoco\nCorpus to provide an important resource for in-depth analysis and further\nresearch in multimodal communication studies.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:17:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17664","submitter":"Erdal Pekel","authors":"Erdal Pekel, Martin Dierolf, Franz Pfeiffer and Tobias Lasser","title":"Spherical acquisition trajectories for X-ray computed tomography with a\n  robotic sample holder","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This work presents methods for the seamless execution of arbitrary spherical\ntrajectories with a seven-degree-of-freedom robotic arm as a sample holder. The\nsample holder is integrated into an existing X-ray computed tomography setup.\nWe optimized the path planning and robot control algorithms for the seamless\nexecution of spherical trajectories. A precision-manufactured sample holder\npart is attached to the robotic arm for the calibration procedure. Different\ndesigns of this part are tested and compared to each other for optimal coverage\nof trajectories and reconstruction image quality.\n  We present experimental results with the robotic sample holder where a sample\nmeasurement on a spherical trajectory achieves improved reconstruction quality\ncompared to a conventional circular trajectory. Our results demonstrate the\nsuperiority of the discussed system as it outperforms single-axis systems by\nreaching nearly 82\\% of all possible rotations.\n  The proposed system is a step towards higher image reconstruction quality in\nflexible X-ray CT systems. It will enable reduced scan times and radiation dose\nexposure with task-specific trajectories in the future, as it can capture\ninformation from various sample angles.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:23:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17665","submitter":"Kejie Tang","authors":"Kejie Tang, Weidong Liu and Yichen Zhang","title":"Acceleration of stochastic gradient descent with momentum by averaging:\n  finite-sample rates and asymptotic normality","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stochastic gradient descent with momentum (SGDM) has been widely used in many\nmachine learning and statistical applications. Despite the observed empirical\nbenefits of SGDM over traditional SGD, the theoretical understanding of the\nrole of momentum for different learning rates in the optimization process\nremains widely open. We analyze the finite-sample convergence rate of SGDM\nunder the strongly convex settings and show that, with a large batch size, the\nmini-batch SGDM converges faster than mini-batch SGD to a neighborhood of the\noptimal value. Furthermore, we analyze the Polyak-averaging version of the SGDM\nestimator, establish its asymptotic normality, and justify its asymptotic\nequivalence to the averaged SGD.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:49:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17666","submitter":"Abhishta Abhishta","authors":"Muhammad Yasir Muzayan Haq, Abhishta Abhishta, Raffaele Sommese,\n  Mattijs Jonker, Lambert J.M. Nieuwenhuis","title":"Assessing Network Operator Actions to Enhance Digital Sovereignty and\n  Strengthen Network Resilience: A Longitudinal Analysis during the\n  Russia-Ukraine Conflict","comments":null,"journal-ref":"2023 IEEE European Symposium on Security and Privacy Workshops\n  (EuroS&PW). IEEE, 2023","doi":null,"report-no":null,"categories":"cs.NI cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We conduct longitudinal and temporal analyses on active DNS measurement data\nto investigate how the Russia-Ukraine conflict impacted the network\ninfrastructures supporting domain names under ICANN's CZDS new gTLDs. Our\nfindings revealed changes in the physical locations of network infrastructures,\nutilization of managed DNS services, infrastructure redundancy, and\ndistribution, which started right after the first reported Russian military\nmovements in February 2022. We also found that domains from different countries\nhad varying location preferences when moving their hosting infrastructure.\nThese observed changes suggest that network operators took proactive measures\nin anticipation of an armed conflict to promote resilience and protect the\nsovereignty of their networks in response to the conflict.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:05:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17667","submitter":"George Filandrianos","authors":"Edmund Dervakos, Konstantinos Thomas, Giorgos Filandrianos, Giorgos\n  Stamou","title":"Choose your Data Wisely: A Framework for Semantic Counterfactuals","comments":"To appear at IJCAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Counterfactual explanations have been argued to be one of the most intuitive\nforms of explanation. They are typically defined as a minimal set of edits on a\ngiven data sample that, when applied, changes the output of a model on that\nsample. However, a minimal set of edits is not always clear and understandable\nto an end-user, as it could, for instance, constitute an adversarial example\n(which is indistinguishable from the original data sample to an end-user).\nInstead, there are recent ideas that the notion of minimality in the context of\ncounterfactuals should refer to the semantics of the data sample, and not to\nthe feature space. In this work, we build on these ideas, and propose a\nframework that provides counterfactual explanations in terms of knowledge\ngraphs. We provide an algorithm for computing such explanations (given some\nassumptions about the underlying knowledge), and quantitatively evaluate the\nframework with a user study.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:06:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17668","submitter":"Pietro Menotti","authors":"Pietro Menotti","title":"Liouville field theory on genus 2 surfaces","comments":"22 pages LaTex","journal-ref":null,"doi":null,"report-no":"IFUP-TH/2023","categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Exploiting the generalization of the Weierstrass $\\wp$ function to genus $2$\ngiven by Komori, we give the exact connection of the related monodromy problem\nfor genus $2$ and the classical weak $n$-point correlation functions. We also\nprovide the Green function of an Helmholtz operator on genus $2$ surfaces and\nprove the real analyticity of the higher genus Green function. This gives at\nthe non perturbative level, through the continuation method, the real\nanalyticity of the conformal factor and of the accessory parameters in presence\nof sources.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:12:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17669","submitter":"Rustem Khasanov","authors":"Rustem Khasanov, Bin-Bin Ruan, Yun-Qing Shi, Gen-Fu Chen, Hubertus\n  Luetkens, Zhi-An Ren, and Zurab Guguchia","title":"Emergence of flat bands and their impact on superconductivity of\n  Mo$_5$Si$_{3-x}$P$_x$","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The first-principles calculations and measurements of the magnetic\npenetration depths, the upper critical field, and the specific heat were\nperformed for a family of Mo$_5$Si$_{3-x}$P$_x$ superconducotrs.\nFirst-principles calculations suggest the presence of a flat band dispersion,\nwhich gradually shifts to the Fermi level as a function of phosphorus doping\n$x$. The flat band approaches the Fermi level at $x\\simeq 1.3$, thus separating\nMo$_5$Si$_{3-x}$P$_x$ between the purely steep band and the steep band/flat\nband superconducting regimes. The emergence of flat bands lead to an abrupt\nchange of nearly all the superconducting quantities. In particular, a strong\nreduction of the coherence length $\\xi$ and enhancement of the penetration\ndepth $\\lambda$ result in nearly factor of three increase of the\nGinzburg-Landau parameter $\\kappa=\\lambda/\\xi$ (from $\\kappa\\simeq 25$ for\n$x\\lesssim 1.2$ to $\\kappa\\simeq 70$ for $x\\gtrsim 1.4$) thus initiating the\ntransition of Mo$_5$Si$_{3-x}$P$_x$ from a moderate to an extreme type-II\nsuperconductivity.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:22:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17670","submitter":"Weize Chen","authors":"Weize Chen, Xu Han, Yankai Lin, Zhiyuan Liu, Maosong Sun, Jie Zhou","title":"Stochastic Bridges as Effective Regularizers for Parameter-Efficient\n  Tuning","comments":"ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Parameter-efficient tuning methods (PETs) have achieved promising results in\ntuning large pre-trained language models (PLMs). By formalizing frozen PLMs and\nadditional tunable parameters as systems and controls respectively, PETs can be\ntheoretically grounded to optimal control and further viewed as optimizing the\nterminal cost and running cost in the optimal control literature. Despite the\nelegance of this theoretical grounding, in practice, existing PETs often ignore\nthe running cost and only optimize the terminal cost, i.e., focus on optimizing\nthe loss function of the output state, regardless of the running cost that\ndepends on the intermediate states. Since it is non-trivial to directly model\nthe intermediate states and design a running cost function, we propose to use\nlatent stochastic bridges to regularize the intermediate states and use the\nregularization as the running cost of PETs. As the first work to propose\nregularized PETs that use stochastic bridges as the regularizers (running\ncosts) for the intermediate states, we show the effectiveness and generality of\nthis regularization across different tasks, PLMs and PETs. In view of the great\npotential and capacity, we believe more sophisticated regularizers can be\ndesigned for PETs and better performance can be achieved in the future. The\ncode is released at\n\\url{https://github.com/thunlp/stochastic-bridge-pet/tree/main}.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:22:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17671","submitter":"Benjamin Bisping","authors":"Benjamin Bisping, David N. Jansen","title":"Linear-Time--Branching-Time Spectroscopy Accounting for Silent Steps","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We provide the first generalized game characterization of van Glabbeek's\nlinear-time--branching-time spectrum with silent steps. Thereby, one\nmulti-dimensional energy game can be used to decide a wide array of behavioral\nequivalences between stability-respecting branching bisimiarity and weak trace\nequivalence in one go. To establish correctness, we relate attacker-winning\nenergy budgets and distinguishing sublanguages of Hennessy--Milner logic\ncharacterized by eight dimensions of formula expressiveness. We outline how to\nderive exponential-time algorithms and divergence-preserving variants.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:27:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17672","submitter":"Ilya Tyuryukanov","authors":"Ilya Tyuryukanov, Marjan Popov, Jorrit A. Bos, Mart A.M.M. van der\n  Meijden, Vladimir Terzija","title":"New Cycle-based Formulation, Cost Function, and Heuristics for DC OPF\n  Based Controlled Islanding","comments":"https://doi.org/10.1016/j.epsr.2022.108588","journal-ref":"Electric Power Systems Research, Volume 212, November 2022","doi":"10.1016/j.epsr.2022.108588","report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents a new formulation for intentional controlled islanding\n(ICI) of power transmission grids based on mixed-integer linear programming\n(MILP) DC optimal power flow (OPF) model. We highlight several deficiencies of\nthe most well-known formulation for this problem and propose new enhancements\nfor their improvement. In particular, we propose a new alternative optimization\nobjective that may be more suitable for ICI than the minimization of load\nshedding, a new set of island connectivity constraints, and a new set of\nconstraints for DC OPF with switching, and a new MILP heuristic to find initial\nfeasible solutions for ICI. It is shown that the proposed improvements help to\nreduce the final optimality gaps as compared to the benchmark model on several\ntest instances.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:44:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17673","submitter":"Jawad Haidar","authors":"Jawad Haidar, Douaa Khalil, Daniel Asmar","title":"OSPC: Online Sequential Photometric Calibration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Photometric calibration is essential to many computer vision applications.\nOne of its key benefits is enhancing the performance of Visual SLAM, especially\nwhen it depends on a direct method for tracking, such as the standard KLT\nalgorithm. Another advantage could be in retrieving the sensor irradiance\nvalues from measured intensities, as a pre-processing step for some vision\nalgorithms, such as shape-from-shading. Current photometric calibration systems\nrely on a joint optimization problem and encounter an ambiguity in the\nestimates, which can only be resolved using ground truth information. We\npropose a novel method that solves for photometric parameters using a\nsequential estimation approach. Our proposed method achieves high accuracy in\nestimating all parameters; furthermore, the formulations are linear and convex,\nwhich makes the solution fast and suitable for online applications. Experiments\non a Visual Odometry system validate the proposed method and demonstrate its\nadvantages.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:44:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17674","submitter":"Li YingZe","authors":"Yingze Li, Hongzhi Wang, Xianglong Liu","title":"One stone, two birds: A lightweight multidimensional learned index with\n  cardinality support","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Innovative learning based structures have recently been proposed to tackle\nindex and cardinality estimation tasks, specifically learned indexes and data\ndriven cardinality estimators. These structures exhibit excellent performance\nin capturing data distribution, making them promising for integration into AI\ndriven database kernels. However, accurate estimation for corner case queries\nrequires a large number of network parameters, resulting in higher computing\nresources on expensive GPUs and more storage overhead. Additionally, the\nseparate implementation for CE and learned index result in a redundancy waste\nby storage of single table distribution twice. These present challenges for\ndesigning AI driven database kernels. As in real database scenarios, a compact\nkernel is necessary to process queries within a limited storage and time\nbudget. Directly integrating these two AI approaches would result in a heavy\nand complex kernel due to a large number of network parameters and repeated\nstorage of data distribution parameters. Our proposed CardIndex structure\neffectively killed two birds with one stone. It is a fast multidim learned\nindex that also serves as a lightweight cardinality estimator with parameters\nscaled at the KB level. Due to its special structure and small parameter size,\nit can obtain both CDF and PDF information for tuples with an incredibly low\nlatency of 1 to 10 microseconds. For tasks with low selectivity estimation, we\ndid not increase the model's parameters to obtain fine grained point density.\nInstead, we fully utilized our structure's characteristics and proposed a\nhybrid estimation algorithm in providing fast and exact results.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:46:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17675","submitter":"Chao Chen Ye","authors":"Chao Chen Ye, W. L. Vleeshouwers, S. Heatley, V. Gritsev, C. Morais\n  Smith","title":"Quantum Geometry of Non-Hermitian Topological Systems","comments":"v2 has added a change in the acknowledgment","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cond-mat.other","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Topological insulators have been studied intensively over the last decades.\nEarlier research focused on Hermitian Hamiltonians, but recently, peculiar and\ninteresting properties were found by introducing non-Hermiticity. In this work,\nwe apply a quantum geometric approach to various Hermitian and non-Hermitian\nversions of the Su-Schrieffer-Heeger (SSH) model. We find that this method\nallows one to correctly identify different topological phases and topological\nphase transitions for all SSH models, but only when using the metric tensor\ncontaining both left and right eigenvectors. Whereas the quantum geometry of\nHermitian systems is Riemannian, introducing non-Hermiticity leads to\npseudo-Riemannian and complex geometries, thus significantly generalizing from\nthe quantum geometries studied thus far. One remarkable example of this is the\nmathematical agreement between topological phase transition curves and\nlightlike paths in general relativity, suggesting a possibility of simulating\nspace-times in non-Hermitian systems. We find that the metric in non-Hermitian\nphases degenerates in such a way that it effectively reduces the dimensionality\nof the quantum geometry by one. This implies that within linear response\ntheory, one can perturb the system by a particular change of parameters while\nmaintaining a zero excitation rate.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:48:40 GMT"},{"version":"v2","created":"Tue, 30 May 2023 09:01:16 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17676","submitter":"Wenbin Lin","authors":"Jie Li, Bo Yang, Wenbin Lin","title":"Massive white dwarfs in Rastall-Rainbow gravity","comments":"13 pages,5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the hydrostatic equilibrium of white dwarfs within the\nframework of Rastall-Rainbow gravity, aiming to explore the effects of this\nmodified gravitational theory on their properties. By employing the\nChandrasekhar equation of state in conjunction with the modified\nTolman-Oppenheimer-Volkoff equation, we derive the mass-radius relations for\nwhite dwarfs. Our results show that the maximum mass of white dwarfs deviates\nsignificantly from the predictions of general relativity, potentially exceeding\nthe Chandrasekhar limit. Furthermore, we discuss other properties of white\ndwarfs, such as the gravitational redshift, compactness and dynamical\nstability, shedding light on their behavior within the context of this modified\ngravitational framework.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:51:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17677","submitter":"Wanxin Li","authors":"Collin Meese, Hang Chen, Syed Ali Asif, Wanxin Li, Chien-Chung Shen,\n  Mark Nejad","title":"BFRT: Blockchained Federated Learning for Real-time Traffic Flow\n  Prediction","comments":"Published in 2022 22nd IEEE International Symposium on Cluster, Cloud\n  and Internet Computing (CCGrid)","journal-ref":null,"doi":"10.1109/CCGrid54584.2022.00041","report-no":null,"categories":"cs.DC cs.CR cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accurate real-time traffic flow prediction can be leveraged to relieve\ntraffic congestion and associated negative impacts. The existing centralized\ndeep learning methodologies have demonstrated high prediction accuracy, but\nsuffer from privacy concerns due to the sensitive nature of transportation\ndata. Moreover, the emerging literature on traffic prediction by distributed\nlearning approaches, including federated learning, primarily focuses on offline\nlearning. This paper proposes BFRT, a blockchained federated learning\narchitecture for online traffic flow prediction using real-time data and edge\ncomputing. The proposed approach provides privacy for the underlying data,\nwhile enabling decentralized model training in real-time at the Internet of\nVehicles edge. We federate GRU and LSTM models and conduct extensive\nexperiments with dynamically collected arterial traffic data shards. We\nprototype the proposed permissioned blockchain network on Hyperledger Fabric\nand perform extensive tests using virtual machines to simulate the edge nodes.\nExperimental results outperform the centralized models, highlighting the\nfeasibility of our approach for facilitating privacy-preserving and\ndecentralized real-time traffic flow prediction.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:54:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17678","submitter":"Ming Shan Hee","authors":"Ming Shan Hee, Wen-Haw Chong and Roy Ka-Wei Lee","title":"Decoding the Underlying Meaning of Multimodal Hateful Memes","comments":"9 pages. Accepted by IJCAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent studies have proposed models that yielded promising performance for\nthe hateful meme classification task. Nevertheless, these proposed models do\nnot generate interpretable explanations that uncover the underlying meaning and\nsupport the classification output. A major reason for the lack of explainable\nhateful meme methods is the absence of a hateful meme dataset that contains\nground truth explanations for benchmarking or training. Intuitively, having\nsuch explanations can educate and assist content moderators in interpreting and\nremoving flagged hateful memes. This paper address this research gap by\nintroducing Hateful meme with Reasons Dataset (HatReD), which is a new\nmultimodal hateful meme dataset annotated with the underlying hateful\ncontextual reasons. We also define a new conditional generation task that aims\nto automatically generate underlying reasons to explain hateful memes and\nestablish the baseline performance of state-of-the-art pre-trained language\nmodels on this task. We further demonstrate the usefulness of HatReD by\nanalyzing the challenges of the new conditional generation task in explaining\nmemes in seen and unseen domains. The dataset and benchmark models are made\navailable here: https://github.com/Social-AI-Studio/HatRed\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:02:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17679","submitter":"Nicolay Rusnachenko","authors":"Anton Golubev, Nicolay Rusnachenko, Natalia Loukachevitch","title":"RuSentNE-2023: Evaluating Entity-Oriented Sentiment Analysis on Russian\n  News Texts","comments":"12 pages, 5 tables, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The paper describes the RuSentNE-2023 evaluation devoted to targeted\nsentiment analysis in Russian news texts. The task is to predict sentiment\ntowards a named entity in a single sentence. The dataset for RuSentNE-2023\nevaluation is based on the Russian news corpus RuSentNE having rich\nsentiment-related annotation. The corpus is annotated with named entities and\nsentiments towards these entities, along with related effects and emotional\nstates. The evaluation was organized using the CodaLab competition framework.\nThe main evaluation measure was macro-averaged measure of positive and negative\nclasses. The best results achieved were of 66% Macro F-measure\n(Positive+Negative classes). We also tested ChatGPT on the test set from our\nevaluation and found that the zero-shot answers provided by ChatGPT reached 60%\nof the F-measure, which corresponds to 4th place in the evaluation. ChatGPT\nalso provided detailed explanations of its conclusion. This can be considered\nas quite high for zero-shot application.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:04:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17680","submitter":"Han Wang","authors":"Han Wang, Ming Shan Hee, Md Rabiul Awal, Kenny Tsu Wei Choo, Roy\n  Ka-Wei Lee","title":"Evaluating GPT-3 Generated Explanations for Hateful Content Moderation","comments":"9 pages, 2 figures, Accepted by International Joint Conference on\n  Artificial Intelligence(IJCAI)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research has focused on using large language models (LLMs) to generate\nexplanations for hate speech through fine-tuning or prompting. Despite the\ngrowing interest in this area, these generated explanations' effectiveness and\npotential limitations remain poorly understood. A key concern is that these\nexplanations, generated by LLMs, may lead to erroneous judgments about the\nnature of flagged content by both users and content moderators. For instance,\nan LLM-generated explanation might inaccurately convince a content moderator\nthat a benign piece of content is hateful. In light of this, we propose an\nanalytical framework for examining hate speech explanations and conducted an\nextensive survey on evaluating such explanations. Specifically, we prompted\nGPT-3 to generate explanations for both hateful and non-hateful content, and a\nsurvey was conducted with 2,400 unique respondents to evaluate the generated\nexplanations. Our findings reveal that (1) human evaluators rated the\nGPT-generated explanations as high quality in terms of linguistic fluency,\ninformativeness, persuasiveness, and logical soundness, (2) the persuasive\nnature of these explanations, however, varied depending on the prompting\nstrategy employed, and (3) this persuasiveness may result in incorrect\njudgments about the hatefulness of the content. Our study underscores the need\nfor caution in applying LLM-generated explanations for content moderation. Code\nand results are available at https://github.com/Social-AI-Studio/GPT3-HateEval.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:05:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17681","submitter":"Wanxin Li","authors":"Hao Guo, Wanxin Li, Mark Nejad","title":"A Hierarchical and Location-aware Consensus Protocol for IoT-Blockchain\n  Applications","comments":"Published in IEEE Transactions on Network and Service Management (\n  Volume: 19, Issue: 3, September 2022). arXiv admin note: text overlap with\n  arXiv:2305.16962","journal-ref":null,"doi":"10.1109/TNSM.2022.3176607","report-no":null,"categories":"cs.CR cs.DC cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Blockchain-based IoT systems can manage IoT devices and achieve a high level\nof data integrity, security, and provenance. However, incorporating existing\nconsensus protocols in many IoT systems limits scalability and leads to high\ncomputational cost and consensus latency. In addition, location-centric\ncharacteristics of many IoT applications paired with limited storage and\ncomputing power of IoT devices bring about more limitations, primarily due to\nthe location-agnostic designs in blockchains. We propose a hierarchical and\nlocation-aware consensus protocol (LH-Raft) for IoT-blockchain applications\ninspired by the original Raft protocol to address these limitations. The\nproposed LH-Raft protocol forms local consensus candidate groups based on\nnodes' reputation and distance to elect the leaders in each sub-layer\nblockchain. It utilizes a threshold signature scheme to reach global consensus\nand the local and global log replication to maintain consistency for blockchain\ntransactions. To evaluate the performance of LH-Raft, we first conduct an\nextensive numerical analysis based on the proposed reputation mechanism and the\ncandidate group formation model. We then compare the performance of LH-Raft\nagainst the classical Raft protocol from both theoretical and experimental\nperspectives. We evaluate the proposed threshold signature scheme using\nHyperledger Ursa cryptography library to measure various consensus nodes'\nsigning and verification time. Experimental results show that the proposed\nLH-Raft protocol is scalable for large IoT applications and significantly\nreduces the communication cost, consensus latency, and agreement time for\nconsensus processing.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:12:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17682","submitter":"Guangtao Zeng","authors":"Guangtao Zeng, Peiyuan Zhang, Wei Lu","title":"One Network, Many Masks: Towards More Parameter-Efficient Transfer\n  Learning","comments":"Accepted by ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fine-tuning pre-trained language models for multiple tasks tends to be\nexpensive in terms of storage. To mitigate this, parameter-efficient transfer\nlearning (PETL) methods have been proposed to address this issue, but they\nstill require a significant number of parameters and storage when being applied\nto broader ranges of tasks. To achieve even greater storage reduction, we\npropose PROPETL, a novel method that enables efficient sharing of a single PETL\nmodule which we call prototype network (e.g., adapter, LoRA, and prefix-tuning)\nacross layers and tasks. We then learn binary masks to select different\nsub-networks from the shared prototype network and apply them as PETL modules\ninto different layers. We find that the binary masks can determine crucial\ninformation from the network, which is often ignored in previous studies. Our\nwork can also be seen as a type of pruning method, where we find that\noverparameterization also exists in the seemingly small PETL modules. We\nevaluate PROPETL on various downstream tasks and show that it can outperform\nother PETL methods with approximately 10% of the parameter storage required by\nthe latter.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:27:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17683","submitter":"Rok Cestnik","authors":"Rok Cestnik and Erik A. Martens","title":"Integrability of a globally coupled complex Riccati array: quadratic\n  integrate-and-fire neurons, phase oscillators and all in between","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.AO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present an exact dimensionality reduction for dynamics of an arbitrary\narray of globally coupled complex-valued Riccati equations. It generalizes the\nWatanabe-Strogatz theory [Phys. Rev. Lett. 70, 2391 (1993)] for sinusoidally\ncoupled phase oscillators and seamlessly includes quadratic integrate-and-fire\nneurons represented by the special case of real-valued Riccati equations. It\nprovides a low dimensional description to a wide new class of complex dynamical\nsystems, warranting their rigorous analysis and thus providing deep insights\ninto their collective dynamics. This result represents a significant\nadvancement in our comprehending of coupled oscillatory systems and opens up\nmany new avenues of research.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:35:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17684","submitter":"Shinichiro Yamano","authors":"Shinichiro Yamano, Takaya Matsuura, Yui Kuramochi, Toshihiko Sasaki,\n  Masato Koashi","title":"General treatment of Gaussian trusted noise in continuous variable\n  quantum key distribution","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Continuous Variable (CV) quantum key distribution (QKD) is a promising\ncandidate for practical implementations due to its compatibility with the\nexisting communication technology. A trusted device scenario assuming that an\nadversary has no access to imperfections such as electronic noises in the\ndetector is expected to provide significant improvement in the key rate, but\nsuch an endeavor so far was made separately for specific protocols and for\nspecific proof techniques. Here, we develop a simple and general treatment that\ncan incorporate the effects of Gaussian trusted noises for any protocol that\nuses homodyne/heterodyne measurements. In our method, a rescaling of the\noutcome of a noisy homodyne/heterodyne detector renders it equivalent to the\noutcome of a noiseless detector with a tiny additional loss, thanks to a\nnoise-loss equivalence well-known in quantum optics. Since this method is\nindependent of protocols and security proofs, it is applicable to\nGaussian-modulation and discrete-modulation protocols, to the finite-size\nregime, and to any proof techniques developed so far and yet to be discovered\nas well.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:38:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17685","submitter":"Daisuke Sagaki","authors":"Toshiaki Maeno, Satoshi Naito, and Daisuke Sagaki","title":"A presentation of the torus-equivariant quantum $K$-theory ring of flag\n  manifolds of type $A$, Part II: quantum double Grothendieck polynomials","comments":"arXiv admin note: text overlap with arXiv:2302.09485","journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA math.AG math.CO math.KT math.RT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In our previous paper, we gave a presentation of the torus-equivariant\nquantum $K$-theory ring $QK_{H}(Fl_{n+1})$ of the (full) flag manifold\n$Fl_{n+1}$ of type $A_{n}$ as a quotient of a polynomial ring by an explicit\nideal. In this paper, we prove that quantum double Grothendieck polynomials,\nintroduced by Lenart-Maeno, represent the corresponding (opposite) Schubert\nclasses in the quantum $K$-theory ring $QK_{H}(Fl_{n+1})$ under this\npresentation. The main ingredient in our proof is an explicit formula\nexpressing the semi-infinite Schubert class associated to the longest element\nof the finite Weyl group, which is proved by making use of the general\nChevalley formula for the torus-equivariant $K$-group of the semi-infinite flag\nmanifold associated to $SL_{n+1}(\\mathbb{C})$.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:41:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17686","submitter":"Zihao Chen","authors":"Zi-Hao Chen and YiJing Yan","title":"Kondo regime of the impurity spectral function and the current noise\n  spectrum in the double impurity Anderson model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The dissipaton equations of motion (DEOM) method is one of the most popular\nmethods for simulating quantum impurity systems. In this article, we use DOEM\ntheory to deal with the Kondo problem of the double quantum dots (DQDs)\nimpurity system. We focus on the impurity spectral function and the total noise\nspectral function, this two function will be used to describe the Kondo effect\nof this system. The influence of the interaction, the hooping and the\ndifference of the chemical potential between the two dots on the Kondo effect\nof the system is studied. We find that the interaction between the two dots can\ninfluence the Kondo effect of the system a lot.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:44:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17687","submitter":"Wanzhou Zhang","authors":"Nan Wu, Zhuohan Li and Wanzhou Zhang","title":"Unsupervised machine learning for identifying phase transition using\n  two-times clustering","comments":"8 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.dis-nn","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  In recent years, developing unsupervised machine learning for identifying\nphase transition is a research direction. In this paper, we introduce a\ntwo-times clustering method that can help select perfect configurations from a\nset of degenerate samples and assign the configuration with labels in a manner\nof unsupervised machine learning. These perfect configurations can then be used\nto train a neural network to classify phases. The derivatives of the predicted\nclassification in the phase diagram, show peaks at the phase transition points.\nThe effectiveness of our method is tested for the Ising, Potts, and Blume-Capel\nmodels. By using the ordered configuration from two-times clustering, our\nmethod can provide a useful way to obtain phase diagrams.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:47:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17688","submitter":"Zhanhao Hu","authors":"Zhanhao Hu, Jun Zhu, Bo Zhang, Xiaolin Hu","title":"Amplification trojan network: Attack deep neural networks by amplifying\n  their inherent weakness","comments":"Published Sep 2022 in Neurocomputing","journal-ref":null,"doi":"10.1016/j.neucom.2022.07.018","report-no":null,"categories":"cs.CR cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent works found that deep neural networks (DNNs) can be fooled by\nadversarial examples, which are crafted by adding adversarial noise on clean\ninputs. The accuracy of DNNs on adversarial examples will decrease as the\nmagnitude of the adversarial noise increase. In this study, we show that DNNs\ncan be also fooled when the noise is very small under certain circumstances.\nThis new type of attack is called Amplification Trojan Attack (ATAttack).\nSpecifically, we use a trojan network to transform the inputs before sending\nthem to the target DNN. This trojan network serves as an amplifier to amplify\nthe inherent weakness of the target DNN. The target DNN, which is infected by\nthe trojan network, performs normally on clean data while being more vulnerable\nto adversarial examples. Since it only transforms the inputs, the trojan\nnetwork can hide in DNN-based pipelines, e.g. by infecting the pre-processing\nprocedure of the inputs before sending them to the DNNs. This new type of\nthreat should be considered in developing safe DNNs.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:53:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17689","submitter":"Wen-Han Dong","authors":"Wen-Han Dong, Jinbo Pan, Jia-Tao Sun and Shixuan Du","title":"Hybrid nodal surface and nodal line phonons in solids","comments":"23+35 pages, 5+44 figures, 1+3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Phonons have provided an ideal platform for a variety of intriguing physical\nstates, such as non-abelian braiding and Haldane model. It is promising that\nphonons will realize the complicated nodal states accompanying with unusual\nquantum phenomena. Here, we propose the hybrid nodal surface and nodal line\n(NS+NL) phonons beyond the single genre nodal phonons. We categorize the NS+NL\nphonons into two-band and four-band situations based on symmetry analysis and\ncompatibility relationships. Combing database screening with first-principles\ncalculations, we identify the ideal candidate materials for realizing all\ncategorized NS+NL phonons. Our calculations and tight-binding models further\ndemonstrate that the interplay between NS and NL induces unique phenomena. In\nspace group 113, the quadratic NL acts as a hub of the Berry curvature between\ntwo NSs, generating ribbon-like surface states. In space group 128, the NS\nserve as counterpart of Weyl NL that NS-NL mixed topological surface states are\nobserved. Our findings extend the scope of hybrid nodal states and enrich the\nphononic states in realistic materials.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:53:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17690","submitter":"Shantipriya Parida","authors":"Shantipriya Parida, Idris Abdulmumin, Shamsuddeen Hassan Muhammad,\n  Aneesh Bose, Guneet Singh Kohli, Ibrahim Said Ahmad, Ketan Kotwal, Sayan Deb\n  Sarkar, Ond\\v{r}ej Bojar, Habeebah Adamu Kakudi","title":"HaVQA: A Dataset for Visual Question Answering and Multimodal Research\n  in Hausa Language","comments":"Accepted at ACL 2023 as a long paper (Findings)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper presents HaVQA, the first multimodal dataset for visual\nquestion-answering (VQA) tasks in the Hausa language. The dataset was created\nby manually translating 6,022 English question-answer pairs, which are\nassociated with 1,555 unique images from the Visual Genome dataset. As a\nresult, the dataset provides 12,044 gold standard English-Hausa parallel\nsentences that were translated in a fashion that guarantees their semantic\nmatch with the corresponding visual information. We conducted several baseline\nexperiments on the dataset, including visual question answering, visual\nquestion elicitation, text-only and multimodal machine translation.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:55:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17691","submitter":"Zhengyan Zhang","authors":"Zhengyan Zhang, Zhiyuan Zeng, Yankai Lin, Huadong Wang, Deming Ye,\n  Chaojun Xiao, Xu Han, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou","title":"Plug-and-Play Knowledge Injection for Pre-trained Language Models","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Injecting external knowledge can improve the performance of pre-trained\nlanguage models (PLMs) on various downstream NLP tasks. However, massive\nretraining is required to deploy new knowledge injection methods or knowledge\nbases for downstream tasks. In this work, we are the first to study how to\nimprove the flexibility and efficiency of knowledge injection by reusing\nexisting downstream models. To this end, we explore a new paradigm\nplug-and-play knowledge injection, where knowledge bases are injected into\nfrozen existing downstream models by a knowledge plugin. Correspondingly, we\npropose a plug-and-play injection method map-tuning, which trains a mapping of\nknowledge embeddings to enrich model inputs with mapped embeddings while\nkeeping model parameters frozen. Experimental results on three knowledge-driven\nNLP tasks show that existing injection methods are not suitable for the new\nparadigm, while map-tuning effectively improves the performance of downstream\nmodels. Moreover, we show that a frozen downstream model can be well adapted to\ndifferent domains with different mapping networks of domain knowledge. Our code\nand models are available at https://github.com/THUNLP/Knowledge-Plugin.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:58:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17692","submitter":"Uzi Pereg","authors":"Uzi Pereg","title":"Communication Over Entanglement-Breaking Channels With Unreliable\n  Entanglement Assistance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Entanglement assistance can improve communication rates significantly. Yet,\nits generation can easily fail. The recently-introduced model of unreliable\nassistance accounts for those challenges. Previous work provided an asymptotic\nformula for the tradeoff between the unassisted and excess rates from\nentanglement assistance. We derive a full characterization for\nentanglement-breaking channels, and show that combining entanglement-assisted\nand unassisted coding is suboptimal. From a networking perspective, this\nfinding is nontrivial and highlights a quantum behavior arising from\nsuperposition.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:10:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17693","submitter":"Andrei Dumitrasc","authors":"Andrei Dumitrasc, Carola Kruse, and Ulrich Ruede","title":"Deflation for the off-diagonal block in symmetric saddle point systems","comments":"26 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Deflation techniques are typically used to shift isolated clusters of small\neigenvalues in order to obtain a tighter distribution and a smaller condition\nnumber. Such changes induce a positive effect in the convergence behavior of\nKrylov subspace methods, which are among the most popular iterative solvers for\nlarge sparse linear systems. We develop a deflation strategy for symmetric\nsaddle point matrices by taking advantage of their underlying block structure.\nThe vectors used for deflation come from an elliptic singular value\ndecomposition relying on the generalized Golub-Kahan bidiagonalization process.\nThe block targeted by deflation is the off-diagonal one since it features a\nproblematic singular value distribution for certain applications. One example\nis the Stokes flow in elongated channels, where the off-diagonal block has\nseveral small, isolated singular values, depending on the length of the\nchannel. Applying deflation to specific parts of the saddle point system is\nimportant when using solvers such as CRAIG, which operates on individual blocks\nrather than the whole system. The theory is developed by extending the existing\nframework for deflating square matrices before applying a Krylov subspace\nmethod like MINRES. Numerical experiments confirm the merits of our strategy\nand lead to interesting questions about using approximate vectors for\ndeflation.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:17:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17694","submitter":"Sabin Roman","authors":"Sabin Roman","title":"Geometric considerations on planetary surface temperatures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ao-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a formula for computing the average planetary surface temperatures\nbased solely on the solar irradiance and the bond albedo. The formula is\nempirically derived from data on Earth, Venus and Titan, and a model is\nproposed to justify it. We introduce the concept of planetary inner albedo, as\na complement to the usual bond albedo. A geometric proof is given for the main\nfinding of the paper, which can be summarized as follows: the ratio of the\ninner to outer albedo is a universal constant, related to the parabolic\nconstant. Furthermore, we extend the surface temperature formula to gas giants,\ngiving the temperature at which condensates (e.g., of ammonia) start forming\nwithing their atmosphere, particularly for Jupiter and Saturn.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:20:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17695","submitter":"Ori Nizan Mr","authors":"Ori Nizan, Ayellet Tal","title":"k-NNN: Nearest Neighbors of Neighbors for Anomaly Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Anomaly detection aims at identifying images that deviate significantly from\nthe norm. We focus on algorithms that embed the normal training examples in\nspace and when given a test image, detect anomalies based on the features\ndistance to the k-nearest training neighbors. We propose a new operator that\ntakes into account the varying structure & importance of the features in the\nembedding space. Interestingly, this is done by taking into account not only\nthe nearest neighbors, but also the neighbors of these neighbors (k-NNN). We\nshow that by simply replacing the nearest neighbor component in existing\nalgorithms by our k-NNN operator, while leaving the rest of the algorithms\nuntouched, each algorithms own results are improved. This is the case both for\ncommon homogeneous datasets, such as flowers or nuts of a specific type, as\nwell as for more diverse datasets\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:39:51 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17696","submitter":"Hwaran Lee","authors":"Hwaran Lee, Seokhee Hong, Joonsuk Park, Takyoung Kim, Meeyoung Cha,\n  Yejin Choi, Byoung Pil Kim, Gunhee Kim, Eun-Ju Lee, Yong Lim, Alice Oh,\n  Sangchul Park and Jung-Woo Ha","title":"SQuARe: A Large-Scale Dataset of Sensitive Questions and Acceptable\n  Responses Created Through Human-Machine Collaboration","comments":"19 pages, 10 figures, ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The potential social harms that large language models pose, such as\ngenerating offensive content and reinforcing biases, are steeply rising.\nExisting works focus on coping with this concern while interacting with\nill-intentioned users, such as those who explicitly make hate speech or elicit\nharmful responses. However, discussions on sensitive issues can become toxic\neven if the users are well-intentioned. For safer models in such scenarios, we\npresent the Sensitive Questions and Acceptable Response (SQuARe) dataset, a\nlarge-scale Korean dataset of 49k sensitive questions with 42k acceptable and\n46k non-acceptable responses. The dataset was constructed leveraging HyperCLOVA\nin a human-in-the-loop manner based on real news headlines. Experiments show\nthat acceptable response generation significantly improves for HyperCLOVA and\nGPT-3, demonstrating the efficacy of this dataset.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:51:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17697","submitter":"Robin Janik Sroka","authors":"Benjamin Br\\\"uck, Robin J. Sroka","title":"Apartment classes of integral symplectic groups","comments":"16 pages. Comments welcome!","journal-ref":null,"doi":null,"report-no":"CPH-GEOTOP-DNRF151","categories":"math.AT math.GR math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this note we present an alternative proof of a theorem of Gunnells, which\nstates that the Steinberg module of $\\operatorname{Sp_{2n}}(\\mathbb{Q})$ is a\ncyclic $\\operatorname{Sp_{2n}}(\\mathbb{Z})$-module, generated by integral\napartment classes.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:51:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17698","submitter":"Lei Li","authors":"Lei Li, Kai Fan, Lingyu Yang, Hongjia Li, Chun Yuan","title":"Neural Machine Translation with Dynamic Graph Convolutional Decoder","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing wisdom demonstrates the significance of syntactic knowledge for the\nimprovement of neural machine translation models. However, most previous works\nmerely focus on leveraging the source syntax in the well-known encoder-decoder\nframework. In sharp contrast, this paper proposes an end-to-end translation\narchitecture from the (graph \\& sequence) structural inputs to the (graph \\&\nsequence) outputs, where the target translation and its corresponding syntactic\ngraph are jointly modeled and generated. We propose a customized Dynamic\nSpatial-Temporal Graph Convolutional Decoder (Dyn-STGCD), which is designed for\nconsuming source feature representations and their syntactic graph, and\nauto-regressively generating the target syntactic graph and tokens\nsimultaneously. We conduct extensive experiments on five widely acknowledged\ntranslation benchmarks, verifying that our proposal achieves consistent\nimprovements over baselines and other syntax-aware variants.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:58:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17699","submitter":"Yutao Mou","authors":"Yutao Mou, Xiaoshuai Song, Keqing He, Chen Zeng, Pei Wang, Jingang\n  Wang, Yunsen Xian and Weiran Xu","title":"Decoupling Pseudo Label Disambiguation and Representation Learning for\n  Generalized Intent Discovery","comments":"Accepted at ACL2023 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generalized intent discovery aims to extend a closed-set in-domain intent\nclassifier to an open-world intent set including in-domain and out-of-domain\nintents. The key challenges lie in pseudo label disambiguation and\nrepresentation learning. Previous methods suffer from a coupling of pseudo\nlabel disambiguation and representation learning, that is, the reliability of\npseudo labels relies on representation learning, and representation learning is\nrestricted by pseudo labels in turn. In this paper, we propose a decoupled\nprototype learning framework (DPL) to decouple pseudo label disambiguation and\nrepresentation learning. Specifically, we firstly introduce prototypical\ncontrastive representation learning (PCL) to get discriminative\nrepresentations. And then we adopt a prototype-based label disambiguation\nmethod (PLD) to obtain pseudo labels. We theoretically prove that PCL and PLD\nwork in a collaborative fashion and facilitate pseudo label disambiguation.\nExperiments and analysis on three benchmark datasets show the effectiveness of\nour method.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:01:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17700","submitter":"James Hepworth","authors":"James H Hepworth, Hendrik D Mouton","title":"Systems Development of a Two-Axis Stabilised Platform to Facilitate\n  Astronomical Observations from a Moving Base","comments":"2019 Southern African Universities Power Engineering\n  Conference/Robotics and Mechatronics/Pattern Recognition Association of South\n  Africa (SAUPEC/RobMech/PRASA)","journal-ref":null,"doi":"10.1109/RoboMech.2019.8704853","report-no":null,"categories":"eess.SY astro-ph.IM cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This project aimed to design, simulate, and implement a two-axis inertially\nstabilised platform (ISP) for use in astronomical applications. It aimed to\napproximate the stabilisation of a Meade ETX-90 3.5\" compound telescope at\nlow-cost using a mechanical assembly designed to geometrically and inertially\nmodel the telescope. A set of system specifications was developed to guide\ndesign decisions and to provide an analysis framework against which the\nperformance of the implemented system was compared. The electro-mechanical\nstructure of the ISP was designed and manufactured, the associated electrical\nsystems were specified and configured, an image processing script capable of\ndetecting and locating the centre of the Moon in a camera field-of-view was\nwritten, a complete simulation model for the system was developed and used to\ndesign various classical controllers for the ISP control system. These\ncontrollers were implemented on a STM32F051 microcontroller and a user\ninterface was written in LabVIEW to facilitate intuitive user control of the\nsystem and perform datalogging of the system runtime data.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:04:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17701","submitter":"Hwaran Lee","authors":"Hwaran Lee, Seokhee Hong, Joonsuk Park, Takyoung Kim, Gunhee Kim and\n  Jung-Woo Ha","title":"KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large\n  Language Model Application","comments":"17 pages, 8 figures, 12 tables, ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) learn not only natural text generation abilities\nbut also social biases against different demographic groups from real-world\ndata. This poses a critical risk when deploying LLM-based applications.\nExisting research and resources are not readily applicable in South Korea due\nto the differences in language and culture, both of which significantly affect\nthe biases and targeted demographic groups. This limitation requires localized\nsocial bias datasets to ensure the safe and effective deployment of LLMs. To\nthis end, we present KO SB I, a new social bias dataset of 34k pairs of\ncontexts and sentences in Korean covering 72 demographic groups in 15\ncategories. We find that through filtering-based moderation, social biases in\ngenerated content can be reduced by 16.47%p on average for HyperCLOVA (30B and\n82B), and GPT-3.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:07:16 GMT"},{"version":"v2","created":"Tue, 30 May 2023 01:42:07 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17702","submitter":"Indrakshi Dey","authors":"Indrakshi Dey and Nicola Marchetti","title":"IoT Localization and Optimized Topology Extraction Using Eigenvector\n  Synchronization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Internet-of-Things (IoT) devices are low size, weight and power (SWaP), low\ncomplexity and include sensors, meters, wearables and trackers. Transmitting\ninformation with high signal power is exacting on device battery life,\ntherefore an efficient link and network configuration is absolutely crucial to\navoid signal power enhancement in interference-rich environment and resorting\nto battery-life extending strategies. Efficient network configuration can also\nensure fulfilment of network performance metrics like throughput, coding rate\nand spectral efficiency. We formulate a novel approach of first localizing the\nIoT nodes and then extracting the network topology for information exchange\nbetween the nodes (devices, gateway and sinks), such that overall network\nthroughput is maximized. The nodes are localized using noisy measurements of a\nsubset of Euclidean distances between two nodes. Realizable subsets of\nneighboring devices agree with their own position within the entire network\ngraph through eigenvector synchronization. Using communication global\ngraph-model-based technique, network topology is constructed in terms of\ntransmit power allocation with the aim of maximizing spatial usage and overall\nnetwork throughput. This topology extraction problem is solved using the\nconcept of linear programming.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:15:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17703","submitter":"Adam Foster Prof","authors":"Shigeki Kawai, Orlando J. Silveira, Lauri Kurki, Zhangyu Yuan,\n  Tomohiko Nishiuchi, Takuya Kodama, Kewei Sun, Oscar Custance, Jose L. Lado,\n  Takashi Kubo and Adam S. Foster","title":"Local Probe Isomerization in a One-Dimensional Molecular Array","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Synthesis of one-dimensional molecular arrays with tailored stereoisomers is\nchallenging yet has a great potential for application in molecular opto-,\nelectronic- and magnetic-devices, where the local array structure plays a\ndecisive role in the functional properties. Here, we demonstrate construction\nand characterization of dehydroazulene isomer and diradical units in\nthree-dimensional organometallic compounds on Ag(111) with a combination of\nlow-temperature scanning tunneling microscopy and density functional theory\ncalculations. Tip-induced voltage pulses firstly result in the formation of a\ndiradical species via successive homolytic fission of two C-Br bonds in the\nnaphthyl groups, which are subsequently transformed into chiral dehydroazulene\nmoieties. The delicate balance of the reaction rates among the diradical and\ntwo stereoisomers, arising from an in-line configuration of tip and molecular\nunit, allows directional azulene-to-azulene and azulene-to-diradical local\nprobe isomerization in a controlled manner. Furthermore, we found that the\ndiradical moiety hosts an open-shell singlet with antiferromagnetic coupling\nbetween the unpaired electrons, which can undergo an inelastic spin transition\nof 91 meV to the ferromagnetically coupled triplet state.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:23:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17704","submitter":"Hyeokjun Kwon","authors":"Hyeokjun Kwon, Sung Joon Maeng, and Ismail Guvenc","title":"RF SSSL by an Autonomous UAV with Two-Ray Channel Model and Dipole\n  Antenna Patterns","comments":"7 Pages, submitted to 2023 PIMRC","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Advancements in unmanned aerial vehicle (UAV) technology have led to their\nincreased utilization in various commercial and military applications. One such\napplication is signal source search and localization (SSSL) using UAVs, which\noffers significant benefits over traditional ground-based methods due to\nimproved RF signal reception at higher altitudes and inherent autonomous 3D\nnavigation capabilities. Nevertheless, practical considerations such as\npropagation models and antenna patterns are frequently neglected in\nsimulation-based studies in the literature. In this work, we address these\nlimitations by using a two-ray channel model and a dipole antenna pattern to\ndevelop a simulator that more closely represents real-world radio signal\nstrength (RSS) observations at a UAV. We then examine and compare the\nperformance of previously proposed linear least square (LLS) based localization\ntechniques using UAVs for SSSL. Localization of radio frequency (RF) signal\nsources is assessed based on two main criteria: 1) achieving the highest\npossible accuracy and 2) localizing the target as quickly as possible with\nreasonable accuracy. Various mission types, such as those requiring precise\nlocalization like identifying hostile troops, and those demanding rapid\nlocalization like search and rescue operations during disasters, have been\npreviously investigated. In this paper, the efficacy of the proposed\nlocalization approaches is examined based on these two main localization\nrequirements through computer simulations.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:23:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17705","submitter":"Areg Karapetyan Dr.","authors":"Eyad Shaklab, Areg Karapetyan, Arjun Sharma, Murad Mebrahtu, Mustofa\n  Basri, Mohamed Nagy, Majid Khonji, and Jorge Dias","title":"Towards Autonomous and Safe Last-mile Deliveries with AI-augmented\n  Self-driving Delivery Robots","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In addition to its crucial impact on customer satisfaction, last-mile\ndelivery (LMD) is notorious for being the most time-consuming and costly stage\nof the shipping process. Pressing environmental concerns combined with the\nrecent surge of e-commerce sales have sparked renewed interest in automation\nand electrification of last-mile logistics. To address the hurdles faced by\nexisting robotic couriers, this paper introduces a customer-centric and\nsafety-conscious LMD system for small urban communities based on AI-assisted\nautonomous delivery robots. The presented framework enables end-to-end\nautomation and optimization of the logistic process while catering for\nreal-world imposed operational uncertainties, clients' preferred time\nschedules, and safety of pedestrians. To this end, the integrated optimization\ncomponent is modeled as a robust variant of the Cumulative Capacitated Vehicle\nRouting Problem with Time Windows, where routes are constructed under uncertain\ntravel times with an objective to minimize the total latency of deliveries\n(i.e., the overall waiting time of customers, which can negatively affect their\nsatisfaction). We demonstrate the proposed LMD system's utility through\nreal-world trials in a university campus with a single robotic courier.\nImplementation aspects as well as the findings and practical insights gained\nfrom the deployment are discussed in detail. Lastly, we round up the\ncontributions with numerical simulations to investigate the scalability of the\ndeveloped mathematical formulation with respect to the number of robotic\nvehicles and customers.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:25:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17706","submitter":"Ying Shi","authors":"Ying Shi, Dong Wang, Lantian Li, Jiqing Han and Shi Yin","title":"Spot keywords from very noisy and mixed speech","comments":"Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.AI eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most existing keyword spotting research focuses on conditions with slight or\nmoderate noise. In this paper, we try to tackle a more challenging task:\ndetecting keywords buried under strong interfering speech (10 times higher than\nthe keyword in amplitude), and even worse, mixed with other keywords. We\npropose a novel Mix Training (MT) strategy that encourages the model to\ndiscover low-energy keywords from noisy and mixed speech. Experiments were\nconducted with a vanilla CNN and two EfficientNet (B0/B2) architectures. The\nresults evaluated with the Google Speech Command dataset demonstrated that the\nproposed mix training approach is highly effective and outperforms standard\ndata augmentation and mixup training.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:26:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17707","submitter":"Ara Ghukasyan","authors":"Ara Ghukasyan and Jack S. Baker and Oktay Goktas and Juan Carrasquilla\n  and Santosh Kumar Radha","title":"Quantum-Classical Multiple Kernel Learning","comments":"15 pages, Supplementary Information on page 15, 6 main figures, 1\n  supplementary figure","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As quantum computers become increasingly practical, so does the prospect of\nusing quantum computation to improve upon traditional algorithms. Kernel\nmethods in machine learning is one area where such improvements could be\nrealized in the near future. Paired with kernel methods like support-vector\nmachines, small and noisy quantum computers can evaluate classically-hard\nquantum kernels that capture unique notions of similarity in data. Taking\ninspiration from techniques in classical machine learning, this work\ninvestigates simulated quantum kernels in the context of multiple kernel\nlearning (MKL). We consider pairwise combinations of several\nclassical-classical, quantum-quantum, and quantum-classical kernels in an\nempirical investigation of their classification performance with support-vector\nmachines. We also introduce a novel approach, which we call QCC-net\n(quantum-classical-convex neural network), for optimizing the weights of base\nkernels together with any kernel parameters. We show this approach to be\neffective for enhancing various performance metrics in an MKL setting. Looking\nat data with an increasing number of features (up to 13 dimensions), we find\nparameter training to be important for successfully weighting kernels in some\ncombinations. Using the optimal kernel weights as indicators of relative\nutility, we find growing contributions from trainable quantum kernels in\nquantum-classical kernel combinations as the number of features increases. We\nobserve the opposite trend for combinations containing simpler, non-parametric\nquantum kernels.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:29:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17708","submitter":"Hao Liu","authors":"Hao Liu, Yanlin Wang, Zhao Wei, Yong Xu, Juhong Wang, Hui Li, Rongrong\n  Ji","title":"RefBERT: A Two-Stage Pre-trained Framework for Automatic Rename\n  Refactoring","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Refactoring is an indispensable practice of improving the quality and\nmaintainability of source code in software evolution. Rename refactoring is the\nmost frequently performed refactoring that suggests a new name for an\nidentifier to enhance readability when the identifier is poorly named. However,\nmost existing works only identify renaming activities between two versions of\nsource code, while few works express concern about how to suggest a new name.\nIn this paper, we study automatic rename refactoring on variable names, which\nis considered more challenging than other rename refactoring activities. We\nfirst point out the connections between rename refactoring and various\nprevalent learning paradigms and the difference between rename refactoring and\ngeneral text generation in natural language processing. Based on our\nobservations, we propose RefBERT, a two-stage pre-trained framework for rename\nrefactoring on variable names. RefBERT first predicts the number of sub-tokens\nin the new name and then generates sub-tokens accordingly. Several techniques,\nincluding constrained masked language modeling, contrastive learning, and the\nbag-of-tokens loss, are incorporated into RefBERT to tailor it for automatic\nrename refactoring on variable names. Through extensive experiments on our\nconstructed refactoring datasets, we show that the generated variable names of\nRefBERT are more accurate and meaningful than those produced by the existing\nmethod.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:29:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17709","submitter":"Gongbo Tang","authors":"Gongbo Tang, Christian Hardmeier","title":"Parallel Data Helps Neural Entity Coreference Resolution","comments":"camera-ready version; to appear in the Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Coreference resolution is the task of finding expressions that refer to the\nsame entity in a text. Coreference models are generally trained on monolingual\nannotated data but annotating coreference is expensive and challenging.\nHardmeier et al.(2013) have shown that parallel data contains latent anaphoric\nknowledge, but it has not been explored in end-to-end neural models yet. In\nthis paper, we propose a simple yet effective model to exploit coreference\nknowledge from parallel data. In addition to the conventional modules learning\ncoreference from annotations, we introduce an unsupervised module to capture\ncross-lingual coreference knowledge. Our proposed cross-lingual model achieves\nconsistent improvements, up to 1.74 percentage points, on the OntoNotes 5.0\nEnglish dataset using 9 different synthetic parallel datasets. These\nexperimental results confirm that parallel data can provide additional\ncoreference knowledge which is beneficial to coreference resolution tasks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:30:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17710","submitter":"Wentao Chao","authors":"Wentao Chao, Fuqing Duan, Xuechun Wang, Yingqian Wang, Guanghui Wang","title":"OccCasNet: Occlusion-aware Cascade Cost Volume for Light Field Depth\n  Estimation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Light field (LF) depth estimation is a crucial task with numerous practical\napplications. However, mainstream methods based on the multi-view stereo (MVS)\nare resource-intensive and time-consuming as they need to construct a finer\ncost volume. To address this issue and achieve a better trade-off between\naccuracy and efficiency, we propose an occlusion-aware cascade cost volume for\nLF depth (disparity) estimation. Our cascaded strategy reduces the sampling\nnumber while keeping the sampling interval constant during the construction of\na finer cost volume. We also introduce occlusion maps to enhance accuracy in\nconstructing the occlusion-aware cost volume. Specifically, we first obtain the\ncoarse disparity map through the coarse disparity estimation network. Then, the\nsub-aperture images (SAIs) of side views are warped to the center view based on\nthe initial disparity map. Next, we propose photo-consistency constraints\nbetween the warped SAIs and the center SAI to generate occlusion maps for each\nSAI. Finally, we introduce the coarse disparity map and occlusion maps to\nconstruct an occlusion-aware refined cost volume, enabling the refined\ndisparity estimation network to yield a more precise disparity map. Extensive\nexperiments demonstrate the effectiveness of our method. Compared with\nstate-of-the-art methods, our method achieves a superior balance between\naccuracy and efficiency and ranks first in terms of MSE and Q25 metrics among\npublished methods on the HCI 4D benchmark. The code and model of the proposed\nmethod are available at https://github.com/chaowentao/OccCasNet.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:31:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17711","submitter":"Christian Rohrbeck","authors":"Christian Rohrbeck and Deborah A Costain","title":"A joint estimation approach for monotonic regression functions in\n  general dimensions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Regression analysis under the assumption of monotonicity is a well-studied\nstatistical problem and has been used in a wide range of applications. However,\nthere remains a lack of a broadly applicable methodology that permits\ninformation borrowing, for efficiency gains, when jointly estimating multiple\nmonotonic regression functions. We introduce such a methodology by extending\nthe isotonic regression problem presented in the article \"The isotonic\nregression problem and its dual\" (Barlow and Brunk, 1972). The presented\napproach can be applied to both fixed and random designs and any number of\nexplanatory variables (regressors). Our framework penalizes pairwise\ndifferences in the values (levels) of the monotonic function estimates, with\nthe weight of penalty being determined based on a statistical test, which\nresults in information being shared across data sets if similarities in the\nregression functions exist. Function estimates are subsequently derived using\nan iterative optimization routine that uses existing solution algorithms for\nthe isotonic regression problem. Simulation studies for normally and binomially\ndistributed response data illustrate that function estimates are consistently\nimproved if similarities between functions exist, and are not oversmoothed\notherwise. We further apply our methodology to analyse two public health data\nsets: neonatal mortality data for Porto Alegre, Brazil, and stroke patient data\nfor North West England.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:32:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17712","submitter":"Cheng-Yang Lee","authors":"Cheng-Yang Lee","title":"Generalized unitary evolution for symplectic scalar fermions","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The theory of symplectic scalar fermion of LeClair and Neubert is studied.\nThe theory evades the conventional spin-statistics theorem because its\nHamiltonian is pseudo Hermitian. Here, we clarify the derivation of the\nsymplectic currents and charges. By demanding the currents and charges to be\npseudo Hermitian, the global symmetry of the free Lagrangian density reduces\nfrom Sp(2,C) to SU(2). By explicit calculations, we show that the\nLeClair-Neubert model of N quartic self-interacting scalar fermions admits\ngeneralized unitary evolution.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:38:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17713","submitter":"Mirko Consiglio","authors":"Mirko Consiglio","title":"Variational Quantum Algorithms for Gibbs State Preparation","comments":"21 pages, 5 figures, submitted to LNCS NUMTA2023 Conference\n  Proceedings. arXiv admin note: substantial text overlap with arXiv:2303.11276","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Preparing the Gibbs state of an interacting quantum many-body system on noisy\nintermediate-scale quantum (NISQ) devices is a crucial task for exploring the\nthermodynamic properties in the quantum regime. It encompasses understanding\nprotocols such as thermalization and out-of-equilibrium thermodynamics, as well\nas sampling from faithfully prepared Gibbs states could pave the way to\nproviding useful resources for quantum algorithms. Variational quantum\nalgorithms (VQAs) show the most promise in efficiently preparing Gibbs states,\nhowever, there are many different approaches that could be applied to\neffectively determine and prepare Gibbs states on a NISQ computer. In this\npaper, we provide a concise overview of the algorithms capable of preparing\nGibbs states, including joint Hamiltonian evolution of a system--environment\ncoupling, quantum imaginary time evolution, and modern VQAs utilizing the\nHelmholtz free energy as a cost function, among others. Furthermore, we perform\na benchmark of one of the latest variational Gibbs state preparation\nalgorithms, developed by Consiglio et al. (arXiv:2303.11276), by applying it to\nthe spin 1/2 one-dimensional $XY$ model.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:47:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17714","submitter":"Amit Moryossef","authors":"Amit Moryossef, Mathias M\\\"uller, Anne G\\\"ohring, Zifan Jiang, Yoav\n  Goldberg, and Sarah Ebling","title":"An Open-Source Gloss-Based Baseline for Spoken to Signed Language\n  Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Sign language translation systems are complex and require many components. As\na result, it is very hard to compare methods across publications. We present an\nopen-source implementation of a text-to-gloss-to-pose-to-video pipeline\napproach, demonstrating conversion from German to Swiss German Sign Language,\nFrench to French Sign Language of Switzerland, and Italian to Italian Sign\nLanguage of Switzerland. We propose three different components for the\ntext-to-gloss translation: a lemmatizer, a rule-based word reordering and\ndropping component, and a neural machine translation system. Gloss-to-pose\nconversion occurs using data from a lexicon for three different signed\nlanguages, with skeletal poses extracted from videos. To generate a sentence,\nthe text-to-gloss system is first run, and the pose representations of the\nresulting signs are stitched together.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:57:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17715","submitter":"Zhuowei Sun","authors":"Zhuowei Sun, Hongyuan Cao, Li Chen and Jason P. Fine","title":"Regression analysis of longitudinal data with mixed synchronous and\n  asynchronous longitudinal covariates","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In linear models, omitting a covariate that is orthogonal to covariates in\nthe model does not result in biased coefficient estimation. This in general\ndoes not hold for longitudinal data, where additional assumptions are needed to\nget unbiased coefficient estimation in addition to the orthogonality between\nomitted longitudinal covariates and longitudinal covariates in the model. We\npropose methods to mitigate the omitted variable bias under weaker assumptions.\nA two-step estimation procedure is proposed for inference about the\nasynchronous longitudinal covariates, when such covariates are observed. For\nmixed synchronous and asynchronous longitudinal covariates, we get parametric\nrate of convergence for the coefficient estimation of the synchronous\nlongitudinal covariates by the two-step method. Extensive simulation studies\nprovide numerical support for the theoretical findings. We illustrate the\nperformance of our method on dataset from the Alzheimers Disease Neuroimaging\nInitiative study.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:57:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17716","submitter":"Haobo Yang","authors":"Haobo Yang, Wenyu Wang, Ze Cao, Zhekai Duan, Xuchen Liu","title":"InDL: A New Dataset and Benchmark for In-Diagram Logic Interpretation\n  based on Visual Illusion","comments":"arXiv admin note: text overlap with arXiv:2305.02299,\n  arXiv:2302.11939, arXiv:2301.13287, arXiv:2305.12686","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper introduces a novel approach to evaluating deep learning models'\ncapacity for in-diagram logic interpretation. Leveraging the intriguing realm\nof visual illusions, we establish a unique dataset, InDL, designed to\nrigorously test and benchmark these models. Deep learning has witnessed\nremarkable progress in domains such as computer vision and natural language\nprocessing. However, models often stumble in tasks requiring logical reasoning\ndue to their inherent 'black box' characteristics, which obscure the\ndecision-making process. Our work presents a new lens to understand these\nmodels better by focusing on their handling of visual illusions -- a complex\ninterplay of perception and logic. We utilize six classic geometric optical\nillusions to create a comparative framework between human and machine visual\nperception. This methodology offers a quantifiable measure to rank models,\nelucidating potential weaknesses and providing actionable insights for model\nimprovements. Our experimental results affirm the efficacy of our benchmarking\nstrategy, demonstrating its ability to effectively rank models based on their\nlogic interpretation ability. As part of our commitment to reproducible\nresearch, the source code and datasets will be made publicly available at\nhttps://github.com/rabbit-magic-wh/InDL\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:01:32 GMT"},{"version":"v2","created":"Tue, 30 May 2023 12:12:15 GMT"},{"version":"v3","created":"Thu, 1 Jun 2023 04:55:10 GMT"},{"version":"v4","created":"Mon, 5 Jun 2023 22:52:57 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.17717","submitter":"Tom Meyerovitch","authors":"Yonatan Gutman, Michael Levin and Tom Meyerovitch","title":"Equivariant embedding of finite-dimensional dynamical systems","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS math.GN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove an equivariant version of the classical Menger-Nobeling theorem.\nWhenever a group $G$ acts on a finite-dimensional compact metric space $X$,\nthere exists an equivariant topological embedding of $X$ to into $([0,1]^d)^G$,\nprovided that for every positive integer $N$ the space of points in $X$ with\norbit size at most $N$ has topological dimension strictly less than\n$\\frac{d}{2}N$. Moreover, under the above assumptions, a generic continuous\nequivariant function from $X$ into $([0,1]^d)^G$ is a topological embedding. We\nemphasize that the result imposes no restrictions whatsoever on the acting\ngroup $G$ (beyond the existence of an action on a finite-dimensional space).\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:15:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17718","submitter":"Noam Rotstein","authors":"Noam Rotstein, David Bensaid, Shaked Brody, Roy Ganz, Ron Kimmel","title":"FuseCap: Leveraging Large Language Models to Fuse Visual Data into\n  Enriched Image Captions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Image captioning is a central task in computer vision which has experienced\nsubstantial progress following the advent of vision-language pre-training\ntechniques. In this paper, we highlight a frequently overlooked limitation of\ncaptioning models that often fail to capture semantically significant elements.\nThis drawback can be traced back to the text-image datasets; while their\ncaptions typically offer a general depiction of image content, they frequently\nomit salient details. To mitigate this limitation, we propose FuseCap - a novel\nmethod for enriching captions with additional visual information, obtained from\nvision experts, such as object detectors, attribute recognizers, and Optical\nCharacter Recognizers (OCR). Our approach fuses the outputs of such vision\nexperts with the original caption using a large language model (LLM), yielding\nenriched captions that present a comprehensive image description. We validate\nthe effectiveness of the proposed caption enrichment method through both\nquantitative and qualitative analysis. Our method is then used to curate the\ntraining set of a captioning model based BLIP which surpasses current\nstate-of-the-art approaches in generating accurate and detailed captions while\nusing significantly fewer parameters and training data. As additional\ncontributions, we provide a dataset comprising of 12M image-enriched caption\npairs and show that the proposed method largely improves image-text retrieval.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:16:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17719","submitter":"Jinhua Liang","authors":"Jinhua Liang, Xubo Liu, Haohe Liu, Huy Phan, Emmanouil Benetos, Mark\n  D. Plumbley, Wenwu Wang","title":"Adapting Language-Audio Models as Few-Shot Audio Learners","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We presented the Treff adapter, a training-efficient adapter for CLAP, to\nboost zero-shot classification performance by making use of a small set of\nlabelled data. Specifically, we designed CALM to retrieve the probability\ndistribution of text-audio clips over classes using a set of audio-label pairs\nand combined it with CLAP's zero-shot classification results. Furthermore, we\ndesigned a training-free version of the Treff adapter by using CALM as a cosine\nsimilarity measure. Experiments showed that the proposed Treff adapter is\ncomparable and even better than fully-supervised methods and adaptation methods\nin low-shot and data-abundant scenarios. While the Treff adapter shows that\ncombining large-scale pretraining and rapid learning of domain-specific\nknowledge is non-trivial for obtaining generic representations for few-shot\nlearning, it is still limited to audio classification tasks. In the future, we\nwill explore how to use audio-language models in diverse audio domains.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:17:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17720","submitter":"Cem Suulker","authors":"Cem Suulker, Sophie Skach, and Kaspar Althoefer","title":"Integrating Elastic Bands to Enhance Performance for Textile Robotics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The elastic bands integrated using the ruffles technique proved to be\neffective in enhancing the performance of the soft robotic structures. In the\nactuator application, the elastic bands greatly increased the bending\ncapability and force capability of the structure, while in the eversion robot\ncap application, the elastic bands improved the performance slightly by\nmaintaining the sensory payload at the tip without restricting the eversion\nprocess. These findings demonstrate the potential of using elastic bands and\ntextile techniques in soft robotics to create more efficient and adaptable\nstructures.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:18:51 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17721","submitter":"Hongqiu Wu","authors":"Hongqiu Wu and Shaohua Zhang and Yuchen Zhang and Hai Zhao","title":"Rethinking Masked Language Modeling for Chinese Spelling Correction","comments":"Accepted by ACL'2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we study Chinese Spelling Correction (CSC) as a joint decision\nmade by two separate models: a language model and an error model. Through\nempirical analysis, we find that fine-tuning BERT tends to over-fit the error\nmodel while under-fit the language model, resulting in poor generalization to\nout-of-distribution error patterns. Given that BERT is the backbone of most CSC\nmodels, this phenomenon has a significant negative impact. To address this\nissue, we are releasing a multi-domain benchmark LEMON, with higher quality and\ndiversity than existing benchmarks, to allow a comprehensive assessment of the\nopen domain generalization of CSC models. Then, we demonstrate that a very\nsimple strategy, randomly masking 20\\% non-error tokens from the input sequence\nduring fine-tuning is sufficient for learning a much better language model\nwithout sacrificing the error model. This technique can be applied to any model\narchitecture and achieves new state-of-the-art results on SIGHAN, ECSpell, and\nLEMON.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:19:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17722","submitter":"Andrei Nikishin","authors":"G. S. Bisnovatyi-Kogan, A. M. Nikishin","title":"Eliminating the Hubble Tension in the Presence of the Interconnection\n  between Dark Energy and Matter in the Modern Universe","comments":null,"journal-ref":"Astronomy Reports, Vol. 67, No. 2 (2023) pp. 115-124","doi":"10.1134/S1063772923020038","report-no":null,"categories":"astro-ph.CO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  It is accepted in modern cosmology that the scalar field responsible for the\ninflationary stage of the early Universe is completely transformed into matter.\nIt is assumed that the accelerated expansion is currently driven by dark energy\n(DE), which is likely determined by Einstein's cosmological constant. We\nconsider a cosmological model where DE can have two components, one of which is\nEinstein's constant ($\\Lambda$) and the other, smaller variable component DEV\n($\\Lambda_V$), is associated with the remnant of the scalar field that caused\ninflation after the main part of the scalar field has turned into matter. It is\nassumed that such a transformation continues at the present time and is\naccompanied by the reverse process of the DM transformation into a scalar\nfield. The interconnection between DM and DEV, which leads to a linear\nrelationship between the energy densities of these components after\nrecombination $\\rho_{DM}=\\alpha\\;\\rho_{DEV}$, is considered. Variants with a\ndependence of the coefficient $\\alpha(z)$ on the redshift are also considered.\nOne of the problems that have arisen in modern cosmology, called Hubble Tension\n(HT), is the discrepancy between the present values of the Hubble constant\nmeasured from observations at small redshifts $z\\lesssim1$ and the values found\nfrom fluctuations of the cosmic microwave background at large redshifts\n$z\\approx1100$. In the considered model, this discrepancy can be explained by\nthe deviation of the real cosmological model from the conventional cold dark\nmatter (CDM) model of the Universe by action of the additional DE component at\nthe stages after recombination. Within this extended model, we consider various\n$\\alpha(z)$ functions that can eliminate the HT. To maintain the ratio of DEV\nand DM energy densities close to constant over the interval $0\\le z\\le1100$, we\nassume the existence of a wide spectrum of DM particle masses.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:27:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17723","submitter":"Subhadip Kumar","authors":"Subhadip Kumar","title":"SAP HANA Data Volume Management","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Today information technology is a data-driven environment. The role of data\nis to empower business leaders to make decisions based on facts, trends, and\nstatistical numbers. SAP is no exception. In modern days many companies use\nbusiness suites like SAP on HANA S/4 or ERP or SAP Business Warehouse and other\nnon-SAP applications and run those on HANA databases for faster processing.\nWhile HANA is an extremely powerful in-memory database, growing business data\nhas an impact on the overall performance and budget of the organization. This\npaper presents best practices to reduce the overall data footprint of HANA\ndatabases for three use cases like SAP Business Suite on HANA, SAP Business\nWarehouse, and Native HANA database.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:42:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17724","submitter":"Sewade Ogun","authors":"Sewade Ogun, Vincent Colotte, Emmanuel Vincent","title":"Stochastic Pitch Prediction Improves the Diversity and Naturalness of\n  Speech in Glow-TTS","comments":"5 pages with 3 figures, InterSpeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Flow-based generative models are widely used in text-to-speech (TTS) systems\nto learn the distribution of audio features (e.g., Mel-spectrograms) given the\ninput tokens and to sample from this distribution to generate diverse\nutterances. However, in the zero-shot multi-speaker TTS scenario, the generated\nutterances lack diversity and naturalness. In this paper, we propose to improve\nthe diversity of utterances by explicitly learning the distribution of\nfundamental frequency sequences (pitch contours) of each speaker during\ntraining using a stochastic flow-based pitch predictor, then conditioning the\nmodel on generated pitch contours during inference. The experimental results\ndemonstrate that the proposed method yields a significant improvement in the\nnaturalness and diversity of speech generated by a Glow-TTS model that uses\nexplicit stochastic pitch prediction, over a Glow-TTS baseline and an improved\nGlow-TTS model that uses a stochastic duration predictor.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:44:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17725","submitter":"Jakub Marecek","authors":"F. V. Difonzo and M. Roubalik and J. Marecek","title":"Predictability and Fairness in Load Aggregation with Deadband","comments":"arXiv admin note: substantial text overlap with arXiv:2110.03001","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.AI cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Virtual power plants and load aggregation are becoming increasingly common.\nThere, one regulates the aggregate power output of an ensemble of distributed\nenergy resources (DERs). Marecek et al. [Automatica, Volume 147, January 2023,\n110743, arXiv:2110.03001] recently suggested that long-term averages of prices\nor incentives offered should exist and be independent of the initial states of\nthe operators of the DER, the aggregator, and the power grid. This can be seen\nas predictability, which underlies fairness. Unfortunately, the existence of\nsuch averages cannot be guaranteed with many traditional regulators, including\nthe proportional-integral (PI) regulator with or without deadband. Here, we\nconsider the effects of losses in the alternating current model and the\ndeadband in the controller. This yields a non-linear dynamical system (due to\nthe non-linear losses) exhibiting discontinuities (due to the deadband). We\nshow that Filippov invariant measures enable reasoning about predictability and\nfairness while considering non-linearity of the alternating-current model and\ndeadband.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:50:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17726","submitter":"Reda Tiani","authors":"Reda Tiani and Uwe C. T\\\"auber","title":"Stochastic analysis of chemical reactions in multi-component interacting\n  systems at criticality","comments":"10 pages, 4 figures, 0 table","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We numerically and analytically investigate the behavior of a non-equilibrium\nphase transition in the second Schl\\\"ogl autocatalytic reaction scheme. Our\nmodel incorporates both an interaction-induced phase separation and a\nbifurcation in the reaction kinetics, with these critical lines coalescing at a\nbicritical point in the macroscopic limit. We construct a stochastic master\nequation for the reaction processes to account for the presence of mutual\nparticle interactions in a thermodynamically consistent manner by imposing a\ngeneralized detailed balance condition, which leads to exponential corrections\nfor the transition rates. In a non-spatially extended (zero-dimensional)\nsetting, we treat the interactions in a mean-field approximation, and introduce\na minimal model that encodes the physical behavior of the bicritical point and\npermits the exact evaluation of the anomalous scaling for the particle number\nfluctuations in the thermodynamic limit. We obtain that the system size scaling\nexponent for the particle number variance changes from $\\beta_0 = 3/2$ at the\nstandard non-interacting bifurcation to $\\beta = 12/7$ at the interacting\nbicritical point. The methodology developed here provides a generic route for\nthe quantitative analysis of fluctuation effects in chemical reactions\noccurring in multi-component interacting systems.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:52:01 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17727","submitter":"Hang Chen","authors":"Hang Chen, Bingyu Liao, Jing Luo, Wenjing Zhu, Xinyu Yang","title":"Learning a Structural Causal Model for Intuition Reasoning in\n  Conversation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reasoning, a crucial aspect of NLP research, has not been adequately\naddressed by prevailing models including Large Language Model. Conversation\nreasoning, as a critical component of it, remains largely unexplored due to the\nabsence of a well-designed cognitive model. In this paper, inspired by\nintuition theory on conversation cognition, we develop a conversation cognitive\nmodel (CCM) that explains how each utterance receives and activates channels of\ninformation recursively. Besides, we algebraically transformed CCM into a\nstructural causal model (SCM) under some mild assumptions, rendering it\ncompatible with various causal discovery methods. We further propose a\nprobabilistic implementation of the SCM for utterance-level relation reasoning.\nBy leveraging variational inference, it explores substitutes for implicit\ncauses, addresses the issue of their unobservability, and reconstructs the\ncausal representations of utterances through the evidence lower bounds.\nMoreover, we constructed synthetic and simulated datasets incorporating\nimplicit causes and complete cause labels, alleviating the current situation\nwhere all available datasets are implicit-causes-agnostic. Extensive\nexperiments demonstrate that our proposed method significantly outperforms\nexisting methods on synthetic, simulated, and real-world datasets. Finally, we\nanalyze the performance of CCM under latent confounders and propose theoretical\nideas for addressing this currently unresolved issue.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:54:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17728","submitter":"Mehdi Khakian Ghomi","authors":"Mohammad Noormohammadi, Mehdi Khakian Ghomi, Hossein Haghi","title":"The membership of stars, density profile and mass segregation in open\n  clusters using a new machine learning-based method","comments":"26 Pages, 18 Figures, accepted by MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1589","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A combination of two unsupervised machine learning algorithms, DBSCAN and GMM\nare used to find members with a high probability of twelve open clusters, M38,\nNGC2099, Coma Ber, NGC752, M67, NGC2243, Alessi01, Bochum04, M34, M35, M41, and\nM48, based on Gaia DR3. These clusters have different ages, distances, and\nnumbers of members which makes a suitable cover of these parameters situation\nto analyze this method. We have identified 752, 1725, 116, 269, 1422, 936, 43,\n38, 743, 1114, 783, and 452, probable and possible members with a higher\nprobability than 0.8 for M38, NGC2099, Coma Ber, NGC752, M67, NGC2243,\nAlessi01, Bochum04, M34, M35, M41, and M48, respectively. Moreover, we obtained\nthe tidal radius, core radius, and clear evidence of mass segregation in ten\nclusters. From an examination of the high-quality color-magnitude data of the\ncluster, we obtained one white dwarf for each of NGC752, Coma Ber and M67. In\nthe young open cluster M38, we found all members inside the tidal radius\nhowever in the older clusters we found some members outside of the tidal\nradius, indicating that the young open clusters had not enough time to form\nclear tidal tails. It is seen that mass segregation occurs at a higher rate in\nolder clusters than the younger ones.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:59:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17729","submitter":"Siqu Long","authors":"Henry Weld, Sijia Hu, Siqu Long, Josiah Poon, Soyeon Caren Han","title":"Tri-level Joint Natural Language Understanding for Multi-turn\n  Conversational Datasets","comments":"accepted at INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Natural language understanding typically maps single utterances to a dual\nlevel semantic frame, sentence level intent and slot labels at the word level.\nThe best performing models force explicit interaction between intent detection\nand slot filling. We present a novel tri-level joint natural language\nunderstanding approach, adding domain, and explicitly exchange semantic\ninformation between all levels. This approach enables the use of multi-turn\ndatasets which are a more natural conversational environment than single\nutterance. We evaluate our model on two multi-turn datasets for which we are\nthe first to conduct joint slot-filling and intent detection. Our model\noutperforms state-of-the-art joint models in slot filling and intent detection\non multi-turn data sets. We provide an analysis of explicit interaction\nlocations between the layers. We conclude that including domain information\nimproves model performance.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:59:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17730","submitter":"Matteo Beccaria","authors":"Matteo Beccaria, Alejandro Cabo-Bizet","title":"On the brane expansion of the Schur index","comments":"25 pages. v2: minor latex fix","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the Schur index of $\\mathcal N=4$ $U(N)$ SYM theory in 4d and its\nholographic giant graviton-type expansion at finite $N$. We compute the\nworld-volume brane superconformal index by a recently proposed definition of\nthe gauge holonomy integral as a multivariate residue. This is evaluated by a\nnovel deformation algorithm that avoids Gr\\\"obner basis methods. Various terms\nof the brane expansion are computed and shown to be free of wall-crossing\nsingularities to the order we explored. The relation between the brane\nexpansion and previous giant graviton-type represenations of the Schur index is\nclarified.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:06:23 GMT"},{"version":"v2","created":"Wed, 31 May 2023 06:54:12 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17731","submitter":"Masaaki Imaizumi","authors":"Kazuma Sawaya, Yoshimasa Uematsu, Masaaki Imaizumi","title":"Statistical Inference in High-Dimensional Generalized Linear Models with\n  Asymmetric Link Functions","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We have developed a statistical inference method applicable to a broad range\nof generalized linear models (GLMs) in high-dimensional settings, where the\nnumber of unknown coefficients scales proportionally with the sample size.\nAlthough a pioneering method has been developed for logistic regression, which\nis a specific instance of GLMs, its direct applicability to other GLMs remains\nlimited. In this study, we address this limitation by developing a new\ninference method designed for a class of GLMs with asymmetric link functions.\nMore precisely, we first introduce a novel convex loss-based estimator and its\nassociated system, which are essential components for the inference. We next\ndevise a methodology for identifying parameters of the system required within\nthe method. Consequently, we construct confidence intervals for GLMs in the\nhigh-dimensional regime. We prove that our proposal has desirable theoretical\nproperties, such as strong consistency and exact coverage probability. Finally,\nwe confirm the validity in experiments.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:07:10 GMT"},{"version":"v2","created":"Tue, 30 May 2023 02:43:31 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17732","submitter":"Kun Song","authors":"Kun Song, Yi Ren, Yi Lei, Chunfeng Wang, Kun Wei, Lei Xie, Xiang Yin,\n  Zejun Ma","title":"StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech\n  Translation","comments":"Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Direct speech-to-speech translation (S2ST) has gradually become popular as it\nhas many advantages compared with cascade S2ST. However, current research\nmainly focuses on the accuracy of semantic translation and ignores the speech\nstyle transfer from a source language to a target language. The lack of\nhigh-fidelity expressive parallel data makes such style transfer challenging,\nespecially in more practical zero-shot scenarios. To solve this problem, we\nfirst build a parallel corpus using a multi-lingual multi-speaker\ntext-to-speech synthesis (TTS) system and then propose the StyleS2ST model with\ncross-lingual speech style transfer ability based on a style adaptor on a\ndirect S2ST system framework. Enabling continuous style space modeling of an\nacoustic model through parallel corpus training and non-parallel TTS data\naugmentation, StyleS2ST captures cross-lingual acoustic feature mapping from\nthe source to the target language. Experiments show that StyleS2ST achieves\ngood style similarity and naturalness in both in-set and out-of-set zero-shot\nscenarios.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:09:17 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 11:48:19 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17733","submitter":"Hao Yang","authors":"Hao Yang, Jinming Zhao, Gholamreza Haffari, Ehsan Shareghi","title":"Investigating Pre-trained Audio Encoders in the Low-Resource Condition","comments":"INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained speech encoders have been central to pushing state-of-the-art\nresults across various speech understanding and generation tasks. Nonetheless,\nthe capabilities of these encoders in low-resource settings are yet to be\nthoroughly explored. To address this, we conduct a comprehensive set of\nexperiments using a representative set of 3 state-of-the-art encoders\n(Wav2vec2, WavLM, Whisper) in the low-resource setting across 7 speech\nunderstanding and generation tasks. We provide various quantitative and\nqualitative analyses on task performance, convergence speed, and\nrepresentational properties of the encoders. We observe a connection between\nthe pre-training protocols of these encoders and the way in which they capture\ninformation in their internal layers. In particular, we observe the Whisper\nencoder exhibits the greatest low-resource capabilities on content-driven tasks\nin terms of performance and convergence speed.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:15:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17734","submitter":"Jiaqi Miao","authors":"Jiaqi Miao, Siqi Sun","title":"Design, Actuation, and Functionalization of Untethered Soft Magnetic\n  Robots with Life-Like Motions: A Review","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Soft robots have demonstrated superior flexibility and functionality than\nconventional rigid robots. These versatile devices can respond to a wide range\nof external stimuli (including light, magnetic field, heat, electric field,\netc.), and can perform sophisticated tasks. Notably, soft magnetic robots\nexhibit unparalleled advantages among numerous soft robots (such as untethered\ncontrol, rapid response, and high safety), and have made remarkable progress in\nsmall-scale manipulation tasks and biomedical applications. Despite the\npromising potential, soft magnetic robots are still in their infancy and\nrequire significant advancements in terms of fabrication, design principles,\nand functional development to be viable for real-world applications. Recent\nprogress shows that bionics can serve as an effective tool for developing soft\nrobots. In light of this, the review is presented with two main goals: (i)\nexploring how innovative bioinspired strategies can revolutionize the design\nand actuation of soft magnetic robots to realize various life-like motions;\n(ii) examining how these bionic systems could benefit practical applications in\nsmall-scale solid/liquid manipulation and therapeutic/diagnostic-related\nbiomedical fields.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:24:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17735","submitter":"Indranil Chakraborty","authors":"Subhajit Barman, Indranil Chakraborty, Sajal Mukherjee","title":"Entanglement harvesting for different gravitational wave burst profiles\n  with and without memory","comments":"22 pages, 6 figures, revtex4","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The possibility of entanglement harvesting is a fascinating phenomenon, which\ngets affected due to the background geometry, the motion of detectors, etc. In\nthe present article, we study how different gravitational wave (GW) burst\nprofiles in linearized gravity, with and without the asymptotic memory, may\ninfluence the harvesting between two static Unruh-DeWitt detectors. To this\nend, we investigate the following burst profiles -- Gaussian, sech-squared, and\ntanh. Out of these, the first two bursts contain no memory, while the latter\nconsists of a non-vanishing memory effect. We found that in all of these cases,\nentanglement harvesting is possible, and it decreases with the increasing\ndistance between detectors. Moreover, the harvesting differs qualitatively\nbased on the presence or absence of the memory. For the two burst profiles\nwithout memory, longer bursts correspond to greater harvesting in the low\ndetector transition energy regime, and this characteristic is reversed for\nlarger transition energy. Meanwhile, for the tanh type profile with memory,\nharvesting is always greater for shorter bursts. We briefly discuss some of the\nconsequences of our findings.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:29:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17736","submitter":"Anatoly Kotikov Vassilievich","authors":"A.V. Kotikov","title":"Short review of interaction effects in graphene","comments":"5 pages, contribution to the proceedings of International Conference\n  \"Modern problems of condensed matter theory\" (October 17-22, Dubna, Russia)","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We review field theoretical studies dedicated to understanding the effects of\nelectron-electron interaction in graphene, which is characterized by gapless\nbands, strong electron-electron interactions, and emerging Lorentz invariance\ndeep in the infrared. We consider the influence of interactions on the\ntransport properties of the system as well as their supposedly decisive\ninfluence on the potential dynamical generation of a gap.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:31:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17737","submitter":"Thomas Fernique","authors":"Thomas Fernique and Olga Mikhailovna Sizova","title":"Shield tilings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We provide a complete description of the edge-to-edge tilings with a regular\ntriangle and a shield-shaped hexagon with no right angle. The case of a hexagon\nwith a right angle is also briefly discussed.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:42:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17738","submitter":"Indrakshi Dey","authors":"Indrakshi Dey and Nicola Marchetti","title":"Wavelet Packet Division Multiplexing (WPDM)-Aided Industrial WSNs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Industrial Internet-of-Things (IIoT) involve multiple groups of sensors, each\ngroup sending its observations on a particular phenomenon to a central\ncomputing platform over a multiple access channel (MAC). The central platform\nincorporates a decision fusion center (DFC) that arrives at global decisions\nregarding each set of phenomena by combining the received local sensor\ndecisions. Owing to the diverse nature of the sensors and heterogeneous nature\nof the information they report, it becomes extremely challenging for the DFC to\ndenoise the signals and arrive at multiple reliable global decisions regarding\nmultiple phenomena. The industrial environment represents a specific indoor\nscenario devoid of windows and filled with different noisy electrical and\nmeasuring units. In that case, the MAC is modelled as a large-scale shadowed\nand slowly-faded channel corrupted with a combination of Gaussian and impulsive\nnoise. The primary contribution of this paper is to propose a flexible, robust\nand highly noise-resilient multi-signal transmission framework based on Wavelet\npacket division multiplexing (WPDM). The local sensor observations from each\ngroup of sensors are waveform coded onto wavelet packet basis functions before\nreporting them over the MAC. We assume a multi-antenna DFC where the\nwaveform-coded sensor observations can be separated by a bank of linear filters\nor a correlator receiver, owing to the orthogonality of the received waveforms.\nAt the DFC we formulate and compare fusion rules for fusing received multiple\nsensor decisions, to arrive at reliable conclusions regarding multiple\nphenomena. Simulation results show that WPDM-aided wireless sensor network\n(WSN) for IIoT environments offer higher immunity to noise by more than 10\ntimes over performance without WPDM in terms of probability of false detection.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:43:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17739","submitter":"Lin Zhang","authors":"Lin Zhang, Xin Wang, Erica Cooper, Nicholas Evans, Junichi Yamagishi","title":"Range-Based Equal Error Rate for Spoof Localization","comments":"Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spoof localization, also called segment-level detection, is a crucial task\nthat aims to locate spoofs in partially spoofed audio. The equal error rate\n(EER) is widely used to measure performance for such biometric scenarios.\nAlthough EER is the only threshold-free metric, it is usually calculated in a\npoint-based way that uses scores and references with a pre-defined temporal\nresolution and counts the number of misclassified segments. Such point-based\nmeasurement overly relies on this resolution and may not accurately measure\nmisclassified ranges. To properly measure misclassified ranges and better\nevaluate spoof localization performance, we upgrade point-based EER to\nrange-based EER. Then, we adapt the binary search algorithm for calculating\nrange-based EER and compare it with the classical point-based EER. Our analyses\nsuggest utilizing either range-based EER, or point-based EER with a proper\ntemporal resolution can fairly and properly evaluate the performance of spoof\nlocalization.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:46:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17740","submitter":"Akshay Nambi","authors":"Akshay Nambi, Vaibhav Balloli, Mercy Ranjit, Tanuja Ganu, Kabir Ahuja,\n  Sunayana Sitaram, Kalika Bali","title":"Breaking Language Barriers with a LEAP: Learning Strategies for Polyglot\n  LLMs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) are at the forefront of transforming numerous\ndomains globally. However, their inclusivity and effectiveness remain limited\nfor non-Latin scripts and low-resource languages. This paper tackles the\nimperative challenge of enhancing the multilingual performance of LLMs,\nspecifically focusing on Generative models. Through systematic investigation\nand evaluation of diverse languages using popular question-answering (QA)\ndatasets, we present novel techniques that unlock the true potential of LLMs in\na polyglot landscape. Our approach encompasses three key strategies that yield\nremarkable improvements in multilingual proficiency. First, by meticulously\noptimizing prompts tailored for polyglot LLMs, we unlock their latent\ncapabilities, resulting in substantial performance boosts across languages.\nSecond, we introduce a new hybrid approach that synergizes GPT generation with\nmultilingual embeddings and achieves significant multilingual performance\nimprovement on critical tasks like QA and retrieval. Finally, to further propel\nthe performance of polyglot LLMs, we introduce a novel learning algorithm that\ndynamically selects the optimal prompt strategy, LLM model, and embeddings per\nquery. This dynamic adaptation maximizes the efficacy of LLMs across languages,\noutperforming best static and random strategies. Our results show substantial\nadvancements in multilingual understanding and generation across a diverse\nrange of languages.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:48:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17741","submitter":"Adam Graham-Squire","authors":"David McCune and Adam Graham-Squire","title":"Monotonicity Anomalies in Scottish Local Government Elections","comments":"30 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The single transferable vote (STV) voting method is used to elect multiple\ncandidates in ranked-choice elections. One weakness of STV is that it fails\nmultiple fairness criteria related to monotonicity and no-show paradoxes. We\nanalyze 1,079 local government STV elections in Scotland to estimate the\nfrequency of such monotonicity anomalies in real-world elections, and compare\nour results with prior empirical and theoretical research about the rates at\nwhich such anomalies occur. In 41 of the 1079 elections we found some kind of\nmonotonicity anomaly. We generally find that the rates of anomalies are similar\nto prior empirical research and much lower than what most theoretical research\nhas found. Most of the STV anomalies we find are the first of their kind to be\ndocumented in real-world elections.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:49:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17742","submitter":"Masaki Waga","authors":"Masaki Waga","title":"Active Learning of Deterministic Timed Automata with Myhill-Nerode Style\n  Characterization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.FL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present an algorithm to learn a deterministic timed automaton (DTA) via\nmembership and equivalence queries. Our algorithm is an extension of the L*\nalgorithm with a Myhill-Nerode style characterization of recognizable timed\nlanguages, which is the class of timed languages recognizable by DTAs. We first\ncharacterize the recognizable timed languages with a Nerode-style congruence.\nUsing it, we give an algorithm with a smart teacher answering symbolic\nmembership queries in addition to membership and equivalence queries. With a\nsymbolic membership query, one can ask the membership of a certain set of timed\nwords at one time. We prove that for any recognizable timed language, our\nlearning algorithm returns a DTA recognizing it. We show how to answer a\nsymbolic membership query with finitely many membership queries. We also show\nthat our learning algorithm requires a polynomial number of queries with a\nsmart teacher and an exponential number of queries with a normal teacher. We\napplied our algorithm to various benchmarks and confirmed its effectiveness\nwith a normal teacher.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:49:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17743","submitter":"Craig Kaplan","authors":"David Smith, Joseph Samuel Myers, Craig S. Kaplan, and Chaim\n  Goodman-Strauss","title":"A chiral aperiodic monotile","comments":"23 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recently discovered \"hat\" aperiodic monotile mixes unreflected and\nreflected tiles in every tiling it admits, leaving open the question of whether\na single shape can tile aperiodically using translations and rotations alone.\nWe show that a close relative of the hat -- the equilateral member of the\ncontinuum to which it belongs -- is a weakly chiral aperiodic monotile: it\nadmits only non-periodic tilings if we forbid reflections by fiat. Furthermore,\nby modifying this polygon's edges we obtain a family of shapes called Spectres\nthat are strictly chiral aperiodic monotiles: they admit only chiral\nnon-periodic tilings based on a hierarchical substitution system.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:51:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17744","submitter":"Naichen Shi","authors":"Naichen Shi and Raed Al Kontar and Salar Fattahi","title":"Heterogeneous Matrix Factorization: When Features Differ by Datasets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In myriad statistical applications, data are collected from related but\nheterogeneous sources. These sources share some commonalities while containing\nidiosyncratic characteristics. More specifically, consider the setting where\nobservation matrices from $N$ sources $\\{M_{i}\\}_{i=1}^N$ are generated from a\nfew common and source-specific factors. Is it possible to recover the shared\nand source-specific factors? We show that under appropriate conditions on the\nalignment of source-specific factors, the problem is well-defined and both\nshared and source-specific factors are identifiable under a constrained matrix\nfactorization objective. To solve this objective, we propose a new class of\nmatrix factorization algorithms, called Heterogeneous Matrix Factorization. HMF\nis easy to implement, enjoys local linear convergence under suitable\nassumptions, and is intrinsically distributed. Through a variety of empirical\nstudies, we showcase the advantageous properties of HMF and its potential\napplication in feature extraction and change detection.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:56:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17745","submitter":"Ran Chen","authors":"Ran Chen and Baogang Xu","title":"Structure and coloring of ($P_7$, $C_5$, diamond)-free graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use $P_t$ and $C_t$ to denote a path and a cycle on t vertices,\nrespectively. A diamond consists of two triangles that share exactly one edge,\na kite is a graph obtained from a diamond by adding a new vertex adjacent to a\nvertex of degree 2 of the diamond, a paraglider is the graph that consists of a\n$C_4$ plus a vertex adjacent to three vertices of the $C_4$, a paw is a graph\nobtained from a triangle by adding a pendant edge. A comparable pair $(u, v)$\nconsists of two nonadjacent vertices $u$ and $v$ such that $N(u)\\subseteq N(v)$\nor $N(v)\\subseteq N(u)$. A universal clique is a clique $K$ such that $xy \\in\nE(G)$ for any two vertices $x \\in K$ and $y\\in V (G)\\setminus K$. A blowup of a\ngraph H is a graph obtained by substituting a stable set for each vertex, and\ncorrespondingly replacing each edge by a complete bipartite graph. We prove\nthat 1) there is a unique connected imperfect $(P_7, C_5$, kite,\nparaglider)-free graph G with \\delta(G) \\geq \\omega(G)+ 1 which has no clique\ncutsets, no comparable pairs, and no universal cliques; 2) if G is a connected\nimperfect $(P_7, C_5$, diamond)-free graph with \\delta(G) \\geq max{3,\n\\omega(G)} and without comparable pairs, then G is isomorphic to a graph of a\nwell defined 12 graph families; and 3) each connected imperfect $(P_7, C_5$,\npaw)-free graph is a blowup of $C_7$. As consequences, we show that \\chi(G)\n\\leq \\omega(G)+1 if G is (P7, C5, kite, paraglider)-free, and \\chi(G) \\leq\nmax{3, \\omega(G)} if G is $(P_7, C_5$, H)-free with H being a diamond or a paw.\nWe also show that \\chi(G) \\leq\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:58:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17746","submitter":"Wenjie Zhuo","authors":"Wenjie Zhuo, Yifan Sun, Xiaohan Wang, Linchao Zhu, Yi Yang","title":"Whitening-based Contrastive Learning of Sentence Embeddings","comments":"ACL 2023 Main Conference(Oral)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a whitening-based contrastive learning method for\nsentence embedding learning (WhitenedCSE), which combines contrastive learning\nwith a novel shuffled group whitening. Generally, contrastive learning pulls\ndistortions of a single sample (i.e., positive samples) close and push negative\nsamples far away, correspondingly facilitating the alignment and uniformity in\nthe feature space. A popular alternative to the \"pushing'' operation is\nwhitening the feature space, which scatters all the samples for uniformity.\nSince the whitening and the contrastive learning have large redundancy w.r.t.\nthe uniformity, they are usually used separately and do not easily work\ntogether. For the first time, this paper integrates whitening into the\ncontrastive learning scheme and facilitates two benefits. 1) Better uniformity.\nWe find that these two approaches are not totally redundant but actually have\nsome complementarity due to different uniformity mechanism. 2) Better\nalignment. We randomly divide the feature into multiple groups along the\nchannel axis and perform whitening independently within each group. By\nshuffling the group division, we derive multiple distortions of a single sample\nand thus increase the positive sample diversity. Consequently, using multiple\npositive samples with enhanced diversity further improves contrastive learning\ndue to better alignment. Extensive experiments on seven semantic textual\nsimilarity tasks show our method achieves consistent improvement over the\ncontrastive learning baseline and sets new states of the art, e.g., 78.78\\%\n(+2.53\\% based on BERT\\ba) Spearman correlation on STS tasks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:58:10 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 05:33:55 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.17747","submitter":"Leonid Petrov","authors":"Svetlana Gavrilova and Leonid Petrov","title":"Tilted biorthogonal ensembles, Grothendieck random partitions, and\n  determinantal tests","comments":"47 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.AG math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study probability measures on partitions based on symmetric Grothendieck\npolynomials. These deformations of Schur polynomials introduced in the K-theory\nof Grassmannians share many common properties. Our Grothendieck measures are\nanalogs of the Schur measures on partitions introduced by Okounkov\n(arXiv:math/9907127 [math.RT]). Despite the similarity of determinantal\nformulas for the probability weights of Schur and Grothendieck measures, we\ndemonstrate that Grothendieck measures are \\emph{not} determinantal point\nprocesses. This question is related to the principal minor assignment problem\nin algebraic geometry, and we employ a determinantal test first obtained by\nNanson in 1897 for the $4\\times4$ problem. We also propose a procedure for\ngetting Nanson-like determinantal tests for matrices of any size $n\\ge4$ which\nappear new for $n\\ge 5$.\n  By placing the Grothendieck measures into a new framework of tilted\nbiorthogonal ensembles generalizing a rich class of determinantal processes\nintroduced by Borodin (arXiv:math/9804027 [math.CA]), we identify Grothendieck\nrandom partitions as a cross-section of a Schur process, a determinantal\nprocess in two dimensions. This identification expresses the correlation\nfunctions of Grothendieck measures through sums of Fredholm determinants, which\nare not immediately suitable for asymptotic analysis. A more direct approach\nallows us to obtain a limit shape result for the Grothendieck random\npartitions. The limit shape curve is not particularly explicit as it arises as\na cross-section of the limit shape surface for the Schur process. The gradient\nof this surface is expressed through the argument of a complex root of a cubic\nequation.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:00:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17748","submitter":"Subhajit Maity","authors":"Subhajit Maity, Ram Kumar Karsh","title":"Image Hash Minimization for Tamper Detection","comments":"Published at the 9th International Conference on Advances in Pattern\n  Recognition, 2017","journal-ref":"2017 Ninth International Conference on Advances in Pattern\n  Recognition (ICAPR), Bangalore, India, 2017, pp. 1-6","doi":"10.1109/ICAPR.2017.8593100","report-no":null,"categories":"cs.CV eess.IV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Tamper detection using image hash is a very common problem of modern days.\nSeveral research and advancements have already been done to address this\nproblem. However, most of the existing methods lack the accuracy of tamper\ndetection when the tampered area is low, as well as requiring long image\nhashes. In this paper, we propose a novel method objectively to minimize the\nhash length while enhancing the performance at low tampered area.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:04:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17749","submitter":"Yongchao Huang Dr.","authors":"Yongchao Huang, Yuhang He, Hong Ge","title":"Bayesian inference and neural estimation of acoustic wave propagation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.AI eess.AS physics.data-an","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work, we introduce a novel framework which combines physics and\nmachine learning methods to analyse acoustic signals. Three methods are\ndeveloped for this task: a Bayesian inference approach for inferring the\nspectral acoustics characteristics, a neural-physical model which equips a\nneural network with forward and backward physical losses, and the non-linear\nleast squares approach which serves as benchmark. The inferred propagation\ncoefficient leads to the room impulse response (RIR) quantity which can be used\nfor relocalisation with uncertainty. The simplicity and efficiency of this\nframework is empirically validated on simulated data.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:14:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17750","submitter":"Ella Rabinovich","authors":"Ella Rabinovich, Matan Vetzler, Samuel Ackerman, Ateret Anaby-Tavor","title":"Reliable and Interpretable Drift Detection in Streams of Short Texts","comments":"ACL2023 industry track (9 pages)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Data drift is the change in model input data that is one of the key factors\nleading to machine learning models performance degradation over time.\nMonitoring drift helps detecting these issues and preventing their harmful\nconsequences. Meaningful drift interpretation is a fundamental step towards\neffective re-training of the model. In this study we propose an end-to-end\nframework for reliable model-agnostic change-point detection and interpretation\nin large task-oriented dialog systems, proven effective in multiple customer\ndeployments. We evaluate our approach and demonstrate its benefits with a novel\nvariant of intent classification training dataset, simulating customer requests\nto a dialog system. We make the data publicly available.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:14:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17751","submitter":"Zhaolin Wang","authors":"Yuanwei Liu, Zhaolin Wang, Jiaqi Xu, Chongjun Ouyang, Xidong Mu,\n  Robert Schober","title":"Near-Field Communications: A Tutorial Review","comments":"45 pages, 35 figures; submitted to possible IEEE journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Extremely large-scale antenna arrays, tremendously high frequencies, and new\ntypes of antennas are three clear trends in multi-antenna technology for\nsupporting the sixth-generation (6G) networks. To properly account for the new\ncharacteristics introduced by these three trends in communication system\ndesign, the near-field spherical-wave propagation model needs to be used, which\ndiffers from the classical far-field planar-wave one. As such, near-field\ncommunication (NFC) will become essential in 6G networks. In this tutorial, we\ncover three key aspects of NFC. 1) Channel Modelling: We commence by reviewing\nnear-field spherical-wave-based channel models for spatially-discrete (SPD)\nantennas. Then, uniform spherical wave (USW) and non-uniform spherical wave\n(NUSW) models are discussed. Subsequently, we introduce a general near-field\nchannel model for SPD antennas and a Green's function-based channel model for\ncontinuous-aperture (CAP) antennas. 2) Beamfocusing and Antenna Architectures:\nWe highlight the properties of near-field beamfocusing and discuss NFC antenna\narchitectures for both SPD and CAP antennas. Moreover, the basic principles of\nnear-field beam training are introduced. 3) Performance Analysis: Finally, we\nprovide a comprehensive performance analysis framework for NFC. For near-field\nline-of-sight channels, the received signal-to-noise ratio and power-scaling\nlaw are derived. For statistical near-field multipath channels, a general\nanalytical framework is proposed, based on which analytical expression for the\noutage probability, ergodic channel capacity, and ergodic mutual information\nare derived. Finally, for each aspect, the topics for future research are\ndiscussed.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:23:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17752","submitter":"Sait Umar","authors":"A.S. Umar, K. Godbey, and C. Simenel","title":"Cluster model of 12C in density functional theory framework","comments":"8 pages, 4 figures, to be published in Phys. Rev. C","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We employ the constrained density functional theory to investigate cluster\nphenomena for the $^{12}$C nucleus. The proton and neutron densities are\ngenerated from the placement of three $^{4}$He nuclei (alpha particles)\ngeometrically. These densities are then used in a density constrained\nHartree-Fock calculation that produces an antisymmetrized state with the same\ndensities through energy minimization. In the calculations no \\textit{a priori}\nanalytic form for the single-particle states is assumed and the full energy\ndensity functional is utilized. The geometrical scan of the energy landscape\nprovides the ground state of $^{12}$C as an equilateral triangular\nconfiguration of three alphas with molecular bond like structures. The use of\nthe nucleon localization function provides further insight to these\nconfigurations. One can conclude that these configurations are a hybrid between\na pure mean-field and a pure alpha particle condensate. This development could\nfacilitate DFT based fusion calculations with a more realistic $^{12}$C ground\nstate.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:24:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17753","submitter":"Kazuo Muroi","authors":"Nasser Heydari and Kazuo Muroi","title":"Pythagorean Theorem in Elamite Mathematics","comments":"26 pages and 17 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This article studies the application of the Pythagorean theorem in the Susa\nMathematical Texts (\\textbf{SMT}) and we discuss those texts whose problems and\nrelated calculations demonstrate its use. Among these texts, \\textbf{SMT\nNo.\\,1} might be the most important as it contains a geometric application of\nthe Pythagorean theorem.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:28:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17754","submitter":"Jie An","authors":"Zhenya Zhang and Jie An and Paolo Arcaini and Ichiro Hasuo","title":"Online Causation Monitoring of Signal Temporal Logic","comments":"31 pages, 7 figures, the full version of the paper accepted by CAV\n  2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.FL cs.LO cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Online monitoring is an effective validation approach for hybrid systems,\nthat, at runtime, checks whether the (partial) signals of a system satisfy a\nspecification in, e.g., Signal Temporal Logic (STL). The classic STL monitoring\nis performed by computing a robustness interval that specifies, at each\ninstant, how far the monitored signals are from violating and satisfying the\nspecification. However, since a robustness interval monotonically shrinks\nduring monitoring, classic online monitors may fail in reporting new violations\nor in precisely describing the system evolution at the current instant. In this\npaper, we tackle these issues by considering the causation of violation or\nsatisfaction, instead of directly using the robustness. We first introduce a\nBoolean causation monitor that decides whether each instant is relevant to the\nviolation or satisfaction of the specification. We then extend this monitor to\na quantitative causation monitor that tells how far an instant is from being\nrelevant to the violation or satisfaction. We further show that classic\nmonitors can be derived from our proposed ones. Experimental results show that\nthe two proposed monitors are able to provide more detailed information about\nsystem evolution, without requiring a significantly higher monitoring cost.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:35:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17755","submitter":"Valeri Makarov","authors":"Valeri V. Makarov, Megan C. Johnson, Nathan J. Secrest","title":"Radio-Optical Reference Catalog, version 1","comments":"To be published in AJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The fundamental celestial reference frame (CRF) is based on two catalogs of\nastrometric positions, the third realization of the International Celestial\nReference Frame (ICRF3), and the much larger Gaia~CRF, built from the third\ndata release (DR3). The objects in common between these two catalogs are mostly\ndistant AGNs and quasars that are both sufficiently optically bright for Gaia\nand radio-loud for the VLBI. This limited collection of reference objects is\ncrucially important for the mutual alignment of the two CRFs and maintenance of\nall the other frames and coordinate systems branching from the ICRF. In this\npaper, we show that the three components of ICRF3 (S/X, K, and X/Ka band\ncatalogs) have significantly different sky-correlated vector fields of position\noffsets with respect to Gaia~DR3. When iteratively expanded in the vector\nspherical harmonics up to degree 4 on a carefully vetted set of common sources,\neach of these components includes several statistically significant terms. The\nmedian sky-correlated offsets from the Gaia positions are found to be 56\n$\\mu$as for the S/X, 100 $\\mu$as for the K, and 324 $\\mu$as for the Ka\ncatalogs. The weighted mean vector field is subtracted from the Gaia reference\npositions, while the deviations from that field are added to each of the ICRF3\ncomponents. The corrected positions from each of the four input catalogs are\ncombined into a single weighted mean catalog, which we propose to be the\ncurrent most accurate realization of an inertial radio-optical CRF.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:41:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17756","submitter":"Ashik Saha","authors":"Ashik Saha","title":"The use of Ethnomedicinal plants in Indigenous Health Care Practice of\n  the Hajong Tribe community in Durgapur, Bangladesh","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.OT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Garo Hills have always been fascination to the naked human eyes. The\nhills are the shelter of the earliest human habitation of Bangladesh. It is a\nplace of ancient cultures and many botanical wonders. It is situated in the\nmost northern part of Durgapur sub-district having border with Meghalaya of\nIndia. Durgapur is rich with ethnic diversity with Hajong and Garo as the major\nethnic groups along with some Bengali settlers from the common population.\nPresent survey was undertaken to compile the medicinal plant usage among the\nHajong Tribe of Durgapur.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:42:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17757","submitter":"Yasaman Sabbagh Ziarani","authors":"Lata Narayanan and Yasaman Sabbagh","title":"Diversity-seeking Jump Games in Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, many researchers have studied strategic games inspired by\nSchelling's influential model of residential segregation. In this model, agents\nbelonging to $k$ different types are placed at the nodes of a network. Agents\ncan be either stubborn, in which case they will always choose their preferred\nlocation, or strategic, in which case they aim to maximize the fraction of\nagents of their own type in their neighborhood. In the so-called Schelling\ngames inspired by this model, strategic agents are assumed to be\nsimilarity-seeking: their utility is defined as the fraction of its neighbors\nof the same type as itself. In this paper, we introduce a new type of strategic\njump game in which agents are instead diversity-seeking: the utility of an\nagent is defined as the fraction of its neighbors that is of a different type\nthan itself. We show that it is NP-hard to determine the existence of an\nequilibrium in such games, if some agents are stubborn. However, in trees, our\ndiversity-seeking jump game always admits a pure Nash equilibrium, if all\nagents are strategic. In regular graphs and spider graphs with a single empty\nnode, as well as in all paths, we prove a stronger result: the game is a\npotential game, that is, improving response dynamics will always converge to a\nNash equilibrium from any initial placement of agents.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:43:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17758","submitter":"Yuki Okamoto","authors":"Yuki Okamoto, Kanta Shimonishi, Keisuke Imoto, Kota Dohi, Shota\n  Horiguchi, Yohei Kawaguchi","title":"CAPTDURE: Captioned Sound Dataset of Single Sources","comments":"Accepted to INTERSPEECH2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In conventional studies on environmental sound separation and synthesis using\ncaptions, datasets consisting of multiple-source sounds with their captions\nwere used for model training. However, when we collect the captions for\nmultiple-source sound, it is not easy to collect detailed captions for each\nsound source, such as the number of sound occurrences and timbre. Therefore, it\nis difficult to extract only the single-source target sound by the\nmodel-training method using a conventional captioned sound dataset. In this\nwork, we constructed a dataset with captions for a single-source sound named\nCAPTDURE, which can be used in various tasks such as environmental sound\nseparation and synthesis. Our dataset consists of 1,044 sounds and 4,902\ncaptions. We evaluated the performance of environmental sound extraction using\nour dataset. The experimental results show that the captions for single-source\nsounds are effective in extracting only the single-source target sound from the\nmixture sound.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:56:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17759","submitter":"Iakovos Androulidakis Dr","authors":"Iakovos Androulidakis","title":"On a remark by Alan Weinstein","comments":"16 pages, to appear in Contemporary Mathematics, Proceedings of the\n  AMS-EMS-SMF conference, special section on Diffeology, Grenoble 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Alan Weinstein remarked that, working in the framework of diffeology, a\nconstruction from Noncommutative Differential Geometry might provide the\nnon-trivial representations required for the geometric quantisation of a\nsymplectic structure which is not integral. In this note we show that the\nconstruction we gave with P. Antonini does indeed provide non-trivial\nrepresentations.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:56:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18366","submitter":"Djemel Ziou","authors":"Djemel Ziou","title":"The Central Tendency, Weighted Likelihood, and Exponential family","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.OT math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we establish the links between the H\\\"older and Lehmer central\ntendencies and the maximum likelihood for the estimation of the one-parameter\nexponential family of probability density functions. For this, we show that the\nmaximum weighted likelihood of the parameter is a generalized weighted mean\nfrom which the central tendencies of H\\\"older and Lehmer can be inferred. Some\nof the links obtained do not seem to be part of the state of the art. Moreover,\nwe show that the maximum weighted likelihood is equivalent to the minimum of\nthe weighted least square error. Experimentations confirm that the maximum\nweighted likelihood leads to a more accurate fitting of histograms.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:52:19 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18367","submitter":"Farzane Tajidini","authors":"Hasan Hejbari Zargar, Saha Hejbari Zargar, Raziye Mehri, Farzane\n  Tajidini","title":"Using VGG16 Algorithms for classification of lung cancer in CT scans\n  Image","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Lung cancer is the leading reason behind cancer-related deaths within the\nworld. Early detection of lung nodules is vital for increasing the survival\nrate of cancer patients. Traditionally, physicians should manually identify the\nworld suspected of getting carcinoma. When developing these detection systems,\nthe arbitrariness of lung nodules' shape, size, and texture could be a\nchallenge. Many studies showed the applied of computer vision algorithms to\naccurate diagnosis and classification of lung nodules. A deep learning\nalgorithm called the VGG16 was developed during this paper to help medical\nprofessionals diagnose and classify carcinoma nodules. VGG16 can classify\nmedical images of carcinoma in malignant, benign, and healthy patients. This\npaper showed that nodule detection using this single neural network had 92.08%\nsensitivity, 91% accuracy, and an AUC of 93%.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:50:12 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18368","submitter":"Elena Fantino Dr","authors":"Burhani M. Burhani, Elena Fantino, Roberto Flores, Manuel\n  Sanjurjo-Rivo","title":"A new automated strategy for optimizing inclined interplanetary\n  low-thrust trajectories","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This study proposes a new automated strategy for designing and optimizing\nthree-dimensional interplanetary low-thrust (LT) trajectories. The method\nformulates the design as a hybrid optimal control problem and solves it using a\ntwo-step approach. In Step 1, a three-dimensional model based on generalized\nlogarithmic spirals is used with heuristics in combination with a\ngradient-based solver to perform an automated multi-objective global search of\ntrajectories and optimize for parameters defining the spirals, the launch date,\nas well as the number, sequence and configuration of the planetary flybys. In\nStep 2, candidate solutions from Step 1 are refined by further optimization\nwith a direct method. Results show that, compared to similar algorithms based\non two-dimensional models, the strategy implemented in Step 1 leads to better\nestimates of the optimal trajectories, especially when the orbits of the\ninvolved bodies are inclined with respect to the ecliptic plane. The proposed\napproximate method (Step 1) yields better agreement with high-fidelity\nsolutions (Step 2) in terms of launch, flyby and arrival dates, in-plane and\nout-of-plane average LT accelerations and propellant consumption, leading to\nimproved convergence when the Step 1 trajectories are employed to initiate the\nsearch in Step 2.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 19:06:07 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18369","submitter":"Sina Kazemian","authors":"Sina Kazemian, Giovanni Fanchini","title":"Influence of higher order electron-phonon interaction terms on the\n  thermal properties of 2D Dirac crystals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To understand the essential properties of Dirac crystals, such as their\nthermal conductivity, we require models that consider the interaction between\nDirac electrons and dispersive acoustic phonons. The exceptionally high thermal\nconductivity in 2D Dirac crystals is attributed to near-ideal phonon quantum\ngases, while undesired limitations arise from electron-phonon (e-ph)\ninteractions which have been shown to limit the thermal conductivity up to\nseveral microns away. The e-ph thermal conductivity is directly linked to the\nphonon scattering rate. Conventional calculations overlook phonons with\nshort-dispersive wavelengths, rendering them inadequate for analyzing 2D Dirac\ncrystals. The phonon scattering rate is typically calculated up to the\nfirst-order magnitude, considering 3-particle interactions involving the decay\nof an electron and phonon (EP-E*) to create a new electron. However, processes\ninvolving the decay of an electron and the creation of a new electron and\nphonon (E-E*P*) are neglected. In this study, we present an accurate expression\nfor the phonon scattering rate and e-ph thermal conductivity in 2D Dirac\ncrystals, accounting for short-dispersive wavelength phonons. We demonstrate\nthe significance of the E-E*P* process even at room temperature in calculating\nthe phonon scattering rate and e-ph thermal conductivity, particularly for\nfirst-order e-ph interactions. Furthermore, we emphasize the importance of\nincorporating second-order e-ph interactions, specifically the EP-E*P*\ninteraction involving the decay of an electron and phonon and the creation of a\nnew electron-phonon pair, to accurately determine the phonon scattering rate\nand e-ph thermal conductivity at high temperatures and low Fermi energies. This\n4-particle interaction process plays a crucial role in characterizing these\nproperties effectively.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:28:16 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18370","submitter":"Saurabh Sihag","authors":"Saurabh Sihag, Gonzalo Mateos, Corey T. McMillan, Alejandro Ribeiro","title":"Explainable Brain Age Prediction using coVariance Neural Networks","comments":"arXiv admin note: substantial text overlap with arXiv:2305.01807","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM cs.LG stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In computational neuroscience, there has been an increased interest in\ndeveloping machine learning algorithms that leverage brain imaging data to\nprovide estimates of \"brain age\" for an individual. Importantly, the\ndiscordance between brain age and chronological age (referred to as \"brain age\ngap\") can capture accelerated aging due to adverse health conditions and\ntherefore, can reflect increased vulnerability towards neurological disease or\ncognitive impairments. However, widespread adoption of brain age for clinical\ndecision support has been hindered due to lack of transparency and\nmethodological justifications in most existing brain age prediction algorithms.\nIn this paper, we leverage coVariance neural networks (VNN) to propose an\nanatomically interpretable framework for brain age prediction using cortical\nthickness features. Specifically, our brain age prediction framework extends\nbeyond the coarse metric of brain age gap in Alzheimer's disease (AD) and we\nmake two important observations: (i) VNNs can assign anatomical\ninterpretability to elevated brain age gap in AD by identifying contributing\nbrain regions, (ii) the interpretability offered by VNNs is contingent on their\nability to exploit specific eigenvectors of the anatomical covariance matrix.\nTogether, these observations facilitate an explainable perspective to the task\nof brain age prediction.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 22:28:25 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18371","submitter":"Sizhen Bian","authors":"Sizhen Bian, Lukas Schulthess, Georg Rutishauser, Alfio Di Mauro, Luca\n  Benini, Michele Magno","title":"ColibriUAV: An Ultra-Fast, Energy-Efficient Neuromorphic Edge Processing\n  UAV-Platform with Event-Based and Frame-Based Cameras","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.AR cs.SY eess.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The interest in dynamic vision sensor (DVS)-powered unmanned aerial vehicles\n(UAV) is raising, especially due to the microsecond-level reaction time of the\nbio-inspired event sensor, which increases robustness and reduces latency of\nthe perception tasks compared to a RGB camera. This work presents ColibriUAV, a\nUAV platform with both frame-based and event-based cameras interfaces for\nefficient perception and near-sensor processing. The proposed platform is\ndesigned around Kraken, a novel low-power RISC-V System on Chip with two\nhardware accelerators targeting spiking neural networks and deep ternary neural\nnetworks.Kraken is capable of efficiently processing both event data from a DVS\ncamera and frame data from an RGB camera. A key feature of Kraken is its\nintegrated, dedicated interface with a DVS camera. This paper benchmarks the\nend-to-end latency and power efficiency of the neuromorphic and event-based UAV\nsubsystem, demonstrating state-of-the-art event data with a throughput of 7200\nframes of events per second and a power consumption of 10.7 \\si{\\milli\\watt},\nwhich is over 6.6 times faster and a hundred times less power-consuming than\nthe widely-used data reading approach through the USB interface. The overall\nsensing and processing power consumption is below 50 mW, achieving latency in\nthe milliseconds range, making the platform suitable for low-latency autonomous\nnano-drones as well.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:08:22 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18372","submitter":"Corina P\\u{a}s\\u{a}reanu","authors":"Corina Pasareanu, Ravi Mangal, Divya Gopinath, and Huafeng Yu","title":"Assumption Generation for the Verification of Learning-Enabled\n  Autonomous Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Providing safety guarantees for autonomous systems is difficult as these\nsystems operate in complex environments that require the use of\nlearning-enabled components, such as deep neural networks (DNNs) for visual\nperception. DNNs are hard to analyze due to their size (they can have thousands\nor millions of parameters), lack of formal specifications (DNNs are typically\nlearnt from labeled data, in the absence of any formal requirements), and\nsensitivity to small changes in the environment. We present an assume-guarantee\nstyle compositional approach for the formal verification of system-level safety\nproperties of such autonomous systems. Our insight is that we can analyze the\nsystem in the absence of the DNN perception components by automatically\nsynthesizing assumptions on the DNN behaviour that guarantee the satisfaction\nof the required safety properties. The synthesized assumptions are the weakest\nin the sense that they characterize the output sequences of all the possible\nDNNs that, plugged into the autonomous system, guarantee the required safety\nproperties. The assumptions can be leveraged as run-time monitors over a\ndeployed DNN to guarantee the safety of the overall system; they can also be\nmined to extract local specifications for use during training and testing of\nDNNs. We illustrate our approach on a case study taken from the autonomous\nairplanes domain that uses a complex DNN for perception.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 23:30:27 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18373","submitter":"Zhiwei Jia","authors":"Zhiwei Jia and Pradyumna Narayana and Arjun R. Akula and Garima Pruthi\n  and Hao Su and Sugato Basu and Varun Jampani","title":"KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature\n  Adaptation of Vision-Language Models","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Image ad understanding is a crucial task with wide real-world applications.\nAlthough highly challenging with the involvement of diverse atypical scenes,\nreal-world entities, and reasoning over scene-texts, how to interpret image ads\nis relatively under-explored, especially in the era of foundational\nvision-language models (VLMs) featuring impressive generalizability and\nadaptability. In this paper, we perform the first empirical study of image ad\nunderstanding through the lens of pre-trained VLMs. We benchmark and reveal\npractical challenges in adapting these VLMs to image ad understanding. We\npropose a simple feature adaptation strategy to effectively fuse multimodal\ninformation for image ads and further empower it with knowledge of real-world\nentities. We hope our study draws more attention to image ad understanding\nwhich is broadly relevant to the advertising industry.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 04:49:01 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18374","submitter":"Edoardo D'Amico","authors":"Edoardo D'Amico, Aonghus Lawlor, Neil Hurley","title":"Pure Spectral Graph Embeddings: Reinterpreting Graph Convolution for\n  Top-N Recommendation","comments":null,"journal-ref":"Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  2023","doi":"10.1007/978-3-031-33380-4_24","report-no":null,"categories":"cs.IR cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The use of graph convolution in the development of recommender system\nalgorithms has recently achieved state-of-the-art results in the collaborative\nfiltering task (CF). While it has been demonstrated that the graph convolution\noperation is connected to a filtering operation on the graph spectral domain,\nthe theoretical rationale for why this leads to higher performance on the\ncollaborative filtering problem remains unknown. The presented work makes two\ncontributions. First, we investigate the effect of using graph convolution\nthroughout the user and item representation learning processes, demonstrating\nhow the latent features learned are pushed from the filtering operation into\nthe subspace spanned by the eigenvectors associated with the highest\neigenvalues of the normalised adjacency matrix, and how vectors lying on this\nsubspace are the optimal solutions for an objective function related to the sum\nof the prediction function over the training data. Then, we present an approach\nthat directly leverages the eigenvectors to emulate the solution obtained\nthrough graph convolution, eliminating the requirement for a time-consuming\ngradient descent training procedure while also delivering higher performance on\nthree real-world datasets.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:34:50 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18375","submitter":"Mingyuan Zhou","authors":"Tianqi Chen and Mingyuan Zhou","title":"Learning to Jump: Thinning and Thickening Latent Counts for Generative\n  Modeling","comments":"ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ME stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning to denoise has emerged as a prominent paradigm to design\nstate-of-the-art deep generative models for natural images. How to use it to\nmodel the distributions of both continuous real-valued data and categorical\ndata has been well studied in recently proposed diffusion models. However, it\nis found in this paper to have limited ability in modeling some other types of\ndata, such as count and non-negative continuous data, that are often highly\nsparse, skewed, heavy-tailed, and/or overdispersed. To this end, we propose\nlearning to jump as a general recipe for generative modeling of various types\nof data. Using a forward count thinning process to construct learning\nobjectives to train a deep neural network, it employs a reverse count\nthickening process to iteratively refine its generation through that network.\nWe demonstrate when learning to jump is expected to perform comparably to\nlearning to denoise, and when it is expected to perform better. For example,\nlearning to jump is recommended when the training data is non-negative and\nexhibits strong sparsity, skewness, heavy-tailedness, and/or heterogeneity.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:38:28 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18376","submitter":"Jun-Gi Jang","authors":"Jun-Gi Jang, Jeongyoung Lee, Yong-chan Park, U Kang","title":"Fast and Accurate Dual-Way Streaming PARAFAC2 for Irregular Tensors --\n  Algorithm and Application","comments":"12 pages, accept to The 29th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining (KDD) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  How can we efficiently and accurately analyze an irregular tensor in a\ndual-way streaming setting where the sizes of two dimensions of the tensor\nincrease over time? What types of anomalies are there in the dual-way streaming\nsetting? An irregular tensor is a collection of matrices whose column lengths\nare the same while their row lengths are different. In a dual-way streaming\nsetting, both new rows of existing matrices and new matrices arrive over time.\nPARAFAC2 decomposition is a crucial tool for analyzing irregular tensors.\nAlthough real-time analysis is necessary in the dual-way streaming, static\nPARAFAC2 decomposition methods fail to efficiently work in this setting since\nthey perform PARAFAC2 decomposition for accumulated tensors whenever new data\narrive. Existing streaming PARAFAC2 decomposition methods work in a limited\nsetting and fail to handle new rows of matrices efficiently. In this paper, we\npropose Dash, an efficient and accurate PARAFAC2 decomposition method working\nin the dual-way streaming setting. When new data are given, Dash efficiently\nperforms PARAFAC2 decomposition by carefully dividing the terms related to old\nand new data and avoiding naive computations involved with old data.\nFurthermore, applying a forgetting factor makes Dash follow recent movements.\nExtensive experiments show that Dash achieves up to 14.0x faster speed than\nexisting PARAFAC2 decomposition methods for newly arrived data. We also provide\ndiscoveries for detecting anomalies in real-world datasets, including Subprime\nMortgage Crisis and COVID-19.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 05:56:47 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18377","submitter":"Jingfeng Zhang","authors":"Jingfeng Zhang, Bo Song, Haohan Wang, Bo Han, Tongliang Liu, Lei Liu,\n  Masashi Sugiyama","title":"BadLabel: A Robust Perspective on Evaluating and Enhancing Label-noise\n  Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Label-noise learning (LNL) aims to increase the model's generalization given\ntraining data with noisy labels. To facilitate practical LNL algorithms,\nresearchers have proposed different label noise types, ranging from\nclass-conditional to instance-dependent noises. In this paper, we introduce a\nnovel label noise type called BadLabel, which can significantly degrade the\nperformance of existing LNL algorithms by a large margin. BadLabel is crafted\nbased on the label-flipping attack against standard classification, where\nspecific samples are selected and their labels are flipped to other labels so\nthat the loss values of clean and noisy labels become indistinguishable. To\naddress the challenge posed by BadLabel, we further propose a robust LNL method\nthat perturbs the labels in an adversarial manner at each epoch to make the\nloss values of clean and noisy labels again distinguishable. Once we select a\nsmall set of (mostly) clean labeled data, we can apply the techniques of\nsemi-supervised learning to train the model accurately. Empirically, our\nexperimental results demonstrate that existing LNL algorithms are vulnerable to\nthe newly introduced BadLabel noise type, while our proposed robust LNL method\ncan effectively improve the generalization performance of the model under\nvarious types of label noise. The new dataset of noisy labels and the source\ncodes of robust LNL algorithms are available at\nhttps://github.com/zjfheart/BadLabels.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:26:23 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18378","submitter":"Kyle Hsu","authors":"Kyle Hsu and Will Dorrell and James C. R. Whittington and Jiajun Wu\n  and Chelsea Finn","title":"Disentanglement via Latent Quantization","comments":"20 pages, 8 figures, code available at\n  https://github.com/kylehkhsu/disentangle","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In disentangled representation learning, a model is asked to tease apart a\ndataset's underlying sources of variation and represent them independently of\none another. Since the model is provided with no ground truth information about\nthese sources, inductive biases take a paramount role in enabling\ndisentanglement. In this work, we construct an inductive bias towards\ncompositionally encoding and decoding data by enforcing a harsh communication\nbottleneck. Concretely, we do this by (i) quantizing the latent space into\nlearnable discrete codes with a separate scalar codebook per dimension and (ii)\napplying strong model regularization via an unusually high weight decay.\nIntuitively, the quantization forces the encoder to use a small number of\nlatent values across many datapoints, which in turn enables the decoder to\nassign a consistent meaning to each value. Regularization then serves to drive\nthe model towards this parsimonious strategy. We demonstrate the broad\napplicability of this approach by adding it to both basic data-reconstructing\n(vanilla autoencoder) and latent-reconstructing (InfoGAN) generative models. In\norder to reliably assess these models, we also propose InfoMEC, new metrics for\ndisentanglement that are cohesively grounded in information theory and fix\nwell-established shortcomings in previous metrics. Together with\nregularization, latent quantization dramatically improves the modularity and\nexplicitness of learned representations on a representative suite of benchmark\ndatasets. In particular, our quantized-latent autoencoder (QLAE) consistently\noutperforms strong methods from prior work in these key disentanglement\nproperties without compromising data reconstruction.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:30:29 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18379","submitter":"Sen Na","authors":"Ilgee Hong, Sen Na, Michael W. Mahoney, Mladen Kolar","title":"Constrained Optimization via Exact Augmented Lagrangian and Randomized\n  Iterative Sketching","comments":"25 pages, 4 figures","journal-ref":"ICML 2023","doi":null,"report-no":null,"categories":"math.OC cs.LG cs.NA math.NA stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider solving equality-constrained nonlinear, nonconvex optimization\nproblems. This class of problems appears widely in a variety of applications in\nmachine learning and engineering, ranging from constrained deep neural\nnetworks, to optimal control, to PDE-constrained optimization. We develop an\nadaptive inexact Newton method for this problem class. In each iteration, we\nsolve the Lagrangian Newton system inexactly via a randomized iterative\nsketching solver, and select a suitable stepsize by performing line search on\nan exact augmented Lagrangian merit function. The randomized solvers have\nadvantages over deterministic linear system solvers by significantly reducing\nper-iteration flops complexity and storage cost, when equipped with suitable\nsketching matrices. Our method adaptively controls the accuracy of the\nrandomized solver and the penalty parameters of the exact augmented Lagrangian,\nto ensure that the inexact Newton direction is a descent direction of the exact\naugmented Lagrangian. This allows us to establish a global almost sure\nconvergence. We also show that a unit stepsize is admissible locally, so that\nour method exhibits a local linear convergence. Furthermore, we prove that the\nlinear convergence can be strengthened to superlinear convergence if we\ngradually sharpen the adaptive accuracy condition on the randomized solver. We\ndemonstrate the superior performance of our method on benchmark nonlinear\nproblems in CUTEst test set, constrained logistic regression with data from\nLIBSVM, and a PDE-constrained problem.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:33:37 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18380","submitter":"Chih-Hong Cheng","authors":"Utku Ayvaz, Chih-Hong Cheng, Hao Shen","title":"Potential-based Credit Assignment for Cooperative RL-based Testing of\n  Autonomous Vehicles","comments":"Accepted at IJCNN'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While autonomous vehicles (AVs) may perform remarkably well in generic\nreal-life cases, their irrational action in some unforeseen cases leads to\ncritical safety concerns. This paper introduces the concept of collaborative\nreinforcement learning (RL) to generate challenging test cases for AV planning\nand decision-making module. One of the critical challenges for collaborative RL\nis the credit assignment problem, where a proper assignment of rewards to\nmultiple agents interacting in the traffic scenario, considering all parameters\nand timing, turns out to be non-trivial. In order to address this challenge, we\npropose a novel potential-based reward-shaping approach inspired by\ncounterfactual analysis for solving the credit-assignment problem. The\nevaluation in a simulated environment demonstrates the superiority of our\nproposed approach against other methods using local and global rewards.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:41:06 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18381","submitter":"Yue Xu","authors":"Yue Xu, Yong-Lu Li, Kaitong Cui, Ziyu Wang, Cewu Lu, Yu-Wing Tai,\n  Chi-Keung Tang","title":"Distill Gold from Massive Ores: Efficient Dataset Distillation via\n  Critical Samples Selection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data-efficient learning has drawn significant attention, especially given the\ncurrent trend of large multi-modal models, where dataset distillation can be an\neffective solution. However, the dataset distillation process itself is still\nvery inefficient. In this work, we model the distillation problem with\nreference to information theory. Observing that severe data redundancy exists\nin dataset distillation, we argue to put more emphasis on the utility of the\ntraining samples. We propose a family of methods to exploit the most valuable\nsamples, which is validated by our comprehensive analysis of the optimal data\nselection. The new strategy significantly reduces the training cost and extends\na variety of existing distillation algorithms to larger and more diversified\ndatasets, e.g. in some cases only 0.04% training data is sufficient for\ncomparable distillation performance. Moreover, our strategy consistently\nenhances the performance, which may open up new analyses on the dynamics of\ndistillation and networks. Our method is able to extend the distillation\nalgorithms to much larger-scale datasets and more heterogeneous datasets, e.g.\nImageNet-1K and Kinetics-400. Our code will be made publicly available.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:53:41 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18382","submitter":"Zahra Atashgahi","authors":"Zahra Atashgahi, Mykola Pechenizkiy, Raymond Veldhuis, Decebal\n  Constantin Mocanu","title":"Adaptive Sparsity Level during Training for Efficient Time Series\n  Forecasting with Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Efficient time series forecasting has become critical for real-world\napplications, particularly with deep neural networks (DNNs). Efficiency in DNNs\ncan be achieved through sparse connectivity and reducing the model size.\nHowever, finding the sparsity level automatically during training remains a\nchallenging task due to the heterogeneity in the loss-sparsity tradeoffs across\nthe datasets. In this paper, we propose \\enquote{\\textbf{P}runing with\n\\textbf{A}daptive \\textbf{S}parsity \\textbf{L}evel} (\\textbf{PALS}), to\nautomatically seek an optimal balance between loss and sparsity, all without\nthe need for a predefined sparsity level. PALS draws inspiration from both\nsparse training and during-training methods. It introduces the novel \"expand\"\nmechanism in training sparse neural networks, allowing the model to dynamically\nshrink, expand, or remain stable to find a proper sparsity level. In this\npaper, we focus on achieving efficiency in transformers known for their\nexcellent time series forecasting performance but high computational cost.\nNevertheless, PALS can be applied directly to any DNN. In the scope of these\narguments, we demonstrate its effectiveness also on the DLinear model.\nExperimental results on six benchmark datasets and five state-of-the-art\ntransformer variants show that PALS substantially reduces model size while\nmaintaining comparable performance to the dense model. More interestingly, PALS\neven outperforms the dense model, in 12 and 14 cases out of 30 cases in terms\nof MSE and MAE loss, respectively, while reducing 65% parameter count and 63%\nFLOPs on average. Our code will be publicly available upon acceptance of the\npaper.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 06:57:27 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18383","submitter":"Yefan Zhou","authors":"Yefan Zhou, Yaoqing Yang, Arin Chang, Michael W. Mahoney","title":"A Three-regime Model of Network Pruning","comments":"ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent work has highlighted the complex influence training hyperparameters,\ne.g., the number of training epochs, can have on the prunability of machine\nlearning models. Perhaps surprisingly, a systematic approach to predict\nprecisely how adjusting a specific hyperparameter will affect prunability\nremains elusive. To address this gap, we introduce a phenomenological model\ngrounded in the statistical mechanics of learning. Our approach uses\ntemperature-like and load-like parameters to model the impact of neural network\n(NN) training hyperparameters on pruning performance. A key empirical result we\nidentify is a sharp transition phenomenon: depending on the value of a\nload-like parameter in the pruned model, increasing the value of a\ntemperature-like parameter in the pre-pruned model may either enhance or impair\nsubsequent pruning performance. Based on this transition, we build a\nthree-regime model by taxonomizing the global structure of the pruned NN loss\nlandscape. Our model reveals that the dichotomous effect of high temperature is\nassociated with transitions between distinct types of global structures in the\npost-pruned model. Based on our results, we present three case-studies: 1)\ndetermining whether to increase or decrease a hyperparameter for improved\npruning; 2) selecting the best model to prune from a family of models; and 3)\ntuning the hyperparameter of the Sharpness Aware Minimization method for better\npruning performance.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:09:25 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18384","submitter":"Yiqi Zhong","authors":"Yiqi Zhong, Xianming Liu, Deming Zhai, Junjun Jiang, Xiangyang Ji","title":"Backdoor Attacks Against Incremental Learners: An Empirical Evaluation\n  Study","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large amounts of incremental learning algorithms have been proposed to\nalleviate the catastrophic forgetting issue arises while dealing with\nsequential data on a time series. However, the adversarial robustness of\nincremental learners has not been widely verified, leaving potential security\nrisks. Specifically, for poisoning-based backdoor attacks, we argue that the\nnature of streaming data in IL provides great convenience to the adversary by\ncreating the possibility of distributed and cross-task attacks -- an adversary\ncan affect \\textbf{any unknown} previous or subsequent task by data poisoning\n\\textbf{at any time or time series} with extremely small amount of backdoor\nsamples injected (e.g., $0.1\\%$ based on our observations). To attract the\nattention of the research community, in this paper, we empirically reveal the\nhigh vulnerability of 11 typical incremental learners against poisoning-based\nbackdoor attack on 3 learning scenarios, especially the cross-task\ngeneralization effect of backdoor knowledge, while the poison ratios range from\n$5\\%$ to as low as $0.1\\%$. Finally, the defense mechanism based on activation\nclustering is found to be effective in detecting our trigger pattern to\nmitigate potential security risks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:17:48 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18385","submitter":"Yurui Lai","authors":"Yurui Lai, Taiyan Zhang, Rui Fan","title":"Self-attention Dual Embedding for Graphs with Heterophily","comments":"9 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph Neural Networks (GNNs) have been highly successful for the node\nclassification task. GNNs typically assume graphs are homophilic, i.e.\nneighboring nodes are likely to belong to the same class. However, a number of\nreal-world graphs are heterophilic, and this leads to much lower classification\naccuracy using standard GNNs. In this work, we design a novel GNN which is\neffective for both heterophilic and homophilic graphs. Our work is based on\nthree main observations. First, we show that node features and graph topology\nprovide different amounts of informativeness in different graphs, and therefore\nthey should be encoded independently and prioritized in an adaptive manner.\nSecond, we show that allowing negative attention weights when propagating graph\ntopology information improves accuracy. Finally, we show that asymmetric\nattention weights between nodes are helpful. We design a GNN which makes use of\nthese observations through a novel self-attention mechanism. We evaluate our\nalgorithm on real-world graphs containing thousands to millions of nodes and\nshow that we achieve state-of-the-art results compared to existing GNNs. We\nalso analyze the effectiveness of the main components of our design on\ndifferent graphs.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:38:28 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18386","submitter":"Tanishk Nandal","authors":"Tanishk Nandal, Vaibhav Fulara, Raj Kumar Singh","title":"A Synergistic Framework Leveraging Autoencoders and Generative\n  Adversarial Networks for the Synthesis of Computational Fluid Dynamics\n  Results in Aerofoil Aerodynamics","comments":"9 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the realm of computational fluid dynamics (CFD), accurate prediction of\naerodynamic behaviour plays a pivotal role in aerofoil design and optimization.\nThis study proposes a novel approach that synergistically combines autoencoders\nand Generative Adversarial Networks (GANs) for the purpose of generating CFD\nresults. Our innovative framework harnesses the intrinsic capabilities of\nautoencoders to encode aerofoil geometries into a compressed and informative\n20-length vector representation. Subsequently, a conditional GAN network\nadeptly translates this vector into precise pressure-distribution plots,\naccounting for fixed wind velocity, angle of attack, and turbulence level\nspecifications. The training process utilizes a meticulously curated dataset\nacquired from JavaFoil software, encompassing a comprehensive range of aerofoil\ngeometries. The proposed approach exhibits profound potential in reducing the\ntime and costs associated with aerodynamic prediction, enabling efficient\nevaluation of aerofoil performance. The findings contribute to the advancement\nof computational techniques in fluid dynamics and pave the way for enhanced\ndesign and optimization processes in aerodynamics.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 09:46:18 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18387","submitter":"Mohammad Lataifeh","authors":"Mohammad Lataifeh, Xavier Carrasco, Ashraf Elnagar, Naveed Ahmed","title":"Augmenting Character Designers Creativity Using Generative Adversarial\n  Networks","comments":"18 pages","journal-ref":"Preprint- ICR'23 - The Second International Conference on\n  Innovations in Computing Research, 2023","doi":null,"report-no":null,"categories":"cs.HC cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Recent advances in Generative Adversarial Networks (GANs) continue to attract\nthe attention of researchers in different fields due to the wide range of\napplications devised to take advantage of their key features. Most recent GANs\nare focused on realism, however, generating hyper-realistic output is not a\npriority for some domains, as in the case of this work. The generated outcomes\nare used here as cognitive components to augment character designers creativity\nwhile conceptualizing new characters for different multimedia projects. To\nselect the best-suited GANs for such a creative context, we first present a\ncomparison between different GAN architectures and their performance when\ntrained from scratch on a new visual characters dataset using a single Graphics\nProcessing Unit. We also explore alternative techniques, such as transfer\nlearning and data augmentation, to overcome computational resource limitations,\na challenge faced by many researchers in the domain. Additionally, mixed\nmethods are used to evaluate the cognitive value of the generated visuals on\ncharacter designers agency conceptualizing new characters. The results\ndiscussed proved highly effective for this context, as demonstrated by early\nadaptations to the characters design process. As an extension for this work,\nthe presented approach will be further evaluated as a novel co-design process\nbetween humans and machines to investigate where and how the generated concepts\nare interacting with and influencing the design process outcome.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:52:03 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18388","submitter":"Mark Rowland","authors":"Mark Rowland, Yunhao Tang, Clare Lyle, R\\'emi Munos, Marc G.\n  Bellemare, Will Dabney","title":"The Statistical Benefits of Quantile Temporal-Difference Learning for\n  Value Estimation","comments":"ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the problem of temporal-difference-based policy evaluation in\nreinforcement learning. In particular, we analyse the use of a distributional\nreinforcement learning algorithm, quantile temporal-difference learning (QTD),\nfor this task. We reach the surprising conclusion that even if a practitioner\nhas no interest in the return distribution beyond the mean, QTD (which learns\npredictions about the full distribution of returns) may offer performance\nsuperior to approaches such as classical TD learning, which predict only the\nmean return, even in the tabular setting.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:52:46 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18389","submitter":"Mansour Zoubeirou A Mayaki","authors":"Mansour Zoubeirou A Mayaki and Michel Riveill","title":"AnoRand: A Semi Supervised Deep Learning Anomaly Detection Method by\n  Random Labeling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Anomaly detection or more generally outliers detection is one of the most\npopular and challenging subject in theoretical and applied machine learning.\nThe main challenge is that in general we have access to very few labeled data\nor no labels at all. In this paper, we present a new semi-supervised anomaly\ndetection method called \\textbf{AnoRand} by combining a deep learning\narchitecture with random synthetic label generation. The proposed architecture\nhas two building blocks: (1) a noise detection (ND) block composed of feed\nforward ferceptron and (2) an autoencoder (AE) block. The main idea of this new\narchitecture is to learn one class (e.g. the majority class in case of anomaly\ndetection) as well as possible by taking advantage of the ability of auto\nencoders to represent data in a latent space and the ability of Feed Forward\nPerceptron (FFP) to learn one class when the data is highly imbalanced. First,\nwe create synthetic anomalies by randomly disturbing (add noise) few samples\n(e.g. 2\\%) from the training set. Second, we use the normal and the synthetic\nsamples as input to our model. We compared the performance of the proposed\nmethod to 17 state-of-the-art unsupervised anomaly detection method on\nsynthetic datasets and 57 real-world datasets. Our results show that this new\nmethod generally outperforms most of the state-of-the-art methods and has the\nbest performance (AUC ROC and AUC PR) on the vast majority of reference\ndatasets. We also tested our method in a supervised way by using the actual\nlabels to train the model. The results show that it has very good performance\ncompared to most of state-of-the-art supervised algorithms.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:53:34 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18390","submitter":"Zhengyan Zhang","authors":"Zhengyan Zhang, Zhiyuan Zeng, Yankai Lin, Chaojun Xiao, Xiaozhi Wang,\n  Xu Han, Zhiyuan Liu, Ruobing Xie, Maosong Sun, Jie Zhou","title":"Emergent Modularity in Pre-trained Transformers","comments":"Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work examines the presence of modularity in pre-trained Transformers, a\nfeature commonly found in human brains and thought to be vital for general\nintelligence. In analogy to human brains, we consider two main characteristics\nof modularity: (1) functional specialization of neurons: we evaluate whether\neach neuron is mainly specialized in a certain function, and find that the\nanswer is yes. (2) function-based neuron grouping: we explore finding a\nstructure that groups neurons into modules by function, and each module works\nfor its corresponding function. Given the enormous amount of possible\nstructures, we focus on Mixture-of-Experts as a promising candidate, which\npartitions neurons into experts and usually activates different experts for\ndifferent inputs. Experimental results show that there are functional experts,\nwhere clustered are the neurons specialized in a certain function. Moreover,\nperturbing the activations of functional experts significantly affects the\ncorresponding function. Finally, we study how modularity emerges during\npre-training, and find that the modular structure is stabilized at the early\nstage, which is faster than neuron stabilization. It suggests that Transformers\nfirst construct the modular structure and then learn fine-grained neuron\nfunctions. Our code and data are available at\nhttps://github.com/THUNLP/modularity-analysis.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:02:32 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18391","submitter":"Vasiliki Kougia","authors":"Vasiliki Kougia, Simon Fetzel, Thomas Kirchmair, Erion \\c{C}ano, Sina\n  Moayed Baharlou, Sahand Sharifzadeh, Benjamin Roth","title":"MemeGraphs: Linking Memes to Knowledge Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Memes are a popular form of communicating trends and ideas in social media\nand on the internet in general, combining the modalities of images and text.\nThey can express humor and sarcasm but can also have offensive content.\nAnalyzing and classifying memes automatically is challenging since their\ninterpretation relies on the understanding of visual elements, language, and\nbackground knowledge. Thus, it is important to meaningfully represent these\nsources and the interaction between them in order to classify a meme as a\nwhole. In this work, we propose to use scene graphs, that express images in\nterms of objects and their visual relations, and knowledge graphs as structured\nrepresentations for meme classification with a Transformer-based architecture.\nWe compare our approach with ImgBERT, a multimodal model that uses only learned\n(instead of structured) representations of the meme, and observe consistent\nimprovements. We further provide a dataset with human graph annotations that we\ncompare to automatically generated graphs and entity linking. Analysis shows\nthat automatic methods link more entities than human annotators and that\nautomatically generated graphs are better suited for hatefulness classification\nin memes.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:17:30 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18392","submitter":"Kwanghee Choi","authors":"Eun Jung Yeo, Kwanghee Choi, Sunhee Kim, Minhwa Chung","title":"Speech Intelligibility Assessment of Dysarthric Speech by using Goodness\n  of Pronunciation with Uncertainty Quantification","comments":"Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper proposes an improved Goodness of Pronunciation (GoP) that utilizes\nUncertainty Quantification (UQ) for automatic speech intelligibility assessment\nfor dysarthric speech. Current GoP methods rely heavily on neural\nnetwork-driven overconfident predictions, which is unsuitable for assessing\ndysarthric speech due to its significant acoustic differences from healthy\nspeech. To alleviate the problem, UQ techniques were used on GoP by 1)\nnormalizing the phoneme prediction (entropy, margin, maxlogit, logit-margin)\nand 2) modifying the scoring function (scaling, prior normalization). As a\nresult, prior-normalized maxlogit GoP achieves the best performance, with a\nrelative increase of 5.66%, 3.91%, and 23.65% compared to the baseline GoP for\nEnglish, Korean, and Tamil, respectively. Furthermore, phoneme analysis is\nconducted to identify which phoneme scores significantly correlate with\nintelligibility scores in each language.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 11:48:36 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18393","submitter":"Stephan Rabanser","authors":"Stephan Rabanser, Anvith Thudi, Abhradeep Thakurta, Krishnamurthy\n  Dvijotham, Nicolas Papernot","title":"Training Private Models That Know What They Don't Know","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Training reliable deep learning models which avoid making overconfident but\nincorrect predictions is a longstanding challenge. This challenge is further\nexacerbated when learning has to be differentially private: protection provided\nto sensitive data comes at the price of injecting additional randomness into\nthe learning process. In this work, we conduct a thorough empirical\ninvestigation of selective classifiers -- that can abstain when they are unsure\n-- under a differential privacy constraint. We find that several popular\nselective prediction approaches are ineffective in a differentially private\nsetting as they increase the risk of privacy leakage. At the same time, we\nidentify that a recent approach that only uses checkpoints produced by an\noff-the-shelf private learning algorithm stands out as particularly suitable\nunder DP. Further, we show that differential privacy does not just harm utility\nbut also degrades selective classification performance. To analyze this effect\nacross privacy levels, we propose a novel evaluation mechanism which isolate\nselective prediction performance across model utility levels. Our experimental\nresults show that recovering the performance level attainable by non-private\nmodels is possible but comes at a considerable coverage cost as the privacy\nbudget decreases.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:20:07 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18394","submitter":"Sebastian Scott","authors":"Matthias J. Ehrhardt, Silvia Gazzola and Sebastian J. Scott\n  (Department of Mathematical Sciences, University of Bath, Bath, UK)","title":"On Optimal Regularization Parameters via Bilevel Learning","comments":"26 pages, 6 figures. Fixed typos in the header and Lemma 3","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Variational regularization is commonly used to solve linear inverse problems,\nand involves augmenting a data fidelity by a regularizer. The regularizer is\nused to promote a priori information, and is weighted by a regularization\nparameter. Selection of an appropriate regularization parameter is critical,\nwith various choices leading to very different reconstructions. Existing\nstrategies such as the discrepancy principle and L-curve can be used to\ndetermine a suitable parameter value, but in recent years a supervised machine\nlearning approach called bilevel learning has been employed. Bilevel learning\nis a powerful framework to determine optimal parameters, and involves solving a\nnested optimisation problem. While previous strategies enjoy various\ntheoretical results, the well-posedness of bilevel learning in this setting is\nstill a developing field. One necessary property is positivity of the\ndetermined regularization parameter. In this work, we provide a new condition\nthat better characterises positivity of optimal regularization parameters than\nthe existing theory. Numerical results verify and explore this new condition\nfor both small and large dimensional problems.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 12:34:07 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 04:35:03 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.18395","submitter":"Minki Kang","authors":"Minki Kang, Seanie Lee, Jinheon Baek, Kenji Kawaguchi, Sung Ju Hwang","title":"Knowledge-Augmented Reasoning Distillation for Small Language Models in\n  Knowledge-Intensive Tasks","comments":"Preprint. Under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large Language Models (LLMs) have shown promising performance in\nknowledge-intensive reasoning tasks that require a compound understanding of\nknowledge. However, deployment of the LLMs in real-world applications can be\nchallenging due to their high computational requirements and concerns on data\nprivacy. Previous studies have focused on building task-specific small language\nmodels (LMs) by fine-tuning them with labeled data or distilling LLMs. However,\nthese approaches are ill-suited for knowledge-intensive reasoning tasks due to\nthe limited capacity of small LMs in memorizing the knowledge required.\nMotivated by our theoretical analysis on memorization, we propose\nKnowledge-Augmented Reasoning Distillation (KARD), a novel method that\nfine-tunes small LMs to generate rationales with augmented knowledge retrieved\nfrom an external knowledge base. Moreover, we further propose a neural reranker\nto obtain documents relevant to rationale generation. We empirically show that\nKARD significantly improves the performance of small T5 and Flan-T5 models on\nthe challenging knowledge-intensive reasoning datasets, namely MedQA-USMLE and\nStrategyQA. Notably, our method makes the 250M models achieve superior\nperformance against the fine-tuned 3B models, having 12 times larger\nparameters, on both MedQA-USMLE and StrategyQA benchmarks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:00:00 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18396","submitter":"Xuanqi Liu","authors":"Xuanqi Liu and Zhuotao Liu","title":"LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly\n  Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL cs.CR","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Prior works have attempted to build private inference frameworks for\ntransformer-based large language models (LLMs) in a server-client setting,\nwhere the server holds the model parameters and the client inputs the private\ndata for inference. However, these frameworks impose significant overhead when\nthe private inputs are forward propagated through the original LLMs. In this\npaper, we show that substituting the computation- and communication-heavy\noperators in the transformer architecture with privacy-computing friendly\napproximations can greatly reduce the private inference costs with minor impact\non model performance. Compared to the state-of-the-art Iron (NeurIPS 2022), our\nprivacy-computing friendly model inference pipeline achieves a $5\\times$\nacceleration in computation and an 80\\% reduction in communication overhead,\nwhile retaining nearly identical accuracy.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:08:13 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18397","submitter":"Aysun Bozanta","authors":"Aysun Bozanta, Fuad Bayrak, Ayse Basar","title":"Prediction of the 2023 Turkish Presidential Election Results Using\n  Social Media Data","comments":"25 pages, 7 tables, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Social media platforms influence the way political campaigns are run and\ntherefore they have become an increasingly important tool for politicians to\ndirectly interact with citizens. Previous elections in various countries have\nshown that social media data may significantly impact election results. In this\nstudy, we aim to predict the vote shares of parties participating in the 2023\nelections in Turkey by combining social media data from various platforms\ntogether with traditional polling data. Our approach is a volume-based approach\nthat considers the number of social media interactions rather than content. We\ncompare several prediction models across varying time windows. Our results show\nthat for all time windows, the ARIMAX model outperforms the other algorithms.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:17:51 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18398","submitter":"Manuel Brack","authors":"Manuel Brack, Felix Friedrich, Patrick Schramowski, Kristian Kersting","title":"Mitigating Inappropriateness in Image Generation: Can there be Value in\n  Reflecting the World's Ugliness?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-conditioned image generation models have recently achieved astonishing\nresults in image quality and text alignment and are consequently employed in a\nfast-growing number of applications. Since they are highly data-driven, relying\non billion-sized datasets randomly scraped from the web, they also reproduce\ninappropriate human behavior. Specifically, we demonstrate inappropriate\ndegeneration on a large-scale for various generative text-to-image models, thus\nmotivating the need for monitoring and moderating them at deployment. To this\nend, we evaluate mitigation strategies at inference to suppress the generation\nof inappropriate content. Our findings show that we can use models'\nrepresentations of the world's ugliness to align them with human preferences.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 13:35:50 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18399","submitter":"Amir Joudaki","authors":"Amir Joudaki, Hadi Daneshmand, Francis Bach","title":"On the impact of activation and normalization in obtaining isometric\n  embeddings at initialization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we explore the structure of the penultimate Gram matrix in\ndeep neural networks, which contains the pairwise inner products of outputs\ncorresponding to a batch of inputs. In several architectures it has been\nobserved that this Gram matrix becomes degenerate with depth at initialization,\nwhich dramatically slows training. Normalization layers, such as batch or layer\nnormalization, play a pivotal role in preventing the rank collapse issue.\nDespite promising advances, the existing theoretical results (i) do not extend\nto layer normalization, which is widely used in transformers, (ii) can not\ncharacterize the bias of normalization quantitatively at finite depth.\n  To bridge this gap, we provide a proof that layer normalization, in\nconjunction with activation layers, biases the Gram matrix of a multilayer\nperceptron towards isometry at an exponential rate with depth at\ninitialization. We quantify this rate using the Hermite expansion of the\nactivation function, highlighting the importance of higher order ($\\ge 2$)\nHermite coefficients in the bias towards isometry.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:45:11 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18400","submitter":"Xiaojin Zhang","authors":"Xiaojin Zhang, Yan Kang, Lixin Fan, Kai Chen, Qiang Yang","title":"A Meta-learning Framework for Tuning Parameters of Protection Mechanisms\n  in Trustworthy Federated Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Trustworthy Federated Learning (TFL) typically leverages protection\nmechanisms to guarantee privacy. However, protection mechanisms inevitably\nintroduce utility loss or efficiency reduction while protecting data privacy.\nTherefore, protection mechanisms and their parameters should be carefully\nchosen to strike an optimal tradeoff between \\textit{privacy leakage},\n\\textit{utility loss}, and \\textit{efficiency reduction}. To this end,\nfederated learning practitioners need tools to measure the three factors and\noptimize the tradeoff between them to choose the protection mechanism that is\nmost appropriate to the application at hand. Motivated by this requirement, we\npropose a framework that (1) formulates TFL as a problem of finding a\nprotection mechanism to optimize the tradeoff between privacy leakage, utility\nloss, and efficiency reduction and (2) formally defines bounded measurements of\nthe three factors. We then propose a meta-learning algorithm to approximate\nthis optimization problem and find optimal protection parameters for\nrepresentative protection mechanisms, including Randomization, Homomorphic\nEncryption, Secret Sharing, and Compression. We further design estimation\nalgorithms to quantify these found optimal protection parameters in a practical\nhorizontal federated learning setting and provide a theoretical analysis of the\nestimation error.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:01:18 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 13:28:22 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.18401","submitter":"Jawad Ettayb","authors":"Jawad Ettayb","title":"Condition pseudospectrum of operator pencils on non-archimedean Banach\n  spaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper deals with the condition pseudospectrum and essential condition\npseudospectrum of operator pencils on n.a Banach spaces. We give a\ncharacterization of the condition pseudospectrum of operator pencils on n.a\nBanach spaces, the relation between the condition pseudospectrum of $(A,B)$ and\nthe usual spectrum in a n.a valued field is investigated. Finally, we give a\ncharacterization of the essential spectrum of $(A,B)$ where $A\\neq B$ by means\nof n.a completely continuous operators and we give some examples.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:09:52 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18402","submitter":"Shreyas Malakarjun Patil","authors":"Shreyas Malakarjun Patil, Loizos Michael, Constantine Dovrolis","title":"Neural Sculpting: Uncovering hierarchically modular task structure\n  through pruning and network analysis","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Natural target functions and tasks typically exhibit hierarchical modularity\n- they can be broken down into simpler sub-functions that are organized in a\nhierarchy. Such sub-functions have two important features: they have a distinct\nset of inputs (input-separability) and they are reused as inputs higher in the\nhierarchy (reusability). Previous studies have established that hierarchically\nmodular neural networks, which are inherently sparse, offer benefits such as\nlearning efficiency, generalization, multi-task learning, and transferability.\nHowever, identifying the underlying sub-functions and their hierarchical\nstructure for a given task can be challenging. The high-level question in this\nwork is: if we learn a task using a sufficiently deep neural network, how can\nwe uncover the underlying hierarchy of sub-functions in that task? As a\nstarting point, we examine the domain of Boolean functions, where it is easier\nto determine whether a task is hierarchically modular. We propose an approach\nbased on iterative unit and edge pruning (during training), combined with\nnetwork analysis for module detection and hierarchy inference. Finally, we\ndemonstrate that this method can uncover the hierarchical modularity of a wide\nrange of Boolean functions and two vision tasks based on the MNIST digits\ndataset.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:12:32 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 03:38:02 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.18403","submitter":"Mingyang Zhang","authors":"Mingyang Zhang and Hao Chen and Chunhua Shen and Zhen Yang and Linlin\n  Ou and Xinyi Yu and Bohan Zhuang","title":"Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large pre-trained models (LPMs), such as LLaMA and ViT-G, have shown\nexceptional performance across various tasks. Although parameter-efficient\nfine-tuning (PEFT) has emerged to cheaply fine-tune these large models on\ndownstream tasks, their deployment is still hindered by the vast model scale\nand computational costs. Neural network pruning offers a solution for model\ncompression by removing redundant parameters, but most existing methods rely on\ncomputing parameter gradients. However, obtaining the gradients is\ncomputationally prohibitive for LPMs, which necessitates the exploration of\nalternative approaches. To this end, we propose a unified framework for\nefficient fine-tuning and deployment of LPMs, termed LoRAPrune. We first design\na PEFT-aware pruning criterion, which utilizes the values and gradients of\nLow-Rank Adaption (LoRA), rather than the gradients of pre-trained parameters\nfor importance estimation. We then propose an iterative pruning procedure to\nremove redundant parameters while maximizing the advantages of PEFT. Thus, our\nLoRAPrune delivers an accurate, compact model for efficient inference in a\nhighly cost-effective manner. Experimental results on various tasks demonstrate\nthat our method achieves state-of-the-art results. For instance, in the VTAB-1k\nbenchmark, LoRAPrune utilizes only 0.76% of the trainable parameters and\noutperforms magnitude and movement pruning methods by a significant margin,\nachieving a mean Top-1 accuracy that is 5.7% and 4.3% higher, respectively.\nMoreover, our approach achieves comparable performance to PEFT methods,\nhighlighting its efficacy in delivering high-quality results while benefiting\nfrom the advantages of pruning.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:15:48 GMT"},{"version":"v2","created":"Wed, 31 May 2023 22:32:19 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.18404","submitter":"Bhawesh Kumar","authors":"Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy,\n  Ramesh Raskar, Andrew Beam","title":"Conformal Prediction with Large Language Models for Multi-Choice\n  Question Answering","comments":"Added additional references","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As large language models continue to be widely developed, robust uncertainty\nquantification techniques will become crucial for their safe deployment in\nhigh-stakes scenarios. In this work, we explore how conformal prediction can be\nused to provide uncertainty quantification in language models for the specific\ntask of multiple-choice question-answering. We find that the uncertainty\nestimates from conformal prediction are tightly correlated with prediction\naccuracy. This observation can be useful for downstream applications such as\nselective classification and filtering out low-quality predictions. We also\ninvestigate the exchangeability assumption required by conformal prediction to\nout-of-subject questions, which may be a more realistic scenario for many\npractical applications. Our work contributes towards more trustworthy and\nreliable usage of large language models in safety-critical situations, where\nrobust guarantees of error rate are required.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:26:10 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 09:46:27 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.18405","submitter":"Yue Liu","authors":"Yue Liu, Ke Liang, Jun Xia, Sihang Zhou, Xihong Yang, Xinwang Liu,\n  Stan Z. Li","title":"Dink-Net: Neural Clustering on Large Graphs","comments":"18 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep graph clustering, which aims to group the nodes of a graph into disjoint\nclusters with deep neural networks, has achieved promising progress in recent\nyears. However, the existing methods fail to scale to the large graph with\nmillion nodes. To solve this problem, a scalable deep graph clustering method\n(Dink-Net) is proposed with the idea of dilation and shrink. Firstly, by\ndiscriminating nodes, whether being corrupted by augmentations, representations\nare learned in a self-supervised manner. Meanwhile, the cluster centres are\ninitialized as learnable neural parameters. Subsequently, the clustering\ndistribution is optimized by minimizing the proposed cluster dilation loss and\ncluster shrink loss in an adversarial manner. By these settings, we unify the\ntwo-step clustering, i.e., representation learning and clustering optimization,\ninto an end-to-end framework, guiding the network to learn clustering-friendly\nfeatures. Besides, Dink-Net scales well to large graphs since the designed loss\nfunctions adopt the mini-batch data to optimize the clustering distribution\neven without performance drops. Both experimental results and theoretical\nanalyses demonstrate the superiority of our method. Compared to the runner-up,\nDink-Net achieves 9.62% NMI improvement on the ogbn-papers100M dataset with 111\nmillion nodes and 1.6 billion edges. The source code is released at\nhttps://github.com/yueliu1999/Dink-Net. Besides, a collection (papers, codes,\nand datasets) of deep graph clustering is shared at\nhttps://github.com/yueliu1999/Awesome-Deep-Graph-Clustering.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:33:24 GMT"},{"version":"v2","created":"Wed, 31 May 2023 09:39:12 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.18406","submitter":"Tullio Traverso Dr.","authors":"Tullio Traverso, Francesco Coletti, Luca Magri, Tassos G. Karayiannis,\n  Omar K. Matar","title":"A machine learning approach to the prediction of heat-transfer\n  coefficients in micro-channels","comments":"7 pages, 2 figures, to be published in the proceedings of the 17th\n  International Heat Transfer Conference 2023 (IHTC-17)","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn cs.LG physics.data-an","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The accurate prediction of the two-phase heat transfer coefficient (HTC) as a\nfunction of working fluids, channel geometries and process conditions is key to\nthe optimal design and operation of compact heat exchangers. Advances in\nartificial intelligence research have recently boosted the application of\nmachine learning (ML) algorithms to obtain data-driven surrogate models for the\nHTC. For most supervised learning algorithms, the task is that of a nonlinear\nregression problem. Despite the fact that these models have been proven capable\nof outperforming traditional empirical correlations, they have key limitations\nsuch as overfitting the data, the lack of uncertainty estimation, and\ninterpretability of the results. To address these limitations, in this paper,\nwe use a multi-output Gaussian process regression (GPR) to estimate the HTC in\nmicrochannels as a function of the mass flow rate, heat flux, system pressure\nand channel diameter and length. The model is trained using the Brunel\nTwo-Phase Flow database of high-fidelity experimental data. The advantages of\nGPR are data efficiency, the small number of hyperparameters to be trained\n(typically of the same order of the number of input dimensions), and the\nautomatic trade-off between data fit and model complexity guaranteed by the\nmaximization of the marginal likelihood (Bayesian approach). Our paper proposes\nresearch directions to improve the performance of the GPR-based model in\nextrapolation.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:48:01 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18407","submitter":"Shengchao Liu","authors":"Shengchao Liu, Weitao Du, Zhiming Ma, Hongyu Guo, Jian Tang","title":"A Group Symmetric Stochastic Differential Equation Model for Molecule\n  Multi-modal Pretraining","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI q-bio.BM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Molecule pretraining has quickly become the go-to schema to boost the\nperformance of AI-based drug discovery. Naturally, molecules can be represented\nas 2D topological graphs or 3D geometric point clouds. Although most existing\npertaining methods focus on merely the single modality, recent research has\nshown that maximizing the mutual information (MI) between such two modalities\nenhances the molecule representation ability. Meanwhile, existing molecule\nmulti-modal pretraining approaches approximate MI based on the representation\nspace encoded from the topology and geometry, thus resulting in the loss of\ncritical structural information of molecules. To address this issue, we propose\nMoleculeSDE. MoleculeSDE leverages group symmetric (e.g., SE(3)-equivariant and\nreflection-antisymmetric) stochastic differential equation models to generate\nthe 3D geometries from 2D topologies, and vice versa, directly in the input\nspace. It not only obtains tighter MI bound but also enables prosperous\ndownstream tasks than the previous work. By comparing with 17 pretraining\nbaselines, we empirically verify that MoleculeSDE can learn an expressive\nrepresentation with state-of-the-art performance on 26 out of 32 downstream\ntasks.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:56:02 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18952","submitter":"Soyoung Yoon","authors":"Soyoung Yoon, Chaeeun Kim, Hyunji Lee, Joel Jang, Minjoon Seo","title":"Continually Updating Generative Retrieval on Dynamic Corpora","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generative retrieval has recently been gaining a lot of attention from the\nresearch community for its simplicity, high performance, and the ability to\nfully leverage the power of deep autoregressive models. However, prior work on\ngenerative retrieval has mostly investigated on static benchmarks, while\nrealistic retrieval applications often involve dynamic environments where\nknowledge is temporal and accumulated over time. In this paper, we introduce a\nnew benchmark called STREAMINGIR, dedicated to quantifying the generalizability\nof retrieval methods to dynamically changing corpora derived from StreamingQA,\nthat simulates realistic retrieval use cases. On this benchmark, we conduct an\nin-depth comparative evaluation of bi-encoder and generative retrieval in terms\nof performance as well as efficiency under varying degree of supervision. Our\nresults suggest that generative retrieval shows (1) detrimental performance\nwhen only supervised data is used for fine-tuning, (2) superior performance\nover bi-encoders when only unsupervised data is available, and (3) lower\nperformance to bi-encoders when both unsupervised and supervised data is used\ndue to catastrophic forgetting; nevertheless, we show that parameter-efficient\nmeasures can effectively mitigate the issue and result in competitive\nperformance and efficiency with respect to the bi-encoder baseline. Our results\nopen up a new potential for generative retrieval in practical dynamic\nenvironments. Our work will be open-sourced.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 16:05:00 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19147","submitter":"Lorenzo Baldassari","authors":"Lorenzo Baldassari, Ali Siahkoohi, Josselin Garnier, Knut Solna,\n  Maarten V. de Hoop","title":"Conditional score-based diffusion models for Bayesian inference in\n  infinite dimensions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.AP math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Since their first introduction, score-based diffusion models (SDMs) have been\nsuccessfully applied to solve a variety of linear inverse problems in\nfinite-dimensional vector spaces due to their ability to efficiently\napproximate the posterior distribution. However, using SDMs for inverse\nproblems in infinite-dimensional function spaces has only been addressed\nrecently and by learning the unconditional score. While this approach has some\nadvantages, depending on the specific inverse problem at hand, in order to\nsample from the conditional distribution it needs to incorporate the\ninformation from the observed data with a proximal optimization step, solving\nan optimization problem numerous times. This may not be feasible in inverse\nproblems with computationally costly forward operators. To address these\nlimitations, in this work we propose a method to learn the posterior\ndistribution in infinite-dimensional Bayesian linear inverse problems using\namortized conditional SDMs. In particular, we prove that the conditional\ndenoising estimator is a consistent estimator of the conditional score in\ninfinite dimensions. We show that the extension of SDMs to the conditional\nsetting requires some care because the conditional score typically blows up for\nsmall times contrarily to the unconditional score. We also discuss the\nrobustness of the learned distribution against perturbations of the\nobservations. We conclude by presenting numerical examples that validate our\napproach and provide additional insights.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:34:15 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19148","submitter":"Yu Fei","authors":"Yu Fei, Yifan Hou, Zeming Chen, Antoine Bosselut","title":"Mitigating Label Biases for In-context Learning","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Various design settings for in-context learning (ICL), such as the choice and\norder of the in-context examples, can bias the model's predictions. While many\nstudies discuss these design choices, there have been few systematic\ninvestigations into categorizing them and mitigating their impact. In this\nwork, we define a typology for three types of label biases in ICL for text\nclassification: vanilla-label bias, context-label bias, and domain-label bias\n(which we conceptualize and detect for the first time). Our analysis\ndemonstrates that prior label bias calibration methods fall short of addressing\nall three types of biases. Specifically, domain-label bias restricts LLMs to\nrandom-level performance on many tasks regardless of the choice of in-context\nexamples. To mitigate the effect of these biases, we propose a simple bias\ncalibration method that estimates a language model's label bias using random\nin-domain words from the task corpus. After controlling for this estimated bias\nwhen making predictions, our novel domain-context calibration significantly\nimproves the ICL performance of GPT-J and GPT-3 on a wide range of tasks. The\ngain is substantial on tasks with large domain-label bias (up to 37% in\nMacro-F1). Furthermore, our results generalize to models with different scales,\npretraining methods, and manually-designed task instructions, showing the\nprevalence of label biases in ICL.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:37:39 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19156","submitter":"Jeffrey Kuan","authors":"Jeffrey Kuan","title":"An explicit central element of $\\mathcal{U}_q(\\mathfrak{so}_5)$ and its\n  corresponding quantum Hamiltonian","comments":"An accessible version of this PDF is available at:\n  https://www.math.tamu.edu/~jkuan/CentralElementB2_Accessible.pdf","journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA math-ph math.MP math.RT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  A previous paper of the author developed a general method for producing\nexplicit central elements of quantized Lie algebras using Lusztig's inner\nproduct. This method had previously been applied for the type $C_2$, $D_3$ and\n$D_4$ Lie algebras. The current paper repeats the calculation for the type\n$B_2$ Lie algebra, which is actually isomorphic to the $C_2$ Lie algebra. The\nexplicit expression for the corresponding quantum Hamiltonian is computed.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 18:23:28 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19283","submitter":"Nader Zare","authors":"Aref Sayareh, Nader Zare, Omid Amini, Arad Firouzkouhi, Mahtab\n  Sarvmaili, Stan Matwin","title":"Observation Denoising in CYRUS Soccer Simulation 2D Team For RoboCup\n  2023","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.RO","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The RoboCup competitions hold various leagues, and the Soccer Simulation 2D\nLeague is a major one among them. Soccer Simulation 2D (SS2D) match involves\ntwo teams, including 11 players and a coach, competing against each other. The\nplayers can only communicate with the Soccer Simulation Server during the game.\nThis paper presents the latest research of the CYRUS soccer simulation 2D team,\nthe champion of RoboCup 2021. We will explain our denoising idea powered by\nlong short-term memory networks (LSTM) and deep neural networks (DNN). The\nCYRUS team uses the CYRUS2D base code that was developed based on the Helios\nand Gliders bases.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:46:33 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.19284","submitter":"J. C. Phillips","authors":"J. C. Phillips","title":"Sequence Evolution, Structure and Dynamics of Transmembrane Proteins:\n  Rhodopsin","comments":"11 pages, 5 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.OT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Rhodopsin is a G-protein coupled receptor found in retinal rod cells, where\nit mediates monocrhromatic vision in dim light. It is one of the most studied\nproteins with thousands of reviewed entries in Uniprot. It has seven\ntransmembrane segments, here examined for their hydrophobic character, and how\nthat has evolved from chickens to humans. Elastic features associated with\nProline are also discussed. Finally, differences between rhodopsin and cone\nopsins are also discussed.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 14:56:03 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.19298","submitter":"Abdullah Ikram Ullah Tabassam Mr.","authors":"A. I. Ullah Tabassam","title":"MLOps: A Step Forward to Enterprise Machine Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine Learning Operations (MLOps) is becoming a highly crucial part of\nbusinesses looking to capitalize on the benefits of AI and ML models. This\nresearch presents a detailed review of MLOps, its benefits, difficulties,\nevolutions, and important underlying technologies such as MLOps frameworks,\nDocker, GitHub actions, and Kubernetes. The MLOps workflow, which includes\nmodel design, deployment, and operations, is explained in detail along with the\nvarious tools necessary for both model and data exploration and deployment.\nThis article also puts light on the end-to-end production of ML projects using\nvarious maturity levels of automated pipelines, with the least at no automation\nat all and the highest with complete CI/CD and CT capabilities. Furthermore, a\ndetailed example of an enterprise-level MLOps project for an object detection\nservice is used to explain the workflow of the technology in a real-world\nscenario. For this purpose, a web application hosting a pre-trained model from\nTensorFlow 2 Model Zoo is packaged and deployed to the internet making sure\nthat the system is scalable, reliable, and optimized for deployment at an\nenterprise level.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 20:44:14 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.20022","submitter":"Hristu Culetu","authors":"Hristu Culetu","title":"Geodesics in the conformally flat Eisenhart metric","comments":"5 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The (4+1) dimensional conformally flat Eisenhart geometry is investigated in\nthis letter, stressing the contribution of the stress tensor generating its\ncurvature. The null and timelike geodesics are computed in the pure\ncosmological case when the Eisenhart potential energy is $V(r) =\n-m\\omega^{2}r^{2}/2$, where $\\omega$ is related to the cosmological constant\n$\\Lambda$. Although the metric is curved, the radial null geodesics $R(T)$ and\n$Y(T)$ are straight lines, with finite $R_{max}$ and $Y_{max}$, $Y$ being the\n5th coordinate. In contrast, for a radial timelike geodesic, $Y_{max}\n\\rightarrow \\infty$ if $T \\rightarrow T_{max} = 1/\\omega$.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 15:16:52 GMT"}],"update_date":"2023-06-01"}
{"id":"2306.00005","submitter":"Tung Nguyen Thanh","authors":"Thanh-Tung Nguyen, Viktor Schlegel, Abhinav Kashyap, Stefan Winkler","title":"A Two-Stage Decoder for Efficient ICD Coding","comments":"Accepted to ACL'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Clinical notes in healthcare facilities are tagged with the International\nClassification of Diseases (ICD) code; a list of classification codes for\nmedical diagnoses and procedures. ICD coding is a challenging multilabel text\nclassification problem due to noisy clinical document inputs and long-tailed\nlabel distribution. Recent automated ICD coding efforts improve performance by\nencoding medical notes and codes with additional data and knowledge bases.\nHowever, most of them do not reflect how human coders generate the code: first,\nthe coders select general code categories and then look for specific\nsubcategories that are relevant to a patient's condition. Inspired by this, we\npropose a two-stage decoding mechanism to predict ICD codes. Our model uses the\nhierarchical properties of the codes to split the prediction into two steps: At\nfirst, we predict the parent code and then predict the child code based on the\nprevious prediction. Experiments on the public MIMIC-III data set show that our\nmodel performs well in single-model settings without external data or\nknowledge.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 17:25:13 GMT"}],"update_date":"2023-06-02"}
{"id":"2306.00835","submitter":"J. Xavier Prochaska","authors":"Angelina Agabin (1) and J. Xavier Prochaska (1) ((1) University of\n  California, Santa Cruz)","title":"Reconstructing Sea Surface Temperature Images: A Masked Autoencoder\n  Approach for Cloud Masking and Reconstruction","comments":"33 pages, 18 figures; Masters Thesis","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV physics.ao-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This thesis presents a new algorithm to mitigate cloud masking in the\nanalysis of sea surface temperature (SST) data generated by remote sensing\ntechnologies, e.g., Clouds interfere with the analysis of all remote sensing\ndata using wavelengths shorter than 12 microns, significantly limiting the\nquantity of usable data and creating a biased geographical distribution\n(towards equatorial and coastal regions). To address this issue, we propose an\nunsupervised machine learning algorithm called Enki which uses a Vision\nTransformer with Masked Autoencoding to reconstruct masked pixels. We train\nfour different models of Enki with varying mask ratios (t) of 10%, 35%, 50%,\nand 75% on the generated Ocean General Circulation Model (OGCM) dataset\nreferred to as LLC4320. To evaluate performance, we reconstruct a validation\nset of LLC4320 SST images with random ``clouds'' corrupting p=10%, 20%, 30%,\n40%, 50% of the images with individual patches of 4x4 pixel^2. We consistently\nfind that at all levels of p there is one or multiple models that reconstruct\nthe images with a mean RMSE of less than 0.03K, i.e. lower than the estimated\nsensor error of VIIRS data. Similarly, at the individual patch level, the\nreconstructions have RMSE 8x smaller than the fluctuations in the patch. And,\nas anticipated, reconstruction errors are larger for images with a higher\ndegree of complexity. Our analysis also reveals that patches along the image\nborder have systematically higher reconstruction error; we recommend ignoring\nthese in production. We conclude that Enki shows great promise to surpass\nin-painting as a means of reconstructing cloud masking. Future research will\ndevelop Enki to reconstruct real-world data.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 10:46:18 GMT"}],"update_date":"2023-06-02"}
{"id":"2306.01767","submitter":"Anuj Jakhar","authors":"Anuj Jakhar","title":"On Schur's irreducibility results and generalised $\\phi$-Hermite\n  polynomials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let $c$ be a fixed integer such that $c \\in \\{0,2\\}.$ Let $n$ be a positive\ninteger such that either $n\\geq 2$ or $2n+1 \\neq 3^u$ for any integer $u\\geq 2$\naccording as $c = 0$ or not. Let $\\phi(x)$ belonging to $\\mathbb{Z}[x]$ be a\nmonic polynomial which is irreducible modulo all primes less than $2n+c$. Let\n$a_i(x)$ with $0\\leq i\\leq n-1$ belonging to $\\mathbb{Z}[x]$ be polynomials\nhaving degree less than $\\deg\\phi(x)$. Let $a_n \\in \\mathbb{Z}$ and the content\nof $(a_na_0(x))$ is not divisible by any prime less than $2n+c$. For a positive\ninteger $j$, if $u_j$ denotes the product of the odd numbers $\\leq j$, then we\nshow that the polynomial\n$\\frac{a_{n}}{u_{2n+c}}\\phi(x)^{2n}+\\sum\\limits_{j=0}^{n-1}a_j(x)\\frac{\\phi(x)^{2j}}{u_{2j+c}}$\nis irreducible over the field $\\mathbb{Q}$ of rational numbers. This\ngeneralises a well-known result of Schur which states that the polynomial\n$\\sum\\limits_{j=0}^{n}a_j\\frac{x^{2j}}{u_{2j+c}}$ with $a_j \\in \\mathbb{Z}$ and\n$|a_0| = |a_n| = 1$ is irreducible over $\\mathbb{Q}$. We illustrate our result\nthrough examples.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:08:14 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.03294","submitter":"Anuj Jakhar","authors":"Anuj Jakhar, Ravi Kalwaniya","title":"An extension of a second irreducibility theorem of I. Schur","comments":"arXiv admin note: substantial text overlap with arXiv:2305.04781.\n  substantial text overlap with arXiv:2306.01767","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let $n \\neq 8$ be a positive integer such that $n+1 \\neq 2^u$ for any integer\n$u\\geq 2$. Let $\\phi(x)$ belonging to $\\mathbb{Z}[x]$ be a monic polynomial\nwhich is irreducible modulo all primes less than or equal to $n+1$. Let\n$a_j(x)$ with $0\\leq j\\leq n-1$ belonging to $\\mathbb{Z}[x]$ be polynomials\nhaving degree less than $\\deg\\phi(x)$. Assume that the content of $(a_na_0(x))$\nis not divisible by any prime less than or equal to $n+1$. In this paper, we\nprove that the polynomial $f(x) = a_n\\frac{\\phi(x)^n}{(n+1)!}+\n\\sum\\limits_{j=0}^{n-1}a_j(x)\\frac{\\phi(x)^{j}}{(j+1)!}$ is irreducible over\nthe field $\\mathbb{Q}$ of rational numbers. This generalises a well-known\nresult of Schur which states that the polynomial\n$\\sum\\limits_{j=0}^{n}a_j\\frac{x^{j}}{(j+1)!}$ with $a_j \\in \\mathbb{Z}$ and\n$|a_0| = |a_n| = 1$ is irreducible over $\\mathbb{Q}$. We illustrate our result\nthrough examples.\n","versions":[{"version":"v1","created":"Sun, 28 May 2023 08:10:57 GMT"}],"update_date":"2023-06-07"}
