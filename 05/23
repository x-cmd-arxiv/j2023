{"id":"2305.13172","submitter":"Ningyu Zhang","authors":"Yunzhi Yao, Peng Wang, Bozhong Tian, Siyuan Cheng, Zhoubo Li, Shumin\n  Deng, Huajun Chen, Ningyu Zhang","title":"Editing Large Language Models: Problems, Methods, and Opportunities","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advancements in deep learning have precipitated the emergence of large\nlanguage models (LLMs) which exhibit an impressive aptitude for understanding\nand producing text akin to human language. Despite the ability to train highly\ncapable LLMs, the methodology for maintaining their relevancy and rectifying\nerrors remains elusive. To that end, the past few years have witnessed a surge\nin techniques for editing LLMs, the objective of which is to alter the behavior\nof LLMs within a specific domain without negatively impacting performance\nacross other inputs. This paper embarks on a deep exploration of the problems,\nmethods, and opportunities relating to model editing for LLMs. In particular,\nwe provide an exhaustive overview of the task definition and challenges\nassociated with model editing, along with an in-depth empirical analysis of the\nmost progressive methods currently at our disposal. We also build a new\nbenchmark dataset to facilitate a more robust evaluation and pinpoint enduring\nissues intrinsic to existing techniques. Our objective is to provide valuable\ninsights into the effectiveness and feasibility of each model editing\ntechnique, thereby assisting the research community in making informed\ndecisions when choosing the most appropriate method for a specific task or\ncontext. Code and datasets will be available at\nhttps://github.com/zjunlp/EasyEdit.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:00:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13173","submitter":"Henghui Ding","authors":"Shuting He, Henghui Ding, Wei Jiang","title":"Semantic-Promoted Debiasing and Background Disambiguation for Zero-Shot\n  Instance Segmentation","comments":"CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Zero-shot instance segmentation aims to detect and precisely segment objects\nof unseen categories without any training samples. Since the model is trained\non seen categories, there is a strong bias that the model tends to classify all\nthe objects into seen categories. Besides, there is a natural confusion between\nbackground and novel objects that have never shown up in training. These two\nchallenges make novel objects hard to be raised in the final instance\nsegmentation results. It is desired to rescue novel objects from background and\ndominated seen categories. To this end, we propose D$^2$Zero with\nSemantic-Promoted Debiasing and Background Disambiguation to enhance the\nperformance of Zero-shot instance segmentation. Semantic-promoted debiasing\nutilizes inter-class semantic relationships to involve unseen categories in\nvisual feature training and learns an input-conditional classifier to conduct\ndynamical classification based on the input image. Background disambiguation\nproduces image-adaptive background representation to avoid mistaking novel\nobjects for background. Extensive experiments show that we significantly\noutperform previous state-of-the-art methods by a large margin, e.g., 16.86%\nimprovement on COCO. Project page: https://henghuiding.github.io/D2Zero/\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:00:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13174","submitter":"Javier Cuerda","authors":"Javier Cuerda, Jani M. Taskinen, Nicki K\\\"allman, Leo Grabitz, P\\\"aivi\n  T\\\"orm\\\"a","title":"Observation of Quantum metric and non-Hermitian Berry curvature in a\n  plasmonic lattice","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We experimentally observe the quantum geometric tensor, namely the quantum\nmetric and the Berry curvature, for a square lattice of radiatively coupled\nplasmonic nanoparticles. We observe a non-zero Berry curvature and show that it\narises solely from non-Hermitian effects. The quantum metric is found to\noriginate from a pseudospin-orbit coupling. The long-range nature of the\nradiative interaction renders the behavior distinct from tight-binding systems:\nBerry curvature and quantum metric are centered around high-symmetry lines of\nthe Brillouin zone instead of high-symmetry points. Our results inspire new\npathways in the design of topological systems by tailoring losses or gain.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:01:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13175","submitter":"Momose Oyama","authors":"Hiroaki Yamagiwa, Momose Oyama, Hidetoshi Shimodaira","title":"Discovering Universal Geometry in Embeddings with ICA","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This study employs Independent Component Analysis (ICA) to uncover universal\nproperties of embeddings of words or images. Our approach extracts independent\nsemantic components of embeddings, enabling each embedding to be represented as\na composition of intrinsic interpretable axes. We demonstrate that embeddings\ncan be expressed as a combination of a few axes and that these semantic axes\nare consistent across different languages, modalities, and embedding\nalgorithms. This discovery of universal properties in embeddings contributes to\nmodel interpretability, potentially facilitating the development of highly\ninterpretable models and the compression of large-scale models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:04:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13176","submitter":"Alexander Valov","authors":"A.V. Valov, E.V. Dontsov","title":"On the layer crossing problem for a semi-infinite hydraulic fracture","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph cs.CE cs.NA math.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper analyses the problem of a semi-infinite fluid-driven fracture\npropagating through multiple stress layers in a permeable elastic medium. Such\na problem represents the tip region of a planar hydraulic fracture. When the\nhydraulic fracture crosses a stress layer, the use of a standard tip asymptotic\nsolution may lead to a considerable reduction of accuracy, even for the\nsimplest case of a height-contained fracture. In this study, we propose three\napproaches to incorporate the effect of stress layers into the tip asymptote:\nnon-singular integral formulation, toughness-corrected asymptote, and an\nordinary differential equation approximation of the non-singular integral\nformulation mentioned above. As illustrated in the paper, these approaches for\nstress-corrected asymptotes differ in computational complexity, the complexity\nof implementation, and the accuracy of the approximation. In addition, the size\nof the validity region of the stress-corrected asymptote is evaluated, and it\nis shown to be greatly reduced relative to the case without layers. In order to\naddress the issue, the stress relaxation factor is introduced. This, in turn,\nallows for enhancing the accuracy of the layer-crossing computation on a\nrelatively coarse mesh to utilize the stress-corrected asymptote in hydraulic\nfracturing simulators for the purpose of front tracking.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:06:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13177","submitter":"Abhijit Bhattacharyya Prof.","authors":"Vineet Kumar, Prashant Shukla and Abhijit Bhattacharyya","title":"Production of bottomonia states in proton+proton and heavy-ion\n  collisions","comments":"arXiv admin note: substantial text overlap with arXiv:1010.5827,\n  arXiv:1001.5284 by other authors","journal-ref":"Progress in Particle and Nuclear Physics, 131 (2023) 104044","doi":"10.1016/j.ppnp.2023.104044","report-no":null,"categories":"hep-ph nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we review the experimental and theoretical developments of\nbottomonia production in proton+proton and heavy-ion collisions. The bottomonia\nproduction process is proving to be one of the most robust processes to\ninvestigate the fundamental aspects of Quantum Chromodynamics at both low and\nhigh temperatures. The LHC experiments in the last decade have produced large\nstatistics of bottomonia states in wide kinematic ranges in various collision\nsystems. The bottomonia have three $\\Upsilon$ S-states which are reconstructed\nin dilepton invariant mass channel with high mass resolution by LHC detectors\nand P-states are measured via their decay to S-states. We start with the\ndetails of measurements in proton+proton collisions and their understanding in\nterms of various effective theoretical models. Here we cover both the Tevatron\nand LHC measurements with $\\sqrt{s}$ spanning from 1.8 TeV to 13 TeV. The\nbottomonia states have particularly been very good probes to understand\nstrongly interacting matter produced in heavy-ion collisions. The Pb+Pb\ncollisions have been performed at $\\sqrt{s_{NN}}$ = 2.76 TeV and 5.02 TeV at\nLHC. This led to the detailed study of the modification of bottomonia yields as\na function of various observables and collision energy. At the same time, the\nimproved results of bottomonia production became available from RHIC\nexperiments which have proven to be useful for a quantitative comparison. A\nsystematic study of bottomonia production in p+p, p+Pb and Pb+Pb has been very\nuseful to understand the medium effects in these collision systems. We review\nsome of the (if not all the) models of bottomonia evolution due to various\nprocesses in a large dynamically evolving medium and discuss these in\ncomparison with the measurements.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:07:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13178","submitter":"Jiri Tolar","authors":"Miroslav Korbel\\'a\\v{r} and Ji\\v{r}\\'i Tolar","title":"Clifford group is not a semidirect product in dimensions $N$ divisible\n  by four","comments":"28 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The paper is devoted to projective Clifford groups of quantum $N$-dimensional\nsystems. Clearly, Clifford gates allow only the simplest quantum computations\nwhich can be simulated on a classical computer (Gottesmann-Knill theorem).\nHowever, it may serve as a cornerstone of full quantum computation. As to its\ngroup structure it is well-known that -- in $N$-dimensional quantum mechanics\n-- the Clifford group is a natural semidirect product provided the dimension\n$N$ is an odd number. For even $N$ special results on the Clifford groups are\nscattered in the mathematical literature, but they don't concern the semidirect\nstructure. Using appropriate group presentation of $SL(2,Z_N)$ it is proved\nthat for even $N$ projective Clifford groups are not natural semidirect\nproducts if and only if $N$ is divisible by four.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:07:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13179","submitter":"Aliakbar Nafar","authors":"Aliakbar Nafar, Kristen Brent Venable, Parisa Kordjamshidi","title":"Teaching Probabilistic Logical Reasoning to Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent research on transformer-based language models investigates their\nreasoning ability over logical rules expressed in natural language text.\nHowever, their logic is not yet well-understood as we cannot explain the\nabstractions made by the models that help them in reasoning. These models are\ncriticized for merely memorizing complex patterns in the data, which often\ncreates issues for their generalizability in unobserved situations. In this\nwork, we analyze the use of probabilistic logical rules in transformer-based\nlanguage models. In particular, we propose a new approach, Probabilistic\nConstraint Training (PCT), that explicitly models probabilistic logical\nreasoning by imposing the rules of reasoning as constraints during training. We\ncreate a new QA benchmark for evaluating probabilistic reasoning over uncertain\ntextual rules, which creates instance-specific rules, unlike the only existing\nrelevant benchmark. Experimental results show that our proposed technique\nimproves the base language models' accuracy and explainability when\nprobabilistic logical reasoning is required for question answering. Moreover,\nwe show that the learned probabilistic reasoning abilities are transferable to\nnovel situations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:08:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13180","submitter":"Juan Diego Soler","authors":"J. D. Soler and C. Zucker, J. E. G. Peek, M. Heyer, P. F. Goldsmith,\n  S. C. O. Glover, S. Molinari, R. S. Klessen, P. Hennebelle, L. Testi, T.\n  Colman, M. Benedettini, D. Elia, C. Mininni, S. Pezzuto, E. Schisano, A.\n  Traficante","title":"A panoptic view of the Taurus molecular cloud I. The cloud dynamics\n  revealed by gas emission and 3D dust","comments":"18 pages, 21 figures. Accepted for publication in Astronomy &\n  Astrophysics (22MAY2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a study of the three-dimensional (3D) distribution of interstellar\ndust derived from stellar extinction observations toward the Taurus molecular\ncloud (MC) and its relation with the neutral atomic hydrogen (HI) emission at\n21 cm wavelength and the carbon monoxide $^{12}$CO and $^{13}$CO emission in\nthe $J=1\\rightarrow0$ transition. We used the histogram of oriented gradients\n(HOG) method to match the morphology in a 3D reconstruction of the dust density\n(3D dust) and the distribution of the gas tracers' emission. The result of the\nHOG analysis is a map of the relationship between the distances and radial\nvelocities. The HOG comparison between the 3D dust and the HI emission\nindicates a morphological match at the distance of Taurus but an\nanti-correlation between the dust density and the HI emission, which uncovers a\nsignificant amount of cold HI within the Taurus MC. The HOG between the 3D dust\nand $^{12}$CO reveals a pattern in radial velocities and distances that is\nconsistent with converging motions of the gas in the Taurus MC, with the near\nside of the cloud moving at higher velocities and the far side moving at lower\nvelocities. This convergence of flows is likely triggered by the large-scale\ngas compression caused by the interaction of the Local Bubble and the Per-Tau\nshell, with Taurus lying at the intersection of the two bubble surfaces.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:08:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13181","submitter":"Vadim Alekseev","authors":"Vadim Alekseev, Max Schmidt and Andreas Thom","title":"Amenability for unitary groups of C*-algebras","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OA math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this note we state a conjecture that characterizes unital C*-algebras for\nwhich the unitary group is amenable as a topological group in the norm\ntopology. We prove the conjecture for simple, separable, stably finite, unital,\n$\\mathcal Z$-stable, UCT C*-algebras with torsionfree K_0 using the progress on\nthe Elliott classification program for nuclear C*-algebras as well as Pestov's\nstudy of amenability of gauge groups. Based on work of Kirchberg, we provide a\ncounterexample to a question of Ng, who proposed a different characterization\nin earlier work.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:10:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13182","submitter":"Coleridge Faraday","authors":"Coleridge Faraday, Antonia Grindrod, W. A. Horowitz","title":"Inconsistencies in and short pathlength correction to $R_{AA}(p_T)$ in\n  $\\mathrm{A}+\\mathrm{A}$ and $\\mathrm{p} + \\mathrm{A}$ collisions","comments":"19 pages, and 20 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the first leading hadron suppression predictions in\n$\\mathrm{Pb}+\\mathrm{Pb}$ and $\\mathrm{p}+\\mathrm{Pb}$ collisions from a\nconvolved radiative and collisional energy loss model in which partons\npropagate through a realistic background and in which the inelastic energy loss\nreceives a short pathlength correction. We find that the short pathlength\ncorrection is small for $D$ and $B$ meson $R_{AA}(p_T)$ in both\n$\\mathrm{Pb}+\\mathrm{Pb}$ and $\\mathrm{p}+\\mathrm{Pb}$ collisions. However the\nshort pathlength correction leads to a surprisingly large reduction in\nsuppression for $\\pi$ mesons in $\\mathrm{p}+\\mathrm{Pb}$ and even\n$\\mathrm{Pb}+\\mathrm{Pb}$ collisions. We systematically check the consistency\nof the assumptions used in the radiative energy loss\nderivation$\\unicode{x2014}$such as collinearity, softness, and large formation\ntime$\\unicode{x2014}$with the final numerical model. While collinearity and\nsoftness are self-consistently satisfied in the final numerics, we find that\nthe large formation time approximation breaks down at modest to high momenta\n$p_T \\gtrsim 30$ GeV. We find that both the size of the small pathlength\ncorrection to $R_{AA}(p_T)$ and the $p_T$ at which the large formation time\nassumption breaks down are acutely sensitive to the chosen distribution of\nscattering centers in the plasma.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:10:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13183","submitter":"Zixing Wang","authors":"Zixing Wang, Ahmed H. Qureshi","title":"DeRi-Bot: Learning to Collaboratively Manipulate Rigid Objects via\n  Deformable Objects","comments":"8 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research efforts have yielded significant advancements in manipulating\nobjects under homogeneous settings where the robot is required to either\nmanipulate rigid or deformable (soft) objects. However, the manipulation under\nheterogeneous setups that involve both deformable and rigid objects remains an\nunexplored area of research. Such setups are common in various scenarios that\ninvolve the transportation of heavy objects via ropes, e.g., on factory floors,\nat disaster sites, and in forestry. To address this challenge, we introduce\nDeRi-Bot, the first framework that enables the collaborative manipulation of\nrigid objects with deformable objects. Our framework comprises an Action\nPrediction Network (APN) and a Configuration Prediction Network (CPN) to model\nthe complex pattern and stochasticity of soft-rigid body systems. We\ndemonstrate the effectiveness of DeRi-Bot in moving rigid objects to a target\nposition with ropes connected to robotic arms. Furthermore, DeRi-Bot is a\ndistributive method that can accommodate an arbitrary number of robots or human\npartners without reconfiguration or retraining. We evaluate our framework in\nboth simulated and real-world environments and show that it achieves promising\nresults with strong generalization across different types of objects and\nmulti-agent settings, including human-robot collaboration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:11:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13184","submitter":"Francesco Mezzadri","authors":"Francesco Mezzadri and Henry Taylor","title":"A matrix model of a non-Hermitian $\\beta$-ensemble","comments":"23 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce the first random matrix model of a complex $\\beta$-ensemble. The\nmatrices are tridiagonal and can be thought of as the non-Hermitian analogue of\nthe Hermite $\\beta$-ensembles discovered by Dumitriu and Edelman (J. Math.\nPhys., Vol. 43, 5830 (2002)). The main feature of the model is that the\nexponent $\\beta$ of the Vandermonde determinant in the joint probability\ndensity function (j.p.d.f.) of the eigenvalues can take any value in\n$\\mathbb{R}_+$. However, when $\\beta=2$, the j.p.d.f. does not reduce to that\nof the Ginibre ensemble, but it contains an extra factor expressed as a\nmultidimensional integral over the space of the eigenvectors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:12:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13185","submitter":"Toshinori Kitamura","authors":"Toshinori Kitamura, Tadashi Kozuno, Yunhao Tang, Nino Vieillard,\n  Michal Valko, Wenhao Yang, Jincheng Mei, Pierre M\\'enard, Mohammad Gheshlaghi\n  Azar, R\\'emi Munos, Olivier Pietquin, Matthieu Geist, Csaba Szepesv\\'ari,\n  Wataru Kumagai, Yutaka Matsuo","title":"Regularization and Variance-Weighted Regression Achieves Minimax\n  Optimality in Linear MDPs: Theory and Practice","comments":"ICML 2023 accepted","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mirror descent value iteration (MDVI), an abstraction of Kullback-Leibler\n(KL) and entropy-regularized reinforcement learning (RL), has served as the\nbasis for recent high-performing practical RL algorithms. However, despite the\nuse of function approximation in practice, the theoretical understanding of\nMDVI has been limited to tabular Markov decision processes (MDPs). We study\nMDVI with linear function approximation through its sample complexity required\nto identify an $\\varepsilon$-optimal policy with probability $1-\\delta$ under\nthe settings of an infinite-horizon linear MDP, generative model, and G-optimal\ndesign. We demonstrate that least-squares regression weighted by the variance\nof an estimated optimal value function of the next state is crucial to\nachieving minimax optimality. Based on this observation, we present\nVariance-Weighted Least-Squares MDVI (VWLS-MDVI), the first theoretical\nalgorithm that achieves nearly minimax optimal sample complexity for\ninfinite-horizon linear MDPs. Furthermore, we propose a practical VWLS\nalgorithm for value-based deep RL, Deep Variance Weighting (DVW). Our\nexperiments demonstrate that DVW improves the performance of popular\nvalue-based deep RL algorithms on a set of MinAtar benchmarks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:13:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13186","submitter":"Xinyuan Lu","authors":"Xinyuan Lu, Liangming Pan, Qian Liu, Preslav Nakov, Min-Yen Kan","title":"SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim\n  Verification on Scientific Tables","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Scientific fact-checking is crucial for ensuring the accuracy, reliability,\nand trustworthiness of scientific claims. However, existing benchmarks are\nlimited in terms of their claim diversity, reliance on text-based evidence, and\noversimplification of scientific reasoning. To address these gaps, we introduce\nSCITAB, a novel dataset comprising 1,225 challenging scientific claims\nrequiring compositional reasoning with scientific tables. The claims in SCITAB\nare derived from the actual scientific statements, and the evidence is\npresented as tables, closely mirroring real-world fact-checking scenarios. We\nestablish benchmarks on SCITAB using state-of-the-art models, revealing its\ninherent difficulty and highlighting limitations in existing prompting methods.\nOur error analysis identifies unique challenges, including ambiguous\nexpressions and irrelevant claims, suggesting future research directions. The\ncode and the data are publicly available at\nhttps://github.com/XinyuanLu00/SciTab.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:13:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13187","submitter":"Evgenii Chzhen","authors":"Evgenii Chzhen and Sholom Schechtman","title":"SignSVRG: fixing SignSGD via variance reduction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of unconstrained minimization of finite sums of\nfunctions. We propose a simple, yet, practical way to incorporate variance\nreduction techniques into SignSGD, guaranteeing convergence that is similar to\nthe full sign gradient descent. The core idea is first instantiated on the\nproblem of minimizing sums of convex and Lipschitz functions and is then\nextended to the smooth case via variance reduction. Our analysis is elementary\nand much simpler than the typical proof for variance reduction methods. We show\nthat for smooth functions our method gives $\\mathcal{O}(1 / \\sqrt{T})$ rate for\nexpected norm of the gradient and $\\mathcal{O}(1/T)$ rate in the case of smooth\nconvex functions, recovering convergence results of deterministic methods,\nwhile preserving computational advantages of SignSGD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:14:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13188","submitter":"Blake Hansen","authors":"Blake Hansen, Alejandra Avalos-Pacheco, Massimiliano Russo, Roberta De\n  Vito","title":"Fast Variational Inference for Bayesian Factor Analysis in Single and\n  Multi-Study Settings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Factors models are routinely used to analyze high-dimensional data in both\nsingle-study and multi-study settings. Bayesian inference for such models\nrelies on Markov Chain Monte Carlo (MCMC) methods which scale poorly as the\nnumber of studies, observations, or measured variables increase. To address\nthis issue, we propose variational inference algorithms to approximate the\nposterior distribution of Bayesian latent factor models using the\nmultiplicative gamma process shrinkage prior. The proposed algorithms provide\nfast approximate inference at a fraction of the time and memory of MCMC-based\nimplementations while maintaining comparable accuracy in characterizing the\ndata covariance matrix. We conduct extensive simulations to evaluate our\nproposed algorithms and show their utility in estimating the model for\nhigh-dimensional multi-study gene expression data in ovarian cancers. Overall,\nour proposed approaches enable more efficient and scalable inference for factor\nmodels, facilitating their use in high-dimensional settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:17:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13189","submitter":"Lorenzo Perini","authors":"Lorenzo Perini, Jesse Davis","title":"Unsupervised Anomaly Detection with Rejection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Anomaly detection aims at detecting unexpected behaviours in the data.\nBecause anomaly detection is usually an unsupervised task, traditional anomaly\ndetectors learn a decision boundary by employing heuristics based on\nintuitions, which are hard to verify in practice. This introduces some\nuncertainty, especially close to the decision boundary, that may reduce the\nuser trust in the detector's predictions. A way to combat this is by allowing\nthe detector to reject examples with high uncertainty (Learning to Reject).\nThis requires employing a confidence metric that captures the distance to the\ndecision boundary and setting a rejection threshold to reject low-confidence\npredictions. However, selecting a proper metric and setting the rejection\nthreshold without labels are challenging tasks. In this paper, we solve these\nchallenges by setting a constant rejection threshold on the stability metric\ncomputed by ExCeeD. Our insight relies on a theoretical analysis of such a\nmetric. Moreover, setting a constant threshold results in strong guarantees: we\nestimate the test rejection rate, and derive a theoretical upper bound for both\nthe rejection rate and the expected prediction cost. Experimentally, we show\nthat our method outperforms some metric-based methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:22:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13190","submitter":"Daniela Inclezan","authors":"Daniela Inclezan","title":"An ASP Framework for the Refinement of Authorization and Obligation\n  Policies","comments":"Paper accepted for presentation at the 39th International Conference\n  on Logic Programming (ICLP 2023), 16 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper introduces a framework for assisting policy authors in refining\nand improving their policies. In particular, we focus on authorization and\nobligation policies that can be encoded in Gelfond and Lobo's AOPL language for\npolicy specification. We propose a framework that detects the statements that\nmake a policy inconsistent, underspecified, or ambiguous with respect to an\naction being executed in a given state. We also give attention to issues that\narise at the intersection of authorization and obligation policies, for\ninstance when the policy requires an unauthorized action to be executed. The\nframework is encoded in Answer Set Programming. Under consideration for\nacceptance in TPLP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:23:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13191","submitter":"Karthikeyan K","authors":"Karthikeyan K, Yogarshi Vyas, Jie Ma, Giovanni Paolini, Neha Anna\n  John, Shuai Wang, Yassine Benajiba, Vittorio Castelli, Dan Roth, Miguel\n  Ballesteros","title":"Taxonomy Expansion for Named Entity Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training a Named Entity Recognition (NER) model often involves fixing a\ntaxonomy of entity types. However, requirements evolve and we might need the\nNER model to recognize additional entity types. A simple approach is to\nre-annotate entire dataset with both existing and additional entity types and\nthen train the model on the re-annotated dataset. However, this is an extremely\nlaborious task. To remedy this, we propose a novel approach called Partial\nLabel Model (PLM) that uses only partially annotated datasets. We experiment\nwith 6 diverse datasets and show that PLM consistently performs better than\nmost other approaches (0.5 - 2.5 F1), including in novel settings for taxonomy\nexpansion not considered in prior work. The gap between PLM and all other\napproaches is especially large in settings where there is limited data\navailable for the additional entity types (as much as 11 F1), thus suggesting a\nmore cost effective approaches to taxonomy expansion.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:23:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13192","submitter":"Jiahao Xu","authors":"Jiahao Xu, Wei Shao, Lihui Chen and Lemao Liu","title":"ImSimCSE: Improving Contrastive Learning for Sentence Embeddings from\n  Two Perspectives","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper aims to improve contrastive learning for sentence embeddings from\ntwo perspectives: handling dropout noise and addressing feature corruption.\nSpecifically, for the first perspective, we identify that the dropout noise\nfrom negative pairs affects the model's performance. Therefore, we propose a\nsimple yet effective method to deal with such type of noise. Secondly, we\npinpoint the rank bottleneck of current solutions to feature corruption and\npropose a dimension-wise contrastive learning objective to address this issue.\nBoth proposed methods are generic and can be applied to any contrastive\nlearning based models for sentence embeddings. Experimental results on standard\nbenchmarks demonstrate that combining both proposed methods leads to a gain of\n1.8 points compared to the strong baseline SimCSE configured with BERT base.\nFurthermore, applying the proposed method to DiffCSE, another strong\ncontrastive learning based baseline, results in a gain of 1.4 points.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:24:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13193","submitter":"Bela Gipp","authors":"Ankit Satpute and Andr\\'e Greiner-Petter and Moritz Schubotz and\n  Norman Meuschke and Akiko Aizawa and Bela Gipp","title":"TEIMMA: The First Content Reuse Annotator for Text, Images, and Math","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This demo paper presents the first tool to annotate the reuse of text,\nimages, and mathematical formulae in a document pair -- TEIMMA. Annotating\ncontent reuse is particularly useful to develop plagiarism detection\nalgorithms. Real-world content reuse is often obfuscated, which makes it\nchallenging to identify such cases. TEIMMA allows entering the obfuscation type\nto enable novel classifications for confirmed cases of plagiarism. It enables\nrecording different reuse types for text, images, and mathematical formulae in\nHTML and supports users by visualizing the content reuse in a document pair\nusing similarity detection methods for text and math.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:24:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13194","submitter":"Elizabeth Clark","authors":"Elizabeth Clark, Shruti Rijhwani, Sebastian Gehrmann, Joshua Maynez,\n  Roee Aharoni, Vitaly Nikolaev, Thibault Sellam, Aditya Siddhant, Dipanjan\n  Das, Ankur P. Parikh","title":"SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization\n  Evaluation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Reliable automatic evaluation of summarization systems is challenging due to\nthe multifaceted and subjective nature of the task. This is especially the case\nfor languages other than English, where human evaluations are scarce. In this\nwork, we introduce SEAHORSE, a dataset for multilingual, multifaceted\nsummarization evaluation. SEAHORSE consists of 96K summaries with human ratings\nalong 6 quality dimensions: comprehensibility, repetition, grammar,\nattribution, main ideas, and conciseness, covering 6 languages, 9 systems and 4\ndatasets. As a result of its size and scope, SEAHORSE can serve both as a\nbenchmark to evaluate learnt metrics, as well as a large-scale resource for\ntraining such metrics. We show that metrics trained with SEAHORSE achieve\nstrong performance on the out-of-domain meta-evaluation benchmarks TRUE\n(Honovich et al., 2022) and mFACE (Aharoni et al., 2022). We make SEAHORSE\npublicly available for future research on multilingual and multifaceted\nsummarization evaluation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:25:07 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13195","submitter":"Xin Jing","authors":"Xin Jing, Yi Chang, Zijiang Yang, Jiangjian Xie, Andreas\n  Triantafyllopoulos, Bjoern W. Schuller","title":"U-DiT TTS: U-Diffusion Vision Transformer for Text-to-Speech","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deep learning has led to considerable advances in text-to-speech synthesis.\nMost recently, the adoption of Score-based Generative Models (SGMs), also known\nas Diffusion Probabilistic Models (DPMs), has gained traction due to their\nability to produce high-quality synthesized neural speech in neural speech\nsynthesis systems. In SGMs, the U-Net architecture and its variants have long\ndominated as the backbone since its first successful adoption. In this\nresearch, we mainly focus on the neural network in diffusion-model-based\nText-to-Speech (TTS) systems and propose the U-DiT architecture, exploring the\npotential of vision transformer architecture as the core component of the\ndiffusion models in a TTS system. The modular design of the U-DiT architecture,\ninherited from the best parts of U-Net and ViT, allows for great scalability\nand versatility across different data scales. The proposed U-DiT TTS system is\na mel spectrogram-based acoustic model and utilizes a pretrained HiFi-GAN as\nthe vocoder. The objective (ie Frechet distance) and MOS results show that our\nDiT-TTS system achieves state-of-art performance on the single speaker dataset\nLJSpeech. Our demos are publicly available at:\nhttps://eihw.github.io/u-dit-tts/\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:25:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13196","submitter":"Michael H. Mertens","authors":"Michael H. Mertens and Mark A. Norfleet","title":"Weight $1/2$ multiplier systems for the group $\\Gamma_0^+(p)$ and a\n  geometric formulation","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct a weight $1/2$ multiplier system for the group $\\Gamma_0^+(p)$,\nthe normalizer of the congruence subgroup $\\Gamma_0(p)$ where $p$ is an odd\nprime, and we define an analogue of the eta function and Rademacher symbol and\nrelate it to the geometry of edge paths in a triangulation of the upper half\nplane.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:26:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13197","submitter":"Zehan Li","authors":"Zehan Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie","title":"Challenging Decoder helps in Masked Auto-Encoder Pre-training for Dense\n  Passage Retrieval","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently, various studies have been directed towards exploring dense passage\nretrieval techniques employing pre-trained language models, among which the\nmasked auto-encoder (MAE) pre-training architecture has emerged as the most\npromising. The conventional MAE framework relies on leveraging the passage\nreconstruction of decoder to bolster the text representation ability of\nencoder, thereby enhancing the performance of resulting dense retrieval\nsystems. Within the context of building the representation ability of the\nencoder through passage reconstruction of decoder, it is reasonable to\npostulate that a ``more demanding'' decoder will necessitate a corresponding\nincrease in the encoder's ability. To this end, we propose a novel token\nimportance aware masking strategy based on pointwise mutual information to\nintensify the challenge of the decoder. Importantly, our approach can be\nimplemented in an unsupervised manner, without adding additional expenses to\nthe pre-training phase. Our experiments verify that the proposed method is both\neffective and robust on large-scale supervised passage retrieval datasets and\nout-of-domain zero-shot retrieval benchmarks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:27:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13198","submitter":"Marta R. Costa-Juss\\`a","authors":"Marta R. Costa-juss\\`a, Pierre Andrews, Eric Smith, Prangthip\n  Hansanti, Christophe Ropers, Elahe Kalbassi, Cynthia Gao, Daniel Licht,\n  Carleigh Wood","title":"Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil\n  Demographic Biases in Languages at Scale","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We introduce a multilingual extension of the HOLISTICBIAS dataset, the\nlargest English template-based taxonomy of textual people references:\nMULTILINGUALHOLISTICBIAS. This extension consists of 20,459 sentences in 50\nlanguages distributed across all 13 demographic axes. Source sentences are\nbuilt from combinations of 118 demographic descriptors and three patterns,\nexcluding nonsensical combinations. Multilingual translations include\nalternatives for gendered languages that cover gendered translations when there\nis ambiguity in English. Our benchmark is intended to uncover demographic\nimbalances and be the tool to quantify mitigations towards them.\n  Our initial findings show that translation quality for EN-to-XX translations\nis an average of 8 spBLEU better when evaluating with the masculine human\nreference compared to feminine. In the opposite direction, XX-to-EN, we compare\nthe robustness of the model when the source input only differs in gender\n(masculine or feminine) and masculine translations are an average of almost 4\nspBLEU better than feminine. When embedding sentences to a joint multilingual\nsentence representations space, we find that for most languages masculine\ntranslations are significantly closer to the English neutral sentences when\nembedded.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:29:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13199","submitter":"Yucheng Cai","authors":"Yucheng Cai, Hong Liu, Zhijian Ou, Yi Huang, Junlan Feng","title":"Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision","comments":"5 pages, accepted by INTERSPEECH2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most existing task-oriented dialog (TOD) systems track dialog states in terms\nof slots and values and use them to query a database to get relevant knowledge\nto generate responses. In real-life applications, user utterances are noisier,\nand thus it is more difficult to accurately track dialog states and correctly\nsecure relevant knowledge. Recently, a progress in question answering and\ndocument-grounded dialog systems is retrieval-augmented methods with a\nknowledge retriever. Inspired by such progress, we propose a retrieval-based\nmethod to enhance knowledge selection in TOD systems, which significantly\noutperforms the traditional database query method for real-life dialogs.\nFurther, we develop latent variable model based semi-supervised learning, which\ncan work with the knowledge retriever to leverage both labeled and unlabeled\ndialog data. Joint Stochastic Approximation (JSA) algorithm is employed for\nsemi-supervised model training, and the whole system is referred to as that\nJSA-KRTOD. Experiments are conducted on a real-life dataset from China Mobile\nCustom-Service, called MobileCS, and show that JSA-KRTOD achieves superior\nperformances in both labeled-only and semi-supervised settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:29:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13200","submitter":"Shunkai Mao","authors":"Shunkai Mao and Peng Qu","title":"Non-uniqueness for the compressible Euler-Maxwell equations","comments":"77 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the Cauchy problem for the isentropic compressible Euler-Maxwell\nequations under general pressure laws in a three-dimensional periodic domain.\nFor any smooth initial electron density away from the vacuum and smooth\nequilibrium-charged ion density, we could construct infinitely many\n$\\alpha$-H\\\"older continuous entropy solutions emanating from the same initial\ndata for $\\alpha<\\frac{1}{7}$. Especially, the electromagnetic field belongs to\nthe H\\\"older class $C^{1,\\alpha}$. Furthermore, we provide a continuous entropy\nsolution satisfying the entropy inequality strictly. The proof relies on the\nconvex integration scheme. Due to the constrain of the Maxwell equations, we\npropose a method of Mikado potential and construct new building blocks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:30:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13201","submitter":"Emily Adlam","authors":"Emily Adlam","title":"Disappearing Without a Trace: The Arrows of Time in Kent's Solution to\n  the Lorentzian Quantum Reality Problem","comments":"Forthcoming in BJPS","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.hist-ph quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Most existing proposals to explain the temporal asymmetries we see around us\nare sited within an approach to physics based on time evolution, and thus they\ntypically put the asymmetry in at the beginning of time in the form of a\nspecial initial state. But there may be other possibilities for explaining\ntemporal asymmetries if we don't presuppose the time evolution paradigm. In\nthis article, we explore one such possibility, based on Kent's\n`final-measurement' interpretation of quantum mechanics. We argue that this\napproach potentially has the resources to explain the electromagnetic\nasymmetry, the thermodynamic asymmetry, the coarse-graining asymmetry, the fork\nasymmetry, the record asymmetry, and the cosmological asymmetry, and that the\nexplanations it offers may potentially be better than explanations appealing to\na special initial state. Our hope is that this example will encourage further\nexploration of novel approaches to temporal asymmetry outside of the time\nevolution paradigm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:32:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13202","submitter":"Johannes Hecker Denschlag","authors":"Sebastian K\\\"olle, Manuel J\\\"ager, Markus M\\\"uller, Wladimir Schoch,\n  Wolfgang Limmer, Johannes Hecker Denschlag","title":"Holographic imaging of an array of submicron light scatterers at low\n  photon numbers","comments":"7 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas physics.atom-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We experimentally test a recently proposed holographic method for imaging\ncoherent light scatterers which are distributed over a 2-dimensional grid. In\nour setup the scatterers consist of a back-illuminated, opaque mask with\nsubmicron-sized holes. We study how the imaging fidelity depends on various\nparameters of the set-up. We observe that a few hundred scattered photons per\nhole already suffice to obtain a fidelity of 96% to correctly determine whether\na hole is located at a given grid point. The holographic method demonstrated\nhere has a high potential for applications with ultracold atoms in optical\nlattices.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:33:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13203","submitter":"Paulo Andr\\'e D. Gon\\c{c}alves","authors":"P. A. D. Gon\\c{c}alves and F. Javier Garc\\'ia de Abajo","title":"Multi-plasmon effects and plasmon satellites in photoemission from\n  nanostructures","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Plasmons can be excited during photoemission and produce spectral\nphotoelectron features that yield information on the nanoscale optical response\nof the probed materials. However, these so-called plasmon satellites have so\nfar been observed only for planar surfaces, while their potential for the\ncharacterization of nanostructures remains unexplored. Here, we theoretically\ndemonstrate that core-level photoemission from nanostructures can display\nspectrally narrow plasmonic features, reaching relatively high probabilities\nsimilar to the direct peak. Using a nonperturbative quantum-mechanical\nframework, we find a dramatic effect of nanostructure morphology and\ndimensionality as well as a universal scaling law for the plasmon-satellite\nprobabilities. In addition, we introduce a pump--probe scheme in which plasmons\nare optically excited prior to photoemission, leading to plasmon losses and\ngains in the photoemission spectra and granting us access into the ultrafast\ndynamics of the sampled nanostructure. These results emphasize the potential of\nplasmon satellites to explore multi-plasmon effects and ultrafast\nelectron--plasmon dynamics in metal-based nanoparticles and two-dimensional\nnanoislands.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:35:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13204","submitter":"Brian Thompson","authors":"Proyag Pal, Brian Thompson, Yogesh Virkar, Prashant Mathur, Alexandra\n  Chronopoulou, Marcello Federico","title":"Improving Isochronous Machine Translation with Target Factors and\n  Auxiliary Counters","comments":"Accepted at INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To translate speech for automatic dubbing, machine translation needs to be\nisochronous, i.e. translated speech needs to be aligned with the source in\nterms of speech durations. We introduce target factors in a transformer model\nto predict durations jointly with target language phoneme sequences. We also\nintroduce auxiliary counters to help the decoder to keep track of the timing\ninformation while generating target phonemes. We show that our model improves\ntranslation quality and isochrony compared to previous work where the\ntranslation model is instead trained to predict interleaved sequences of\nphonemes and durations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:36:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13205","submitter":"O.S.K.S. Sastri","authors":"Ayushi Awasthi and O.S.K.S Sastri","title":"Study of np-scattering for S, P and D Waves using Deng-Fan Potential by\n  Phase Function Method","comments":"8 pages, 4 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Background: Deng-Fan potential has been utilised to study neutron-proton and\nneutron-Deuteron scattering phase shifts and in turn their corresponding\nscattering cross-sections using Jost function method and phase function method.\nIt has been concluded that phase function method has certain limitations in\nobtaining scattering phase shifts. Purpose: In this paper, scattering phase\nshifts for various S, P and D states of neutron-proton scattering have been\nobtained using Deng-Fan potential as model of interaction. Methods: The\nscattering phase shift for S, P and D channels are determined using phase\nfunction method by incorporating Deng-Fan potential into respective phase\nequations for l = 0, 1, 2. The scattering phase shifts obtained by phase\nfunction method are utilised to determine corresponding scattering\ncross-section. Results: The obtained scattering phase shifts for 3S1, 1S0, 1P1,\n3P0,1,2, 1D2, 3D1, 3D2 and 3D3 states are found to be closely matching with\nrespect to experimental data for lab energies up to 350 MeV. The total\nscattering cross-sections are calculated for available energies and are in good\nmatch with expected ones. Conclusion: The phenomenological Deng-Fan potential\nhas been shown to describe the np-scattering results reasonably well.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:38:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13206","submitter":"Jannis Weil","authors":"Jannis Weil, Johannes Czech, Tobias Meuser, Kristian Kersting","title":"Know your Enemy: Investigating Monte-Carlo Tree Search with Opponent\n  Models in Pommerman","comments":"Accepted at the Adaptive and Learning Agents Workshop (ALA) at AAMAS\n  2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In combination with Reinforcement Learning, Monte-Carlo Tree Search has shown\nto outperform human grandmasters in games such as Chess, Shogi and Go with\nlittle to no prior domain knowledge. However, most classical use cases only\nfeature up to two players. Scaling the search to an arbitrary number of players\npresents a computational challenge, especially if decisions have to be planned\nover a longer time horizon. In this work, we investigate techniques that\ntransform general-sum multiplayer games into single-player and two-player games\nthat consider other agents to act according to given opponent models. For our\nevaluation, we focus on the challenging Pommerman environment which involves\npartial observability, a long time horizon and sparse rewards. In combination\nwith our search methods, we investigate the phenomena of opponent modeling\nusing heuristics and self-play. Overall, we demonstrate the effectiveness of\nour multiplayer search variants both in a supervised learning and reinforcement\nlearning setting.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:39:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13207","submitter":"Sayed Erfan Arefin","authors":"Sayed Erfan Arefin, Tasnia Ashrafi Heya, Jia Uddin","title":"Real-life Implementation of Internet of Robotic Things Using 5 DoF\n  Heterogeneous Robotic Arm","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Establishing a communication bridge by transferring data driven from\ndifferent embedded sensors via internet or reconcilable network protocols\nbetween enormous number of distinctively addressable objects or \"things\", is\nknown as the Internet of Things (IoT). IoT can be amalgamated with\nmultitudinous objects such as thermostats, cars, lights, refrigerators, and\nmany more appliances which will be able to build a connection via internet.\nWhere objects of our diurnal life can establish a network connection and get\nsmarter with IoT, robotics can be another aspect which will get beneficial to\nbe brought under the concept of IoT and is able to add a new perception in\nrobotics having \"Mechanical Smart Intelligence\" which is generally called\n\"Internet of Robotic Things\" (IoRT). A robotic arm is a part of robotics where\nit is usually a programmable mechanical arm which has human arm like\nfunctionalities. In this paper, IoRT will be represented by a 5 DoF (degree of\nfreedoms) Robotic Arm which will be able to communicate as an IoRT device,\ncontrolled with heterogeneous devices using IoT and \"Cloud Robotics\".\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:40:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13209","submitter":"Mahdi Haghifam","authors":"Arun Ganesh, Mahdi Haghifam, Thomas Steinke, Abhradeep Thakurta","title":"Faster Differentially Private Convex Optimization via Second-Order\n  Methods","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR math.OC stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Differentially private (stochastic) gradient descent is the workhorse of DP\nprivate machine learning in both the convex and non-convex settings. Without\nprivacy constraints, second-order methods, like Newton's method, converge\nfaster than first-order methods like gradient descent. In this work, we\ninvestigate the prospect of using the second-order information from the loss\nfunction to accelerate DP convex optimization. We first develop a private\nvariant of the regularized cubic Newton method of Nesterov and Polyak, and show\nthat for the class of strongly convex loss functions, our algorithm has\nquadratic convergence and achieves the optimal excess loss. We then design a\npractical second-order DP algorithm for the unconstrained logistic regression\nproblem. We theoretically and empirically study the performance of our\nalgorithm. Empirical results show our algorithm consistently achieves the best\nexcess loss compared to other baselines and is 10-40x faster than DP-GD/DP-SGD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:43:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13210","submitter":"Dan Stowell","authors":"In\\^es Nolasco, Shubhr Singh, Veronica Morfi, Vincent Lostanlen,\n  Ariana Strandburg-Peshkin, Ester Vida\\~na-Vila, Lisa Gill, Hanna Pamu{\\l}a,\n  Helen Whitehead, Ivan Kiskin, Frants H. Jensen, Joe Morford, Michael G.\n  Emmerson, Elisabetta Versace, Emily Grout, Haohe Liu, Dan Stowell","title":"Learning to detect an animal sound from five examples","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS q-bio.QM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automatic detection and classification of animal sounds has many applications\nin biodiversity monitoring and animal behaviour. In the past twenty years, the\nvolume of digitised wildlife sound available has massively increased, and\nautomatic classification through deep learning now shows strong results.\nHowever, bioacoustics is not a single task but a vast range of small-scale\ntasks (such as individual ID, call type, emotional indication) with wide\nvariety in data characteristics, and most bioacoustic tasks do not come with\nstrongly-labelled training data. The standard paradigm of supervised learning,\nfocussed on a single large-scale dataset and/or a generic pre-trained\nalgorithm, is insufficient. In this work we recast bioacoustic sound event\ndetection within the AI framework of few-shot learning. We adapt this framework\nto sound event detection, such that a system can be given the annotated\nstart/end times of as few as 5 events, and can then detect events in\nlong-duration audio -- even when the sound category was not known at the time\nof algorithm training. We introduce a collection of open datasets designed to\nstrongly test a system's ability to perform few-shot sound event detections,\nand we present the results of a public contest to address the task. We show\nthat prototypical networks are a strong-performing method, when enhanced with\nadaptations for general characteristics of animal sounds. We demonstrate that\nwidely-varying sound event durations are an important factor in performance, as\nwell as non-stationarity, i.e. gradual changes in conditions throughout the\nduration of a recording. For fine-grained bioacoustic recognition tasks without\nmassive annotated training data, our results demonstrate that few-shot sound\nevent detection is a powerful new method, strongly outperforming traditional\nsignal-processing detection methods in the fully automated scenario.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:43:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13212","submitter":"Guruprasad Kadam Dr.","authors":"Somenath Pal, Guruprasad Kadam, Abhijit Bhattacharyya","title":"Conserved charge fluctuations in the relativistic mean-field hadron\n  resonance gas model: constraints on hadronic repulsive interactions","comments":"13 Pages, 17 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph nucl-th","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We investigate the effect of repulsive interaction between hadrons on the\nsusceptibilities of conserved charges, namely baryon number (B), electric\ncharge (Q) and strangeness (S). We estimate second and fourth-order\nsusceptibilities of conserved charges, their differences, ratios and\ncorrelations within the ambit of the mean-field hadron resonance gas (MFHRG)\nmodel. We consider repulsive mean-field interaction among meson pairs,\nanti-meson pairs, baryon pairs and anti-baryon pairs separately and constrain\nthem by confronting MFHRG results of various susceptibilities with the recent\nlattice QCD (LQCD) data. We find that the repulsive interactions between\nbaryon-baryon pairs and antibaryon-antibaryon pairs are sufficient to describe\nthe thermodynamics of hadronic matter at temperatures below the QCD transition\ntemperature. Very weak mesonic repulsive interaction is needed only to describe\nelectric charge susceptibilities and can be neglected in the description of\nother susceptibilities. We finally conclude that the repulsive interaction\nbetween hadrons plays a very important role in describing the thermodynamic\nproperties of hadronic matter, especially near quark-hadron phase transition\ntemperature ($T_c$). The mean-field parameter for baryons ($K_B$) should be\nconstrained to the range $0.40\\le K_B\\le 0.450$ $\\text{GeV.fm}^{3}$ to get a\ngood agreement with the LQCD results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:44:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13214","submitter":"Joe Stacey","authors":"Joe Stacey, Pasquale Minervini, Haim Dubossarsky, Oana-Maria Camburu\n  and Marek Rei","title":"Logical Reasoning for Natural Language Inference Using Generated Facts\n  as Atoms","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  State-of-the-art neural models can now reach human performance levels across\nvarious natural language understanding tasks. However, despite this impressive\nperformance, models are known to learn from annotation artefacts at the expense\nof the underlying task. While interpretability methods can identify influential\nfeatures for each prediction, there are no guarantees that these features are\nresponsible for the model decisions. Instead, we introduce a model-agnostic\nlogical framework to determine the specific information in an input responsible\nfor each model decision. This method creates interpretable Natural Language\nInference (NLI) models that maintain their predictive power. We achieve this by\ngenerating facts that decompose complex NLI observations into individual\nlogical atoms. Our model makes predictions for each atom and uses logical rules\nto decide the class of the observation based on the predictions for each atom.\nWe apply our method to the highly challenging ANLI dataset, where our framework\nimproves the performance of both a DeBERTa-base and BERT baseline. Our method\nperforms best on the most challenging examples, achieving a new\nstate-of-the-art for the ANLI round 3 test set. We outperform every baseline in\na reduced-data setting, and despite using no annotations for the generated\nfacts, our model predictions for individual facts align with human\nexpectations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:45:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13215","submitter":"Kamal Basulaiman","authors":"Kamal Basulaiman, Masoud Barati","title":"Sequence-to-Sequence Forecasting-aided State Estimation for Power\n  Systems","comments":null,"journal-ref":null,"doi":"10.1109/TPEC51183.2021.9384984","report-no":null,"categories":"eess.SY cs.LG cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Power system state forecasting has gained more attention in real-time\noperations recently. Unique challenges to energy systems are emerging with the\nmassive deployment of renewable energy resources. As a result, power system\nstate forecasting are becoming more crucial for monitoring, operating and\nsecuring modern power systems. This paper proposes an end-to-end deep learning\nframework to accurately predict multi-step power system state estimations in\nreal-time. In our model, we employ a sequence-to-sequence framework to allow\nfor multi-step forecasting. Bidirectional gated recurrent units (BiGRUs) are\nincorporated into the model to achieve high prediction accuracy. The dominant\nperformance of our model is validated using real dataset. Experimental results\nshow the superiority of our model in predictive power compared to existing\nalternatives.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:46:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13216","submitter":"Theodore Gull","authors":"Theodore R. Gull, Henrik Hartman, Mairan Teodoro, D. John Hillier,\n  Michael F. Corcoran, Augusto Damineli, Kenji Hamaguchi, Thomas Madura,\n  Anthony F. J. Moffat, Patrick Morris, Noel D. Richardson, Ian R. Stevens,\n  Gerd Weigelt","title":"Eta Carinae: the dissipating occulter is an extended structure","comments":"20 pages, 10 figures, submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Previous STIS long-slit observations of Eta Carinae identified numerous\nabsorption features in both the stellar spectrum, and in the adjacent nebular\nspectra, along our line-of-sight. The absorption features became temporarily\nstronger when the ionizing FUV radiation field was reduced by the periastron\npassage of the secondary star. Subsequently, dissipation of a dusty structure\nin our LOS has led to a long-term increase in the apparent magnitude of \\ec, an\nincrease in the ionizing UV radiation, and the disappearance of absorptions\nfrom multiple velocity-separated shells extending across the foreground\nHomunculus lobe. We use HST/STIS spectro-images, coupled with published\ninfrared and radio observations, to locate this intervening dusty structure.\nVelocity and spatial information indicate the occulter is ~1000 au in front of\nEta Carinae. The Homunculus is a transient structure composed of dusty,\npartially-ionized ejecta that eventually will disappear due to the relentless\nrain of ionizing radiation and wind from the current binary system along with\ndissipation and mixing with the ISM. This evolving complex continues to provide\nan astrophysical laboratory that changes on human timescales.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:47:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13217","submitter":"Kyuil Cho","authors":"Kyuil Cho, M. Konczykowski, M. A. Tanatar, I. I. Mazin, Yong Liu, T.\n  A. Lograsso, R. Prozorov","title":"Ion-selective scattering studied by the variable-energy electron\n  irradiation of Ba$_{0.2}$K$_{0.8}$Fe$_2$As$_2$ superconductor","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Low-temperature variable-energy electron irradiation was used to induce\nnon-magnetic disorder in a single crystal of hole-doped iron-based\nsuperconductor, Ba$_{1-x}$K$_x$Fe$_2$As$_2$, $x=$0.80. To avoid systematic\nerrors, the beam energy was adjusted non-consequently for five values between\n1.0 and 2.5 MeV, whence sample resistance was measured in-situ at 22 K. For all\nenergies, the resistivity raises linearly with the irradiation fluence\nsuggesting the creation of uncorrelated dilute point-like disorder (confirmed\nby simulations). The rate of the resistivity increase peaks at energies below\n1.5 MeV. Comparison with calculated partial cross-sections points to the\npredominant creation of defects in the iron sublattice. Simultaneously,\nsuperconducting $T_c$, measured separately between the irradiation runs, is\nmonotonically suppressed as expected since it depends on the total scattering\nrate, hence total cross-section, which is a monotonically increasing function\nof energy. Our work confirms experimentally an often-made assumption of the\ndominant role of the iron sub-lattice in iron-based superconductors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:47:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13218","submitter":"Shudian Zhao","authors":"Lucia Absalom Bautista, Timotej Hrga, Janez Povh, Shudian Zhao","title":"Ground truth clustering is not the optimum clustering","comments":"23 pages; 2 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The clustering of data is one of the most important and challenging topics in\ndata science. The minimum sum-of-squares clustering (MSSC) problem asks to\ncluster the data points into $k$ clusters such that the sum of squared\ndistances between the data points and their cluster centers (centroids) is\nminimized. This problem is NP-hard, but there exist exact solvers that can\nsolve such problem to optimality for small or medium size instances.\n  In this paper, we use a branch-and-bound solver based on semidefinite\nprogramming relaxations called SOS-SDP to compute the optimum solutions of the\nMSSC problem for various $k$ and for multiple datasets, with real and\nartificial data, for which the data provider has provided ground truth\nclustering.\n  Next, we use several extrinsic and intrinsic measures to evaluate how the\noptimum clustering and ground truth clustering matches, and how well these\nclusterings perform with respect to the criteria underlying the intrinsic\nmeasures. Our calculations show that the ground truth clusterings are generally\nfar from the optimum solution to the MSSC problem. Moreover, the intrinsic\nmeasures evaluated on the ground truth clusterings are generally significantly\nworse compared to the optimum clusterings. However, when the ground truth\nclustering is in the form of convex sets, e.g., ellipsoids, that are well\nseparated from each other, the ground truth clustering comes very close to the\noptimum clustering.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:48:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13219","submitter":"William Johnston","authors":"William Johnston and Rebecca G. Wahl","title":"Bicomplex Matrices and Operators: Jordan Forms, Invariant Subspace\n  Lattice Diagrams, and Compact Operators","comments":"12 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.OA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper extends topics in linear algebra and operator theory for linear\ntransformations on complex vector spaces to those on bicomplex Hilbert and\nBanach spaces. For example, Definition 3 for the first time defines a bicomplex\nvector space, its dimension, and its basis in terms of a corresponding\nvectorial idempotent representation, and the paper shows how an n by n\nbicomplex matrix's idempotent representation leads to its bicomplex Jordan form\nand a description of its bicomplex invariant subspace lattice diagram.\nSimilarly, the paper rigorously defines for the first time \"bicomplex Banach\nand Hilbert\" spaces, and then it expands the theory of compact operators on\ncomplex Banach and Hilbert spaces to those on bicomplex Banach and Hilbert\nspaces. In these ways, the paper shows that complex linear algebra and operator\ntheory are not necessarily built upon the broadest and most natural set of\nscalars to study. Instead, when using the idempotent representation, such\nresults surprisingly generalize in a straightforward way to the\nhigher-dimensional case of bicomplex values.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:49:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13220","submitter":"Wei Dong","authors":"Wei Dong, Chris Choy, Charles Loop, Or Litany, Yuke Zhu, Anima\n  Anandkumar","title":"Fast Monocular Scene Reconstruction with Global-Sparse Local-Dense Grids","comments":"CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Indoor scene reconstruction from monocular images has long been sought after\nby augmented reality and robotics developers. Recent advances in neural field\nrepresentations and monocular priors have led to remarkable results in\nscene-level surface reconstructions. The reliance on Multilayer Perceptrons\n(MLP), however, significantly limits speed in training and rendering. In this\nwork, we propose to directly use signed distance function (SDF) in sparse voxel\nblock grids for fast and accurate scene reconstruction without MLPs. Our\nglobally sparse and locally dense data structure exploits surfaces' spatial\nsparsity, enables cache-friendly queries, and allows direct extensions to\nmulti-modal data such as color and semantic labels. To apply this\nrepresentation to monocular scene reconstruction, we develop a scale\ncalibration algorithm for fast geometric initialization from monocular depth\npriors. We apply differentiable volume rendering from this initialization to\nrefine details with fast convergence. We also introduce efficient\nhigh-dimensional Continuous Random Fields (CRFs) to further exploit the\nsemantic-geometry consistency between scene objects. Experiments show that our\napproach is 10x faster in training and 100x faster in rendering while achieving\ncomparable accuracy to state-of-the-art neural implicit methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:50:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13221","submitter":"Sudipto Saha","authors":"Sudipto Saha and Jonathan R. Bradley","title":"Incorporating Subsampling into Bayesian Models for High-Dimensional\n  Spatial Data","comments":"46 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Additive spatial statistical models with weakly stationary process\nassumptions have become standard in spatial statistics. However, one\ndisadvantage of such models is the computation time, which rapidly increases\nwith the number of datapoints. The goal of this article is to apply an existing\nsubsampling strategy to standard spatial additive models and to derive the\nspatial statistical properties. We call this strategy the ``spatial data subset\nmodel'' approach, which can be applied to big datasets in a computationally\nfeasible way. Our approach has the advantage that one does not require any\nadditional restrictive model assumptions. That is, computational gains increase\nas model assumptions are removed when using our model framework. This provides\none solution to the computational bottlenecks that occur when applying methods\nsuch as Kriging to ``big data''. We provide several properties of this new\nspatial data subset model approach in terms of moments, sill, nugget, and range\nunder several sampling designs. The biggest advantage of our approach is that\nit is scalable to a dataset of any size that can be stored. We present the\nresults of the spatial data subset model approach on simulated datasets, and on\na large dataset consists of 150,000 observations of daytime land surface\ntemperatures measured by the MODIS instrument onboard the Terra satellite.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:52:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13222","submitter":"R\\^omulo M. Vermersch","authors":"R\\^omulo M. Vermersch","title":"Measure-theoretic Uniformly Positive Entropy on the Space of Probability\n  Measures","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For a homeomorphism $T$ on a compact metric space $X$, a $T$-invariant Borel\nprobability measure $\\mu$ on $X$ and a measure-theoretic quasifactor\n$\\widetilde{\\mu}$ of $\\mu$, we study the relationship between the local entropy\nof the system $(X,\\mu,T)$ and of its induced system\n$(\\mathcal{M}(X),\\widetilde{\\mu},\\widetilde{T})$, where $\\widetilde{T}$ is the\nhomeomorphism induced by $T$ on the space $\\mathcal{M}(X)$ of all Borel\nprobability measures defined on $X$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:54:28 GMT"},{"version":"v2","created":"Tue, 23 May 2023 10:33:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13223","submitter":"Yousef Chahine","authors":"Yousef K. Chahine, Ian R. Nemitz, John D. Lekki","title":"Protocol for suppression of noise from stimulated multi-photon emissions\n  in concatenated entanglement swapping links and quantum repeaters","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-photon emissions constitute a fundamental source of noise in quantum\nrepeaters and other quantum communication protocols when probabilistic photon\nsources are employed. In this paper, it is shown that by alternating the Bell\nstate measurement (BSM) basis in concatenated entanglement swapping links one\ncan automatically identify and discard many errors from stimulated multi-photon\nemissions. The proposed protocol is shown to completely eliminate the dominant\nquadratic growth of multi-photon errors with the length of the repeater chain.\nFurthermore, it is shown that the protocol can be employed in\nsatellite-assisted entanglement distribution links to enable links which are\nmore robust in the presence of imbalanced channel losses. The analysis\nintroduces a convenient calculus based on Clifford algebra for modeling\nconcatenated entanglement swapping links with multi-photon emissions. In\nparticular, we present a compact expression for the fidelity of the Bell state\nproduced by a repeater chain of arbitrary length including noise from\ndouble-pair emissions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:55:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13224","submitter":"Ryoichiro Noda","authors":"Ryoichiro Noda","title":"Convergence of local times of stochastic processes associated with\n  resistance forms","comments":"52 pages. arXiv admin note: text overlap with arXiv:1609.05666 by\n  other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We establish that if a sequence of spaces equipped with resistance metrics\nand measures converge with respect to the Gromov-Hausdorff-vague topology, and\ncertain non-explosion and metric-entropy conditions are satisfied, then the\nassociated stochastic processes and their local times also converge. The\nmetric-entropy condition can be checked by volume estimates of balls. Whilst\nsimilar results have been proved previously, the approach of this article is\nmore widely applicable. Indeed, as well as recovering known conclusions for\nscaling limits of some deterministic self-similar fractal graphs and\nGalton-Watson trees, we derive new ones for scaling limits of uniform spanning\ntrees. The metric-entropy condition also implies convergence of Gaussian\nprocesses.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:56:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13225","submitter":"Yue Zhang","authors":"Yue Zhang and Leyang Cui and Deng Cai and Xinting Huang and Tao Fang\n  and Wei Bi","title":"Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A\n  Preliminary Study on Writing Assistance","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  ChatGPT and GPT-4 have attracted substantial interest from both academic and\nindustrial circles, owing to their remarkable few-shot (or even zero-shot)\nability to handle various tasks. Recent work shows that, after being fine-tuned\nwith a few sets of instruction-driven data, the recently proposed LLM, LLaMa,\nexhibits an impressive capability to address a broad range of tasks. However,\nthe zero-shot performance of LLMs does not consistently outperform that of\nmodels fined-tuned for specific scenarios. To explore whether the capabilities\nof LLMs can be further enhanced for specific scenarios, we choose the\nwriting-assistance scenario as the testbed, including seven writing tasks. We\ncollect training data for these tasks, reframe them in an instruction-following\nformat, and subsequently refine LLaMa via instruction tuning. Experimental\nresults show that continually fine-tuning LLaMa on writing instruction data\nsignificantly improves its ability on writing tasks. We also conduct more\nexperiments and analyses to offer insights for future work on effectively\nfine-tuning LLaMa for specific scenarios.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:56:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13226","submitter":"Sean Paulsen","authors":"Sean Paulsen, Michael Casey","title":"Sequential Transfer Learning to Decode Heard and Imagined Timbre from\n  fMRI Data","comments":"Under review. arXiv admin note: substantial text overlap with\n  arXiv:2305.09057","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a sequential transfer learning framework for transformers on\nfunctional Magnetic Resonance Imaging (fMRI) data and demonstrate its\nsignificant benefits for decoding musical timbre. In the first of two phases,\nwe pre-train our stacked-encoder transformer architecture on Next Thought\nPrediction, a self-supervised task of predicting whether or not one sequence of\nfMRI data follows another. This phase imparts a general understanding of the\ntemporal and spatial dynamics of neural activity, and can be applied to any\nfMRI dataset. In the second phase, we fine-tune the pre-trained models and\ntrain additional fresh models on the supervised task of predicting whether or\nnot two sequences of fMRI data were recorded while listening to the same\nmusical timbre. The fine-tuned models achieve significantly higher accuracy\nwith shorter training times than the fresh models, demonstrating the efficacy\nof our framework for facilitating transfer learning on fMRI data. Additionally,\nour fine-tuning task achieves a level of classification granularity beyond\nstandard methods. This work contributes to the growing literature on\ntransformer architectures for sequential transfer learning on fMRI data, and\nprovides evidence that our framework is an improvement over current methods for\ndecoding timbre.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:58:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13227","submitter":"Orhan Koc","authors":"Orhan Koc","title":"Trustless Price Feeds of Cryptocurrencies: Pathfinder","comments":"4 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.CP q-fin.TR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Price feeds of securities is a critical component for many financial\nservices, allowing for collateral liquidation, margin trading, derivative\npricing and more. With the advent of blockchain technology, value in reporting\naccurate prices without a third party has become apparent. There have been many\nattempts at trying to calculate prices without a third party, in which each of\nthese attempts have resulted in being exploited by an exploiter artificially\ninflating the price. The industry has then shifted to a more centralized\ndesign, fetching price data from multiple centralized sources and then applying\nstatistical methods to reach a consensus price. Even though this strategy is\nsecure compared to reading from a single source, enough number of sources need\nto report to be able to apply statistical methods. As more sources participate\nin reporting the price, the feed gets more secure with the slowest feed\nbecoming the bottleneck for query response time, introducing a tradeoff between\nsecurity and speed. This paper provides the design and implementation details\nof a novel method to algorithmically compute security prices in a way that\nartificially inflating targeted pools has no effect on the reported price of\nthe queried asset. We hypothesize that the proposed algorithm can report\naccurate prices given a set of possibly dishonest sources.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:00:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13228","submitter":"Nguyen Manh Linh","authors":"Nguyen Manh Linh","title":"Around the descent conjecture","comments":"46 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.NT","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The descent method is one of the strategies allowing one to study the\nBrauer--Manin obstruction to the local-global principle and to weak\napproximation on varieties over number fields, by reducing the problem to\n\"descent varieties\". Very recently in his Park City lecture notes, Wittenberg\nformulated a \"descent conjecture\" for torsors under linear algebraic groups.\nThe present article gives a proof of this conjecture in the case of connected\ngroups, generalizing the toric case from the previous work of\nHarpaz--Wittenberg. As an application, we deduce directly from Sansuc's work\nthe theorem of Borovoi on Brauer--Manin obstruction for homogeneous spaces of\nconnected linear algebraic groups with connected stabilizers. We are also able\nto reduce the general case to the case of finite (\\'etale) torsors. Another\ninnovation is the notion of non-abelian descent types, which generalizes (and\nwhich is more accessible than) that of extended type of torsors under groups of\nmultiplicative type by Harari--Skorobogatov.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:00:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13229","submitter":"Svante Janson","authors":"Svante Janson","title":"On a central limit theorem in renewal theory","comments":"14 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Serfozo (2009, Theorem 2.65) gives a useful central limit theorem for\nprocesses with regenerative increments. Unfortunately, there is a gap in the\nproof. We fill this gap, and at the same time we weaken the assumptions.\nFurthermore, we give conditions for moment convergence in this setting. We give\nalso further results complementing results in Serfozo (2009) on the law of\nlarge numbers and estimates for the mean; in particular, we show that there is\na gap between conditions for the weak and strong laws of large numbers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:01:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13230","submitter":"Fuzhao Xue","authors":"Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, Yang You","title":"To Repeat or Not To Repeat: Insights from Scaling LLM under Token-Crisis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research has highlighted the importance of dataset size in scaling\nlanguage models. However, large language models (LLMs) are notoriously\ntoken-hungry during pre-training, and high-quality text data on the web is\napproaching its scaling limit for LLMs. To further enhance LLMs, a\nstraightforward approach is to repeat the pre-training data for additional\nepochs. In this study, we empirically investigate three key aspects under this\napproach. First, we explore the consequences of repeating pre-training data,\nrevealing that the model is susceptible to overfitting, leading to multi-epoch\ndegradation. Second, we examine the key factors contributing to multi-epoch\ndegradation, finding that significant factors include dataset size, model\nparameters, and training objectives, while less influential factors consist of\ndataset quality and model FLOPs. Finally, we explore whether widely used\nregularization can alleviate multi-epoch degradation. Most regularization\ntechniques do not yield significant improvements, except for dropout, which\ndemonstrates remarkable effectiveness but requires careful tuning when scaling\nup the model size. Additionally, we discover that leveraging mixture-of-experts\n(MoE) enables cost-effective and efficient hyper-parameter tuning for\ncomputationally intensive dense LLMs with comparable trainable parameters,\npotentially impacting efficient LLM development on a broader scale.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:02:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13231","submitter":"Mark Rychnovsky","authors":"Anna Erschler, Josh Frisch, Mark Rychnovsky","title":"Poisson Boundary for Upper-Triangular Groups","comments":"19 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.DS math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that finite entropy random walks on the torsion-free Baumslag group\nin dimension $d=2$ have non-trivial Poisson boundary. This is in contrast with\nthe torsion case where the situation for simple random walks on Baumslag groups\nis the same as for the lamplighter groups of the same dimension. Our proof uses\nthe realization of the Baumslag group as a linear group. We define and study a\nclass of linear groups associated with multivariable polynomials which we\ndenote $G_k(p)$. We show that the groups $G_3(p)$ have non-trivial Poisson\nboundary for all irreducible finite entropy measures, under a condition on the\npolynomial $p$ which we call the spaced polynomial property. We show that the\nBaumslag group has $G_3(1+x-y)$ as a subgroup, and that the polynomial $p =\n1+x-y$, satisfies this property. Given any upper-triangle group of\ncharacteristic zero, we prove that one of the following must hold: 1) all\nfinite second moment symmetric random walks on $G$ have trivial boundary 2) the\ngroup admits a block, which has a $3$ dimensional wreath product as a subgroup,\nand all non-degenerate random walks on $G$ have non-trivial boundary. 3) $G$\nhas a group $G_3(p)$ as a subgroup. We give a conjectural characterisation of\nall polynomials satisfying the spaced polynomial property. If this is\nconfirmed, our result provides a characterisation of linear groups $G$ which\nadmit a finitely supported symmetric random walk with non-trivial boundary.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:04:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13232","submitter":"Muzhou Yu","authors":"Muzhou Yu, Linfeng Zhang and Kaisheng Ma","title":"Revisiting Data Augmentation in Model Compression: An Empirical and\n  Comprehensive Study","comments":"10 pages, 7 figures, accepted to IJCNN2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The excellent performance of deep neural networks is usually accompanied by a\nlarge number of parameters and computations, which have limited their usage on\nthe resource-limited edge devices. To address this issue, abundant methods such\nas pruning, quantization and knowledge distillation have been proposed to\ncompress neural networks and achieved significant breakthroughs. However, most\nof these compression methods focus on the architecture or the training method\nof neural networks but ignore the influence from data augmentation. In this\npaper, we revisit the usage of data augmentation in model compression and give\na comprehensive study on the relation between model sizes and their optimal\ndata augmentation policy. To sum up, we mainly have the following three\nobservations: (A) Models in different sizes prefer data augmentation with\ndifferent magnitudes. Hence, in iterative pruning, data augmentation with\nvarying magnitudes leads to better performance than data augmentation with a\nconsistent magnitude. (B) Data augmentation with a high magnitude may\nsignificantly improve the performance of large models but harm the performance\nof small models. Fortunately, small models can still benefit from strong data\naugmentations by firstly learning them with \"additional parameters\" and then\ndiscard these \"additional parameters\" during inference. (C) The prediction of a\npre-trained large model can be utilized to measure the difficulty of data\naugmentation. Thus it can be utilized as a criterion to design better data\naugmentation policies. We hope this paper may promote more research on the\nusage of data augmentation in model compression.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:05:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13233","submitter":"George Papamakarios","authors":"Peter Wirnsberger, Borja Ibarz, George Papamakarios","title":"Gibbs free energies via isobaric-isothermal flows","comments":"17 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph cond-mat.stat-mech cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a machine-learning model based on normalizing flows that is\ntrained to sample from the isobaric-isothermal (NPT) ensemble. In our approach,\nwe approximate the joint distribution of a fully-flexible triclinic simulation\nbox and particle coordinates to achieve a desired internal pressure. We test\nour model on monatomic water in the cubic and hexagonal ice phases and find\nexcellent agreement of Gibbs free energies and other observables compared with\nestablished baselines.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:05:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13234","submitter":"Brandon Park Coy","authors":"Brandon Park Coy, Conor A. Nixon, Naomi Rowe-Gurney, Richard\n  Achterberg, Nicholas A. Lombardo, Leigh N. Fletcher, Patrick Irwin","title":"Spitzer IRS Observations of Titan as a Precursor to JWST MIRI\n  Observations","comments":"Accepted to Planetary Science Journal April 28, 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work we present, for the first time, infrared spectra of Titan from\nthe Spitzer Space Telescope ($2004-2009$). The data are from both the short\nwavelength-low resolution (SL, $5.13-14.29\\mathrm{\\mu m}, R\\sim60-127$) and\nshort wavelength-high resolution channels (SH, $9.89 - 19.51\\mathrm{\\mu m},\nR\\sim600$) showing the emissions of CH$_{4}$, C$_{2}$H$_{2}$, C$_{2}$H$_{4}$,\nC$_{2}$H$_{6}$, C$_{3}$H$_{4}$, C$_{3}$H$_{6}$, C$_{3}$H$_{8}$, C$_{4}$H$_{2}$,\nHCN, HC$_{3}$N, and CO$_{2}$. We compare the results obtained for Titan from\nSpitzer to those of the Cassini Composite Infrared Spectrometer (CIRS) for the\nsame time period, focusing on the $16.35-19.35\\mathrm{\\mu m}$ wavelength range\nobserved by the SH channel but impacted by higher noise levels in CIRS\nobservations. We use the SH data to provide estimated haze extinction\ncross-sections for the $16.67-17.54\\mathrm{\\mu m}$ range that are missing in\nprevious studies. We conclude by identifying spectral features in the\n$16.35-19.35\\mathrm{\\mu m}$ wavelength range, including two prominent emission\nfeatures at 16.39 and $17.35\\mathrm{\\mu m}$, that could be analyzed further\nthrough upcoming James Webb Space Telescope Cycle 1 observations with the\nMid-Infrared Instrument ($5.0-28.3\\mathrm{\\mu m}, R\\sim1500-3500$). We also\nhighlight gaps in current spectroscopic knowledge of molecular bands, including\ncandidate trace species such as C$_{60}$ and detected trace species such as\nC$_{3}$H$_{6}$, that could be addressed by theoretical and laboratory study.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:06:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13235","submitter":"Oana-Maria Camburu","authors":"Jesus Solano, Oana-Maria Camburu, Pasquale Minervini","title":"SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly\n  Generating Predictions and Natural Language Explanations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Explaining the decisions of neural models is crucial for ensuring their\ntrustworthiness at deployment time. Using Natural Language Explanations (NLEs)\nto justify a model's predictions has recently gained increasing interest.\nHowever, this approach usually demands large datasets of human-written NLEs for\nthe ground-truth answers, which are expensive and potentially infeasible for\nsome applications. For models to generate high-quality NLEs when only a few\nNLEs are available, the fine-tuning of Pre-trained Language Models (PLMs) in\nconjunction with prompt-based learning recently emerged. However, PLMs\ntypically have billions of parameters, making fine-tuning expensive. We propose\nSparseFit, a sparse few-shot fine-tuning strategy that leverages discrete\nprompts to jointly generate predictions and NLEs. We experiment with SparseFit\non the T5 model and four datasets and compare it against state-of-the-art\nparameter-efficient fine-tuning techniques. We perform automatic and human\nevaluations to assess the quality of the model-generated NLEs, finding that\nfine-tuning only 6.8% of the model parameters leads to competitive results for\nboth the task performance and the quality of the NLEs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:06:41 GMT"},{"version":"v2","created":"Tue, 23 May 2023 09:26:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13236","submitter":"Vahid Janfaza","authors":"Vahid Janfaza, Shantanu Mandal, Farabi Mahmud, Abdullah Muzahid","title":"Adaptive Gradient Prediction for DNN Training","comments":"11 pages, 18 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural network training is inherently sequential where the layers finish the\nforward propagation in succession, followed by the calculation and\nback-propagation of gradients (based on a loss function) starting from the last\nlayer. The sequential computations significantly slow down neural network\ntraining, especially the deeper ones. Prediction has been successfully used in\nmany areas of computer architecture to speed up sequential processing.\nTherefore, we propose ADA-GP, that uses gradient prediction adaptively to speed\nup deep neural network (DNN) training while maintaining accuracy. ADA-GP works\nby incorporating a small neural network to predict gradients for different\nlayers of a DNN model. ADA-GP uses a novel tensor reorganization to make it\nfeasible to predict a large number of gradients. ADA-GP alternates between DNN\ntraining using backpropagated gradients and DNN training using predicted\ngradients. ADA-GP adaptively adjusts when and for how long gradient prediction\nis used to strike a balance between accuracy and performance. Last but not\nleast, we provide a detailed hardware extension in a typical DNN accelerator to\nrealize the speed up potential from gradient prediction. Our extensive\nexperiments with fourteen DNN models show that ADA-GP can achieve an average\nspeed up of 1.47x with similar or even higher accuracy than the baseline\nmodels. Moreover, it consumes, on average, 34% less energy due to reduced\noff-chip memory accesses compared to the baseline hardware accelerator.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:10:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13237","submitter":"Yuhao Zhou","authors":"Yuhao Zhou, Xiaohong Li, Jie Hong, Rony Keppens","title":"Winking filaments due to cyclic evaporation-condensation","comments":"14 pages, 6 figures. Accepted by A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Observations have shown that some filaments appear and disappear in the\nH$\\alpha$ line wing images periodically. There have been no attempts to model\nthese \"winking filaments\" thus far. The evaporation--condensation mechanism is\nwidely used to explain the formation of solar filaments. Here, we demonstrate,\nfor the first time, how multi-dimensional evaporation--condensation in an\narcade setup invariably causes a stretching of the magnetic topology. We aim to\ncheck whether this magnetic stretching during cyclic evaporation--condensation\ncould reproduce a winking filament. We used our open-source code MPI-AMRVAC to\ncarry out 2D magnetohydrodynamic simulations based on a quadrupolar\nconfiguration. A periodic localized heating, which modulates the\nevaporation--condensation process, was imposed before, during, and after the\nformation of the filament. Synthetic H$\\alpha$ and 304 \\r{A}, images were\nproduced to compare the results with observations. For the first time, we\nnoticed the winking filament phenomenon in a simulation of the formation of\non-disk solar filaments, which was in good agreement with observations.\nTypically, the period of the winking is different from the period of the\nimpulsive heating. A forced oscillator model explains this difference and fits\nthe results well. A parameter survey is also done to look into details of the\nmagnetic stretching phenomenon. We found that the stronger the heating or the\nhigher the layer where the heating occurs, the more significant the winking\neffect appears.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:11:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13238","submitter":"Hanlin Li","authors":"Hanlin Li, Nicholas Vincent, Stevie Chancellor, Brent Hecht","title":"The Dimensions of Data Labor: A Road Map for Researchers, Activists, and\n  Policymakers to Empower Data Producers","comments":"To appear at the 2023 ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT)","journal-ref":null,"doi":"10.1145/3593013.3594070","report-no":null,"categories":"cs.CY","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Many recent technological advances (e.g. ChatGPT and search engines) are\npossible only because of massive amounts of user-generated data produced\nthrough user interactions with computing systems or scraped from the web (e.g.\nbehavior logs, user-generated content, and artwork). However, data producers\nhave little say in what data is captured, how it is used, or who it benefits.\nOrganizations with the ability to access and process this data, e.g. OpenAI and\nGoogle, possess immense power in shaping the technology landscape. By\nsynthesizing related literature that reconceptualizes the production of data\nfor computing as ``data labor'', we outline opportunities for researchers,\npolicymakers, and activists to empower data producers in their relationship\nwith tech companies, e.g advocating for transparency about data reuse, creating\nfeedback channels between data producers and companies, and potentially\ndeveloping mechanisms to share data's revenue more broadly. In doing so, we\ncharacterize data labor with six important dimensions - legibility, end-use\nawareness, collaboration requirement, openness, replaceability, and livelihood\noverlap - based on the parallels between data labor and various other types of\nlabor in the computing literature.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:11:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13239","submitter":"Andreas Galanis","authors":"Andreas Galanis, Leslie Ann Goldberg, Paulina Smolarova","title":"Sampling from the random cluster model on random regular graphs at all\n  temperatures via Glauber dynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR cs.DM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the performance of Glauber dynamics for the random cluster model\nwith real parameter $q>1$ and temperature $\\beta>0$. Recent work by Helmuth,\nJenssen and Perkins detailed the ordered/disordered transition of the model on\nrandom $\\Delta$-regular graphs for all sufficiently large $q$ and obtained an\nefficient sampling algorithm for all temperatures $\\beta$ using cluster\nexpansion methods. Despite this major progress, the performance of natural\nMarkov chains, including Glauber dynamics, is not yet well understood on the\nrandom regular graph, partly because of the non-local nature of the model\n(especially at low temperatures) and partly because of severe bottleneck\nphenomena that emerge in a window around the ordered/disordered transition.\n  Nevertheless, it is widely conjectured that the bottleneck phenomena that\nimpede mixing from worst-case starting configurations can be avoided by\ninitialising the chain more judiciously. Our main result establishes this\nconjecture for all sufficiently large $q$ (with respect to $\\Delta$).\nSpecifically, we consider the mixing time of Glauber dynamics initialised from\nthe two extreme configurations, the all-in and all-out, and obtain a pair of\nfast mixing bounds which cover all temperatures $\\beta$, including in\nparticular the bottleneck window. Our result is inspired by the recent approach\nof Gheissari and Sinclair for the Ising model who obtained a similar-flavoured\nmixing-time bound on the random regular graph for sufficiently low\ntemperatures. To cover all temperatures in the RC model, we refine\nappropriately the structural results of Helmuth, Jenssen and Perkins about the\nordered/disordered transition and show spatial mixing properties ''within the\nphase'', which are then related to the evolution of the chain.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:11:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13240","submitter":"Mark Arildsen","authors":"Mark J. Arildsen, Ji-Yao Chen, Norbert Schuch, Andreas W. W. Ludwig","title":"Entanglement Spectrum as a diagnostic of chirality of Topological Spin\n  Liquids: Analysis of an $\\mathrm{SU}(3)$ PEPS","comments":"49 pages, 14 figures, 8 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.stat-mech quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  (2+1)-D chiral topological phases are often identified by studying low-lying\nentanglement spectra (ES) of their wavefunctions on long cylinders of finite\ncircumference. For chiral topological states that possess global\n$\\mathrm{SU}(3)$ symmetry, we can now understand, as shown in this work, the\nnature of the topological phase from the study of the splittings of\ndegeneracies in the finite-size ES, at a given momentum, solely from the\nperspective of conformal field theory (CFT). This is a finer diagnostic than\nLi-Haldane \"state-counting\", extending the approach of PRB 106, 035138 (2022)\nby two of the authors. We contrast ES of such chiral topological states with\nthose of a non-chiral PEPS (Kure\\v{c}i\\'c, Sterdyniak, and Schuch [PRB 99,\n045116 (2019)]) also possessing $\\mathrm{SU}(3)$ symmetry. That latter PEPS has\nthe same discrete symmetry as the chiral PEPS: strong breaking of separate\ntime-reversal and reflection symmetries, with invariance under the product of\nthese two operations. However, the full analysis of the topological sectors of\nthe ES of the latter PEPS in prior work [arXiv:2207.03246] shows lack of\nchirality, as would be manifested, e.g., by a vanishing chiral central charge.\nIn the present work, we identify a distinct indicator and hallmark of chirality\nin the ES: the splittings of conjugate irreps. We prove that in the ES of the\nchiral states conjugate irreps are exactly degenerate, because the operators\n[related to the cubic Casimir invariant of $\\mathrm{SU}(3)$] that would split\nthem are forbidden. By contrast, in the ES of non-chiral states, conjugate\nsplittings are demonstrably non-vanishing. Such a diagnostic significantly\nsimplifies identification of non-chirality in low-energy finite-size ES for\n$\\mathrm{SU}(3)$-symmetric topological states.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:12:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13241","submitter":"Ben Titzer","authors":"Ben L. Titzer","title":"Whose Baseline (compiler) is it anyway?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Compilers face a intrinsic tradeoff between compilation speed and code\nquality. The tradeoff is particularly stark in a dynamic setting where JIT\ncompilation time contributes to application runtime. Many systems now employ\nmultiple compilation tiers, where one tier offers fast compile speed while\nanother has much slower compile speed but produces higher quality code. With\nproper heuristics on when to use each, the overall performance is better than\nusing either compiler in isolation. At the introduction of WebAssembly into the\nWeb platform in 2017, most engines employed optimizing compilers and\npre-compiled entire modules before execution. Yet since that time, all Web\nengines have introduced new \"baseline\" compiler tiers for Wasm to improve\nstartup time. Further, many new non-web engines have appeared, some of which\nalso employ simple compilers. In this paper, we demystify single-pass compilers\nfor Wasm, explaining their internal algorithms and tradeoffs, as well as\nproviding a detailed empirical study of those employed in production. We show\nthe design of a new single-pass compiler for a research Wasm engine that\nintegrates with an in-place interpreter and host garbage collector using value\ntags. In experiments, we measure the effectiveness of optimizations targeting\nthe cost of value tags, the relative compile speed and execution time of six\nbaseline compilers, and place these baseline compilers in the tradeoff space\nwith other execution tiers for Wasm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:13:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13242","submitter":"Yafu Li","authors":"Yafu Li, Qintong Li, Leyang Cui, Wei Bi, Longyue Wang, Linyi Yang,\n  Shuming Shi and Yue Zhang","title":"Deepfake Text Detection in the Wild","comments":"Working in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advances in large language models have enabled them to reach a level\nof text generation comparable to that of humans. These models show powerful\ncapabilities across a wide range of content, including news article writing,\nstory generation, and scientific writing. Such capability further narrows the\ngap between human-authored and machine-generated texts, highlighting the\nimportance of deepfake text detection to avoid potential risks such as fake\nnews propagation and plagiarism. However, previous work has been limited in\nthat they testify methods on testbed of specific domains or certain language\nmodels. In practical scenarios, the detector faces texts from various domains\nor LLMs without knowing their sources. To this end, we build a wild testbed by\ngathering texts from various human writings and deepfake texts generated by\ndifferent LLMs. Human annotators are only slightly better than random guessing\nat identifying machine-generated texts. Empirical results on automatic\ndetection methods further showcase the challenges of deepfake text detection in\na wild testbed. In addition, out-of-distribution poses a greater challenge for\na detector to be employed in realistic application scenarios. We release our\nresources at https://github.com/yafuly/DeepfakeTextDetect.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:13:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13243","submitter":"Hammond Pearce","authors":"Jason Blocklove and Siddharth Garg and Ramesh Karri and Hammond Pearce","title":"Chip-Chat: Challenges and Opportunities in Conversational Hardware\n  Design","comments":"9 pages, 14 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AR cs.PL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modern hardware design starts with specifications provided in natural\nlanguage. These are then translated by hardware engineers into appropriate\nHardware Description Languages (HDLs) such as Verilog before synthesizing\ncircuit elements. Automating this translation could reduce sources of human\nerror from the engineering process. But, it is only recently that artificial\nintelligence (AI) has demonstrated capabilities for machine-based end-to-end\ndesign translations. Commercially-available instruction-tuned Large Language\nModels (LLMs) such as OpenAI's ChatGPT and Google's Bard claim to be able to\nproduce code in a variety of programming languages; but studies examining them\nfor hardware are still lacking. In this work, we thus explore the challenges\nfaced and opportunities presented when leveraging these recent advances in LLMs\nfor hardware design. Using a suite of 8 representative benchmarks, we examined\nthe capabilities and limitations of the state of the art conversational LLMs\nwhen producing Verilog for functional and verification purposes. Given that the\nLLMs performed best when used interactively, we then performed a longer fully\nconversational case study where a hardware engineer co-designed a novel 8-bit\naccumulator-based microprocessor architecture. We sent the benchmarks and\nprocessor to tapeout in a Skywater 130nm shuttle, meaning that these\n'Chip-Chats' resulted in what we believe to be the world's first\nwholly-AI-written HDL for tapeout.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:13:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13244","submitter":"Javier Cuerda","authors":"Javier Cuerda, Jani M. Taskinen, Nicki K\\\"allman, Leo Grabitz, P\\\"aivi\n  T\\\"orm\\\"a","title":"Pseudospin-orbit coupling and non-Hermitian effects in the Quantum\n  Geometric Tensor of a plasmonic lattice","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We theoretically predict the full quantum geometric tensor, comprising the\nquantum metric and the Berry curvature, for a square lattice of plasmonic\nnanoparticles. The gold nanoparticles act as dipole or multipole antenna\nradiatively coupled over long distances. The photonic-plasmonic eigenfunctions\nand energies of the system depend on momentum and polarization (pseudospin),\nand their topological properties are encoded in the quantum geometric tensor.\nBy T-matrix numerical simulations, we identify a TE-TM band splitting at the\ndiagonals of the first Brillouin zone, that is not predicted by the empty\nlattice band structure nor by the highly symmetric nature of the system.\nFurther, we find quantum metric around these regions of the reciprocal space,\nand even a non-zero Berry curvature despite the trivial lattice geometry and\nabsence of magnetic field. We show that this non-zero Berry curvature arises\nexclusively from non-Hermitian effects which break the time-reversal symmetry.\nThe quantum metric, in contrast, originates from a pseudospin-orbit coupling\ngiven by the polarization and directional dependence of the radiation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:13:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13245","submitter":"Michiel de Jong","authors":"Joshua Ainslie, James Lee-Thorp, Michiel de Jong, Yury Zemlyanskiy,\n  Federico Lebr\\'on, Sumit Sanghai","title":"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head\n  Checkpoints","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-query attention (MQA), which only uses a single key-value head,\ndrastically speeds up decoder inference. However, MQA can lead to quality\ndegradation, and moreover it may not be desirable to train a separate model\njust for faster inference. We (1) propose a recipe for uptraining existing\nmulti-head language model checkpoints into models with MQA using 5% of original\npre-training compute, and (2) introduce grouped-query attention (GQA), a\ngeneralization of multi-query attention which uses an intermediate (more than\none, less than number of query heads) number of key-value heads. We show that\nuptrained GQA achieves quality close to multi-head attention with comparable\nspeed to MQA.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:16:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13246","submitter":"Zekun Wang","authors":"Zekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun\n  Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, Qingqing Zhu,\n  Zhenzhu Yang, Adam Nik, Qi Liu, Chenghua Lin, Shi Wang, Ruibo Liu, Wenhu\n  Chen, Ke Xu, Dayiheng Liu, Yike Guo, Jie Fu","title":"Interactive Natural Language Processing","comments":"110 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Interactive Natural Language Processing (iNLP) has emerged as a novel\nparadigm within the field of NLP, aimed at addressing limitations in existing\nframeworks while aligning with the ultimate goals of artificial intelligence.\nThis paradigm considers language models as agents capable of observing, acting,\nand receiving feedback iteratively from external entities. Specifically,\nlanguage models in this context can: (1) interact with humans for better\nunderstanding and addressing user needs, personalizing responses, aligning with\nhuman values, and improving the overall user experience; (2) interact with\nknowledge bases for enriching language representations with factual knowledge,\nenhancing the contextual relevance of responses, and dynamically leveraging\nexternal information to generate more accurate and informed responses; (3)\ninteract with models and tools for effectively decomposing and addressing\ncomplex tasks, leveraging specialized expertise for specific subtasks, and\nfostering the simulation of social behaviors; and (4) interact with\nenvironments for learning grounded representations of language, and effectively\ntackling embodied tasks such as reasoning, planning, and decision-making in\nresponse to environmental observations. This paper offers a comprehensive\nsurvey of iNLP, starting by proposing a unified definition and framework of the\nconcept. We then provide a systematic classification of iNLP, dissecting its\nvarious components, including interactive objects, interaction interfaces, and\ninteraction methods. We proceed to delve into the evaluation methodologies used\nin the field, explore its diverse applications, scrutinize its ethical and\nsafety issues, and discuss prospective research directions. This survey serves\nas an entry point for researchers who are interested in this rapidly evolving\narea and offers a broad view of the current landscape and future trajectory of\niNLP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:18:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13247","submitter":"Shiri Ron","authors":"Moshe Babaioff and Shahar Dobzinski and Shiri Ron","title":"On the Computational Complexity of Mechanism Design in Single-Crossing\n  Settings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore the performance of polynomial-time incentive-compatible mechanisms\nin single-crossing domains. Single-crossing domains were extensively studied in\nthe economics literature. Roughly speaking, a domain is single crossing if\nmonotonicity characterizes incentive compatibility. That is, single-crossing\ndomains are the standard mathematical formulation of domains that are\ninformally known as ``single parameter''. In all major single-crossing domains\nstudied so far (e.g., welfare maximization in various auctions with\nsingle-minded bidders, makespan minimization on related machines), the\nperformance of the best polynomial-time incentive-compatible mechanisms matches\nthe performance of the best polynomial-time non-incentive-compatible\nalgorithms. Our two main results make progress in understanding the power of\nincentive-compatible polynomial-time mechanisms in single-crossing domains:\n  We provide the first proof of a gap in the power of polynomial-time\nincentive-compatible mechanisms and polynomial-time non-incentive-compatible\nalgorithms: we present an objective function in a single-crossing multi-unit\nauction for which there is a polynomial-time algorithm that provides an\napproximation ratio of $\\frac{1}{2}$, yet no polynomial-time\nincentive-compatible mechanism provides a finite approximation (under standard\ncomputational complexity assumptions).\n  The objective function used above is not natural. We show that to some extent\nthis is unavoidable by providing a sweeping positive result for the most\nnatural objective function in multi-unit auctions, that of welfare\nmaximization. We present an incentive-compatible FPTAS mechanism for every\nmulti-unit auction with single-crossing domains. This improves over the\nmechanism of Briest et al. [STOC'05] that only applies to the much simpler case\nof single-minded bidders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:18:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13248","submitter":"Katharina Ott","authors":"Katharina Ott, Michael Tiemann, Philipp Hennig, Fran\\c{c}ois-Xavier\n  Briol","title":"Bayesian Numerical Integration with Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bayesian probabilistic numerical methods for numerical integration offer\nsignificant advantages over their non-Bayesian counterparts: they can encode\nprior information about the integrand, and can quantify uncertainty over\nestimates of an integral. However, the most popular algorithm in this class,\nBayesian quadrature, is based on Gaussian process models and is therefore\nassociated with a high computational cost. To improve scalability, we propose\nan alternative approach based on Bayesian neural networks which we call\nBayesian Stein networks. The key ingredients are a neural network architecture\nbased on Stein operators, and an approximation of the Bayesian posterior based\non the Laplace approximation. We show that this leads to orders of magnitude\nspeed-ups on the popular Genz functions benchmark, and on challenging problems\narising in the Bayesian analysis of dynamical systems, and the prediction of\nenergy production for a large-scale wind farm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:19:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13250","submitter":"Xiaofan Zhou","authors":"Xiaofan Zhou, Xunzhu Tang","title":"Copy Recurrent Neural Network Structure Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electronic Health Record (EHR) coding involves automatically classifying EHRs\ninto diagnostic codes. While most previous research treats this as a\nmulti-label classification task, generating probabilities for each code and\nselecting those above a certain threshold as labels, these approaches often\noverlook the challenge of identifying complex diseases. In this study, our\nfocus is on detecting complication diseases within EHRs.\n  We propose a novel coarse-to-fine ICD path generation framework called the\nCopy Recurrent Neural Network Structure Network (CRNNet), which employs a Path\nGenerator (PG) and a Path Discriminator (PD) for EHR coding. By using RNNs to\ngenerate sequential outputs and incorporating a copy module, we efficiently\nidentify complication diseases. Our method achieves a 57.30\\% ratio of complex\ndiseases in predictions, outperforming state-of-the-art and previous\napproaches.\n  Additionally, through an ablation study, we demonstrate that the copy\nmechanism plays a crucial role in detecting complex diseases.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:22:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13252","submitter":"Orion Weller","authors":"Orion Weller and Marc Marone and Nathaniel Weir and Dawn Lawrie and\n  Daniel Khashabi and Benjamin Van Durme","title":"\"According to ...\" Prompting Language Models Improves Quoting from\n  Pre-Training Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large Language Models (LLMs) may hallucinate and generate fake information,\ndespite pre-training on factual data. Inspired by the journalistic device of\n\"according to sources\", we propose according-to prompting: directing LLMs to\nground responses against previously observed text. To quantify this grounding,\nwe propose a novel evaluation metric (QUIP-Score) that measures the extent to\nwhich model-produced answers are directly found in underlying text corpora. We\nillustrate with experiments on Wikipedia that these prompts improve grounding\nunder our metrics, with the additional benefit of often improving end-task\nperformance. Furthermore, prompts that ask the model to decrease grounding (or\nto ground to other corpora) decrease grounding, indicating the ability of\nlanguage models to increase or decrease grounded generations on request.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:25:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13255","submitter":"Steven Damelin Dr","authors":"Leon A. Luxemburg and Steven B. Damelin","title":"The Geometric Approach to the Classification of Signals via a Maximal\n  Set of Signals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we study the scale-space classification of signals via the\nmaximal set of kernels. We use a geometric approach which arises naturally when\nwe consider parameter variations in scale-space. We derive the Fourier\ntransform formulas for quick and efficient computation of zero-crossings and\nthe corresponding classifying trees. General theory of convergence for\nconvolutions is developed, and practically useful properties of scale-space\nclassification are derived as a consequence also give a complete topological\ndescription of level curves for convolutions of signals with the maximal set of\nkernels. We use these results to develop a bifurcation theory for the curves\nunder the parameter changes. This approach leads to a novel set of integer\ninvariants for arbitrary signals.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:26:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13256","submitter":"Joongwon Kim","authors":"Joongwon Kim, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi","title":"TaskWeb: Selecting Better Source Tasks for Multi-task NLP","comments":"22 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent work in NLP has shown promising results in training models on large\namounts of tasks to achieve better generalization. However, it is not\nwell-understood how tasks are related, and how helpful training tasks can be\nchosen for a new task. In this work, we investigate whether knowing task\nrelationships via pairwise task transfer improves choosing one or more source\ntasks that help to learn a new target task. We provide TaskWeb, a large-scale\nbenchmark of pairwise task transfers for 22 NLP tasks using three different\nmodel types, sizes, and adaptation methods, spanning about 25,000 experiments.\nThen, we design a new method TaskShop based on our analysis of TaskWeb.\nTaskShop uses TaskWeb to estimate the benefit of using a source task for\nlearning a new target, and to choose a subset of helpful training tasks for\nmulti-task learning. Our method improves overall rankings and top-k precision\nof source tasks by 12% and 29%, respectively. We also use TaskShop to build\nsmaller multi-task training sets that improve zero-shot performances across 11\ndifferent target tasks by at least 4.3%.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:27:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13257","submitter":"Yixin Liu","authors":"Yixin Liu, Hongsheng Hu, Xuyun Zhang and Lichao Sun","title":"Watermarking Text Data on Large Language Models for Dataset Copyright\n  Protection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large Language Models (LLMs), such as BERT and GPT-based models like ChatGPT,\nhave recently demonstrated their impressive capacity for learning language\nrepresentations, yielding significant benefits for various downstream Natural\nLanguage Processing (NLP) tasks. However, the immense data requirements of\nthese large models have incited substantial concerns regarding copyright\nprotection and data privacy. In an attempt to address these issues,\nparticularly the unauthorized use of private data in LLMs, we introduce a novel\nwatermarking technique via a backdoor-based membership inference approach,\ni.e., TextMarker, which can safeguard diverse forms of private information\nembedded in the training text data in LLMs. Specifically, TextMarker is a new\nmembership inference framework that can eliminate the necessity for additional\nproxy data and surrogate model training, which are common in traditional\nmembership inference techniques, thereby rendering our proposal significantly\nmore practical and applicable.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:28:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13258","submitter":"David Herron","authors":"David Herron, Ernesto Jim\\'enez-Ruiz, Giacomo Tarroni and Tillman\n  Weyde","title":"NeSy4VRD: A Multifaceted Resource for Neurosymbolic AI Research using\n  Knowledge Graphs in Visual Relationship Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  NeSy4VRD is a multifaceted resource designed to support the development of\nneurosymbolic AI (NeSy) research. NeSy4VRD re-establishes public access to the\nimages of the VRD dataset and couples them with an extensively revised,\nquality-improved version of the VRD visual relationship annotations. Crucially,\nNeSy4VRD provides a well-aligned, companion OWL ontology that describes the\ndataset domain.It comes with open source infrastructure that provides\ncomprehensive support for extensibility of the annotations (which, in turn,\nfacilitates extensibility of the ontology), and open source code for loading\nthe annotations to/from a knowledge graph. We are contributing NeSy4VRD to the\ncomputer vision, NeSy and Semantic Web communities to help foster more NeSy\nresearch using OWL-based knowledge graphs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:28:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13259","submitter":"Neo Chung-Kit Yiu","authors":"Jiseong Noh, Donghwan Kwon, Soohwan Cho, Neo C.K. Yiu","title":"Network Participation and Accessibility of Proof-of-Stake (PoS)\n  Blockchains: A Cross-platform Comparative Analysis","comments":"8 pages, 8 tables and 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.CY cs.DC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The comparative analysis examined eleven Proof-of-Stake (PoS) consensus-based\nblockchain networks to assess their openness based on five indicative metrics.\nThese metrics include those of decentralization-related aspects, such as the\nnumber of validators and capital concentration, and participation-related\naspects, including entry capital requirements and economic network stability.\nThis is to assess and characterize the openness of Proof-of-Stake blockchain\nnetworks. The analysis suggested that networks with higher openness included\nSolana and Avalanche, while BNB Chain, Klaytn, and Polygon measured with lower\nlevels of openness. According to the comparative analysis, Ethereum scored high\non network openness in terms of the number of participants and the cost of\nrunning the chain, but scored relatively low on capital concentration and\nstaking ratio, which is likely due to the low ratio of staked ether (ETH) to\ncirculating supply and the significant stakes in staking pools like Lido.\nPermissioned blockchains such as Klaytn and Polygon have limited openness,\nwhich suggests the need to take the level of openness into account when\ntransitioning into a permissionless blockchain architecture with a more\ndecentralized setting.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:31:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13262","submitter":"Christopher Mitcheltree","authors":"Christopher Mitcheltree, Christian J. Steinmetz, Marco Comunit\\`a,\n  Joshua D. Reiss","title":"Modulation Extraction for LFO-driven Audio Effects","comments":"Accepted to DAFx 2023. Listening samples and plugins can be found at\n  https://christhetree.github.io/mod_extraction/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Low frequency oscillator (LFO) driven audio effects such as phaser, flanger,\nand chorus, modify an input signal using time-varying filters and delays,\nresulting in characteristic sweeping or widening effects. It has been shown\nthat these effects can be modeled using neural networks when conditioned with\nthe ground truth LFO signal. However, in most cases, the LFO signal is not\naccessible and measurement from the audio signal is nontrivial, hindering the\nmodeling process. To address this, we propose a framework capable of extracting\narbitrary LFO signals from processed audio across multiple digital audio\neffects, parameter settings, and instrument configurations. Since our system\nimposes no restrictions on the LFO signal shape, we demonstrate its ability to\nextract quasiperiodic, combined, and distorted modulation signals that are\nrelevant to effect modeling. Furthermore, we show how coupling the extraction\nmodel with a simple processing network enables training of end-to-end black-box\nmodels of unseen analog or digital LFO-driven audio effects using only dry and\nwet audio pairs, overcoming the need to access the audio effect or internal LFO\nsignal. We make our code available and provide the trained audio effect models\nin a real-time VST plugin.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:33:07 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13264","submitter":"Jennifer Hu","authors":"Jennifer Hu and Roger Levy","title":"Prompt-based methods may underestimate large language models' linguistic\n  generalizations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Prompting is now a dominant method for evaluating the linguistic knowledge of\nlarge language models (LLMs). While other methods directly read out models'\nprobability distributions over strings, prompting requires models to access\nthis internal information by processing linguistic input, thereby implicitly\ntesting a new type of emergent ability: metalinguistic judgment. In this study,\nwe compare metalinguistic prompting and direct probability measurements as ways\nof measuring models' knowledge of English. Broadly, we find that LLMs'\nmetalinguistic judgments are inferior to quantities directly derived from\nrepresentations. Furthermore, consistency gets worse as the prompt diverges\nfrom direct measurements of next-word probabilities. Our findings suggest that\nnegative results relying on metalinguistic prompts cannot be taken as\nconclusive evidence that an LLM lacks a particular linguistic competence. Our\nresults also highlight the lost value with the move to closed APIs where access\nto probability distributions is limited.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:33:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13265","submitter":"Takeo Uramoto","authors":"Takeo Uramoto","title":"Semi-galois Categories IV: A deformed reciprocity law for Siegel modular\n  functions","comments":"many typos fixed; preprint. 24 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper is a sequel to our previous work, where we proved the ``modularity\ntheorem'' for algebraic Witt vectors over imaginary quadratic fields. This\ntheorem states that, in the case of imaginary quadratic fields $K$, the\nalgebraic Witt vectors over $K$ are precisely those generated by the modular\nvectors whose components are given by special values of deformation family of\nFricke modular functions; arithmetically, this theorem implies certain\ncongruences between special values of modular functions that are not\nnecessarily galois conjugate. In order to take a closer look at this modularity\ntheorem, the current paper extends it to the case of CM fields. The main\nresults include (i) a construction of algebraic Witt vectors from special\nvalues of deformation family of Siegel modular functions on Siegel upper-half\nspace given by ratios of theta functions, and (ii) a galois-theoretic\ncharacterization of which algebraic Witt vectors arise in this modular way,\nintending to exemplify a general galois-correspondence result which is also\nproved in this paper.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:33:30 GMT"},{"version":"v2","created":"Wed, 24 May 2023 13:55:15 GMT"},{"version":"v3","created":"Thu, 25 May 2023 14:43:57 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13267","submitter":"Wenjuan Han","authors":"Yueting Yang, Xintong Zhang, Wenjuan Han","title":"Enhance Reasoning Ability of Visual-Language Models via Large Language\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained visual language models (VLM) have shown excellent performance in\nimage caption tasks. However, it sometimes shows insufficient reasoning\nability. In contrast, large language models (LLMs) emerge with powerful\nreasoning capabilities. Therefore, we propose a method called TReE, which\ntransfers the reasoning ability of a large language model to a visual language\nmodel in zero-shot scenarios. TReE contains three stages: observation,\nthinking, and re-thinking. Observation stage indicates that VLM obtains the\noverall information of the relative image. Thinking stage combines the image\ninformation and task description as the prompt of the LLM, inference with the\nrationals. Re-Thinking stage learns from rationale and then inference the final\nresult through VLM.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:33:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13269","submitter":"Xingxuan Li","authors":"Xingxuan Li, Ruochen Zhao, Yew Ken Chia, Bosheng Ding, Lidong Bing,\n  Shafiq Joty, Soujanya Poria","title":"Chain of Knowledge: A Framework for Grounding Large Language Models with\n  Structured Knowledge Bases","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce Chain of Knowledge (CoK), a framework that augments large\nlanguage models with structured knowledge bases to improve factual correctness\nand reduce hallucination. Compared to previous works which only retrieve\nunstructured texts, CoK leverages structured knowledge bases which support\ncomplex queries and offer more direct factual statements. To assist large\nlanguage models to effectively query knowledge bases, we propose a query\ngenerator model with contrastive instruction-tuning. As the query generator is\nseparate from the frozen large language model, our framework is modular and\nthus easily adapted to various knowledge sources and models. Experiments show\nthat our framework significantly enhances the factual correctness of large\nlanguage models on knowledge-intensive tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:34:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13270","submitter":"Samya Kumar Ray","authors":"Rajeev Gupta, Gadadhar Misra and Samya Kumar Ray","title":"On a variant of the Grothendieck inequality and estimates on tensor\n  product norms","comments":"Preliminary version, 21 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we propose a generalization of the Grothendieck inequality for\npairs of Banach spaces $E$ and $F$ with $E$ being finite dimensional and\ninvestigate the behaviour of the Grothendieck constant $K_G(E,F)$ implicit in\nsuch an inequality. We show that if $\\sup\\{K_G(E_n,F): n\\geqslant 1\\}$ is\nfinite for some sequence of finite dimensional Banach spaces $(E_n)_{n\\geqslant\n1}$ with $\\dim E_n=n$, and an infinite dimensional Banach space $F$, then both\n$F$ and $F^*$ must have finite cotype. In addition to that if $F$ has the\nbounded approximation property, we conclude that $(E_n^*)_{n\\geqslant 1}$\nsatisfies G.T. uniformly by assuming the validity of a conjecture due to\nPisier. We also show that $K_G(E,F)$ is closely related to the constant\n$\\rho(E,F)$, introduced recently, comparing the projective and injective norms\non the tensor product of two finite dimensional Banach spaces $E$ and $F$. We\nalso study, analogously, these constants by computing the supremum only on\nnon-negative tensors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:34:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13271","submitter":"Felix Hensel","authors":"Felix Hensel, Charles Arnal, Mathieu Carri\\`ere, Th\\'eo Lacombe,\n  Hiroaki Kurihara, Yuichi Ike, Fr\\'ed\\'eric Chazal","title":"MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of\n  Deep Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite their successful application to a variety of tasks, neural networks\nremain limited, like other machine learning methods, by their sensitivity to\nshifts in the data: their performance can be severely impacted by differences\nin distribution between the data on which they were trained and that on which\nthey are deployed. In this article, we propose a new family of representations,\ncalled MAGDiff, that we extract from any given neural network classifier and\nthat allows for efficient covariate data shift detection without the need to\ntrain a new model dedicated to this task. These representations are computed by\ncomparing the activation graphs of the neural network for samples belonging to\nthe training distribution and to the target distribution, and yield powerful\ndata- and task-adapted statistics for the two-sample tests commonly used for\ndata set shift detection. We demonstrate this empirically by measuring the\nstatistical powers of two-sample Kolmogorov-Smirnov (KS) tests on several\ndifferent data sets and shift types, and showing that our novel representations\ninduce significant improvements over a state-of-the-art baseline relying on the\nnetwork output.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:34:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13272","submitter":"Shashank Sonkar","authors":"Shashank Sonkar, Lucy Liu, Debshila Basu Mallick, Richard G. Baraniuk","title":"CLASS Meet SPOCK: An Education Tutoring Chatbot based on Learning\n  Science Principles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a design framework called Conversational Learning with Analytical\nStep-by-Step Strategies (CLASS) for developing high-performance Intelligent\nTutoring Systems (ITS). The CLASS framework aims to empower ITS with with two\ncritical capabilities: imparting tutor-like step-by-step guidance and enabling\ntutor-like conversations in natural language to effectively engage learners. To\nempower ITS with the aforementioned capabilities, the CLASS framework employs\ntwo carefully curated synthetic datasets. The first scaffolding dataset\nencompasses a variety of elements, including problems, their corresponding\nsubproblems, hints, incorrect solutions, and tailored feedback. This dataset\nprovides ITS with essential problem-solving strategies necessary for guiding\nstudents through each step of the conversation. The second conversational\ndataset contains simulated student-tutor conversations that involve the\napplication of problem-solving strategies learned from the first dataset. In\nthe second dataset, the tutoring system adheres to a pre-defined response\ntemplate, which helps to maintain consistency and structure in ITS's responses\nduring its interactions. This structured methodology facilitates seamless\nintegration of user feedback and yields valuable insights into ITS's internal\ndecision-making process, allowing for continuous refinement and improvement of\nthe system. We also present a proof-of-concept ITS, referred to as SPOCK,\ntrained using the CLASS framework with a focus on college level introductory\nbiology content. A carefully constructed protocol was developed for SPOCK's\npreliminary evaluation, examining aspects such as the factual accuracy and\nrelevance of its responses. Experts in the field of biology offered favorable\nremarks, particularly highlighting SPOCK's capability to break down questions\ninto manageable subproblems and provide step-by-step guidance to students.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:35:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13273","submitter":"Lennart Jehle","authors":"Michal Vyvlecka (1), Lennart Jehle (1), Cornelius Nawrath (2),\n  Francesco Giorgino (1), Mathieu Bozzio (3), Robert Sittig (2), Michael Jetter\n  (2), Simone L. Portalupi (2), Peter Michler (2), and Philip Walther (3 and 4)\n  ((1) University of Vienna, Faculty of Physics & Vienna Doctoral School in\n  Physics & Vienna Center for Quantum Science and Technology, Boltzmanngasse 5,\n  A-1090 Vienna, Austria, (2) Institut f\\\"ur Halbleiteroptik und Funktionelle\n  Grenzfl\\\"achen, Center for Integrated Quantum Science and Technology (IQST)\n  and SCoPE, University of Stuttgart, Allmandring 3, 70569 Stuttgart, Germany,\n  (3) Vienna Center for Quantum Science and Technology, Faculty of Physics,\n  University of Vienna, Vienna, Austria, (4) Christian Doppler Laboratory for\n  Photonic Quantum Computer, Faculty of Physics, University of Vienna, Vienna,\n  Austria)","title":"Robust excitation of C-band quantum dots for enhanced quantum\n  communication","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Building a quantum internet requires efficient and reliable quantum hardware,\nfrom photonic sources to quantum repeaters and detectors, ideally operating at\ntelecommunication wavelengths. Thanks to their high brightness and\nsingle-photon purity, quantum dot (QD) sources hold the promise to achieve high\ncommunication rates for quantum-secured network applications. Furthermore, it\nwas recently shown that excitation schemes, such as longitudinal acoustic\nphonon-assisted (LA) pumping, provide security benefits by scrambling the\ncoherence between the emitted photon-number states. In this work, we\ninvestigate further advantages of LA-pumped quantum dots with emission in the\ntelecom C-band as a core hardware component of the quantum internet. We\nexperimentally demonstrate how varying the pump energy and spectral detuning\nwith respect to the excitonic transition can improve quantum-secured\ncommunication rates and provide stable emission statistics regardless of\nnetwork-environment fluctuations. These findings have significant implications\nfor general implementations of QD single-photon sources in practical quantum\ncommunication networks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:35:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13274","submitter":"Nikhil Mahajan","authors":"Nikhil Mahajan and Marten H. van Kerkwijk","title":"Using Giant Pulses to Measure the Impulse Response of the Interstellar\n  Medium","comments":"14 pages, 8 figures, submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Giant pulses emitted by PSR B1937+21 are bright, intrinsically impulsive\nbursts. Thus, the observed signal from a giant pulse is a noisy but direct\nmeasurement of the impulse response from the ionized interstellar medium. We\nuse this fact to detect 13,025 giant pulses directly in the baseband data of\ntwo observations of PSR B1937+21. Using the giant pulse signals, we model the\ntime-varying impulse response with a sparse approximation method, in which the\ntime dependence at each delay is decomposed in Fourier components, thus\nconstructing a wavefield as a function of delay and differential Doppler shift.\nWe find that the resulting wavefield has the expected parabolic shape, with\nseveral diffuse structures within it, suggesting the presence of multiple\nscattering locations along the line of sight. We also detect an echo at a delay\nof about 2.4 ms, over 1.5 times the rotation period of the pulsar, which\nbetween the two observations moves along the trajectory expected from geometry.\nThe structures in the wavefield are insufficiently sparse to produce a complete\nmodel of the system, and hence the model is not predictive across gaps larger\nthan about the scintillation time. Nevertheless, within its range, it\nreproduces about 75% of the power of the impulse response, a fraction limited\nmostly by the signal-to-noise ratio of the observations. Furthermore, we show\nthat by deconvolution, using the model impulse response, we can successfully\nrecover the intrinsic pulsar emission from the observed signal.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:36:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13275","submitter":"Ziaullah Momand","authors":"Ziaullah Momand, Debajyoti Pal, Pornchai Mongkolnam, Jonathan H. Chan","title":"A Machine Learning Approach to Detect Dehydration in Afghan Children","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Child dehydration is a significant health concern, especially among children\nunder 5 years of age who are more susceptible to diarrhea and vomiting. In\nAfghanistan, severe diarrhea contributes to child mortality due to dehydration.\nHowever, there is no evidence of research exploring the potential of machine\nlearning techniques in diagnosing dehydration in Afghan children under five. To\nfill this gap, this study leveraged various classifiers such as Random Forest,\nMultilayer Perceptron, Support Vector Machine, J48, and Logistic Regression to\ndevelop a predictive model using a dataset of sick children retrieved from the\nAfghanistan Demographic and Health Survey (ADHS). The primary objective was to\ndetermine the dehydration status of children under 5 years. Among all the\nclassifiers, Random Forest proved to be the most effective, achieving an\naccuracy of 91.46%, precision of 91%, and AUC of 94%. This model can\npotentially assist healthcare professionals in promptly and accurately\nidentifying dehydration in under five children, leading to timely\ninterventions, and reducing the risk of severe health complications. Our study\ndemonstrates the potential of machine learning techniques in improving the\nearly diagnosis of dehydration in Afghan children.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:36:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13276","submitter":"Mithun Das","authors":"Mithun Das, Saurabh Kumar Pandey, Animesh Mukherjee","title":"Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate\n  Speech Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hate speech is a severe issue that affects many online platforms. So far,\nseveral studies have been performed to develop robust hate speech detection\nsystems. Large language models like ChatGPT have recently shown a great promise\nin performing several tasks, including hate speech detection. However, it is\ncrucial to comprehend the limitations of these models to build robust hate\nspeech detection systems. To bridge this gap, our study aims to evaluate the\nstrengths and weaknesses of the ChatGPT model in detecting hate speech at a\ngranular level across 11 languages. Our evaluation employs a series of\nfunctionality tests that reveals various intricate failures of the model which\nthe aggregate metrics like macro F1 or accuracy are not able to unfold. In\naddition, we investigate the influence of complex emotions, such as the use of\nemojis in hate speech, on the performance of the ChatGPT model. Our analysis\nhighlights the shortcomings of the generative models in detecting certain types\nof hate speech and highlighting the need for further research and improvements\nin the workings of these models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:36:58 GMT"},{"version":"v2","created":"Tue, 23 May 2023 03:39:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13277","submitter":"Corinne Stucker","authors":"Corinne Stucker, Vivien Sainte Fare Garnot, Konrad Schindler","title":"U-TILISE: A Sequence-to-sequence Model for Cloud Removal in Optical\n  Satellite Time Series","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Satellite image time series in the optical and infrared spectrum suffer from\nfrequent data gaps due to cloud cover, cloud shadows, and temporary sensor\noutages. It has been a long-standing problem of remote sensing research how to\nbest reconstruct the missing pixel values and obtain complete, cloud-free image\nsequences. We approach that problem from the perspective of representation\nlearning and develop U-TILISE, an efficient neural model that is able to\nimplicitly capture spatio-temporal patterns of the spectral intensities, and\nthat can therefore be trained to map a cloud-masked input sequence to a\ncloud-free output sequence. The model consists of a convolutional spatial\nencoder that maps each individual frame of the input sequence to a latent\nencoding; an attention-based temporal encoder that captures dependencies\nbetween those per-frame encodings and lets them exchange information along the\ntime dimension; and a convolutional spatial decoder that decodes the latent\nembeddings back into multi-spectral images. We experimentally evaluate the\nproposed model on EarthNet2021, a dataset of Sentinel-2 time series acquired\nall over Europe, and demonstrate its superior ability to reconstruct the\nmissing pixels. Compared to a standard interpolation baseline, it increases the\nPSNR by 1.8 dB at previously seen locations and by 1.3 dB at unseen locations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:37:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13278","submitter":"Frans Klinkhamer","authors":"F.R. Klinkhamer","title":"Vacuum defect wormholes and a mirror world","comments":"14 pages, 3 figures, v2: new bound in Sec. IV E","journal-ref":null,"doi":null,"report-no":"KA-TP-08-2023","categories":"gr-qc hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have recently obtained a smooth vacuum-wormhole solution of the\nfirst-order equations of general relativity. Here, we present the corresponding\nmultiple vacuum-wormhole solution. Assuming that our world is essentially\nMinkowski spacetime with a large number of these vacuum defect wormholes\ninserted, there is then another flat spacetime with opposite spatial\norientation, which may be called a \"mirror\" world. We briefly discuss some\nphenomenological aspects and point out that there will be no significant\nvacuum-Cherenkov radiation in our world, so that ultrahigh-energy cosmic rays\ndo not constrain the typical sizes and separations of the wormhole mouths\n(different from the constraints obtained for a single Minkowski spacetime with\nsimilar defects). Other possible signatures from a \"gas\" of vacuum defect\nwormholes are mentioned.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:38:22 GMT"},{"version":"v2","created":"Mon, 29 May 2023 17:15:36 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13279","submitter":"Vivek Sridhar","authors":"Vivek Sridhar and Michael Breu{\\ss}","title":"Morphological Sampling Theorem and its Extension to Grey-value Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Sampling is a basic operation in image processing. In classic literature, a\nmorphological sampling theorem has been established, which shows how sampling\ninteracts by morphological operations with image reconstruction. Many aspects\nof morphological sampling have been investigated for binary images, but only\nsome of them have been explored for grey-value imagery. With this paper, we\nmake a step towards completion of this open matter. By relying on the umbra\nnotion, we show how to transfer classic theorems in binary morphology about the\ninteraction of sampling with the fundamental morphological operations dilation,\nerosion, opening and closing, to the grey-value setting. In doing this we also\nextend the theory relating the morphological operations and corresponding\nreconstructions to use of non-flat structuring elements. We illustrate the\ntheoretical developments at hand of examples.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:40:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13280","submitter":"Jaeuk Kim","authors":"Jaeuk Kim and Salvatore Torquato","title":"Effective Electromagnetic Wave Properties of Disordered Stealthy\n  Hyperuniform Layered Media Beyond the Quasistatic Regime","comments":"8 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics cond-mat.dis-nn cond-mat.stat-mech physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Disordered stealthy hyperuniform dielectric composites exhibit novel\nelectromagnetic wave transport properties in two and three dimensions. Here, we\ncarry out the first study of the electromagnetic properties of one-dimensional\n(1D) disordered stealthy hyperuniform layered media. From an exact nonlocal\ntheory, we derive an approximation formula for the effective dynamic dielectric\nconstant tensor ${\\boldsymbol \\varepsilon}_e({\\bf k}_q,\\omega)$ of general 1D\nmedia that is valid well beyond the quasistatic regime and apply it to 1D\nstealthy hyperuniform systems. We consider incident waves of transverse\npolarization, frequency $\\omega$, and wavenumber $k_q$. Our formula for\n${\\boldsymbol \\varepsilon}_e({k}_q,\\omega)$, which is given in terms of the\nspectral density, leads to a closed-form relation for the transmittance $T$.\nOur theoretical predictions are in excellent agreement with finite-difference\ntime-domain (FDTD) simulations. Stealthy hyperuniform layered media have\nperfect transparency intervals up to a finite wavenumber, implying no Anderson\nlocalization, but non-stealthy hyperuniform media are not perfectly\ntransparent. Our predictive theory provides a new path for the inverse design\nof the wave characteristics of disordered layered media, which are readily\nfabricated, by engineering their spectral densities.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:41:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13281","submitter":"Roi Cohen","authors":"Roi Cohen, May Hamri, Mor Geva, Amir Globerson","title":"LM vs LM: Detecting Factual Errors via Cross Examination","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A prominent weakness of modern language models (LMs) is their tendency to\ngenerate factually incorrect text, which hinders their usability. A natural\nquestion is whether such factual errors can be detected automatically. Inspired\nby truth-seeking mechanisms in law, we propose a factuality evaluation\nframework for LMs that is based on cross-examination. Our key idea is that an\nincorrect claim is likely to result in inconsistency with other claims that the\nmodel generates. To discover such inconsistencies, we facilitate a multi-turn\ninteraction between the LM that generated the claim and another LM (acting as\nan examiner) which introduces questions to discover inconsistencies. We\nempirically evaluate our method on factual claims made by multiple recent LMs\non four benchmarks, finding that it outperforms existing methods and baselines,\noften by a large gap. Our results demonstrate the potential of using\ninteracting LMs for capturing factual errors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:42:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13282","submitter":"Rheeya Uppaal","authors":"Rheeya Uppaal, Junjie Hu, Yixuan Li","title":"Is Fine-tuning Needed? Pre-trained Language Models Are Near Perfect for\n  Out-of-Domain Detection","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Out-of-distribution (OOD) detection is a critical task for reliable\npredictions over text. Fine-tuning with pre-trained language models has been a\nde facto procedure to derive OOD detectors with respect to in-distribution (ID)\ndata. Despite its common use, the understanding of the role of fine-tuning and\nits necessity for OOD detection is largely unexplored. In this paper, we raise\nthe question: is fine-tuning necessary for OOD detection? We present a study\ninvestigating the efficacy of directly leveraging pre-trained language models\nfor OOD detection, without any model fine-tuning on the ID data. We compare the\napproach with several competitive fine-tuning objectives, and offer new\ninsights under various types of distributional shifts. Extensive evaluations on\n8 diverse ID-OOD dataset pairs demonstrate near-perfect OOD detection\nperformance (with 0% FPR95 in many cases), strongly outperforming its\nfine-tuned counterparts. We show that using distance-based detection methods,\npre-trained language models are near-perfect OOD detectors when the\ndistribution shift involves a domain change. Furthermore, we study the effect\nof fine-tuning on OOD detection and identify how to balance ID accuracy with\nOOD detection performance. Our code is publically available at\nhttps://github.com/Uppaal/lm-ood.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:42:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13283","submitter":"Mirko Giacchini","authors":"Flavio Chierichetti, Mirko Giacchini, Ravi Kumar, Alessandro\n  Panconesi, Andrew Tomkins","title":"Approximating a RUM from Distributions on k-Slates","comments":null,"journal-ref":"Proceedings of The 26th International Conference on Artificial\n  Intelligence and Statistics (AISTATS), 2023, pages 4757-4767, volume 206","doi":null,"report-no":null,"categories":"cs.LG cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we consider the problem of fitting Random Utility Models (RUMs)\nto user choices. Given the winner distributions of the subsets of size $k$ of a\nuniverse, we obtain a polynomial-time algorithm that finds the RUM that best\napproximates the given distribution on average. Our algorithm is based on a\nlinear program that we solve using the ellipsoid method. Given that its\ncorresponding separation oracle problem is NP-hard, we devise an approximate\nseparation oracle that can be viewed as a generalization of the weighted\nfeedback arc set problem to hypergraphs. Our theoretical result can also be\nmade practical: we obtain a heuristic that is effective and scales to\nreal-world datasets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:43:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13284","submitter":"Kowshik Thopalli","authors":"Kowshik Thopalli, Rakshith Subramanyam, Pavan Turaga and Jayaraman J.\n  Thiagarajan","title":"Target-Aware Generative Augmentations for Single-Shot Adaptation","comments":"Accepted at International Conference Machine Learning (ICML) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we address the problem of adapting models from a source domain\nto a target domain, a task that has become increasingly important due to the\nbrittle generalization of deep neural networks. While several test-time\nadaptation techniques have emerged, they typically rely on synthetic toolbox\ndata augmentations in cases of limited target data availability. We consider\nthe challenging setting of single-shot adaptation and explore the design of\naugmentation strategies. We argue that augmentations utilized by existing\nmethods are insufficient to handle large distribution shifts, and hence propose\na new approach SiSTA, which first fine-tunes a generative model from the source\ndomain using a single-shot target, and then employs novel sampling strategies\nfor curating synthetic target data. Using experiments on a variety of\nbenchmarks, distribution shifts and image corruptions, we find that SiSTA\nproduces significantly improved generalization over existing baselines in face\nattribute detection and multi-class object recognition. Furthermore, SiSTA\nperforms competitively to models obtained by training on larger target\ndatasets. Our codes can be accessed at https://github.com/Rakshith-2905/SiSTA.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:46:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13285","submitter":"James Kohel","authors":"Kamal Oudrhiri, James M. Kohel, Nate Harvey, James R. Kellogg, David\n  C. Aveline, Roy L. Butler, Javier Bosch-Lluis, John L. Callas, Leo Y. Cheng,\n  Arvid P. Croonquist, Walker L. Dula, Ethan R. Elliott, Jose E. Fernandez,\n  Jorge Gonzales, Raymond J. Higuera, Shahram Javidnia, Sandy M. Kwan, Norman\n  E. Lay, Dennis K. Lee, Irena Li, Gregory J. Miles, Michael T. Pauken, Kelly\n  L. Perry, Leah E. Phillips, Diane C. Malarik, DeVon W. Griffin, Bradley M.\n  Carpenter and Michael P. Robinson, Kirt Costello Sarah K. Rees, Matteo S.\n  Sbroscia, Christian Schneider, Robert F. Shotwell, Gregory Y. Shin, Cao V.\n  Tran, Michel E. William, Jason R. Williams, Oscar Yang, Nan Yu and Robert J.\n  Thompson","title":"NASA's Cold Atom Laboratory: Four Years of Quantum Science Operations in\n  Space","comments":"13 pages, 7 figures. Presented at SpaceOps 2023 Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.quant-gas","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Cold Atom Laboratory (CAL) is a quantum facility for studying ultra-cold\ngases in the microgravity environment of the International Space Station. It\nenables research in a temperature regime and force-free environment\ninaccessible to terrestrial laboratories. In the microgravity environment,\nobservation times over a few seconds and temperatures below 100 pK are\nachievable, unlocking the potential to observe new quantum phenomena. CAL\nlaunched to the International Space Station in May 2018 and has been operating\nsince then as the world's first multi-user facility for studying ultra\\-cold\natoms in space. CAL is the first quantum science facility to produce the fifth\nstate of matter called a Bose-Einstein condensate with rubidium-87 and\npotassium-41 in Earth orbit. We will give an overview of CAL's operational\nsetup, outline its contributions to date, present planned upgrades for the next\nfew years, and consider design choices for microgravity BEC successor-mission\nplanning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:47:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13286","submitter":"Rochelle Choenni","authors":"Rochelle Choenni, Dan Garrette, Ekaterina Shutova","title":"How do languages influence each other? Studying cross-lingual data\n  sharing during LLM fine-tuning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multilingual large language models (MLLMs) are jointly trained on data from\nmany different languages such that representation of individual languages can\nbenefit from other languages' data. Impressive performance on zero-shot\ncross-lingual transfer shows that these models are capable of exploiting data\nfrom other languages. Yet, it remains unclear to what extent, and under which\nconditions, languages rely on each other's data. In this study, we use TracIn\n(Pruthi et al., 2020), a training data attribution (TDA) method, to retrieve\nthe most influential training samples seen during multilingual fine-tuning for\na particular test language. This allows us to analyse cross-lingual sharing\nmechanisms of MLLMs from a new perspective. While previous work studied\ncross-lingual sharing at the level of model parameters, we present the first\napproach to study cross-lingual sharing at the data level. We find that MLLMs\nrely on data from multiple languages from the early stages of fine-tuning and\nthat this reliance gradually increases as fine-tuning progresses. We further\nstudy how different fine-tuning languages influence model performance on a\ngiven test language and find that they can both reinforce and complement the\nknowledge acquired from data of the test language itself.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:47:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13287","submitter":"Aldin Vehabovic","authors":"Aldin Vehabovic, Hadi Zanddizari, Nasir Ghani, Farooq Shaikh, Elias\n  Bou-Harb, Morteza Safaei Pour and Jorge Crichigno","title":"Data-Centric Machine Learning Approach for Early Ransomware Detection\n  and Attribution","comments":"6 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Researchers have proposed a wide range of ransomware detection and analysis\nschemes. However, most of these efforts have focused on older families\ntargeting Windows 7/8 systems. Hence there is a critical need to develop\nefficient solutions to tackle the latest threats, many of which may have\nrelatively fewer samples to analyze. This paper presents a machine learning(ML)\nframework for early ransomware detection and attribution. The solution pursues\na data-centric approach which uses a minimalist ransomware dataset and\nimplements static analysis using portable executable(PE) files. Results for\nseveral ML classifiers confirm strong performance in terms of accuracy and\nzero-day threat detection.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:47:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13288","submitter":"John Cardy","authors":"John Cardy","title":"The Yang-Lee Edge Singularity and Related Problems","comments":"Contribution to `Fifty years of the renormalization group. Dedicated\n  to the memory of Michael E Fisher', A Aharony, O Entin-Wohlman, D Huse and L\n  Radzihovsky, eds. (World Scientific, to appear.)","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Yang-Lee edge singularity is a prototypical example of the application of\nrenormalization group ideas to critical behavior, and one to which Michael\nFisher made several important contributions. Moreover it has connections to\nseveral other problems such as the statistics of branched polymers, and its\nscaling limit in two dimensions provides a simple example of integrable field\ntheory. This article aims to give a pedagogical introduction to these matters,\nwith a few new ideas thrown in.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:48:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13289","submitter":"Yue Wang","authors":"Yue Wang, Yuting Hu, Jinjun Xiong, Shaofeng Zou","title":"Distributionally Robust Optimization Efficiently Solves Offline\n  Reinforcement Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Offline reinforcement learning aims to find the optimal policy from a\npre-collected dataset without active exploration. This problem is faced with\nmajor challenges, such as a limited amount of data and distribution shift.\nExisting studies employ the principle of pessimism in face of uncertainty, and\npenalize rewards for less visited state-action pairs. In this paper, we\ndirectly model the uncertainty in the transition kernel using an uncertainty\nset, and then employ the approach of distributionally robust optimization that\noptimizes the worst-case performance over the uncertainty set. We first design\na Hoeffding-style uncertainty set, which guarantees that the true transition\nkernel lies in the uncertainty set with high probability. We theoretically\nprove that it achieves an $\\epsilon$-accuracy with a sample complexity of\n$\\mathcal{O}\\left((1-\\gamma)^{-4}\\epsilon^{-2}SC^{\\pi^*} \\right)$, where\n$\\gamma$ is the discount factor, $C^{\\pi^*}$ is the single-policy\nconcentrability for any comparator policy $\\pi^*$, and $S$ is the number of\nstates. We further design a Bernstein-style uncertainty set, which does not\nnecessarily guarantee the true transition kernel lies in the uncertainty set.\nWe show an improved and near-optimal sample complexity of\n$\\mathcal{O}\\left((1-\\gamma)^{-3}\\epsilon^{-2}\\left(SC^{\\pi^*}+(\\mu_{\\min})^{-1}\\right)\n\\right)$, where $\\mu_{\\min}$ denotes the minimal non-zero entry of the behavior\ndistribution. In addition, the computational complexity of our algorithms is\nthe same as one of the LCB-based methods in the literature. Our results\ndemonstrate that distributionally robust optimization method can also\nefficiently solve offline reinforcement learning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:50:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13290","submitter":"Katharina Ott","authors":"Katharina Ott, Michael Tiemann, Philipp Hennig","title":"Uncertainty and Structure in Neural Ordinary Differential Equations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural ordinary differential equations (ODEs) are an emerging class of deep\nlearning models for dynamical systems. They are particularly useful for\nlearning an ODE vector field from observed trajectories (i.e., inverse\nproblems). We here consider aspects of these models relevant for their\napplication in science and engineering. Scientific predictions generally\nrequire structured uncertainty estimates. As a first contribution, we show that\nbasic and lightweight Bayesian deep learning techniques like the Laplace\napproximation can be applied to neural ODEs to yield structured and meaningful\nuncertainty quantification. But, in the scientific domain, available\ninformation often goes beyond raw trajectories, and also includes mechanistic\nknowledge, e.g., in the form of conservation laws. We explore how mechanistic\nknowledge and uncertainty quantification interact on two recently proposed\nneural ODE frameworks - symplectic neural ODEs and physical models augmented\nwith neural ODEs. In particular, uncertainty reflects the effect of mechanistic\ninformation more directly than the predictive power of the trained model could.\nAnd vice versa, structure can improve the extrapolation abilities of neural\nODEs, a fact that can be best assessed in practice through uncertainty\nestimates. Our experimental analysis demonstrates the effectiveness of the\nLaplace approach on both low dimensional ODE problems and a high dimensional\npartial differential equation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:50:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13291","submitter":"Prafull Sharma","authors":"Prafull Sharma, Julien Philip, Micha\\\"el Gharbi, William T. Freeman,\n  Fredo Durand, Valentin Deschaintre","title":"Materialistic: Selecting Similar Materials in Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.GR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Separating an image into meaningful underlying components is a crucial first\nstep for both editing and understanding images. We present a method capable of\nselecting the regions of a photograph exhibiting the same material as an\nartist-chosen area. Our proposed approach is robust to shading, specular\nhighlights, and cast shadows, enabling selection in real images. As we do not\nrely on semantic segmentation (different woods or metal should not be selected\ntogether), we formulate the problem as a similarity-based grouping problem\nbased on a user-provided image location. In particular, we propose to leverage\nthe unsupervised DINO features coupled with a proposed Cross-Similarity module\nand an MLP head to extract material similarities in an image. We train our\nmodel on a new synthetic image dataset, that we release. We show that our\nmethod generalizes well to real-world images. We carefully analyze our model's\nbehavior on varying material properties and lighting. Additionally, we evaluate\nit against a hand-annotated benchmark of 50 real photographs. We further\ndemonstrate our model on a set of applications, including material editing,\nin-video selection, and retrieval of object photographs with similar materials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:50:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13292","submitter":"Chen Guo","authors":"Guo Chen, Yin-Dong Zheng, Jiahao Wang, Jilan Xu, Yifei Huang, Junting\n  Pan, Yi Wang, Yali Wang, Yu Qiao, Tong Lu, Limin Wang","title":"VideoLLM: Modeling Video Sequence with Large Language Models","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  With the exponential growth of video data, there is an urgent need for\nautomated technology to analyze and comprehend video content. However, existing\nvideo understanding models are often task-specific and lack a comprehensive\ncapability of handling diverse tasks. The success of large language models\n(LLMs) like GPT has demonstrated their impressive abilities in sequence causal\nreasoning. Building upon this insight, we propose a novel framework called\nVideoLLM that leverages the sequence reasoning capabilities of pre-trained LLMs\nfrom natural language processing (NLP) for video sequence understanding.\nVideoLLM incorporates a carefully designed Modality Encoder and Semantic\nTranslator, which convert inputs from various modalities into a unified token\nsequence. This token sequence is then fed into a decoder-only LLM.\nSubsequently, with the aid of a simple task head, our VideoLLM yields an\neffective unified framework for different kinds of video understanding tasks.\nTo evaluate the efficacy of VideoLLM, we conduct extensive experiments using\nmultiple LLMs and fine-tuning methods. We evaluate our VideoLLM on eight tasks\nsourced from four different datasets. The experimental results demonstrate that\nthe understanding and reasoning capabilities of LLMs can be effectively\ntransferred to video understanding tasks. We release the code at\nhttps://github.com/cg1177/VideoLLM.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:51:22 GMT"},{"version":"v2","created":"Tue, 23 May 2023 07:48:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13293","submitter":"Adam Lechowicz","authors":"Adam Lechowicz, Rik Sengupta, Bo Sun, Shahin Kamali, Mohammad\n  Hajiesmaili","title":"Time Fairness in Online Knapsack Problems","comments":"24 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The online knapsack problem is a classic problem in the field of online\nalgorithms. Its canonical version asks how to pack items of different values\nand weights arriving online into a capacity-limited knapsack so as to maximize\nthe total value of the admitted items. Although optimal competitive algorithms\nare known for this problem, they may be fundamentally unfair, i.e., individual\nitems may be treated inequitably in different ways. Inspired by recent\nattention to fairness in online settings, we develop a natural and\npractically-relevant notion of time fairness for the online knapsack problem,\nand show that the existing optimal algorithms perform poorly under this metric.\nWe propose a parameterized deterministic algorithm where the parameter\nprecisely captures the Pareto-optimal trade-off between fairness and\ncompetitiveness. We show that randomization is theoretically powerful enough to\nbe simultaneously competitive and fair; however, it does not work well in\npractice, using trace-driven experiments. To further improve the trade-off\nbetween fairness and competitiveness, we develop a fair, robust (competitive),\nand consistent learning-augmented algorithm with substantial performance\nimprovement in trace-driven experiments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:51:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13294","submitter":"Michael Herrmann","authors":"Michael Herrmann and Katia Kleine","title":"Korteweg-de Vries waves in peridynamical media","comments":"22 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a one-dimensional peridynamical medium and show the existence of\nsolitary waves with small amplitudes and long wavelength. Our proof uses\nnonlinear Bochner integral operators and characterizes their asymptotic\nproperties in a singular scaling limit.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:51:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13295","submitter":"Chen Firestein","authors":"Chen Firestein, Amir Shlivinski and Yakir Hadad","title":"Bound and Optimal Design of Dallenbach Absorber Under Finite-Bandwidth\n  Multiple-Angle Illumination","comments":"7 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dallenbach absorbers are lossy substances attached to a perfect electric\nconductor sheet. For such a configuration Rozanov derived a sum rule that\nrelates the absorber's efficacy with its thickness and frequency-band of\noperation. Rozanov's derivation is valid only for layer impinged by a normally\nincident plane wave. Later, this relation was extended for oblique incidence\nconsidering both transverse electric and transverse magnetic polarizations.\nHere, we follow the same approach and present a sum rule that is valid for\nmultiple and possibly a spectrum of oblique incident waves which are\narbitrarily weighted. We recast the design of the Dallenbach absorber as an\noptimization problem, where optimization is performed over its electromagnetic\nproperties. The optimization problem is applicable for practical\nimplementations where finite spectral bandwidth is considered, as well as for\ntheoretical aspects such as determining the tightness of the sum rule over an\ninfinite bandwidth. We provide a numerical example for a practical case where\nwe perform an optimization procedure for a given weight function and finite\nbandwidth. Additionally, we demonstrate the effect of the weight function on\nthe optimization results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:52:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13296","submitter":"Yebo Feng","authors":"Jun Li, Devkishen Sisodia, Yebo Feng, Lumin Shi, Mingwei Zhang,\n  Christopher Early, Peter Reiher","title":"Adaptive Distributed Filtering of DDoS Traffic on the Internet","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite the proliferation of traffic filtering capabilities throughout the\nInternet, attackers continue to launch distributed denial-of-service (DDoS)\nattacks to successfully overwhelm the victims with DDoS traffic. In this paper,\nwe introduce a distributed filtering system that leverages nodes distributed\nalong the paths of DDoS traffic to filter the DDoS traffic. In particular, we\nfocus on adaptive distributed filtering, a new direction in filtering DDoS\ntraffic. In our design, a subscriber to the distributed filtering service can\nact on behalf of a DDoS victim and generate filtering rules that not only adapt\nto the most suitable and effective filtering granularity (e.g., IP source\naddress and a port number vs. an individual IP address vs. IP prefixes at\ndifferent lengths), but also adapt to the preferences of the subscriber (e.g.,\nmaximum coverage of DDoS traffic vs. minimum collateral damage from dropping\nlegitimate traffic vs. minimum number of rules).\n  We design an efficient algorithm that can generate rules adaptive toward\nfiltering granularities and objectives, which can further help determine where\nto deploy generated rules for the best efficacy. We evaluated our system\nthrough both large-scale simulations based on real-world DDoS attack traces and\npilot studies. Our evaluations confirm that our algorithm can generate rules\nthat adapt to every distinct filtering objective and achieve optimal results.\nWe studied the success rate and distribution of rule deployment under different\nInternet-scale rule deployment profiles, and found a small number of autonomous\nsystems can contribute disproportionately to the defense. Our pilot studies\nalso show our adaptive distributed filtering system can effectively defend\nagainst real-world DDoS attack traces in real time.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:53:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13297","submitter":"Shashank Sonkar","authors":"Shashank Sonkar, Richard G. Baraniuk","title":"Investigating the Role of Feed-Forward Networks in Transformers Using\n  Parallel Attention and Feed-Forward Net Design","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper investigates the key role of Feed-Forward Networks (FFNs) in\ntransformer models by utilizing the Parallel Attention and Feed-Forward Net\nDesign (PAF) architecture, and comparing it to their Series Attention and\nFeed-Forward Net Design (SAF) counterparts. Central to the effectiveness of PAF\nare two main assumptions regarding the FFN block and the attention block within\na layer: 1) the primary function of the FFN block is to maintain isotropy among\ntoken embeddings and prevent their degeneration, and 2) the residual norm\ncomputed in the attention block is substantially smaller than the input token\nembedding norm. To empirically validate these assumptions, we train PAF\nvariants of two large language models (RoBERTa-large and bert-large-uncased).\nOur results demonstrate that both assumptions hold true in the PAF design. This\nstudy contributes to a deeper understanding of the roles and interactions\nbetween FFNs and self-attention mechanisms in transformer architectures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:56:09 GMT"},{"version":"v2","created":"Thu, 25 May 2023 17:01:13 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13298","submitter":"Yongliang Shen","authors":"Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, Yueting\n  Zhuang","title":"DiffusionNER: Boundary Diffusion for Named Entity Recognition","comments":"Accepted to ACL 2023, submission version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we propose DiffusionNER, which formulates the named entity\nrecognition task as a boundary-denoising diffusion process and thus generates\nnamed entities from noisy spans. During training, DiffusionNER gradually adds\nnoises to the golden entity boundaries by a fixed forward diffusion process and\nlearns a reverse diffusion process to recover the entity boundaries. In\ninference, DiffusionNER first randomly samples some noisy spans from a standard\nGaussian distribution and then generates the named entities by denoising them\nwith the learned reverse diffusion process. The proposed boundary-denoising\ndiffusion process allows progressive refinement and dynamic sampling of\nentities, empowering DiffusionNER with efficient and flexible entity generation\ncapability. Experiments on multiple flat and nested NER datasets demonstrate\nthat DiffusionNER achieves comparable or even better performance than previous\nstate-of-the-art models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:56:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13299","submitter":"Chenglei Si","authors":"Chenglei Si, Dan Friedman, Nitish Joshi, Shi Feng, Danqi Chen, He He","title":"Measuring Inductive Biases of In-Context Learning with Underspecified\n  Demonstrations","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In-context learning (ICL) is an important paradigm for adapting large\nlanguage models (LLMs) to new tasks, but the generalization behavior of ICL\nremains poorly understood. We investigate the inductive biases of ICL from the\nperspective of feature bias: which feature ICL is more likely to use given a\nset of underspecified demonstrations in which two features are equally\npredictive of the labels. First, we characterize the feature biases of GPT-3\nmodels by constructing underspecified demonstrations from a range of NLP\ndatasets and feature combinations. We find that LLMs exhibit clear feature\nbiases - for example, demonstrating a strong bias to predict labels according\nto sentiment rather than shallow lexical features, like punctuation. Second, we\nevaluate the effect of different interventions that are designed to impose an\ninductive bias in favor of a particular feature, such as adding a natural\nlanguage instruction or using semantically relevant label words. We find that,\nwhile many interventions can influence the learner to prefer a particular\nfeature, it can be difficult to overcome strong prior biases. Overall, our\nresults provide a broader picture of the types of features that ICL may be more\nlikely to exploit and how to impose inductive biases that are better aligned\nwith the intended task.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:56:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13300","submitter":"Kai Zhang","authors":"Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, Yu Su","title":"Adaptive Chameleon or Stubborn Sloth: Unraveling the Behavior of Large\n  Language Models in Knowledge Clashes","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  By providing external information to large language models (LLMs), tool\naugmentation (including retrieval augmentation) has emerged as a promising\nsolution for addressing the limitations of LLMs' static parametric memory.\nHowever, how receptive are LLMs to such external evidence, especially when the\nevidence conflicts with their parametric memory? We present the first\ncomprehensive and controlled investigation into the behavior of LLMs when\nencountering knowledge conflicts. We propose a systematic framework to elicit\nhigh-quality parametric memory from LLMs and construct the corresponding\ncounter-memory, which enables us to conduct a series of controlled experiments.\nOur investigation reveals seemingly contradicting behaviors of LLMs. On the one\nhand, different from prior wisdom, we find that LLMs can be highly receptive to\nexternal evidence even when that conflicts with their parametric memory, given\nthat the external evidence is coherent and convincing. On the other hand, LLMs\nalso demonstrate a strong confirmation bias when the external evidence contains\nsome information that is consistent with their parametric memory, despite being\npresented with conflicting evidence at the same time. These results pose\nimportant implications that are worth careful consideration for the further\ndevelopment and deployment of tool- and retrieval-augmented LLMs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:57:41 GMT"},{"version":"v2","created":"Wed, 24 May 2023 04:15:46 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13301","submitter":"Kevin Black","authors":"Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, and Sergey\n  Levine","title":"Training Diffusion Models with Reinforcement Learning","comments":"20 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diffusion models are a class of flexible generative models trained with an\napproximation to the log-likelihood objective. However, most use cases of\ndiffusion models are not concerned with likelihoods, but instead with\ndownstream objectives such as human-perceived image quality or drug\neffectiveness. In this paper, we investigate reinforcement learning methods for\ndirectly optimizing diffusion models for such objectives. We describe how\nposing denoising as a multi-step decision-making problem enables a class of\npolicy gradient algorithms, which we refer to as denoising diffusion policy\noptimization (DDPO), that are more effective than alternative reward-weighted\nlikelihood approaches. Empirically, DDPO is able to adapt text-to-image\ndiffusion models to objectives that are difficult to express via prompting,\nsuch as image compressibility, and those derived from human feedback, such as\naesthetic quality. Finally, we show that DDPO can improve prompt-image\nalignment using feedback from a vision-language model without the need for\nadditional data collection or human annotation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:57:41 GMT"},{"version":"v2","created":"Tue, 23 May 2023 04:48:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13302","submitter":"Abdullatif K\\\"oksal","authors":"Abdullatif K\\\"oksal, Omer Faruk Yalcin, Ahmet Akbiyik, M. Tahir\n  Kilavuz, Anna Korhonen, Hinrich Sch\\\"utze","title":"Language-Agnostic Bias Detection in Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pretrained language models (PLMs) are key components in NLP, but they contain\nstrong social biases. Quantifying these biases is challenging because current\nmethods focusing on fill-the-mask objectives are sensitive to slight changes in\ninput. To address this, we propose LABDet, a robust language-agnostic method\nfor evaluating bias in PLMs. For nationality as a case study, we show that\nLABDet \"surfaces\" nationality bias by training a classifier on top of a frozen\nPLM on non-nationality sentiment detection. Collaborating with political\nscientists, we find consistent patterns of nationality bias across monolingual\nPLMs in six languages that align with historical and political context. We also\nshow for English BERT that bias surfaced by LABDet correlates well with bias in\nthe pretraining data; thus, our work is one of the few studies that directly\nlinks pretraining data to PLM behavior. Finally, we verify LABDet's reliability\nand applicability to different templates and languages through an extensive set\nof robustness checks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:58:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13303","submitter":"Jannis Vamvas","authors":"Jannis Vamvas and Rico Sennrich","title":"Towards Unsupervised Recognition of Semantic Differences in Related\n  Documents","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Automatically highlighting words that cause semantic differences between two\ndocuments could be useful for a wide range of applications. We formulate\nrecognizing semantic differences (RSD) as a token-level regression task and\nstudy three unsupervised approaches that rely on a masked language model. To\nassess the approaches, we begin with basic English sentences and gradually move\nto more complex, cross-lingual document pairs. Our results show that an\napproach based on word alignment and sentence-level contrastive learning has a\nrobust correlation to gold labels. However, all unsupervised approaches still\nleave a large margin of improvement. Code to reproduce our experiments is\navailable at https://github.com/ZurichNLP/recognizing-semantic-differences\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:58:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13304","submitter":"Wangchunshu Zhou","authors":"Wangchunshu Zhou, Yuchen Eleanor Jiang, Peng Cui, Tiannan Wang,\n  Zhenxin Xiao, Yifan Hou, Ryan Cotterell, Mrinmaya Sachan","title":"RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text","comments":"Under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The fixed-size context of Transformer makes GPT models incapable of\ngenerating arbitrarily long text. In this paper, we introduce RecurrentGPT, a\nlanguage-based simulacrum of the recurrence mechanism in RNNs. RecurrentGPT is\nbuilt upon a large language model (LLM) such as ChatGPT and uses natural\nlanguage to simulate the Long Short-Term Memory mechanism in an LSTM. At each\ntimestep, RecurrentGPT generates a paragraph of text and updates its\nlanguage-based long-short term memory stored on the hard drive and the prompt,\nrespectively. This recurrence mechanism enables RecurrentGPT to generate texts\nof arbitrary length without forgetting. Since human users can easily observe\nand edit the natural language memories, RecurrentGPT is interpretable and\nenables interactive generation of long text. RecurrentGPT is an initial step\ntowards next-generation computer-assisted writing systems beyond local editing\nsuggestions. In addition to producing AI-generated content (AIGC), we also\ndemonstrate the possibility of using RecurrentGPT as an interactive fiction\nthat directly interacts with consumers. We call this usage of generative models\nby ``AI As Contents'' (AIAC), which we believe is the next form of conventional\nAIGC. We further demonstrate the possibility of using RecurrentGPT to create\npersonalized interactive fiction that directly interacts with readers instead\nof interacting with writers. More broadly, RecurrentGPT demonstrates the\nutility of borrowing ideas from popular model designs in cognitive science and\ndeep learning for prompting LLMs. Our code is available at\nhttps://github.com/aiwaves-cn/RecurrentGPT and an online demo is available at\nhttps://www.aiwaves.org/recurrentgpt.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:58:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13305","submitter":"Zhengwei Liu","authors":"Zheng-Wei Liu, Friedrich K. Roepke, Zhanwen Han","title":"Type Ia Supernova Explosions in Binary Systems: A Review","comments":"An invited review (accepted for publication in RAA)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  SNe Ia play a key role in the fields of astrophysics and cosmology. It is\nwidely accepted that SNe Ia arise from thermonuclear explosions of WDs in\nbinaries. However, there is no consensus on the fundamental aspects of the\nnature of SN Ia progenitors and their explosion mechanism. This fundamentally\nflaws our understanding of these important astrophysical objects. We outline\nthe diversity of SNe Ia and the proposed progenitor models and explosion\nmechanisms. We discuss the recent theoretical and observational progress in\naddressing the SN Ia progenitor and explosion mechanism in terms of the\nobservables at various stages of the explosion, including rates and delay\ntimes, pre-explosion companion stars, ejecta-companion interaction, early\nexcess emission, early radio/X-ray emission from CSM interaction, surviving\ncompanions, late-time spectra and photometry, polarization signals, and SNR\nproperties, etc. Despite the efforts from both the theoretical and\nobservational side, the questions of how the WDs reach an explosive state and\nwhat progenitor systems are more likely to produce SNe Ia remain open. No\nsingle published model is able to consistently explain all observational\nfeatures and the full diversity of SNe Ia. This may indicate that either a new\nprogenitor paradigm or the improvement of current models is needed if all SNe\nIa arise from the same origin. An alternative scenario is that different\nprogenitor channels and explosion mechanisms contribute to SNe Ia. In the next\ndecade, the ongoing campaigns with the JWST, Gaia and the ZTF, and upcoming\nextensive projects with the LSST and the SKA will allow us to conduct not only\nstudies of individual SNe Ia in unprecedented detail but also systematic\ninvestigations for different subclasses of SNe Ia. This will advance theory and\nobservations of SNe Ia sufficiently far to gain a deeper understanding of their\norigin and explosion mechanism.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:58:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13306","submitter":"Abhijit Biswas","authors":"Abhijit Biswas, Gustavo A. Alvarez, Tao Li, Joyce\n  Christiansen-Salameh, Eugene Jeong, Anand B. Puthirath, Sathvik Ajay Iyengar,\n  Chenxi Li, Tia Gray, Xiang Zhang, Tymofii S. Pieshkov, Harikishan Kannan,\n  Jacob Elkins, Robert Vajtai, A. Glen Birdwell, Mahesh R. Neupane, Elias J.\n  Garratt, Bradford B. Pate, Tony G. Ivanov, Yuji Zhao, Zhiting Tian, and\n  Pulickel M. Ajayan","title":"Growth of ultrawide-bandgap BN/diamond heterostructures by pulsed laser\n  deposition","comments":"16 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Heterostructures based on ultrawide-bandgap (UWBG) semiconductors (bandgap\n>4.0 eV), boron nitride (BN) and diamond are important for next-generation\nhigh-power electronics. However, in-situ hetero-epitaxy of BN/diamond or\nvice-versa remains extremely challenging, due to their non-trivial growth\nkinetics. Here, we have grown BN thin film on (100) single crystal diamond by\npulsed laser deposition and investigated its structural and magnetic\nproperties, optical refractive index, and thermal conductivity. Structural\ncharacterizations confirm the mixed (stable hexagonal and metastable cubic)\nphase growth. Film shows diamagnetic behavior at room temperature. It displays\nanisotropic refractive index within the visible-to-near-infrared wavelength\nrange. The room temperature cross-plane thermal conductivity of BN is ~1.53\nW/(mK), and the thermal conductance of the BN/diamond interface is ~20\nMW/(m2K). Our findings are useful for various device related applications based\non UWBG BN/diamond heterostructures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:58:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13307","submitter":"Jiading Fang","authors":"Jiading Fang, Shengjie Lin, Igor Vasiljevic, Vitor Guizilini, Rares\n  Ambrus, Adrien Gaidon, Gregory Shakhnarovich, Matthew R. Walter","title":"NeRFuser: Large-Scale Scene Representation by NeRF Fusion","comments":"Code available at https://github.com/ripl/nerfuser","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  A practical benefit of implicit visual representations like Neural Radiance\nFields (NeRFs) is their memory efficiency: large scenes can be efficiently\nstored and shared as small neural nets instead of collections of images.\nHowever, operating on these implicit visual data structures requires extending\nclassical image-based vision techniques (e.g., registration, blending) from\nimage sets to neural fields. Towards this goal, we propose NeRFuser, a novel\narchitecture for NeRF registration and blending that assumes only access to\npre-generated NeRFs, and not the potentially large sets of images used to\ngenerate them. We propose registration from re-rendering, a technique to infer\nthe transformation between NeRFs based on images synthesized from individual\nNeRFs. For blending, we propose sample-based inverse distance weighting to\nblend visual information at the ray-sample level. We evaluate NeRFuser on\npublic benchmarks and a self-collected object-centric indoor dataset, showing\nthe robustness of our method, including to views that are challenging to render\nfrom the individual source NeRFs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13308","submitter":"Karsten Roth","authors":"Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, Zeynep Akata","title":"If at First You Don't Succeed, Try, Try Again: Faithful Diffusion-based\n  Text-to-Image Generation by Selection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite their impressive capabilities, diffusion-based text-to-image (T2I)\nmodels can lack faithfulness to the text prompt, where generated images may not\ncontain all the mentioned objects, attributes or relations. To alleviate these\nissues, recent works proposed post-hoc methods to improve model faithfulness\nwithout costly retraining, by modifying how the model utilizes the input\nprompt. In this work, we take a step back and show that large T2I diffusion\nmodels are more faithful than usually assumed, and can generate images faithful\nto even complex prompts without the need to manipulate the generative process.\nBased on that, we show how faithfulness can be simply treated as a candidate\nselection problem instead, and introduce a straightforward pipeline that\ngenerates candidate images for a text prompt and picks the best one according\nto an automatic scoring system that can leverage already existing T2I\nevaluation metrics. Quantitative comparisons alongside user studies on diverse\nbenchmarks show consistently improved faithfulness over post-hoc enhancement\nmethods, with comparable or lower computational cost. Code is available at\n\\url{https://github.com/ExplainableML/ImageSelect}.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13309","submitter":"Dennis Aumiller","authors":"Jing Fan, Dennis Aumiller, Michael Gertz","title":"Evaluating Factual Consistency of Texts with Semantic Role Labeling","comments":"Accepted at *SEM 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Automated evaluation of text generation systems has recently seen increasing\nattention, particularly checking whether generated text stays truthful to input\nsources. Existing methods frequently rely on an evaluation using task-specific\nlanguage models, which in turn allows for little interpretability of generated\nscores. We introduce SRLScore, a reference-free evaluation metric designed with\ntext summarization in mind. Our approach generates fact tuples constructed from\nSemantic Role Labels, applied to both input and summary texts. A final\nfactuality score is computed by an adjustable scoring mechanism, which allows\nfor easy adaption of the method across domains. Correlation with human\njudgments on English summarization datasets shows that SRLScore is competitive\nwith state-of-the-art methods and exhibits stable generalization across\ndatasets without requiring further training or hyperparameter tuning. We\nexperiment with an optional co-reference resolution step, but find that the\nperformance boost is mostly outweighed by the additional compute required. Our\nmetric is available online at https://github.com/heyjing/SRLScore.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13310","submitter":"Yang Liu","authors":"Yang Liu, Muzhi Zhu, Hengtao Li, Hao Chen, Xinlong Wang, Chunhua Shen","title":"Matcher: Segment Anything with One Shot Using All-Purpose Feature\n  Matching","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Powered by large-scale pre-training, vision foundation models exhibit\nsignificant potential in open-world image understanding. Even though individual\nmodels have limited capabilities, combining multiple such models properly can\nlead to positive synergies and unleash their full potential. In this work, we\npresent Matcher, which segments anything with one shot by integrating an\nall-purpose feature extraction model and a class-agnostic segmentation model.\nNaively connecting the models results in unsatisfying performance, e.g., the\nmodels tend to generate matching outliers and false-positive mask fragments. To\naddress these issues, we design a bidirectional matching strategy for accurate\ncross-image semantic dense matching and a robust prompt sampler for mask\nproposal generation. In addition, we propose a novel instance-level matching\nstrategy for controllable mask merging. The proposed Matcher method delivers\nimpressive generalization performance across various segmentation tasks, all\nwithout training. For example, it achieves 52.7% mIoU on COCO-20$^i$ for\none-shot semantic segmentation, surpassing the state-of-the-art specialist\nmodel by 1.6%. In addition, our visualization results show open-world\ngenerality and flexibility on images in the wild. The code shall be released at\nhttps://github.com/aim-uofa/Matcher.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13311","submitter":"Mingyu Ding","authors":"Haoyu Lu, Guoxing Yang, Nanyi Fei, Yuqi Huo, Zhiwu Lu, Ping Luo,\n  Mingyu Ding","title":"VDT: An Empirical Study on Video Diffusion with Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work introduces Video Diffusion Transformer (VDT), which pioneers the\nuse of transformers in diffusion-based video generation. It features\ntransformer blocks with modularized temporal and spatial attention modules,\nallowing separate optimization of each component and leveraging the rich\nspatial-temporal representation inherited from transformers. VDT offers several\nappealing benefits. 1) It excels at capturing temporal dependencies to produce\ntemporally consistent video frames and even simulate the dynamics of 3D objects\nover time. 2) It enables flexible conditioning information through simple\nconcatenation in the token space, effectively unifying video generation and\nprediction tasks. 3) Its modularized design facilitates a spatial-temporal\ndecoupled training strategy, leading to improved efficiency. Extensive\nexperiments on video generation, prediction, and dynamics modeling (i.e.,\nphysics-based QA) tasks have been conducted to demonstrate the effectiveness of\nVDT in various scenarios, including autonomous driving, human action, and\nphysics-based simulation.\n  We hope our study on the capabilities of transformer-based video diffusion in\ncapturing accurate temporal dependencies, handling conditioning information,\nand achieving efficient training will benefit future research and advance the\nfield. Codes and models are available at https://github.com/RERV/VDT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13312","submitter":"Theo Costain","authors":"Theo W. Costain, Kejie Li, Victor A. Prisacariu","title":"Contextualising Implicit Representations for Semantic Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Prior works have demonstrated that implicit representations trained only for\nreconstruction tasks typically generate encodings that are not useful for\nsemantic tasks. In this work, we propose a method that contextualises the\nencodings of implicit representations, enabling their use in downstream tasks\n(e.g. semantic segmentation), without requiring access to the original training\ndata or encoding network. Using an implicit representation trained for a\nreconstruction task alone, our contextualising module takes an encoding trained\nfor reconstruction only and reveals meaningful semantic information that is\nhidden in the encodings, without compromising the reconstruction performance.\nWith our proposed module, it becomes possible to pre-train implicit\nrepresentations on larger datasets, improving their reconstruction performance\ncompared to training on only a smaller labelled dataset, whilst maintaining\ntheir segmentation performance on the labelled dataset. Importantly, our method\nallows for future foundation implicit representation models to be fine-tuned on\nunseen tasks, regardless of encoder or dataset availability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:59:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13348","submitter":"Justin Eilertsen","authors":"Justin Eilertsen and Wylie Stroberg","title":"On the role of eigenvalue disparity and coordinate transformations in\n  the reduction of the linear noise approximation","comments":"9 Figures, 38 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.MN math.DS math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Eigenvalue disparity, also known as timescale separation, permits the\nsystematic reduction of deterministic models of enzyme kinetics. Geometric\nsingular perturbation theory, of which eigenvalue disparity is central,\nprovides a coordinate-free framework for deriving reduced mass action models in\nthe deterministic realm. Moreover, homologous deterministic reductions are\noften employed in stochastic models to reduce the computational complexity\nrequired to simulate reactions with the Gillespie algorithm. Interestingly,\nseveral detailed studies indicate that timescale separation does not always\nguarantee the accuracy of reduced stochastic models. In this work, we examine\nthe roles of timescale separation and coordinate transformations in the\nreduction of the Linear Noise Approximation (LNA) and, unlike previous studies,\nwe do not require the system to be comprised of distinct fast and slow\nvariables. Instead, we adopt a coordinate-free approach. We demonstrate that\neigenvalue disparity does not guarantee the accuracy of the reduced LNA, known\nas the slow scale LNA (ssLNA). However, the inaccuracy of the ssLNA can often\nbe eliminated with a proper coordinate transformation. For planar systems in\nseparated (standard) form, we prove that the error between the variances of the\nslow variable generated by the LNA and the ssLNA is $\\mathcal{O}(\\varepsilon)$.\nWe also address a nilpotent Jacobian scenario and use the blow-up method to\nconstruct a reduced equation that is accurate near the singular limit in the\ndeterministic regime. However, this reduction in the stochastic regime is far\nless accurate, which illustrates that eigenvalue disparity plays a central role\nin stochastic model reduction.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:39:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13349","submitter":"Shuoyang Wang","authors":"Shuoyang Wang, Guanqun Cao","title":"Multiclass classification for multidimensional functional data through\n  deep neural networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The intrinsically infinite-dimensional features of the functional\nobservations over multidimensional domains render the standard classification\nmethods effectively inapplicable. To address this problem, we introduce a novel\nmulticlass functional deep neural network (mfDNN) classifier as an innovative\ndata mining and classification tool. Specifically, we consider sparse deep\nneural network architecture with rectifier linear unit (ReLU) activation\nfunction and minimize the cross-entropy loss in the multiclass classification\nsetup. This neural network architecture allows us to employ modern\ncomputational tools in the implementation. The convergence rates of the\nmisclassification risk functions are also derived for both fully observed and\ndiscretely observed multidimensional functional data. We demonstrate the\nperformance of mfDNN on simulated data and several benchmark datasets from\ndifferent application domains.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:56:01 GMT"},{"version":"v2","created":"Wed, 24 May 2023 03:02:42 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13350","submitter":"Steven Damelin Dr","authors":"Leon A. Luxemburg and Steven B. Damelin","title":"A Multiple Parameter Linear Scale-Space for one dimensional Signal\n  Classification","comments":"arXiv admin note: text overlap with arXiv:2305.13255","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST cs.LG stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article we construct a maximal set of kernels for a multi-parameter\nlinear scale-space that allow us to construct trees for classification and\nrecognition of one-dimensional continuous signals similar the Gaussian linear\nscale-space approach. Fourier transform formulas are provided and used for\nquick and efficient computations. A number of useful properties of the maximal\nset of kernels are derived. We also strengthen and generalize some previous\nresults on the classification of Gaussian kernels. Finally, a new topologically\ninvariant method of constructing trees is introduced.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:14:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13351","submitter":"Thijs Havinga","authors":"Thijs Havinga, Xianjun Jiao, Wei Liu and Ingrid Moerman","title":"Accelerating FPGA-Based Wi-Fi Transceiver Design and Prototyping by\n  High-Level Synthesis","comments":"7 pages, extended version of poster accepted at FCCM 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Field-Programmable Gate Array (FPGA)-based Software-Defined Radio (SDR) is\nwell-suited for experimenting with advanced wireless communication systems, as\nit allows to alter the architecture promptly while obtaining high performance.\nHowever, programming the FPGA using a Hardware Description Language (HDL) is a\ntime-consuming task for FPGA developers and difficult for software developers,\nwhich limits the potential of SDR. High-Level Synthesis (HLS) tools aid the\ndesigners by allowing them to program on a higher layer of abstraction.\nHowever, if not carefully designed, it may lead to a degradation in computing\nperformance or significant increase in resource utilization. This work shows\nthat it is feasible to design modern Orthogonal Frequency Division Multiplex\n(OFDM) baseband processing modules like channel estimation and equalization\nusing HLS without sacrificing performance and to integrate them in an HDL\ndesign to form a fully-operational FPGA-based Wi-Fi (IEEE 802.11a/g/n)\ntransceiver. Starting from no HLS experience, a design with minor overhead in\nterms of latency and resource utilization as compared to the HDL approach was\ncreated in less than one month. We show the readability of the sequential logic\nas coded in HLS, and discuss the lessons learned from the approach taken and\nthe benefits it brings for further design and experimentation. The FPGA design\ngenerated by HLS was verified to be bit-true with its MATLAB implementation in\nsimulation. Furthermore, we show its practical performance when deployed on a\nSystem-on-Chip (SoC)-based SDR using a professional wireless connectivity\ntester.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:09:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13352","submitter":"Zhentao Zhang","authors":"Zhentao Zhang","title":"Notes on the tangential Casimir force","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We discuss three developments in the study of the tangential Casimir force\n[Z. Zhang, New J. Phys. 24 (2022) 113036]. The first one generalizes the force\nfrom dielectrics to magnetodielectrics. This generalization is readily realized\nwith the help of working out the total zero-point energy of multilayered\nmagnetodielectrics. The second one revisits the tangential force for real\nconductors by taking into account the temperature dependence of their\ndielectric constants, and provides needed theoretical results for experimental\ninvestigations that are expected to be conducted at room temperature. The third\ninvestigates the Casimir torque from plates made of isotropic media, which\noffers a simple way to realize torques for uncharged surfaces.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:45:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13353","submitter":"Dongwei Pan","authors":"Dongwei Pan, Long Zhuo, Jingtan Piao, Huiwen Luo, Wei Cheng, Yuxin\n  Wang, Siming Fan, Shengqi Liu, Lei Yang, Bo Dai, Ziwei Liu, Chen Change Loy,\n  Chen Qian, Wayne Wu, Dahua Lin, Kwan-Yee Lin","title":"RenderMe-360: A Large Digital Asset Library and Benchmarks Towards\n  High-fidelity Head Avatars","comments":"Technical Report; Project Page: 36; Github Link:\n  https://github.com/RenderMe-360/RenderMe-360","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Synthesizing high-fidelity head avatars is a central problem for computer\nvision and graphics. While head avatar synthesis algorithms have advanced\nrapidly, the best ones still face great obstacles in real-world scenarios. One\nof the vital causes is inadequate datasets -- 1) current public datasets can\nonly support researchers to explore high-fidelity head avatars in one or two\ntask directions; 2) these datasets usually contain digital head assets with\nlimited data volume, and narrow distribution over different attributes. In this\npaper, we present RenderMe-360, a comprehensive 4D human head dataset to drive\nadvance in head avatar research. It contains massive data assets, with 243+\nmillion complete head frames, and over 800k video sequences from 500 different\nidentities captured by synchronized multi-view cameras at 30 FPS. It is a\nlarge-scale digital library for head avatars with three key attributes: 1) High\nFidelity: all subjects are captured by 60 synchronized, high-resolution 2K\ncameras in 360 degrees. 2) High Diversity: The collected subjects vary from\ndifferent ages, eras, ethnicities, and cultures, providing abundant materials\nwith distinctive styles in appearance and geometry. Moreover, each subject is\nasked to perform various motions, such as expressions and head rotations, which\nfurther extend the richness of assets. 3) Rich Annotations: we provide\nannotations with different granularities: cameras' parameters, matting, scan,\n2D/3D facial landmarks, FLAME fitting, and text description.\n  Based on the dataset, we build a comprehensive benchmark for head avatar\nresearch, with 16 state-of-the-art methods performed on five main tasks: novel\nview synthesis, novel expression synthesis, hair rendering, hair editing, and\ntalking head generation. Our experiments uncover the strengths and weaknesses\nof current methods. RenderMe-360 opens the door for future exploration in head\navatars.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:54:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13354","submitter":"Shohei Saga","authors":"Shohei Saga, St\\'ephane Colombi, Atsushi Taruya","title":"The gravitational force field of proto-pancakes","comments":"16 pages, 9 figures","journal-ref":null,"doi":null,"report-no":"YITP-23-65","categories":"astro-ph.CO gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is well known that the first structures that form from small fluctuations\nin a self-gravitating, collisionless and initially smooth cold dark matter\n(CDM) fluid are pancakes. We study the gravitational force generated by such\npancakes just after shell-crossing, and find a simple analytical formula for\nthe force along the collapse direction, which can be applied to both the\nsingle- and multi-stream regimes. The formula is tested on the early growth of\nCDM protohaloes seeded by two or three crossed sine waves. Adopting the\nhigh-order Lagrangian perturbation theory (LPT) solution as a proxy for the\ndynamics, we confirm that our analytical prediction agrees well with the exact\nsolution computed by direct resolution of the Poisson equation, as long as the\ncaustic structure remains locally sufficiently one-dimensional. These results\nare further confirmed by comparisons of the LPT predictions performed this way\nto measurements in Vlasov simulations performed with the public code ColDICE.\nWe also show that the component of the force orthogonal to the collapse\ndirection preserves its single stream nature by not changing qualitatively\nbefore and after the collapse, allowing sufficiently high-order LPT\nacceleration to be used to approximate it accurately as long as the LPT series\nconverges. As expected, solving Poisson equation on the density field generated\nwith LPT displacement provides a more accurate force than the LPT acceleration\nitself, as a direct consequence of the faster convergence of the LPT series for\nthe positions than for the accelerations. This may provide a clue on improving\nstandard LPT predictions. Our investigations represent a very needed first step\nto study analytically gravitational dynamics in the multi-stream regime, by\nestimating, at leading order in time and space the proper backreaction on the\ngravitational field inside the pancakes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13355","submitter":"Debanjan Chowdhury","authors":"Thomas G. Kiely, Debanjan Chowdhury","title":"Bandwidth-tuned Wigner-Mott Transition at $\\nu=1/5$: an Infinite Matrix\n  Product State Study","comments":"Main text: 5 pages, 3 figures. Supplementary material: 7 pages, 6\n  figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.supr-con","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Electrons can organize themselves into charge-ordered states to minimize the\neffects of long-ranged Coulomb interactions. In the presence of a lattice,\ncommensurability constraints lead to the emergence of incompressible\nWigner-Mott (WM) insulators at various rational electron fillings, $\\nu~=p/q$.\nThe mechanism for quantum fluctuation-mediated melting of the WM insulators\nwith increasing electron kinetic energy remains an outstanding problem. Here we\nanalyze numerically the bandwidth-tuned transition out of the WM insulator at\n$\\nu=1/5$ on infinite cylinders with varying circumference. For the two-leg\nladder, the transition from the WM insulator to the Luttinger liquid proceeds\nvia a distinct intermediate gapless phase -- the Luther-Emery liquid. We place\nthese results in the context of a low-energy bosonization based theory for the\ntransition. We also comment on the bandwidth-tuned transition(s) on the\nfive-leg cylinder, and connections to ongoing experiments in dual-gated bilayer\nmoir\\'e transition metal dichalcogenide materials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13356","submitter":"Shayan Majidy","authors":"Shayan Majidy, Utkarsh Agrawal, Sarang Gopalakrishnan, Andrew C.\n  Potter, Romain Vasseur, Nicole Yunger Halpern","title":"Critical phase and spin sharpening in SU(2)-symmetric monitored quantum\n  circuits","comments":"8.5 pages (6 figures) + appendices (11.5 pages)","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.dis-nn cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Monitored quantum circuits exhibit entanglement transitions at certain\nmeasurement rates. Such a transition separates phases characterized by how much\ninformation an observer can learn from the measurement outcomes. We study\nSU(2)-symmetric monitored quantum circuits, using exact numerics and a mapping\nonto an effective statistical-mechanics model. Due to the symmetry's\nnon-Abelian nature, measuring qubit pairs allows for nontrivial entanglement\nscaling even in the measurement-only limit. We find a transition between a\nvolume-law entangled phase and a critical phase whose diffusive purification\ndynamics emerge from the non-Abelian symmetry. Additionally, we numerically\nidentify a \"spin-sharpening transition.\" On one side is a phase in which the\nmeasurements can efficiently identify the system's total spin quantum number;\non the other side is a phase in which measurements cannot.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13357","submitter":"Matthew Foster","authors":"Tsz Chun Wu, Patrick A. Lee, Matthew S. Foster","title":"Enhancement of Superconductivity in a Dirty Marginal Fermi Liquid","comments":"7+10 pages, 2+4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.dis-nn cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study superconductivity in a two-dimensional, disordered marginal Fermi\nliquid. At the semiclassical level, the transition temperature $T_c$ is\nstrongly suppressed because marginal Fermi liquid effects destroy well-defined\nquasiparticles. However, we show that interference between quantum-critical\ncollective modes must be included, and these enhance $T_c$, violating\nAnderson's theorem. Our results suggest that phase coherence in a disordered,\nquantum-critical system can survive and manifest in the form of collective\nexcitations, despite the absence of coherent quasiparticles.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13358","submitter":"Sung Hak Lim","authors":"Sung Hak Lim, Eric Putney, Matthew R. Buckley, David Shih","title":"Mapping Dark Matter in the Milky Way using Normalizing Flows and Gaia\n  DR3","comments":"19 pages, 13 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a novel, data-driven analysis of Galactic dynamics, using\nunsupervised machine learning -- in the form of density estimation with\nnormalizing flows -- to learn the underlying phase space distribution of 6\nmillion nearby stars from the Gaia DR3 catalog. Solving the collisionless\nBoltzmann equation with the assumption of approximate equilibrium, we calculate\n-- for the first time ever -- a model-free, unbinned, fully 3D map of the local\nacceleration and mass density fields within a 3 kpc sphere around the Sun. As\nour approach makes no assumptions about symmetries, we can test for signs of\ndisequilibrium in our results. We find our results are consistent with\nequilibrium at the 10% level, limited by the current precision of the\nnormalizing flows. After subtracting the known contribution of stars and gas\nfrom the calculated mass density, we find clear evidence for dark matter\nthroughout the analyzed volume. Assuming spherical symmetry and averaging mass\ndensity measurements, we find a local dark matter density of $0.47\\pm\n0.05\\;\\mathrm{GeV/cm}^3$. We fit our results to a generalized NFW, and find a\nprofile broadly consistent with other recent analyses.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13359","submitter":"Andrew Larkoski","authors":"Zhong-Bo Kang, Robert Kao and Andrew J. Larkoski","title":"The Multiplicity Scaling of the Fragmentation Function","comments":"5 + 2 pages, 2 + 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The single-particle inclusive fragmentation function and the particle\nmultiplicity are observables of fundamental importance in studying properties\nof quantum chromodynamics at colliders. It is well-known that at high energies,\nthe multiplicity distribution satisfies KNO scaling in which all moments are\nproportional to powers of the mean multiplicity. We prove that, under weak\nassumptions, the leading dependence of the fragmentation function on\nmultiplicity is itself a kind of KNO scaling in which all moments are inversely\nproportional to powers of the mean multiplicity. This scaling with multiplicity\nadditionally accounts for the dominant dependence on collision energy in the\nfragmentation function. The proof relies crucially on properties of the\nfragmentation function conditioned on the total multiplicity and application of\nthe Stieltjes moment problem. In the process, we construct a novel basis of the\nfragmentation function expressed as an overall exponential suppression times a\nseries of Laguerre polynomials. We study this scaling of the fragmentation\nfunction in experimental electron-position collision data and observe that\nresidual scale violations are significantly reduced.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13360","submitter":"Alessandro Savino","authors":"A. Savino, D. R. Weisz, E. D. Skillman, A. Dolphin, A. A. Cole, N.\n  Kallivayalil, A. Wetzel, J. Anderson, G. Besla, M. Boylan-Kolchin, T. M.\n  Brown, J. S. Bullock, M. L. M. Collins, M. C. Cooper, A. J. Deason, A. L.\n  Dotter, M. Fardal, A. M. N. Ferguson, T. K. Fritz, M. C. Geha, K. M. Gilbert,\n  P. Guhathakurta, R. Ibata, M. J. Irwin, M. Jeon, E. N. Kirby, G. F. Lewis, D.\n  Mackey, S. R. Majewski, N. Martin, A. McConnachie, E. Patel, R. M. Rich, J.\n  D. Simon, S. T. Sohn, E. J. Tollerud and R. P. van der Marel","title":"The Hubble Space Telescope Survey of M31 Satellite Galaxies II. The Star\n  Formation Histories of Ultra-Faint Dwarf Galaxies","comments":"18 pages, 9 figures, 3 appendices, submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We present the lifetime star formation histories (SFHs) for six ultra-faint\ndwarf (UFD; $M_V>-7.0$, $ 4.9<\\log_{10}({M_*(z=0)}/{M_{\\odot}})<5.5$) satellite\ngalaxies of M31 based on deep color-magnitude diagrams constructed from Hubble\nSpace Telescope imaging. These are the first SFHs obtained from the oldest main\nsequence turn-off of UFDs outside the halo of the Milky Way (MW). We find that\nfive UFDs formed at least 50% of their stellar mass by $z=5$ (12.6 Gyr ago),\nsimilar to known UFDs around the MW, but that 10-40% of their stellar mass\nformed at later times. We uncover one remarkable UFD, And XIII, which formed\nonly 10% of its stellar mass by $z=5$, and 75% in a rapid burst at $z\\sim2-3$,\na result that is robust to choices of underlying stellar model and is\nconsistent with its predominantly red horizontal branch. This ''young'' UFD is\nthe first of its kind and indicates that not all UFDs are necessarily quenched\nby reionization, which is consistent with predictions from several cosmological\nsimulations of faint dwarf galaxies. SFHs of the combined MW and M31 samples\nsuggest reionization did not homogeneously quench UFDs. We find that the least\nmassive MW UFDs ($M_*(z=5) \\lesssim 5\\cdot10^4 M_{\\odot}$) are likely quenched\nby reionization, whereas more massive M31 UFDs ($M_*(z=5) \\gtrsim 10^5\nM_{\\odot}$) may only have their star formation suppressed by reionization and\nquench at a later time. We discuss these findings in the context of the\nevolution and quenching of UFDs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13361","submitter":"Valentin Benedetti","authors":"Valentin Benedetti, Pablo Bueno and Javier M. Magan","title":"Generalized Symmetries For Generalized Gravitons","comments":"13 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct generalized symmetries for linearized Einstein gravity in\narbitrary dimensions. First-principle considerations in QFT force generalized\nsymmetries to appear in dual pairs. Verifying this prediction helps us find the\nfull set of non-trivial conserved charges -- associated, in equal parts, with\n2-form and $(D-2)$-form currents. Their total number is $D(D+1)$. We compute\nthe quantum commutators of pairs of dual charges, showing that they are\nnon-vanishing for regions whose boundaries are non-trivially linked with each\nother and zero otherwise, as expected on general grounds. We also consider\ngeneral linearized higher-curvature gravities. These propagate, in addition to\nthe usual graviton, a spin-0 mode as well as a massive ghost-like spin-2 one.\nWhen the latter is absent, the theory is unitary and the dual-pairs principle\nis respected. In particular, we find that the number and types of charges\nremain the same as for Einstein gravity, and that they correspond to continuous\ngeneralizations of the Einsteinian ones.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13362","submitter":"Amira Abbas","authors":"Amira Abbas, Robbie King, Hsin-Yuan Huang, William J. Huggins, Ramis\n  Movassagh, Dar Gilboa, Jarrod R. McClean","title":"On quantum backpropagation, information reuse, and cheating measurement\n  collapse","comments":"29 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The success of modern deep learning hinges on the ability to train neural\nnetworks at scale. Through clever reuse of intermediate information,\nbackpropagation facilitates training through gradient computation at a total\ncost roughly proportional to running the function, rather than incurring an\nadditional factor proportional to the number of parameters - which can now be\nin the trillions. Naively, one expects that quantum measurement collapse\nentirely rules out the reuse of quantum information as in backpropagation. But\nrecent developments in shadow tomography, which assumes access to multiple\ncopies of a quantum state, have challenged that notion. Here, we investigate\nwhether parameterized quantum models can train as efficiently as classical\nneural networks. We show that achieving backpropagation scaling is impossible\nwithout access to multiple copies of a state. With this added ability, we\nintroduce an algorithm with foundations in shadow tomography that matches\nbackpropagation scaling in quantum resources while reducing classical auxiliary\ncomputational costs to open problems in shadow tomography. These results\nhighlight the nuance of reusing quantum information for practical purposes and\nclarify the unique difficulties in training large quantum models, which could\nalter the course of quantum machine learning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13363","submitter":"Marianna Annunziatella Dr","authors":"Marianna Annunziatella, Anna Sajina, Mauro Stefanon, Danilo\n  Marchesini, Mark Lacy, Ivo Labbe, Lilianna Houston, Rachel Bezanson, Eiichi\n  Egami, Xiaohui Fan, Duncan Farrah, Jenny Greene, Andy Goulding, Yen-Ting Lin,\n  Xin Liu, Thibaud Moutard, Yoshiaki Ono, Masami Ouchi, Marcin Sawicki, Jason\n  Surace, and Katherine Whitaker","title":"The Spitzer Coverage of HSC-Deep with IRAC for Z studies (SHIRAZ) I:\n  IRAC mosaics","comments":"accepted for publication in AJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present new Spitzer Infrared Array Camera (IRAC) 3.6 and 4.5{\\mu}m mosaics\nof three fields, E-COSMOS, DEEP2-F3, and ELAIS-N1. Our mosaics include both new\nIRAC observations as well as re-processed archival data in these fields. These\nfields are part of the HSC-Deep grizy survey and have a wealth of additional\nancillary data. The addition of these new IRAC mosaics is critical in allowing\nfor improved photometric redshifts and stellar population parameters at cosmic\nnoon and earlier epochs. The total area mapped by this work is {\\sim} 17 deg2\nwith a mean integration time of {\\sim}1200s, providing a median 5{\\sigma} depth\nof 23.7(23.3) at 3.6(4.5){\\mu}m in AB. We perform SExtractor photometry both on\nthe combined mosaics as well as the single-epoch mosaics taken {\\sim}6 months\napart. The resultant IRAC number counts show good agreement with previous\nstudies. In combination with the wealth of existing and upcoming\nspectro-photometric data in these fields, our IRAC mosaics will enable a wide\nrange of galactic evolution and AGN studies. With that goal in mind, we make\nthe combined IRAC mosaics and coverage maps of these three fields publicly\navailable. counts show good agreement with previous studies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13364","submitter":"Marco Castellano","authors":"M. Castellano, D. Belfiori, L. Pentericci, A. Calabr\\`o, S. Mascia, L.\n  Napolitano, F. Caro, S. Charlot, J. Chevallard, E. Curtis-Lake, M. Talia, A.\n  Bongiorno, A. Fontana, J. P. U. Fynbo, B. Garilli, L. Guaita, R. J. McLure,\n  E. Merlin, M. Mignoli, M. Moresco, E. Pompei, L. Pozzetti, A. Saldana Lopez,\n  A. Saxena, P. Santini, D. Schaerer, C. Schreiber, A. E. Shapley, E. Vanzella,\n  G. Zamorani","title":"The ionizing photon production efficiency of bright z$\\sim$2-5 galaxies","comments":"11 pages, 9 figures, accepted for publication in A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the production efficiency of ionizing photons ($\\xi_{ion}^*$)\nof 1174 galaxies with secure redshift at z=2-5 from the VANDELS survey to\ndetermine the relation between ionizing emission and physical properties of\nbright and massive sources. We constrain $\\xi_{ion}^*$ and galaxy physical\nparameters by means of spectro-photometric fits performed with the BEAGLE code.\nThe analysis exploits the multi-band photometry in the VANDELS fields, and the\nmeasurement of UV rest-frame emission lines (CIII]$\\lambda 1909$, HeII$\\lambda\n1640$, OIII]$\\lambda 1666$) from deep VIMOS spectra. We find no clear evolution\nof $\\xi_{ion}^*$ with redshift within the probed range. The ionizing efficiency\nslightly increases at fainter $M_{UV}$, and bluer UV slopes, but these trends\nare less evident when restricting the analysis to a complete subsample at\nlog(M$_{star}$/M$_{\\odot}$)$>$9.5. We find a significant trend of increasing\n$\\xi_{ion}^*$ with increasing EW(Ly$\\alpha$), with an average\nlog($\\xi_{ion}^*$/Hz erg$^{-1}$)$>$25 at EW$>$50\\AA, and a higher ionizing\nefficiency for high-EW CIII]$\\lambda 1909$ and OIII]$\\lambda 1666$ emitters.\nThe most significant correlations are found with respect to stellar mass,\nspecific star-formation rate (sSFR) and SFR surface density ($\\Sigma_{SFR}$).\nThe relation between $\\xi_{ion}^*$ and sSFR shows a monotonic increase from\nlog($\\xi_{ion}^*$/Hz erg$^{-1}$) $\\sim$24.5 at log(sSFR)$\\sim$-9.5$yr^{-1}$ to\n$\\sim$25.5 at log(sSFR)$\\sim$-7.5$yr^{-1}$, a low scatter and little dependence\non mass. The objects above the main-sequence of star-formation consistently\nhave higher-than-average $\\xi_{ion}^*$. A clear increase of $\\xi_{ion}^*$ with\n$\\Sigma_{SFR}$ is also found, with log($\\xi_{ion}^*$/Hz erg$^{-1}$)$>$25 for\nobjects at $\\Sigma_{SFR}>$10 M$_{\\odot}/yr/kpc^2$.(Abridged)\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13365","submitter":"Jernej Rudi Fin\\v{z}gar","authors":"Jernej Rudi Fin\\v{z}gar, Martin J. A. Schuetz, J. Kyle Brubaker,\n  Hidetoshi Nishimori, Helmut G. Katzgraber","title":"Designing Quantum Annealing Schedules using Bayesian Optimization","comments":"20 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose and analyze the use of Bayesian optimization techniques to design\nquantum annealing schedules with minimal user and resource requirements. We\nshowcase our scheme with results for two paradigmatic spin models. We find that\nBayesian optimization is able to identify schedules resulting in fidelities\nseveral orders of magnitude better than standard protocols for both quantum and\nreverse annealing, as applied to the $p$-spin model. We also show that our\nscheme can help improve the design of hybrid quantum algorithms for hard\ncombinatorial optimization problems, such as the maximum independent set\nproblem, and illustrate these results via experiments on a neutral atom quantum\nprocessor available on Amazon Braket.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13366","submitter":"Michael Petersen","authors":"Michael S. Petersen, Martin D. Weinberg, Neal Katz","title":"Measuring the dynamical length of galactic bars","comments":"Submitted to MNRAS, comments welcome. arXiv admin note: text overlap\n  with arXiv:1903.08203","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We define a physically-motivated measure for galactic bar length, called the\ndynamical length. The dynamical length of the bar corresponds to the radial\nextent of the orbits that are the backbone supporting the bar feature. We\npropose a direct observational technique using integral field unit spectroscopy\nto measure it. Identifying these orbits and using the dynamical length is a\nmore faithful tracer of the secular evolution and influence of the bar. We\ndemonstrate the success of the metric for recovering the maximal bar-parenting\norbit in a range of simulations, and to show its promise we perform its\nmeasurement on a real galaxy. We also study the difference between\ntraditionally used ellipse fit approaches to determine bar length and the\ndynamical length proposed here in a wide range of bar-forming N-body\nsimulations of a stellar disc and dark matter halo. We find that ellipse\nfitting may severely overestimate measurements of the bar length by a factor of\n1.5-2.5 relative to the extent of the orbits that are trapped and actually\ncomprise the bar. This bias leads to overestimates of both bar mass and the\nratio of corotation radius to bar length, i.e. the bar speed, affecting\ninferences about the evolution of bars in the real universe.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13367","submitter":"Debasish Borah","authors":"Debasish Borah, Suruj Jyoti Das, Rishav Roshan","title":"Baryon asymmetry from dark matter decay","comments":"7 pages, 5 captioned figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a novel framework where baryon asymmetry can arise due to\nforbidden decay of dark matter (DM) enabled by finite temperature effects in\nthe early universe. In order to implement it in a realistic setup, we consider\nthe DM to be a singlet Dirac fermion which acquires a dark asymmetry from a\nscalar field $\\Phi$ via Affleck-Dine mechanism. Due to finite-temperature\neffects, DM can decay in the early universe into leptons and a second Higgs\ndoublet thereby transferring a part of the dark asymmetry into lepton asymmetry\nwith the latter getting converted into baryon asymmetry subsequently via\nelectroweak sphalerons. DM becomes stable below a critical temperature leading\nto a stable relic. While the scalar field $\\Phi$ can play the role of inflaton\nwith specific predictions for inflationary parameters, the setup also remains\nverifiable via astrophysical as well as laboratory based observations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13368","submitter":"Matilde Signorini","authors":"Matilde Signorini, Stefano Marchesi, Roberto Gilli, Marcella Brusa,\n  Andrea Comastri, Quirino D'Amato, Kazushi Iwasawa, Giorgio Lanzuisi, Giovanni\n  Mazzolari, Marco Mignoli, Alessandro Peca, Isabella Prandoni, Paolo Tozzi,\n  Cristian Vignali, Fabio Vito, Colin Norman","title":"X-ray properties and obscured fraction of AGN in the J1030 Chandra field","comments":"A&A, in press","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.CO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The 500ks Chandra ACIS-I observation of the field around the $z=6.31$ quasar\nSDSS J1030+0524 is currently the 5th deepest extragalactic X-ray survey. The\nrich multi-band coverage of the field allowed for an effective identification\nand redshift determination of the X-ray source counterparts: to date a catalog\nof 243 extragalactic X-ray sources with either a spectroscopic or photometric\nredshift estimate in the range $z\\approx0-6$ is available over a 355 arcmin$^2$\narea. Given its depth and the multi-band information, this catalog is an\nexcellent resource to investigate X-ray spectral properties of distant Active\nGalactic Nuclei (AGN) and derive the redshift evolution of their obscuration.\nWe performed a thorough X-ray spectral analysis for each object in the sample,\nmeasuring its nuclear column density $N_{\\rm H}$ and intrinsic (de-absorbed)\n2-10 keV rest-frame luminosity, $L_{2-10}$. Whenever possible, we also used the\npresence of the Fe K$_\\alpha$ emission line to improve the photometric redshift\nestimates. We measured the fractions of AGN hidden by column densities in\nexcess of $10^{22}$ and $10^{23}$cm$^{-2}$ ($f_{22}$ and $f_{23}$,\nrespectively) as a function of $L_{2-10}$ and redshift, and corrected for\nselection effects to recover the intrinsic obscured fractions. At $z\\sim 1.2$,\nwe found $f_{22}\\sim0.7-0.8$ and $f_{23}\\sim0.5-0.6$, respectively, in broad\nagreement with the results from other X-ray surveys. No significant variations\nwith X-ray luminosity were found within the limited luminosity range probed by\nour sample (log$L_{2-10}\\sim 42.8-44.3$). When focusing on luminous AGN with\nlog$L_{2-10}\\sim44$ to maximize the sample completeness up to large\ncosmological distances, we did not observe any significant change in $f_{22}$\nor $f_{23}$ over the redshift range $z\\sim0.8-3$. Nonetheless, the obscured\nfractions we measure are significantly higher than ...\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13369","submitter":"Roberta Calabrese","authors":"Roberta Calabrese, Marco Chianese, Jacob Gunn, Gennaro Miele, Stefano\n  Morisi, Ninetta Saviano","title":"Limits on light primordial black holes from high-scale leptogenesis","comments":"12 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the role that the evaporation of light primordial black holes\nmay have played in the production of the baryon asymmetry of the Universe\nthrough the high-scale leptogenesis. In particular, for mass of primordial\nblack hole in the range [$10^6$-$10^9$] g, we find a dilution of thermally\ngenerated lepton asymmetry via entropy injection in the primordial plasma after\nthe sphaleron freeze-out. As a consequence, we can put strong constraints on\nthe primordial black hole parameters, showing the mutual exclusion limits\nbetween primordial black holes and high-scale leptogenesis. Remarkably, we\npoint out an interplay between the upper bound on the initial abundance of\nprimordial black holes and the active neutrino mass scale.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13370","submitter":"Madhumita Sarkar","authors":"Madhumita Sarkar, Roopayan Ghosh, Ivan Khaymovich","title":"Tuning the phase diagram of a Rosenzweig-Porter model with fractal\n  disorder","comments":"9 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.dis-nn cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Rosenzweig-Porter (RP) model has garnered much attention in the last decade,\nas it is a simple analytically tractable model showing both ergodic--nonergodic\nextended and Anderson localization transitions. Thus, it is a good toy model to\nunderstand the Hilbert-space structure of many body localization phenomenon. In\nour study, we present analytical evidence, supported by exact numerical\ncomputations, that demonstrates the controllable tuning of the phase diagram in\nthe RP model by employing on-site potentials with a non-trivial fractal\ndimension instead of the conventional random disorder. We demonstrate that\ndoing so extends the fractal phase and creates unusual dependence of fractal\ndimensions of the eigenfunctions. Furthermore, we study the fate of level\nstatistics in such a system and analyze the return probability of a wave packet\nlocalized at a single site to provide a dynamical test-bed for our theory.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13371","submitter":"Keith Inight","authors":"K. Inight, Boris T. G\\\"ansicke, A. Schwope, S. F. Anderson, C.\n  Badenes, E. Breedt, V. Chandra, B. D. R. Davies, N. P. Gentile Fusillo, M. J.\n  Green, J. J. Hermes, I. Achaica Huamani, H. Hwang, K. Knauff, J. Kurpas, K.\n  S. Long, V. Malanushenko, S. Morrison, I.J. Quiroz C., G. N. Aichele Ramos,\n  A. Roman-Lopes, M.R. Schreiber, A. Standke, L. St\\\"utz, J. R. Thorstensen, O.\n  Toloza, G. Tovmassian, N. L. Zakamska","title":"Cataclysmic Variables from Sloan Digital Sky Survey V -- the search for\n  period bouncers continues","comments":"Submitted to MNRAS","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  SDSS-V is carrying out a dedicated survey for white dwarfs, single and in\nbinaries, and we report the analysis of the spectroscopy of cataclysmic\nvariables (CVs) and CV candidates obtained during the final plug plate\nobservations of SDSS. We identify eight new CVs, spectroscopically confirm 53\nand refute eleven published CV candidates, and we report 21 new or improved\norbital periods. Combined with previously published data, the orbital period\ndistribution of the SDSS-V CVs does not clearly exhibit a period gap. This is\nconsistent with previous findings that spectroscopically identified CVs have a\nlarger proportion of short-period systems compared to samples identified from\nphotometric variability. Remarkably, despite a systematic search, we find very\nfew period bouncers. We estimate the space density of period bouncers to be\n$\\simeq0.2\\times10^{-6}\\,\\mathrm{pc}^{-3}$, i.e. they represent only a few per\ncent of the total CV population. This suggests that during their final phase of\nevolution, CVs either destroy the donor, e.g. via a merger, or that they become\ndetached and cease mass transfer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13372","submitter":"Md Mursalin Islam","authors":"Md Mursalin Islam, K. Sengupta and Rajdeep Sensarma","title":"Non-equilibrium dynamics of bosons with dipole symmetry: A large $N$\n  Keldysh approach","comments":"10+6 pages, 6 figures","journal-ref":null,"doi":null,"report-no":"TIFR/TH/23-9","categories":"cond-mat.quant-gas cond-mat.stat-mech cond-mat.str-el hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the quench and the ramp dynamics of interacting $N$-component\ncharged bosons with dipole symmetry using Schwinger-Keldysh field theory in the\nlarge $N$ limit. The equilibrium phase diagram of these bosons shows two phases\nin the large $N$ limit. The first is a normal phase where both the global\n$U(N)$ and the dipole symmetries are conserved and the second is a delocalized\ncondensed phase where both the symmetries are broken. In contrast, our explicit\ncomputation of the steady state after an instantaneous quantum quench from the\ncondensed phase shows that an additional, novel, delocalized normal phase,\nwhere the global $U(N)$ symmetry is conserved but the dipole symmetry is\nbroken, can exist for a range of quench parameters. A study of ramp dynamics of\nthe model shows that the above-mentioned steady state exists only above a\ncritical ramp rate which we estimate.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:07 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13373","submitter":"Ohad Antebi","authors":"Ohad Antebi, Ady Stern, and Erez Berg","title":"Stoner ferromagnetism in a momentum-confined interacting 2D electron gas","comments":"4 pages, 4 figures + supplemental material","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work we investigate the ground state of a momentum-confined\ninteracting 2D electron gas, a momentum-space analog of an infinite quantum\nwell. The study is performed by combining analytical results with a numerical\nexact diagonalization procedure. We find a ferromagnetic ground state near a\nparticular electron density and for a range of effective electron (or hole)\nmasses. We argue that this observation may be relevant to the generalized\nStoner ferromagnetism recently observed in multilayer graphene systems. The\ncollective magnon excitations exhibit a linear dispersion, which originates\nfrom a diverging spin stiffness.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13374","submitter":"Julian Rincon","authors":"Joshua D. Baktay, Alexander V. Rozhkov, Adrian E. Feiguin, Julian\n  Rincon","title":"Quasi-Fermi liquid behavior in a one-dimensional system of interacting\n  spinless fermions","comments":"9+3 pages; 8+4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.mtrl-sci cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present numerical evidence for a new paradigm in one-dimensional\ninteracting fermion systems, whose phenomenology has traits of both, Luttinger\nliquids and Fermi liquids. This new state, dubbed a quasi-Fermi liquid,\npossesses a discontinuity in its fermion occupation number at the Fermi\nmomentum. The excitation spectrum presents particle-like quasiparticles, and\nabsence of hole-like quasiparticles, giving rise instead to edge singularities.\nSuch a state is realized in a one-dimensional spinless fermion lattice\nHamiltonian by fine-tuning the interactions to a regime where they become\nirrelevant in the renormalization group sense. We show, using uniform infinite\nmatrix products states and finite-entanglement scaling analysis, that the\nsystem ground state is characterized by a Luttinger parameter $K = 1$ and a\ndiscontinuous jump in the fermion occupation number. We support the\ncharacterization with calculations of the spectral function, that show a\nparticle-hole asymmetry reflected in the existence of well-defined Landau\nquasiparticles above the Fermi level, and edge singularities without the\nassociated quasiparticles below. These results indicate that the quasi-Fermi\nliquid paradigm can be realized beyond the low-energy perturbative realm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13375","submitter":"Ryotaro Sano","authors":"Ryotaro Sano, Yuya Ominato, and Mamoru Matsuo","title":"Acousto-magnonic Hall effect in honeycomb antiferromagnets","comments":"8 pages and 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recently discovered van der Waals antiferromagnets have suffered from the\nlack of a comprehensive method to study their magnetic properties. Here, we\npropose a dissipationless magnon spin Hall current driven by surface acoustic\nwaves as a novel probe for such antiferromagnets. Our results pave the way\ntowards mechanical detection and manipulation of the magnetic order in\ntwo-dimensional antiferromagnets. Furthermore, they will overcome the\ndifficulties with weak magnetic responses inherent in the use of\nantiferromagnets and hence provide a building block for future\nantiferromagnetic spintronics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13376","submitter":"Thomas Wiegart","authors":"Thomas Wiegart, Linfang Wang, Diego Lentner, Richard D. Wesel","title":"Probabilistic Shaping for Asymmetric Channels and Low-Density\n  Parity-Check Codes","comments":"submitted to ISTC 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An algorithm is proposed to encode low-density parity-check (LDPC) codes into\ncodewords with a non-uniform distribution. This enables power-efficient\nsignalling for asymmetric channels. We show gains of 0.9 dB for additive white\nGaussian noise (AWGN) channels with on-off keying modulation using 5G LDPC\ncodes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13377","submitter":"Mohammadreza Zakeri","authors":"Jeffrey M. Berryman, Susan Gardner, Mohammadreza Zakeri","title":"How Macroscopic Limits on Neutron Star Baryon Loss Yield Microscopic\n  Limits on Non-Standard-Model Baryon Decay","comments":"84 pages, 18 figures","journal-ref":null,"doi":null,"report-no":"FERMILAB-PUB-23-224-T; INT-PUB-23-001; N3AS-23-012","categories":"hep-ph astro-ph.CO astro-ph.HE gr-qc nucl-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate how our baryon-loss limits from anomalous binary-pulsar period\nlengthening can be interpreted microscopically to yield specific constraints on\nthe particle physics of baryon number violation within a neutron star. We focus\non the possibility of anomalous baryon disappearance via dark baryon processes\nand on scenarios in which the produced dark-sector particles do not survive to\ninfluence the response of the star to baryon-number-violating effects. We flesh\nout the conditions for which this may occur, as well as other key assumptions.\nWe then turn to the analysis of particle processes in the dense nuclear medium\nfound at the core of a neutron star, employing the techniques of relativistic\nmean-field theory. Using our study of in-medium effects and limits on\nmacroscopic baryon number violation we extract limits on in-vacuum\nbaryon-number-violating processes, and we determine them for various equations\nof state. We conclude by noting the implications of our results for models of\ndark-sector-enabled baryogenesis.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:09 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13378","submitter":"Bridget Ratcliffe","authors":"Bridget Ratcliffe, Ivan Minchev, Friedrich Anders, Sergey Khoperskov,\n  Guillaume Guiglion, Tobias Buck, Katia Cunha, Anna Queiroz, Christian\n  Nitschelm, Szabolcs Meszaros, Matthias Steinmetz, Roelof S. de Jong, Samir\n  Nepal, Richard R. Lane, Jennifer Sobeck","title":"Unveiling the time evolution of chemical abundances across the Milky Way\n  disk with APOGEE","comments":"accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1573","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Chemical abundances are an essential tool in untangling the Milky Way's\nenrichment history. However, the evolution of the interstellar medium abundance\ngradient with cosmic time is lost as a result of radial mixing processes. For\nthe first time, we quantify the evolution of many observational abundances\nacross the Galactic disk as a function of lookback time and birth radius,\n$R_\\text{birth}$. Using an empirical approach, we derive $R_\\text{birth}$\nestimates for 145,447 APOGEE DR17 red giant disk stars, based solely on their\nages and [Fe/H]. We explore the detailed evolution of 6 abundances (Mg, Ca\n($\\alpha$), Mn (iron-peak), Al, C (light), Ce (s-process)) across the Milky Way\ndisk using 87,426 APOGEE DR17 red giant stars. We discover that the\ninterstellar medium had three fluctuations in the metallicity gradient $\\sim\n9$, $\\sim 6$, and $\\sim4$ Gyr ago. The first coincides with the end of\nhigh-$\\alpha$ sequence formation around the time of the Gaia-Sausage-Enceladus\ndisruption, while the others are likely related to passages of the Sagittarius\ndwarf galaxy. A clear distinction is found between present-day observed radial\ngradients with age and the evolution with lookback time for both [X/Fe] and\n[X/H], resulting from the significant flattening and inversion in old\npopulations due to radial migration. We find the [Fe/H]--[$\\alpha$/Fe]\nbimodality is also seen as a separation in the $R_\\text{birth}$--[X/Fe] plane\nfor the light and $\\alpha$-elements. Our results recover the chemical\nenrichment of the Galactic disk over the past 12 Gyr, providing tight\nconstraints on Galactic disk chemical evolution models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:10 GMT"},{"version":"v2","created":"Fri, 26 May 2023 11:29:55 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.13379","submitter":"Isabel Mira Oldengott","authors":"Emil Brinch Holm, Isabel M. Oldengott, Stefan Zentarra","title":"Local clustering of relic neutrinos with kinetic field theory","comments":"7 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The density of relic neutrinos is expected to be enhanced due to clustering\nin our local neighbourhood at Earth. We introduce a novel analytical technique\nto calculate the neutrino overdensity, based on kinetic field theory. Kinetic\nfield theory is a particle-based theory for cosmic structure formation and in\nthis work we apply it for the first time to massive neutrinos. The\ngravitational interaction is expanded in a perturbation series and we take into\naccount the first-order contribution to the local density of relic neutrinos.\nFor neutrino masses that are consistent with cosmological neutrino mass bounds,\nour results are in excellent agreement with state-of-the-art calculations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13380","submitter":"Matthieu Schaller","authors":"Matthieu Schaller (1), Josh Borrow, Peter W. Draper, Mladen Ivkovic,\n  Stuart McAlpine, Bert Vandenbroucke, Yannick Bah\\'e, Evgenii Chaikin, Aidan\n  B. G. Chalk, Tsang Keung Chan, Camila Correa, Marcel van Daalen, Willem\n  Elbers, Pedro Gonnet, Lo\\\"ic Hausammann, John Helly, Filip Hu\\v{s}ko, Jacob\n  A. Kegerreis, Folkert S. J. Nobels, Sylvia Ploeckinger, Yves Revaz, William\n  J. Roper, Sergio Ruiz-Bonilla, Thomas D. Sandnes, Yolan Uyttenhove, James S.\n  Willis and Zhen Xiang ((1) Lorentz Institute & Leiden Observatory)","title":"Swift: A modern highly-parallel gravity and smoothed particle\n  hydrodynamics solver for astrophysical and cosmological applications","comments":"39 pages, 18 figures, submitted to MNRAS. Code, documentation, and\n  examples available at www.swiftsim.com","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM astro-ph.CO astro-ph.EP astro-ph.GA cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Numerical simulations have become one of the key tools used by theorists in\nall the fields of astrophysics and cosmology. The development of modern tools\nthat target the largest existing computing systems and exploit state-of-the-art\nnumerical methods and algorithms is thus crucial. In this paper, we introduce\nthe fully open-source highly-parallel, versatile, and modular coupled\nhydrodynamics, gravity, cosmology, and galaxy-formation code Swift. The\nsoftware package exploits hybrid task-based parallelism, asynchronous\ncommunications, and domain-decomposition algorithms based on balancing the\nworkload, rather than the data, to efficiently exploit modern high-performance\ncomputing cluster architectures. Gravity is solved for using a\nfast-multipole-method, optionally coupled to a particle mesh solver in Fourier\nspace to handle periodic volumes. For gas evolution, multiple modern flavours\nof Smoothed Particle Hydrodynamics are implemented. Swift also evolves\nneutrinos using a state-of-the-art particle-based method. Two complementary\nnetworks of sub-grid models for galaxy formation as well as extensions to\nsimulate planetary physics are also released as part of the code. An extensive\nset of output options, including snapshots, light-cones, power spectra, and a\ncoupling to structure finders are also included. We describe the overall code\narchitecture, summarize the consistency and accuracy tests that were performed,\nand demonstrate the excellent weak-scaling performance of the code using a\nrepresentative cosmological hydrodynamical problem with $\\approx$$300$ billion\nparticles. The code is released to the community alongside extensive\ndocumentation for both users and developers, a large selection of example test\nproblems, and a suite of tools to aid in the analysis of large simulations run\nwith Swift.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13381","submitter":"Mohammad Ali Gorji","authors":"Mohammad Ali Gorji","title":"Spin-2 dark matter from inflation","comments":"23 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO gr-qc hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The seed of dark matter can be generated from light spectator fields during\ninflation through a similar mechanism that the seed of observed large scale\nstructures are produced from the inflaton field. The accumulated energy density\nof the corresponding excited modes, which is subdominant during inflation,\ndominates energy density of the universe later around the time of matter and\nradiation equality and plays the role of dark matter. For spin-2 spectator\nfields, Higuchi bound may seem to prevent excitation of such light modes since\ndeviation of the inflationary background from the exact de Sitter spacetime is\nvery small. However, sizable interactions with the inflaton field breaks (part\nof) isometries of the de Sitter space in the inflationary background and\nrelaxes the Higuchi bound. Looking for this possibility in the context of\neffective field theory of inflation, we suggest a dark matter model consisting\nof spin-2 particles that produce during inflation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13382","submitter":"Antonio Junior Iovino","authors":"Giacomo Ferrante, Gabriele Franciolini, Antonio Junior Iovino, Alfredo\n  Urbano","title":"Primordial black holes in the curvaton model: possible connections to\n  pulsar timing arrays and dark matter","comments":"25 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO gr-qc hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We revise primordial black holes (PBHs) production in the axion-curvaton\nmodel, in light of recent developments in the computation of their abundance\naccounting for non-gaussianities (NGs) in the curvature perturbation up to all\norders. We find that NGs intrinsically generated in such scenarios have a\nrelevant impact on the phenomenology associated to PBHs and, in particular, on\nthe relation between the abundance and the signal of second-order gravitational\nwaves. We show that this model could explain both the totality of dark matter\nin the asteroid mass range and the tentative signal reported by the NANOGrav\nand IPTA collaborations in the nano-Hz frequency range. En route, we provide a\nnew, explicit computation of the power spectrum of curvature perturbations\ngoing beyond the sudden-decay approximation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13383","submitter":"Maksym Ovchynnikov","authors":"Maksym Ovchynnikov, Jean-Loup Tastet, Oleksii Mikulenko, Kyrylo\n  Bondarenko","title":"Sensitivities to feebly interacting particles: public and unified\n  calculations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The idea that new physics could take the form of feebly interacting particles\n(FIPs) - particles with a mass below the electroweak scale, but which may have\nevaded detection due to their tiny couplings or very long lifetime - has gained\na lot of traction in the last decade, and numerous experiments have been\nproposed to search for such particles. It is important, and now very timely, to\nconsistently compare the potential of these experiments for exploring the\nparameter space of various well-motivated FIPs. The present paper addresses\nthis pressing issue by presenting an open-source tool to estimate the\nsensitivity of many experiments - located at Fermilab or at the CERN's SPS,\nLHC, and FCC-hh - to various models of FIPs in a unified way: the\nMathematica-based code SensCalc.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:00:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13384","submitter":"Alvaro S. de Jesus","authors":"L. Angel, P. Arias, C. O. Dib, A. S. de Jesus, S. Kuleshov, V.\n  Kozhuharov, L. Lin, M. Lindner, F. S. Queiroz, R. C. Silva, and Y. Villamizar","title":"Toward a search for axion-like particles at the LNLS","comments":"10 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Axion-Like Particles (ALPs) appear in several dark sector studies. They have\ngained increasing attention from the theoretical and experimental community. In\nthis work, we propose the first search for ALPs to be conducted at the\nBrazilian Synchrotron Light Laboratory (LNLS). In this work, we derive the\nprojected sensitivity of a proposed experiment for the production of ALPs via\nthe channel $e^+ e^- \\to a \\gamma$. We show that such an experiment could probe\nALP masses between $1-55\\,\\mbox{MeV}$, and ALP-electron couplings down to\n$g_{aee}=2-6\\times10^{-4} \\,\\mbox{GeV}^{-1}$ depending on the energy beam,\nthickness of the target, and background assumptions. Therefore, this quest\nwould cover an unexplored region of parameter space for experiments of this\nkind, constitute a promising probe for dark sectors, and potentially become the\nfirst Latin-American dark sector detector.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:01:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13385","submitter":"Tobias Pfandzelter","authors":"Marvin Kruber and Tobias Pfandzelter and David Bermbach","title":"Efficient Exchange of Metadata Information in Geo-Distributed Fog\n  Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Metadata information is crucial for efficient geo-distributed fog computing\nsystems. Many existing solutions for metadata exchange overlook geo-awareness\nor lack adequate failure tolerance, which are vital in such systems. To address\nthis, we propose HFCS, a novel hybrid communication system that combines\nhierarchical and peer-to-peer elements, along with edge pools. HFCS utilizes a\ngossip protocol for dynamic metadata exchange.\n  In simulation, we investigate the impact of node density and edge pool size\non HFCS performance. We observe a significant performance improvement for\nclustered node distributions, aligning well with real-world scenarios.\nAdditionally, we compare HFCS with a hierarchical system and a peer-to-peer\nbroadcast approach. HFCS outperforms both in task fulfillment at the cost of an\naverage 16\\% detected failures due to its peer-to-peer structures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:02:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13386","submitter":"Nadir Durrani Dr","authors":"Basel Mousi, Nadir Durrani, Fahim Dalvi","title":"Can LLMs facilitate interpretation of pre-trained language models?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Work done to uncover the knowledge encoded within pre-trained language\nmodels, rely on annotated corpora or human-in-the-loop methods. However, these\napproaches are limited in terms of scalability and the scope of interpretation.\nWe propose using a large language model, ChatGPT, as an annotator to enable\nfine-grained interpretation analysis of pre-trained language models. We\ndiscover latent concepts within pre-trained language models by applying\nhierarchical clustering over contextualized representations and then annotate\nthese concepts using GPT annotations. Our findings demonstrate that ChatGPT\nproduces accurate and semantically richer annotations compared to\nhuman-annotated concepts. Additionally, we showcase how GPT-based annotations\nempower interpretation analysis methodologies of which we demonstrate two:\nprobing framework and neuron interpretation. To facilitate further exploration\nand experimentation in this field, we have made available a substantial\nConceptNet dataset comprising 39,000 annotated latent concepts.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:03:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13387","submitter":"Igor Zinchenko A.","authors":"I. A. Zinchenko","title":"Gas and stellar kinematic misalignment in MaNGA galaxies: what is the\n  origin of counter-rotating gas?","comments":"5 pages, 3 figures, accepted for publication in A&A Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Kinematic misalignment between gas and stellar components observed in a\ncertain fraction of galaxies. It believed to be caused by acquisition of gas\nfrom the external reservoir by major or minor mergers, accretion from\ncosmological filaments or circumgalactic medium, etc. We aim to constrain\npossible sources of the gas that forms counter-rotating component. We derived\nthe gas-phase oxygen abundance in 69 galaxies with kinematic misalignment\nbetween gas and stellar components from MaNGA DR17 survey and compared it with\nthe metallicity expected according to the mass-metallicity relation. We found\nthat the oxygen abundance of the counter-rotating gas in our sample is higher\nthan 8.2 dex that excludes significant role of inflow of pristine gas.\nMeanwhile, there is a significant difference in the oxygen abundance of the\ncounter-rotating gas between red and blue galaxies. In general, the oxygen\nabundance is lower than expected for their stellar mass in red galaxies, but is\ncompatible with or even higher than typical values for their stellar mass in\nblue galaxies. We showed that the exchange of enriched gas between galaxies is\nthe most plausible mechanism for explaining the metallicity of counter-rotating\ngas components in galaxies of all masses and colors. Meanwhile, minor mergers\nmay play a significant role in the formation of counter-rotating gas components\nin red and quenched galaxies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:04:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13388","submitter":"Jon Gauthier","authors":"Jon Gauthier and Roger Levy","title":"The neural dynamics of auditory word recognition and integration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL q-bio.NC","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Listeners recognize and integrate words in rapid and noisy everyday speech by\ncombining expectations about upcoming content with incremental sensory\nevidence. We present a computational model of word recognition which formalizes\nthis perceptual process in Bayesian decision theory. We fit this model to\nexplain scalp EEG signals recorded as subjects passively listened to a\nfictional story, revealing both the dynamics of the online auditory word\nrecognition process and the neural correlates of the recognition and\nintegration of words.\n  The model reveals distinct neural processing of words depending on whether or\nnot they can be quickly recognized. While all words trigger a neural response\ncharacteristic of probabilistic integration -- voltage modulations predicted by\na word's surprisal in context -- these modulations are amplified for words\nwhich require more than roughly 100 ms of input to be recognized. We observe no\ndifference in the latency of these neural responses according to words'\nrecognition times.Our results support a two-part model of speech comprehension,\ncombining an eager and rapid process of word recognition with a temporally\nindependent process of word integration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:06:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13389","submitter":"Jon Zink","authors":"Jon K. Zink, Kevin K. Hardegree-Ullman, Jessie L. Christiansen, Erik\n  A. Petigura, Kiersten M. Boley, Sakhee Bhure, Malena Rice, Samuel W. Yee,\n  Howard Isaacson, Rachel B. Fernandes, Andrew W. Howard, Sarah Blunt, Jack\n  Lubin, Ashley Chontos, Daria Pidhorodetska, and Mason G. MacDougall","title":"Scaling K2. VI. Reduced Small Planet Occurrence in High Galactic\n  Amplitude Stars","comments":"28 Pages, 12 Figures, 3 Tables; Accepted for Publication AJ","journal-ref":null,"doi":"10.3847/1538-3881/acd24c","report-no":null,"categories":"astro-ph.EP astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we performed a homogeneous analysis of the planets around FGK\ndwarf stars observed by the Kepler and K2 missions, providing spectroscopic\nparameters for 310 K2 targets -- including 239 Scaling K2 hosts -- observed\nwith Keck/HIRES. For orbital periods less than 40 days, we found that the\ndistribution of planets as a function of orbital period, stellar effective\ntemperature, and metallicity was consistent between K2 and Kepler, reflecting\nconsistent planet formation efficiency across numerous ~1 kpc sight-lines in\nthe local Milky Way. Additionally, we detected a 3X excess of sub-Saturns\nrelative to warm Jupiters beyond 10 days, suggesting a closer association\nbetween sub-Saturn and sub-Neptune formation than between sub-Saturn and Jovian\nformation. Performing a joint analysis of Kepler and K2 demographics, we\nobserved diminishing super-Earth, sub-Neptune, and sub-Saturn populations at\nhigher stellar effective temperatures, implying an inverse relationship between\nformation and disk mass. In contrast, no apparent host-star spectral-type\ndependence was identified for our population of Jupiters, which indicates\ngas-giant formation saturates within the FGK mass regimes. We present support\nfor stellar metallicity trends reported by previous Kepler analyses. Using GAIA\nDR3 proper motion and RV measurements, we discovered a galactic location trend:\nstars that make large vertical excursions from the plane of the Milky Way host\nfewer super-Earths and sub-Neptunes. While oscillation amplitude is associated\nwith metallicity, metallicity alone cannot explain the observed trend,\ndemonstrating that galactic influences are imprinted on the planet population.\nOverall, our results provide new insights into the distribution of planets\naround FGK dwarf stars and the factors that influence their formation and\nevolution.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:07:06 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.13390","submitter":"Peiqi Sun","authors":"Peiqi Sun and Michel Grabisch and Christophe Labreuche","title":"An improvement of Random Node Generator for the uniform generation of\n  capacities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Capacity is an important tool in decision-making under risk and uncertainty\nand multi-criteria decision-making. When learning a capacity-based model, it is\nimportant to be able to generate uniformly a capacity. Due to the monotonicity\nconstraints of a capacity, this task reveals to be very difficult. The\nclassical Random Node Generator (RNG) algorithm is a fast-running speed\ncapacity generator, however with poor performance. In this paper, we firstly\npresent an exact algorithm for generating a $n$ elements' general capacity,\nusable when $n < 5$. Then, we present an improvement of the classical RNG by\nstudying the distribution of the value of each element of a capacity.\nFurthermore, we divide it into two cases, the first one is the case without any\nconditions, and the second one is the case when some elements have been\ngenerated. Experimental results show that the performance of this improved\nalgorithm is much better than the classical RNG while keeping a very reasonable\ncomputation time.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:08:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13391","submitter":"Kyoungmin Han","authors":"Kyoungmin Han, Minsik Lee","title":"EnSiam: Self-Supervised Learning With Ensemble Representations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Recently, contrastive self-supervised learning, where the proximity of\nrepresentations is determined based on the identities of samples, has made\nremarkable progress in unsupervised representation learning. SimSiam is a\nwell-known example in this area, known for its simplicity yet powerful\nperformance. However, it is known to be sensitive to changes in training\nconfigurations, such as hyperparameters and augmentation settings, due to its\nstructural characteristics. To address this issue, we focus on the similarity\nbetween contrastive learning and the teacher-student framework in knowledge\ndistillation. Inspired by the ensemble-based knowledge distillation approach,\nthe proposed method, EnSiam, aims to improve the contrastive learning procedure\nusing ensemble representations. This can provide stable pseudo labels,\nproviding better performance. Experiments demonstrate that EnSiam outperforms\nprevious state-of-the-art methods in most cases, including the experiments on\nImageNet, which shows that EnSiam is capable of learning high-quality\nrepresentations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:09:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13393","submitter":"Megala Anandan","authors":"Megala Anandan, Benjamin Boutin, Nicolas Crouseilles","title":"High order asymptotic preserving scheme for linear kinetic equations\n  with diffusive scaling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work, high order asymptotic preserving schemes are constructed and\nanalysed for kinetic equations under a diffusive scaling. The framework enables\nto consider different cases: the diffusion equation, the advection-diffusion\nequation and the presence of inflow boundary conditions. Starting from the\nmicro-macro reformulation of the original kinetic equation, high order time\nintegrators are introduced. This class of numerical schemes enjoys the\nAsymptotic Preserving (AP) property for arbitrary initial data and degenerates\nwhen $\\epsilon$ goes to zero into a high order scheme which is implicit for the\ndiffusion term, which makes it free from the usual diffusion stability\ncondition. The space discretization is also discussed and high order methods\nare also proposed based on classical finite differences schemes. The Asymptotic\nPreserving property is analysed and numerical results are presented to\nillustrate the properties of the proposed schemes in different regimes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:13:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13394","submitter":"Yuri Abramovich","authors":"Yuri Abramovich, Tanit Pongsiri","title":"Toeplitz Inverse Eigenvalue Problem: Application to the Uniform Linear\n  Antenna Array Calibration","comments":"27 pages, 40 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The inverse Toeplitz eigenvalue problem (ToIEP) concerns finding a vector\nthat specifies the real-valued symmetric Toeplitz matrix with the prescribed\nset of eigenvalues. Since phase \"calibration\" errors in uniform linear antenna\narrays (ULAs) do not change the covariance matrix eigenvalues and the moduli of\nthe covariance matrix elements, we formulate a number of the new ToIEP problems\nof the Hermitian Toeplitz matrix reconstruction, given the moduli of the matrix\nelements and the matrix eigenvalues. We demonstrate that for the real-valued\ncase, only two solutions to this problem exist, with the \"non-physical\" one\nthat in most practical cases could be easily disregarded. The computational\nalgorithm for the real-valued case is quite simple. For the complex-valued\ncase, we demonstrate that the family of solutions is broader and includes\nsolutions inappropriate for calibration. For this reason, we modified this\nToIEP problem to match the covariance matrix of the uncalibrated ULA. We\ninvestigate the statistical convergence of the ad-hoc algorithm with the sample\nmatrices instead of the true ones. The proposed ad-hoc algorithms require the\nso-called \"strong\" or \"argumental\" convergence, which means a large enough\nrequired sample volume that reduces the errors in the estimated covariance\nmatrix elements. Along with the ULA arrays, we also considered the fully\naugmentable minimum redundancy arrays that generate the same (full) set of\ncovariance lags as the uniform linear arrays, and we specified the conditions\nwhen the ULA Toeplitz covariance matrix may be reconstructed given the\nM-variate MRA covariance matrix.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:15:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13395","submitter":"Karel D'Oosterlinck","authors":"Karel D'Oosterlinck, Fran\\c{c}ois Remy, Johannes Deleu, Thomas\n  Demeester, Chris Develder, Klim Zaporojets, Aneiss Ghodsi, Simon Ellershaw,\n  Jack Collins, Christopher Potts","title":"BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for\n  Real-World Pharmacovigilance","comments":"28 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical\nliterature is paramount for public safety, but involves slow and costly manual\nlabor. We set out to improve drug safety monitoring (pharmacovigilance, PV)\nthrough the use of Natural Language Processing (NLP). We introduce BioDEX, a\nlarge-scale resource for Biomedical adverse Drug Event Extraction, rooted in\nthe historical output of drug safety reporting in the U.S. BioDEX consists of\n65k abstracts and 19k full-text biomedical papers with 256k associated\ndocument-level safety reports created by medical experts. The core features of\nthese reports include the reported weight, age, and biological sex of a\npatient, a set of drugs taken by the patient, the drug dosages, the reactions\nexperienced, and whether the reaction was life threatening. In this work, we\nconsider the task of predicting the core information of the report given its\noriginating paper. We estimate human performance to be 72.0% F1, whereas our\nbest model achieves 62.3% F1, indicating significant headroom on this task. We\nalso begin to explore ways in which these models could help professional PV\nreviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:15:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13396","submitter":"Chris Doyle","authors":"Chris Doyle, Sarah Shader, Michelle Lau, Megumi Sano, Daniel L. K.\n  Yamins and Nick Haber","title":"Developmental Curiosity and Social Interaction in Virtual Agents","comments":"6 pages, 5 figures, 2 tables; accepted to CogSci 2023 with full paper\n  publication in the proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Infants explore their complex physical and social environment in an organized\nway. To gain insight into what intrinsic motivations may help structure this\nexploration, we create a virtual infant agent and place it in a\ndevelopmentally-inspired 3D environment with no external rewards. The\nenvironment has a virtual caregiver agent with the capability to interact\ncontingently with the infant agent in ways that resemble play. We test\nintrinsic reward functions that are similar to motivations that have been\nproposed to drive exploration in humans: surprise, uncertainty, novelty, and\nlearning progress. These generic reward functions lead the infant agent to\nexplore its environment and discover the contingencies that are embedded into\nthe caregiver agent. The reward functions that are proxies for novelty and\nuncertainty are the most successful in generating diverse experiences and\nactivating the environment contingencies. We also find that learning a world\nmodel in the presence of an attentive caregiver helps the infant agent learn\nhow to predict scenarios with challenging social and physical dynamics. Taken\ntogether, our findings provide insight into how curiosity-like intrinsic\nrewards and contingent social interaction lead to dynamic social behavior and\nthe creation of a robust predictive world model.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:17:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13397","submitter":"Kyle Hixenbaugh","authors":"Kyle Hixenbaugh, Xian-Yu Wang, Malena Rice, Songhu Wang","title":"The Spin-Orbit Misalignment of TOI-1842b: The First Measurement of the\n  Rossiter-McLaughlin Effect for a Warm Sub-Saturn around a Massive Star","comments":"8 pages, 2 tables, 2 figures, accepted for publication in ApJL","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The mechanisms responsible for generating spin-orbit misalignments in\nexoplanetary systems are still not fully understood. It is unclear whether\nthese misalignments are related to the migration of hot Jupiters or are a\nconsequence of general star and planet formation processes. One promising\nmethod to address this question is to constrain the distribution of spin-orbit\nangle measurements for a broader range of planets beyond hot Jupiters. In this\nwork, we present the sky-projected obliquity ($\\lambda=-68.1_{-14.7}^{+21.2}\n\\,^{\\circ}$) for the warm sub-Saturn TOI-1842b, obtained through a measurement\nof the Rossiter-McLaughlin effect using WIYN/NEID. Using the projected\nobliquity, the stellar rotation period obtained from the TESS light curve, and\nthe projected rotation velocity from spectral analysis, we infer the 3D\nspin-orbit angle ($\\psi$) to be $\\psi=73.3^{+16.3}_{-12.9} \\,^{\\circ}$. As the\nfirst spin-orbit angle determination made for a sub-Saturn-mass planet around a\nmassive ($M_{\\rm *}=1.45 \\,{\\rm M_\\odot}$) star, our result presents an\nopportunity to examine the orbital geometries for new regimes of planetary\nsystems. When combined with archival measurements, our observations of\nTOI-1842b support the hypothesis that the previously established prevalence of\nmisaligned systems around hot, massive stars may be driven by planet-planet\ndynamical interactions. In massive stellar systems, multiple gas giants are\nmore likely to form and can then dynamically interact with each other to excite\nspin-orbit misalignments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:18:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13398","submitter":"Maysam Orouskhani","authors":"Maysam Orouskhani, Negar Firoozeh, Shaojun Xia, Mahmud Mossa-Basha,\n  Chengcheng Zhu","title":"nnDetection for Intracranial Aneurysms Detection and Localization","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG q-bio.QM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Intracranial aneurysms are a commonly occurring and life-threatening\ncondition, affecting approximately 3.2% of the general population.\nConsequently, detecting these aneurysms plays a crucial role in their\nmanagement. Lesion detection involves the simultaneous localization and\ncategorization of abnormalities within medical images. In this study, we\nemployed the nnDetection framework, a self-configuring framework specifically\ndesigned for 3D medical object detection, to detect and localize the 3D\ncoordinates of aneurysms effectively. To capture and extract diverse features\nassociated with aneurysms, we utilized TOF-MRA and structural MRI, both\nobtained from the ADAM dataset. The performance of our proposed deep learning\nmodel was assessed through the utilization of free-response receiver operative\ncharacteristics for evaluation purposes. The model's weights and 3D prediction\nof the bounding box of TOF-MRA are publicly available at\nhttps://github.com/orouskhani/AneurysmDetection.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:18:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13399","submitter":"Denisa Olteanu Roberts","authors":"Eden Dolev, Alaa Awad, Denisa Roberts, Zahra Ebrahimzadeh, Marcin\n  Mejran, Vaibhav Malpani and Mahir Yavuz","title":"Efficient Large-Scale Vision Representation Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we present our approach to single-modality vision\nrepresentation learning. Understanding vision representations of product\ncontent is vital for recommendations, search, and advertising applications in\ne-commerce. We detail and contrast techniques used to fine tune large-scale\nvision representation learning models in an efficient manner under low-resource\nsettings, including several pretrained backbone architectures, both in the\nconvolutional neural network as well as the vision transformer family. We\nhighlight the challenges for e-commerce applications at-scale and highlight the\nefforts to more efficiently train, evaluate, and serve visual representations.\nWe present ablation studies for several downstream tasks, including our\nvisually similar ad recommendations. We evaluate the offline performance of the\nderived visual representations in downstream tasks. To this end, we present a\nnovel text-to-image generative offline evaluation method for visually similar\nrecommendation systems. Finally, we include online results from deployed\nmachine learning systems in production at Etsy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:25:03 GMT"},{"version":"v2","created":"Wed, 24 May 2023 12:55:21 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13400","submitter":"Jared Siegel","authors":"Jared Siegel, Joshua Winn, Simon Albrecht","title":"Ponderings on the Possible Preponderance of Perpendicular Planets","comments":"15 pages, accepted to ApJ Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Misalignments between planetary orbits and the equatorial planes of their\nhost stars are clues about the formation and evolution of planetary systems.\nEarlier work found evidence for a peak near $90^\\circ$ in the distribution of\nstellar obliquities, based on frequentist tests. We performed hierarchical\nBayesian inference on a sample of 174 planets for which either the full\nthree-dimensional stellar obliquity has been measured (72 planets) or for which\nonly the sky-projected stellar obliquity has been measured (102 planets). We\ninvestigated whether the obliquities are best described by a Rayleigh\ndistribution, or by a mixture of a Rayleigh distribution representing\nwell-aligned systems and a different distribution representing misaligned\nsystems. The mixture models are strongly favored over the single-component\ndistribution. For the misaligned component, we tried an isotropic distribution\nand a distribution peaked at 90$^\\circ$, and found the evidence to be\nessentially the same for both models. Thus, our Bayesian inference engine did\nnot find strong evidence favoring a \"perpendicular peak,'' unlike the\nfrequentist tests. We also investigated selection biases that affect the\ninferred obliquity distribution, such as the bias of the gravity-darkening\nmethod against obliquities near $0^\\circ$ or $180^\\circ$. Further progress in\ncharacterizing the obliquity distribution will probably require the\nconstruction of a more homogeneous and complete sample of measurements.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:25:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13401","submitter":"Haotian Ye","authors":"Haotian Ye, Yihong Liu, Hinrich Sch\\\"utze","title":"A study of conceptual language similarity: comparison and evaluation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An interesting line of research in natural language processing (NLP) aims to\nincorporate linguistic typology to bridge linguistic diversity and assist the\nresearch of low-resource languages. While most works construct linguistic\nsimilarity measures based on lexical or typological features, such as word\norder and verbal inflection, recent work has introduced a novel approach to\ndefining language similarity based on how they represent basic concepts, which\nis complementary to existing similarity measures. In this work, we study the\nconceptual similarity in detail and evaluate it extensively on a binary\nclassification task.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:28:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13402","submitter":"Erasmo Tani","authors":"Adela Frances DePavia, Olga Medrano Mart\\'in del Campo, Erasmo Tani","title":"Error-Tolerant Exact Query Learning of Finite Set Partitions with\n  Same-Cluster Oracle","comments":"28 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper initiates the study of active learning for exact recovery of\npartitions exclusively through access to a same-cluster oracle in the presence\nof bounded adversarial error. We first highlight a novel connection between\nlearning partitions and correlation clustering. Then we use this connection to\nbuild a R\\'enyi-Ulam style analytical framework for this problem, and prove\nupper and lower bounds on its worst-case query complexity. Further, we bound\nthe expected performance of a relevant randomized algorithm. Finally, we study\nthe relationship between adaptivity and query complexity for this problem and\nrelated variants.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:33:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13403","submitter":"Yuqian Dai","authors":"Yuqian Dai, Serge Sharoff, Marc de Kamps","title":"GATology for Linguistics: What Syntactic Dependencies It Knows","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph Attention Network (GAT) is a graph neural network which is one of the\nstrategies for modeling and representing explicit syntactic knowledge and can\nwork with pre-trained models, such as BERT, in downstream tasks. Currently,\nthere is still a lack of investigation into how GAT learns syntactic knowledge\nfrom the perspective of model structure. As one of the strategies for modeling\nexplicit syntactic knowledge, GAT and BERT have never been applied and\ndiscussed in Machine Translation (MT) scenarios. We design a dependency\nrelation prediction task to study how GAT learns syntactic knowledge of three\nlanguages as a function of the number of attention heads and layers. We also\nuse a paired t-test and F1-score to clarify the differences in syntactic\ndependency prediction between GAT and BERT fine-tuned by the MT task (MT-B).\nThe experiments show that better performance can be achieved by appropriately\nincreasing the number of attention heads with two GAT layers. With more than\ntwo layers, learning suffers. Moreover, GAT is more competitive in training\nspeed and syntactic dependency prediction than MT-B, which may reveal a better\nincorporation of modeling explicit syntactic knowledge and the possibility of\ncombining GAT and BERT in the MT tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:34:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13404","submitter":"Bo Zhao","authors":"Bo Zhao, Robert M. Gower, Robin Walters, Rose Yu","title":"Improving Convergence and Generalization Using Parameter Symmetries","comments":"29 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In overparametrized models, different values of the parameters may result in\nthe same loss value. Parameter space symmetries are transformations that change\nthe model parameters but leave the loss invariant. Teleportation applies such\ntransformations to accelerate optimization. However, the exact mechanism behind\nthis algorithm's success is not well understood. In this paper, we show that\nteleportation not only speeds up optimization in the short-term, but gives\noverall faster time to convergence. Additionally, we show that teleporting to\nminima with different curvatures improves generalization and provide insights\non the connection between the curvature of the minima and generalization\nability. Finally, we show that integrating teleportation into a wide range of\noptimization algorithms and optimization-based meta-learning improves\nconvergence.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:35:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13405","submitter":"Keunho Kim","authors":"Keunho J. Kim, Matthew B. Bayliss, Jane R. Rigby, Michael D. Gladders,\n  John Chisholm, Keren Sharon, H{\\aa}kon Dahle, T. Emil Rivera-Thorsen, Michael\n  K. Florian, Gourav Khullar, Guillaume Mahler, Ramesh Mainali, Kate A. Napier,\n  Alexander Navarre, M. Riley Owens, Joshua Roberson","title":"Small Region, Big Impact: Highly Anisotropic Lyman-continuum Escape from\n  a Compact Starburst Region with Extreme Physical Properties","comments":"17 pages, 5 figures, 3 tables, submitted to ApJ Letters. Comments\n  welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Extreme, young stellar populations are considered the primary contributor to\ncosmic reionization. However, how Lyman-continuum (LyC) escapes these galaxies\nremains highly elusive because LyC escape can vary on sub-galactic scales that\nare technically challenging to observe in LyC emitters. We investigate the\nSunburst Arc: a strongly lensed, LyC emitter at $z=2.37$. This galaxy reveals\nthe exceptionally small scale (tens of parsecs) physics of LyC escape thanks to\nhigh magnification from strong lensing. Analyzing HST broadband and narrowband\nimaging, we find that the small ($<$100 pc) LyC leaking region shows distinctly\nextreme properties: a very blue UV slope ($\\beta=-2.9\\pm0.1$), high ionization\nstate ([OIII]$\\lambda 5007$/[OII]$\\lambda 3727=11\\pm3$ and [OIII]$\\lambda\n5007$/H$\\beta=6.8\\pm0.4$), strong oxygen emission (EW([OIII])$=1095\\pm 40\n\\r{A}$), and high Lyman-$\\alpha$ escape fraction ($0.3\\pm 0.03$), none of which\nare found in any non-leaking regions of the galaxy. Moreover, a UV slope\ncomparison with starburst population models indicates that the leaking region's\nUV emission consists of nearly ``pure'' stellar light with minimal\ncontamination from surrounding nebular continuum emission and dust extinction.\nThese results suggest a highly directional LyC escape such that LyC is produced\nand escapes from a small, extreme starburst region where the stellar feedback\nfrom an ionizing star cluster may create an anisotropic ``pencil beam'' viewing\ngeometry in the surrounding gas. As a result, unabsorbed LyC directly escapes\nthrough these perforated hole(s). Importantly, such anisotropic escape\nprocesses imply that unfavorable sightline effects are a crucial contributor to\nthe significant scatters between galaxy properties and LyC escape fraction in\nobservations and that strong lensing uniquely reveals the small-scale physics\nthat regulates the ionizing budget of galaxies for reionization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:37:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13406","submitter":"Yanchen Liu","authors":"Yanchen Liu, William Held, Diyi Yang","title":"DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing large language models (LLMs) that mainly focus on Standard American\nEnglish (SAE) often lead to significantly worse performance when being applied\nto other English dialects. While existing mitigations tackle discrepancies for\nindividual target dialects, they assume access to high-accuracy dialect\nidentification systems. The boundaries between dialects are inherently\nflexible, making it difficult to categorize language into discrete predefined\ncategories. In this paper, we propose DADA (Dialect Adaptation via Dynamic\nAggregation), a modular approach to imbue SAE-trained models with\nmulti-dialectal robustness by composing adapters which handle specific\nlinguistic features. The compositional architecture of DADA allows for both\ntargeted adaptation to specific dialect variants and simultaneous adaptation to\nvarious dialects. We show that DADA is effective for both single task and\ninstruction finetuned language models, offering an extensible and interpretable\nframework for adapting existing LLMs to different English dialects.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:43:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13407","submitter":"Johno van IJsseldijk","authors":"Johno van IJsseldijk, Musab Al Hasani, Eric Verschuur, Guy\n  Drijkoningen and Kees Wapenaar","title":"Application of virtual seismology to DAS data in Groningen","comments":"7 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this report we investigate whether and under what conditions virtual\nseismology via the acoustic Marchenko method can be applied to DAS data from a\nsurvey in the province of Groningen, The Netherlands. Virtual seismology allows\nto retrieve the band-limited Green's function between a virtual source at an\narbitrary focal point in the subsurface, while accounting for all orders of\nmultiples. The method requires the reflection response at the surface and an\nestimate of the traveltime between the surface and focal point. However, in\norder to successfully apply the method the reflection response needs to be free\nfrom surface waves and other direct waves, and properly scaled in order for the\nMarchenko scheme to converge. These limitations severely complicate the\napplication of the Marchenko method to field data, especially seismic surveys\non land. This report considers a full 2D geophone survey as well as a 1.5D\napproximation for a DAS survey, and compares the results of the virtual sources\nwith an actual dynamite source. The results show that virtual seismology can be\nused to recreate the reflections recorded at the surface from the dynamite\nsource using either geophone or DAS data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:48:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13408","submitter":"Qiujia Li","authors":"Qiujia Li, Bo Li, Dongseong Hwang, Tara N. Sainath, Pedro M. Mengibar","title":"Modular Domain Adaptation for Conformer-Based Streaming ASR","comments":"Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.LG cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Speech data from different domains has distinct acoustic and linguistic\ncharacteristics. It is common to train a single multidomain model such as a\nConformer transducer for speech recognition on a mixture of data from all\ndomains. However, changing data in one domain or adding a new domain would\nrequire the multidomain model to be retrained. To this end, we propose a\nframework called modular domain adaptation (MDA) that enables a single model to\nprocess multidomain data while keeping all parameters domain-specific, i.e.,\neach parameter is only trained by data from one domain. On a streaming\nConformer transducer trained only on video caption data, experimental results\nshow that an MDA-based model can reach similar performance as the multidomain\nmodel on other domains such as voice search and dictation by adding per-domain\nadapters and per-domain feed-forward networks in the Conformer encoder.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:49:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13409","submitter":"Daniel Liang","authors":"Sabee Grewal, Vishnu Iyer, William Kretschmer, Daniel Liang","title":"Efficient Learning of Quantum States Prepared With Few Non-Clifford\n  Gates","comments":"23 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We give an algorithm that efficiently learns a quantum state prepared by\nClifford gates and $O(\\log(n))$ non-Clifford gates. Specifically, for an\n$n$-qubit state $\\lvert \\psi \\rangle$ prepared with at most $t$ non-Clifford\ngates, we show that $\\mathsf{poly}(n,2^t,1/\\epsilon)$ time and copies of\n$\\lvert \\psi \\rangle$ suffice to learn $\\lvert \\psi \\rangle$ to trace distance\nat most $\\epsilon$. This result follows as a special case of an algorithm for\nlearning states with large stabilizer dimension, where a quantum state has\nstabilizer dimension $k$ if it is stabilized by an abelian group of $2^k$ Pauli\noperators. We also develop an efficient property testing algorithm for\nstabilizer dimension, which may be of independent interest.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:49:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13410","submitter":"Nayan Myerson-Jain","authors":"Kaixiang Su, Nayan Myerson-Jain, Cenke Xu","title":"Conformal Field Theories generated by Chern Insulators under Quantum\n  Decoherence","comments":"8.5 pages, including references","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el hep-th quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We demonstrate that the fidelity between a pure state trivial insulator and\nthe mixed state density matrix of a Chern insulator under decoherence can be\nmapped to a variety of two-dimensional conformal field theories (CFT); more\nspecifically, the quantity $\\mathcal{Z} = \\text{tr}\\{ \\hat{\\rho}^D_c\n\\hat{\\rho}_\\Omega \\}$ is mapped to the partition function of the desired CFT,\nwhere $\\hat{\\rho}^D_c$ and $\\hat{\\rho}_\\Omega$ are respectively the density\nmatrices of the decohered Chern insulator and a pure state trivial insulator.\nFor a pure state Chern insulator with Chern number $2N$, the fidelity\n$\\mathcal{Z}$ is mapped to the partition function of the $\\text{U}(2N)_1$ CFT;\nunder weak decoherence, the Chern insulator density matrix can experience\ncertain instability, and the \"partition function\" $\\mathcal{Z}$ can flow to\nother interacting CFTs with smaller central charges. The R\\'{e}nyi relative\nentropy $\\mathcal{F} = - \\log \\text{tr}\\{ \\hat{\\rho}^D_c \\hat{\\rho}_\\Omega \\}$\nis mapped to the free energy of the CFT, and we demonstrate that the central\ncharge of the CFT can be extracted from the finite size scaling of\n$\\mathcal{F}$, analogous to the well-known finite size scaling of $2d$ CFT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:50:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13411","submitter":"Kailash Gogineni","authors":"Kailash Gogineni, Peng Wei, Tian Lan and Guru Venkataramani","title":"Towards Efficient Multi-Agent Learning Systems","comments":"Accepted at MLArchSys, ISCA 2023. Compared to arXiv:2302.05007, we\n  explore a neighbor sampling strategy to improve the locality of data access\n  within the mini-batch sampling phase. Our preliminary experiments provide\n  performance improvement ranging from 26.66% (3 agents) to 27.39% (12 agents)\n  in the sampling phase training run-time","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-Agent Reinforcement Learning (MARL) is an increasingly important\nresearch field that can model and control multiple large-scale autonomous\nsystems. Despite its achievements, existing multi-agent learning methods\ntypically involve expensive computations in terms of training time and power\narising from large observation-action space and a huge number of training\nsteps. Therefore, a key challenge is understanding and characterizing the\ncomputationally intensive functions in several popular classes of MARL\nalgorithms during their training phases. Our preliminary experiments reveal new\ninsights into the key modules of MARL algorithms that limit the adoption of\nMARL in real-world systems. We explore neighbor sampling strategy to improve\ncache locality and observe performance improvement ranging from 26.66% (3\nagents) to 27.39% (12 agents) during the computationally intensive mini-batch\nsampling phase. Additionally, we demonstrate that improving the locality leads\nto an end-to-end training time reduction of 10.2% (for 12 agents) compared to\nexisting multi-agent algorithms without significant degradation in the mean\nreward.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:51:12 GMT"},{"version":"v2","created":"Wed, 24 May 2023 02:22:40 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13412","submitter":"Yiming Wang","authors":"Yiming Wang, Zhuosheng Zhang, Rui Wang","title":"Element-aware Summarization with Large Language Models: Expert-aligned\n  Evaluation and Chain-of-Thought Method","comments":"Accepted by ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Automatic summarization generates concise summaries that contain key ideas of\nsource documents. As the most mainstream datasets for the news sub-domain,\nCNN/DailyMail and BBC XSum have been widely used for performance benchmarking.\nHowever, the reference summaries of those datasets turn out to be noisy, mainly\nin terms of factual hallucination and information redundancy. To address this\nchallenge, we first annotate new expert-writing Element-aware test sets\nfollowing the \"Lasswell Communication Model\" proposed by Lasswell (1948),\nallowing reference summaries to focus on more fine-grained news elements\nobjectively and comprehensively. Utilizing the new test sets, we observe the\nsurprising zero-shot summary ability of LLMs, which addresses the issue of the\ninconsistent results between human preference and automatic evaluation metrics\nof LLMs' zero-shot summaries in prior work. Further, we propose a Summary\nChain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step\nby step, which helps them integrate more fine-grained details of source\ndocuments into the final summaries that correlate with the human writing\nmindset. Experimental results show our method outperforms state-of-the-art\nfine-tuned PLMs and zero-shot LLMs by +4.33/+4.77 in ROUGE-L on the two\ndatasets, respectively. Dataset and code are publicly available at\nhttps://github.com/Alsace08/SumCoT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:54:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13413","submitter":"Yuqian Dai","authors":"Yuqian Dai, Serge Sharoff, Marc de Kamps","title":"Syntactic Knowledge via Graph Attention with BERT in Machine Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although the Transformer model can effectively acquire context features via a\nself-attention mechanism, deeper syntactic knowledge is still not effectively\nmodeled. To alleviate the above problem, we propose Syntactic knowledge via\nGraph attention with BERT (SGB) in Machine Translation (MT) scenarios. Graph\nAttention Network (GAT) and BERT jointly represent syntactic dependency feature\nas explicit knowledge of the source language to enrich source language\nrepresentations and guide target language generation. Our experiments use gold\nsyntax-annotation sentences and Quality Estimation (QE) model to obtain\ninterpretability of translation quality improvement regarding syntactic\nknowledge without being limited to a BLEU score. Experiments show that the\nproposed SGB engines improve translation quality across the three MT tasks\nwithout sacrificing BLEU scores. We investigate what length of source sentences\nbenefits the most and what dependencies are better identified by the SGB\nengines. We also find that learning of specific dependency relations by GAT can\nbe reflected in the translation quality containing such relations and that\nsyntax on the graph leads to new modeling of syntactic aspects of source\nsentences in the middle and bottom layers of BERT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:56:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13414","submitter":"Daniel Jorge","authors":"Daniel Cardoso Pereira Jorge and Ricardo Martinez-Garcia","title":"Demographic effects of aggregation in the presence of a component Allee\n  effect","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.PE nlin.AO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Intraspecific interactions are key drivers of population dynamics because\nthey establish relations between individual fitness and population density. The\ncomponent Allee effect is defined as a positive correlation between any fitness\ncomponent of a focal organism and population density, and it can lead to\npositive density dependence in the population per capita growth rate. The\nspatial structure is key to determining whether and to which extent a component\nAllee effect will manifest at the demographic level because it determines how\nindividuals interact with one another. However, existing spatial models to\nstudy the Allee effect impose a fixed spatial structure, which limits our\nunderstanding of how a component Allee effect and the spatial dynamics jointly\ndetermine the existence of demographic Allee effects. To fill this gap, we\nintroduce a spatially-explicit theoretical framework where spatial structure\nand population dynamics are emergent properties of the individual-level\ndemographic rates. Depending on the intensity of the individual processes the\npopulation exhibits a variety of spatial patterns that determine the\ndemographic-level by-products of an existing individual-level component Allee\neffect. We find that aggregation increases population abundance and allows\npopulations to survive in harsher environments and at lower global population\ndensities when compared with uniformly distributed organisms. Moreover,\naggregation can prevent the component Allee effect from manifesting at the\npopulation level or restrict it to the level of each independent group. These\nresults provide a mechanistic understanding of how component Allee effects\noperate for different spatial population structures and show at the population\nlevel. Our results contribute to better understanding population dynamics in\nthe presence of Allee effects and can potentially inform population management\nstrategies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:57:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13415","submitter":"Wen Yin","authors":"Wen Yin and Kohei Hayashi","title":"Indirect Detection of Decaying Dark Matter with High Angular Resolution:\n  Case for axion search by IRCS at Subaru Telescope","comments":"13 pages, 39 figures, 1 table","journal-ref":null,"doi":null,"report-no":"TU-1191","categories":"astro-ph.CO astro-ph.HE astro-ph.IM hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advances in cosmic-ray detectors have provided exceptional\nsensitivities of dark matter with high angular resolution. Motivated by this,\nwe present a comprehensive study of cosmic-ray flux from dark matter decay in\ndwarf spheroidal galaxies (dSphs), with a focus on detectors possessing\narcsecond-level field of view and/or angular resolution. We propose to use\ndifferential $D$-factors, which are estimated for various dSphs since such\ndetectors are sensitive to their dark matter distributions. Our findings reveal\nthat the resulting signal flux can experience a more than $O$(1-10) enhancement\nwith different theoretical uncertainty compared to traditional estimations.\nBased on this analysis, we find that the Infrared Camera and Spectrograph\n(IRCS) installed on the 8.2m Subaru telescope can be a good dark matter\ndetector for the mass in the eV range, particularly axion-like particles\n(ALPs). Observing the Draco or Ursa Major II galaxies with the IRCS for just a\nfew nights will be sufficient to surpass the stellar cooling bounds for ALP\ndark matter with a mass in the range of $1\\,{\\rm eV} \\lesssim m_a \\lesssim\n2\\,\\rm eV$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:00:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13416","submitter":"Paulo Lima-Filho","authors":"Paulo Lima-Filho","title":"Explicit Chern Cycles in BGL and KV-theory","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Using determinantal schemes, we construct explicit cycles in the higher Chow\ncomplex of BGL that represent the universal Chern classes in higher Chow\ngroups. As an application, we use these cycles, along with a canonical\n\\emph{stable moving lemma} for Karoubi-Villamayor \\(K\\)-theory, to give a\ndirect construction of the Chern class homomorphisms \\(c_{p,r}\\) from the r-th\nKV group of a regular k-algebra over a field \\( k \\), to the higher Chow group\n\\( CH^p(Spec(R),r) \\).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:01:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13417","submitter":"Shahar Katz","authors":"Shahar Katz, Yonatan Belinkov","title":"Interpreting Transformer's Attention Dynamic Memory and Visualizing the\n  Semantic Information Flow of GPT","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent advances in interpretability suggest we can project weights and hidden\nstates of transformer-based language models (LMs) to their vocabulary, a\ntransformation that makes them human interpretable and enables us to assign\nsemantics to what was seen only as numerical vectors. In this paper, we\ninterpret LM attention heads and memory values, the vectors the models\ndynamically create and recall while processing a given input. By analyzing the\ntokens they represent through this projection, we identify patterns in the\ninformation flow inside the attention mechanism. Based on these discoveries, we\ncreate a tool to visualize a forward pass of Generative Pre-trained\nTransformers (GPTs) as an interactive flow graph, with nodes representing\nneurons or hidden states and edges representing the interactions between them.\nOur visualization simplifies huge amounts of data into easy-to-read plots that\nreflect why models output their results. We demonstrate the utility of our\nmodeling by identifying the effect LM components have on the intermediate\nprocessing in the model before outputting a prediction. For instance, we\ndiscover that layer norms are used as semantic filters and find neurons that\nact as regularization vectors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:04:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13418","submitter":"Aditya Arun","authors":"William Hunter, Aditya Arun, Dinesh Bharadia","title":"WiROS: WiFi sensing toolbox for robotics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many recent works have explored using WiFi-based sensing to improve SLAM,\nrobot manipulation, or exploration. Moreover, widespread availability makes\nWiFi the most advantageous RF signal to leverage. But WiFi sensors lack an\naccurate, tractable, and versatile toolbox, which hinders their widespread\nadoption with robot's sensor stacks.\n  We develop WiROS to address this immediate need, furnishing many WiFi-related\nmeasurements as easy-to-consume ROS topics. Specifically, WiROS is a\nplug-and-play WiFi sensing toolbox providing access to coarse-grained WiFi\nsignal strength (RSSI), fine-grained WiFi channel state information (CSI), and\nother MAC-layer information (device address, packet id's or frequency-channel\ninformation). Additionally, WiROS open-sources state-of-art algorithms to\ncalibrate and process WiFi measurements to furnish accurate bearing information\nfor received WiFi signals. The open-sourced repository is:\nhttps://github.com/ucsdwcsng/WiROS\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:07:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13419","submitter":"Revathi Jambunathan","authors":"Revathi Jambunathan, Zhi Yao, Richard Lombardini, Aaron Rodriguez,\n  Andrew Nonaka","title":"Two-fluid Physical Modeling of Superconducting Resonators in the ARTEMIS\n  Framework","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we implement a new London equation module for superconductivity\nin the GPU-enabled ARTEMIS framework, and couple it to a finite-difference\ntime-domain solver for Maxwell's equations. We apply this two-fluid approach to\nmodel a superconducting coplanar waveguide (CPW) resonator. We validate our\nimplementation by verifying that the theoretical skin depth and reflection\ncoefficients can be obtained for several superconductive materials, with\ndifferent London penetration depths, over a range of frequencies. Our\nconvergence studies show that the algorithm is second-order accurate in both\nspace and time, except at superconducting interfaces where the approach is\nspatially first-order. In our CPW simulations, we leverage the GPU scalability\nof our code to compare the two-fluid model to more traditional approaches that\napproximate superconducting behavior and demonstrate that superconducting\nphysics can show comparable performance to the assumption of quasi-infinite\nconductivity as measured by the Q-factor.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:07:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13420","submitter":"Alexander Schmidt","authors":"Alexander Schmidt, Peter Hiemeyer, Fred Wolf","title":"An Analytically Solvable Model of Firing Rate Heterogeneity in Balanced\n  State Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Distributions of neuronal activity within cortical circuits are often found\nto display highly skewed shapes with many neurons emitting action potentials at\nlow or vanishing rates, while some are active at high rates. Theoretical\nstudies were able to reproduce such distributions, but come with a lack of\nmathematical tractability, preventing a deeper understanding of the impact of\nmodel parameters. In this study, using the Gauss-Rice neuron model, we present\na balanced-state cortical circuit model for which the firing rate distribution\ncan be exactly calculated. It offers selfconsistent solutions to recurrent\nneuronal networks and allows for the combination of multiple neuronal\npopulations, with single or multiple synaptic receptors (e.g. AMPA and NMDA in\nexcitatory populations), paving the way for a deeper understanding of how\nfiring rate distributions are impacted by single neuron or synaptic properties.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:10:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13421","submitter":"Sebastian Krumscheid","authors":"Sebastian Krumscheid and Per Pettersson","title":"Sequential Estimation using Hierarchically Stratified Domains with Latin\n  Hypercube Sampling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantifying the effect of uncertainties in systems where only point\nevaluations in the stochastic domain but no regularity conditions are available\nis limited to sampling-based techniques. This work presents an adaptive\nsequential stratification estimation method that uses Latin Hypercube Sampling\nwithin each stratum. The adaptation is achieved through a sequential\nhierarchical refinement of the stratification, guided by previous estimators\nusing local (i.e., stratum-dependent) variability indicators based on\ngeneralized polynomial chaos expansions and Sobol decompositions. For a given\ntotal number of samples $N$, the corresponding hierarchically constructed\nsequence of Stratified Sampling estimators combined with Latin Hypercube\nsampling is adequately averaged to provide a final estimator with reduced\nvariance. Numerical experiments illustrate the procedure's efficiency,\nindicating that it can offer a variance decay proportional to $N^{-2}$ in some\ncases.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:12:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13422","submitter":"Lukas Michel","authors":"Ant\\'onio Gir\\~ao, Freddie Illingworth, Lukas Michel, Michael Savery,\n  Alex Scott","title":"Flashes and rainbows in tournaments","comments":"14 pages, improved Theorem 1.3 slightly","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Colour the edges of the complete graph with vertex set $\\{1, 2, \\dotsc, n\\}$\nwith an arbitrary number of colours. What is the smallest integer $f(l,k)$ such\nthat if $n > f(l,k)$ then there must exist a monotone monochromatic path of\nlength $l$ or a monotone rainbow path of length $k$? Lefmann, R\\\"{o}dl, and\nThomas conjectured in 1992 that $f(l, k) = l^{k - 1}$ and proved this for $l\n\\ge (3 k)^{2 k}$. We prove the conjecture for $l \\geq k^3 (\\log k)^{1 + o(1)}$\nand establish the general upper bound $f(l, k) \\leq k (\\log k)^{1 + o(1)} \\cdot\nl^{k - 1}$. This reduces the gap between the best lower and upper bounds from\nexponential to polynomial in $k$. We also generalise some of these results to\nthe tournament setting.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:13:47 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 09:57:27 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.13423","submitter":"Kaushal Kumar Kesharpu","authors":"Kaushal K. Kesharpu","title":"Dependence of topological phase on nuclear spin $S$ and spin modulation\n  vector in van der Waals Magnets","comments":"9 Pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently non-chiral spin structures on the surface of the van der Waals (vdW)\nmagnets have been observed down to monolayers. We provide a Hamiltonian to\nanalyze the electronic properties of these materials. The Hamiltonian takes\ninto account the arbitrary background spin structures and large atomic spin $S$\nof the materials. The large spin-\\emph{S} treatment is necessary as magnetic\natoms of the vdW magnets can have spin $S > 1/2$. In this work the Hamiltonian\nis solved for the spin spirals with azimuthal and polar degrees of freedom --\nthis spin structure was recently observed in Fe$_{3}$GeTe$_{2}$. We\nmethodically analyze the Hamiltonian for both integer and half-integer spins in\nthe honeycomb lattice. It shows emerging topological hall effect emerges\nirrespective of the spin. The Chern number, hence the topological phase,\ndepends on the spin \\emph{S}, and interestingly only on the azimuthal angle of\nthe spin vector. These results will be useful for the design of the topological\nelectronics devices based on vdW magnets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:14:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13424","submitter":"Jasper Halekas","authors":"J. S. Halekas, S. D. Bale, M. Berthomier, B. D. G. Chandran, J. F.\n  Drake, J. C. Kasper, K. G. Klein, D. E. Larson, R. Livi, M. P. Pulupa, M. L.\n  Stevens, J. L. Verniero, P. Whittlesey","title":"Quantifying the Energy Budget in the Solar Wind from 13.3-100 Solar\n  Radii","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR physics.plasm-ph physics.space-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  A variety of energy sources, ranging from dynamic processes like magnetic\nreconnection and waves to quasi-steady terms like the plasma pressure, may\ncontribute to the acceleration of the solar wind. We utilize a combination of\ncharged particle and magnetic field observations from the Parker Solar Probe\n(PSP) to attempt to quantify the steady-state contribution of the proton\npressure, the electric potential, and the wave energy to the solar wind proton\nacceleration observed by PSP between 13.3 and ~100 solar radii (RS). The proton\npressure provides a natural kinematic driver of the outflow. The ambipolar\nelectric potential acts to couple the electron pressure to the protons,\nproviding another definite proton acceleration term. Fluctuations and waves,\nwhile inherently dynamic, can act as an additional effective steady-state\npressure term. To analyze the contributions of these terms, we utilize radial\nbinning of single-point PSP measurements, as well as repeated crossings of the\nsame stream at different distances on individual PSP orbits (i.e. \"fast radial\nscans\"). In agreement with previous work, we find that the electric potential\ncontains sufficient energy to fully explain the acceleration of the slower wind\nstreams. On the other hand, we find that the wave pressure plays an\nincreasingly important role in the faster wind streams. The combination of\nthese terms can explain the continuing acceleration of both slow and fast wind\nstreams beyond 13.3 RS.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:14:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13425","submitter":"Aidan Barbieux","authors":"Aidan Barbieux, Rodrigo Canaan","title":"EINCASM: Emergent Intelligence in Neural Cellular Automaton Slime Molds","comments":"Extended Abstract for the 2023 ALife conference. 2 Pages, 1 Figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI cs.MA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents EINCASM, a prototype system employing a novel framework\nfor studying emergent intelligence in organisms resembling slime molds. EINCASM\nevolves neural cellular automata with NEAT to maximize cell growth constrained\nby nutrient and energy costs. These organisms capitalize physically simulated\nfluid to transport nutrients and chemical-like signals to orchestrate growth\nand adaptation to complex, changing environments. Our framework builds the\nfoundation for studying how the presence of puzzles, physics, communication,\ncompetition and dynamic open-ended environments contribute to the emergence of\nintelligent behavior. We propose preliminary tests for intelligence in such\norganisms and suggest future work for more powerful systems employing EINCASM\nto better understand intelligence in distributed dynamical systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:15:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13426","submitter":"Helen Zhou","authors":"Helen Zhou, Yuwen Chen, Zachary C. Lipton","title":"Evaluating Model Performance in Medical Datasets Over Time","comments":"To appear at Conference on Health, Inference, and Learning (CHIL)\n  2023. arXiv admin note: substantial text overlap with arXiv:2211.07165","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning (ML) models deployed in healthcare systems must face data\ndrawn from continually evolving environments. However, researchers proposing\nsuch models typically evaluate them in a time-agnostic manner, splitting\ndatasets according to patients sampled randomly throughout the entire study\ntime period. This work proposes the Evaluation on Medical Datasets Over Time\n(EMDOT) framework, which evaluates the performance of a model class across\ntime. Inspired by the concept of backtesting, EMDOT simulates possible training\nprocedures that practitioners might have been able to execute at each point in\ntime and evaluates the resulting models on all future time points. Evaluating\nboth linear and more complex models on six distinct medical data sources\n(tabular and imaging), we show how depending on the dataset, using all\nhistorical data may be ideal in many cases, whereas using a window of the most\nrecent data could be advantageous in others. In datasets where models suffer\nfrom sudden degradations in performance, we investigate plausible explanations\nfor these shocks. We release the EMDOT package to help facilitate further works\nin deployment-oriented evaluation over time.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:16:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13427","submitter":"Lucas Rudelt Mr","authors":"Lucas Rudelt, Daniel Gonz\\'alez Marx, F. Paul Spitzner, Benjamin\n  Cramer, Johannes Zierenberg, and Viola Priesemann","title":"Signatures of hierarchical temporal processing in the mouse visual\n  system","comments":"20 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A core challenge for information processing in the brain is to integrate\ninformation across various timescales. This could be achieved by a hierarchical\norganization of temporal processing, as reported for primates; however, it is\nopen whether this hierarchical organization generalizes to sensory processing\nacross species. Here, we studied signatures of temporal processing along the\nanatomical hierarchy in the mouse visual system. We found that the intrinsic\nand information timescales of spiking activity, which serve as proxies for how\nlong information is stored in neural activity, increased along the anatomical\nhierarchy. Using information theory, we also quantified the predictability of\nneural spiking. The predictability is expected to be higher for longer\nintegration of past information, but low for redundancy reduction in an\nefficient code. We found that predictability decreases along the anatomical\ncortical hierarchy, which is in line with efficient coding, but in contrast to\nthe expectation of higher predictability for areas with higher timescales.\nMechanistically, we could explain these results in a basic network model, where\nthe increase in timescales arises from increasing network recurrence, while\nrecurrence also reduces predictability if the model's input is correlated. The\nmodel thus suggests that timescales are mainly a network-intrinsic effect,\nwhereas information-theoretic predictability depends on other sources such as\n(correlated) sensory stimuli. This is supported by a comparison of experimental\ndata from different stimulus conditions. Our results show a clear hierarchy\nacross mouse visual cortex, and thus suggest that hierarchical temporal\nprocessing presents a general organization principle across mammals.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:16:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13428","submitter":"Yusen Long","authors":"Yusen Long","title":"Hyperbolic embedding of infinite-dimensional convex bodies","comments":"34 pages. Some typos are corrected and some comments on support\n  functions are added. All comments are welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we use the second intrinsic volume to define a metric on the\nspace of homothetic classes of Gaussian bounded convex bodies in a separable\nreal Hilbert space. Using kernels of hyperbolic type, we can deduce that this\nspace is isometrically embedded into an infinite-dimensional real hyperbolic\nspace. Applying Malliavin calculus, it is possible to adapt integral geometry\nfor convex bodies in infinite dimensions. Moreover, we give a new formula for\ncomputing second intrinsic volumes of convex bodies and offer a description of\nthe completion for the hyperbolic embedding of Gaussian bounded convex bodies\nwith dimension at least two and thus answer a question asked by Debin and\nFillastre [DF22].\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:16:56 GMT"},{"version":"v2","created":"Tue, 30 May 2023 15:49:42 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13429","submitter":"Zachary Picker","authors":"Zachary S. C. Picker and Alexander Kusenko","title":"Constraints on late-forming exploding black holes","comments":"7 pages, 5 figures","journal-ref":null,"doi":null,"report-no":"IPMU23-0017","categories":"astro-ph.CO astro-ph.HE hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Black holes can be produced in collapse of small-scale dark matter\nstructures, which can happen at any time from the early to present-day\nuniverse. Microstructure black holes (MSBHs) can have a wide range of masses.\nSmall MSBHs evaporate via Hawking radiation with lifetimes shorter than the age\nof the universe, but they are not subject to the usual early-universe bounds on\nthe abundance of small primordial black holes. We investigate the possible\nsignal of such a population of exploding, late-forming black holes,\nconstraining their abundance with observations from diffuse extragalactic\ngamma- and x-ray sources, the galactic center, and dwarf spheroidal galaxies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:16:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13430","submitter":"Beth Bjorkman","authors":"Beth Bjorkman and Esther Conrad","title":"Introduction to Robust Power Domination","comments":"19 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sensors called phasor measurement units (PMUs) are used to monitor the\nelectric power network. The power domination problem seeks to minimize the\nnumber of PMUs needed to monitor the network. We extend the power domination\nproblem and consider the minimum number of sensors and appropriate placement to\nensure monitoring when $k$ sensors are allowed to fail with multiple sensors\nallowed to be placed in one location. That is, what is the minimum multiset of\nthe vertices, $S$, such that for every $F\\subseteq S$ with $|F|=k$, $S\\setminus\nF$ is a power dominating set. Such a set of PMUs is called a $k$-robust power\ndomination set. This paper generalizes the work done by Pai, Chang and Wang in\n2010 on vertex-fault-tolerant power domination, which did not allow for\nmultiple sensors to be placed at the same vertex. We provide general bounds and\ndetermine the $k$-robust power domination number of some graph families.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:17:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13431","submitter":"Nikos Prantzos","authors":"Nikos Prantzos, Carlos Abia, Tianxiang Chen, Patrick de Laverny,\n  Alejandra Recio-Blanco, E. Athanassoula, Lorenzo Roberti, Diego Vescovi,\n  Marco Limongi, Alessandro Chieffi, Sergio Cristallo","title":"On the origin of the Galactic thin and thick discs, their abundance\n  gradients and the diagnostic potential of their abundance ratios","comments":"20 pages, 16 figures, to appear in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1551","report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using a semi-analytical model of the evolution of the Milky Way, we show how\nsecular evolution can create distinct overdensities in the phase space of\nvarious properties (e.g. age vs metallicity or abundance ratios vs age)\ncorresponding to the thin and thick discs. In particular, we show how key\nproperties of the Solar vicinity can be obtained by secular evolution, with no\nneed for external or special events, like galaxy mergers or paucity in star\nformation. This concerns the long established double-branch behaviour of\n[alpha/Fe] vs metallicity and the recently found non-monotonic evolution of the\nstellar abundance gradient, evaluated at the birth radii of stars. We extend\nthe discussion to other abundance ratios and we suggest a classification\nscheme, based on the nature of the corresponding yields (primary vs secondary\nor odd elements) and on the lifetimes of their sources (short-lived vs\nlong-lived ones). The latter property is critical in determining the single- or\ndouble- branch behavior of an elementary abundance ratio in the Solar\nneighborhood. We underline the high diagnostic potential of this finding, which\ncan help to separate clearly elements with sources evolving on different\ntimescales and help determining the site of e.g. the r-process(es). We define\nthe \"abundance distance\" between the thin and thick disc sequences as an\nimportant element for such a separation. We also show how the inside-out\nevolution of the Milky Way disc leads rather to a single-branch behavior in\nother disc regions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:17:47 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13432","submitter":"Gieri Simonett","authors":"Hengrong Du, Yuanzhen Shao, Gieri Simonett","title":"On a thermodynamically consistent model for magnetoviscoelastic fluids\n  in 3D","comments":"36 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a system of equations\n  that models a non-isothermal magnetoviscoelastic fluid. We show that the\nmodel is thermodynamically consistent,\n  and that the critical points of the entropy functional with prescribed energy\ncorrespond exactly with the equilibria of the system.\n  The system is investigated in the framework of quasilinear parabolic systems\nand shown to be\n  locally well-posed in an $L_p$-setting. Furthermore, we prove that\n  constant equilibria are normally stable. In particular, we show that\nsolutions\n  that start close to a constant equilibrium exist globally and converge\nexponentially fast to a (possibly different)\n  constant equilibrium. Finally, we establish that the negative entropy serves\nas a strict Lyapunov functional\n  and we then show that every solution that is eventually bounded in the\ntopology of the natural state\n  space exists globally and converges to the set of equilibria.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:20:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13433","submitter":"Annie Pichery","authors":"Annie Pichery, Matthias Meister, Baptist Piest, Jonas B\\\"ohm, Ernst\n  Maria Rasel, Eric Charron, Naceur Gaaloul","title":"Efficient numerical description of the dynamics of interacting\n  multispecies quantum gases","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a highly efficient method for the numerical solution of coupled\nGross-Pitaevskii equations describing the evolution dynamics of a multispecies\nmixture of Bose-Einstein condensates in time-dependent potentials. This method,\nbased on a grid-scaling technique, compares favorably to a more standard but\nmuch more computationally expensive solution based on a frozen-resolution grid.\nIt allows an accurate description of the long-time behavior of interacting,\nmulti-species quantum mixtures including the challenging problem of long free\nexpansions relevant for microgravity and space experiments. We demonstrate a\nsuccessful comparison to experimental measurements of a binary Rb-K mixture\nrecently performed with the payload of a sounding rocket experiment.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:22:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13434","submitter":"Zachary Picker","authors":"Zachary S. C. Picker and Alexander Kusenko","title":"Explaining the GeV excess with exploding black holes","comments":"letter---4 pages 1 figure","journal-ref":null,"doi":null,"report-no":"IPMU23-0016","categories":"astro-ph.HE hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Black holes may form in present-day collapse of microscopic structures of\ndark matter. We show that, if microstructure black holes (MSBH) with mass\n$m\\sim 10^{13}~g$ are produced, the spectrum of gamma rays from their\nevaporation agrees remarkably well with the GeV excess observed by Fermi\nGamma-ray Space Telescope, while still avoiding all observational constraints.\nWe also discuss the generic requirements for MSBHs to explain the GeV excess.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:25:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13435","submitter":"David G. Grier","authors":"Lauren E. Altman, Andrew D. Hollingsworth and David G. Grier","title":"Anomalous tumbling of colloidal ellipsoids in Poiseuille flows","comments":"5 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Shear flows cause aspherical colloidal particles to tumble so that their\norientations trace out complex trajectories known as Jeffery orbits. The\nJeffery orbit of a prolate ellipsoid is predicted to align the particle's\nprincipal axis preferentially in the plane transverse to the axis of shear.\nHolographic microscopy measurements reveal instead that colloidal ellipsoids'\ntrajectories in Poiseuille flows strongly favor an orientation inclined by\nroughly $\\pi/8$ relative to this plane. This anomalous observation is\nconsistent with at least two previous reports of colloidal rods and dimers of\ncolloidal spheres in Poiseuille flow and therefore appears to be a generic, yet\nunexplained feature of colloidal transport at low Reynolds numbers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:25:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13436","submitter":"Jakub Nadolny","authors":"Jakub Nadolny, Micha{\\l} Jerzy Micha{\\l}owski, J. Ricardo Rizzo, Agata\n  Karska, Jesper Rasmussen, Jesper Sollerman, Jens Hjorth, Andrea Rossi,\n  Mar\\'in Solar, Rados{\\l}aw Wr\\'oblewski, Aleksandra Le\\'sniewska","title":"Main Sequence to Starburst Transitioning Galaxies: Gamma-ray Burst Hosts\n  at $z\\sim2$","comments":"11 pages, 4 figures, accepted for publication in ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Star-forming galaxies populate a main sequence (MS), a well-defined relation\nbetween stellar mass (M*) and star-formation rate (SFR). Starburst (SB)\ngalaxies lie significantly above the relation whereas quenched galaxies lie\nbelow the sequence. In order to study the evolution of galaxies on the SFR-M*\nplane and its connection to the gas content, we use the fact that recent\nepisodes of star formation can be pinpointed by the existence of gamma-ray\nbursts (GRBs). Here we present sensitive [CI]-nondetections of z$\\sim$2 ultra\nluminous infrared (ULIRG) GRB host galaxies. We find that our GRB hosts have\nsimilar molecular masses to those of other ULIRGs. However, unlike other\nULIRGs, the GRB hosts are located at the MS or only a factor of a few above it.\nHence, our GRB hosts are caught in the transition toward the SB phase. This is\nfurther supported by the estimated depletion times, which are similar to those\nof other transitioning galaxies. The GRB hosts are [CI]-dark galaxies, defined\nas having a [CI]/CO temperature brightness ratio of <0.1. Such a low [CI]/CO\nratio has been found in high-density environments (nH > 10$^4$ cm$^{-3}$) where\nCO is shielded from photodissociation, leading to under-abundances of [CI].\nThis is consistent with the merger process that is indeed suggested for our GRB\nhosts by their morphologies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:26:51 GMT"},{"version":"v2","created":"Fri, 26 May 2023 08:24:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13437","submitter":"Jose Alvarellos","authors":"Anthony R. Dobrovolskis, Jack J. Lissauer, Jose L. Alvarellos","title":"Top-shaped Asteroids as Lens-shaped Bodies","comments":"Submitted to Icarus","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Several asteroids are known to be shaped like toy tops. This paper models\nTop-Shaped Asteroids (TSAs) as Homogeneous Symmetric Lenses (HSLs), and derives\ntheir rotational, self-gravitational, and total energies as functions of their\nmass, density, and angular momentum. Then we raise, test, and ultimately reject\nthe hypothesis that TSAs take the shape of lowest total energy, subject to the\nconstraint that they keep the same mass, density, and angular momentum, while\nremaining HSLs. Other processes must control the shapes of TSAs. For\ncompleteness, we also describe a Core-Mantle Model for TSAs, as well as an\nInverted Core-Mantle Model, and derive their self-gravitational energies, along\nwith their rotational energies. The gravitational potential at the center of an\nHSL then is derived.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:26:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13438","submitter":"Bernd Schr\\\"oder","authors":"Bernd S. W. Schr\\\"oder","title":"The Automorphism Conjecture for Ordered Sets of Width $\\leq 11$ (Version\n  2)","comments":"arXiv admin note: substantial text overlap with arXiv:2209.09312","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce a recursive method to deconstruct the automorphism group of an\nordered set. By connecting this method with deep results for permutation\ngroups, we prove the Automorphism Conjecture for ordered sets of width less\nthan or equal to $11$. Subsequent investigations show that the method presented\nhere could lead to a resolution of the Automorphism Conjecture.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:28:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13439","submitter":"The CMS Collaboration","authors":"CMS Collaboration","title":"Observation of four top quark production in proton-proton collisions at\n  $\\sqrt{s}$ = 13 TeV","comments":"Submitted to Physics Letters B. All figures and tables can be found\n  at\n  http://cms-results.web.cern.ch/cms-results/public-results/publications/TOP-22-013\n  (CMS Public Pages)","journal-ref":null,"doi":null,"report-no":"CMS-TOP-22-013, CERN-EP-2023-090","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The observation of the production of four top quarks in proton-proton\ncollisions is reported, based on a data sample collected by the CMS experiment\nat a center-of-mass energy of 13 TeV in 2016-2018 at the CERN LHC and\ncorresponding to an integrated luminosity of 138 fb$^{-1}$. Events with two\nsame-sign, three, or four charged leptons (electrons and muons) and additional\njets are analyzed. Compared to previous results in these channels, updated\nidentification techniques for charged leptons and jets originating from the\nhadronization of b quarks, as well as a revised multivariate analysis strategy\nto distinguish the signal process from the main backgrounds, lead to an\nimproved expected signal significance of 4.9 standard deviations above the\nbackground-only hypothesis. Four top quark production is observed with a\nsignificance of 5.6 standard deviations, and its cross section is measured to\nbe 17.7$^{+3.7}_{-3.5}$ (stat) $^{+2.3}_{-1.9}$ (syst) fb, in agreement with\nthe available standard model predictions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:29:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13440","submitter":"Jonathan Ullman","authors":"Maryam Aliakbarpour and Rose Silver and Thomas Steinke and Jonathan\n  Ullman","title":"Differentially Private Medians and Interior Points for Non-Pathological\n  Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct differentially private estimators with low sample complexity\nthat estimate the median of an arbitrary distribution over $\\mathbb{R}$\nsatisfying very mild moment conditions. Our result stands in contrast to the\nsurprising negative result of Bun et al. (FOCS 2015) that showed there is no\ndifferentially private estimator with any finite sample complexity that returns\nany non-trivial approximation to the median of an arbitrary distribution.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:30:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13441","submitter":"Juan Marchant Gonz\\'alez","authors":"A. E. C\\'arcamo Hern\\'andez, Juan Marchant Gonz\\'alez, M.L.\n  Mora-Urruti and Daniel Salinas-Arizmendi","title":"Phenomenological aspects of the fermion and scalar sectors of a $S_4$\n  flavored 3-3-1 model","comments":"23 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a viable and predictive model based on the $SU(3)_C \\times SU(3)_L\n\\times U(1)_X$ gauge symmetry, supplemented by the global $U(1)_{Lg}$ symmetry,\nthe $S_4$ family symmetry and several auxiliary cyclic symmetries, which\nsuccessfully reproduces the observed SM fermion mass and mixing pattern. The SM\ncharged fermion mass and quark mixing hierarchy is caused by the spontaneous\nbreaking of the discrete symmetries, whereas the tiny active neutrino masses\nare generated through an inverse seesaw mechanism mediated by right-handed\nMajorana neutrinos. The model is consistent with the SM fermion masses and\nmixings and successfully accommodates the current Higgs diphoton decay rate\nconstraints as well as the constraints arising from oblique $S$, $T$ and $U$\nparameters and meson oscillations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:35:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13442","submitter":"Pablo Manuel Gal\\'an-de Anta","authors":"Pablo M. Gal\\'an-de Anta, Pedro R. Capelo, Eugene Vasiliev, Massimo\n  Dotti, Marc Sarzi, Enrico Maria Corsini, and Lorenzo Morelli","title":"The fragility of thin discs in galaxies -- II. Thin discs as tracers of\n  the assembly history of galaxies","comments":"11 pages, 10 figures","journal-ref":null,"doi":"10.1093/mnras/stad1593","report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Thin galactic discs and nuclear stellar discs (NSDs) are fragile structures\nthat can be easily disturbed by merger events. By studying the age of the\nstellar populations in present-day discs, we can learn about the assembly\nhistory of galaxies and place constraints on their past merger events.\nFollowing on the steps of our initial work, we explore the fragility of such\ndisc structures in intermediate-mass-ratio dry encounters using the previously\nconstructed $N$-body model of the Fornax galaxy NGC 1381 (FCC 170), which hosts\nboth a thin galactic disc and a NSD. We dismiss major and minor encounters, as\nthe former were previously shown to easily destroy thin-disc structures,\nwhereas the latter take several Hubble times to complete in the specific case\nof FCC 170. The kinematics and structure of the thin galactic disc are\ndramatically altered by the mergers, whereas the NSD shows a remarkable\nresilience, exhibiting only a smooth increase of its size when compared to the\nmodel evolved in isolation. Our results suggest that thin galactic discs are\nbetter tracers for intermediate-mass-ratio mergers, while NSDs may be more\nuseful for major encounters. Based on our simulations and previous analysis of\nthe stellar populations, we concluded that FCC 170 has not experienced any\nintermediate-mass-ratio dry encounters for at least $\\sim$10 Gyr, as indicated\nby the age of its thin-disc stellar populations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:37:10 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13443","submitter":"Chao Cheng","authors":"Chao Cheng, Yueqi Guo, Bo Liu, Lisa Wruck, Fan Li, Fan Li","title":"Multiply robust estimation for causal survival analysis with treatment\n  noncompliance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Comparative effectiveness research with randomized trials or observational\nstudies frequently addresses a time-to-event outcome and can require unique\nconsiderations in the presence of treatment noncompliance. Motivated by the\nchallenges in addressing noncompliance in the ADAPTABLE pragmatic trial, we\ndevelop a multiply robust estimator to estimate the principal survival causal\neffects under the principal ignorability and monotonicity assumption. The\nmultiply robust estimator involves several working models including that for\nthe treatment assignment, the compliance strata, censoring, and time to event\nof interest. We demonstrate that the proposed estimator is consistent even if\none, and sometimes two, of the working models are incorrectly specified. We\nfurther contribute sensitivity analysis strategies for investigating the\nrobustness of the multiply robust estimator under violation of two\nidentification assumptions specific to noncompliance. We implement the multiply\nrobust method in the ADAPTABLE trial to evaluate the effect of low- versus\nhigh-dose aspirin assignment on patients' death and hospitalization from\ncardiovascular diseases, and further obtain the causal effect estimates when\nthe identification assumptions fail to hold. We find that, comparing to\nlow-dose assignment, assignment to the high-dose leads to differential effects\namong always high-dose takers, compliers, and always low-dose takers. Such\ntreatment effect heterogeneity contributes to the null intention-to-treatment\neffect, and suggests that policy makers should design personalized strategies\nbased on potential compliance patterns to maximize treatment benefits to the\nentire study population.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:37:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13444","submitter":"Teague Henry","authors":"Teague R. Henry, Lindley R. Slipetz, Ami Falk, Jiaxing Qiu, Meng Chen","title":"Ordinal Outcome State-Space Models for Intensive Longitudinal Data","comments":"28 pages, 6 figures, 7 pages supplementary materials","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Intensive longitudinal (IL) data are increasingly prevalent in psychological\nscience, coinciding with technological advancements that make it simple to\ndeploy study designs such as daily diary and ecological momentary assessments.\nIL data are characterized by a rapid rate of data collection (1+ collections\nper day), over a period of time, allowing for the capture of the dynamics that\nunderlie psychological and behavioral processes. One powerful framework for\nanalyzing IL data is state-space modeling, where observed variables are\nconsidered measurements for underlying states (i.e., latent variables) that\nchange together over time. However, state-space modeling has typically relied\non continuous measurements, whereas psychological data often comes in the form\nof ordinal measurements such as Likert scale items. In this manuscript, we\ndevelop a general estimating approach for state-space models with ordinal\nmeasurements, specifically focusing on a graded response model for Likert scale\nitems. We evaluate the performance of our model and estimator against that of\nthe commonly used ``linear approximation'' model, which treats ordinal\nmeasurements as though they are continuous. We find that our model resulted in\nunbiased estimates of the state dynamics, while the linear approximation\nresulted in strongly biased estimates of the state dynamics\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:37:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13445","submitter":"Tim Langen","authors":"Tim Langen, Giacomo Valtolina, Dajun Wang, Jun Ye","title":"Quantum state manipulation and science of ultracold molecules","comments":"5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas physics.atom-ph quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An increasingly large variety of molecular species are being cooled down to\nlow energies in recent years, and innovative ideas and powerful techniques\ncontinue to emerge to gain ever more precise control of molecular motion. In\nthis brief review we focus our discussions on two widely employed cooling\ntechniques that have brought molecular gases into the quantum regime:\nassociation of ultracold atomic gases into quantum gases of molecules and\ndirect laser cooling of molecules. These advances have brought into reality our\ncapability to prepare and manipulate both internal and external states of\nmolecules quantum mechanically, opening the field of cold molecules to a wide\nrange of scientific explorations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:39:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13446","submitter":"Beth Bjorkman","authors":"Johnathan Koch and Beth Bjorkman","title":"The Power Domination Toolbox","comments":"12 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Phasor Measurement Units (PMUs) are placed at strategic nodes in an\nelectrical power network to directly monitor nearby transmission lines and\nmonitor further parts of the network through conservation of energy\nlaws.Efficient placement of PMUs is modeled by the graph theoretic process\ncalled Power Domination (PD). This paper describes a Power Domination Toolbox\n(PDT) that efficiently identifies potential PMU locations. The PDT leverages\nthe graph theoretic literature to reduce the complexity of determining optimal\nPMU placements by: reducing the size of the network (contraction),\nidentification of preferred nodes, elimination of redundant nodes, assignment\nof a qualitative score to the remaining nodes, and parallel processing\ntechniques. After pre-processing steps to reduce network size, current\nstate-of-the-art PD techniques based on the minimum rank sage library (MRZG)\nare used to analyze the network. The PDT is an extension of MRZG in Python and\nmaintains the compatibility of MRZG with SageMath. The PDT can identify minimum\nPMU placements for networks with hundreds of nodes on personal computers and\ncan analyze larger networks on high performance computers. The PDT affords\nusers the ability to investigate power domination on networks previously\nconsidered infeasible due to the number of nodes resulting in a prohibitively\nlong run-time.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:43:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13447","submitter":"Pedro Castro","authors":"Pedro Henrique Nascimento Castro, Gabriel C\\'assia Fortuna, Rafael\n  Alves Bonfim de Queiroz, Gladston Juliano Prates Moreira and Eduardo Jos\\'e\n  da Silva Luz","title":"Regularization Through Simultaneous Learning: A Case Study for Hop\n  Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Overfitting remains a prevalent challenge in deep neural networks, leading to\nsuboptimal real-world performance. Employing regularization techniques is a\ncommon strategy to counter this challenge, improving model generalization. This\npaper proposes Simultaneous Learning, a novel regularization approach drawing\non Transfer Learning and Multi-task Learning principles, applied specifically\nto the classification of hop varieties - an integral component of beer\nproduction. Our approach harnesses the power of auxiliary datasets in synergy\nwith the target dataset to amplify the acquisition of highly relevant features.\nThrough a strategic modification of the model's final layer, we enable the\nsimultaneous classification of both datasets without the necessity to treat\nthem as disparate tasks. To realize this, we formulate a loss function that\nincludes an inter-group penalty. We conducted experimental evaluations using\nthe InceptionV3 and ResNet50 models, designating the UFOP-HVD hop leaf dataset\nas the target and ImageNet and PlantNet as auxiliary datasets. Our proposed\nmethod exhibited a substantial performance advantage over models without\nregularization and those adopting dropout regularization, with accuracy\nimprovements ranging from 5 to 22 percentage points. Additionally, we introduce\na technique for interpretability devised to assess the quality of features by\nanalyzing correlations among class features in the network's convolutional\nlayers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:44:57 GMT"},{"version":"v2","created":"Wed, 24 May 2023 01:54:33 GMT"},{"version":"v3","created":"Thu, 25 May 2023 03:34:47 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13448","submitter":"Predrag Jovanovic","authors":"Predrag Jovanovi\\'c, Vesna Borka Jovanovi\\'c, Du\\v{s}ko Borka,\n  Alexander F. Zakharov","title":"Improvement of graviton mass constraints using GRAVITY's detection of\n  Schwarzschild precession in the orbit of S2 star around the Galactic Center","comments":"10 pages, 2 tables, 6 figures. Submitted to Chinese Physics C","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Here we study the possible improvements of the existing constraints on the\nupper bound of graviton mass by the analysis of the stellar orbits around the\nsupermassive black hole (SMBH) at the Galactic Center (GC) in the framework of\nYukawa gravity. Main motivation for this study is recent detection of\nSchwarzschild precession in the orbit of S2 star around the SMBH at the GC by\nthe GRAVITY Collaboration in 2020. They indicated that the orbital precession\nof the S2 star is close to the General Relativity (GR) prediction, but with\npossible small deviation from it, and parametrized this effect by introducing\nan ad hoc factor in the parameterized post-Newtonian (PPN) equations of motion.\nHere we use the value of this factor presented by GRAVITY in order to perform\ntwo-body simulations of the stellar orbits in massive gravity using equations\nof motion in the modified PPN formalism, as well as to constrain the range of\nmassive interaction $\\Lambda$. From the obtained values of $\\Lambda$, and\nassuming that it corresponds to the Compton wavelength of graviton, we then\ncalculated new estimates for the upper bound of graviton mass which are found\nto be independent, but consistent with the LIGO's estimate of graviton mass\nfrom the first gravitational wave (GW) signal GW150914. We also performed\nMarkov chain Monte Carlo (MCMC) simulations in order to constrain the bounds on\ngraviton mass in the case of a small deviation of the stellar orbits from the\ncorresponding GR predictions and showed that our method could further improve\nprevious estimates for upper bounds on the graviton mass. It is also\ndemonstrated that such analysis of the observed orbits of S-stars around the GC\nin the frame of the Yukawa gravity represents a tool for constraining the upper\nbound for the graviton mass, as well as for probing the predictions of GR or\nother gravity theories.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:45:19 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 16:44:09 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.13449","submitter":"Michael Shull","authors":"J. Michael Shull (1) and S. R. Kulkarni (2) ((1) University of\n  Colorado, (2) Caltech)","title":"Interstellar Bow Shocks around Fast Stars Passing through the Local\n  Interstellar Medium","comments":"Accepted to Astrophysical Journal, 12 pages with one table","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bow-shocks are produced in the local interstellar medium by the passage of\nfast stars from the Galactic thin-disk and thick-disk populations with\nvelocities $V_* = $ 40-80 km/s. Stellar transits of local H I clouds occur\nevery 3500-7000 yr on average and last between $10^4$ and $10^5$ yr. There\ncould be 10-20 active bow shocks around low-mass stars inside clouds within\n10-15 pc of the Sun. At local cloud distances of 3-10 pc, their turbulent wakes\nhave transverse radial extents $R_{\\rm wake} \\approx$ 10-300 AU, angular sizes\n10-100 arcsec, and Lyman-alpha surface brightnesses of 2-8 Rayleighs in gas\nwith total hydrogen density $n_H \\approx 0.1~{\\rm cm}^{-3}$ and $V_* =$ 40-80\nkm/s. These transit wakes may cover an area fraction $f_A \\approx (R_{\\rm\nwake}/R_{\\rm cl}) \\approx 10^{-3}$ of local H I clouds and be detectable in IR\n(dust), UV (Lya, two-photon), or non-thermal radio emission. Turbulent heating\nin these wakes could produce the observed elevated rotational populations of\nH$_2$ ($J \\geq 2$) and influence the endothermic formation of CH$^+$ in diffuse\ninterstellar gas at $T > 10^3$ K.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:49:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13450","submitter":"Abhinav Jangda","authors":"Abhinav Jangda, Saeed Maleki, Maryam Mehri Dehnavi, Madan Musuvathi,\n  Olli Saarikivi","title":"A Framework for Fine-Grained Synchronization of Dependent GPU Kernels","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Machine Learning (ML) models contain highly-parallel computations, such as,\nMatrix Multiplication, Convolutions, Dropout, etc. These computations are\ncommonly executed on Graphics Processing Units (GPUs), by dividing the\ncomputation in independent processing blocks, known as tiles. Since the number\nof tiles are usually higher than the execution units of a GPU, tiles are\nexecuted on all execution units in waves. However, the tiles executed in the\nlast wave can under-utilize the execution units because tiles are not always a\nmultiple of execution units. This under-utilization can be reduced by executing\nmultiple independent kernels concurrently on a GPU, but is not currently\npossible for dependent kernels.\n  In this paper, we present cuSync, a framework to write custom fine-grained\nsynchronization policies for dependent kernels to improve GPU utilization.\ncuSync synchronizes tiles instead of kernels, which allows executing tiles of\nmultiple dependent kernels. Using cuSync we expressed several synchronization\npolicies in a few lines of code and reduced the inference times of GPT-3 and\nResNet-38 by up to 1.19x and 1.16x respectively.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:49:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13451","submitter":"Leonora Kaldaras","authors":"Leonora Kaldaras and Carl Wieman","title":"Introducing an Instructional Model for Teaching Blended Math-Science\n  Sensemaking in Undergraduate STEM Courses Using Computer Simulations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ed-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ability to express scientific concepts in mathematical terms and\nintegrate scientific and mathematical reasoning about a phenomenon is a\nfoundational cognitive process involved in scientific thinking. This process\ncalled blended math-science sensemaking (blended MSS) is a desired skill for\nall STEM students, but few students are learning it, and there is little\nresearch on how to teach it. In this work we introduce the development and\ntesting of a novel instructional method for teaching blended (MSS) that is\nsuitable for use in STEM courses in undergraduate and K-12 educational\nsettings. This study builds on our past work on developing and validating a\nframework for characterizing in detail the cognitive levels involved in such\nsensemaking. This work uses the unique power of interactive simulations for\nassessing and developing blended MSS. We designed instructional activities to\nhelp students use blended MSS in the contexts of heat capacity and Coulombs\nlaw. The Heat Capacity activity was piloted in a freshmen Chemistry course and\nthe Coulombs law activity was piloted in a freshmen Physics course. The results\nindicate that for students who came in with no knowledge of the relevant\nequation the activity supported the development of both the equation, and their\nunderstanding of the mathematical relationships of the equation. These results\nindicate that the teaching approach helps students engage in blended MSS at\nhigher levels of cognitive complexity.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:50:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13452","submitter":"Julio Martinez","authors":"Julio Martinez, Felix Binder, Haoliang Wang, Nicker Haber, Judith Fan,\n  Daniel L. K. Yamins","title":"Measuring and Modeling Physical Intrinsic Motivation","comments":"6 pages, 5 figures, accepted to CogSci 2023 with full paper\n  publication in the proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Humans are interactive agents driven to seek out situations with interesting\nphysical dynamics. Here we formalize the functional form of physical intrinsic\nmotivation. We first collect ratings of how interesting humans find a variety\nof physics scenarios. We then model human interestingness responses by\nimplementing various hypotheses of intrinsic motivation including models that\nrely on simple scene features to models that depend on forward physics\nprediction. We find that the single best predictor of human responses is\nadversarial reward, a model derived from physical prediction loss. We also find\nthat simple scene feature models do not generalize their prediction of human\nresponses across all scenarios. Finally, linearly combining the adversarial\nmodel with the number of collisions in a scene leads to the greatest\nimprovement in predictivity of human responses, suggesting humans are driven\ntowards scenarios that result in high information gain and physical activity.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:52:08 GMT"},{"version":"v2","created":"Wed, 24 May 2023 08:47:28 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13453","submitter":"Ali Owfi","authors":"Ali Owfi, ChunChih Lin, Linke Guo, Fatemeh Afghah, Jonathan Ashdown,\n  Kurt Turck","title":"A Meta-learning based Generalizable Indoor Localization Model using\n  Channel State Information","comments":"6 pages, 6 figures, submitted to IEEE GLOBECOM 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Indoor localization has gained significant attention in recent years due to\nits various applications in smart homes, industrial automation, and healthcare,\nespecially since more people rely on their wireless devices for location-based\nservices. Deep learning-based solutions have shown promising results in\naccurately estimating the position of wireless devices in indoor environments\nusing wireless parameters such as Channel State Information (CSI) and Received\nSignal Strength Indicator (RSSI). However, despite the success of deep\nlearning-based approaches in achieving high localization accuracy, these models\nsuffer from a lack of generalizability and can not be readily-deployed to new\nenvironments or operate in dynamic environments without retraining. In this\npaper, we propose meta-learning-based localization models to address the lack\nof generalizability that persists in conventionally trained DL-based\nlocalization models. Furthermore, since meta-learning algorithms require\ndiverse datasets from several different scenarios, which can be hard to collect\nin the context of localization, we design and propose a new meta-learning\nalgorithm, TB-MAML (Task Biased Model Agnostic Meta Learning), intended to\nfurther improve generalizability when the dataset is limited. Lastly, we\nevaluate the performance of TB-MAML-based localization against conventionally\ntrained localization models and localization done using other meta-learning\nalgorithms.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:54:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13454","submitter":"Fernando Rosas","authors":"Patricio Orio, Pedro A.M. Mediano, Fernando E. Rosas","title":"Dynamical noise can enhance high-order statistical structure in complex\n  systems","comments":"8 pages, 4 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.AO cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research has provided a wealth of evidence highlighting the pivotal\nrole of high-order interdependencies in supporting the information-processing\ncapabilities of distributed complex systems. These findings may suggest that\nhigh-order interdependencies constitute a powerful resource that is, however,\nchallenging to harness and can be readily disrupted. In this paper we contest\nthis perspective by demonstrating that high-order interdependencies can not\nonly exhibit robustness to stochastic perturbations, but can in fact be\nenhanced by them. Using elementary cellular automata as a general testbed, our\nresults unveil the capacity of dynamical noise to enhance the statistical\nregularities between agents and, intriguingly, even alter the prevailing\ncharacter of their interdependencies. Furthermore, our results show that these\neffects are related to the high-order structure of the local rules, which\naffect the system's susceptibility to noise and characteristic times-scales.\nThese results deepen our understanding of how high-order interdependencies may\nspontaneously emerge within distributed systems interacting with stochastic\nenvironments, thus providing an initial step towards elucidating their origin\nand function in complex systems like the human brain.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:56:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13455","submitter":"David Schlangen","authors":"Kranti Chalamalasetti and Jana G\\\"otze and Sherzod Hakimov and Brielen\n  Madureira and Philipp Sadler and David Schlangen","title":"clembench: Using Game Play to Evaluate Chat-Optimized Language Models as\n  Conversational Agents","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent work has proposed a methodology for the systematic evaluation of\n\"Situated Language Understanding Agents\"-agents that operate in rich linguistic\nand non-linguistic contexts-through testing them in carefully constructed\ninteractive settings. Other recent work has argued that Large Language Models\n(LLMs), if suitably set up, can be understood as (simulators of) such agents. A\nconnection suggests itself, which this paper explores: Can LLMs be evaluated\nmeaningfully by exposing them to constrained game-like settings that are built\nto challenge specific capabilities? As a proof of concept, this paper\ninvestigates five interaction settings, showing that current chat-optimised\nLLMs are, to an extent, capable to follow game-play instructions. Both this\ncapability and the quality of the game play, measured by how well the\nobjectives of the different games are met, follows the development cycle, with\nnewer models performing better. The metrics even for the comparatively simple\nexample games are far from being saturated, suggesting that the proposed\ninstrument will remain to have diagnostic value. Our general framework for\nimplementing and evaluating games with LLMs is available at\nhttps://github.com/clp-research/clembench.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:56:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13456","submitter":"Isaac Corley","authors":"Isaac Corley, Caleb Robinson, Rahul Dodhia, Juan M. Lavista Ferres,\n  Peyman Najafirad","title":"Revisiting pre-trained remote sensing model benchmarks: resizing and\n  normalization matters","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Research in self-supervised learning (SSL) with natural images has progressed\nrapidly in recent years and is now increasingly being applied to and\nbenchmarked with datasets containing remotely sensed imagery. A common\nbenchmark case is to evaluate SSL pre-trained model embeddings on datasets of\nremotely sensed imagery with small patch sizes, e.g., 32x32 pixels, whereas\nstandard SSL pre-training takes place with larger patch sizes, e.g., 224x224.\nFurthermore, pre-training methods tend to use different image normalization\npreprocessing steps depending on the dataset. In this paper, we show, across\nseven satellite and aerial imagery datasets of varying resolution, that by\nsimply following the preprocessing steps used in pre-training (precisely, image\nsizing and normalization methods), one can achieve significant performance\nimprovements when evaluating the extracted features on downstream tasks -- an\nimportant detail overlooked in previous work in this space. We show that by\nfollowing these steps, ImageNet pre-training remains a competitive baseline for\nsatellite imagery based transfer learning tasks -- for example we find that\nthese steps give +32.28 to overall accuracy on the So2Sat random split dataset\nand +11.16 on the EuroSAT dataset. Finally, we report comprehensive benchmark\nresults with a variety of simple baseline methods for each of the seven\ndatasets, forming an initial benchmark suite for remote sensing imagery.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:57:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13457","submitter":"Luan Vinicio De Mattos Ferreira Silva","authors":"Douglas D. Novaes and Luan V. M. F. Silva","title":"Invariant tori and boundedness of solutions of non-smooth oscillators\n  with Lebesgue integrable forcing term","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Since Littlewood works in the 1960's, the boundedness of solutions of\nDuffing-type equations $\\ddot{x}+g(x)=p(t)$ has been extensively investigated.\nMore recently, some researches have focused on the family of non-smooth forced\noscillators $ \\ddot{x}+\\text{sgn}(x)=p(t)$, mainly because it represents a\nsimple limit scenario of Duffing-type equations for when $g$ is bounded. Here,\nwe provide a simple proof for the boundedness of solutions of the non-smooth\nforced oscillator in the case that the forcing term $p(t)$ is a $T$-periodic\nLebesgue integrable function with vanishing average. We reach this result by\nconstructing a sequence of invariant tori whose union of their interiors covers\nall the $(t,x,\\dot x)$-space, $(t,x,\\dot{x})\\in\n\\mathbb{S}^1\\times\\mathbb{R}^2$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:57:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13458","submitter":"Andrew Nelson","authors":"A. O. Nelson, L. Schmitz, C. Paz-Soldan, K. E. Thome, T. B. Cote, N.\n  Leuthold, F. Scotti, M. E. Austin, A. Hyatt, T. Osborne","title":"Robust avoidance of edge-localized modes alongside gradient formation in\n  the negative triangularity tokamak edge","comments":"5 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a series of high performance diverted discharges on DIII-D, we demonstrate\nthat strong negative triangularity (NT) shaping robustly suppresses all\nedge-localized mode (ELM) activity over a wide range of plasma conditions:\n$\\langle n\\rangle=0.1-1.5\\times10^{20}$m$^{-3}$, $P_\\mathrm{aux}=0-15$MW and\n$|B_\\mathrm{t}|=1-2.2$T, corresponding to\n$P_\\mathrm{loss}/P_\\mathrm{LH08}\\sim8$. The full dataset is consistent with the\ntheoretical prediction that magnetic shear in the NT edge inhibits access to\nELMing H-mode regimes; all experimental pressure profiles are found to be at or\nbelow the infinite-$n$ ballooning stability limit. Importantly, we also report\nenhanced edge pressure gradients at strong NT that are significantly steeper\nthan in traditional ELM-free L-mode plasmas and provide significant promise for\nNT reactor integration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:58:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13459","submitter":"Benjamin Doerr","authors":"Sacha Cerf, Benjamin Doerr, Benjamin Hebras, Yakob Kahane, Simon\n  Wietheger","title":"The First Proven Performance Guarantees for the Non-Dominated Sorting\n  Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem","comments":"Author-generated version of a paper appearing in the proceedings of\n  IJCAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DS cs.NE math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most\nprominent algorithms to solve multi-objective optimization problems. Recently,\nthe first mathematical runtime guarantees have been obtained for this\nalgorithm, however only for synthetic benchmark problems.\n  In this work, we give the first proven performance guarantees for a classic\noptimization problem, the NP-complete bi-objective minimum spanning tree\nproblem. More specifically, we show that the NSGA-II with population size $N\n\\ge 4((n-1) w_{\\max} + 1)$ computes all extremal points of the Pareto front in\nan expected number of $O(m^2 n w_{\\max} \\log(n w_{\\max}))$ iterations, where\n$n$ is the number of vertices, $m$ the number of edges, and $w_{\\max}$ is the\nmaximum edge weight in the problem instance. This result confirms, via\nmathematical means, the good performance of the NSGA-II observed empirically.\nIt also shows that mathematical analyses of this algorithm are not only\npossible for synthetic benchmark problems, but also for more complex\ncombinatorial optimization problems.\n  As a side result, we also obtain a new analysis of the performance of the\nglobal SEMO algorithm on the bi-objective minimum spanning tree problem, which\nimproves the previous best result by a factor of $|F|$, the number of extremal\npoints of the Pareto front, a set that can be as large as $n w_{\\max}$. The\nmain reason for this improvement is our observation that both multi-objective\nevolutionary algorithms find the different extremal points in parallel rather\nthan sequentially, as assumed in the previous proofs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:59:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13460","submitter":"Yiwen Huang","authors":"Yiwen Huang, Zhiqiu Yu, Xinjie Yi, Yue Wang, James Tompkin","title":"'Tax-free' 3DMM Conditional Face Generation","comments":"Accepted to the AI for Content Creation Workshop at CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  3DMM conditioned face generation has gained traction due to its well-defined\ncontrollability; however, the trade-off is lower sample quality: Previous works\nsuch as DiscoFaceGAN and 3D-FM GAN show a significant FID gap compared to the\nunconditional StyleGAN, suggesting that there is a quality tax to pay for\ncontrollability. In this paper, we challenge the assumption that quality and\ncontrollability cannot coexist. To pinpoint the previous issues, we\nmathematically formalize the problem of 3DMM conditioned face generation. Then,\nwe devise simple solutions to the problem under our proposed framework. This\nresults in a new model that effectively removes the quality tax between 3DMM\nconditioned face GANs and the unconditional StyleGAN.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:02:00 GMT"},{"version":"v2","created":"Fri, 26 May 2023 20:42:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13461","submitter":"Jean Lelis","authors":"Jean Lelis, Diego Marques, Carlos Gustavo Moreira and Pavel\n  Trojovsk\\'y","title":"A Note On Transcendental Analytic Functions With Rational Coefficients\n  Mapping $\\mathbb{Q}$ Into Itself","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT math.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this note, the main focus is on a question about transcendental entire\nfunctions mapping $\\mathbb{Q}$ into $\\mathbb{Q}$ (which is related to a\nMahler's problem). In particular, we prove that, for any $t>0$, there is no a\ntranscendental entire function $f\\in\\mathbb{Q}[[z]]$ such that\n$f(\\mathbb{Q})\\subseteq\\mathbb{Q}$ and whose denominator of $f(p/q)$ is\n$O(q^{t})$, for all rational numbers $p/q$, with $q$ sufficiently large.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:04:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13462","submitter":"Philippe Gagnon","authors":"Philippe Gagnon and Yuxi Wang","title":"Robust heavy-tailed versions of generalized linear models with\n  applications in actuarial science","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generalized linear models (GLMs) form one of the most popular classes of\nmodels in statistics. The gamma variant is used, for instance, in actuarial\nscience for the modelling of claim amount in insurance. A flaw of GLMs is that\nthey are not robust against outliers (i.e., against erroneous or extreme data\npoints). A difference in trends in the bulk of the data and the outliers thus\nyields skewed inference and prediction. Cantoni and Ronchetti (2001) proposed a\nrobust frequentist approach which is now the most commonly applied. It consists\nin an estimator which is derived from a modification of the derivative of the\nlog-likelihood. We propose an approach which is modelling-based and thus\nfundamentally different. It allows for an understanding and interpretation of\nthe modelling, and it can be applied for both frequentist and Bayesian\nstatistical analyses. We show that the approach possesses appealing theoretical\nand empirical properties. In particular, we show through a simulation study\nthat it offers an advantage in terms of estimation performance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:09:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13463","submitter":"Taeju Lee","authors":"Taeju Lee, Minkyu Je","title":"Trend Investigation of Biopotential Recording Front-End Channels for\n  Invasive and Non-Invasive Applications","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents the trend of biopotential recording front-end channels\ndeveloped from the 1970s to the 2020s while describing a basic background on\nthe front-end channel design. Only the front-end channels that conduct\nelectrical recording invasively and non-invasively are addressed. The front-end\nchannels are investigated in terms of technology node, number of channels,\nsupply voltage, noise efficiency factor, and power efficiency factor. Also,\nmulti-faceted comparisons are made to figure out the correlation between these\nfive categories. In each category, the design trend is presented over time, and\nrelated circuit techniques are discussed. While addressing the characteristics\nof circuit techniques used to improve the channel performance, what needs to be\nimproved is also suggested.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:10:56 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13464","submitter":"Cezary Adamczyk","authors":"Cezary Adamczyk, Adrian Kliks","title":"Detection and mitigation of indirect conflicts between xApps in Open\n  Radio Access Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In Open Radio Access Networks, the Conflict Mitigation component, which is\npart of the Near-RT RIC, aims to detect and resolve any conflicts between xApp\ndecisions. In this paper, we propose a universal method for detecting and\nresolving of indirect conflicts between xApps. Its efficiency is validated by\nextensive computer simulations. Our results demonstrate that, in the considered\nscenario, the mean bitrate satisfaction of users increases by 2%, while the\nnumber of radio link failures and ping-pong handovers in the network is\nsignificantly reduced.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:12:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13465","submitter":"Sergei Nechaev","authors":"Bogdan Slavov, Kirill Polovnikov, Sergei Nechaev, and Nikita Pospelov","title":"Largest eigenvalue statistics of sparse random adjacency matrices","comments":"18 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the statistics of the largest eigenvalue, $\\lambda_{\\rm max}$,\nin an ensemble of $N\\times N$ large ($N\\gg 1$) sparse adjacency matrices,\n$A_N$. The most attention is paid to the distribution and typical fluctuations\nof $\\lambda_{\\rm max}$ in the vicinity of the percolation threshold,\n$p_c=\\frac{1}{N}$. The overwhelming majority of subgraphs representing $A_N$\nnear $p_c$ are exponentially distributed linear subchains, for which the\nstatistics of the normalized largest eigenvalue can be analytically connected\nwith the Gumbel distribution. For the ensemble of {\\rm all} subgraphs near\n$p_c$ we suggest that under an appropriate modification of the normalization\nconstant the Gumbel distribution provides a reasonably good approximation.\nUsing numerical simulations we demonstrate that the proposed transformation of\n$\\lambda_{\\rm max}$ is indeed Gumbel-distributed and the leading finite-size\ncorrections in the vicinity of $p_c$ scale with $N$ as $\\sim \\ln^{-2}N$. All\ntogether, our results reveal a previously unknown universality in eigenvalue\nstatistics of sparse matrices close to the percolation threshold.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:13:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13466","submitter":"Jakub Rysz","authors":"Agnieszka I. Paw{\\l}owska, Pawe{\\l} D\\k{a}bczy\\'nski, Sebastian Lalik,\n  Juan Pablo Carbajal, Dante R. Chialvo, Jakub Rysz","title":"Dynamically altered conductance in an Organic Thin Film Memristive\n  Device","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The memristive device is one of the basic elements of novel, brain-inspired,\nfast, and energy-efficient information processing systems in which there is no\nseparation between memorization and information analysis functions. Since the\nfirst demonstration of the resistive switching effect, several types of\nmemristive devices have been developed. In most of them, the memristive effect\noriginates from direct modification of the conducting area, e.g. conducting\nfilament formation/disintegration, or semiconductor doping/dedoping. Here, we\nreport a solution-processed lateral memristive device based on a new\nconductivity modulation mechanism. The device architecture resembles that of an\norganic field-effect transistor in which the top gate electrode is replaced\nwith an additional insulator layer containing mobile ions. Alteration of the\nion distribution under the influence of applied potential changes the electric\nfield, modifying the conductivity of the semiconductor channel. The devices\nexhibit highly stable current-voltage hysteresis loops and Short-Term\nPlasticity (STP). We also demonstrate short-term synaptic plasticity with\ntunable time constants.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:19:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13467","submitter":"Yiwei Lyu","authors":"Yiwei Lyu, Wenhao Luo and John M. Dolan","title":"Risk-aware Safe Control for Decentralized Multi-agent Systems via\n  Dynamic Responsibility Allocation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decentralized control schemes are increasingly favored in various domains\nthat involve multi-agent systems due to the need for computational efficiency\nas well as general applicability to large-scale systems. However, in the\nabsence of an explicit global coordinator, it is hard for distributed agents to\ndetermine how to efficiently interact with others. In this paper, we present a\nrisk-aware decentralized control framework that provides guidance on how much\nrelative responsibility share (a percentage) an individual agent should take to\navoid collisions with others while moving efficiently without direct\ncommunications. We propose a novel Control Barrier Function (CBF)-inspired risk\nmeasurement to characterize the aggregate risk agents face from potential\ncollisions under motion uncertainty. We use this measurement to allocate\nresponsibility shares among agents dynamically and develop risk-aware\ndecentralized safe controllers. In this way, we are able to leverage the\nflexibility of robots with lower risk to improve the motion flexibility for\nthose with higher risk, thus achieving improved collective safety. We\ndemonstrate the validity and efficiency of our proposed approach through two\nexamples: ramp merging in autonomous driving and a multi-agent\nposition-swapping game.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:21:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13468","submitter":"Jos\\'e Domingo Vela Arba\\~nil","authors":"Jos\\'e D. V. Arba\\~nil, Cesar V. Flores, C\\'esar H. Lenzi, and Juan M.\n  Z. Pretel","title":"Fluid pulsation modes and tidal deformability of anisotropic strange\n  stars in light of the GW$170817$ event","comments":"To appear in PRD","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR gr-qc nucl-th","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The effects of the anisotropy on the fluid pulsation modes adopting the\nso-called Cowling approximation and tidal deformability of strange quark stars\nare investigated by using the numerical integration of the hydrostatic\nequilibrium, nonradial oscillations, and tidal deformability equations, being\nthese equations modified from their standard form to include the anisotropic\neffects. The fluid matter inside the compact stars is described by the MIT bag\nmodel equation of state. For the anisotropy profile, we consider a local\nanisotropy that is both regular at the center and null at the star's surface.\nWe find that the effect of the anisotropy is reflected in the fluid pulsation\nmodes and tidal deformability. Finally, we analyze the correlation between the\ntidal deformability of the GW$170817$ event with the anisotropy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:27:49 GMT"},{"version":"v2","created":"Fri, 26 May 2023 11:54:08 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13469","submitter":"Saurabh Srivastava","authors":"Saurabh Srivastava, Gaurav Singh, Shou Matsumoto, Ali Raz, Paulo\n  Costa, Joshua Poore, Ziyu Yao","title":"MAILEX: Email Event and Argument Extraction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we present the first dataset, \\dataset, for performing event\nextraction from conversational email threads. To this end, we first proposed a\nnew taxonomy covering 10 event types and 76 arguments in the email domain. Our\nfinal dataset includes $\\sim$4K emails annotated with $\\sim$9K event instances.\nTo understand the task challenges, we conducted a series of experiments\ncomparing two commonly-seen lines of approaches for event extraction, i.e.,\nsequence labeling and generative end-to-end extraction (including few-shot\nGPT-3.5). Our results showed that the task of email event extraction is far\nfrom being addressed, due to challenges lying in, e.g., extracting\nnon-continuous, shared trigger spans, extracting non-named entity arguments,\nand modeling the email conversational history. Our work thus suggests more\ninvestigations in this domain-specific event extraction task in the\nfuture.\\footnote{The source code and dataset can be obtained from\n\\url{https://github.com/salokr/Email-Event-Extraction}.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:28:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13470","submitter":"Ismaila Ba","authors":"Jean-Fran\\c{c}ois Coeurjolly, Isma\\\"ila Ba, Achmad Choiruddin","title":"Regularization techniques for inhomogeneous (spatial) point processes\n  intensity and conditional intensity estimation","comments":"19 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Point processes are stochastic models generating interacting points or events\nin time, space, etc. Among characteristics of these models, first-order\nintensity and conditional intensity functions are often considered. We focus on\ninhomogeneous parametric forms of these functions assumed to depend on a\ncertain number of spatial covariates. When this number of covariates is large,\nwe are faced with a high-dimensional problem. This paper provides an overview\nof these questions and existing solutions based on regularizations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:29:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13471","submitter":"Hossein Taheri","authors":"Hossein Taheri, Christos Thrampoulidis","title":"Fast Convergence in Learning Two-Layer Neural Networks with Separable\n  Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Normalized gradient descent has shown substantial success in speeding up the\nconvergence of exponentially-tailed loss functions (which includes exponential\nand logistic losses) on linear classifiers with separable data. In this paper,\nwe go beyond linear models by studying normalized GD on two-layer neural nets.\nWe prove for exponentially-tailed losses that using normalized GD leads to\nlinear rate of convergence of the training loss to the global optimum. This is\nmade possible by showing certain gradient self-boundedness conditions and a\nlog-Lipschitzness property. We also study generalization of normalized GD for\nconvex objectives via an algorithmic-stability analysis. In particular, we show\nthat normalized GD does not overfit during training by establishing finite-time\ngeneralization bounds.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:30:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13472","submitter":"Francesco Marchetti","authors":"Francesco Marchetti, Sabrina Guastavino, Cristina Campi, Federico\n  Benvenuto, Michele Piana","title":"A comprehensive theoretical framework for the optimization of neural\n  networks classification performance with respect to weighted metrics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.NA math.NA stat.ML","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In many contexts, customized and weighted classification scores are designed\nin order to evaluate the goodness of the predictions carried out by neural\nnetworks. However, there exists a discrepancy between the maximization of such\nscores and the minimization of the loss function in the training phase. In this\npaper, we provide a complete theoretical setting that formalizes weighted\nclassification metrics and then allows the construction of losses that drive\nthe model to optimize these metrics of interest. After a detailed theoretical\nanalysis, we show that our framework includes as particular instances\nwell-established approaches such as classical cost-sensitive learning, weighted\ncross entropy loss functions and value-weighted skill scores.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:33:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13473","submitter":"Volodymyr Koverga","authors":"Volodymyr Koverga and Anh T. Ngo","title":"The local structure organization and dynamics in lithium borate ionic\n  liquids using molecular dynamics simulation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph cond-mat.other","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite significant progress in the development of lithium-ion batteries, the\nmajority still rely on electrolytes based on organic solvents. However,\nsingle-ion conducting electrolytes offer a promising alternative by mitigating\noverpotential at the electrode and, thus, increasing the device's lifespan. In\na recent study, Guzman-Gonzalez et al. (Adv. Energy Mater., 2022, 2202974)\npresented a novel approach to designing a new class of lithium ionic liquids,\nbased on tetracoordinated boron atom with oligoethylene glycol groups and\ndifferent fluorinated electron-withdrawing groups. To gain insights into the\nstructural and dynamic aspects underlying the high ionic conductivity of these\nelectrolytes, molecular dynamics simulations were employed. Our results\nestablish a relationship between the variation in ionic conductivity and the\nextent of uncorrelated motion among the counterions. This phenomenon was\nexplained by differences in the rate of ion coordination dynamics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:34:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13474","submitter":"Peter Sternberg","authors":"\\'Etienne Sandier and Peter Sternberg","title":"Allen-Cahn Solutions with Triple Junction Structure at Infinity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct an entire solution $U:\\mathbb{R}^2\\to\\mathbb{R}^2$ to the\nelliptic system \\[ \\Delta U=\\nabla_uW(U), \\] where $W:\\mathbb{R}^2\\to\n[0,\\infty)$ is a `triple-well' potential. This solution is a local minimizer of\nthe associated energy \\[ \\int \\frac{1}{2}|\\nabla U|^2+W(U)\\,dx \\] in the sense\nthat $U$ minimizes the energy on any compact set among competitors agreeing\nwith $U$ outside that set. Furthermore, we show that along subsequences, the\n`blowdowns' of $U$ given by $U_R(x):=U(Rx)$ approach a minimal triple junction\nas $R\\to\\infty$. Previous results had assumed various levels of symmetry for\nthe potential and had not established local minimality, but here we make no\nsuch symmetry assumptions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:39:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13475","submitter":"Sandro Vaienti","authors":"F. Lillo, G. Livieri, S. Marmi, A. Solomko, S. Vaienti","title":"Unimodal maps perturbed by heteroscedastic noise: an application to a\n  financial systems","comments":"31 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS math.PR nlin.CD q-fin.MF","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate and prove the mathematical properties of a general class of\none-dimensional unimodal smooth maps perturbed with a heteroscedastic noise.\nSpecifically, we investigate the stability of the associated Markov chain, show\nthe weak convergence of the unique stationary measure to the invariant measure\nof the map, and show that the average Lyapunov exponent depends continuously on\nthe Markov chain parameters. Representing the Markov chain in terms of random\ntransformation enables us to state and prove the Central Limit Theorem, the\nlarge deviation principle, and the Berry-Ess\\`een inequality. We perform a\nmultifractal analysis for the invariant and the stationary measures, and we\nprove Gumbel's law for the Markov chain with an extreme index equal to 1. In\naddition, we present an example linked to the financial concept of systemic\nrisk and leverage cycle, and we use the model to investigate the finite sample\nproperties of our asymptotic results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:39:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13476","submitter":"Sara Hosseinirad","authors":"Sara Hosseinirad, Alireza Alian Porzani, Giulio Salizzoni, Maryam\n  Kamgarpour","title":"General-Sum Finite-Horizon Potential Linear-Quadratic Games with a\n  Convergent Policy","comments":"Submitted to CDC Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper explores the potential game properties of the non-cooperative\nfinite-horizon general-sum Linear Quadratic (LQ) game. We show that a general\nLQ game is potential if and only if it is an identical interest game. Based on\nthis result, we restrict the class of LQ games to those with decoupled agent\ndynamics and information structure. For this restricted subset, we derive\nconditions under which the game is potential. Furthermore, for the identified\nsubset, we prove the convergence of policy gradient to a Nash equilibrium.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:41:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13477","submitter":"Nan Xu","authors":"Nan Xu, Chunting Zhou, Asli Celikyilmaz, Xuezhe Ma","title":"Look-back Decoding for Open-Ended Text Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Given a prefix (context), open-ended generation aims to decode texts that are\ncoherent, which don't abruptly drift from previous topics, and informative,\nwhich don't suffer from undesired repetitions. In this paper, we propose\nLook-back, an improved decoding algorithm that leverages the Kullback-Leibler\ndivergence to track the distribution distance between current and historical\ndecoding steps. Thus Look-back can automatically predict potential repetitive\nphrase and topic drift, and remove tokens that may cause the failure modes,\nrestricting the next token probability distribution within a plausible distance\nto the history. We perform decoding experiments on document continuation and\nstory generation, and demonstrate that Look-back is able to generate more\nfluent and coherent text, outperforming other strong decoding methods\nsignificantly in both automatic and human evaluations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:42:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13478","submitter":"Joseph Marvin Imperial","authors":"Joseph Marvin Imperial, Ekaterina Kochmar","title":"Automatic Readability Assessment for Closely Related Languages","comments":"Camera-ready version for ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In recent years, the main focus of research on automatic readability\nassessment (ARA) has shifted towards using expensive deep learning-based\nmethods with the primary goal of increasing models' accuracy. This, however, is\nrarely applicable for low-resource languages where traditional handcrafted\nfeatures are still widely used due to the lack of existing NLP tools to extract\ndeeper linguistic representations. In this work, we take a step back from the\ntechnical component and focus on how linguistic aspects such as mutual\nintelligibility or degree of language relatedness can improve ARA in a\nlow-resource setting. We collect short stories written in three languages in\nthe Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment\nmodels and explore the interaction of data and features in various\ncross-lingual setups. Our results show that the inclusion of CrossNGO, a novel\nspecialized feature exploiting n-gram overlap applied to languages with high\nmutual intelligibility, significantly improves the performance of ARA models\ncompared to the use of off-the-shelf large multilingual language models alone.\nConsequently, when both linguistic representations are combined, we achieve\nstate-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA\nin Bikol.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:42:53 GMT"},{"version":"v2","created":"Thu, 25 May 2023 10:41:50 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13479","submitter":"Siva Kesava Reddy Kakarla","authors":"Behnaz Arzani, Siva Kesava Reddy Kakarla, Miguel Castro, Srikanth\n  Kandula, Saeed Maleki, Luke Marshall","title":"Rethinking Machine Learning Collective Communication as a\n  Multi-Commodity Flow Problem","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show communication schedulers' recent work proposed for ML collectives\ndoes not scale to the increasing problem sizes that arise from training larger\nmodels. These works also often produce suboptimal schedules. We make a\nconnection with similar problems in traffic engineering and propose a new\nmethod, TECCL, that finds better quality schedules (e.g., finishes collectives\nfaster and/or while sending fewer bytes) and does so more quickly on larger\ntopologies. We present results on many different GPU topologies that show\nsubstantial improvement over the state-of-the-art.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:42:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13480","submitter":"Mina Aganagic","authors":"Mina Aganagic, Elise LePage and Miroslav Rapcak","title":"Homological Link Invariants from Floer Theory","comments":"146 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th math.AG math.QA math.RT math.SG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is a generalization of Heegaard-Floer theory from\n${\\mathfrak{gl}}_{1|1}$ to other Lie (super)algebras $^L{\\mathfrak{g}}$. The\ncorresponding category of A-branes is solvable explicitly and categorifies\nquantum $U_q(^L{\\mathfrak{g}})$ link invariants. The theory was discovered in\n\\cite{A1,A2}, using homological mirror symmetry. It has novel features,\nincluding equivariance and, if $^L{\\mathfrak{g}} \\neq {\\mathfrak{gl}}_{1|1}$,\ncoefficients in categories. In this paper, we describe the theory and how it is\nsolved in detail in the two simplest cases: the ${\\mathfrak{gl}}_{1|1}$ theory\nitself, categorifying the Alexander polynomial, and the ${\\mathfrak{su}}_{2}$\ntheory, categorifying the Jones polynomial. Our approach to solving the theory\nis new, even in the familiar ${\\mathfrak{gl}}_{1|1}$ case.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:44:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13481","submitter":"Ra\\'ul Alvarez-Pati\\v{n}o","authors":"Ra\\'ul Alvarez-Pati\\~no","title":"A homotopy classification of $\\mathrm{Spin}(7)$-structures with\n  applications to exceptional Riemannian holonomy","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We use classical obstruction theory \\`{a} la Eilenberg-Steenrod to obtain a\nhomotopy classification of $\\mathrm{Spin}(7)$-structures on compact\n$8$-manifolds with abelian fundamental group. As an application, we show that a\ncompact, connected Riemannian $8$-manifold with holonomy contained inside the\ngroup $\\mathrm{Spin}(7)$ has exactly two $\\mathrm{Spin}(7)$-structures\nextending the induced $G_{2}$-structure on the boundary.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:47:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13482","submitter":"Janusz Adamus","authors":"Janusz Adamus","title":"Globally subanalytic arc-symmetric sets","comments":"v2: Minor corrections in the proof of Thm.3.1","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that a globally subanalytic set can be realized as the image of a\nsemianalytic set by a finite composite of global blowings-up. As an\napplication, we prove that a globally subanalytic arc-symmetric set of pure\ndimension is the image under such a composite of a real analytic manifold of\nthe same dimension, and derive basic geometric properties of the class of\nglobally subanalytic arc-symmetric sets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:47:21 GMT"},{"version":"v2","created":"Sun, 28 May 2023 16:40:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13483","submitter":"Qingkai Shi","authors":"Qingkai Shi and Xiangzhe Xu and Xiangyu Zhang","title":"Extracting Protocol Format as State Machine via Controlled Static Loop\n  Analysis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.PL cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Reverse engineering of protocol message formats is critical for many security\napplications. Mainstream techniques use dynamic analysis and inherit its\nlow-coverage problem -- the inferred message formats only reflect the features\nof their inputs. To achieve high coverage, we choose to use static analysis to\ninfer message formats from the implementation of protocol parsers. In this\nwork, we focus on a class of extremely challenging protocols whose formats are\ndescribed via constraint-enhanced regular expressions and parsed using\nfinite-state machines. Such state machines are often implemented as complicated\nparsing loops, which are inherently difficult to analyze via conventional\nstatic analysis. Our new technique extracts a state machine by regarding each\nloop iteration as a state and the dependency between loop iterations as state\ntransitions. To achieve high, i.e., path-sensitive, precision but avoid path\nexplosion, the analysis is controlled to merge as many paths as possible based\non carefully-designed rules. The evaluation results show that we can infer a\nstate machine and, thus, the message formats, in five minutes with over 90%\nprecision and recall, far better than state of the art. We also applied the\nstate machines to enhance protocol fuzzers, which are improved by 20% to 230%\nin terms of coverage and detect ten more zero-days compared to baselines.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:58:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13484","submitter":"Jinghan Yao","authors":"Jinghan Yao, Nawras Alnaasan, Tian Chen, Aamir Shafi, Hari Subramoni,\n  Dhabaleswar K. (DK) Panda","title":"Flover: A Temporal Fusion Framework for Efficient Autoregressive Model\n  Parallel Inference","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.AI cs.CL cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the rapidly evolving field of deep learning, the performance of model\ninference has become a pivotal aspect as models become more complex and are\ndeployed in diverse applications. Among these, autoregressive models stand out\ndue to their state-of-the-art performance in numerous generative tasks. These\nmodels, by design, harness a temporal dependency structure, where the current\ntoken's probability distribution is conditioned on preceding tokens. This\ninherently sequential characteristic, however, adheres to the Markov Chain\nassumption and lacks temporal parallelism, which poses unique challenges.\nParticularly in industrial contexts where inference requests, following a\nPoisson time distribution, necessitate diverse response lengths, this absence\nof parallelism is more profound. Existing solutions, such as dynamic batching\nand concurrent model instances, nevertheless, come with severe overheads and a\nlack of flexibility, these coarse-grained methods fall short of achieving\noptimal latency and throughput. To address these shortcomings, we propose\nFlavor -- a temporal fusion framework for efficient inference in autoregressive\nmodels, eliminating the need for heuristic settings and applies to a wide range\nof inference scenarios. By providing more fine-grained parallelism on the\ntemporality of requests and employing an efficient memory shuffle algorithm,\nFlover achieves up to 11x faster inference on GPT models compared to the\ncutting-edge solutions provided by NVIDIA Triton FasterTransformer. Crucially,\nby leveraging the advanced tensor parallel technique, Flover proves efficacious\nacross diverse computational landscapes, from single-GPU setups to multi-node\nscenarios, thereby offering robust performance optimization that transcends\nhardware boundaries.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:58:09 GMT"},{"version":"v2","created":"Wed, 24 May 2023 17:43:53 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13485","submitter":"Donald Martin Jr.","authors":"Jill A. Kuhlberg (1), Irene Headen (2), Ellis A. Ballard (3), Donald\n  Martin Jr., (4) ((1) System Stars LLC, (2) Drexel University, (3) Washington\n  University in St. Louis, (4) Google)","title":"Advancing Community Engaged Approaches to Identifying Structural Drivers\n  of Racial Bias in Health Diagnostic Algorithms","comments":"2020 International System Dynamics Conference, Honorable Mention\n  Award, 28 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Much attention and concern has been raised recently about bias and the use of\nmachine learning algorithms in healthcare, especially as it relates to\nperpetuating racial discrimination and health disparities. Following an initial\nsystem dynamics workshop at the Data for Black Lives II conference hosted at\nMIT in January of 2019, a group of conference participants interested in\nbuilding capabilities to use system dynamics to understand complex societal\nissues convened monthly to explore issues related to racial bias in AI and\nimplications for health disparities through qualitative and simulation\nmodeling. In this paper we present results and insights from the modeling\nprocess and highlight the importance of centering the discussion of data and\nhealthcare on people and their experiences with healthcare and science, and\nrecognizing the societal context where the algorithm is operating. Collective\nmemory of community trauma, through deaths attributed to poor healthcare, and\nnegative experiences with healthcare are endogenous drivers of seeking\ntreatment and experiencing effective care, which impact the availability and\nquality of data for algorithms. These drivers have drastically disparate\ninitial conditions for different racial groups and point to limited impact of\nfocusing solely on improving diagnostic algorithms for achieving better health\noutcomes for some groups.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:58:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13486","submitter":"Pengyu Nie","authors":"Yu Liu, Zachary Thurston, Alan Han, Pengyu Nie, Milos Gligoric,\n  Owolabi Legunsen","title":"pytest-inline: An Inline Testing Tool for Python","comments":"Accepted as a tool demo paper at ICSE DEMO 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present pytest-inline, the first inline testing framework for Python. We\nrecently proposed inline tests to make it easier to test individual program\nstatements. But, there is no framework-level support for developers to write\ninline tests in Python. To fill this gap, we design and implement pytest-inline\nas a plugin for pytest, the most popular Python testing framework. Using\npytest-inline, a developer can write an inline test by assigning test inputs to\nvariables in a target statement and specifying the expected test output. Then,\npytest-inline runs each inline test and fails if the target statement's output\ndoes not match the expected output. In this paper, we describe our design of\npytest-inline, the testing features that it provides, and the intended use\ncases. Our evaluation on inline tests that we wrote for 80 target statements\nfrom 31 open-source Python projects shows that using pytest-inline incurs\nnegligible overhead, at 0.012x. pytest-inline is integrated into the pytest-dev\norganization, and a video demo is at\nhttps://www.youtube.com/watch?v=pZgiAxR_uJg.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:58:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13487","submitter":"Lianjun Li","authors":"Lianjun Li, Sai Sree Rayala, Jiarui Xu, Lizhong Zheng, Lingjia Liu","title":"Learning to Estimate: A Real-Time Online Learning Framework for\n  MIMO-OFDM Channel Estimation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we introduce StructNet-CE, a novel real-time online learning\nframework for MIMO-OFDM channel estimation, which only utilizes over-the-air\n(OTA) pilot symbols for online training and converges within one OFDM subframe.\nThe design of StructNet-CE leverages the structure information in the MIMO-OFDM\nsystem, including the repetitive structure of modulation constellation and the\ninvariant property of symbol classification to inter-stream interference. The\nembedded structure information enables StructNet-CE to conduct channel\nestimation with a binary classification task and accurately learn channel\ncoefficients with as few as two pilot OFDM symbols. Experiments show that the\nchannel estimation performance is significantly improved with the incorporation\nof structure knowledge. StructNet-CE is compatible and readily applicable to\ncurrent and future wireless networks, demonstrating the effectiveness and\nimportance of combining machine learning techniques with domain knowledge for\nwireless communication systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:00:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13488","submitter":"Charles Driscoll","authors":"Charles F. Driscoll","title":"The Electric Fields and \"Lightning Jets\" of the Sun and Solar Wind","comments":"24 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A model of electric energization of the Solar Wind and Corona is developed,\nincluding electro-magnetic (EM) particle effects precluded by traditional\nmagneto-hydro (MHD) assumptions. Using standard 1-D radial Solar models for\nparticle density and temperature, the Core gravito-electric field is\ncalculated; and the range of possible Photospheric photoelectric fields is\nestimated. These DC fields plausibly arise from about 500.Coulombs of charge\ndisplacement, mainly caused by the immense Solar energy flux pushing electrons\noutward. Energetically, these electric fields can accelerate surface protons\nout of the 2.keV gravity well and up to the 4. keV energies observed in the\nFast Solar Wind. The electrical energy is released in pervasive, persistent\n\"proton lightning jets\", which are proton beams, charge-neutralized by\nco-propagating electrons. The jets are formed by pinched \"avalanche breakdown\"\nof resistivity, probably initiated on the down-welling edges of Solar surface\ngranulations. These energetic jets will glow as discrete filamentary surface\nspicules, and will be observed in reflect solar light as the diffuse K-Corona.\nSignificantly, the electric model exposes a new \"virial limit\": the observed\nFast Wind speed occurs when the (positive) electrical potential energy at r=0\nis as large as the 10.keV gravitational well at r=0.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:10:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13489","submitter":"Himanshi Sharma","authors":"H. Sharma, M. M. Hedman, S. Vahidinia","title":"New Insights into Variations in Enceladus Plume Particle Launch\n  Velocities from Cassini-VIMS spectral data","comments":"13 pages, 8 figures, accepted for publication in PSJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Enceladus' plume consists mainly of a mixture of water vapor and solid ice\nparticles that may originate from a subsurface ocean. The physical processes\nunderlying Enceladus' plume particle dynamics are still being debated, and\nquantifying the particles' size distribution and launch velocities can help\nconstrain these processes. Cassini's Visual and Infrared Mapping Spectrometer\n(VIMS) observed the Enceladus plume over a wavelength range of 0.9 micron to\n5.0 microns for a significant fraction of Enceladus' orbital period on three\ndates in the summer of 2017. We find that the relative brightness of the plume\non these different dates varies with wavelength, implying that the particle\nsize distribution in the plume changes over time. These observations also\nenable us to study how the particles' launch velocities vary with time and\nobserved wavelength. We find that the typical launch velocity of particles\nremains between 140 m/s and 148 m/s at wavelengths between 1.2 microns and 3.7\nmicrons. This may not be consistent with prior models where particles are only\naccelerated by interactions with the vent walls and gas, and could imply that\nmutual particle collisions close to the vent are more important than previously\nrecognized.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:14:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13490","submitter":"Vardhan Jai","authors":"Jai Vardhan, Kothapalli Sai Swetha","title":"Detection of healthy and diseased crops in drone captured images using\n  Deep Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Monitoring plant health is crucial for maintaining agricultural productivity\nand food safety. Disruptions in the plant's normal state, caused by diseases,\noften interfere with essential plant activities, and timely detection of these\ndiseases can significantly mitigate crop loss. In this study, we propose a deep\nlearning-based approach for efficient detection of plant diseases using\ndrone-captured imagery. A comprehensive database of various plant species,\nexhibiting numerous diseases, was compiled from the Internet and utilized as\nthe training and test dataset. A Convolutional Neural Network (CNN), renowned\nfor its performance in image classification tasks, was employed as our primary\npredictive model. The CNN model, trained on this rich dataset, demonstrated\nsuperior proficiency in crop disease categorization and detection, even under\nchallenging imaging conditions. For field implementation, we deployed a\nprototype drone model equipped with a high-resolution camera for live\nmonitoring of extensive agricultural fields. The captured images served as the\ninput for our trained model, enabling real-time identification of healthy and\ndiseased plants. Our approach promises an efficient and scalable solution for\nimproving crop health monitoring systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:15:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13491","submitter":"Andersen Chang","authors":"Andersen Chang and Lili Zheng and Gautam Dasarthy and Genevera I.\n  Allen","title":"Nonparanormal Graph Quilting with Applications to Calcium Imaging","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Probabilistic graphical models have become an important unsupervised learning\ntool for detecting network structures for a variety of problems, including the\nestimation of functional neuronal connectivity from two-photon calcium imaging\ndata. However, in the context of calcium imaging, technological limitations\nonly allow for partially overlapping layers of neurons in a brain region of\ninterest to be jointly recorded. In this case, graph estimation for the full\ndata requires inference for edge selection when many pairs of neurons have no\nsimultaneous observations. This leads to the Graph Quilting problem, which\nseeks to estimate a graph in the presence of block-missingness in the empirical\ncovariance matrix. Solutions for the Graph Quilting problem have previously\nbeen studied for Gaussian graphical models; however, neural activity data from\ncalcium imaging are often non-Gaussian, thereby requiring a more flexible\nmodeling approach. Thus, in our work, we study two approaches for nonparanormal\nGraph Quilting based on the Gaussian copula graphical model, namely a maximum\nlikelihood procedure and a low-rank based framework. We provide theoretical\nguarantees on edge recovery for the former approach under similar conditions to\nthose previously developed for the Gaussian setting, and we investigate the\nempirical performance of both methods using simulations as well as real data\ncalcium imaging data. Our approaches yield more scientifically meaningful\nfunctional connectivity estimates compared to existing Gaussian graph quilting\nmethods for this calcium imaging data set.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:16:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13492","submitter":"Veit Elser","authors":"Veit Elser","title":"How densely can spheres be packed with moderate effort in high\n  dimensions?","comments":"10 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We generate non-lattice packings of spheres in up to 22 dimensions using the\ngeometrical constraint satisfaction algorithm RRR. Our results suggest that it\nis easy to double the density of Ball's lower bound, and more tentatively, that\nthe decay rate of the density can be improved exponentially.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:19:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13493","submitter":"Nunzio Alexandro Letizia Mr","authors":"Nunzio A. Letizia, Andrea M. Tonello, H. Vincent Poor","title":"Cooperative Channel Capacity Learning","comments":"5 pages, 6 figures, submitted to IEEE","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this paper, the problem of determining the capacity of a communication\nchannel is formulated as a cooperative game, between a generator and a\ndiscriminator, that is solved via deep learning techniques. The task of the\ngenerator is to produce channel input samples for which the discriminator\nideally distinguishes conditional from unconditional channel output samples.\nThe learning approach, referred to as cooperative channel capacity learning\n(CORTICAL), provides both the optimal input signal distribution and the channel\ncapacity estimate. Numerical results demonstrate that the proposed framework\nlearns the capacity-achieving input distribution under challenging non-Shannon\nsettings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:22:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13494","submitter":"Hafiz Rauf","authors":"Hafiz Tayyab Rauf, Norman W. Paton and Andre Freitas","title":"Deep Clustering for Data Cleaning and Integration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deep Learning (DL) techniques now constitute the state-of-the-art for\nimportant problems in areas such as text and image processing, and there have\nbeen impactful results that deploy DL in several data management tasks. Deep\nClustering (DC) has recently emerged as a sub-discipline of DL, in which data\nrepresentations are learned in tandem with clustering, with a view to\nautomatically identifying the features of the data that lead to improved\nclustering results. While DC has been used to good effect in several domains,\nparticularly in image processing, the impact of DC on mainstream data\nmanagement tasks still remains unexplored. In this paper, we address this gap,\nby investigating the impact of DC in canonical data cleaning and integration\ntasks, including schema inference, entity resolution and domain discovery,\ntasks which represent clustering form the perspective of tables, rows and\ncolumns, respectively. In this setting, we compare and contrast several DC and\nnon-DC clustering algorithms using standard benchmarks. The results show, among\nother things, that the most effective DC algorithms consistently outperform\nnon-DC clustering algorithms for data integration tasks. However, we also\nobserved that the chosen embedding approaches for rows, columns, and tables\nsignificantly impacted the clustering performance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:25:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13495","submitter":"Pha Nguyen","authors":"Pha Nguyen, Kha Gia Quach, Kris Kitani, Khoa Luu","title":"Type-to-Track: Retrieve Any Object via Prompt-based Tracking","comments":"22 pages, 8 tables, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the recent trends in vision problems is to use natural language\ncaptions to describe the objects of interest. This approach can overcome some\nlimitations of traditional methods that rely on bounding boxes or category\nannotations. This paper introduces a novel paradigm for Multiple Object\nTracking called Type-to-Track, which allows users to track objects in videos by\ntyping natural language descriptions. We present a new dataset for that\nGrounded Multiple Object Tracking task, called GroOT, that contains videos with\nvarious types of objects and their corresponding textual captions describing\ntheir appearance and action in detail. Additionally, we introduce two new\nevaluation protocols and formulate evaluation metrics specifically for this\ntask. We develop a new efficient method that models a transformer-based\neMbed-ENcoDE-extRact framework (MENDER) using the third-order tensor\ndecomposition. The experiments in five scenarios show that our MENDER approach\noutperforms another two-stage design in terms of accuracy and efficiency, up to\n14.7% accuracy and 4$\\times$ speed faster.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:25:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13496","submitter":"Bozidar Jovanovic","authors":"Bozidar Jovanovic","title":"Affine Geometry and Relativity","comments":"22 pages, 10 figures, to appear in Foundations of Physics","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the basic concepts of space and time, the Galilean and\npseudo-Euclidean geometry. We use an elementary geometric framework of affine\nspaces and groups of affine transformations to illustrate the natural\nrelationship between classical mechanics and theory of relativity, which is\nquite often hidden, despite its fundamental importance. We have emphasized a\npassage from the group of Galilean motions to the group of Poincar\\'e\ntransformations of a plane. In particular, a 1-parametric family of natural\ndeformations of the Poincar\\'e group is described. We also visualized the\nunderlying groups of Galilean, Euclidean, and pseudo-Euclidean rotations within\nthe special linear group.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:27:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13497","submitter":"Laura Di Gesu","authors":"Laura Di Gesu, Herman L. Marshall, Steven R. Ehlert, Dawoon E. Kim,\n  Immacolata Donnarumma, Fabrizio Tavecchio, Ioannis Liodakis, Sebastian\n  Kiehlmann, Iv\\'an Agudo, Svetlana G. Jorstad, Fabio Muleri, Alan P. Marscher,\n  Simonetta Puccetti, Riccardo Middei, Matteo Perri, Luigi Pacciani, Michela\n  Negro, Roger W. Romani, Alessandro Di Marco, Dmitry Blinov, Ioakeim G.\n  Bourbah, Evangelos Kontopodis, Nikos Mandarakas, Stylianos Romanopoulos,\n  Raphael Skalidis, Anna Vervelaki, Carolina Casadio, Juan Escudero, Ioannis\n  Myserlis, Mark Gurwell, Ramprasad Rao, Garrett Keating, Pouya M. Kouch, Elina\n  Lindfors, Francisco Jos\\`e Aceituno, Maria I. Bernardos, Giacomo Bonnoli,\n  V\\`ictor Casanova, Maya Garc\\`ia-Comas, Beatriz Ag\\`is-Gonz\\`alez, C\\`esar\n  Husillos, Alessandro Marchini, Alfredo Sota, Ryo Imazawa, Mahito Sasada,\n  Yasushi Fukazawa, Koji S. Kawabata, Makoto Uemura, Tsunefumi Mizuno, Tatsuya\n  Nakaoka, Hiroshi Akitaya, Sergey S. Savchenko, Andrey A. Vasilyev, Jos\\`e L.\n  G\\`omez, Lucio A. Antonelli, Thibault Barnouin, Raffaella Bonino, Elisabetta\n  Cavazzuti, Luigi Costamante, Chien-Ting Chen, Nicol\\`o Cibrario, Alessandra\n  De Rosa, Federico Di Pierro, Manel Errando, Philip Kaaret, Vladimir Karas,\n  Henric Krawczynski, Lindsey Lisalda, Grzegorz Madejski, Christian Malacaria,\n  Fr\\'ed\\'eric Marin, Andrea Marinucci, Francesco Massaro, Giorgio Matt,\n  Ikuyuki Mitsuishi, Stephen L. O'Dell, Alessandro Paggi, Abel L. Peirson,\n  Pierre-Olivier Petrucci, Brian D. Ramsey, Allyn F. Tennant, Kinwah Wu, Matteo\n  Bachetti, Luca Baldini, Wayne H. Baumgartner, Ronaldo Bellazzini, Stefano\n  Bianchi, Stephen D. Bongiorno, Alessandro Brez, Niccol\\`o Bucciantini, Fiamma\n  Capitanio, Simone Castellano, Stefano Ciprini, Enrico Costa, Ettore Del\n  Monte, Niccol\\`o Di Lalla, Victor Doroshenko, Michal Dov\\v{c}iak, Teruaki\n  Enoto, Yuri Evangelista, Sergio Fabiani, Riccardo Ferrazzoli, Javier A.\n  Garcia, Shuichi Gunji, Kiyoshi Hayashida, Jeremy Heyl, Wataru Iwakiri, Fabian\n  Kislat, Takao Kitaguchi, Jeffery J. Kolodziejczak, Fabio La Monaca, Luca\n  Latronico, Simone Maldera, Alberto Manfreda, C.-Y. Ng, Nicola Omodei, Chiara\n  Oppedisano, Alessandro Papitto, George G. Pavlov, Melissa Pesce-Rollins,\n  Maura Pilia, Andrea Possenti, Juri Poutanen, John Rankin, Ajay Ratheesh,\n  Oliver J. Roberts, Carmelo Sgr\\`o, Patrick Slane, Paolo Soffitta, Gloria\n  Spandre, Douglas A. Swartz, Toru Tamagawa, Roberto Taverna, Yuzuru Tawara,\n  Nicholas E. Thomas, Francesco Tombesi, Alessio Trois, Sergey S. Tsygankov,\n  Roberto Turolla, Jacco Vink, Martin C. Weisskopf, Fei Xie, Silvia Zane","title":"Discovery of X-ray polarization angle rotation in active galaxy Mrk 421","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The magnetic field conditions in astrophysical relativistic jets can be\nprobed by multiwavelength polarimetry, which has been recently extended to\nX-rays. For example, one can track how the magnetic field changes in the flow\nof the radiating particles by observing rotations of the electric vector\nposition angle $\\Psi$. Here we report the discovery of a $\\Psi_{\\mathrm x}$\nrotation in the X-ray band in the blazar Mrk 421 at an average flux state.\nAcross the 5 days of Imaging X-ray Polarimetry Explorer (IXPE) observations of\n4-6 and 7-9 June 2022, $\\Psi_{\\mathrm x}$ rotated in total by $\\geq360^\\circ$.\nOver the two respective date ranges, we find constant, within uncertainties,\nrotation rates ($80 \\pm 9$ and $91 \\pm 8 ^\\circ/\\rm day$) and polarization\ndegrees ($\\Pi_{\\mathrm x}=10\\%\\pm1\\%$). Simulations of a random walk of the\npolarization vector indicate that it is unlikely that such rotation(s) are\nproduced by a stochastic process. The X-ray emitting site does not completely\noverlap the radio/infrared/optical emission sites, as no similar rotation of\n$\\Psi$ was observed in quasi-simultaneous data at longer wavelengths. We\npropose that the observed rotation was caused by a helical magnetic structure\nin the jet, illuminated in the X-rays by a localized shock propagating along\nthis helix. The optically emitting region likely lies in a sheath surrounding\nan inner spine where the X-ray radiation is released.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:28:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13498","submitter":"Helmut Strey","authors":"Simon Carter and Helmut H. Strey","title":"Parameter estimation from an Ornstein-Uhlenbeck process with measurement\n  noise","comments":"16 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG q-bio.QM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This article aims to investigate the impact of noise on parameter fitting for\nan Ornstein-Uhlenbeck process, focusing on the effects of multiplicative and\nthermal noise on the accuracy of signal separation. To address these issues, we\npropose algorithms and methods that can effectively distinguish between thermal\nand multiplicative noise and improve the precision of parameter estimation for\noptimal data analysis. Specifically, we explore the impact of both\nmultiplicative and thermal noise on the obfuscation of the actual signal and\npropose methods to resolve them. Firstly, we present an algorithm that can\neffectively separate thermal noise with comparable performance to Hamilton\nMonte Carlo (HMC) but with significantly improved speed. Subsequently, we\nanalyze multiplicative noise and demonstrate that HMC is insufficient for\nisolating thermal and multiplicative noise. However, we show that, with\nadditional knowledge of the ratio between thermal and multiplicative noise, we\ncan accurately distinguish between the two types of noise when provided with a\nsufficiently large sampling rate or an amplitude of multiplicative noise\nsmaller than thermal noise. This finding results in a situation that initially\nseems counterintuitive. When multiplicative noise dominates the noise spectrum,\nwe can successfully estimate the parameters for such systems after adding\nadditional white noise to shift the noise balance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:28:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13499","submitter":"Kuan-Hao Huang","authors":"Kuan-Hao Huang, Liang Tan, Rui Hou, Sinong Wang, Amjad Almahairi, Ruty\n  Rinott","title":"Learning Easily Updated General Purpose Text Representations with\n  Adaptable Task-Specific Prefixes","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many real-world applications require making multiple predictions from the\nsame text. Fine-tuning a large pre-trained language model for each downstream\ntask causes computational burdens in the inference time due to several times of\nforward passes. To amortize the computational cost, freezing the language model\nand building lightweight models for downstream tasks based on fixed text\nrepresentations are common solutions. Accordingly, how to learn fixed but\ngeneral text representations that can generalize well to unseen downstream\ntasks becomes a challenge. Previous works have shown that the generalizability\nof representations can be improved by fine-tuning the pre-trained language\nmodel with some source tasks in a multi-tasking way. In this work, we propose a\nprefix-based method to learn the fixed text representations with source tasks.\nWe learn a task-specific prefix for each source task independently and combine\nthem to get the final representations. Our experimental results show that\nprefix-based training performs better than multi-tasking training and can\nupdate the text representations at a smaller computational cost than\nmulti-tasking training.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:31:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13500","submitter":"Sitao Zhang","authors":"Sitao Zhang, Yimu Pan, James Z. Wang","title":"Learning Emotion Representations from Verbal and Nonverbal Communication","comments":"CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Emotion understanding is an essential but highly challenging component of\nartificial general intelligence. The absence of extensively annotated datasets\nhas significantly impeded advancements in this field. We present EmotionCLIP,\nthe first pre-training paradigm to extract visual emotion representations from\nverbal and nonverbal communication using only uncurated data. Compared to\nnumerical labels or descriptions used in previous methods, communication\nnaturally contains emotion information. Furthermore, acquiring emotion\nrepresentations from communication is more congruent with the human learning\nprocess. We guide EmotionCLIP to attend to nonverbal emotion cues through\nsubject-aware context encoding and verbal emotion cues using sentiment-guided\ncontrastive learning. Extensive experiments validate the effectiveness and\ntransferability of EmotionCLIP. Using merely linear-probe evaluation protocol,\nEmotionCLIP outperforms the state-of-the-art supervised visual emotion\nrecognition methods and rivals many multimodal approaches across various\nbenchmarks. We anticipate that the advent of EmotionCLIP will address the\nprevailing issue of data scarcity in emotion understanding, thereby fostering\nprogress in related domains. The code and pre-trained models are available at\nhttps://github.com/Xeaver/EmotionCLIP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:36:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13501","submitter":"Marcella Cornia","authors":"Davide Morelli, Alberto Baldrati, Giuseppe Cartella, Marcella Cornia,\n  Marco Bertini, Rita Cucchiara","title":"LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The rapidly evolving fields of e-commerce and metaverse continue to seek\ninnovative approaches to enhance the consumer experience. At the same time,\nrecent advancements in the development of diffusion models have enabled\ngenerative networks to create remarkably realistic images. In this context,\nimage-based virtual try-on, which consists in generating a novel image of a\ntarget model wearing a given in-shop garment, has yet to capitalize on the\npotential of these powerful generative solutions. This work introduces\nLaDI-VTON, the first Latent Diffusion textual Inversion-enhanced model for the\nVirtual Try-ON task. The proposed architecture relies on a latent diffusion\nmodel extended with a novel additional autoencoder module that exploits\nlearnable skip connections to enhance the generation process preserving the\nmodel's characteristics. To effectively maintain the texture and details of the\nin-shop garment, we propose a textual inversion component that can map the\nvisual features of the garment to the CLIP token embedding space and thus\ngenerate a set of pseudo-word token embeddings capable of conditioning the\ngeneration process. Experimental results on Dress Code and VITON-HD datasets\ndemonstrate that our approach outperforms the competitors by a consistent\nmargin, achieving a significant milestone for the task. Source code and trained\nmodels will be publicly released at: https://github.com/miccunifi/ladi-vton.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:38:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13502","submitter":"Mahdi Anbarloei","authors":"Mahdi Anbarloei","title":"(weakly) (s,n)-closed hyperideals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA math.AC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A multiplicative hyperring is a well-known type of algebraic hyperstructures\nwhich extend a ring to a structure in which the addition is an operation but\nmultiplication is a hyperoperation. Let G be a commutative multiplicative\nhyperring and s,n \\in Z^+. A proper hyperideal Q of G is called (weakly)\n(s,n)-closed if (0 \\neq a^s \\subseteq Q) s^s \\subseteq Q for a\\in G implies a^n\n\\subseteq Q. In this paper, we aim to investigate (weakly) (s,n)-closed\nhyperideals and give some results explaining the structures of these notions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:39:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13503","submitter":"Zhan-Lun Chang","authors":"Zhan-Lun Chang, Seyyedali Hosseinalipour, Mung Chiang, Christopher G.\n  Brinton","title":"Asynchronous Multi-Model Federated Learning over Wireless Networks:\n  Theory, Modeling, and Optimization","comments":"Submission to Mobihoc 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.DC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Federated learning (FL) has emerged as a key technique for distributed\nmachine learning (ML). Most literature on FL has focused on systems with (i) ML\nmodel training for a single task/model, (ii) a synchronous setting for\nuplink/downlink transfer of model parameters, which is often unrealistic. To\naddress this, we develop MA-FL, which considers FL with multiple downstream\ntasks to be trained over an asynchronous model transmission architecture. We\nfirst characterize the convergence of ML model training under MA-FL via\nintroducing a family of scheduling tensors to capture the scheduling of\ndevices. Our convergence analysis sheds light on the impact of resource\nallocation (e.g., the mini-batch size and number of gradient descent\niterations), device scheduling, and individual model states (i.e., warmed vs.\ncold initialization) on the performance of ML models. We then formulate a\nnon-convex mixed integer optimization problem for jointly configuring the\nresource allocation and device scheduling to strike an efficient trade-off\nbetween energy consumption and ML performance, which is solved via successive\nconvex approximations. Through numerical simulations, we reveal the advantages\nof MA-FL in terms of model performance and network resource savings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:39:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13504","submitter":"Dharma Kc","authors":"Dharma KC, Clayton T. Morrison","title":"Neural Machine Translation for Code Generation","comments":"33 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neural machine translation (NMT) methods developed for natural language\nprocessing have been shown to be highly successful in automating translation\nfrom one natural language to another. Recently, these NMT methods have been\nadapted to the generation of program code. In NMT for code generation, the task\nis to generate output source code that satisfies constraints expressed in the\ninput. In the literature, a variety of different input scenarios have been\nexplored, including generating code based on natural language description,\nlower-level representations such as binary or assembly (neural decompilation),\npartial representations of source code (code completion and repair), and source\ncode in another language (code translation). In this paper we survey the NMT\nfor code generation literature, cataloging the variety of methods that have\nbeen explored according to input and output representations, model\narchitectures, optimization techniques used, data sets, and evaluation methods.\nWe discuss the limitations of existing methods and future research directions\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:43:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13505","submitter":"Florent Baudier","authors":"Florent P. Baudier and Christian Rosendal","title":"Abstract embeddability ranks","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.FA math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We describe several ordinal indices that are capable of detecting, according\nto various metric notions of faithfulness, the embeddability between pairs of\nPolish spaces. These embeddability ranks are of theoretical interest but seem\ndifficult to estimate in practice. Embeddability ranks, which are easier to\nestimate in practice, are embeddability ranks generated by Schauder bases.\nThese embeddability are inspired by the nonlinear indices \\`a la Bourgain from\n\\cite{BLMS_FM}. In particular, we resolve a problem \\cite[Problem\n3.10]{BLMS_FM} regarding the necessity of additional set-theoretic axioms\nregarding the main coarse universality result of \\cite{BLMS_FM}.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:46:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13506","submitter":"Paul-Hermann Balduf","authors":"Paul-Hermann Balduf","title":"Statistics of Feynman amplitudes in $\\phi^4$-theory","comments":"59 pages, 70 figures, 17 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The amplitude of subdivergence-free logarithmically divergent Feynman graphs\nin $\\phi^4$-theory in 4 spacetime dimensions is given by a single number, the\nFeynman period. We numerically compute the periods of 1.3 million\nnon-isomorphic completed graphs, this represents more than 31 million graphs\ncontributing to the beta function. Our data set includes all primitive graphs\nup to 13 loops, and non-complete samples up to 18 loops, with an accuracy of\nca. 4 significant digits.\n  We implement all known symmetries of the period in a new computer program and\ncount them up to 14 loops. We discover some combinations of symmetries that had\nbeen overlooked earlier, resulting in an overall slightly lower count of\nindependent graphs than previously assumed.\n  Using the numerical data, we examine the distribution of Feynman periods. We\nconfirm the leading asymptotic growth of the average period with growing loop\norder. At high loop order, a limiting distribution is reached for the\namplitudes near the mean. We construct two different models to approximate this\ndistribution. A small class of graphs, most notably the zigzags, grows\nsignificantly faster than the mean and causes the limiting distribution to have\ndivergent moments even when normalized to unit mean. We examine the relation\nbetween the period and various properties of the underlying graphs. We confirm\nthe strong correlation with the Hepp bound, the Martin invariant, and the\nnumber of 6-edge cuts. We find that, on average, the amplitude of planar graphs\nis significantly larger than that of non-planar graphs, irrespective of $O(N)$\nsymmetry.\n  We estimate the primitive contribution to the 18-loop beta function of the\n$O(N)$-symmetric theory. We confirm that primitive graphs constitute a large\npart of the known asymptotics of the beta function in MS. However, we can not\ndetermine if they are, asymptotically, the only leading contribution.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:51:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13507","submitter":"Mubashara Akhtar","authors":"Akhtar Mubashara, Schlichtkrull Michael, Guo Zhijiang, Cocarascu Oana,\n  Simperl Elena, Vlachos Andreas","title":"Multimodal Automated Fact-Checking: A Survey","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Misinformation, i.e. factually incorrect information, is often conveyed in\nmultiple modalities, e.g. an image accompanied by a caption. It is perceived as\nmore credible by humans, and spreads faster and wider than its text-only\ncounterparts. While an increasing body of research investigates automated\nfact-checking (AFC), previous surveys mostly focus on textual misinformation.\nIn this survey, we conceptualise a framework for AFC including subtasks unique\nto multimodal misinformation. Furthermore, we discuss related terminological\ndeveloped in different communities in the context of our framework. We focus on\nfour modalities prevalent in real-world fact-checking: text, image, audio, and\nvideo. We survey benchmarks and models, and discuss limitations and promising\ndirections for future research.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:52:24 GMT"},{"version":"v2","created":"Wed, 24 May 2023 10:26:07 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13508","submitter":"Haitham Khedr","authors":"Haitham Khedr and Yasser Shoukry","title":"DeepBern-Nets: Taming the Complexity of Certifying Neural Networks using\n  Bernstein Polynomial Activations and Precise Bound Propagation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Formal certification of Neural Networks (NNs) is crucial for ensuring their\nsafety, fairness, and robustness. Unfortunately, on the one hand, sound and\ncomplete certification algorithms of ReLU-based NNs do not scale to large-scale\nNNs. On the other hand, incomplete certification algorithms are easier to\ncompute, but they result in loose bounds that deteriorate with the depth of NN,\nwhich diminishes their effectiveness. In this paper, we ask the following\nquestion; can we replace the ReLU activation function with one that opens the\ndoor to incomplete certification algorithms that are easy to compute but can\nproduce tight bounds on the NN's outputs? We introduce DeepBern-Nets, a class\nof NNs with activation functions based on Bernstein polynomials instead of the\ncommonly used ReLU activation. Bernstein polynomials are smooth and\ndifferentiable functions with desirable properties such as the so-called range\nenclosure and subdivision properties. We design a novel algorithm, called\nBern-IBP, to efficiently compute tight bounds on DeepBern-Nets outputs. Our\napproach leverages the properties of Bernstein polynomials to improve the\ntractability of neural network certification tasks while maintaining the\naccuracy of the trained networks. We conduct comprehensive experiments in\nadversarial robustness and reachability analysis settings to assess the\neffectiveness of the proposed Bernstein polynomial activation in enhancing the\ncertification process. Our proposed framework achieves high certified accuracy\nfor adversarially-trained NNs, which is often a challenging task for certifiers\nof ReLU-based NNs. Moreover, using Bern-IBP bounds for certified training\nresults in NNs with state-of-the-art certified accuracy compared to ReLU\nnetworks. This work establishes Bernstein polynomial activation as a promising\nalternative for improving NN certification tasks across various applications.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:52:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13509","submitter":"Cuong Ly","authors":"Cuong Ly, Grayson Jorgenson, Dan Rosa de Jesus, Henry Kvinge, Adam\n  Attarian, Yijing Watkins","title":"ColMix -- A Simple Data Augmentation Framework to Improve Object\n  Detector Performance and Robustness in Aerial Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the last decade, Convolutional Neural Network (CNN) and transformer based\nobject detectors have achieved high performance on a large variety of datasets.\nThough the majority of detection literature has developed this capability on\ndatasets such as MS COCO, these detectors have still proven effective for\nremote sensing applications. Challenges in this particular domain, such as\nsmall numbers of annotated objects and low object density, hinder overall\nperformance. In this work, we present a novel augmentation method, called\ncollage pasting, for increasing the object density without a need for\nsegmentation masks, thereby improving the detector performance. We demonstrate\nthat collage pasting improves precision and recall beyond related methods, such\nas mosaic augmentation, and enables greater control of object density. However,\nwe find that collage pasting is vulnerable to certain out-of-distribution\nshifts, such as image corruptions. To address this, we introduce two simple\napproaches for combining collage pasting with PixMix augmentation method, and\nrefer to our combined techniques as ColMix. Through extensive experiments, we\nshow that employing ColMix results in detectors with superior performance on\naerial imagery datasets and robust to various corruptions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:56:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13510","submitter":"Nikita Olekhno","authors":"Alexey A. Dmitriev, Alina D. Rozenblit, Vadim A. Porvatov, Mikhail K.\n  Buzakov, Anastasia A. Molodtsova, Daria V. Sennikova, Vyacheslav A. Smirnov,\n  Oleg I. Burmistrov, Timur I. Karimov, Ekaterina M. Puhtina, Nikita A. Olekhno","title":"Swarmodroid 1.0: A Modular Bristle-Bot Platform for Robotic Active\n  Matter Studies","comments":"18 pages, 7 figures, 1 table + Supplementary Information. Comments\n  are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft cond-mat.stat-mech cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large swarms of extremely simple robots (i.e., capable just of basic motion\nactivities, like propelling forward or self-rotating) are widely applied to\nstudy collective task performance based on self-organization or local\nalgorithms instead of sophisticated programming and global swarm coordination.\nMoreover, they represent a versatile yet affordable platform for experimental\nstudies in physics, particularly in active matter - non-equilibrium assemblies\nof particles converting their energy to a directed motion. However, a large set\nof robotics platforms is being used in different studies, while the universal\ndesign is still lacking. Despite such platforms possess advantages in certain\napplication scenarios, their large number sufficiently limits further\ndevelopment of results in the field, as advancing some study requires to buy or\nmanually produce the corresponding robots. To address this issue, we develop an\nopen-source Swarmodroid 1.0 platform based on bristle-bots with reconfigurable\n3D-printed bodies, external control of motion velocity, and basic capabilities\nof velocity profile programming. In addition, we introduce AMPy software\npackage in Python featuring OpenCV-based extraction of robotic swarm kinematics\naccompanied by the evaluation of key physical quantities describing the\ncollective dynamics. We perform a detailed analysis of individual Swarmodroids'\nmotion characteristics and address their use cases with two examples: a cargo\ntransport performed by self-rotating robots and a velocity-dependent jam\nformation in a bottleneck by self-propelling robots. Finally, we provide a\ncomparison of existing centimeter-scale robotic platforms, a review of key\nquantities describing collective dynamics of many-particle systems, and a\ncomprehensive outlook considering potential applications as well as further\ndirections for fundamental studies and Swarmodroid 1.0 platform development.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:56:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13511","submitter":"Witlef Wieczorek","authors":"Sushanth Kini Manjeshwar, Anastasiia Ciers, Juliette Monsel, Hannes\n  Pfeifer, Cindy Peralle, Shu Min Wang, Philippe Tassin, Witlef Wieczorek","title":"Integrated microcavity optomechanics with a suspended photonic crystal\n  mirror above a distributed Bragg reflector","comments":"11 pages, 6 figures + Supplementary Material with 10 pages, 12\n  figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Increasing the interaction between light and mechanical resonators is an\nongoing endeavor in the field of cavity optomechanics. Optical microcavities\nallow for boosting the interaction strength through their strong spatial\nconfinement of the optical field. In this work, we follow this approach by\nrealizing a sub-wavelength-long, free-space optomechanical microcavity on-chip\nfabricated from an (Al,Ga)As heterostructure. A suspended GaAs photonic crystal\nmirror is acting as a highly reflective mechanical resonator, which together\nwith a distributed Bragg reflector forms an optomechanical microcavity. We\ndemonstrate precise control over the microcavity resonance by change of the\nphotonic crystal parameters. The interplay between the microcavity mode and a\nguided resonance of the photonic crystal modifies the cavity response and\nresults in a stronger dynamical backaction on the mechanical resonator compared\nto conventional optomechanical dynamics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:57:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13512","submitter":"Mutian He","authors":"Mutian He, Philip N. Garner","title":"Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken\n  Language Understanding","comments":"6 pages, 2 figures; Accepted by Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, large pretrained language models have demonstrated strong language\nunderstanding capabilities. This is particularly reflected in their zero-shot\nand in-context learning abilities on downstream tasks through prompting. To\nassess their impact on spoken language understanding (SLU), we evaluate several\nsuch models like ChatGPT and OPT of different sizes on multiple benchmarks. We\nverify the emergent ability unique to the largest models as they can reach\nintent classification accuracy close to that of supervised models with zero or\nfew shots on various languages given oracle transcripts. By contrast, the\nresults for smaller models fitting a single GPU fall far behind. We note that\nthe error cases often arise from the annotation scheme of the dataset;\nresponses from ChatGPT are still reasonable. We show, however, that the model\nis worse at slot filling, and its performance is sensitive to ASR errors,\nsuggesting serious challenges for the application of those textual models on\nSLU.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:59:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13513","submitter":"Sergio Di Matteo","authors":"Sergio Di Matteo","title":"On the relation between thermodynamical and statistical entropy: The\n  origin of the N!","comments":"11 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The division by N! in the expression of statistical entropy is usually\njustified to students by the statement that classical particles should be\ncounted as indistinguishable. Sometimes, quantum indistinguishability is\ninvoked to explain it. In this paper, we try to clarify the issue starting from\nClausius thermodynamical entropy and deriving from it Boltzmann statistical\nentropy for the ideal gas. This approach appears interesting for two reasons:\nFirstly, it provides a direct heuristic link between thermodynamical and\nstatistical expressions of entropy that is missing in the usual approach. In\nsecond place, it explicitly reminds that also statistical entropy is defined\nwith respect to a reference state, chosen to be the quantum-mechanical (T=0)\nground state of the N-particles in a box. Both factors $h^{3N}$ and $N!$ at the\ndenominator of the statistical entropy are a consequence of the quantum nature\nof the reference state: in particular, the $N!$ is not related to the particle\nidentity, but to the identity of the boundary conditions on the\nquantum-mechanical ground-state momenta, and to a general statistical\nmaximization principle. The introduction of a reference state also allows to\nreinterpret the standard case of two mixing gases.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:01:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13514","submitter":"Giorgos Vernikos","authors":"Giorgos Vernikos, Arthur Bra\\v{z}inskas, Jakub Adamek, Jonathan\n  Mallinson, Aliaksei Severyn, Eric Malmi","title":"Small Language Models Improve Giants by Rewriting Their Outputs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) have demonstrated impressive few-shot learning\ncapabilities, but they often underperform compared to fine-tuned models on\nchallenging tasks. Furthermore, their large size and restricted access only\nthrough APIs make task-specific fine-tuning impractical. Moreover, LLMs are\nsensitive to different aspects of prompts (e.g., the selection and order of\ndemonstrations) and can thus require time-consuming prompt engineering. In this\nlight, we propose a method to correct LLM outputs without relying on their\nweights. First, we generate a pool of candidates by few-shot prompting an LLM.\nSecond, we refine the LLM-generated outputs using a smaller model, the\nLM-corrector (LMCor), which is trained to rank, combine and rewrite the\ncandidates to produce the final target output. Our experiments demonstrate that\neven a small LMCor model (250M) substantially improves the few-shot performance\nof LLMs (62B) across diverse tasks. Moreover, we illustrate that the LMCor\nexhibits robustness against different prompts, thereby minimizing the need for\nextensive prompt engineering. Finally, we showcase that the LMCor can be\nseamlessly integrated with different LLMs at inference time, serving as a\nplug-and-play module to improve their performance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:07:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13515","submitter":"Stavros Komineas","authors":"George Theodorou, Stavros Komineas","title":"Interaction and collision of skyrmions in chiral antiferromagnets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Skyrmions in an antiferromagnet can travel as solitary waves in stark\ncontrast to the situation in ferromagnets. Traveling skyrmion solutions have\nbeen found numerically in chiral antiferromagnets. We consider head-on\ncollision events between two skyrmions. We find that the result of the\ncollision depends on the initial velocity of the skyrmions. For small\nvelocities, the skyrmions are shrinking as they are approaching, they bounce\nback and eventually acquire almost their initial speed. For larger velocities,\nthe skyrmions approach each other and shrink until they become singular points\nand are eventually annihilated. We describe the observed phenomena in terms of\nskyrmion energetics and thus determine the regimes of the different dynamical\nbehaviors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:08:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13516","submitter":"Michael Auli","authors":"Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu,\n  Sayani Kundu, Ali Elkahky, Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi,\n  Alexei Baevski, Yossi Adi, Xiaohui Zhang, Wei-Ning Hsu, Alexis Conneau,\n  Michael Auli","title":"Scaling Speech Technology to 1,000+ Languages","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Expanding the language coverage of speech technology has the potential to\nimprove access to information for many more people. However, current speech\ntechnology is restricted to about one hundred languages which is a small\nfraction of the over 7,000 languages spoken around the world. The Massively\nMultilingual Speech (MMS) project increases the number of supported languages\nby 10-40x, depending on the task. The main ingredients are a new dataset based\non readings of publicly available religious texts and effectively leveraging\nself-supervised learning. We built pre-trained wav2vec 2.0 models covering\n1,406 languages, a single multilingual automatic speech recognition model for\n1,107 languages, speech synthesis models for the same number of languages, as\nwell as a language identification model for 4,017 languages. Experiments show\nthat our multilingual speech recognition model more than halves the word error\nrate of Whisper on 54 languages of the FLEURS benchmark while being trained on\na small fraction of the labeled data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:09:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13517","submitter":"Ziyu Chen","authors":"Ziyu Chen, Markos A. Katsoulakis, Luc Rey-Bellet, Wei Zhu","title":"Statistical Guarantees of Group-Invariant GANs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Group-invariant generative adversarial networks (GANs) are a type of GANs in\nwhich the generators and discriminators are hardwired with group symmetries.\nEmpirical studies have shown that these networks are capable of learning\ngroup-invariant distributions with significantly improved data efficiency. In\nthis study, we aim to rigorously quantify this improvement by analyzing the\nreduction in sample complexity for group-invariant GANs. Our findings indicate\nthat when learning group-invariant distributions, the number of samples\nrequired for group-invariant GANs decreases proportionally with a power of the\ngroup size, and this power depends on the intrinsic dimension of the\ndistribution's support. To our knowledge, this work presents the first\nstatistical estimation for group-invariant generative models, specifically for\nGANs, and it may shed light on the study of other group-invariant generative\nmodels.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:13:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13518","submitter":"Bilel Hamil","authors":"R. Oubagha, B. Hamil, B. C. L\\\"utf\\\"uo\\u{g}lu, M. Merad","title":"Extended uncertainty principle and Van der Waals black holes","comments":"13 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this manuscript, we investigate the extended uncertainty principle (EUP)\neffects on the Van der Waals (VdW) black holes whose thermal quantities mimic\nthe VdW liquid. We find that the considered formalism imposes an upper bound on\nthe event horizon radius. Thus, the mass, Hawking temperature, and heat\ncapacity become physically meaningful within a certain range of event horizon\nradii. At a large event horizon radius the black hole has a remnant. Whether\nthe VdW black hole is stable or not depends on the black hole parameters.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:18:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13519","submitter":"Patrick dos Anjos","authors":"Patrick dos Anjos, Lucas A. Quaresma, Marcelo L. P. Machado","title":"Development of Non-Linear Equations for Predicting Electrical\n  Conductivity in Silicates","comments":"8 pages, 6 figures, 1 table (AISTech 2023 - Presented and Accepted)","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP cs.LG cs.NE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electrical conductivity is of fundamental importance in electric arc furnaces\n(EAF) and the interaction of this phenomenon with the process slag results in\nenergy losses and low optimization. As mathematical modeling helps in\nunderstanding the behavior of phenomena and it was used to predict the\nelectrical conductivity of EAF slags through artificial neural networks. The\nbest artificial neural network had 100 neurons in the hidden layer, with 6\npredictor variables and the predicted variable, electrical conductivity. Mean\nabsolute error and standard deviation of absolute error were calculated, and\nsensitivity analysis was performed to correlate the effect of each predictor\nvariable with the predicted variable.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:20:57 GMT"},{"version":"v2","created":"Sun, 28 May 2023 13:33:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13520","submitter":"Emirhan Kurtulus","authors":"Emirhan Kurtulus, Zichao Li, Yann Dauphin, Ekin Dogus Cubuk","title":"Tied-Augment: Controlling Representation Similarity Improves Data\n  Augmentation","comments":"14 pages, 2 figures, ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Data augmentation methods have played an important role in the recent advance\nof deep learning models, and have become an indispensable component of\nstate-of-the-art models in semi-supervised, self-supervised, and supervised\ntraining for vision. Despite incurring no additional latency at test time, data\naugmentation often requires more epochs of training to be effective. For\nexample, even the simple flips-and-crops augmentation requires training for\nmore than 5 epochs to improve performance, whereas RandAugment requires more\nthan 90 epochs. We propose a general framework called Tied-Augment, which\nimproves the efficacy of data augmentation in a wide range of applications by\nadding a simple term to the loss that can control the similarity of\nrepresentations under distortions. Tied-Augment can improve state-of-the-art\nmethods from data augmentation (e.g. RandAugment, mixup), optimization (e.g.\nSAM), and semi-supervised learning (e.g. FixMatch). For example,\nTied-RandAugment can outperform RandAugment by 2.0% on ImageNet. Notably, using\nTied-Augment, data augmentation can be made to improve generalization even when\ntraining for a few epochs and when fine-tuning. We open source our code at\nhttps://github.com/ekurtulus/tied-augment/tree/main.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:23:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13521","submitter":"Nan Xu","authors":"Nan Xu, Hongming Zhang, Jianshu Chen","title":"CEO: Corpus-based Open-Domain Event Ontology Induction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Existing event-centric NLP models often only apply to the pre-defined\nontology, which significantly restricts their generalization capabilities. This\npaper presents CEO, a novel Corpus-based Event Ontology induction model to\nrelax the restriction imposed by pre-defined event ontologies. Without direct\nsupervision, CEO leverages distant supervision from available summary datasets\nto detect corpus-wise salient events and exploits external event knowledge to\nforce events within a short distance to have close embeddings. Experiments on\nthree popular event datasets show that the schema induced by CEO has better\ncoverage and higher accuracy than previous methods. Moreover, CEO is the first\nevent ontology induction model that can induce a hierarchical event ontology\nwith meaningful names on eleven open-domain corpora, making the induced schema\nmore trustworthy and easier to be further curated.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:26:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13522","submitter":"Nishchay Suri","authors":"Nishchay Suri, Chong Wang, Benjamin M. Hunt and Di Xiao","title":"Superlattice Engineering of Topology in Massive Dirac Fermions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that a superlattice potential can be employed to engineer topology in\nmassive Dirac fermions in systems such as bilayer graphene, moir\\'e\ngraphene-boron nitride, and transition-metal dichalcogenide (TMD) monolayers\nand bilayers. We use symmetry analysis to analyze band inversions to determine\nthe Chern number $\\mathscr C$ for the valence band as a function of tunable\npotential parameters for a class of $C_4$ and $C_3$ symmetric potentials. We\npresent a novel method to engineer Chern number $\\mathscr{C}=2$ for the valence\nband and show that the applied potential at minimum must have a scalar together\nwith a non-scalar periodic part. We discover that certain forms of the\nsuperlattice potential, which may be difficult to realize in naturally\noccurring moir\\'e patterns, allow for the possibility of non-trivial\ntopological transitions. These forms may be achievable using an external\nsuperlattice potential that can be created using contemporary experimental\ntechniques. Our work paves the way to realize the quantum Spin Hall effect\n(QSHE), quantum anomalous Hall effect (QAHE), and even exotic non-Abelian\nanyons in the fractional quantum Hall effect (FQHE).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:27:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13523","submitter":"Yonghui Wu","authors":"Cheng Peng, Xi Yang, Aokun Chen, Kaleb E Smith, Nima PourNejatian,\n  Anthony B Costa, Cheryl Martin, Mona G Flores, Ying Zhang, Tanja Magoc,\n  Gloria Lipori, Duane A Mitchell, Naykky S Ospina, Mustafa M Ahmed, William R\n  Hogan, Elizabeth A Shenkman, Yi Guo, Jiang Bian, Yonghui Wu","title":"A Study of Generative Large Language Model for Medical Research and\n  Healthcare","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p < 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:37:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13524","submitter":"Syeda Khadija Zaidi","authors":"Khadija F. Zaidi and Michelle Harris-Love","title":"Upper extremity kinematics: Development of a quantitative measure of\n  impairment severity and dissimilarity after stroke","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Strokes are a leading cause of disability, with many experiencing difficulty\nin recovering arm movement, particularly hand function and grasping ability.\nThere is currently no objective measure of movement quality, and without it,\nrehabilitative interventions remain at best estimations of the underlying\nneural structures response to produce movement. In this paper, we utilize a\nnovel modification to Procrustean distance to quantify curve dissimilarity and\npropose the Reach Severity and Dissimilarity Index (RSDI) as an objective\nmeasure of motor deficits. All experiments took place at the Medstar National\nRehabilitation Hospital; persons with stroke were recruited from the hospital\npatient population. Using Fugl-Meyer (FM) scores and reach capacities, stroke\nsurvivors were placed in mild or severe impairment groups. Individuals\ncompleted sets of reach-to-target tasks to extrapolate kinematic metrics\ndescribing motor performance. The Procrustes method of statistical shape\nanalysis was modified to identify reaching sub-movements that were congruous to\nable-bodied sub-movements. Movement initiation proceeds comparably to the\nreference curve in two- and three-dimensional representations of mild\nimpairment movement. There were significant effects of the location of\ncongruent segments between subject and reference curves, mean velocities, peak\nroll angle, and target error. These metrics were used to calculate a\npreliminary RSDI score with severity and dissimilarity sub-scores, and subjects\nwere reclassified in terms of rehabilitation goals as Speed Emphasis, Strength\nEmphasis, and Combined Emphasis. The Modified Procrustes method shows promise\nin identifying disruptions in movement and monitoring recovery without adding\nto patient burden. The proposed RSDI score, while limited in scope, can be\nadapted and expanded to other functional movements and used as an objective\nclinical tool.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:40:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13525","submitter":"Abhinav Bhatele","authors":"Siddharth Singh, Zack Sating, Abhinav Bhatele","title":"Communication-minimizing Asynchronous Tensor Parallelism","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.DC cs.PF","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As state-of-the-art neural networks scale to billions of parameters,\ndesigning parallel algorithms that can train these networks efficiently on\nmulti-GPU clusters has become critical. This paper presents Tensor3D, a novel\nthree-dimensional (3D) approach to parallelize tensor computations, that\nstrives to minimize the idle time incurred due to communication in parallel\ntraining of large multi-billion parameter models. First, we introduce an\nintelligent distribution of neural network parameters across GPUs that\neliminates communication required for satisfying data dependencies of\nindividual layers. Then, we propose a novel overdecomposition of the parallel\ntraining process, using which we achieve significant overlap of communication\nwith computation, thereby reducing GPU idle time. Finally, we present a\ncommunication model, which helps users identify communication optimal\ndecompositions of available hardware resources for a given neural network. For\na 28B parameter CNN on 256 A100 GPUs, Tensor3D improves the training time by\nnearly 60% as compared to Megatron-LM.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:41:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13526","submitter":"Guang Yuan Zhang","authors":"Tian-Run Li, Yun-Ling Chen and Guang-Yuan Zhang","title":"A finite theorem for Ahlfors' covering surface theory","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ahlfors' theory of covering surfaces is one of the major mathematical\nachievement of last century. The most important part of his theory is the\nSecond Fundamental Theorem (SFT). We are interested in the relation of errors\nof Ahlfors' SFT with the same boundary curve.\n  In this paper we will prove a result which is used to establish the best\nbound of the constant in Ahlfors' SFT (in \\cite{Zh}).\n  Precisely speaking, we will prove that for any surface\n$\\Sigma\\in\\mathcal{F}_r(L,m)$, a new surface $\\Sigma_1$ can be constructed\nbased on it, such that $R(\\Sigma_1)\\ge R(\\Sigma)$ and $L(\\partial\\Sigma_1)\\le\nL(\\partial\\Sigma)$, where $R(\\Sigma)$ is Ahlfors' error term and\n$L(\\partial\\Sigma)$ is the boundary length of the surface $\\Sigma$, and the\ncovering degree of $\\Sigma_1$ has an upper bound independent of surfaces.\nMeanwhile, this conclusion suggests that the supremum of\n$H(\\Sigma)=R(\\Sigma)/L(\\partial\\Sigma)$ can be achieved by surfaces in the\nspace $\\mathcal{F}_r'(L,m)$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:43:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13527","submitter":"Tollef Emil J{\\o}rgensen","authors":"Tollef Emil J{\\o}rgensen and Andre K{\\aa}sen","title":"Aligning the Norwegian UD Treebank with Entity and Coreference\n  Information","comments":"4 pages, 1 table. Appendix: 3 tables and 5 data examples","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper presents a merged collection of entity and coreference annotated\ndata grounded in the Universal Dependencies (UD) treebanks for the two written\nforms of Norwegian: Bokm{\\aa}l and Nynorsk. The aligned and converted corpora\nare the Norwegian Named Entities (NorNE) and Norwegian Anaphora Resolution\nCorpus (NARC). While NorNE is aligned with an older version of the treebank,\nNARC is misaligned and requires extensive transformation from the original\nannotations to the UD structure and CoNLL-U format. We here demonstrate the\nconversion and alignment processes, along with an analysis of discovered issues\nand errors in the data - some of which include data split overlaps in the\noriginal treebank. These procedures and the developed system may prove helpful\nfor future corpus alignment and coreference annotation endeavors. The merged\ncorpora comprise the first Norwegian UD treebank enriched with named entities\nand coreference information.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:44:53 GMT"},{"version":"v2","created":"Thu, 25 May 2023 22:36:36 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13528","submitter":"Evgeniia Razumovskaia","authors":"Evgeniia Razumovskaia, Ivan Vuli\\'c, Anna Korhonen","title":"Transfer-Free Data-Efficient Multilingual Slot Labeling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Slot labeling (SL) is a core component of task-oriented dialogue (ToD)\nsystems, where slots and corresponding values are usually language-, task- and\ndomain-specific. Therefore, extending the system to any new\nlanguage-domain-task configuration requires (re)running an expensive and\nresource-intensive data annotation process. To mitigate the inherent data\nscarcity issue, current research on multilingual ToD assumes that sufficient\nEnglish-language annotated data are always available for particular tasks and\ndomains, and thus operates in a standard cross-lingual transfer setup. In this\nwork, we depart from this often unrealistic assumption. We examine challenging\nscenarios where such transfer-enabling English annotated data cannot be\nguaranteed, and focus on bootstrapping multilingual data-efficient slot\nlabelers in transfer-free scenarios directly in the target languages without\nany English-ready data. We propose a two-stage slot labeling approach (termed\nTWOSL) which transforms standard multilingual sentence encoders into effective\nslot labelers. In Stage 1, relying on SL-adapted contrastive learning with only\na handful of SL-annotated examples, we turn sentence encoders into\ntask-specific span encoders. In Stage 2, we recast SL from a token\nclassification into a simpler, less data-intensive span classification task.\nOur results on two standard multilingual TOD datasets and across diverse\nlanguages confirm the effectiveness and robustness of TWOSL. It is especially\neffective for the most challenging transfer-free few-shot setups, paving the\nway for quick and data-efficient bootstrapping of multilingual slot labelers\nfor ToD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:47:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13529","submitter":"Junho Peter Whang","authors":"Junho Peter Whang","title":"Deciding periodicity on algebraic varieties","comments":"5 pages. v2: Corrected minor typos in the proof of Theorem 1.1.\n  Comments are welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS math.AG math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We demonstrate the decidability of periodicity for algebraic points in\nfinitely generated dynamical systems of algebraic varieties. The main tool is\nan effective nonlinear Selberg's lemma of Bass-Lubotzky. As an application, we\nobtain an effective universal upper bound on periods of integral points for\narbitrary sets of polynomial endomorphisms of a fixed affine space.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:48:42 GMT"},{"version":"v2","created":"Tue, 30 May 2023 01:39:43 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13530","submitter":"Inez Okulska","authors":"Daria Stetsenko and Inez Okulska","title":"The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian\n  Language","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper provides an overview of a text mining tool the StyloMetrix\ndeveloped initially for the Polish language and further extended for English\nand recently for Ukrainian. The StyloMetrix is built upon various metrics\ncrafted manually by computational linguists and researchers from literary\nstudies to analyze grammatical, stylistic, and syntactic patterns. The idea of\nconstructing the statistical evaluation of syntactic and grammar features is\nstraightforward and familiar for the languages like English, Spanish, German,\nand others; it is yet to be developed for low-resource languages like\nUkrainian. We describe the StyloMetrix pipeline and provide some experiments\nwith this tool for the text classification task. We also describe our package's\nmain limitations and the metrics' evaluation procedure.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:52:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13531","submitter":"Alex  H. Ardila","authors":"Alex H. Ardila, Jason Murphy, and Jiqiang Zheng","title":"Threshold dynamics for the 3$d$ radial NLS with combined nonlinearity","comments":"31 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the nonlinear Schr\\\"odinger equation with focusing quintic and\ndefocusing cubic nonlinearity in three space dimensions: \\[\n(i\\partial_t+\\Delta)u = |u|^2 u - |u|^4 u. \\] In [18, 23], the authors\nclassified the dynamics of solutions under the energy constraint $E(u)<\nE^c(W)$, where $W$ is the quintic NLS ground state and $E^c$ is the quintic NLS\nenergy. In this work we classify the dynamics of $H^1$ solutions at the\nthreshold $E(u)=E^c(W)$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:54:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13532","submitter":"Simerjot Kaur","authors":"Simerjot Kaur, Andrea Stefanucci, Sameena Shah","title":"InProC: Industry and Product/Service Code Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.CP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Determining industry and product/service codes for a company is an important\nreal-world task and is typically very expensive as it involves manual curation\nof data about the companies. Building an AI agent that can predict these codes\nautomatically can significantly help reduce costs, and eliminate human biases\nand errors. However, unavailability of labeled datasets as well as the need for\nhigh precision results within the financial domain makes this a challenging\nproblem. In this work, we propose a hierarchical multi-class industry code\nclassifier with a targeted multi-label product/service code classifier\nleveraging advances in unsupervised representation learning techniques. We\ndemonstrate how a high quality industry and product/service code classification\nsystem can be built using extremely limited labeled dataset. We evaluate our\napproach on a dataset of more than 20,000 companies and achieved a\nclassification accuracy of more than 92\\%. Additionally, we also compared our\napproach with a dataset of 350 manually labeled product/service codes provided\nby Subject Matter Experts (SMEs) and obtained an accuracy of more than 96\\%\nresulting in real-life adoption within the financial domain.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:09:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13533","submitter":"William Hogan","authors":"William Hogan, Jiacheng Li, Jingbo Shang","title":"Open-world Semi-supervised Generalized Relation Discovery Aligned in a\n  Real-world Setting","comments":"10 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Open-world Relation Extraction (OpenRE) has recently garnered significant\nattention. However, existing approaches tend to oversimplify the problem by\nassuming that all unlabeled texts belong to novel classes, thereby limiting the\npracticality of these methods. We argue that the OpenRE setting should be more\naligned with the characteristics of real-world data. Specifically, we propose\ntwo key improvements: (a) unlabeled data should encompass known and novel\nclasses, including hard-negative instances; and (b) the set of novel classes\nshould represent long-tail relation types. Furthermore, we observe that popular\nrelations such as titles and locations can often be implicitly inferred through\nspecific patterns, while long-tail relations tend to be explicitly expressed in\nsentences. Motivated by these insights, we present a novel method called KNoRD\n(Known and Novel Relation Discovery), which effectively classifies explicitly\nand implicitly expressed relations from known and novel classes within\nunlabeled data. Experimental evaluations on several Open-world RE benchmarks\ndemonstrate that KNoRD consistently outperforms other existing methods,\nachieving significant performance gains.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:12:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13534","submitter":"Muru Zhang","authors":"Muru Zhang, Ofir Press, William Merrill, Alisa Liu, Noah A. Smith","title":"How Language Model Hallucinations Can Snowball","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A major risk of using language models in practical applications is their\ntendency to hallucinate incorrect statements. Hallucinations are often\nattributed to knowledge gaps in LMs, but we hypothesize that in some cases,\nwhen justifying previously generated hallucinations, LMs output false claims\nthat they can separately recognize as incorrect. We construct three\nquestion-answering datasets where ChatGPT and GPT-4 often state an incorrect\nanswer and offer an explanation with at least one incorrect claim. Crucially,\nwe find that ChatGPT and GPT-4 can identify 67% and 87% of their own mistakes,\nrespectively. We refer to this phenomenon as hallucination snowballing: an LM\nover-commits to early mistakes, leading to more mistakes that it otherwise\nwould not make.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:14:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13535","submitter":"Ananth Balashankar","authors":"Ananth Balashankar, Xuezhi Wang, Yao Qin, Ben Packer, Nithum Thain,\n  Jilin Chen, Ed H. Chi, Alex Beutel","title":"Improving Classifier Robustness through Active Generation of Pairwise\n  Counterfactuals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Counterfactual Data Augmentation (CDA) is a commonly used technique for\nimproving robustness in natural language classifiers. However, one fundamental\nchallenge is how to discover meaningful counterfactuals and efficiently label\nthem, with minimal human labeling cost. Most existing methods either completely\nrely on human-annotated labels, an expensive process which limits the scale of\ncounterfactual data, or implicitly assume label invariance, which may mislead\nthe model with incorrect labels. In this paper, we present a novel framework\nthat utilizes counterfactual generative models to generate a large number of\ndiverse counterfactuals by actively sampling from regions of uncertainty, and\nthen automatically label them with a learned pairwise classifier. Our key\ninsight is that we can more correctly label the generated counterfactuals by\ntraining a pairwise classifier that interpolates the relationship between the\noriginal example and the counterfactual. We demonstrate that with a small\namount of human-annotated counterfactual data (10%), we can generate a\ncounterfactual augmentation dataset with learned labels, that provides an\n18-20% improvement in robustness and a 14-21% reduction in errors on 6\nout-of-domain datasets, comparable to that of a fully human-annotated\ncounterfactual dataset for both sentiment classification and question\nparaphrase tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:19:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13536","submitter":"Olga Saukh","authors":"Olga Saukh, Dong Wang, Xiaoxi He, Lothar Thiele","title":"Representing Input Transformations by Low-Dimensional Parameter\n  Subspaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Deep models lack robustness to simple input transformations such as rotation,\nscaling, and translation, unless they feature a particular invariant\narchitecture or undergo specific training, e.g., learning the desired\nrobustness from data augmentations. Alternatively, input transformations can be\ntreated as a domain shift problem, and solved by post-deployment model\nadaptation. Although a large number of methods deal with transformed inputs,\nthe fundamental relation between input transformations and optimal model\nweights is unknown. In this paper, we put forward the configuration subspace\nhypothesis that model weights optimal for parameterized continuous\ntransformations can reside in low-dimensional linear subspaces. We introduce\nsubspace-configurable networks to learn these subspaces and observe their\nstructure and surprisingly low dimensionality on all tested transformations,\ndatasets and architectures from computer vision and audio signal processing\ndomains. Our findings enable efficient model reconfiguration, especially when\nlimited storage and computing resources are at stake.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:19:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13537","submitter":"Nelson Martins-Ferreira","authors":"Nelson Martins-Ferreira","title":"Internal groupoids as involutive-2-links","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CT","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Regardless of its environment, the category of internal groupoids is shown to\nbe equivalent to the full subcategory of involutive-2-links that are unital and\nassociative. The new notion of involutive-2-link originates from the study of\ntriangulated surfaces and their application in additive manufacturing and\n3d-printing. Thus, this result establishes a bridge between the structure of an\ninternal groupoid and an abstract triangulated surface. An example is provided\nwhich can be thought of as a crossed-module of magmas rather than groups.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:20:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13538","submitter":"Linwei Sang","authors":"Linwei Sang, Yinliang Xu, Hongbin Sun","title":"Encoding Carbon Emission Flow in Energy Management: A Compact Constraint\n  Learning Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decarbonizing the energy supply is essential and urgent to mitigate the\nincreasingly visible climate change. Its basis is identifying emission\nresponsibility during power allocation by the carbon emission flow (CEF) model.\nHowever, the main challenge of CEF application is the intractable nonlinear\nrelationship between carbon emission and power allocation. So this paper\nleverages the high approximation capability and the mixed-integer linear\nprogramming (MILP) representability of the deep neural networks to tackle the\ncomplex CEF model in carbon-electricity coordinated optimization. The compact\nconstraint learning approach is proposed to learn the mapping from power\ninjection to bus emission with sparse neural networks (SNNs). Then the trained\nSNNs are transformed equivalently as MILP constraints in the downstream\noptimization. In light of the ``high emission with high price'' principle, the\nblocked carbon price mechanism is designed to price emissions from the demand\nside. Based on the constraint learning and mechanism design, this paper\nproposes the carbon-aware energy management model in the tractable MILP form to\nunlock the carbon reduction potential from the demand side. The case study\nverifies the approximation accuracy and sparsity of SNN with fewer parameters\nfor accelerating optimization solution and reduction effectiveness of\ndemand-side capability for mitigating emission.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:22:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13539","submitter":"Ananth Hari","authors":"Ananth Hari and Uzi Vishkin","title":"Empirical Challenge for NC Theory","comments":"10 pages, 5 figures. Accepted at HOPC'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Horn-satisfiability or Horn-SAT is the problem of deciding whether a\nsatisfying assignment exists for a Horn formula, a conjunction of clauses each\nwith at most one positive literal (also known as Horn clauses). It is a\nwell-known P-complete problem, which implies that unless P = NC, it is a hard\nproblem to parallelize. In this paper, we empirically show that, under a known\nsimple random model for generating the Horn formula, the ratio of\nhard-to-parallelize instances (closer to the worst-case behavior) is\ninfinitesimally small. We show that the depth of a parallel algorithm for\nHorn-SAT is polylogarithmic on average, for almost all instances, while keeping\nthe work linear. This challenges theoreticians and programmers to look beyond\nworst-case analysis and come up with practical algorithms coupled with\nrespective performance guarantees.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:23:05 GMT"},{"version":"v2","created":"Thu, 25 May 2023 16:41:39 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13540","submitter":"Mollie Wood","authors":"Mollie E. Wood, Chase D. Latour, Lucia C. Petito","title":"Treatments for pregestational chronic conditions during pregnancy:\n  emulating a target trial with a treatment decision design","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As a solution to methodologic challenges inherent to estimating causal\neffects of exposures in early pregnancy, we suggest emulating a target trial\nusing a treatment decision design, wherein time zero is centered around\nclinical landmarks where treatment decisions may occur, such as the date of\npreconception counseling or prenatal care initiation. These ideas are\nillustrated via protocols for two target trials in large administrative\ndatabases, antidepressant use for pre-existing depressive disorder and\nantihypertensive medication use for mild-to-moderate chronic hypertension.\nCareful consideration of these issues is critical to the identification of the\ncausal effects of early-pregnancy pharmacotherapies on pregnancy outcomes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:24:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13541","submitter":"Yu Guan","authors":"Shuai Shao, Yu Guan, Bing Zhai, Paolo Missier, Thomas Ploetz","title":"ConvBoost: Boosting ConvNets for Sensor-based Activity Recognition","comments":"21 pages","journal-ref":"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 7, 2,\n  Article 75 (June 2023)","doi":"10.1145/3596234","report-no":null,"categories":"cs.LG cs.AI cs.CV cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Human activity recognition (HAR) is one of the core research themes in\nubiquitous and wearable computing. With the shift to deep learning (DL) based\nanalysis approaches, it has become possible to extract high-level features and\nperform classification in an end-to-end manner. Despite their promising overall\ncapabilities, DL-based HAR may suffer from overfitting due to the notoriously\nsmall, often inadequate, amounts of labeled sample data that are available for\ntypical HAR applications. In response to such challenges, we propose ConvBoost\n-- a novel, three-layer, structured model architecture and boosting framework\nfor convolutional network based HAR. Our framework generates additional\ntraining data from three different perspectives for improved HAR, aiming to\nalleviate the shortness of labeled training data in the field. Specifically,\nwith the introduction of three conceptual layers--Sampling Layer, Data\nAugmentation Layer, and Resilient Layer -- we develop three \"boosters\" --\nR-Frame, Mix-up, and C-Drop -- to enrich the per-epoch training data by\ndense-sampling, synthesizing, and simulating, respectively. These new\nconceptual layers and boosters, that are universally applicable for any kind of\nconvolutional network, have been designed based on the characteristics of the\nsensor data and the concept of frame-wise HAR. In our experimental evaluation\non three standard benchmarks (Opportunity, PAMAP2, GOTOV) we demonstrate the\neffectiveness of our ConvBoost framework for HAR applications based on variants\nof convolutional networks: vanilla CNN, ConvLSTM, and Attention Models. We\nachieved substantial performance gains for all of them, which suggests that the\nproposed approach is generic and can serve as a practical solution for boosting\nthe performance of existing ConvNet-based HAR models. This is an open-source\nproject, and the code can be found at https://github.com/sshao2013/ConvBoost\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:27:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13542","submitter":"Judy Hanwen Shen","authors":"Inbal Livni Navon, Charlotte Peale, Omer Reingold, Judy Hanwen Shen","title":"Bidding Strategies for Proportional Representation in Advertisement\n  Campaigns","comments":"Foundations of Responsible Computing (FORC 2023)","journal-ref":null,"doi":"10.4230/LIPIcs.FORC.2023.3","report-no":null,"categories":"cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many companies rely on advertising platforms such as Google, Facebook, or\nInstagram to recruit a large and diverse applicant pool for job openings. Prior\nworks have shown that equitable bidding may not result in equitable outcomes\ndue to heterogeneous levels of competition for different types of individuals.\nSuggestions have been made to address this problem via revisions to the\nadvertising platform. However, it may be challenging to convince platforms to\nundergo a costly re-vamp of their system, and in addition it might not offer\nthe flexibility necessary to capture the many types of fairness notions and\nother constraints that advertisers would like to ensure. Instead, we consider\nalterations that make no change to the platform mechanism and instead change\nthe bidding strategies used by advertisers. We compare two natural fairness\nobjectives: one in which the advertisers must treat groups equally when bidding\nin order to achieve a yield with group-parity guarantees, and another in which\nthe bids are not constrained and only the yield must satisfy parity\nconstraints. We show that requiring parity with respect to both bids and yield\ncan result in an arbitrarily large decrease in efficiency compared to requiring\nequal yield proportions alone. We find that autobidding is a natural way to\nrealize this latter objective and show how existing work in this area can be\nextended to provide efficient bidding strategies that provide high utility\nwhile satisfying group parity constraints as well as deterministic and\nrandomized rounding techniques to uphold these guarantees. Finally, we\ndemonstrate the effectiveness of our proposed solutions on data adapted from a\nreal-world employment dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:29:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13543","submitter":"Yosuke Ashida","authors":"Yosuke Ashida, Ken'ichiro Nakazato, Takuji Tsujimoto","title":"Diffuse Neutrino Flux Based on the Rates of Core-Collapse Supernovae and\n  Black Hole Formation Deduced from a Novel Galactic Chemical Evolution Model","comments":"11 pages, 10 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fluxes of the diffuse supernova neutrino background (DSNB) are calculated\nbased on a new modeling of galactic chemical evolution, where a variable\nstellar initial mass function (IMF) depending on the galaxy type is introduced\nand black hole (BH) formation from the failed supernova is considered for\nprogenitors heavier than 18$M_{\\odot}$. The flux calculations are performed for\ndifferent combinations of the star formation rate, nuclear equation of state,\nand neutrino mass hierarchy to examine the systematic effects from these\nfactors. In any case, our new model predicts the enhanced DSNB $\\bar{\\nu}_{e}$\nflux at $E_\\nu \\gtsim 30$~MeV and $E_\\nu \\ltsim 10$~MeV due to more frequent BH\nformation and a larger core collapse rate at high redshifts in the early-type\ngalaxies, respectively. Event rate spectra of the DSNB $\\bar{\\nu}_{e}$ at a\ndetector from the new model are shown and detectability at water-based\nCherenkov detectors, SK-Gd and Hyper-Kamiokande, is discussed. In order to\ninvestigate impacts of the assumptions in the new model, we prepare alternative\nmodels based on the different IMF form and treatment of BH formation, and\nestimate discrimination capabilities between the new and alternative models at\nthese detectors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:34:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13544","submitter":"Mehran Mozaffari Kermani","authors":"Alvaro Cintas Canto, Jasmin Kaur, Mehran Mozaffari Kermani, Reza\n  Azarderakhsh","title":"Algorithmic Security is Insufficient: A Comprehensive Survey on\n  Implementation Attacks Haunting Post-Quantum Security","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This survey is on forward-looking, emerging security concerns in post-quantum\nera, i.e., the implementation attacks for 2022 winners of NIST post-quantum\ncryptography (PQC) competition and thus the visions, insights, and discussions\ncan be used as a step forward towards scrutinizing the new standards for\napplications ranging from Metaverse, Web 3.0 to deeply-embedded systems. The\nrapid advances in quantum computing have brought immense opportunities for\nscientific discovery and technological progress; however, it poses a major risk\nto today's security since advanced quantum computers are believed to break all\ntraditional public-key cryptographic algorithms. This has led to active\nresearch on PQC algorithms that are believed to be secure against classical and\npowerful quantum computers. However, algorithmic security is unfortunately\ninsufficient, and many cryptographic algorithms are vulnerable to side-channel\nattacks (SCA), where an attacker passively or actively gets side-channel data\nto compromise the security properties that are assumed to be safe\ntheoretically. In this survey, we explore such imminent threats and their\ncountermeasures with respect to PQC. We provide the respective, latest\nadvancements in PQC research, as well as assessments and providing visions on\nthe different types of SCAs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:36:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13545","submitter":"Yuming Shi","authors":"Yuming Shi, Yi Shi, Adam Wasserman","title":"Stretching bonds in Density Functional Theory without artificial\n  symmetry breaking","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph physics.comp-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Accurate first-principles calculations for the energies, charge\ndistributions, and spin symmetries of many-electron systems are essential to\nunderstand and predict the electronic and structural properties of molecules\nand materials. Kohn-Sham density functional theory (KS-DFT) stands out among\nelectronic-structure methods due to its balance of accuracy and computational\nefficiency. It is now extensively used in fields ranging from materials\nengineering to rational drug design. However, to achieve chemically accurate\nenergies, standard density functional approximations in KS-DFT often need to\nbreak underlying symmetries, a long-standing \"symmetry dilemma\". By employing\nfragment spin densities as the main variables in calculations (rather than\ntotal molecular densities as in KS-DFT), we present an embedding framework in\nwhich this symmetry dilemma is resolved for the case of stretched molecules.\nThe spatial overlap between fragment densities is used as the main ingredient\nto construct a simple, physically-motivated approximation to a universal\nfunctional of the fragment densities. This 'overlap approximation' is shown to\nsignificantly improve semi-local KS-DFT binding energies of molecules without\nartificial symmetry breaking.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:38:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13546","submitter":"Allan Zhou","authors":"Allan Zhou, Kaien Yang, Yiding Jiang, Kaylee Burns, Winnie Xu, Samuel\n  Sokota, J. Zico Kolter, Chelsea Finn","title":"Neural Functional Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent success of neural networks as implicit representation of data has\ndriven growing interest in neural functionals: models that can process other\nneural networks as input by operating directly over their weight spaces.\nNevertheless, constructing expressive and efficient neural functional\narchitectures that can handle high-dimensional weight-space objects remains\nchallenging. This paper uses the attention mechanism to define a novel set of\npermutation equivariant weight-space layers and composes them into deep\nequivariant models called neural functional Transformers (NFTs). NFTs respect\nweight-space permutation symmetries while incorporating the advantages of\nattention, which have exhibited remarkable success across multiple domains. In\nexperiments processing the weights of feedforward MLPs and CNNs, we find that\nNFTs match or exceed the performance of prior weight-space methods. We also\nleverage NFTs to develop Inr2Array, a novel method for computing permutation\ninvariant latent representations from the weights of implicit neural\nrepresentations (INRs). Our proposed method improves INR classification\naccuracy by up to $+17\\%$ over existing methods. We provide an implementation\nof our layers at https://github.com/AllanYangZhou/nfn.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:38:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13547","submitter":"Haoqi Zheng","authors":"Haoqi Zheng, Qihuang Zhong, Liang Ding, Zhiliang Tian, Xin Niu,\n  Dongsheng Li, Dacheng Tao","title":"Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot\n  Text Classification Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Text classification tasks often encounter few shot scenarios with limited\nlabeled data, and addressing data scarcity is crucial. Data augmentation with\nmixup has shown to be effective on various text classification tasks. However,\nmost of the mixup methods do not consider the varying degree of learning\ndifficulty in different stages of training and generate new samples with one\nhot labels, resulting in the model over confidence. In this paper, we propose a\nself evolution learning (SE) based mixup approach for data augmentation in text\nclassification, which can generate more adaptive and model friendly pesudo\nsamples for the model training. SE focuses on the variation of the model's\nlearning ability. To alleviate the model confidence, we introduce a novel\ninstance specific label smoothing approach, which linearly interpolates the\nmodel's output and one hot labels of the original samples to generate new soft\nfor label mixing up. Through experimental analysis, in addition to improving\nclassification accuracy, we demonstrate that SE also enhances the model's\ngeneralize ability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:43:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13548","submitter":"Chun Pong Lau","authors":"Chun Pong Lau, Jiang Liu, Rama Chellappa","title":"Attribute-Guided Encryption with Facial Texture Masking","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The increasingly pervasive facial recognition (FR) systems raise serious\nconcerns about personal privacy, especially for billions of users who have\npublicly shared their photos on social media. Several attempts have been made\nto protect individuals from unauthorized FR systems utilizing adversarial\nattacks to generate encrypted face images to protect users from being\nidentified by FR systems. However, existing methods suffer from poor visual\nquality or low attack success rates, which limit their usability in practice.\nIn this paper, we propose Attribute Guided Encryption with Facial Texture\nMasking (AGE-FTM) that performs a dual manifold adversarial attack on FR\nsystems to achieve both good visual quality and high black box attack success\nrates. In particular, AGE-FTM utilizes a high fidelity generative adversarial\nnetwork (GAN) to generate natural on-manifold adversarial samples by modifying\nfacial attributes, and performs the facial texture masking attack to generate\nimperceptible off-manifold adversarial samples. Extensive experiments on the\nCelebA-HQ dataset demonstrate that our proposed method produces more\nnatural-looking encrypted images than state-of-the-art methods while achieving\ncompetitive attack performance. We further evaluate the effectiveness of\nAGE-FTM in the real world using a commercial FR API and validate its usefulness\nin practice through an user study.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:50:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13549","submitter":"Yue-Wen Fang Dr.","authors":"Rui-Qi Wang, Tianmin Lei, Yue-Wen Fang","title":"First-principles design of ferromagnetic monolayer MnO$_2$ at the\n  complex interface","comments":"24 pages, 7 figures","journal-ref":"Physica Scripta (2023)","doi":"10.1088/1402-4896/acd7b3","report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rapidly increasing interest in low-dimensional materials is driven by the\nemerging requirement to develop nanoscale\n  solid-state devices with novel functional properties that are not available\nin three-dimensional bulk phases.\n  Among the well-known low-dimensional systems, complex transition metal oxide\ninterface holds promise for broad\n  applications in electronic and spintronics devices. Herein, intriguing\nmetal-insulator and\n  ferromagnetic-antiferromagnetic transitions are achieved in monolayer MnO$_2$\nthat is sandwiched into\n  SrTiO$_3$-based heterointerface systems through interface engineering.\n  By using first-principles calculations, we modeled three types of\nSrTiO$_3$-based heterointerface systems with different interface terminations\nand performed a comparative study on the spin-dependent magnetic and electronic\nproperties that are established in the confined MnO$_2$ monolayer.\nFirst-principles study predicts that metal-insulator transition and magnetic\ntransition in the monolayer MnO$_2$ are independent on the thickness of capping\nlayers. Moreover, 100$\\%$ spin-polarized two-dimensional electron gases\naccompanied by robust room temperature magnetism are uncovered in the monolayer\nMnO$_2$. Not only is the buried MnO$_2$ monolayer a new interface phase of\nfundamental physical interest, but it is also a promising candidate material\nfor nanoscale spintronics applications. Our study suggests interface\nengineering at complex oxide interfaces is an alternative approach to designing\nhigh-performance two-dimensional materials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:51:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13550","submitter":"Daichi Kashino","authors":"Daichi Kashino, Simon J. Lilly, Robert A. Simcoe, Rongmon Bordoloi,\n  Ruari Mackenzie, Jorryt Matthee and Anna-Christina Eilers","title":"Compact [C II] emitters around a C IV absorption complex at redshift 5.7","comments":"Published in Nature on 10 May 2023; authors' version; link to the\n  paper: https://www.nature.com/articles/s41586-023-05901-3","journal-ref":"Nature 617, 261-264 (2023)","doi":"10.1038/s41586-023-05901-3","report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The physical conditions of the circumgalactic medium are probed by\nintervening absorption-line systems in the spectrum of background quasi-stellar\nobjects out to the epoch of cosmic reionization. A correlation between the\nionization state of the absorbing gas and the nature of the nearby galaxies has\nbeen suggested by the sources detected either in Lyalpha or [C ii] 158 m near\nto respectively highly-ionized and neutral absorbers. This is also likely\nlinked to the global changes in the incidence of absorption systems of\ndifferent types and the process of cosmic reionization. Here we report the\ndetection of two [C ii]-emitting galaxies at redshift $z \\sim 5.7$ that are\nassociated with a complex high-ionization C iv absorption system. These objects\nare part of an overdensity of galaxies and have compact sizes (< 2.4 kpc) and\nnarrow line widths (FWHM $\\sim$ 62--64 km s-1). Hydrodynamic simulations\npredict that similar narrow [C ii] emission may arise from the heating of small\n($\\lesssim$ 3 kpc) clumps of cold neutral medium or a compact photodissociation\nregion. The lack of counterparts in the rest-frame ultraviolet indicates severe\nobscuration of the sources that are exciting the [C ii] emission. These results\nmay suggest a connection between the properties of the [C ii] emission, the\nrare overdensity of galaxies and the unusual high ionization state of the gas\nin this region.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:53:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13551","submitter":"Yiwei Wang","authors":"Yiwei Wang, Bryan Hooi, Fei Wang, Yujun Cai, Yuxuan Liang, Wenxuan\n  Zhou, Jing Tang, Manjuan Duan, Muhao Chen","title":"How Fragile is Relation Extraction under Entity Replacements?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Relation extraction (RE) aims to extract the relations between entity names\nfrom the textual context. In principle, textual context determines the\nground-truth relation and the RE models should be able to correctly identify\nthe relations reflected by the textual context. However, existing work has\nfound that the RE models memorize the entity name patterns to make RE\npredictions while ignoring the textual context. This motivates us to raise the\nquestion: ``are RE models robust to the entity replacements?'' In this work, we\noperate the random and type-constrained entity replacements over the RE\ninstances in TACRED and evaluate the state-of-the-art RE models under the\nentity replacements. We observe the 30\\% - 50\\% F1 score drops on the\nstate-of-the-art RE models under entity replacements. These results suggest\nthat we need more efforts to develop effective RE models robust to entity\nreplacements. We release the source code at\nhttps://github.com/wangywUST/RobustRE.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:53:32 GMT"},{"version":"v2","created":"Tue, 30 May 2023 02:25:53 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13552","submitter":"Russell Tsuchida PhD","authors":"Russell Tsuchida and Cheng Soon Ong and Dino Sejdinovic","title":"Squared Neural Families: A New Class of Tractable Density Models","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Flexible models for probability distributions are an essential ingredient in\nmany machine learning tasks. We develop and investigate a new class of\nprobability distributions, which we call a Squared Neural Family (SNEFY),\nformed by squaring the 2-norm of a neural network and normalising it with\nrespect to a base measure. Following the reasoning similar to the well\nestablished connections between infinitely wide neural networks and Gaussian\nprocesses, we show that SNEFYs admit a closed form normalising constants in\nmany cases of interest, thereby resulting in flexible yet fully tractable\ndensity models. SNEFYs strictly generalise classical exponential families, are\nclosed under conditioning, and have tractable marginal distributions. Their\nutility is illustrated on a variety of density estimation and conditional\ndensity estimation tasks. Software available at\nhttps://github.com/RussellTsuchida/snefy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:56:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13553","submitter":"Wei Chen","authors":"Lei Guo, Wei Chen, Yuxuan Sun, Bo Ai","title":"Joint Device-Edge Digital Semantic Communication with Adaptive Network\n  Split and Learned Non-Linear Quantization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Semantic communication, an intelligent communication paradigm that aims to\ntransmit useful information in the semantic domain, is facilitated by deep\nlearning techniques. Although robust semantic features can be learned and\ntransmitted in an analog fashion, it poses new challenges to hardware,\nprotocol, and encryption. In this paper, we propose a digital semantic\ncommunication system, which consists of an encoding network deployed on a\nresource-limited device and a decoding network deployed at the edge. To acquire\nbetter semantic representation for digital transmission, a novel non-linear\nquantization module is proposed with the trainable quantization levels that\nefficiently quantifies semantic features. Additionally, structured pruning by a\nsparse scaling vector is incorporated to reduce the dimension of the\ntransmitted features. We also introduce a semantic learning loss (SLL) function\nto reduce semantic error. To adapt to various channel conditions and inputs\nunder constraints of communication and computing resources, a policy network is\ndesigned to adaptively choose the split point and the dimension of the\ntransmitted semantic features. Experiments using the CIFAR-10 dataset for image\nclassification are employed to evaluate the proposed digital semantic\ncommunication network, and ablation studies are conducted to assess the\nproposed modules including the quantization module, structured pruning and SLL.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:58:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13554","submitter":"Hang Yuan","authors":"Hang Yuan","title":"Family Floer SYZ conjecture for $A_n$ singularity","comments":"53 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math-ph math.DG math.MP math.RT math.SG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We resolve a mathematically precise SYZ conjecture for $A_n$ singularity by\nbuilding a quantum-corrected T-duality between two singular torus fibrations\nrelated to the Kahler geometry of the $A_n$-smoothing and the Berkovich\ngeometry of the $A_n$-resolution, respectively. Our approach involves heavy\ncomputations that embody a non-archimedean version of the partition of unity,\nand it confirms the strategy that patching verified local singularity models\nbrings global SYZ conjecture solutions (like K3 surfaces) within reach. There\nis also remarkably explicit extra evidence concerning the collision of singular\nfibers and braid group actions. On one hand, we address the central challenge\nof matching SYZ singular loci identified by Joyce. In reality, we construct not\nmerely an isolated SYZ mirror fibration partner, but a parameter-dependent one\nthat always keeps the matching singular loci plus integral affine structure,\neven when the collision of singular fibers occurs. On the other hand, our SYZ\nresult surprisingly displays a visible tie, regardless of the parameter choice,\nbetween the $(A_n)$-configuration of Lagrangian spheres occurred as vanishing\ncycles in the $A_n$-smoothing and the exceptional locus of rational\n$(-2)$-curves in the $A_n$-resolution. It closely aligns with the celebrated\nworks of Khovanov, Seidel, and Thomas from around 20 years ago in a somewhat\ndistant subject, providing geometric evidence for the family Floer functor\napproach explored by Abouzaid and Fukaya. Intriguingly, these discoveries use\ncertain explicit realizations by order statistics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:59:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13555","submitter":"Jackson Morgan","authors":"J. P. Morgan, Ilham Variansyah, Todd S. Palmer, Kyle E. Niemeyer","title":"Exploring One-Cell Inversion Method for Transient Transport on GPU","comments":"11 pages, 4 figures, M\\&C 2023 ANS conference","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  To find deterministic solutions to the transient $S_N$ neutron transport\nequation, iterative schemes are typically used to treat the scattering (and\nfission) source terms. We explore the one-cell inversion iteration scheme to do\nthis on the GPU and make comparisons to a source iteration scheme. We examine\nconvergence behavior, through the analysis of spectral radii, of both one-cell\ninversion and source iterations. To further boost the GPU parallel efficiency,\nwe derive a higher-order discretization method, simple corner balance (in\nspace) and multiple balance (in time), to add more work to the threads and gain\naccuracy. Fourier analysis on this higher-order numerical method shows that it\nis unconditionally stable, but it can produce negative flux alterations that\nare critically damped through time. We explore a whole-problem (in all angle\nand all cell) sparse linear algebra framework, for both iterative schemes, to\nquickly produce performant code for GPUs. Despite one-cell inversion requiring\nadditional iterations to convergence, those iterations can be done faster to\nprovide a significant speedup over source iteration in quadrature sets at or\nbelow $S_{128}$. Going forward we will produce a two-dimensional implementation\nof this code to experiment with memory and performance impacts of a\nwhole-problem framework including methods of synthetic acceleration and\npre-conditioners for this scheme, then we will begin making direct comparisons\nto traditionally implemented source iteration in production code.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:59:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13556","submitter":"Maofan Yin","authors":"Dahlia Malkhi, Maofan Yin","title":"Lessons from HotStuff","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This article will take you on a journey to the core of blockchains, their\nByzantine consensus engine, where HotStuff emerged as a new algorithmic\nfoundation for the classical Byzantine generals consensus problem.\n  The first part of the article underscores the theoretical advances HotStuff\nenabled, including several models in which HotStuff-based solutions closed\nproblems which were opened for decades.\n  The second part focuses on HotStuff performance in real life setting, where\nits simplicity drove adoption of HotStuff as the golden standard for blockchain\ndesign, and many variants and improvements built on top of it.\n  Both parts of this document are meant to describe lessons drawn from HotStuff\nas well as dispel certain myths.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:59:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13557","submitter":"Kazuya Shinjo","authors":"Kazuya Shinjo, Shigetoshi Sota, Seiji Yunoki, and Takami Tohyama","title":"Spin loop-current textures in the Hubbard models","comments":"13 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent experimental observations of loop current in Sr$_{2}$IrO$_{4}$,\nYBa$_{2}$Cu$_{3}$O$_{7}$, and Sr$_{14}$Cu$_{24}$O$_{41}$ have inspired a\ntheoretical study that broadly redefines loop current as a manifestation of\nquantum liquid crystals. Using the density-matrix renormalization group method,\nhere we investigate the emergence of spin loop-current (sLC) textures in\ncarrier-doped (i) excitonic insulators, (ii) orbital-selective Mott insulators,\nand (iii) two-dimensional Mott insulators, modeled by a two-orbital Hubbard\nmodel on a ladder lattice in (i) and (ii) and a single-orbital Hubbard model on\na square lattice in (iii). Calculating the spatial distribution of spin current\naround a bond to which a pinning field is applied, we find conditions for\nlonger-ranged sLC correlations. In system (i), using typical sets of model\nparameters for Pr$_{0.5}$Ca$_{0.5}$CoO$_{3}$, we find that a sLC texture\nappears near half filling, associated with an excitonic condensation in a spin\nchannel. In system (ii), using typical sets of model parameters for\nBaFe$_{2}$Se$_{3}$, we find that a sLC texture appears at electron fillings\nwhere a block-type antiferromagnetism develops. In system (iii), introducing a\nnext-nearest-neighbor hopping $t'\\sim -0.25$ (in unit of the nearest neighbor\nhopping) suggested for high-$T_\\text{c}$ cuprates, we find that an axial-sLC\ntexture emerges at hole-carrier density $\\delta=0.125$, where the charge stripe\nsimultaneously appears.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:04:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13558","submitter":"Sean Monahan","authors":"Sean Monahan","title":"An overview of horospherical varieties and coloured fans","comments":"42 pages, comments/questions welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We provide an overview of the combinatorial theory of horospherical varieties\nvia coloured fans, a generalization of the combinatorial theory of toric\nvarieties via fans.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:06:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13559","submitter":"Christopher Thomas","authors":"Christopher Thomas, S\\'ebastien Burdin, Claudine Lacroix","title":"Metamagnetic transition in the two $f$ orbitals Kondo lattice model","comments":"15 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we study the effects of a transverse magnetic field in a Kondo\nlattice model with two $f$ orbitals interacting with the conduction electrons.\nThe $f$ electrons that are present on the same site interact through Hund's\ncoupling, while on neighboring sites they interact through intersite exchange.\nWe consider here that part of $f$ electrons are localized (orbital 1) while\nanother part (orbital 2) are delocalized, as it is frequent in uranium systems.\nThen, only electrons in the localized orbital 1 interact through exchange\ninteraction with the neighboring ones, while electrons in orbital 2 are coupled\nwith conduction electrons through a Kondo interaction. We obtain a solution\nwhere ferromagnetism and Kondo effect coexist for small values of an applied\ntransverse magnetic field for $T\\rightarrow0$. Increasing the transverse field,\ntwo situations can be obtained when Kondo coupling vanishes: first, a\nmetamagnetic transition occurs just before or at the same time of the fully\npolarized state, and second, a metamagnetic transition occurs when the spins\nare already pointing out along the magnetic field.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:11:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13560","submitter":"Konstantin Makarychev","authors":"Sayak Chakrabarty and Konstantin Makarychev","title":"Single-Pass Pivot Algorithm for Correlation Clustering. Keep it simple!","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that a simple single-pass semi-streaming variant of the Pivot\nalgorithm for Correlation Clustering gives a (3 + {\\epsilon})-approximation\nusing O(n/{\\epsilon}) words of memory. This is a slight improvement over the\nrecent results of Cambus, Kuhn, Lindy, Pai, and Uitto, who gave a (3 +\n{\\epsilon})-approximation using O(n log n) words of memory, and Behnezhad,\nCharikar, Ma, and Tan, who gave a 5-approximation using O(n) words of memory.\nOne of the main contributions of this paper is that both the algorithm and its\nanalysis are very simple, and also the algorithm is easy to implement.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:15:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13561","submitter":"John Cardy","authors":"John Cardy","title":"Fluids in random media and dimensional augmentation","comments":"v2: 5 pages, new title, new results for the Ising lattice gas","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cond-mat.dis-nn","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a solution to the puzzle of dimensional reduction in the random\nfield Ising model, inverting the question and asking: to what random problem in\n$D=d+2$ dimensions does a pure system in $d$ dimensions correspond? We consider\ntwo models: a continuum binary fluid, and a lattice gas which maps exactly onto\nan Ising model. In both cases we show that the mean density and other\nobservables are equal to those of a similar model in $D$ dimensions, but with\ninteractions and correlated disorder in the extra two dimensions of range\n$\\propto l$, in the limit as $l\\to\\infty$. There is no conflict with rigorous\nresults that the finite range model with locally correlated disorder orders in\n$D=3$. Our arguments avoid the use of replicas and perturbative field theory,\ninstead being based on convergent cluster expansions, which, for the lattice\ngas, may be extended all the way to the critical point by virtue of the\nLee-Yang theorem. Although the results may be viewed as a consequence of\nParisi-Sourlas supersymmetry, they follow more directly from Kirchhoff's\nmatrix-tree theorem.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:21:35 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 10:32:59 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.13562","submitter":"Nicholas Alonso","authors":"Nick Alonso, Jeff Krichmar, Emre Neftci","title":"Understanding and Improving Optimization in Predictive Coding Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Backpropagation (BP), the standard learning algorithm for artificial neural\nnetworks, is often considered biologically implausible. In contrast, the\nstandard learning algorithm for predictive coding (PC) models in neuroscience,\nknown as the inference learning algorithm (IL), is a promising, bio-plausible\nalternative. However, several challenges and questions hinder IL's application\nto real-world problems. For example, IL is computationally demanding, and\nwithout memory-intensive optimizers like Adam, IL may converge to poor local\nminima. Moreover, although IL can reduce loss more quickly than BP, the reasons\nfor these speedups or their robustness remains unclear. In this paper, we\ntackle these challenges by 1) altering the standard implementation of PC\ncircuits to substantially reduce computation, 2) developing a novel optimizer\nthat improves the convergence of IL without increasing memory usage, and 3)\nestablishing theoretical results that help elucidate the conditions under which\nIL is sensitive to second and higher-order information.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:32:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13563","submitter":"Daliang Ouyang","authors":"Daliang Ouyang, Su He, Guozhong Zhang, Mingzhu Luo, Huaiyong Guo, Jian\n  Zhan, Zhijie Huang","title":"Efficient Multi-Scale Attention Module with Cross-Spatial Learning","comments":"Accepted to ICASSP2023","journal-ref":null,"doi":"10.1109/ICASSP49357.2023.10096516","report-no":"originally announced March 2023","categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Remarkable effectiveness of the channel or spatial attention mechanisms for\nproducing more discernible feature representation are illustrated in various\ncomputer vision tasks. However, modeling the cross-channel relationships with\nchannel dimensionality reduction may bring side effect in extracting deep\nvisual representations. In this paper, a novel efficient multi-scale attention\n(EMA) module is proposed. Focusing on retaining the information on per channel\nand decreasing the computational overhead, we reshape the partly channels into\nthe batch dimensions and group the channel dimensions into multiple\nsub-features which make the spatial semantic features well-distributed inside\neach feature group. Specifically, apart from encoding the global information to\nre-calibrate the channel-wise weight in each parallel branch, the output\nfeatures of the two parallel branches are further aggregated by a\ncross-dimension interaction for capturing pixel-level pairwise relationship. We\nconduct extensive ablation studies and experiments on image classification and\nobject detection tasks with popular benchmarks (e.g., CIFAR-100, ImageNet-1k,\nMS COCO and VisDrone2019) for evaluating its performance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:35:47 GMT"},{"version":"v2","created":"Tue, 6 Jun 2023 10:07:05 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.13564","submitter":"Se Kwon Kim","authors":"Se Kwon Kim and Suk Bum Chung","title":"Current-driven motion of magnetic topological defects in ferromagnetic\n  superconductors","comments":"14 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent years have seen a number of instances where magnetism and\nsuperconductivity intrinsically coexist. Our focus is on the case where\nspin-triplet superconductivity arises out of ferromagnetism, and we make a\nhydrodynamic analysis of the effect of a charge supercurrent on magnetic\ntopological defects like domain walls and merons. We find that the emergent\nelectromagnetic field that arises out of the superconducting order parameter\nprovides a description for not only the physical quantities such as the local\nenergy flux density and the interaction between current and defects but also\nthe energy dissipation through magnetic dynamics of the Gilbert damping, which\nbecomes more prominent compared to the normal state as superconductivity\nattenuates the energy dissipation through the charge sector. In particular, we\nreveal that the current-induced dynamics of domain walls and merons in the\npresence of the Gilbert damping give rise to the nonsingular $4\\pi$ and $2\\pi$\nphase slips, respectively, revealing the intertwined dynamics of spin and\ncharge degrees of freedom in ferromagnetic superconductors.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:38:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13565","submitter":"Sangli Teng","authors":"Sangli Teng, Ashkan Jasour, Ram Vasudevan, Maani Ghaffari","title":"Convex Geometric Motion Planning on Lie Groups via Moment Relaxation","comments":"Accepted to Robotics: Science and Systems (RSS), 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper reports a novel result: with proper robot models on matrix Lie\ngroups, one can formulate the kinodynamic motion planning problem for rigid\nbody systems as \\emph{exact} polynomial optimization problems that can be\nrelaxed as semidefinite programming (SDP). Due to the nonlinear rigid body\ndynamics, the motion planning problem for rigid body systems is nonconvex.\nExisting global optimization-based methods do not properly deal with the\nconfiguration space of the 3D rigid body; thus, they do not scale well to\nlong-horizon planning problems. We use Lie groups as the configuration space in\nour formulation and apply the variational integrator to formulate the forced\nrigid body systems as quadratic polynomials. Then we leverage Lasserre's\nhierarchy to obtain the globally optimal solution via SDP. By constructing the\nmotion planning problem in a sparse manner, the results show that the proposed\nalgorithm has \\emph{linear} complexity with respect to the planning horizon.\nThis paper demonstrates the proposed method can provide rank-one optimal\nsolutions at relaxation order two for most of the testing cases of 1) 3D drone\nlanding using the full dynamics model and 2) inverse kinematics for serial\nmanipulators.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:42:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13566","submitter":"Shuang Zhang","authors":"Shaojie Ma, Hongwei Jia, Yangang Bi, Shangqiang Ning, Fuxin Guan,\n  Hongchao Liu, Chenjie Wang, Shuang Zhang","title":"Gauge Field Induced Chiral Zero Mode in Five-dimensional Yang Monopole\n  Metamaterials","comments":"64 pages including supplementary material, to appear in Physical\n  Review Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Owing to the chirality of Weyl nodes characterized by the first Chern number,\na Weyl system supports one-way chiral zero modes under a magnetic field, which\nunderlies the celebrated chiral anomaly. As a generalization of Weyl nodes from\nthree-dimensional to five-dimensional physical systems, Yang monopoles are\ntopological singularities carrying nonzero second-order Chern numbers c2 = +1\nor -1. Here, we couple a Yang monopole with an external gauge field using an\ninhomogeneous Yang monopole metamaterial, and experimentally demonstrate the\nexistence of a gapless chiral zero mode, where the judiciously designed\nmetallic helical structures and the corresponding effective antisymmetric\nbianisotropic terms provide the means for controlling gauge fields in a\nsynthetic five-dimensional space. This zeroth mode is found to originate from\nthe coupling between the second Chern singularity and a generalized 4-form\ngauge field - the wedge product of the magnetic field with itself. This\ngeneralization reveals intrinsic connections between physical systems of\ndifferent dimensions, while a higher dimensional system exhibits much richer\nsupersymmetric structures in Landau level degeneracy due to the internal\ndegrees of freedom. Our study offers the possibility of controlling\nelectromagnetic waves by leveraging the concept of higher-order and\nhigher-dimensional topological phenomena.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:45:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13567","submitter":"Bohan Wu","authors":"Bohan Wu, Roberto Martin-Martin, Li Fei-Fei","title":"M-EMBER: Tackling Long-Horizon Mobile Manipulation via Factorized Domain\n  Transfer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper, we propose a method to create visuomotor mobile manipulation\nsolutions for long-horizon activities. We propose to leverage the recent\nadvances in simulation to train visual solutions for mobile manipulation. While\nprevious works have shown success applying this procedure to autonomous visual\nnavigation and stationary manipulation, applying it to long-horizon visuomotor\nmobile manipulation is still an open challenge that demands both perceptual and\ncompositional generalization of multiple skills. In this work, we develop\nMobile-EMBER, or M-EMBER, a factorized method that decomposes a long-horizon\nmobile manipulation activity into a repertoire of primitive visual skills,\nreinforcement-learns each skill, and composes these skills to a long-horizon\nmobile manipulation activity. On a mobile manipulation robot, we find that\nM-EMBER completes a long-horizon mobile manipulation activity,\ncleaning_kitchen, achieving a 53% success rate. This requires successfully\nplanning and executing five factorized, learned visual skills.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:53:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13568","submitter":"Pei Zhang","authors":"Pei Zhang, Nur Anisah Mohamed, Adriana Irawati Nur Ibrahim","title":"Anticipated BSDEs driven by fractional Brownian motion with time-delayed\n  generator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper discusses a new type of anticipated backward stochastic\ndifferential equation with a time-delayed generator (DABSDEs, for short) driven\nby fractional Brownian motion, also known as fractional BSDEs, with Hurst\nparameter $H\\in(1/2,1)$, which extends the results of the anticipated backward\nstochastic differential equation to the case of the drive is fractional\nBrownian motion instead of a standard Brownian motion and in which the\ngenerator considers not only the present and future times but also the past\ntime. By using the fixed point theorem, we will demonstrate the existence and\nuniqueness of the solutions to these equations. Moreover, we shall establish a\ncomparison theorem for the solutions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:53:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13569","submitter":"Edward Miller","authors":"Sylvain E. Cappell and Edward Y. Miller","title":"The Spectral Geometry of the Mesh Matrices of Graphs","comments":"21 Pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.GT math.SP","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The mesh matrix $Mesh(G,T_0)$ of a connected finite graph\n$G=(V(G),E(G))=(vertices, edges) \\ of \\ G$ of with respect to a choice of a\nspanning tree $T_0 \\subset G$ is defined and studied. It was introduced by\nTrent \\cite{Trent1,Trent2}. Its characteristic polynomial $det(X \\cdot Id\n-Mesh(G,T_0))$ is shown to equal $\\Sigma_{j=0}^{N} \\ (-1)^j \\ ST_{j}(G,T_0)\\\n(X-1)^{N-j} \\ (\\star)$ \\ where $ST_j(G,T_0)$ is the number of spanning trees of\n$G$ meeting $E(G-T_0)$ in j edges and $N=|E(G-T_0)|$. As a consequence, there\nare Tutte-type deletion-contraction formulae for computing this polynomial.\nAdditionally, $Mesh(G,T_0) -Id$ is of the special form $Y^t \\cdot Y$; so the\neigenvalues of the mesh matrix $Mesh(G,T_0)$ are all real and are furthermore\nbe shown to be $\\ge +1$. It is shown that $Y \\cdot Y^t$, called the mesh\nLaplacian, is a generalization of the standard graph Kirchhoff Laplacian\n$\\Delta(H)= Deg -Adj$ of a graph $H$.For example, $(\\star)$ generalizes the all\nminors matrix tree theorem for graphs $H$ and gives a deletion-contraction\nformula for the characteristic polynomial of $\\Delta(H)$. This generalization\nis explored in some detail. The smallest positive eigenvalue of the mesh\nLaplacian, a measure of flux, is estimated, thus extending the classical\ninequality for the Kirchoff Laplacian of graphs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:54:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13570","submitter":"Xiaoshui Huang","authors":"Xiaoshui Huang, Guofeng Mei, Jian Zhang","title":"Cross-source Point Cloud Registration: Challenges, Progress and\n  Prospects","comments":"Accepted by Neurocomputing 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The emerging topic of cross-source point cloud (CSPC) registration has\nattracted increasing attention with the fast development background of 3D\nsensor technologies. Different from the conventional same-source point clouds\nthat focus on data from same kind of 3D sensor (e.g., Kinect), CSPCs come from\ndifferent kinds of 3D sensors (e.g., Kinect and { LiDAR}). CSPC registration\ngeneralizes the requirement of data acquisition from same-source to different\nsources, which leads to generalized applications and combines the advantages of\nmultiple sensors. In this paper, we provide a systematic review on CSPC\nregistration. We first present the characteristics of CSPC, and then summarize\nthe key challenges in this research area, followed by the corresponding\nresearch progress consisting of the most recent and representative developments\non this topic. Finally, we discuss the important research directions in this\nvibrant area and explain the role in several application fields.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:03:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13571","submitter":"Ta-Chung Chi","authors":"Ta-Chung Chi and Ting-Han Fan and Li-Wei Chen and Alexander I.\n  Rudnicky and Peter J. Ramadge","title":"Latent Positional Information is in the Self-Attention Variance of\n  Transformer Language Models Without Positional Embeddings","comments":"Accepted by ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The use of positional embeddings in transformer language models is widely\naccepted. However, recent research has called into question the necessity of\nsuch embeddings. We further extend this inquiry by demonstrating that a\nrandomly initialized and frozen transformer language model, devoid of\npositional embeddings, inherently encodes strong positional information through\nthe shrinkage of self-attention variance. To quantify this variance, we derive\nthe underlying distribution of each step within a transformer layer. Through\nempirical validation using a fully pretrained model, we show that the variance\nshrinkage effect still persists after extensive gradient updates. Our findings\nserve to justify the decision to discard positional embeddings and thus\nfacilitate more efficient pretraining of transformer language models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:03:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13573","submitter":"Jintang Li","authors":"Sheng Tian, Jihai Dong, Jintang Li, Wenlong Zhao, Xiaolong Xu, Baokun\n  wang, Bowen Song, Changhua Meng, Tianyi Zhang, Liang Chen","title":"SAD: Semi-Supervised Anomaly Detection on Dynamic Graphs","comments":"Accepted to IJCAI'23. Code will be available at\n  https://github.com/D10Andy/SAD","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Anomaly detection aims to distinguish abnormal instances that deviate\nsignificantly from the majority of benign ones. As instances that appear in the\nreal world are naturally connected and can be represented with graphs, graph\nneural networks become increasingly popular in tackling the anomaly detection\nproblem. Despite the promising results, research on anomaly detection has\nalmost exclusively focused on static graphs while the mining of anomalous\npatterns from dynamic graphs is rarely studied but has significant application\nvalue. In addition, anomaly detection is typically tackled from semi-supervised\nperspectives due to the lack of sufficient labeled data. However, most proposed\nmethods are limited to merely exploiting labeled data, leaving a large number\nof unlabeled samples unexplored. In this work, we present semi-supervised\nanomaly detection (SAD), an end-to-end framework for anomaly detection on\ndynamic graphs. By a combination of a time-equipped memory bank and a\npseudo-label contrastive learning module, SAD is able to fully exploit the\npotential of large unlabeled samples and uncover underlying anomalies on\nevolving graph streams. Extensive experiments on four real-world datasets\ndemonstrate that SAD efficiently discovers anomalies from dynamic graphs and\noutperforms existing advanced methods even when provided with only little\nlabeled data.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:05:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13574","submitter":"Wenbo Shi","authors":"Wenbo Shi and Robert Malaney","title":"Error-Mitigated Quantum Routing on Noisy Devices","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With sub-threshold quantum error correction on quantum hardware still out of\nreach, quantum error mitigation methods are currently deemed an attractive\noption for implementing certain applications on near-term noisy quantum\ndevices. One such application is quantum routing - the ability to map an\nincoming quantum signal into a superposition of paths. In this work, we use a\n7-qubit IBM quantum device to experimentally deploy two promising quantum error\nmitigation methods, Zero-Noise Extrapolation (ZNE) and Probabilistic Error\nCancellation (PEC), in the context of quantum routing. Importantly, beyond\ninvestigating the improved performance of quantum routing via ZNE and PEC\nseparately, we also investigate the routing performance provided by the\nconcatenation of these two error-mitigation methods. Our experimental results\ndemonstrate that such concatenation leads a very significant performance\nimprovement relative to implementation with no error mitigation. Indeed, an\nalmost perfect performance in terms of fidelity of the output entangled paths\nis found. These new results reveal that with concatenated quantum\nerror-mitigation embedded, useful quantum routing becomes feasible on current\ndevices without the need for quantum error correction - opening up a potential\nimplementation pathway to other applications that utilize a superposition of\ncommunication links.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:08:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13575","submitter":"Beichen Wang","authors":"Shuman Sun, Beichen Wang, Kaikai Liu, Mark Harrington, Fatemehsadat\n  Tabatabaei, Ruxuan Liu, Jiawei Wang, Samin Hanifi, Jesse S. Morgan, Mandana\n  Jahanbozorgi, Zijiao Yang, Steven Bowers, Paul Morton, Karl Nelson, Andreas\n  Beling, Daniel Blumenthal, Xu Yi","title":"Integrated optical frequency division for stable microwave and mmWave\n  generation","comments":"8 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The generation of ultra-low noise microwave and mmWave in miniaturized,\nchip-based platforms can transform communication, radar, and sensing systems.\nOptical frequency division that leverages optical references and optical\nfrequency combs has emerged as a powerful technique to generate microwaves with\nsuperior spectral purity than any other approaches. We demonstrate a\nminiaturized optical frequency division system that can potentially transfer\nthe approach to a CMOS-compatible integrated photonic platform. Phase stability\nis provided by a large-mode-volume, planar-waveguide-based optical reference\ncoil cavity and is divided down from optical to mmWave frequency by using\nsoliton microcombs generated in a waveguide-coupled microresonator. Besides\nachieving record-low phase noise for integrated photonic microwave/mmWave\noscillators, these devices can be heterogeneously integrated with semiconductor\nlasers, amplifiers, and photodiodes, holding the potential of large-volume,\nlow-cost manufacturing for fundamental and mass-market applications.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:08:14 GMT"},{"version":"v2","created":"Wed, 31 May 2023 01:33:38 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13576","submitter":"Muhammad Saleem","authors":"Shahid Nawaz, Muhammad Saleem, F. V. Kusmartsev, Dalaver H. Anjum","title":"Approach to Data Science with Multiscale Information Theory","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.data-an quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data Science is a multidisciplinary field that plays a crucial role in\nextracting valuable insights and knowledge from large and intricate datasets.\nWithin the realm of Data Science, two fundamental components are Information\nTheory (IT) and Statistical Mechanics (SM), which provide a theoretical\nframework for understanding dataset properties. IT enables efficient storage\nand transmission of information, while SM focuses on the behavior of systems\ncomprising numerous interacting components. In the context of data science, SM\nallows us to model complex interactions among variables within a dataset. By\nleveraging these tools, data scientists can gain a profound understanding of\ndata properties, leading to the development of advanced models and algorithms\nfor analysis and interpretation. Consequently, data science has the potential\nto drive accurate predictions and enhance decision-making across various\ndomains, including finance, marketing, healthcare, and scientific research.\n  In this paper, we apply this data science framework to a large and intricate\nquantum mechanical system composed of particles. Our research demonstrates that\nthe dynamic and probabilistic nature of such systems can be effectively\naddressed using a Multiscale Entropic Dynamics (MED) approach, derived from the\nBoltzmann methods of SM. Through the MED approach, we can describe the system's\ndynamics by formulating a general form of the Nonlinear Schr\\\"odinger equation\nand how it can be applied to various systems with particles and\nquasi-particles, such as electrons, plasmons, polarons, and solitons. By\nemploying this innovative approach, we pave the way for a deeper understanding\nof quantum mechanical systems and their behaviors within complex materials.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:08:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13577","submitter":"Amin Jafarimoghaddam","authors":"Amin Jafarimoghaddam and Manuel Soler","title":"Time-Fuel-Optimal Navigation of a Commercial Aircraft in Cruise with\n  Heading and Throttle Controls using Pontryagin's Maximum Principle","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this research, we consider the commercial aircraft trajectory optimization\nproblem for a general cruise model with arbitrary spatial wind fields to be\nsolved using the Pontryagin maximum principle. The model features two\nfundamental controls, namely, throttle setting (which appears as a singular\ncontrol) and heading angle (appearing as a regular control). For a constrained\nproblem with minimum time-fuel objective, we show that the optimal heading\nangle is fully defined through the classic Zermelo navigation identity. We also\nshow that the optimal throttle setting can be characterized through a complete\nfeedback function. The switching-point algorithm is employed to solve a case\nstudy where we inspect the optimality conditions and graph the optimal controls\ntogether with the optimal state and co-state variables.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:09:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13578","submitter":"Paul Estrada","authors":"R. H. Durisen and Paul. R. Estrada","title":"Large mass inflow rates in Saturn's rings due to ballistic transport and\n  mass loading","comments":"25 pages, 6 figures, Published in Icarus","journal-ref":"Icarus, Volume 400, 2023, article id. 115221","doi":"10.1016/j.icarus.2022.115221 10.1016/j.icarus.2022.115221\n  10.1016/j.icarus.2022.115221","report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The Cassini mission provided key measurements needed to determine the\nabsolute age of Saturn's rings, including the extrinsic micrometeoroid flux at\nSaturn, the volume fraction of non-icy pollutants in the rings, and the total\nring mass. These three factors constrain the ring age to be no more than a few\n100 Myr (Kempf et al., 2023). Observations during the Cassini Grand Finale also\nshowed that the rings are losing mass to the planet at a prodigious rate. Some\nof the mass flux falls as \"ring rain\" at high latitudes. However, the influx in\nring rain is considerably less than the total measured mass influx of 4800 to\n45000 kg/s at lower latitudes (Waite et al., 2018).\n  In addition to polluting the rings, micrometeoroid impacts lead to ballistic\ntransport, the mass and angular momentum transport due to net exchanges of\nmeteoroid impact ejecta. Because the ejecta are predominantly prograde, they\ncarry net angular momentum outward. As a result, ring material drifts inward\ntoward the planet. Here, for the first time, we use a simple model to quantify\nthis radial mass inflow rate for dense rings and find that, for plausible\nchoices of parameters, ballistic transport and mass loading by meteoroids can\nproduce a total inward flux of material in the inner B ring and in the C ring\nthat is on the order of a few x 10^3 to a few x 10^4 kg/s, in agreement with\nmeasurements during the Cassini Grand Finale. From these mass inflow rates, we\nestimate that the remaining ring lifetime is ~15 to 400 Myr. Combining this\nwith a revised pollution age of ~120 Myr, we conclude that Saturn's rings are\nnot only young but ephemeral and probably started their evolution on a similar\ntimescale to their pollution age with an initial mass of one to a few Mimas\nmasses.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:11:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13579","submitter":"Yufan Zhou","authors":"Yufan Zhou, Ruiyi Zhang, Tong Sun, Jinhui Xu","title":"Enhancing Detail Preservation for Customized Text-to-Image Generation: A\n  Regularization-Free Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Recent text-to-image generation models have demonstrated impressive\ncapability of generating text-aligned images with high fidelity. However,\ngenerating images of novel concept provided by the user input image is still a\nchallenging task. To address this problem, researchers have been exploring\nvarious methods for customizing pre-trained text-to-image generation models.\nCurrently, most existing methods for customizing pre-trained text-to-image\ngeneration models involve the use of regularization techniques to prevent\nover-fitting. While regularization will ease the challenge of customization and\nleads to successful content creation with respect to text guidance, it may\nrestrict the model capability, resulting in the loss of detailed information\nand inferior performance. In this work, we propose a novel framework for\ncustomized text-to-image generation without the use of regularization.\nSpecifically, our proposed framework consists of an encoder network and a novel\nsampling method which can tackle the over-fitting problem without the use of\nregularization. With the proposed framework, we are able to customize a\nlarge-scale text-to-image generation model within half a minute on single GPU,\nwith only one image provided by the user. We demonstrate in experiments that\nour proposed framework outperforms existing methods, and preserves more\nfine-grained details.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:14:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13580","submitter":"Marc Delcroix","authors":"Marc Delcroix, Naohiro Tawara, Mireia Diez, Federico Landini, Anna\n  Silnova, Atsunori Ogawa, Tomohiro Nakatani, Lukas Burget, Shoko Araki","title":"Multi-Stream Extension of Variational Bayesian HMM Clustering (MS-VBx)\n  for Combined End-to-End and Vector Clustering-based Diarization","comments":"Accepted at Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Combining end-to-end neural speaker diarization (EEND) with vector clustering\n(VC), known as EEND-VC, has gained interest for leveraging the strengths of\nboth methods. EEND-VC estimates activities and speaker embeddings for all\nspeakers within an audio chunk and uses VC to associate these activities with\nspeaker identities across different chunks. EEND-VC generates thus multiple\nstreams of embeddings, one for each speaker in a chunk. We can cluster these\nembeddings using constrained agglomerative hierarchical clustering (cAHC),\nensuring embeddings from the same chunk belong to different clusters. This\npaper introduces an alternative clustering approach, a multi-stream extension\nof the successful Bayesian HMM clustering of x-vectors (VBx), called MS-VBx.\nExperiments on three datasets demonstrate that MS-VBx outperforms cAHC in\ndiarization and speaker counting performance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:19:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13581","submitter":"Riddhi Swaroop Gupta","authors":"Riddhi S. Gupta, Neereja Sundaresan, Thomas Alexander, Christopher J.\n  Wood, Seth T. Merkel, Michael B. Healy, Marius Hillenbrand, Tomas\n  Jochym-O'Connor, James R. Wootton, Theodore J. Yoder, Andrew W. Cross, Maika\n  Takita and Benjamin J. Brown","title":"Encoding a magic state with beyond break-even fidelity","comments":"10 pages, 7 figures, comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We distill magic states to complete a universal set of fault-tolerant logic\ngates that is needed for large-scale quantum computing. By encoding better\nquality input states for our distillation procedure, we can reduce the\nconsiderable resource cost of producing magic states. We demonstrate an\nerror-suppressed encoding scheme for a two-qubit input magic state, that we\ncall the CZ state, on an array of superconducting qubits. Using a complete set\nof projective logical Pauli measurements, that are also tolerant to a single\ncircuit error, we propose a circuit that demonstrates a magic state prepared\nwith infidelity $(1.87 \\pm 0.16) \\times 10^{-2}$. Additionally, the yield of\nour scheme increases with the use of adaptive circuit elements that are\nconditioned in real time on mid-circuit measurement outcomes. We find our\nresults are consistent with variations of the experiment, including where we\nuse only post-selection in place of adaptive circuits, and where we interrogate\nour output state using quantum state tomography on the data qubits of the code.\nRemarkably, the error-suppressed preparation experiment demonstrates a fidelity\nexceeding that of the preparation of the same unencoded magic-state on any\nsingle pair of physical qubits on the same device.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:19:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13582","submitter":"Yang Chen","authors":"Yang Chen, Vedaant Shah, Alan Ritter","title":"Better Low-Resource Entity Recognition Through Translation and\n  Annotation Fusion","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Pre-trained multilingual language models have enabled significant\nadvancements in cross-lingual transfer. However, these models often exhibit a\nperformance disparity when transferring from high-resource languages to\nlow-resource languages, especially for languages that are underrepresented or\nnot in the pre-training data. Motivated by the superior performance of these\nmodels on high-resource languages compared to low-resource languages, we\nintroduce a Translation-and-fusion framework, which translates low-resource\nlanguage text into a high-resource language for annotation using fully\nsupervised models before fusing the annotations back into the low-resource\nlanguage. Based on this framework, we present TransFusion, a model trained to\nfuse predictions from a high-resource language to make robust predictions on\nlow-resource languages. We evaluate our methods on two low-resource named\nentity recognition (NER) datasets, MasakhaNER2.0 and LORELEI NER, covering 25\nlanguages, and show consistent improvement up to +16 F$_1$ over English\nfine-tuning systems, achieving state-of-the-art performance compared to\nTranslate-train systems. Our analysis depicts the unique advantages of the\nTransFusion method which is robust to translation errors and source language\nprediction errors, and complimentary to adapted multilingual language models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:23:22 GMT"},{"version":"v2","created":"Wed, 24 May 2023 04:20:10 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13583","submitter":"Yuanchao Li","authors":"Yaoting Wang, Yuanchao Li, Peter Bell, Catherine Lai","title":"Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment\n  Analysis and Emotion Recognition","comments":"*Equal contribution","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.MM eess.AS eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fusing multiple modalities for affective computing tasks has proven effective\nfor performance improvement. However, how multimodal fusion works is not well\nunderstood, and its use in the real world usually results in large model sizes.\nIn this work, on sentiment and emotion analysis, we first analyze how the\nsalient affective information in one modality can be affected by the other in\ncrossmodal attention. We find that inter-modal incongruity exists at the latent\nlevel due to crossmodal attention. Based on this finding, we propose a\nlightweight model via Hierarchical Crossmodal Transformer with Modality Gating\n(HCT-MG), which determines a primary modality according to its contribution to\nthe target task and then hierarchically incorporates auxiliary modalities to\nalleviate inter-modal incongruity and reduce information redundancy. The\nexperimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and\nIEMOCAP verifies the efficacy of our approach, showing that it: 1) outperforms\nmajor prior work by achieving competitive results and can successfully\nrecognize hard samples; 2) mitigates the inter-modal incongruity at the latent\nlevel when modalities have mismatched affective tendencies; 3) reduces model\nsize to less than 1M parameters while outperforming existing models of similar\nsizes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:24:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13584","submitter":"Pan Li","authors":"Li Pan, Lv Peizhuo, Chen Kai, Cai Yuling, Xiang Fan, Zhang Shengzhi","title":"Model Stealing Attack against Multi-Exit Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Compared to traditional neural networks with a single exit, a multi-exit\nnetwork has multiple exits that allow for early output from intermediate layers\nof the model, thus bringing significant improvement in computational efficiency\nwhile maintaining similar recognition accuracy. When attempting to steal such\nvaluable models using traditional model stealing attacks, we found that\nconventional methods can only steal the model's classification function while\nfailing to capture its output strategy. This results in a significant decrease\nin computational efficiency for the stolen substitute model, thereby losing the\nadvantages of multi-exit networks.In this paper, we propose the first model\nstealing attack to extract both the model function and output strategy. We\nemploy bayesian changepoint detection to analyze the target model's output\nstrategy and use performance loss and strategy loss to guide the training of\nthe substitute model. Furthermore, we designed a novel output strategy search\nalgorithm that can find the optimal output strategy to maximize the consistency\nbetween the victim model and the substitute model's outputs. Through\nexperiments on multiple mainstream multi-exit networks and benchmark datasets,\nwe thoroughly demonstrates the effectiveness of our method.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:24:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13585","submitter":"Siyuan Wang","authors":"Siyuan Wang, Zhongyu Wei, Meng Han, Zhihao Fan, Haijun Shan, Qi Zhang,\n  Xuanjing Huang","title":"Query Structure Modeling for Inductive Logical Reasoning Over Knowledge\n  Graphs","comments":"11 pages, 2 figures, 8 tables, accepted as a long paper to ACL 203","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Logical reasoning over incomplete knowledge graphs to answer complex logical\nqueries is a challenging task. With the emergence of new entities and relations\nin constantly evolving KGs, inductive logical reasoning over KGs has become a\ncrucial problem. However, previous PLMs-based methods struggle to model the\nlogical structures of complex queries, which limits their ability to generalize\nwithin the same structure. In this paper, we propose a structure-modeled\ntextual encoding framework for inductive logical reasoning over KGs. It encodes\nlinearized query structures and entities using pre-trained language models to\nfind answers. For structure modeling of complex queries, we design stepwise\ninstructions that implicitly prompt PLMs on the execution order of geometric\noperations in each query. We further separately model different geometric\noperations (i.e., projection, intersection, and union) on the representation\nspace using a pre-trained encoder with additional attention and maxout layers\nto enhance structured modeling. We conduct experiments on two inductive logical\nreasoning datasets and three transductive datasets. The results demonstrate the\neffectiveness of our method on logical reasoning over KGs in both inductive and\ntransductive settings.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:25:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13586","submitter":"Abhinendra Singh","authors":"Abhinendra Singh","title":"Hidden hierarchy in the rheology of dense suspensions","comments":"Perspective article under review; Comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft physics.flu-dyn physics.geo-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dense suspensions of fine particles are significant in numerous biological,\nindustrial, and natural phenomena. They also provide an ideal tool to develop\nstatistical mechanics description for out-of-equilibrium systems. Predicting\nthe bulk response of such materials has been challenging since these systems\noften undergo liquid-solid transitions upon a small change in solid\nconcentration or applied loading. Developing an understanding of the mechanisms\nthat drive these phenomena has over the last several years led to a surge in\nresearch activity at the intersection of fluid mechanics, granular materials,\ndriven disordered systems, tribology, and soft condensed matter physics. One\ncentral aspect that emerged is that these phenomena are due to a\nshear-activated or deactivated network of contacts between particles. The\nperspective briefly presents the current state of understanding and challenges\nassociated with relating the flow of material at the bulk scale with the\nmicroscopic physics at the particle scale.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:27:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13587","submitter":"Shui-Jing Tang","authors":"Shui-Jing Tang, Mingjie Zhang, Jialve Sun, Jia-Wei Meng, Xiao Xiong,\n  Qihuang Gong, Dayong Jin, Qi-Fan Yang, Yun-Feng Xiao","title":"Single-particle vibrational spectroscopy using optical microresonators","comments":"15 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vibrational spectroscopy is a ubiquitous technology that derives the species,\nconstituents, and morphology of an object from its natural vibrations. However,\nthe vibrational spectra of mesoscopic particles - including most biological\ncells - have remained hidden from existing technologies. These particles are\nexpected to vibrate faintly at megahertz to gigahertz rates, imposing\nunpractical sensitivity and resolution for current optical and piezoelectric\nspectroscopy. Here we demonstrate the real-time measurement of natural\nvibrations of single mesoscopic particles using an optical microresonator,\nextending the reach of vibrational spectroscopy to a new spectral window.\nConceptually, a spectrum of vibrational modes of the particles is stimulated\nphotoacoustically, and correlated to a high-quality-factor optical resonance\nfor the ultrasensitive readout. Experimentally, this scheme is testified by\nmeasuring mesoscopic particles with different constituents, sizes, and internal\nstructures, showing an unprecedented signal-to-noise ratio of 50 dB and\ndetection bandwidth over 1 GHz. This new technology is further applied for the\nbiomechanical fingerprinting of single microbial cells with different species\nand living states. The present method opens up new avenues to study\nsingle-particle mechanical properties in vibrational degrees of freedom, and\nmay find applications in photoacoustic sensing and imaging, cavity\noptomechanics and biomechanics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:37:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13588","submitter":"Yuka Hashimoto","authors":"Yuka Hashimoto, Masahiro Ikeda, Hachem Kadri","title":"Deep Learning with Kernels through RKHM and the Perron-Frobenius\n  Operator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Reproducing kernel Hilbert $C^*$-module (RKHM) is a generalization of\nreproducing kernel Hilbert space (RKHS) by means of $C^*$-algebra, and the\nPerron-Frobenius operator is a linear operator related to the composition of\nfunctions. Combining these two concepts, we present deep RKHM, a deep learning\nframework for kernel methods. We derive a new Rademacher generalization bound\nin this setting and provide a theoretical interpretation of benign overfitting\nby means of Perron-Frobenius operators. By virtue of $C^*$-algebra, the\ndependency of the bound on output dimension is milder than existing bounds. We\nshow that $C^*$-algebra is a suitable tool for deep learning with kernels,\nenabling us to take advantage of the product structure of operators and to\nprovide a clear connection with convolutional neural networks. Our theoretical\nanalysis provides a new lens through which one can design and analyze deep\nkernel methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:38:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13589","submitter":"Yiming Zhang","authors":"Yiming Zhang, Sravani Nanduri, Liwei Jiang, Tongshuang Wu, Maarten Sap","title":"BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of\n  Implied Social Biases","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Toxicity annotators and content moderators often default to mental shortcuts\nwhen making decisions. This can lead to subtle toxicity being missed, and\nseemingly toxic but harmless content being over-detected. We introduce BiasX, a\nframework that enhances content moderation setups with free-text explanations\nof statements' implied social biases, and explore its effectiveness through a\nlarge-scale crowdsourced user study. We show that indeed, participants\nsubstantially benefit from explanations for correctly identifying subtly\n(non-)toxic content. The quality of explanations is critical: imperfect\nmachine-generated explanations (+2.4% on hard toxic examples) help less\ncompared to expert-written human explanations (+7.2%). Our results showcase the\npromise of using free-text explanations to encourage more thoughtful toxicity\nmoderation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:45:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13590","submitter":"Xichao Zhang","authors":"Xichao Zhang, Jing Xia, Oleg A. Tretiakov, Motohiko Ezawa, Guoping\n  Zhao, Yan Zhou, Xiaoxi Liu, Masahito Mochizuki","title":"Laminar and Quasi-Turbulent Dynamics of a Magnetic Skyrmion Pipe Flow","comments":"7 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.app-ph physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report the laminar and quasi-turbulent dynamic behaviors of magnetic\nskyrmions flowing in a pipe channel. The skyrmion flow driven by a uniform\ncurrent may show a lattice structural transition. The skyrmion flow driven by a\nnon-uniform current shows a dynamically varying lattice structure. A large\nuniform current could result in the compression of skyrmions toward the channel\nedge, leading to the transition of the skyrmion pipe flow into an open-channel\nflow with a free surface. Skyrmions on the free surface may form a single shear\nlayer adjacent to the main skyrmion flow. Our results reveal the fluid nature\nof skyrmionic quasiparticles that may play an essential role in applications.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:46:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13591","submitter":"Mingshuai Dong","authors":"Mingshuai Dong and Yuxuan Bai and Shimin Wei and Xiuli Yu","title":"A Single Multi-Task Deep Neural Network with a Multi-Scale Feature\n  Aggregation Mechanism for Manipulation Relationship Reasoning in Robotic\n  Grasping","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Grasping specific objects in complex and irregularly stacked scenes is still\nchallenging for robotics. Because the robot is not only required to identify\nthe object's grasping posture but also needs to reason the manipulation\nrelationship between the objects. In this paper, we propose a manipulation\nrelationship reasoning network with a multi-scale feature aggregation (MSFA)\nmechanism for robot grasping tasks. MSFA aggregates high-level semantic\ninformation and low-level spatial information in a cross-scale connection way\nto improve the generalization ability of the model. Furthermore, to improve the\naccuracy, we propose to use intersection features with rich location priors for\nmanipulation relationship reasoning. Experiments are validated in VMRD datasets\nand real environments, respectively. The experimental results demonstrate that\nour proposed method can accurately predict the manipulation relationship\nbetween objects in the scene of multi-object stacking. Compared with previous\nmethods, it significantly improves reasoning speed and accuracy.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:46:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13592","submitter":"Yiwen Guo","authors":"Jianyu Zhao and Yuyang Rong and Yiwen Guo and Yifeng He and Hao Chen","title":"Understanding Programs by Exploiting (Fuzzing) Test Cases","comments":"Findings of the Association for Computational Linguistics: ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.CR cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Semantic understanding of programs has attracted great attention in the\ncommunity. Inspired by recent successes of large language models (LLMs) in\nnatural language understanding, tremendous progress has been made by treating\nprogramming language as another sort of natural language and training LLMs on\ncorpora of program code. However, programs are essentially different from texts\nafter all, in a sense that they are normally heavily structured and\nsyntax-strict. In particular, programs and their basic units (i.e., functions\nand subroutines) are designed to demonstrate a variety of behaviors and/or\nprovide possible outputs, given different inputs. The relationship between\ninputs and possible outputs/behaviors represents the functions/subroutines and\nprofiles the program as a whole. Therefore, we propose to incorporate such a\nrelationship into learning, for achieving a deeper semantic understanding of\nprograms. To obtain inputs that are representative enough to trigger the\nexecution of most part of the code, we resort to fuzz testing and propose fuzz\ntuning to boost the performance of program understanding and code\nrepresentation learning, given a pre-trained LLM. The effectiveness of the\nproposed method is verified on two program understanding tasks including code\nclone detection and code classification, and it outperforms current\nstate-of-the-arts by large margins. Code is available at\nhttps://github.com/rabbitjy/FuzzTuning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:51:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13593","submitter":"Xinyu Zhang","authors":"Xinyu Zhang, Hefei Huang, Xu Jia, Dong Wang, Huchuan Lu","title":"Neural Image Re-Exposure","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The shutter strategy applied to the photo-shooting process has a significant\ninfluence on the quality of the captured photograph. An improper shutter may\nlead to a blurry image, video discontinuity, or rolling shutter artifact.\nExisting works try to provide an independent solution for each issue. In this\nwork, we aim to re-expose the captured photo in post-processing to provide a\nmore flexible way of addressing those issues within a unified framework.\nSpecifically, we propose a neural network-based image re-exposure framework. It\nconsists of an encoder for visual latent space construction, a re-exposure\nmodule for aggregating information to neural film with a desired shutter\nstrategy, and a decoder for 'developing' neural film into a desired image. To\ncompensate for information confusion and missing frames, event streams, which\ncan capture almost continuous brightness changes, are leveraged in computing\nvisual latent content. Both self-attention layers and cross-attention layers\nare employed in the re-exposure module to promote interaction between neural\nfilm and visual latent content and information aggregation to neural film. The\nproposed unified image re-exposure framework is evaluated on several\nshutter-related image recovery tasks and performs favorably against independent\nstate-of-the-art methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:55:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13594","submitter":"Micha{\\l} St\\k{e}ch{\\l}y","authors":"Micha{\\l} St\\k{e}ch{\\l}y, Lanruo Gao, Boniface Yogendran, Enrico\n  Fontana, Manuel Rudolph","title":"Connecting the Hamiltonian structure to the QAOA energy and Fourier\n  landscape structure","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we aim to expand the understanding of the relationship between\nthe composition of the Hamiltonian in the Quantum Approximate Optimization\nAlgorithm (QAOA) and the corresponding cost landscape characteristics. QAOA is\na prominent example of a Variational Quantum Algorithm (VQA), which is most\ncommonly used for combinatorial optimization. The success of QAOA heavily\nrelies on parameter optimization, which is a great challenge, especially on\nscarce noisy quantum hardware. Thus understanding the cost function landscape\ncan aid in designing better optimization heuristics and therefore potentially\nprovide eventual value. We consider the case of 1-layer QAOA for Hamiltonians\nwith up to 5-local terms and up to 20 qubits. In addition to visualizing the\ncost landscapes, we calculate their Fourier transform to study the relationship\nwith the structure of the Hamiltonians from a complementary perspective.\nFurthermore, we introduce metrics to quantify the roughness of the landscape,\nwhich provide valuable insights into the nature of high-dimensional\nparametrized landscapes. While these techniques allow us to elucidate the role\nof Hamiltonian structure, order of the terms and their coefficients on the\nroughness of the optimization landscape, we also find that predicting the\nintricate landscapes of VQAs from first principles is very challenging and\nunlikely to be feasible in general.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:56:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13595","submitter":"Ziwei Zhu","authors":"Ziwei Zhu, Zhaocheng Liu, Changxi Zheng","title":"Metalens Enhanced Ray Optics: An End-to-End Wave-Ray Co-Optimization\n  Framework","comments":"14 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a fully differentiable framework for seamlessly integrating wave\noptical components with geometrical lenses, offering an approach to enhance the\nperformance of large-scale end-to-end optical systems. In this study, we focus\non the integration of a metalens, a geometrical lens, and image data. Through\nthe use of gradient-based optimization techniques, we demonstrate the design of\nnonparaxial imaging systems and the correction of aberrations inherent in\ngeometrical optics. Our framework enables efficient and effective optimization\nof the entire optical system, leading to improved overall performance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:56:44 GMT"},{"version":"v2","created":"Fri, 26 May 2023 17:36:38 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13596","submitter":"Lequn Chen","authors":"Lequn Chen, Xiling Yao, Wenhe Feng, Youxiang Chew, Seung Ki Moon","title":"Multimodal sensor fusion for real-time location-dependent defect\n  detection in laser-directed energy deposition","comments":"8 pages, 10 figures. This paper has been accepted to be published in\n  the proceedings of IDETC-CIE 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV eess.AS eess.SP","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Real-time defect detection is crucial in laser-directed energy deposition\n(L-DED) additive manufacturing (AM). Traditional in-situ monitoring approach\nutilizes a single sensor (i.e., acoustic, visual, or thermal sensor) to capture\nthe complex process dynamic behaviors, which is insufficient for defect\ndetection with high accuracy and robustness. This paper proposes a novel\nmultimodal sensor fusion method for real-time location-dependent defect\ndetection in the robotic L-DED process. The multimodal fusion sources include a\nmicrophone sensor capturing the laser-material interaction sound and a visible\nspectrum CCD camera capturing the coaxial melt pool images. A hybrid\nconvolutional neural network (CNN) is proposed to fuse acoustic and visual\ndata. The key novelty in this study is that the traditional manual feature\nextraction procedures are no longer required, and the raw melt pool images and\nacoustic signals are fused directly by the hybrid CNN model, which achieved the\nhighest defect prediction accuracy (98.5 %) without the thermal sensing\nmodality. Moreover, unlike previous region-based quality prediction, the\nproposed hybrid CNN can detect the onset of defect occurrences. The defect\nprediction outcomes are synchronized and registered with in-situ acquired robot\ntool-center-point (TCP) data, which enables localized defect identification.\nThe proposed multimodal sensor fusion method offers a robust solution for\nin-situ defect detection.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:57:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13597","submitter":"Riku Togashi","authors":"Naoto Ohsaka, Riku Togashi","title":"Curse of \"Low\" Dimensionality in Recommender Systems","comments":"Accepted by SIGIR'23","journal-ref":null,"doi":"10.1145/3539618.3591659","report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Beyond accuracy, there are a variety of aspects to the quality of recommender\nsystems, such as diversity, fairness, and robustness. We argue that many of the\nprevalent problems in recommender systems are partly due to low-dimensionality\nof user and item embeddings, particularly when dot-product models, such as\nmatrix factorization, are used.\n  In this study, we showcase empirical evidence suggesting the necessity of\nsufficient dimensionality for user/item embeddings to achieve diverse, fair,\nand robust recommendation. We then present theoretical analyses of the\nexpressive power of dot-product models. Our theoretical results demonstrate\nthat the number of possible rankings expressible under dot-product models is\nexponentially bounded by the dimension of item factors. We empirically found\nthat the low-dimensionality contributes to a popularity bias, widening the gap\nbetween the rank positions of popular and long-tail items; we also give a\ntheoretical justification for this phenomenon.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:59:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13598","submitter":"Yong Zhang","authors":"Xu-Jia Ouyang, Yong Zhang, Albert Zijlstra, Chuan-Peng Zhang, Jun-ichi\n  Nakashima, Quentin A Parker","title":"FAST search for circumstellar atomic hydrogen. II. Is BD+303639 an\n  interacting planetary nebula?","comments":"20 pages, 7 figures, accepted for publication in ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The young, compact, very high surface brightness but low excitation planetary\nnebula (PN) BD+303639 is one of the very few PNe that have been reported to\nexhibit the 21cm HI emission line. As part of a long-term programme to search\nfor circumstellar atomic hydrogen, we observed the 21cm feature toward\nBD+303639 with the Five-hundred-meter Aperture Spherical radio Telescope\n(FAST). Assuming a direct association between the PN and the detected HI\nemission, these new observations show that this surrounding emission is\nsignificantly more spatially extended than indicated by previous\ninterferometric observations, and can be resolved into two velocity components.\nThe estimated HI mass is larger than 100M_sun, invalidating an origin from the\nhost star itself or its ejecta for the emitting material. We discuss the\npossibility that the extended HI emission stems from the interstellar medium\n(ISM) swept out over time by the stellar wind. Moreover, we report tentative\ndetections of HI absorption features lying near and blueward of the systemic\nvelocity of this PN, which are probably from a stalled asterosphere at the\nouter boundary of the expanding ionized region. The mass of the gas producing\nthe HI absorption is insufficient to solve the so-called `PN missing mass\nproblem'. We demonstrate the capability of FAST to investigate the interaction\nprocess between a PN and the surrounding ISM.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:59:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13599","submitter":"Wei Liu","authors":"Wei Liu, Jun Wang, Haozhao Wang, Ruixuan Li, Yang Qiu, YuanKai Zhang,\n  Jie Han, Yixiong Zou","title":"Decoupled Rationalization with Asymmetric Learning Rates: A Flexible\n  Lipschitz Restraint","comments":"KDD 2023 research track","journal-ref":null,"doi":"10.1145/3580305.3599299","report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  A self-explaining rationalization model is generally constructed by a\ncooperative game where a generator selects the most human-intelligible pieces\nfrom the input text as rationales, followed by a predictor that makes\npredictions based on the selected rationales. However, such a cooperative game\nmay incur the degeneration problem where the predictor overfits to the\nuninformative pieces generated by a not yet well-trained generator and in turn,\nleads the generator to converge to a sub-optimal model that tends to select\nsenseless pieces. In this paper, we theoretically bridge degeneration with the\npredictor's Lipschitz continuity. Then, we empirically propose a simple but\neffective method named DR, which can naturally and flexibly restrain the\nLipschitz constant of the predictor, to address the problem of degeneration.\nThe main idea of DR is to decouple the generator and predictor to allocate them\nwith asymmetric learning rates. A series of experiments conducted on two widely\nused benchmarks have verified the effectiveness of the proposed method. Codes:\n\\href{https://github.com/jugechengzi/Rationalization-DR}{https://github.com/jugechengzi/Rationalization-DR}.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:01:13 GMT"},{"version":"v2","created":"Fri, 26 May 2023 07:59:42 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13600","submitter":"Mingkun Li","authors":"Mingkun Li, Peng Xu, Chun-Guang Li, Jun Guo","title":"MaskCL: Semantic Mask-Driven Contrastive Learning for Unsupervised\n  Person Re-Identification with Clothes Change","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper considers a novel and challenging problem: unsupervised long-term\nperson re-identification with clothes change. Unfortunately, conventional\nunsupervised person re-id methods are designed for short-term cases and thus\nfail to perceive clothes-independent patterns due to simply being driven by RGB\nprompt. To tackle with such a bottleneck, we propose a semantic mask-driven\ncontrastive learning approach, in which silhouette masks are embedded into\ncontrastive learning framework as the semantic prompts and cross-clothes\ninvariance is learnt from hierarchically semantic neighbor structure by\ncombining both RGB and semantic features in a two-branches network. Since such\na challenging re-id task setting is investigated for the first time, we\nconducted extensive experiments to evaluate state-of-the-art unsupervised\nshort-term person re-id methods on five widely-used clothes-change re-id\ndatasets. Experimental results verify that our approach outperforms the\nunsupervised re-id competitors by a clear margin, remaining a narrow gap to the\nsupervised baselines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:02:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13601","submitter":"Yulin Pan","authors":"Ashleigh Simonis, Alexander Hrabski and Yulin Pan","title":"On the time scales of spectral evolution of nonlinear waves","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As presented in Annenkov & Shrira (2009), when a surface gravity wave field\nis subjected to an abrupt perturbation of external forcing, its spectrum\nevolves on a ``fast'' dynamic time scale of $O(\\varepsilon^{-2})$, with\n$\\varepsilon$ a measure of wave steepness. This observation poses a challenge\nto wave turbulence theory that predicts an evolution with a kinetic time scale\nof $O(\\varepsilon^{-4})$. We revisit this unresolved problem by studying the\nsame situation in the context of a one-dimensional Majda-McLaughlin-Tabak (MMT)\nequation with gravity wave dispersion relation. Our results show that the\nkinetic and dynamic time scales can both be realised, with the former and\nlatter occurring for weaker and stronger forcing perturbations, respectively.\nThe transition between the two regimes corresponds to a critical forcing\nperturbation, with which the spectral evolution time scale drops to the same\norder as the linear wave period (of some representative mode). Such fast\nspectral evolution is mainly induced by a far-from-stationary state after a\nsufficiently strong forcing perturbation is applied. We further develop a\nset-based interaction analysis to show that the inertial-range modal evolution\nin the studied cases is dominated by their (mostly non-local) interactions with\nthe low-wavenumber ``condensate'' induced by the forcing perturbation. The\nresults obtained in this work should be considered to provide significant\ninsight into the original gravity wave problem.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:06:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13602","submitter":"Haoqin Tu","authors":"Haoqin Tu, Yitong Li, Fei Mi, Zhongliang Yang","title":"ReSee: Responding through Seeing Fine-grained Visual Knowledge in\n  Open-domain Dialogue","comments":"15 pages, preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Incorporating visual knowledge into text-only dialogue systems has become a\npotential direction to imitate the way humans think, imagine, and communicate.\nHowever, existing multimodal dialogue systems are either confined by the scale\nand quality of available datasets or the coarse concept of visual knowledge. To\naddress these issues, we provide a new paradigm of constructing multimodal\ndialogues as well as two datasets extended from text-only dialogues under such\nparadigm (ReSee-WoW, ReSee-DD). We propose to explicitly split the visual\nknowledge into finer granularity (``turn-level'' and ``entity-level''). To\nfurther boost the accuracy and diversity of augmented visual information, we\nretrieve them from the Internet or a large image dataset. To demonstrate the\nsuperiority and universality of the provided visual knowledge, we propose a\nsimple but effective framework ReSee to add visual representation into vanilla\ndialogue models by modality concatenations. We also conduct extensive\nexperiments and ablations w.r.t. different model configurations and visual\nknowledge settings. Empirical, encouraging results not only demonstrate the\neffectiveness of introducing visual knowledge at both entity and turn level but\nalso verify the proposed model ReSee outperforms several state-of-the-art\nmethods on automatic and human evaluations. By leveraging text and vision\nknowledge, ReSee can produce informative responses with real-world visual\nconcepts.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:08:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13603","submitter":"Sergei Silvestrov","authors":"Domingos Djinja, Sergei Silvestrov, Alex Behakanira Tumwesigye","title":"Volterra integral operators and general linear integral operators\n  representing polynomial covariance type commutation relations on $L_p$ spaces","comments":"39 pages. arXiv admin note: text overlap with arXiv:2305.09851,\n  arXiv:2305.04144","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Conditions for linear integral operators on $L_p$ over measure spaces to\nsatisfy the polynomial covariance type commutation relations are described in\nterms of defining kernels of the corresponding integral operators.\nRepresentation by integral operators are studied both for general polynomial\ncovariance commutation relations and for important classes of polynomial\ncovariance commutation relations associated to arbitrary monomials and to\naffine functions. Representations of the covariance type commutation relations\nby integral Volterra operators and integral convolution operators are\ninvestigated.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:10:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13604","submitter":"Ya-Nan Zhu","authors":"Ya-Nan Zhu, Jingwei Liang and Xiaoqun Zhang","title":"Federated Primal Dual Fixed Point Algorithm","comments":"29 pages and 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Federated learning (FL) is a distributed learning paradigm that allows\nseveral clients to learn a global model without sharing their private data. In\nthis paper, we generalize a primal dual fixed point (PDFP) \\cite{PDFP} method\nto federated learning setting and propose an algorithm called Federated PDFP\n(FPDFP) for solving composite optimization problems. In addition, a\nquantization scheme is applied to reduce the communication overhead during the\nlearning process. An $O(\\frac{1}{k})$ convergence rate (where $k$ is the\ncommunication round) of the proposed FPDFP is provided. Numerical experiments,\nincluding graph-guided logistic regression, 3D Computed Tomography (CT)\nreconstruction are considered to evaluate the proposed algorithm.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:12:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13605","submitter":"Mei Wang","authors":"Mei Wang, Weihong Deng","title":"Adaptive Face Recognition Using Adversarial Information Network","comments":"Accepted by TIP","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In many real-world applications, face recognition models often degenerate\nwhen training data (referred to as source domain) are different from testing\ndata (referred to as target domain). To alleviate this mismatch caused by some\nfactors like pose and skin tone, the utilization of pseudo-labels generated by\nclustering algorithms is an effective way in unsupervised domain adaptation.\nHowever, they always miss some hard positive samples. Supervision on\npseudo-labeled samples attracts them towards their prototypes and would cause\nan intra-domain gap between pseudo-labeled samples and the remaining unlabeled\nsamples within target domain, which results in the lack of discrimination in\nface recognition. In this paper, considering the particularity of face\nrecognition, we propose a novel adversarial information network (AIN) to\naddress it. First, a novel adversarial mutual information (MI) loss is proposed\nto alternately minimize MI with respect to the target classifier and maximize\nMI with respect to the feature extractor. By this min-max manner, the positions\nof target prototypes are adaptively modified which makes unlabeled images\nclustered more easily such that intra-domain gap can be mitigated. Second, to\nassist adversarial MI loss, we utilize a graph convolution network to predict\nlinkage likelihoods between target data and generate pseudo-labels. It\nleverages valuable information in the context of nodes and can achieve more\nreliable results. The proposed method is evaluated under two scenarios, i.e.,\ndomain adaptation across poses and image conditions, and domain adaptation\nacross faces with different skin tones. Extensive experiments show that AIN\nsuccessfully improves cross-domain generalization and offers a new\nstate-of-the-art on RFW dataset.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:14:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13606","submitter":"Dmitri Vassilevich","authors":"Rodrigo Fresneda, Lucas de Souza, Dmitri Vassilevich","title":"Edge states and the $\\eta$ invariant","comments":"8 pages, v2: minor changes, a reference added","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a relation between the $\\eta$ invariant on a manifold with\nboundary, the $\\eta$ invariants of edge states, and the $\\eta$ invariant in an\ninfinite volume limit. With the example of planar fermions with bag and chiral\nbag boundary conditions we show that this relation holds whenever edge states\nare sufficiently well-localized near the boundary. As a by-product we show that\nthe spectrum of edge modes for chiral bag boundary conditions is linear but\nbounded.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:15:53 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 03:21:40 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.13607","submitter":"Mengqi Huang","authors":"Mengqi Huang, Zhendong Mao, Quan Wang, Yongdong Zhang","title":"Not All Image Regions Matter: Masked Vector Quantization for\n  Autoregressive Image Generation","comments":"accepted by CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing autoregressive models follow the two-stage generation paradigm that\nfirst learns a codebook in the latent space for image reconstruction and then\ncompletes the image generation autoregressively based on the learned codebook.\nHowever, existing codebook learning simply models all local region information\nof images without distinguishing their different perceptual importance, which\nbrings redundancy in the learned codebook that not only limits the next stage's\nautoregressive model's ability to model important structure but also results in\nhigh training cost and slow generation speed. In this study, we borrow the idea\nof importance perception from classical image coding theory and propose a novel\ntwo-stage framework, which consists of Masked Quantization VAE (MQ-VAE) and\nStackformer, to relieve the model from modeling redundancy. Specifically,\nMQ-VAE incorporates an adaptive mask module for masking redundant region\nfeatures before quantization and an adaptive de-mask module for recovering the\noriginal grid image feature map to faithfully reconstruct the original images\nafter quantization. Then, Stackformer learns to predict the combination of the\nnext code and its position in the feature map. Comprehensive experiments on\nvarious image generation validate our effectiveness and efficiency. Code will\nbe released at https://github.com/CrossmodalGroup/MaskedVectorQuantization.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:15:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13608","submitter":"Wenxiao Cai","authors":"Wenxiao Cai, Ke Jin, Jinyan Hou, Cong Guo, Letian Wu, Wankou Yang","title":"VDD: Varied Drone Dataset for Semantic Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Semantic segmentation of drone images is critical to many aerial vision tasks\nas it provides essential semantic details that can compensate for the lack of\ndepth information from monocular cameras. However, maintaining high accuracy of\nsemantic segmentation models for drones requires diverse, large-scale, and\nhigh-resolution datasets, which are rare in the field of aerial image\nprocessing. Existing datasets are typically small and focus primarily on urban\nscenes, neglecting rural and industrial areas. Models trained on such datasets\nare not sufficiently equipped to handle the variety of inputs seen in drone\nimagery. In the VDD-Varied Drone Dataset, we offer a large-scale and densely\nlabeled dataset comprising 400 high-resolution images that feature carefully\nchosen scenes, camera angles, and varied light and weather conditions.\nFurthermore, we have adapted existing drone datasets to conform to our\nannotation standards and integrated them with VDD to create a dataset 1.5 times\nthe size of fine annotation of Cityscapes. We have developed a novel DeepLabT\nmodel, which combines CNN and Transformer backbones, to provide a reliable\nbaseline for semantic segmentation in drone imagery. Our experiments indicate\nthat DeepLabT performs admirably on VDD and other drone datasets. We expect\nthat our dataset will generate considerable interest in drone image\nsegmentation and serve as a foundation for other drone vision tasks. VDD is\nfreely available on our website at https://vddvdd.com .\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:16:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13609","submitter":"Paul Estrada","authors":"Paul R. Estrada and Richard. H. Durisen","title":"Constraints on the initial mass, age and lifetime of Saturn's rings from\n  viscous evolutions that include pollution and transport due to micrometeoroid\n  bombardment","comments":"31 pages, 19 figures, 2 tables, Published in Icarus","journal-ref":"Icarus, Volume 400, 2023, article id. 115296","doi":"10.1016/j.icarus.2022.115296","report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The Cassini spacecraft provided key measurements during its more than twelve\nyear mission that constrain the absolute age of Saturn's rings. These include\nthe extrinsic micrometeoroid flux at Saturn, the volume fraction of non-icy\npollutants in the rings, and a measurement of the ring mass. These observations\ntaken together limit the ring exposure age to be < a few 100 Myr if the flux\nwas persistent over that time (Kempf et al., 2023). In addition, Cassini\nobservations during the Grand Finale further indicate the rings are losing mass\n(Hsu et al., 2018; Waite et al., 2018) suggesting the rings are ephemeral as\nwell. In a companion paper (Durisen and Estrada, 2023), we show that the\neffects of micrometeoroid bombardment and ballistic transport of their impact\nejecta can account for these loss rates for reasonable parameter choices. In\nthis paper, we conduct numerical simulations of an evolving ring in a\nsystematic way in order to determine initial conditions that are consistent\nwith these observations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:16:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13610","submitter":"Meghana Sistla","authors":"Meghana Sistla, Swarat Chaudhuri, Thomas Reps","title":"Weighted Context-Free-Language Ordered Binary Decision Diagrams","comments":"21 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.FL quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Over the years, many variants of Binary Decision Diagrams (BDDs) have been\ndeveloped to address the deficiencies of vanilla BDDs. A recent innovation is\nthe Context-Free-Language Ordered BDD (CFLOBDD), a hierarchically structured\ndecision diagram, akin to BDDs enhanced with a procedure-call mechanism, which\nallows substructures to be shared in ways not possible with BDDs. For some\nfunctions, CFLOBDDs are exponentially more succinct than BDDs. Unfortunately,\nthe multi-terminal extension of CFLOBDDs, like multi-terminal BDDs, cannot\nefficiently represent functions of type B^n -> D, when the function's range has\nmany different values. This paper addresses this limitation through a new data\nstructure called Weighted CFLOBDDs (WCFLOBDDs). WCFLOBDDs extend CFLOBDDs using\ninsights from the design of Weighted BDDs (WBDDs) -- BDD-like structures with\nweights on edges. We show that WCFLOBDDs can be exponentially more succinct\nthan both WBDDs and CFLOBDDs. We also evaluate WCFLOBDDs for quantum-circuit\nsimulation, and find that they perform better than WBDDs and CFLOBDDs on most\nbenchmarks. With a 15-minute timeout, the number of qubits that can be handled\nby WCFLOBDDs is 1,048,576 for GHZ (1x over CFLOBDDs, 256x over WBDDs); 262,144\nfor BV and DJ (2x over CFLOBDDs, 64x over WBDDs); and 2,048 for QFT (128x over\nCFLOBDDs, 2x over WBDDs).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:16:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13611","submitter":"Yue Lu","authors":"Congqi Cao, Yue Lu, Peng Wang and Yanning Zhang","title":"A New Comprehensive Benchmark for Semi-supervised Video Anomaly\n  Detection and Anticipation","comments":"CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Semi-supervised video anomaly detection (VAD) is a critical task in the\nintelligent surveillance system. However, an essential type of anomaly in VAD\nnamed scene-dependent anomaly has not received the attention of researchers.\nMoreover, there is no research investigating anomaly anticipation, a more\nsignificant task for preventing the occurrence of anomalous events. To this\nend, we propose a new comprehensive dataset, NWPU Campus, containing 43 scenes,\n28 classes of abnormal events, and 16 hours of videos. At present, it is the\nlargest semi-supervised VAD dataset with the largest number of scenes and\nclasses of anomalies, the longest duration, and the only one considering the\nscene-dependent anomaly. Meanwhile, it is also the first dataset proposed for\nvideo anomaly anticipation. We further propose a novel model capable of\ndetecting and anticipating anomalous events simultaneously. Compared with 7\noutstanding VAD algorithms in recent years, our method can cope with\nscene-dependent anomaly detection and anomaly anticipation both well, achieving\nstate-of-the-art performance on ShanghaiTech, CUHK Avenue, IITB Corridor and\nthe newly proposed NWPU Campus datasets consistently. Our dataset and code is\navailable at: https://campusvad.github.io.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:20:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13612","submitter":"Ziyue Jiang","authors":"Ziyue Jiang, Qian Yang, Jialong Zuo, Zhenhui Ye, Rongjie Huang, Yi\n  Ren, Zhou Zhao","title":"FluentSpeech: Stutter-Oriented Automatic Speech Editing with\n  Context-Aware Diffusion Models","comments":"Accepted by ACL 2023 (Findings)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Stutter removal is an essential scenario in the field of speech editing.\nHowever, when the speech recording contains stutters, the existing text-based\nspeech editing approaches still suffer from: 1) the over-smoothing problem in\nthe edited speech; 2) lack of robustness due to the noise introduced by\nstutter; 3) to remove the stutters, users are required to determine the edited\nregion manually. To tackle the challenges in stutter removal, we propose\nFluentSpeech, a stutter-oriented automatic speech editing model. Specifically,\n1) we propose a context-aware diffusion model that iteratively refines the\nmodified mel-spectrogram with the guidance of context features; 2) we introduce\na stutter predictor module to inject the stutter information into the hidden\nsequence; 3) we also propose a stutter-oriented automatic speech editing (SASE)\ndataset that contains spontaneous speech recordings with time-aligned stutter\nlabels to train the automatic stutter localization model. Experimental results\non VCTK and LibriTTS datasets demonstrate that our model achieves\nstate-of-the-art performance on speech editing. Further experiments on our SASE\ndataset show that FluentSpeech can effectively improve the fluency of\nstuttering speech in terms of objective and subjective metrics. Code and audio\nsamples can be found at https://github.com/Zain-Jiang/Speech-Editing-Toolkit.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:20:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13613","submitter":"Giovanni Stabile","authors":"Valentin Nkana Ngan and Giovanni Stabile and Andrea Mola and Gianluigi\n  Rozza","title":"A reduced-order model for segregated fluid-structure interaction solvers\n  based on an ALE approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This article presents a Galerkin projection model order reduction approach\nfor fluid-structure interaction (FSI) problems in the Finite Volume context.\nThe reduced-order model (ROM) is based on proper orthogonal decomposition\n(POD), where a reduced basis is formed using energy-dominant POD modes. The\nreduced basis also consists of characteristics of the POD time modes derived\nfrom the POD time modes coefficients. In addition, the solution state vector\ncomprises the mesh deformation, considering the structural motion in FSI. The\nresults are obtained by applying the proposed method to time-dependent problems\ngoverned by the 2D incompressible Navier-Stokes equations. The main objective\nof this work is to introduce a hybrid technique mixing up the classical\nGalerkin-projection approach with a data-driven method to obtain a versatile\nand accurate algorithm for resolving FSI problems with moving meshes. The\neffectiveness of this approach is demonstrated in the case study of\nvortex-induced vibrations (VIV) of a cylinder at Reynolds number Re = 200. The\nresults show the stability and accuracy of the proposed method with respect to\nthe high-dimensional model by capturing transient flow fields and, more\nimportantly, the forces acting on the moving objects.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:22:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13614","submitter":"Siyuan Chen","authors":"Siyuan Chen, Mengyue Wu, Kenny Q. Zhu, Kunyao Lan, Zhiling Zhang,\n  Lyuchun Cui","title":"LLM-empowered Chatbots for Psychiatrist and Patient Simulation:\n  Application and Evaluation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Empowering chatbots in the field of mental health is receiving increasing\namount of attention, while there still lacks exploration in developing and\nevaluating chatbots in psychiatric outpatient scenarios. In this work, we focus\non exploring the potential of ChatGPT in powering chatbots for psychiatrist and\npatient simulation. We collaborate with psychiatrists to identify objectives\nand iteratively develop the dialogue system to closely align with real-world\nscenarios. In the evaluation experiments, we recruit real psychiatrists and\npatients to engage in diagnostic conversations with the chatbots, collecting\ntheir ratings for assessment. Our findings demonstrate the feasibility of using\nChatGPT-powered chatbots in psychiatric scenarios and explore the impact of\nprompt designs on chatbot behavior and user experience.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:25:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13615","submitter":"Wei Sun","authors":"Ping Sun, Ze-Chun Hu and Wei Sun","title":"Variation comparison between the $F$-distribution and the normal\n  distribution","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $X_{d_1,d_2}$ be an $F$-random variable with numerator and denominator\ndegrees of freedom $d_1$ and $d_2$, respectively. We investigate the\ninequality: $P\\{|X_{d_1,d_2}-E[X_{d_1,d_2}]|\\le \\sqrt{{\\rm\nVar}(X_{d_1,d_2})}\\}\\ge P\\{|W-E[W]|\\le \\sqrt{{\\rm Var}(W)}\\}$, where $W$ is a\nstandard normal random variable or a $\\chi^2(d_1)$ random variable. We prove\nthat this inequality holds for $d_1\\in\\{1,2,3,4\\}$ and $5\\le d_2\\in\\mathbb{N}$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:25:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13616","submitter":"Nan Ma","authors":"Nan Ma, Ying Yang, Dongkai Zhou","title":"An Entire Renal Anatomy Extraction Network for Advanced CAD During\n  Partial Nephrectomy","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Partial nephrectomy (PN) is common surgery in urology. Digitization of renal\nanatomies brings much help to many computer-aided diagnosis (CAD) techniques\nduring PN. However, the manual delineation of kidney vascular system and tumor\non each slice is time consuming, error-prone, and inconsistent. Therefore, we\nproposed an entire renal anatomies extraction method from Computed Tomographic\nAngiographic (CTA) images fully based on deep learning. We adopted a\ncoarse-to-fine workflow to extract target tissues: first, we roughly located\nthe kidney region, and then cropped the kidney region for more detail\nextraction. The network we used in our workflow is based on 3D U-Net. To\ndealing with the imbalance of class contributions to loss, we combined the dice\nloss with focal loss, and added an extra weight to prevent excessive attention.\nWe also improved the manual annotations of vessels by merging semi-trained\nmodel's prediction and original annotations under supervision. We performed\nseveral experiments to find the best-fitting combination of variables for\ntraining. We trained and evaluated the models on our 60 cases dataset with 3\ndifferent sources. The average dice score coefficient (DSC) of kidney, tumor,\ncyst, artery, and vein, were 90.9%, 90.0%, 89.2%, 80.1% and 82.2% respectively.\nOur modulate weight and hybrid strategy of loss function increased the average\nDSC of all tissues about 8-20%. Our optimization of vessel annotation improved\nthe average DSC about 1-5%. We proved the efficiency of our network on renal\nanatomies segmentation. The high accuracy and fully automation make it possible\nto quickly digitize the personal renal anatomies, which greatly increases the\nfeasibility and practicability of CAD application on urology surgery.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:25:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13617","submitter":"Shumin Deng","authors":"Shumin Deng, Shengyu Mao, Ningyu Zhang, Bryan Hooi","title":"SPEECH: Structured Prediction with Energy-Based Event-Centric\n  Hyperspheres","comments":"Accepted by ACL 2023 Main Conference. Code is released at\n  \\url{https://github.com/zjunlp/SPEECH}","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Event-centric structured prediction involves predicting structured outputs of\nevents. In most NLP cases, event structures are complex with manifold\ndependency, and it is challenging to effectively represent these complicated\nstructured events. To address these issues, we propose Structured Prediction\nwith Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex\ndependency among event structured components with energy-based modeling, and\nrepresents event classes with simple but effective hyperspheres. Experiments on\ntwo unified-annotated event datasets indicate that SPEECH is predominant in\nevent detection and event-relation extraction tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:28:09 GMT"},{"version":"v2","created":"Fri, 26 May 2023 12:58:13 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13618","submitter":"Simon Kaspar Schnyder","authors":"Simon K. Schnyder, John J. Molina, Ryoichi Yamamoto, Matthew S. Turner","title":"Rational social distancing in epidemics with uncertain vaccination\n  timing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.TH math.OC physics.soc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  During epidemics people reduce their social and economic activity to lower\ntheir risk of infection. Such social distancing strategies will depend on\ninformation about the course of the epidemic but also on when they expect the\nepidemic to end, for instance due to vaccination. Typically it is difficult to\nmake optimal decisions, because the available information is incomplete and\nuncertain. Here, we show how optimal decision making depends on knowledge about\nvaccination timing in a differential game in which individual decision making\ngives rise to Nash equilibria, and the arrival of the vaccine is described by a\nprobability distribution. We show that the earlier the vaccination is expected\nto happen and the more precisely the timing of the vaccination is known, the\nstronger is the incentive to socially distance. In particular, equilibrium\nsocial distancing only meaningfully deviates from the no-vaccination\nequilibrium course if the vaccine is expected to arrive before the epidemic\nwould have run its course. We demonstrate how the probability distribution of\nthe vaccination time acts as a generalised form of discounting, with the\nspecial case of an exponential vaccination time distribution directly\ncorresponding to regular exponential discounting.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:28:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13619","submitter":"Yuma Fujimoto","authors":"Yuma Fujimoto, Kaito Ariu and Kenshi Abe","title":"Memory Asymmetry: A Key to Convergence in Zero-Sum Games","comments":"11 pages & 5 figures (main), 4 pages & 1 figure (appendix)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.MA math.OC nlin.CD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study provides a new convergence mechanism in learning in games.\nLearning in games considers how multiple agents maximize their own rewards\nthrough repeated plays of games. Especially in two-player zero-sum games, where\nagents compete with each other for their rewards, the reward of the agent\ndepends on the opponent's strategy. Thus, a critical problem emerges when both\nagents learn their strategy following standard algorithms such as replicator\ndynamics and gradient ascent; their learning dynamics often draw cycles and\ncannot converge to their optimal strategies, i.e., the Nash equilibrium. We\ntackle this problem with a novel perspective on asymmetry in learning\nalgorithms between the agents. We consider with-memory games where the agents\ncan store the played actions in their memories in order to choose their\nsubsequent actions. In such games, we focus on the asymmetry in memory\ncapacities between the agents. Interestingly, we demonstrate that learning\ndynamics converge to the Nash equilibrium when the agents have different memory\ncapacities, from theoretical and experimental aspects. Moreover, we give an\ninterpretation of this convergence; the agent with a longer memory can use a\nmore complex strategy, endowing the utility of the other with strict concavity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:29:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13620","submitter":"Zeyu Xiao","authors":"Zeyu Xiao, Jiawang Bai, Zhihe Lu, Zhiwei Xiong","title":"A Dive into SAM Prior in Image Restoration","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The goal of image restoration (IR), a fundamental issue in computer vision,\nis to restore a high-quality (HQ) image from its degraded low-quality (LQ)\nobservation. Multiple HQ solutions may correspond to an LQ input in this poorly\nposed problem, creating an ambiguous solution space. This motivates the\ninvestigation and incorporation of prior knowledge in order to effectively\nconstrain the solution space and enhance the quality of the restored images. In\nspite of the pervasive use of hand-crafted and learned priors in IR, limited\nattention has been paid to the incorporation of knowledge from large-scale\nfoundation models. In this paper, we for the first time leverage the prior\nknowledge of the state-of-the-art segment anything model (SAM) to boost the\nperformance of existing IR networks in an parameter-efficient tuning manner. In\nparticular, the choice of SAM is based on its robustness to image degradations,\nsuch that HQ semantic masks can be extracted from it. In order to leverage\nsemantic priors and enhance restoration quality, we propose a lightweight SAM\nprior tuning (SPT) unit. This plug-and-play component allows us to effectively\nintegrate semantic priors into existing IR networks, resulting in significant\nimprovements in restoration quality. As the only trainable module in our\nmethod, the SPT unit has the potential to improve both efficiency and\nscalability. We demonstrate the effectiveness of the proposed method in\nenhancing a variety of methods across multiple tasks, such as image\nsuper-resolution and color image denoising.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:31:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13621","submitter":"Sihan Wang","authors":"Sihan Wang, Jingran Xu, and Yong Zeng","title":"On the Energy-Efficiency Trade-off Between Active and Passive\n  Communications with RIS-based Symbiotic Radio","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.ET math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Symbiotic radio (SR) is a promising technology of spectrum- and\nenergy-efficient wireless systems, for which the key idea is to use cognitive\nbackscattering communication to achieve mutualistic spectrum and energy sharing\nwith passive backscatter devices (BDs). In this paper, a reconfigurable\nintelligent surface (RIS) based SR system is considered, where the RIS is used\nnot only to assist the primary active communication, but also for passive\ncommunication to transmit its own information. For the considered system, we\ninvestigate the EE trade-off between active and passive communications, by\ncharacterizing the EE region. To gain some insights, we first derive the\nmaximum achievable individual EEs of the primary transmitter (PT) and RIS,\nrespectively, and then analyze the asymptotic performance by exploiting the\nchannel hardening effect. To characterize the non-trivial EE trade-off, we\nformulate an optimization problem to find the Pareto boundary of the EE region\nby jointly optimizing the transmit beamforming, power allocation and the\npassive beamforming of RIS. The formulated problem is non-convex, and an\nefficient algorithm is proposed by decomposing it into a series of subproblems\nby using alternating optimization (AO) and successive convex approximation\n(SCA) techniques. Finally, simulation results are presented to validate the\neffectiveness of the proposed algorithm.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:38:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13622","submitter":"Tao Zhuo","authors":"Tao Zhuo, Zhiyong Cheng, Zan Gao, Mohan Kankanhalli","title":"Continual Learning with Strong Experience Replay","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Continual Learning (CL) aims at incrementally learning new tasks without\nforgetting the knowledge acquired from old ones. Experience Replay (ER) is a\nsimple and effective rehearsal-based strategy, which optimizes the model with\ncurrent training data and a subset of old samples stored in a memory buffer. To\nfurther reduce forgetting, recent approaches extend ER with various techniques,\nsuch as model regularization and memory sampling. However, the prediction\nconsistency between the new model and the old one on current training data has\nbeen seldom explored, resulting in less knowledge preserved when few previous\nsamples are available. To address this issue, we propose a CL method with\nStrong Experience Replay (SER), which additionally utilizes future experiences\nmimicked on the current training data, besides distilling past experience from\nthe memory buffer. In our method, the updated model will produce approximate\noutputs as its original ones, which can effectively preserve the acquired\nknowledge. Experimental results on multiple image classification datasets show\nthat our SER method surpasses the state-of-the-art methods by a noticeable\nmargin.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:42:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13623","submitter":"Wenxuan Wang","authors":"Wenxuan Wang, Jingyuan Huang, Chang Chen, Jiazhen Gu, Jianping Zhang,\n  Weibin Wu, Pinjia He, Michael Lyu","title":"Validating Multimedia Content Moderation Software via Semantic Fusion","comments":"Accepted by ISSTA 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI cs.CL cs.CV cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The exponential growth of social media platforms, such as Facebook and\nTikTok, has revolutionized communication and content publication in human\nsociety. Users on these platforms can publish multimedia content that delivers\ninformation via the combination of text, audio, images, and video. Meanwhile,\nthe multimedia content release facility has been increasingly exploited to\npropagate toxic content, such as hate speech, malicious advertisements, and\npornography. To this end, content moderation software has been widely deployed\non these platforms to detect and blocks toxic content. However, due to the\ncomplexity of content moderation models and the difficulty of understanding\ninformation across multiple modalities, existing content moderation software\ncan fail to detect toxic content, which often leads to extremely negative\nimpacts.\n  We introduce Semantic Fusion, a general, effective methodology for validating\nmultimedia content moderation software. Our key idea is to fuse two or more\nexisting single-modal inputs (e.g., a textual sentence and an image) into a new\ninput that combines the semantics of its ancestors in a novel manner and has\ntoxic nature by construction. This fused input is then used for validating\nmultimedia content moderation software. We realized Semantic Fusion as DUO, a\npractical content moderation software testing tool. In our evaluation, we\nemploy DUO to test five commercial content moderation software and two\nstate-of-the-art models against three kinds of toxic content. The results show\nthat DUO achieves up to 100% error finding rate (EFR) when testing moderation\nsoftware. In addition, we leverage the test cases generated by DUO to retrain\nthe two models we explored, which largely improves model robustness while\nmaintaining the accuracy on the original test set.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:44:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13624","submitter":"William Fiore","authors":"William Fiore, Lina Levin, Maura A. McLaughlin, Akash Anumarlapudi,\n  David L. Kaplan, Joseph K. Swiggum, Gabriella Y. Agazie, Robert Bavisotto,\n  Pragya Chawla, Megan E. DeCesar, Timothy Dolch, Emmanuel Fonseca, Victoria M.\n  Kaspi, Zachary Komassa, Vlad I. Kondratiev, Joeri van Leeuwen, Evan F. Lewis,\n  Ryan S. Lynch, Alexander E. McEwen, Rusty Mundorf, Hind Al Noori, Emilie\n  Parent, Ziggy Pleunis, Scott M. Ransom, Xavier Siemens, Ren\\'ee Spiewak,\n  Ingrid H. Stairs, Mayuresh Surnis, Thomas J. Tobin","title":"The Green Bank North Celestial Cap Survey. VIII. 21 New Pulsar Timing\n  Solutions","comments":"32 pages, 17 figures, 9 tables. Submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present timing solutions for 21 pulsars discovered in 350 MHz surveys\nusing the Green Bank Telescope (GBT). All were discovered in the Green Bank\nNorth Celestial Cap pulsar survey, with the exception of PSR J0957-0619, which\nwas found in the GBT 350 MHz Drift-scan pulsar survey. The majority of our\ntiming observations were made with the GBT at 820 MHz. With a spin period of 37\nms and a 528-day orbit, PSR J0032+6946 joins a small group of five other mildly\nrecycled wide binary pulsars, for which the duration of recycling through\naccretion is limited by the length of the companion's giant phase. PSRs\nJ0141+6303 and J1327+3423 are new disrupted recycled pulsars. We incorporate\nArecibo observations from the NANOGrav pulsar timing array into our analysis of\nthe latter. We also observed PSR J1327+3423 with the Long Wavelength Array, and\nour data suggest a frequency-dependent dispersion measure. PSR J0957-0619 was\ndiscovered as a rotating radio transient, but is a nulling pulsar at 820 MHz.\nPSR J1239+3239 is a new millisecond pulsar (MSP) in a 4-day orbit with a\nlow-mass companion. Four of our pulsars already have published timing\nsolutions, which we update in this work: the recycled wide binary PSR\nJ0214+5222, the non-eclipsing black widow PSR J0636+5128, the disrupted\nrecycled pulsar J1434+7257, and the eclipsing binary MSP J1816+4510, which is\nin an 8.7 hr orbit with a redback-mass companion.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:44:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13625","submitter":"Jiang Liu","authors":"Jiang Liu, Chun Pong Lau, Rama Chellappa","title":"DiffProtect: Generate Adversarial Examples with Diffusion Models for\n  Facial Privacy Protection","comments":"Code will be available at https://github.com/joellliu/DiffProtect/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The increasingly pervasive facial recognition (FR) systems raise serious\nconcerns about personal privacy, especially for billions of users who have\npublicly shared their photos on social media. Several attempts have been made\nto protect individuals from being identified by unauthorized FR systems\nutilizing adversarial attacks to generate encrypted face images. However,\nexisting methods suffer from poor visual quality or low attack success rates,\nwhich limit their utility. Recently, diffusion models have achieved tremendous\nsuccess in image generation. In this work, we ask: can diffusion models be used\nto generate adversarial examples to improve both visual quality and attack\nperformance? We propose DiffProtect, which utilizes a diffusion autoencoder to\ngenerate semantically meaningful perturbations on FR systems. Extensive\nexperiments demonstrate that DiffProtect produces more natural-looking\nencrypted images than state-of-the-art methods while achieving significantly\nhigher attack success rates, e.g., 24.5% and 25.1% absolute improvements on the\nCelebA-HQ and FFHQ datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:45:49 GMT"},{"version":"v2","created":"Sun, 28 May 2023 20:23:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13626","submitter":"Yang Deng","authors":"Yang Deng, Wenqiang Lei, Lizi Liao, Tat-Seng Chua","title":"Prompting and Evaluating Large Language Models for Proactive Dialogues:\n  Clarification, Target-guided, and Non-collaboration","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Conversational systems based on Large Language Models (LLMs), such as\nChatGPT, show exceptional proficiency in context understanding and response\ngeneration. However, despite their impressive capabilities, they still possess\nlimitations, such as providing randomly-guessed answers to ambiguous queries or\nfailing to refuse users' requests, both of which are considered aspects of a\nconversational agent's proactivity. This raises the question of whether\nLLM-based conversational systems are equipped to handle proactive dialogue\nproblems. In this work, we conduct a comprehensive analysis of LLM-based\nconversational systems, specifically focusing on three aspects of proactive\ndialogue systems: clarification, target-guided, and non-collaborative\ndialogues. To trigger the proactivity of LLMs, we propose the Proactive\nChain-of-Thought prompting scheme, which augments LLMs with the goal planning\ncapability over descriptive reasoning chains. Empirical findings are discussed\nto promote future studies on LLM-based proactive dialogue systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:49:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13627","submitter":"Samuel Cahyawijaya","authors":"Samuel Cahyawijaya, Holy Lovenia, Tiezheng Yu, Willy Chung, Pascale\n  Fung","title":"Instruct-Align: Teaching Novel Languages with to LLMs through\n  Alignment-based Cross-Lingual Instruction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Instruction-tuned large language models (LLMs) have shown remarkable\ngeneralization capability over multiple tasks in multiple languages.\nNevertheless, their generalization towards different languages varies\nespecially to underrepresented languages or even to unseen languages. Prior\nworks on adapting new languages to LLMs find that naively adapting new\nlanguages to instruction-tuned LLMs will result in catastrophic forgetting,\nwhich in turn causes the loss of multitasking ability in these LLMs. To tackle\nthis, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables\ninstruction-tuned LLMs to learn cross-lingual alignment between unseen and\npreviously learned languages via alignment-based cross-lingual\ninstruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$\nis able to learn a new language effectively with only a limited amount of\nparallel data and at the same time prevent catastrophic forgetting by applying\ncontinual instruction-tuning through experience replay. Our work contributes to\nthe progression of language adaptation methods for instruction-tuned LLMs and\nopens up the possibility of adapting underrepresented low-resource languages\ninto existing instruction-tuned LLMs. Our code will be publicly released upon\nacceptance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:51:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13628","submitter":"Ran Zhou","authors":"Ran Zhou, Xin Li, Lidong Bing, Erik Cambria, Chunyan Miao","title":"Improving Self-training for Cross-lingual Named Entity Recognition with\n  Contrastive and Prototype Learning","comments":"Accepted by ACL2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In cross-lingual named entity recognition (NER), self-training is commonly\nused to bridge the linguistic gap by training on pseudo-labeled target-language\ndata. However, due to sub-optimal performance on target languages, the pseudo\nlabels are often noisy and limit the overall performance. In this work, we aim\nto improve self-training for cross-lingual NER by combining representation\nlearning and pseudo label refinement in one coherent framework. Our proposed\nmethod, namely ContProto mainly comprises two components: (1) contrastive\nself-training and (2) prototype-based pseudo-labeling. Our contrastive\nself-training facilitates span classification by separating clusters of\ndifferent classes, and enhances cross-lingual transferability by producing\nclosely-aligned representations between the source and target language.\nMeanwhile, prototype-based pseudo-labeling effectively improves the accuracy of\npseudo labels during training. We evaluate ContProto on multiple transfer\npairs, and experimental results show our method brings in substantial\nimprovements over current state-of-the-art methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:52:16 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 16:32:41 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13629","submitter":"Hongfei Xue","authors":"Hongfei Xue, Qijie Shao, Peikun Chen, Pengcheng Guo, Lei Xie, Jie Liu","title":"TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation\n  Learning for Cross-lingual Speech Recognition","comments":"5 pages, 3 figures. Accepted by INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  UniSpeech has achieved superior performance in cross-lingual automatic speech\nrecognition (ASR) by explicitly aligning latent representations to phoneme\nunits using multi-task self-supervised learning. While the learned\nrepresentations transfer well from high-resource to low-resource languages,\npredicting words directly from these phonetic representations in downstream ASR\nis challenging. In this paper, we propose TranUSR, a two-stage model comprising\na pre-trained UniData2vec and a phoneme-to-word Transcoder. Different from\nUniSpeech, UniData2vec replaces the quantized discrete representations with\ncontinuous and contextual representations from a teacher model for\nphonetically-aware pre-training. Then, Transcoder learns to translate phonemes\nto words with the aid of extra texts, enabling direct word generation.\nExperiments on Common Voice show that UniData2vec reduces PER by 5.3% compared\nto UniSpeech, while Transcoder yields a 14.4% WER reduction compared to\ngrapheme fine-tuning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:57:45 GMT"},{"version":"v2","created":"Tue, 30 May 2023 13:57:38 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13630","submitter":"Songnian Xu","authors":"Songnian Xu","title":"Near automorphisms of complement of a cycle","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Let $G$ be a graph with vertex set $V(G)$, $f$ a permutation of $V(G)$.\nDefine $\\delta_f(G)=|d(x,y)-d(f(x),f(y))|$ and\n$\\delta_f(G)=\\Sigma\\delta_f(x,y)$, where the sum is taken over all unordered\npair $x$, $y$ of distinct vertices of $G$. $\\delta_f(x,U)=\\Sigma\\delta_f(x,y)$,\nwhere $U\\subseteq V(G)$ and $y\\in U$. Let $\\pi(G)$ denote the smallest positive\nvalue of $\\delta_f(G)$ among all permutations of $V(G)$. A permutation $f$ with\n$\\delta_f(G)=\\pi(G)$ is called a near automorphisms of $G$. In this paper, the\nnear automorphism of the complement of a cycle is characterized, moreover,\n$\\pi(\\overline{C_n})$ is determined.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:57:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13631","submitter":"Weixi Feng","authors":"Siqi Liu, Weixi Feng, Wenhu Chen, William Yang Wang","title":"EDIS: Entity-Driven Image Search over Multimodal Web Content","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Making image retrieval methods practical for real-world search applications\nrequires significant progress in dataset scales, entity comprehension, and\nmultimodal information fusion. In this work, we introduce\n\\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch (EDIS), a\nchallenging dataset for cross-modal image search in the news domain. EDIS\nconsists of 1 million web images from actual search engine results and curated\ndatasets, with each image paired with a textual description. Unlike datasets\nthat assume a small set of single-modality candidates, EDIS reflects real-world\nweb image search scenarios by including a million multimodal image-text pairs\nas candidates. EDIS encourages the development of retrieval models that\nsimultaneously address cross-modal information fusion and matching. To achieve\naccurate ranking results, a model must: 1) understand named entities and events\nfrom text queries, 2) ground entities onto images or text descriptions, and 3)\neffectively fuse textual and visual representations. Our experimental results\nshow that EDIS challenges state-of-the-art methods with dense entities and a\nlarge-scale candidate set. The ablation study also proves that fusing textual\nfeatures with visual features is critical in improving retrieval results.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:59:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13632","submitter":"Yifu Qiu","authors":"Yifu Qiu, Yftah Ziser, Anna Korhonen, Edoardo M. Ponti, Shay B. Cohen","title":"Detecting and Mitigating Hallucinations in Multilingual Summarisation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hallucinations pose a significant challenge to the reliability of neural\nmodels for abstractive summarisation. While automatically generated summaries\nmay be fluent, they often lack faithfulness to the original document. This\nissue becomes even more pronounced in low-resource settings, such as\ncross-lingual transfer. With the existing faithful metrics focusing on English,\neven measuring the extent of this phenomenon in cross-lingual settings is hard.\nTo address this, we first develop a novel metric, mFACT, evaluating the\nfaithfulness of non-English summaries, leveraging translation-based transfer\nfrom multiple English faithfulness metrics. We then propose a simple but\neffective method to reduce hallucinations with a cross-lingual transfer, which\nweighs the loss of each training example by its faithfulness score. Through\nextensive experiments in multiple languages, we demonstrate that mFACT is the\nmetric that is most suited to detect hallucinations. Moreover, we find that our\nproposed loss weighting method drastically increases both performance and\nfaithfulness according to both automatic and human evaluation when compared to\nstrong baselines for cross-lingual transfer such as MAD-X. Our code and dataset\nare available at https://github.com/yfqiu-nlp/mfact-summ.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:59:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13633","submitter":"Yuting Wu","authors":"Yuting Wu and Chengyang Yi","title":"Michael-Simon Sobolev inequalities in Euclidean space","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inspired by [1, 13], we prove Michael-Simon type inequalities for smooth\nsymmetric uniformly positive define (0, 2)-tensor fields on compact\nsubmanifolds in Euclidean space by the Alexandrov-Bakelman-Pucci (ABP) method.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:59:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13634","submitter":"Zekun Qiu","authors":"Zekun Qiu, Zhipu Xie, Zehua Ji, Yuhao Mao, Ke Cheng","title":"SMAP: A Novel Heterogeneous Information Framework for Scenario-based\n  Optimal Model Assignment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The increasing maturity of big data applications has led to a proliferation\nof models targeting the same objectives within the same scenarios and datasets.\nHowever, selecting the most suitable model that considers model's features\nwhile taking specific requirements and constraints into account still poses a\nsignificant challenge. Existing methods have focused on worker-task assignments\nbased on crowdsourcing, they neglect the scenario-dataset-model assignment\nproblem. To address this challenge, a new problem named the Scenario-based\nOptimal Model Assignment (SOMA) problem is introduced and a novel framework\nentitled Scenario and Model Associative percepts (SMAP) is developed. SMAP is a\nheterogeneous information framework that can integrate various types of\ninformation to intelligently select a suitable dataset and allocate the optimal\nmodel for a specific scenario. To comprehensively evaluate models, a new score\nfunction that utilizes multi-head attention mechanisms is proposed. Moreover, a\nnovel memory mechanism named the mnemonic center is developed to store the\nmatched heterogeneous information and prevent duplicate matching. Six popular\ntraffic scenarios are selected as study cases and extensive experiments are\nconducted on a dataset to verify the effectiveness and efficiency of SMAP and\nthe score function.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:01:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13635","submitter":"Ran Liu","authors":"Ran Liu and Billy Pik Lik Lau and Khairuldanial Ismail and Achala\n  Chathuranga and Chau Yuen and Simon X. Yang and Yong Liang Guan and Shiwen\n  Mao and U-Xuan Tan","title":"Exploiting Radio Fingerprints for Simultaneous Localization and Mapping","comments":"This paper has been accepted by IEEE Pervasive Computing with DOI:\n  10.1109/MPRV.2023.3274770","journal-ref":null,"doi":"10.1109/MPRV.2023.3274770","report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Simultaneous localization and mapping (SLAM) is paramount for unmanned\nsystems to achieve self-localization and navigation. It is challenging to\nperform SLAM in large environments, due to sensor limitations, complexity of\nthe environment, and computational resources. We propose a novel approach for\nlocalization and mapping of autonomous vehicles using radio fingerprints, for\nexample WiFi (Wireless Fidelity) or LTE (Long Term Evolution) radio features,\nwhich are widely available in the existing infrastructure. In particular, we\npresent two solutions to exploit the radio fingerprints for SLAM. In the first\nsolution-namely Radio SLAM, the output is a radio fingerprint map generated\nusing SLAM technique. In the second solution-namely Radio+LiDAR SLAM, we use\nradio fingerprint to assist conventional LiDAR-based SLAM to improve accuracy\nand speed, while generating the occupancy map. We demonstrate the effectiveness\nof our system in three different environments, namely outdoor, indoor building,\nand semi-indoor environment.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:01:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13636","submitter":"Zhihao Xu","authors":"Jinghu Liu and Zhihao Xu","title":"From Ergodicity to Many-Body Localization in a One-Dimensional\n  Interacting Non-Hermitian Stark System","comments":"10 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.dis-nn quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent studies on disorder-induced many-body localization (MBL) in\nnon-Hermitian quantum systems have attracted great interest. However, the\nnon-Hermitian disorder-free MBL still needs to be clarified. We consider a\none-dimensional interacting Stark model with nonreciprocal hoppings having\ntime-reversal symmetry, the properties of which are boundary dependent. Under\nperiodic boundary conditions (PBC), such a model exhibits three types of phase\ntransitions: the real-complex transition of eigenenergies, the topological\nphase transition, and the non-Hermitian Stark MBL transition. The real-complex\nand topological phase transitions occur at the same point in the thermodynamic\nlimit, but do not coincide with the non-Hermitian Stark MBL transition, which\nis quite different from the non-Hermitian disordered cases. By the level\nstatistics, the system undergoes from the Ginibre ensemble (GE) to Gaussian\northogonal ensemble (GOE) to Possion ensemble (PE) transitions with the\nincrease of the linear tilt potential's strength $\\gamma$. The real-complex\ntransition of the eigenvalues is accompanied by the GE-to-GOE transition in the\nergodic regime. Moreover, the second transition of the level statistics\ncorresponds to the occurrence of non-Hermitian Stark MBL. We demonstrate that\nthe non-Hermitian Stark MBL is robust and shares many similarities with\ndisorder-induced MBL, which several existing characteristic quantities of the\nspectral statistics and eigenstate properties can confirm. The dynamical\nevolutions of the entanglement entropy and the density imbalance can\ndistinguish the real-complex and Stark MBL transitions. Finally, we find that\nour system under open boundary conditions lacks a real-complex transition, and\nthe transition of non-Hermitian Stark MBL is the same as that under PBCs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:09:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13637","submitter":"Narutatsu Ri","authors":"Narutatsu Ri, Bill Sun, Sam Davidson, Zhou Yu","title":"IdEALS: Idiomatic Expressions for Advancement of Language Skills","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Although significant progress has been made in developing methods for\nGrammatical Error Correction (GEC), addressing word choice improvements has\nbeen notably lacking and enhancing sentence expressivity by replacing phrases\nwith advanced expressions is an understudied aspect. In this paper, we focus on\nthis area and present our investigation into the task of incorporating the\nusage of idiomatic expressions in student writing. To facilitate our study, we\ncurate extensive training sets and expert-annotated testing sets using\nreal-world data and evaluate various approaches and compare their performance\nagainst human experts.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:11:41 GMT"},{"version":"v2","created":"Wed, 24 May 2023 17:25:55 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13638","submitter":"Manuel Rivera","authors":"Emilio Minichiello, Manuel Rivera, Mahmoud Zeinalian","title":"A detailed look at the Szczarba map","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT math.CT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explain how to derive an explicit formula for a natural transformation\nrelating the (left adjoints of) the homotopy coherent nerve and the Dwyer-Kan\nsimplicial classifying space functor. The formula is derived using a method\nintroduced by Szczarba when comparing two different chain models of a\nfibration. This note may be taken as a companion to section 3 of our previous\narticle \"Categorical models for path spaces\".\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:14:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13639","submitter":"Yuta Kambe","authors":"Yuta Kambe","title":"Analysis of the computation of Gr\\\"obner bases and Gr\\\"obner\n  degenerations via theory of signatures","comments":"22 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The signatures of polynomials were originally introduced by Faug\\`{e}re for\nthe efficient computation of Gr\\\"obner bases [Fau02], and redefined by\nArri-Perry [AP11] as the standard monomials modulo the module of syzygies.\nSince it is difficult to determine signatures, Vaccon-Yokoyama [VY17]\nintroduced an alternative object called guessed signatures. In this paper, we\nconsider a module $\\mathrm{Gobs}(F)$ consisting of the equivalent classes of\nthe guessed signatures for a tuple of polynomials $F$. This is the residue\nmodule\n$\\mathrm{ini}_{\\prec}(\\mathrm{Syz}(\\mathrm{LM}(F)))/\\mathrm{ini}_{\\prec}(\\mathrm{Syz}(F))$\ndefined by the initial modules of the syzygy modules with respect to the\nSchreyer order. We first show that $F$ is a Gr\\\"obner basis if and only if\n$\\mathrm{Gobs}(F)$ is the zero module. Then we find a necessity to compute\ndivisions of S-polynomials to find Gr\\\"obner bases. We give examples of\ntransitions of minimal free resolutions of $\\mathrm{Gobs}(F)$ in a signature\nbased algorithm. Finally, we show a connection between the module\n$\\mathrm{Gobs}(F)$ and Gr\\\"obner degenerations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:15:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13640","submitter":"Mitsuhiro Nishijima","authors":"Mitsuhiro Nishijima","title":"On the longest chain of faces of completely positive and copositive\n  cones","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a wide class of closed convex cones $K$ in the space of real\n$n\\times n$ symmetric matrices and establish the existence of a chain of faces\nof $K$, the length of which is maximized at $\\frac{n(n+1)}{2} + 1$. Examples of\nsuch cones include, but are not limited to, the completely positive and the\ncopositive cones. Using this chain, we prove that the distance to polyhedrality\nof any closed convex cone $K$ that is sandwiched between the completely\npositive cone and the doubly nonnegative cone of order $n \\ge 2$, as well as\nits dual, is at least $\\frac{n(n+1)}{2} - 2$, which is also the worst-case\nscenario.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:18:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13641","submitter":"Nikhil Krishnaswamy","authors":"Abhijnan Nath, Sheikh Mannan, Nikhil Krishnaswamy","title":"AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese","comments":"16 pages, 6 figures, 8 tables, appearing in Findings of the ACL: ACL\n  2023. This version compiled using pdfLaTeX-compatible Assamese script font.\n  Assamese text may appear differently here than in official ACL 2023\n  proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite their successes in NLP, Transformer-based language models still\nrequire extensive computing resources and suffer in low-resource or low-compute\nsettings. In this paper, we present AxomiyaBERTa, a novel BERT model for\nAssamese, a morphologically-rich low-resource language (LRL) of Eastern India.\nAxomiyaBERTa is trained only on the masked language modeling (MLM) task,\nwithout the typical additional next sentence prediction (NSP) objective, and\nour results show that in resource-scarce settings for very low-resource\nlanguages like Assamese, MLM alone can be successfully leveraged for a range of\ntasks. AxomiyaBERTa achieves SOTA on token-level tasks like Named Entity\nRecognition and also performs well on \"longer-context\" tasks like Cloze-style\nQA and Wiki Title Prediction, with the assistance of a novel embedding\ndisperser and phonological signals respectively. Moreover, we show that\nAxomiyaBERTa can leverage phonological signals for even more challenging tasks,\nsuch as a novel cross-document coreference task on a translated version of the\nECB+ corpus, where we present a new SOTA result for an LRL. Our source code and\nevaluation scripts may be found at https://github.com/csu-signal/axomiyaberta.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:19:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13642","submitter":"Wadim Gerner","authors":"Wadim Gerner","title":"Existence of optimal domains for the helicity maximisation problem among\n  domains satisfying a uniform ball condition","comments":"11 pages, comments welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the present work we present a general framework which guarantees the\nexistence of optimal domains for isoperimetric problems within the class of\n$C^{1,1}$-regular domains satisfying a uniform ball condition as long as the\ndesired objective function satisfies certain properties. We then verify that\nthe helicity isoperimetric problem studied by Cantarella, DeTurck, Gluck and\nTeytel in \\cite{CDGT002} satisfies the conditions of our framework and hence\nestablish the existence of optimal domains within the given class of domains.\nWe additionally use the same framework to prove the existence of optimal\ndomains among uniform $C^{1,1}$-domains for a first curl eigenvalue problem\nwhich has been studied recently for other classes of domains in \\cite{EGPS23}.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:33:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13643","submitter":"Jacob Sillman","authors":"Jacob Sillman, Ajay Suresh","title":"Hardware Trojans in Power Conversion Circuits","comments":"4 pages, 6 figures, will not be submitted to any journals","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.SY eess.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This report investigates the potential impact of a Trojan attack on power\nconversion circuits, specifically a switching signal attack designed to trigger\na locking of the pulse width modulation (PWM) signal that goes to a power\nfield-effect transistor (FET). The first simulation shows that this type of\nattack can cause severe overvoltage, potentially leading to functional failure.\nThe report proposes a solution using a large bypass capacitor to force signal\nparity, effectively negating the Trojan circuit. The simulation results\ndemonstrate that the proposed solution can effectively thwart the Trojan\nattack. However, several caveats must be considered, such as the size of the\ncapacitor, possible current leakage, and the possibility that the solution can\nbe circumvented by an adversary with knowledge of the protection strategy.\nOverall, the findings suggest that proper protection mechanisms, such as the\nproposed signal-parity solution, must be considered when designing power\nconversion circuits to mitigate the risk of Trojan attacks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:37:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13644","submitter":"Jing Wang","authors":"Jing Wang, Hairun Xie, Miao Zhang, Hui Xu","title":"Physics-Assisted Reduced-Order Modeling for Identifying Dominant\n  Features of Transonic Buffet","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transonic buffet is a flow instability phenomenon that arises from the\ninteraction between the shock wave and the separated boundary layer. This flow\nphenomenon is considered to be highly detrimental during flight and poses a\nsignificant risk to the structural strength and fatigue life of aircraft. Up to\nnow, there has been a lack of an accurate, efficient, and intuitive metric to\npredict buffet and impose a feasible constraint on aerodynamic design. In this\npaper, a Physics-Assisted Variational Autoencoder (PAVAE) is proposed to\nidentify dominant features of transonic buffet, which combines unsupervised\nreduced-order modeling with additional physical information embedded via a\nbuffet classifier. Specifically, four models with various weights adjusting the\ncontribution of the classifier are trained, so as to investigate the impact of\nbuffet information on the latent space. Statistical results reveal that buffet\nstate can be determined exactly with just one latent space when a proper weight\nof classifier is chosen. The dominant latent space further reveals a strong\nrelevance with the key flow features located in the boundary layers downstream\nof shock. Based on this identification, the displacement thickness at 80%\nchordwise location is proposed as a metric for buffet prediction. This metric\nachieves an accuracy of 98.5% in buffet state classification, which is more\nreliable than the existing separation metric used in design. The proposed\nmethod integrates the benefits of feature extraction, flow reconstruction, and\nbuffet prediction into a unified framework, demonstrating its potential in\nlow-dimensional representations of high-dimensional flow data and interpreting\nthe \"black box\" neural network.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:40:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13645","submitter":"Weiwen Xu","authors":"Weiwen Xu, Xin Li, Wai Lam, Lidong Bing","title":"mPMR: A Multilingual Pre-trained Machine Reader at Scale","comments":"To appear at ACL 2023 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present multilingual Pre-trained Machine Reader (mPMR), a novel method for\nmultilingual machine reading comprehension (MRC)-style pre-training. mPMR aims\nto guide multilingual pre-trained language models (mPLMs) to perform natural\nlanguage understanding (NLU) including both sequence classification and span\nextraction in multiple languages. To achieve cross-lingual generalization when\nonly source-language fine-tuning data is available, existing mPLMs solely\ntransfer NLU capability from a source language to target languages. In\ncontrast, mPMR allows the direct inheritance of multilingual NLU capability\nfrom the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires\nbetter NLU capability for target languages. mPMR also provides a unified solver\nfor tackling cross-lingual span extraction and sequence classification, thereby\nenabling the extraction of rationales to explain the sentence-pair\nclassification process.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:40:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13646","submitter":"Tirthankar Roy","authors":"Sinan Rasiya Koya, Kanak Kanti Kar, Shivendra Srivastava, Tsegaye\n  Tadesse, Mark Svoboda, Tirthankar Roy","title":"An Autoencoder-based Snow Drought Index","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In several regions across the globe, snow has a significant impact on\nhydrology. The amounts of water that infiltrate the ground and flow as runoff\nare driven by the melting of snow. Therefore, it is crucial to study the\nmagnitude and effect of snowmelt. Snow droughts, resulting from reduced snow\nstorage, can drastically impact the water supplies in basins where snow\npredominates, such as in the western United States. Hence, it is important to\ndetect the time and severity of snow droughts efficiently. We propose Snow\nDrought Response Index or SnoDRI, a novel indicator that could be used to\nidentify and quantify snow drought occurrences. Our index is calculated using\ncutting-edge ML algorithms from various snow-related variables. The\nself-supervised learning of an autoencoder is combined with mutual information\nin the model. In this study, we use random forests for feature extraction for\nSnoDRI and assess the importance of each variable. We use reanalysis data\n(NLDAS-2) from 1981 to 2021 for the Pacific United States to study the efficacy\nof the new snow drought index. We evaluate the index by confirming the\ncoincidence of its interpretation and the actual snow drought incidents.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:41:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13647","submitter":"Zhixuan Zhang","authors":"Zhixuan Zhang, Yuheng Huang, Dan Ou, Sen Li, Longbin Li, Qingwen Liu,\n  Xiaoyi Zeng","title":"Rethinking the Role of Pre-ranking in Large-scale E-Commerce Searching\n  System","comments":"13 pages, 7 figures, submitted to KDD 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  E-commerce search systems such as Taobao Search, the largest e-commerce\nsearching system in China, aim at providing users with the most preferred items\n(e.g., products). Due to the massive data and limited time for response, a\ntypical industrial ranking system consists of three or more modules, including\nmatching, pre-ranking, and ranking. The pre-ranking is widely considered a\nmini-ranking module, as it needs to rank hundreds of times more items than the\nranking under limited latency. Existing researches focus on building a lighter\nmodel that imitates the ranking model. As such, the metric of a pre-ranking\nmodel follows the ranking model using Area Under ROC (AUC) for offline\nevaluation. However, such a metric is inconsistent with online A/B tests in\npractice, so engineers have to perform costly online tests to reach a\nconvincing conclusion. In our work, we rethink the role of the pre-ranking. We\nargue that the primary goal of the pre-ranking stage is to return an optimal\nunordered set rather than an ordered list of items because it is the ranking\nthat determines the final exposures. Since AUC measures the quality of an\nordered item list, it is not suitable for evaluating the quality of the output\nunordered set. This paper proposes a new evaluation metric called All-Scenario\nHitrate (ASH) for pre-ranking. ASH is proven effective in the offline\nevaluation and consistent with online A/B tests based on numerous experiments\nin Taobao Search. We also introduce an all-scenario-based multi-objective\nlearning framework (ASMOL), which improves the ASH significantly. Surprisingly,\nthe new pre-ranking model can outperforms the ranking model when outputting\nthousands of items. The phenomenon validates that the pre-ranking stage should\nnot imitate the ranking blindly. With the improvements in ASH consistently\ntranslating to online improvement, it makes a 1.2% GMV improvement on Taobao\nSearch.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:43:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13648","submitter":"Jiayi Wang","authors":"Jiayi Wang, Ke Wang, Yuqi Zhang, Yu Zhao, Pontus Stenetorp","title":"Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine\n  Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:44:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13649","submitter":"Jacob Sillman","authors":"Jacob Sillman","title":"Analog Implementation of the Softmax Function","comments":"17 pages, 20 figures, no current plans to submit to any journals","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An analog implementation of the Softmax activation function is presented. A\nmodular design is proposed, scaling linearly with the number of inputs and\noutputs. The circuit behaves similarly using both a BJT and NMOS design scheme.\nExperimental results extracted from a BJT breadboard prototype presents\ncomputational accuracy within 4.2% margin of error. Simulation data presents\naccuracy within 1.3% margin of error for BJT and 0.9% margin of error for NMOS\ndesign schemes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:47:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13650","submitter":"Saba Ghaffari","authors":"Saba Ghaffari, Ehsan Saleh, Alexander G. Schwing, Yu-Xiong Wang,\n  Martin D. Burke, Saurabh Sinha","title":"Property-Guided Generative Modelling for Robust Model-Based Design with\n  Imbalanced Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The problem of designing protein sequences with desired properties is\nchallenging, as it requires to explore a high-dimensional protein sequence\nspace with extremely sparse meaningful regions. This has led to the development\nof model-based optimization (MBO) techniques that aid in the design, by using\neffective search models guided by the properties over the sequence space.\nHowever, the intrinsic imbalanced nature of experimentally derived datasets\ncauses existing MBO approaches to struggle or outright fail. We propose a\nproperty-guided variational auto-encoder (PGVAE) whose latent space is\nexplicitly structured by the property values such that samples are prioritized\naccording to these properties. Through extensive benchmarking on real and\nsemi-synthetic protein datasets, we demonstrate that MBO with PGVAE robustly\nfinds sequences with improved properties despite significant dataset\nimbalances. We further showcase the generality of our approach to continuous\ndesign spaces, and its robustness to dataset imbalance in an application to\nphysics-informed neural networks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:47:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13651","submitter":"Zhiyi Dong","authors":"Zhiyi Dong and Yongyi Mao","title":"Adversarial Defenses via Vector Quantization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Building upon Randomized Discretization, we develop two novel adversarial\ndefenses against white-box PGD attacks, utilizing vector quantization in higher\ndimensional spaces. These methods, termed pRD and swRD, not only offer a\ntheoretical guarantee in terms of certified accuracy, they are also shown, via\nabundant experiments, to perform comparably or even superior to the current art\nof adversarial defenses. These methods can be extended to a version that allows\nfurther training of the target classifier and demonstrates further improved\nperformance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:49:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13652","submitter":"Jan Silovsky","authors":"Jan Silovsky, Liuhui Deng, Arturo Argueta, Tresi Arvizo, Roger Hsiao,\n  Sasha Kuznietsov, Yiu-Chang Lin, Xiaoqiang Xiao, Yuanyuan Zhang","title":"Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for\n  Low-Resource Speech Recognition with Transducers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Voice technology has become ubiquitous recently. However, the accuracy, and\nhence experience, in different languages varies significantly, which makes the\ntechnology not equally inclusive. The availability of data for different\nlanguages is one of the key factors affecting accuracy, especially in training\nof all-neural end-to-end automatic speech recognition systems.\n  Cross-lingual knowledge transfer and iterative pseudo-labeling are two\ntechniques that have been shown to be successful for improving the accuracy of\nASR systems, in particular for low-resource languages, like Ukrainian.\n  Our goal is to train an all-neural Transducer-based ASR system to replace a\nDNN-HMM hybrid system with no manually annotated training data. We show that\nthe Transducer system trained using transcripts produced by the hybrid system\nachieves 18% reduction in terms of word error rate. However, using a\ncombination of cross-lingual knowledge transfer from related languages and\niterative pseudo-labeling, we are able to achieve 35% reduction of the error\nrate.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:50:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13653","submitter":"Yang Bai","authors":"Yang Bai, Min Cao, Daming Gao, Ziqiang Cao, Chen Chen, Zhenfeng Fan,\n  Liqiang Nie, Min Zhang","title":"RaSa: Relation and Sensitivity Aware Representation Learning for\n  Text-based Person Search","comments":"Accepted by IJCAI 2023. Code is available at\n  https://github.com/Flame-Chasers/RaSa","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-based person search aims to retrieve the specified person images given a\ntextual description. The key to tackling such a challenging task is to learn\npowerful multi-modal representations. Towards this, we propose a Relation and\nSensitivity aware representation learning method (RaSa), including two novel\ntasks: Relation-Aware learning (RA) and Sensitivity-Aware learning (SA). For\none thing, existing methods cluster representations of all positive pairs\nwithout distinction and overlook the noise problem caused by the weak positive\npairs where the text and the paired image have noise correspondences, thus\nleading to overfitting learning. RA offsets the overfitting risk by introducing\na novel positive relation detection task (i.e., learning to distinguish strong\nand weak positive pairs). For another thing, learning invariant representation\nunder data augmentation (i.e., being insensitive to some transformations) is a\ngeneral practice for improving representation's robustness in existing methods.\nBeyond that, we encourage the representation to perceive the sensitive\ntransformation by SA (i.e., learning to detect the replaced words), thus\npromoting the representation's robustness. Experiments demonstrate that RaSa\noutperforms existing state-of-the-art methods by 6.94%, 4.45% and 15.35% in\nterms of Rank@1 on CUHK-PEDES, ICFG-PEDES and RSTPReid datasets, respectively.\nCode is available at: https://github.com/Flame-Chasers/RaSa.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:53:57 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13654","submitter":"Oscar Chew","authors":"Oscar Chew, Kuan-Hao Huang, Kai-Wei Chang, Hsuan-Tien Lin","title":"Understanding and Mitigating Spurious Correlations in Text\n  Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent work has shown that deep learning models are prone to exploit spurious\ncorrelations that are present in the training set, yet may not hold true in\ngeneral. A sentiment classifier may erroneously learn that the token spielberg\nis always tied to positive movie reviews. Relying on spurious correlations may\nlead to significant degradation in generalizability and should be avoided. In\nthis paper, we propose a neighborhood analysis framework to explain how exactly\nlanguage models exploit spurious correlations. Driven by the analysis, we\npropose a family of regularization methods, NFL (do Not Forget your Language)\nto prevent the situation. Experiments on two text classification tasks show\nthat NFL brings a significant improvement over standard fine-tuning in terms of\nrobustness without sacrificing in-distribution accuracy.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:55:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13655","submitter":"Long Lian","authors":"Long Lian, Boyi Li, Adam Yala, Trevor Darrell","title":"LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image\n  Diffusion Models with Large Language Models","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advancements in text-to-image generation with diffusion models have\nyielded remarkable results synthesizing highly realistic and diverse images.\nHowever, these models still encounter difficulties when generating images from\nprompts that demand spatial or common sense reasoning. We propose to equip\ndiffusion models with enhanced reasoning capabilities by using off-the-shelf\npretrained large language models (LLMs) in a novel two-stage generation\nprocess. First, we adapt an LLM to be a text-guided layout generator through\nin-context learning. When provided with an image prompt, an LLM outputs a scene\nlayout in the form of bounding boxes along with corresponding individual\ndescriptions. Second, we steer a diffusion model with a novel controller to\ngenerate images conditioned on the layout. Both stages utilize frozen\npretrained models without any LLM or diffusion model parameter optimization. We\nvalidate the superiority of our design by demonstrating its ability to\noutperform the base diffusion model in accurately generating images according\nto prompts that necessitate both language and spatial reasoning. Additionally,\nour method naturally allows dialog-based scene specification and is able to\nhandle prompts in a language that is not well-supported by the underlying\ndiffusion model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:59:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13656","submitter":"Zexi Huang","authors":"Zexi Huang, Mert Kosan, Arlei Silva, Ambuj Singh","title":"Link Prediction without Graph Neural Networks","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Link prediction, which consists of predicting edges based on graph features,\nis a fundamental task in many graph applications. As for several related\nproblems, Graph Neural Networks (GNNs), which are based on an attribute-centric\nmessage-passing paradigm, have become the predominant framework for link\nprediction. GNNs have consistently outperformed traditional topology-based\nheuristics, but what contributes to their performance? Are there simpler\napproaches that achieve comparable or better results? To answer these\nquestions, we first identify important limitations in how GNN-based link\nprediction methods handle the intrinsic class imbalance of the problem -- due\nto the graph sparsity -- in their training and evaluation. Moreover, we propose\nGelato, a novel topology-centric framework that applies a topological heuristic\nto a graph enhanced by attribute information via graph learning. Our model is\ntrained end-to-end with an N-pair loss on an unbiased training set to address\nclass imbalance. Experiments show that Gelato is 145% more accurate, trains 11\ntimes faster, infers 6,000 times faster, and has less than half of the\ntrainable parameters compared to state-of-the-art GNNs for link prediction.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:59:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13657","submitter":"Md. Mahadi Hassan","authors":"Md Mahadi Hassan, Alex Knipper, Shubhra Kanti Karmaker Santu","title":"ChatGPT as your Personal Data Scientist","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The rise of big data has amplified the need for efficient, user-friendly\nautomated machine learning (AutoML) tools. However, the intricacy of\nunderstanding domain-specific data and defining prediction tasks necessitates\nhuman intervention making the process time-consuming while preventing full\nautomation. Instead, envision an intelligent agent capable of assisting users\nin conducting AutoML tasks through intuitive, natural conversations without\nrequiring in-depth knowledge of the underlying machine learning (ML) processes.\nThis agent's key challenge is to accurately comprehend the user's prediction\ngoals and, consequently, formulate precise ML tasks, adjust data sets and model\nparameters accordingly, and articulate results effectively. In this paper, we\ntake a pioneering step towards this ambitious goal by introducing a\nChatGPT-based conversational data-science framework to act as a \"personal data\nscientist\". Precisely, we utilize Large Language Models (ChatGPT) to build a\nnatural interface between the users and the ML models (Scikit-Learn), which in\nturn, allows us to approach this ambitious problem with a realistic solution.\n  Our model pivots around four dialogue states: Data Visualization, Task\nFormulation, Prediction Engineering, and Result Summary and Recommendation.\nEach state marks a unique conversation phase, impacting the overall user-system\ninteraction. Multiple LLM instances, serving as \"micro-agents\", ensure a\ncohesive conversation flow, granting us granular control over the\nconversation's progression. In summary, we developed an end-to-end system that\nnot only proves the viability of the novel concept of conversational data\nscience but also underscores the potency of LLMs in solving complex tasks.\nInterestingly, its development spotlighted several critical weaknesses in the\ncurrent LLMs (ChatGPT) and highlighted substantial opportunities for\nimprovement.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:00:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13658","submitter":"Farhan Samir","authors":"Farhan Samir and Miikka Silfverberg","title":"Understanding compositional data augmentation in automatic morphological\n  inflection","comments":"13 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Data augmentation techniques are widely used in low-resource automatic\nmorphological inflection to address the issue of data sparsity. However, the\nfull implications of these techniques remain poorly understood. In this study,\nwe aim to shed light on the theoretical aspects of the data augmentation\nstrategy StemCorrupt, a method that generates synthetic examples by randomly\nsubstituting stem characters in existing gold standard training examples. Our\nanalysis uncovers that StemCorrupt brings about fundamental changes in the\nunderlying data distribution, revealing inherent compositional concatenative\nstructure. To complement our theoretical analysis, we investigate the\ndata-efficiency of StemCorrupt. Through evaluation across a diverse set of\nseven typologically distinct languages, we demonstrate that selecting a subset\nof datapoints with both high diversity and high predictive uncertainty\nsignificantly enhances the data-efficiency of StemCorrupt compared to\ncompetitive baselines. Furthermore, we explore the impact of typological\nfeatures on the choice of augmentation strategy and find that languages\nincorporating non-concatenativity, such as morphonological alternations, derive\nless benefit from synthetic examples with high predictive uncertainty. We\nattribute this effect to phonotactic violations induced by StemCorrupt,\nemphasizing the need for further research to ensure optimal performance across\nthe entire spectrum of natural language morphology.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:02:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13659","submitter":"Chenglong Li","authors":"Aihua Zheng, Zhiqi Ma, Zi Wang, Chenglong Li","title":"Flare-Aware Cross-modal Enhancement Network for Multi-spectral Vehicle\n  Re-identification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-spectral vehicle re-identification aims to address the challenge of\nidentifying vehicles in complex lighting conditions by incorporating\ncomplementary visible and infrared information. However, in harsh environments,\nthe discriminative cues in RGB and NIR modalities are often lost due to strong\nflares from vehicle lamps or sunlight, and existing multi-modal fusion methods\nare limited in their ability to recover these important cues. To address this\nproblem, we propose a Flare-Aware Cross-modal Enhancement Network that\nadaptively restores flare-corrupted RGB and NIR features with guidance from the\nflare-immunized thermal infrared spectrum. First, to reduce the influence of\nlocally degraded appearance due to intense flare, we propose a Mutual Flare\nMask Prediction module to jointly obtain flare-corrupted masks in RGB and NIR\nmodalities in a self-supervised manner. Second, to use the flare-immunized TI\ninformation to enhance the masked RGB and NIR, we propose a Flare-Aware\nCross-modal Enhancement module that adaptively guides feature extraction of\nmasked RGB and NIR spectra with prior flare-immunized knowledge from the TI\nspectrum. Third, to extract common informative semantic information from RGB\nand NIR, we propose an Inter-modality Consistency loss that enforces semantic\nconsistency between the two modalities. Finally, to evaluate the proposed\nFACENet in handling intense flare, we introduce a new multi-spectral vehicle\nre-ID dataset, called WMVEID863, with additional challenges such as motion\nblur, significant background changes, and particularly intense flare\ndegradation. Comprehensive experiments on both the newly collected dataset and\npublic benchmark multi-spectral vehicle re-ID datasets demonstrate the superior\nperformance of the proposed FACENet compared to state-of-the-art methods,\nespecially in handling strong flares. The code and dataset will be released\nsoon.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:04:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13660","submitter":"Xiao Yu","authors":"Xiao Yu, Maximillian Chen, Zhou Yu","title":"Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy\n  Planning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Planning for goal-oriented dialogue often requires simulating future dialogue\ninteractions and estimating task progress. Many approaches thus consider\ntraining neural networks to perform look-ahead search algorithms such as A*\nsearch and Monte Carlo Tree Search (MCTS). However, this training often require\nabundant annotated data, which creates challenges when faced with noisy\nannotations or low-resource settings. We introduce GDP-Zero, an approach using\nOpen-Loop MCTS to perform goal-oriented dialogue policy planning without any\nmodel training. GDP-Zero prompts a large language model to act as a policy\nprior, value function, user simulator, and system model during the tree search.\nWe evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that\nits responses are preferred over ChatGPT up to 59.32% of the time, and are\nrated more persuasive than ChatGPT during interactive evaluations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:07:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13661","submitter":"Yikang Pan","authors":"Yikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, Min-Yen Kan,\n  William Yang Wang","title":"On the Risk of Misinformation Pollution with Large Language Models","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we comprehensively investigate the potential misuse of modern\nLarge Language Models (LLMs) for generating credible-sounding misinformation\nand its subsequent impact on information-intensive applications, particularly\nOpen-Domain Question Answering (ODQA) systems. We establish a threat model and\nsimulate potential misuse scenarios, both unintentional and intentional, to\nassess the extent to which LLMs can be utilized to produce misinformation. Our\nstudy reveals that LLMs can act as effective misinformation generators, leading\nto a significant degradation in the performance of ODQA systems. To mitigate\nthe harm caused by LLM-generated misinformation, we explore three defense\nstrategies: prompting, misinformation detection, and majority voting. While\ninitial results show promising trends for these defensive strategies, much more\nwork needs to be done to address the challenge of misinformation pollution. Our\nwork highlights the need for further research and interdisciplinary\ncollaboration to address LLM-generated misinformation and to promote\nresponsible use of LLMs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:10:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13662","submitter":"Eng Lieh Ouh","authors":"Eng Lieh Ouh, Benjamin Kok Siew Gan","title":"Are you cloud-certified? Preparing Computing Undergraduates for Cloud\n  Certification with Experiential Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Cloud Computing skills have been increasing in demand. Many software\nengineers are learning these skills and taking cloud certification examinations\nto be job competitive. Preparing undergraduates to be cloud-certified remains\nchallenging as cloud computing is a relatively new topic in the computing\ncurriculum, and many of these certifications require working experience. In\nthis paper, we report our experiences designing a course with experiential\nlearning to prepare our computing undergraduates to take the cloud\ncertification. We adopt a university project-based experiential learning\nframework to engage industry partners who provide project requirements for\nstudents to develop cloud solutions and an experiential risk learning model to\ndesign the course contents. We prepare these students to take on the Amazon Web\nServices Solution Architect - Associate (AWS-SAA) while doing the course. We do\nthis over 3 semester terms and report our findings before and after our design\nwith experiential learning. We are motivated by the students' average 93\\%\npassing rates over the terms. Even when the certification is taken out of the\ngraded components, we still see an encouraging 89\\% participation rate. The\nquantitative feedback shows increased ratings across the survey questions\ncompared to before experiential learning. We acknowledge concerns about the\nstudents' heavy workload and increased administrative efforts for the faculty\nmembers. We summarise our approach with actionable weekly topics, activities\nand takeaways. We hope this experience report can help other educators design\ncloud computing content and certifications for computing students in software\nengineering.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:12:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13663","submitter":"Shuai Wang","authors":"Lexiong Huang, Ruihua Han, Guoliang Li, He Li, Shuai Wang, Yang Wang,\n  Chengzhong Xu","title":"iCOIL: Scenario Aware Autonomous Parking Via Integrated Constrained\n  Optimization and Imitation Learning","comments":"6 pages, 8 figures, IEEE ICDCS Workshops, 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Autonomous parking (AP) is an emering technique to navigate an intelligent\nvehicle to a parking space without any human intervention. Existing AP methods\nbased on mathematical optimization or machine learning may lead to potential\nfailures due to either excessive execution time or lack of generalization. To\nfill this gap, this paper proposes an integrated constrained optimization and\nimitation learning (iCOIL) approach to achieve efficient and reliable AP. The\niCOIL method has two candidate working modes, i.e., CO and IL, and adopts a\nhybrid scenario analysis (HSA) model to determine the better mode under various\nscenarios. We implement and verify iCOIL on the Macao Car Racing Metaverse\n(MoCAM) platform. Results show that iCOIL properly adapts to different\nscenarios during the entire AP procedure, and achieves significantly larger\nsuccess rates than other benchmarks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:12:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13664","submitter":"Achraf Bahamou","authors":"Achraf Bahamou, Donald Goldfarb","title":"Layer-wise Adaptive Step-Sizes for Stochastic First-Order Methods for\n  Deep Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a new per-layer adaptive step-size procedure for stochastic\nfirst-order optimization methods for minimizing empirical loss functions in\ndeep learning, eliminating the need for the user to tune the learning rate\n(LR). The proposed approach exploits the layer-wise stochastic curvature\ninformation contained in the diagonal blocks of the Hessian in deep neural\nnetworks (DNNs) to compute adaptive step-sizes (i.e., LRs) for each layer. The\nmethod has memory requirements that are comparable to those of first-order\nmethods, while its per-iteration time complexity is only increased by an amount\nthat is roughly equivalent to an additional gradient computation. Numerical\nexperiments show that SGD with momentum and AdamW combined with the proposed\nper-layer step-sizes are able to choose effective LR schedules and outperform\nfine-tuned LR versions of these methods as well as popular first-order and\nsecond-order algorithms for training DNNs on Autoencoder, Convolutional Neural\nNetwork (CNN) and Graph Convolutional Network (GCN) models. Finally, it is\nproved that an idealized version of SGD with the layer-wise step sizes\nconverges linearly when using full-batch gradients.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:12:55 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 01:25:48 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13665","submitter":"Linwei Tao","authors":"Linwei Tao, Minjing Dong and Chang Xu","title":"Dual Focal Loss for Calibration","comments":"ICML 2023 Accept","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The use of deep neural networks in real-world applications require\nwell-calibrated networks with confidence scores that accurately reflect the\nactual probability. However, it has been found that these networks often\nprovide over-confident predictions, which leads to poor calibration. Recent\nefforts have sought to address this issue by focal loss to reduce\nover-confidence, but this approach can also lead to under-confident\npredictions. While different variants of focal loss have been explored, it is\ndifficult to find a balance between over-confidence and under-confidence. In\nour work, we propose a new loss function by focusing on dual logits. Our method\nnot only considers the ground truth logit, but also take into account the\nhighest logit ranked after the ground truth logit. By maximizing the gap\nbetween these two logits, our proposed dual focal loss can achieve a better\nbalance between over-confidence and under-confidence. We provide theoretical\nevidence to support our approach and demonstrate its effectiveness through\nevaluations on multiple models and datasets, where it achieves state-of-the-art\nperformance. Code is available at https://github.com/Linwei94/DualFocalLoss\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:19:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13666","submitter":"Wanli Xing","authors":"Wanli Xing, Xuan-Gong Wang, Anthony W. Thomas","title":"Electromagnetic form factors for nucleons in short-range correlations","comments":"6 pages, 6 figures, 2 tables","journal-ref":null,"doi":null,"report-no":"ADP-23-13/T1222","categories":"hep-ph hep-ex nucl-ex nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent experimental studies have led to the suggestion that short-range\ncorrelations may be a major contributor to the nuclear EMC effect. This\nhypothesis requires that the structure function for nucleons involved in\nshort-range correlations should be heavily suppressed compared to that of a\nfree nucleon. Based on calculations performed within an AdS/QCD motivated,\nlight-front quark-diquark model, we find that this large suppression of the\nnucleon structure function leads to a strong suppression of the nucleon elastic\nform factors.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:20:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13667","submitter":"Chenxin An","authors":"Chenxin An, Jiangtao Feng, Fei Huang, Xipeng Qiu, Lingpeng Kong","title":"Optimizing Non-Autoregressive Transformers with Contrastive Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-autoregressive Transformers (NATs) reduce the inference latency of\nAutoregressive Transformers (ATs) by predicting words all at once rather than\nin sequential order. They have achieved remarkable progress in machine\ntranslation as well as many other applications. However, a long-standing\nchallenge for NATs is the learning of multi-modality data distribution, which\nis the main cause of the performance gap between NATs and ATs. In this paper,\nwe propose to ease the difficulty of modality learning via sampling from the\nmodel distribution instead of the data distribution. We derive contrastive\nconstraints to stabilize the training process and integrate this resulting\nobjective with the state-of-the-art NAT architecture DA-Transformer. Our model\n\\method is examined on 3 different tasks, including machine translation, text\nsummarization, and paraphrasing with 5 benchmarks. Results show that our\napproach outperforms previous non-autoregressive baselines by a significant\nmargin and establishes new state-of-the-art results for non-autoregressive\ntransformers on all the benchmarks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:20:13 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 10:48:41 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.13668","submitter":"Sadaf Ghaffari","authors":"Sadaf Ghaffari and Nikhil Krishnaswamy","title":"Grounding and Distinguishing Conceptual Vocabulary Through Similarity\n  Learning in Embodied Simulations","comments":"Accepted at IWCS Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a novel method for using agent experiences gathered through an\nembodied simulation to ground contextualized word vectors to object\nrepresentations. We use similarity learning to make comparisons between\ndifferent object types based on their properties when interacted with, and to\nextract common features pertaining to the objects' behavior. We then use an\naffine transformation to calculate a projection matrix that transforms\ncontextualized word vectors from different transformer-based language models\ninto this learned space, and evaluate whether new test instances of transformed\ntoken vectors identify the correct concept in the object embedding space. Our\nresults expose properties of the embedding spaces of four different transformer\nmodels and show that grounding object token vectors is usually more helpful to\ngrounding verb and attribute token vectors than the reverse, which reflects\nearlier conclusions in the analogical reasoning and psycholinguistic\nliterature.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:22:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13669","submitter":"Shuo Zhang","authors":"Shuo Zhang, Liangming Pan, Junzhou Zhao, William Yang Wang","title":"Mitigating Language Model Hallucination with Interactive\n  Question-Knowledge Alignment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite the remarkable recent advances in language models, they still\nstruggle with the hallucination problem and can generate misleading and\nunsupported responses. A common approach to mitigate the hallucination issue is\nretrieving and incorporating supporting evidence from a knowledge base.\nHowever, user questions usually do not align well with the stored knowledge, as\nthey are unaware of the information available before asking questions. This\nmisalignment can limit the language model's ability to locate and utilize the\nknowledge, potentially forcing it to hallucinate by ignoring or overriding the\nretrieved evidence. To address this issue, we introduce MixAlign, a framework\nthat interacts with both the user and the knowledge base to obtain and\nintegrate clarifications on how the user question relates to the stored\ninformation. MixAlign employs a language model to achieve automatic\nquestion-knowledge alignment and, if necessary, further enhances this alignment\nthrough human user clarifications. Experimental results demonstrate significant\nimprovements over state-of-the-art methods, showcasing the effectiveness of\nMixAlign in mitigating language model hallucination.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:22:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13670","submitter":"Ping Li","authors":"Ping Li, Xiao Yang, Qing-Song Jiang, Yin-Zhong Wu, and Wei Xun","title":"Built-in electric field and strain tunable valley-related multiple\n  topological phase transitions in VSiXN$_4$ (X= C, Si, Ge, Sn, Pb) monolayers","comments":"9 pages, 8 figures, Accepted Physical Review Materials (2023). arXiv\n  admin note: text overlap with arXiv:2204.07488","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The valley-related multiple topological phase transitions attracted\nsignificant attention due to their providing significant opportunities for\nfundamental research and practical applications. However, unfortunately, to\ndate there is no real material that can realize valley-related multiple\ntopological phase transitions. Here, through first-principles calculations and\nmodel analysis, we investigate the structural, magnetic, electronic, and\ntopological properties of VSiXN$_4$ (X = C, Si, Ge, Sn, Pb) monolayers.\nVSiXN$_4$ monolayers are stable and intrinsically ferrovalley materials.\nIntriguingly, we found that the built-in electric field and strain can induce\nvalley-related multiple topological phase transitions in the materials from\nvalley semiconductor to valley-half-semimetal, to valley quantum anomalous Hall\ninsulator, to valley-half-semimetal, and to valley semiconductor (or to\nvalley-metal). The nature of topological phase transition is the built-in\nelectric field and strain induce band inversion between the\nd$_{xy}$/d$_{x2-y2}$ and d$_{z2}$ at obritals at K and K' valleys. Our findings\nnot only reveal the mechanism of multiple topological phase transitions, but\nalso provides an ideal platform for the multi-field manipulating the spin,\nvalley, and topological physics. It will open new perspectives for spintronic,\nvalleytronic, and topological nanoelectronic applications based on these\nmaterials.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:25:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13671","submitter":"Yanfeng Luo","authors":"Jun Tong, Bing Duan, Yanfeng Luo","title":"A combinatorial model for $q$-characters of fundamental modules of type\n  $D_{n}$","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA math.CO math.RT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we introduce a combinatorial path model of representation of\nthe quantum affine algebra of type $D_n$, inspired by Mukhin and Young's\ncombinatorial path models of representations of the quantum affine algebras of\ntypes $A_n$ and $B_n$. In particular, we give a combinatorial formula for\n$q$-characters of fundamental modules of type $D_{n}$ by assigning each path to\na monomial or binomial. By counting our paths, a new expression on dimensions\nof fundamental modules of type $D_n$ is obtained.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:26:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13672","submitter":"Elahe Vedadi","authors":"Elahe Vedadi, Joshua V. Dillon, Philip Andrew Mansfield, Karan\n  Singhal, Arash Afkanpour, Warren Richard Morningstar","title":"Federated Variational Inference: Towards Improved Personalization and\n  Generalization","comments":"16 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conventional federated learning algorithms train a single global model by\nleveraging all participating clients' data. However, due to heterogeneity in\nclient generative distributions and predictive models, these approaches may not\nappropriately approximate the predictive process, converge to an optimal state,\nor generalize to new clients. We study personalization and generalization in\nstateless cross-device federated learning setups assuming heterogeneity in\nclient data distributions and predictive models. We first propose a\nhierarchical generative model and formalize it using Bayesian Inference. We\nthen approximate this process using Variational Inference to train our model\nefficiently. We call this algorithm Federated Variational Inference (FedVI). We\nuse PAC-Bayes analysis to provide generalization bounds for FedVI. We evaluate\nour model on FEMNIST and CIFAR-100 image classification and show that FedVI\nbeats the state-of-the-art on both tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:28:07 GMT"},{"version":"v2","created":"Thu, 25 May 2023 21:07:53 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13673","submitter":"Zeyuan Allen-Zhu","authors":"Zeyuan Allen-Zhu, Yuanzhi Li","title":"Physics of Language Models: Part 1, Context-Free Grammar","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We design experiments to study $\\textit{how}$ generative language models,\nlike GPT, learn context-free grammars (CFGs) -- diverse language systems with a\ntree-like structure capturing many aspects of natural languages, programs, and\nhuman logics. CFGs are as hard as pushdown automata, and can be ambiguous so\nthat verifying if a string satisfies the rules requires dynamic programming. We\nconstruct synthetic data and demonstrate that even for very challenging CFGs,\npre-trained transformers can learn to generate sentences with near-perfect\naccuracy and remarkable $\\textit{diversity}$.\n  More importantly, we delve into the $\\textit{physical principles}$ behind how\ntransformers learns CFGs. We discover that the hidden states within the\ntransformer implicitly and $\\textit{precisely}$ encode the CFG structure (such\nas putting tree node information exactly on the subtree boundary), and learn to\nform \"boundary to boundary\" attentions that resemble dynamic programming. We\nalso cover some extension of CFGs as well as the robustness aspect of\ntransformers against grammar mistakes. Overall, our research provides a\ncomprehensive and empirical understanding of how transformers learn CFGs, and\nreveals the physical mechanisms utilized by transformers to capture the\nstructure and rules of languages.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:28:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13674","submitter":"Christopher Bailey Dr","authors":"Christopher G. Bailey, Lara V. Gillan, Minwoo Lee, Nicholas Sloane, Xu\n  Liu, Arman Mahboubi Soufiani, Xiaojing Hao, and Dane R. McCamey","title":"Influence of Organic Spacer Cation on Dark Excitons in 2D Perovskites","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.app-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The organic spacer cation plays a crucial role in determining the exciton\nfine structure in two-dimensional (2D) perovskites. Here, we use\nlow-temperature magneto-optical spectroscopy to gain insight into the influence\nof the organic spacer on dark excitons in Ruddlesden-Popper (RP) perovskites.\nWe show that by using modest magnetic field strengths (<1.5 T), the\nspin-forbidden dark exciton state can be identified and its emission properties\nsignificantly modulated through the application of in-plane magnetic fields, up\nto temperatures of 15 K. At low temperatures, an increase in collected\nphotoluminescence efficiency of >30% is demonstrated, signifying the critical\nrole of the dark exciton state for light-emitting applications of 2D\nperovskites. The exciton fine structure and the degree of\nmagnetic-field-induced mixing are impacted by the choice of organic spacer\ncation, with 4-methoxyphenethylammonium (MeO-PEA) showing the largest effect\ndue to larger bright-dark exciton splitting. Our results suggest that dark\nexcitons preferentially form biexcitons depending on the choice of spacer. We\ndistinguish between interior (bulk) and surface dark-exciton emission, showing\nthat bright-dark exciton splitting differs between the interior and surface.\nOur results emphasize the significance of the organic spacer cation in\ncontrolling the exciton fine structure in 2D perovskites and have important\nimplications for the development of optoelectronic technology based on 2D\nperovskites.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:30:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13675","submitter":"Timothy Schott","authors":"Tim Schott, Daniel Furman, and Shreshta Bhat","title":"Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval\n  from Foundation Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we evaluate the capacity for foundation models to retrieve\nencyclopedic knowledge across a wide range of languages, topics, and contexts.\nTo support this effort, we 1) produce a new dataset containing 303k factual\nassociations in 20 different languages, 2) formulate a new counterfactual\nknowledge assessment, Polyglot or Not, and 3) benchmark 5 foundation models in\na multilingual setting and a diverse set of 20 models in an English-only\nsetting. We observed significant accuracy differences in models of interest,\nwith Meta's LLaMA topping both the multilingual and English-only assessments.\nError analysis reveals a significant deficiency in LLaMA's ability to retrieve\nfacts in languages written in the Cyrillic script and gaps in its understanding\nof facts based on the location and gender of entailed subjects. Ultimately, we\nargue that the promise of utilizing foundation language models as bonafide\npolyglots is greatly diminished when they are tasked with retrieving\ninformation in languages other than English. Supporting code\n(https://github.com/daniel-furman/Polyglot-or-Not) and dataset\n(https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion) are openly\nreleased.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:31:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13676","submitter":"Naomi Ginsberg","authors":"Hannah L. Weaver, Cora M. Went, Joeson Wong, Dipti Jasrasaria, Eran\n  Rabani, Harry A. Atwater, Naomi S. Ginsberg","title":"Detecting, distinguishing, and spatiotemporally tracking photogenerated\n  charge and heat at the nanoscale","comments":"22 pages, 4 figures, SI included as ancilliary file","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.app-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Since dissipative processes are ubiquitous in semiconductors, characterizing\nhow electronic and thermal energy transduce and transport at the nanoscale is\nvital for understanding and leveraging their fundamental properties. For\nexample, in low-dimensional transition metal dichalcogenides (TMDCs), excess\nheat generation upon photoexcitation is difficult to avoid since even with\nmodest injected exciton densities, exciton-exciton annihilation still occurs.\nBoth heat and photoexcited electronic species imprint transient changes in the\noptical response of a semiconductor, yet the unique signatures of each are\ndifficult to disentangle in typical spectra due to overlapping resonances. In\nresponse, we employ stroboscopic optical scattering microscopy (stroboSCAT) to\nsimultaneously map both heat and exciton populations in few-layer \\ch{MoS2} on\nrelevant nanometer and picosecond length- and time scales and with 100-mK\ntemperature sensitivity. We discern excitonic contributions to the signal from\nheat by combining observations close to and far from exciton resonances,\ncharacterizing photoinduced dynamics for each. Our approach is general and can\nbe applied to any electronic material, including thermoelectrics, where heat\nand electronic observables spatially interplay, and lays the groundwork for\ndirect and quantitative discernment of different types of coexisting energy\nwithout recourse to complex models or underlying assumptions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:34:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13677","submitter":"Chu Fei Luo","authors":"Chu Fei Luo, Rohan Bhambhoria, Xiaodan Zhu, Samuel Dahan","title":"Towards Legally Enforceable Hate Speech Detection for Public Forums","comments":"4 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hate speech is a serious issue on public forums, and proper enforcement of\nhate speech laws is key for protecting groups of people against harmful and\ndiscriminatory language. However, determining what constitutes hate speech is a\ncomplex task that is highly open to subjective interpretations. Existing works\ndo not align their systems with enforceable definitions of hate speech, which\ncan make their outputs inconsistent with the goals of regulators. Our work\nintroduces a new task for enforceable hate speech detection centred around\nlegal definitions, and a dataset annotated on violations of eleven possible\ndefinitions by legal experts. Given the challenge of identifying clear, legally\nenforceable instances of hate speech, we augment the dataset with\nexpert-generated samples and an automatically mined challenge set. We\nexperiment with grounding the model decision in these definitions using\nzero-shot and few-shot prompting. We then report results on several large\nlanguage models (LLMs). With this task definition, automatic hate speech\ndetection can be more closely aligned to enforceable laws, and hence assist in\nmore rigorous enforcement of legal protections against harmful speech in public\nforums.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:34:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13678","submitter":"Minchan Kwon","authors":"Minchan Kwon, Kangil Kim","title":"Enhancing Accuracy and Robustness through Adversarial Training in Class\n  Incremental Continual Learning","comments":"9 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In real life, adversarial attack to deep learning models is a fatal security\nissue. However, the issue has been rarely discussed in a widely used\nclass-incremental continual learning (CICL). In this paper, we address problems\nof applying adversarial training to CICL, which is well-known defense method\nagainst adversarial attack. A well-known problem of CICL is class-imbalance\nthat biases a model to the current task by a few samples of previous tasks.\nMeeting with the adversarial training, the imbalance causes another imbalance\nof attack trials over tasks. Lacking clean data of a minority class by the\nclass-imbalance and increasing of attack trials from a majority class by the\nsecondary imbalance, adversarial training distorts optimal decision boundaries.\nThe distortion eventually decreases both accuracy and robustness than\nadversarial training. To exclude the effects, we propose a straightforward but\nsignificantly effective method, External Adversarial Training (EAT) which can\nbe applied to methods using experience replay. This method conduct adversarial\ntraining to an auxiliary external model for the current task data at each time\nstep, and applies generated adversarial examples to train the target model. We\nverify the effects on a toy problem and show significance on CICL benchmarks of\nimage classification. We expect that the results will be used as the first\nbaseline for robustness research of CICL.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:37:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13679","submitter":"Magdalena Grzeszczyk","authors":"M. Grzeszczyk, K. Vaklinova, K. Watanabe, T. Taniguchi, K. S.\n  Novoselov, and M. Koperski","title":"Electrical excitation of carbon centers in hexagonal boron nitride with\n  tuneable quantum efficiency","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Defect centers in wide-band-gap crystals attracted considerable attention due\nto the realisations of qubits, sensors, or single photon emitters at room\ntemperature. The family of these centers is constantly growing, including\nwell-known examples such as nitrogen-vacancy centers in diamond,\nsilicon-vacancy in silicon carbide, chromium substitutions in aluminium oxide,\nand many others. Unfortunately, such defect centers embedded in highly\ninsulating crystals have been notoriously difficult to excite electrically.\nHerewith, we present a realisation of insulating light-emitting diodes based on\ncarbon centers in hexagonal boron nitride. The rational design of the vertical\ntunnelling devices via van der Waals technology enabled us to control the\ncharge dynamics related to non-radiative tunelling, defect-to-band\nelectroluminescence, and intradefect electroluminescence. The fundamental\nunderstanding of the tunnelling events enabled us to achieve high efficiency of\nelectrical excitation, which exceeded by a few orders of magnitude the\nefficiency of optical excitation in the sub-band-gap regime. A combination of a\nStark effect and screening by band electrons provide a control knob for tuning\nthe energy of emission. With this work, we solve an outstanding problem of\ncreating electrically driven devices realised with defect centers in\nwide-band-gap crystals, which are relevant in the domain of optoelectronics,\ntelecommunication, computation, or sensing.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:38:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13680","submitter":"Eng Lieh Ouh","authors":"Eng Lieh Ouh, Benjamin Kok Siew Gan, Kyong Jin Shim, Swavek Wlodkowski","title":"ChatGPT, Can You Generate Solutions for my Coding Exercises? An\n  Evaluation on its Effectiveness in an undergraduate Java Programming Course","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this study, we assess the efficacy of employing the ChatGPT language model\nto generate solutions for coding exercises within an undergraduate Java\nprogramming course. ChatGPT, a large-scale, deep learning-driven natural\nlanguage processing model, is capable of producing programming code based on\ntextual input. Our evaluation involves analyzing ChatGPT-generated solutions\nfor 80 diverse programming exercises and comparing them to the correct\nsolutions. Our findings indicate that ChatGPT accurately generates Java\nprogramming solutions, which are characterized by high readability and\nwell-structured organization. Additionally, the model can produce alternative,\nmemory-efficient solutions. However, as a natural language processing model,\nChatGPT struggles with coding exercises containing non-textual descriptions or\nclass files, leading to invalid solutions. In conclusion, ChatGPT holds\npotential as a valuable tool for students seeking to overcome programming\nchallenges and explore alternative approaches to solving coding problems. By\nunderstanding its limitations, educators can design coding exercises that\nminimize the potential for misuse as a cheating aid while maintaining their\nvalidity as assessment tools.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:38:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13681","submitter":"Weiye Zhao","authors":"Weiye Zhao, Rui Chen, Yifan Sun, Ruixuan Liu, Tianhao Wei, Changliu\n  Liu","title":"GUARD: A Safe Reinforcement Learning Benchmark","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to the trial-and-error nature, it is typically challenging to apply RL\nalgorithms to safety-critical real-world applications, such as autonomous\ndriving, human-robot interaction, robot manipulation, etc, where such errors\nare not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly\nin the literature, in which the agents explore the environment while satisfying\nconstraints. Due to the diversity of algorithms and tasks, it remains difficult\nto compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a\nGeneralized Unified SAfe Reinforcement Learning Development Benchmark. GUARD\nhas several advantages compared to existing benchmarks. First, GUARD is a\ngeneralized benchmark with a wide variety of RL agents, tasks, and safety\nconstraint specifications. Second, GUARD comprehensively covers\nstate-of-the-art safe RL algorithms with self-contained implementations. Third,\nGUARD is highly customizable in tasks and algorithms. We present a comparison\nof state-of-the-art safe RL algorithms in various task settings using GUARD and\nestablish baselines that future work can build on.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:40:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13682","submitter":"David Egger","authors":"Maximilian J. Schilcher, David J. Abramovitch, Matthew Z. Mayers,\n  Liang Z. Tan, David R. Reichman, David A. Egger","title":"Correlated Anharmonicity and Dynamic Disorder Control Carrier Transport\n  in Halide Perovskites","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Halide pervoskites are an important class of semiconducting materials which\nhold great promise for optoelectronic applications. In this work we investigate\nthe relationship between vibrational anharmonicity and dynamic disorder in this\nclass of solids. Via a multi-scale model parameterized from first-principles\ncalculations, we demonstrate that the non-Gaussian lattice motion in halide\nperovskites is microscopically connected to the dynamic disorder of overlap\nfluctuations among electronic states. This connection allows us to rationalize\nthe emergent differences in temperature-dependent mobilities of prototypical\nMAPbI$_3$ and MAPbBr$_3$ compounds across structural phase-transitions, in\nagreement with experimental findings. Our analysis suggests that the details of\nvibrational anharmonicity and dynamic disorder can complement known predictors\nof electronic conductivity and can provide structure-property guidelines for\nthe tuning of carrier transport characteristics in anharmonic semiconductors.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:41:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13683","submitter":"Shijie Chen","authors":"Shijie Chen, Ziru Chen, Huan Sun, Yu Su","title":"Error Detection for Text-to-SQL Semantic Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite remarkable progress in text-to-SQL semantic parsing in recent years,\nthe performance of existing parsers is still far from perfect. At the same\ntime, modern deep learning based text-to-SQL parsers are often over-confident\nand thus casting doubt on their trustworthiness when deployed for real use. To\nthat end, we propose to build a parser-independent error detection model for\ntext-to-SQL semantic parsing. The proposed model is based on pre-trained\nlanguage model of code and is enhanced with structural features learned by\ngraph neural networks. We train our model on realistic parsing errors collected\nfrom a cross-domain setting. Experiments with three strong text-to-SQL parsers\nfeaturing different decoding mechanisms show that our approach outperforms\nparser-dependent uncertainty metrics and could effectively improve the\nperformance and usability of text-to-SQL semantic parsers regardless of their\narchitectures.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:44:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13684","submitter":"Peiqin Lin","authors":"Peiqin Lin, Chengzhi Hu, Zheyu Zhang, Andr\\'e F. T. Martins, Hinrich\n  Sch\\\"utze","title":"mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in\n  Multilingual Pretrained Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent multilingual pretrained language models (mPLMs) have been shown to\nencode strong language-specific signals, which are not explicitly provided\nduring pretraining. It remains an open question whether it is feasible to\nemploy mPLMs to measure language similarity, and subsequently use the\nsimilarity results to select source languages for boosting cross-lingual\ntransfer. To investigate this, we propose mPLM-Sim, a new language similarity\nmeasure that induces the similarities across languages from mPLMs using\nmulti-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high\ncorrelations with linguistic similarity measures, such as lexicostatistics,\ngenealogical language family, and geographical sprachbund. We also conduct a\ncase study on languages with low correlation and observe that mPLM-Sim yields\nmore accurate similarity results. Additionally, we find that similarity results\nvary across different mPLMs and different layers within an mPLM. We further\ninvestigate whether mPLM-Sim is effective for zero-shot cross-lingual transfer\nby conducting experiments on both low-level syntactic tasks and high-level\nsemantic tasks. The experimental results demonstrate that mPLM-Sim is capable\nof selecting better source languages than linguistic measures, resulting in a\n1%-2% improvement in zero-shot cross-lingual transfer performance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:44:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13685","submitter":"Jiachang Liu","authors":"Jiachang Liu, Qi Zhang, Chongyang Shi, Usman Naseem, Shoujin Wang,\n  Ivor Tsang","title":"Causal Intervention for Abstractive Related Work Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Abstractive related work generation has attracted increasing attention in\ngenerating coherent related work that better helps readers grasp the background\nin the current research. However, most existing abstractive models ignore the\ninherent causality of related work generation, leading to low quality of\ngenerated related work and spurious correlations that affect the models'\ngeneralizability. In this study, we argue that causal intervention can address\nthese limitations and improve the quality and coherence of the generated\nrelated works. To this end, we propose a novel Causal Intervention Module for\nRelated Work Generation (CaM) to effectively capture causalities in the\ngeneration process and improve the quality and coherence of the generated\nrelated works. Specifically, we first model the relations among sentence order,\ndocument relation, and transitional content in related work generation using a\ncausal graph. Then, to implement the causal intervention and mitigate the\nnegative impact of spurious correlations, we use do-calculus to derive ordinary\nconditional probabilities and identify causal effects through CaM. Finally, we\nsubtly fuse CaM with Transformer to obtain an end-to-end generation model.\nExtensive experiments on two real-world datasets show that causal interventions\nin CaM can effectively promote the model to learn causal relations and produce\nrelated work of higher quality and coherence.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:48:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13686","submitter":"Ye-Xin Lu","authors":"Ye-Xin Lu, Yang Ai, Zhen-Hua Ling","title":"MP-SENet: A Speech Enhancement Model with Parallel Denoising of\n  Magnitude and Phase Spectra","comments":"Accepted by Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes MP-SENet, a novel Speech Enhancement Network which\ndirectly denoises Magnitude and Phase spectra in parallel. The proposed\nMP-SENet adopts a codec architecture in which the encoder and decoder are\nbridged by convolution-augmented transformers. The encoder aims to encode\ntime-frequency representations from the input noisy magnitude and phase\nspectra. The decoder is composed of parallel magnitude mask decoder and phase\ndecoder, directly recovering clean magnitude spectra and clean-wrapped phase\nspectra by incorporating learnable sigmoid activation and parallel phase\nestimation architecture, respectively. Multi-level losses defined on magnitude\nspectra, phase spectra, short-time complex spectra, and time-domain waveforms\nare used to train the MP-SENet model jointly. Experimental results show that\nour proposed MP-SENet achieves a PESQ of 3.50 on the public VoiceBank+DEMAND\ndataset and outperforms existing advanced speech enhancement methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:48:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13687","submitter":"Mohammad Arshad Rahman","authors":"Ivan Jeliazkov, Shubham Karnawat, Mohammad Arshad Rahman, Angela\n  Vossmeyer","title":"Flexible Bayesian Quantile Analysis of Residential Rental Rates","comments":"36 Pages, 3 Figures, 8 Tables","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.EM stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This article develops a random effects quantile regression model for panel\ndata that allows for increased distributional flexibility, multivariate\nheterogeneity, and time-invariant covariates in situations where mean\nregression may be unsuitable. Our approach is Bayesian and builds upon the\ngeneralized asymmetric Laplace distribution to decouple the modeling of\nskewness from the quantile parameter. We derive an efficient simulation-based\nestimation algorithm, demonstrate its properties and performance in targeted\nsimulation studies, and employ it in the computation of marginal likelihoods to\nenable formal Bayesian model comparisons. The methodology is applied in a study\nof U.S. residential rental rates following the Global Financial Crisis. Our\nempirical results provide interesting insights on the interaction between rents\nand economic, demographic and policy variables, weigh in on key modeling\nfeatures, and overwhelmingly support the additional flexibility at nearly all\nquantiles and across several sub-samples. The practical differences that arise\nas a result of allowing for flexible modeling can be nontrivial, especially for\nquantiles away from the median.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:49:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13688","submitter":"Tieying Li","authors":"Tieying Li, Kan Wu, Xujia Zhang, Minglu Cai and Jianping Chen","title":"Experimental observation of Kerr-Raman solitons in a normal-dispersion\n  FP resonator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Different from the Kerr effect,stimulated Raman scattering (SRS) is a delayed\nresponse to molecular vibrations in materials. In microcavities, when driven in\nan anomalous group velocity dispersion (GVD) regime, SRS typically leads to\nself-frequency shift of solitons and generation of breather solitons which have\nbeen verified both theoretically and experimentally. However, when driven in a\nnormal GVD regime, recent theoretical work predicts that SRS can cause the\nlocking of switching waves (SWs) and thus support bright moving localized\nstructures (LSs), which we term as Kerr-Raman solitons (KRSs). Limited by the\ndesign of suitable experimental parameters, experimental observation of the\nKRSs is not achieved yet. Here, we provide numerical investigation, and to our\nknowledge, the first experimental observation of these SRS enabled KRSs in a\nfiber Fabry-Perot (FP) resonator with ultra-low normal GVD. Such Kerr-Raman\nsolitons exhibit localized temporal features with strong oscillations at ~13\nTHz local frequency on the top of a flat-top pulse. The corresponding spectrum\nis a low-noise and broadband Kerr comb with typical platicon-like spectrum in\nthe center and two Raman Stokes and anti-Stokes peaks located near 13 THz away\nfrom the center. With such SRS enabled broadband Kerr comb, we have achieved a\nKRS spectrum with a repetition rate of ~3.68 GHz and a -40 dB spectral width of\n260 nm. The corresponding comb tooth count is >9000, covering the S+C+L\ntelecommunication bands. Moreover, the formation process of such KRSs is also\nrevealed, and it is found that the GVD plays a key role in its generation. Our\nwork will help to advance the study of the dynamics of optical frequency combs\nunder the influence of SRS, as well as providing a broadband coherent\nmode-locked optical source for wide applications.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:53:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13689","submitter":"Utku Ozbulak","authors":"Utku Ozbulak, Hyun Jung Lee, Beril Boga, Esla Timothy Anzaku, Homin\n  Park, Arnout Van Messem, Wesley De Neve, Joris Vankerschaver","title":"Know Your Self-supervised Learning: A Survey on Image-based Generative\n  and Discriminative Training","comments":"Published in Transactions on Machine Learning Research","journal-ref":"Transactions on Machine Learning Research, 2023","doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although supervised learning has been highly successful in improving the\nstate-of-the-art in the domain of image-based computer vision in the past, the\nmargin of improvement has diminished significantly in recent years, indicating\nthat a plateau is in sight. Meanwhile, the use of self-supervised learning\n(SSL) for the purpose of natural language processing (NLP) has seen tremendous\nsuccesses during the past couple of years, with this new learning paradigm\nyielding powerful language models. Inspired by the excellent results obtained\nin the field of NLP, self-supervised methods that rely on clustering,\ncontrastive learning, distillation, and information-maximization, which all\nfall under the banner of discriminative SSL, have experienced a swift uptake in\nthe area of computer vision. Shortly afterwards, generative SSL frameworks that\nare mostly based on masked image modeling, complemented and surpassed the\nresults obtained with discriminative SSL. Consequently, within a span of three\nyears, over $100$ unique general-purpose frameworks for generative and\ndiscriminative SSL, with a focus on imaging, were proposed. In this survey, we\nreview a plethora of research efforts conducted on image-oriented SSL,\nproviding a historic view and paying attention to best practices as well as\nuseful software packages. While doing so, we discuss pretext tasks for\nimage-based SSL, as well as techniques that are commonly used in image-based\nSSL. Lastly, to aid researchers who aim at contributing to image-focused SSL,\nwe outline a number of promising research directions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:54:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13690","submitter":"Yue Feng","authors":"Yue Feng, Hossein A. Rahmani, Aldo Lipani, Emine Yilmaz","title":"Towards Asking Clarification Questions for Information Seeking on\n  Task-Oriented Dialogues","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Task-oriented dialogue systems aim at providing users with task-specific\nservices. Users of such systems often do not know all the information about the\ntask they are trying to accomplish, requiring them to seek information about\nthe task. To provide accurate and personalized task-oriented information\nseeking results, task-oriented dialogue systems need to address two potential\nissues: 1) users' inability to describe their complex information needs in\ntheir requests; and 2) ambiguous/missing information the system has about the\nusers. In this paper, we propose a new Multi-Attention Seq2Seq Network, named\nMAS2S, which can ask questions to clarify the user's information needs and the\nuser's profile in task-oriented information seeking. We also extend an existing\ndataset for task-oriented information seeking, leading to the \\ourdataset which\ncontains about 100k task-oriented information seeking dialogues that are made\npublicly available\\footnote{Dataset and code is available at\n\\href{https://github.com/sweetalyssum/clarit}{https://github.com/sweetalyssum/clarit}.}.\nExperimental results on \\ourdataset show that MAS2S outperforms baselines on\nboth clarification question generation and answer prediction.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:56:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13691","submitter":"Mingda Chen","authors":"Mingda Chen, Xilun Chen, Wen-tau Yih","title":"Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data\n  Synthesis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Few-shot learning for open domain multi-hop question answering typically\nrelies on large language models (LLMs). While powerful, LLMs are inefficient at\nthe inference time. We propose a data synthesis framework for multi-hop\nquestion answering that allows for improving smaller language models with less\nthan 10 human-annotated question answer pairs. The framework is built upon the\ndata generation functions parameterized by LLMs and prompts, which requires\nminimal hand-crafted features. Empirically, we synthesize millions of multi-hop\nquestions and claims. After finetuning language models on the synthetic data,\nwe evaluate the models on popular benchmarks on multi-hop question answering\nand fact verification. Our experimental results show that finetuning on the\nsynthetic data improves model performance significantly, allowing our finetuned\nmodels to be competitive with prior models while being almost one-third the\nsize in terms of parameter counts.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:57:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13692","submitter":"Egor Frolov","authors":"A. Buzulutskov, E. Frolov, E. Borisova, V. Nosov, V. Oleynikov, A.\n  Sokolov","title":"Evidence for the production of Ar$_2^{*-}$ metastable negative molecular\n  ions in two-phase argon detectors for dark matter searches","comments":"4 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det astro-ph.IM hep-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent studies of electroluminescence (EL) properties in two-phase argon\ndetectors for dark matter searches have revealed the presence of unusual\ndelayed pulses in the EL signal in the form of two slow components with time\nconstants of about 5 and 50 $\\mu$s. These components were shown to be present\nin the charge signal itself, which clearly indicates that drifting electrons\nare temporarily trapped on two states of metastable negative argon ions which\nhave never been observed before. In this work, using the pressure dependence of\nthe ratio of slow component contributions measured in experiment, it is shown\nthat these states are those of two types of metastable negative molecular ions,\n$\\mathrm{Ar}_2^{*-}(b \\ ^4\\Sigma_u^-)$ and $\\mathrm{Ar}_2^{*-}(a \\\n^4\\Sigma_g^+)$ for the higher and lower energy level respectively.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:58:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13693","submitter":"Lucy Lu Wang","authors":"Lucy Lu Wang, Yulia Otmakhova, Jay DeYoung, Thinh Hung Truong, Bailey\n  E. Kuehl, Erin Bransom, Byron C. Wallace","title":"Automated Metrics for Medical Multi-Document Summarization Disagree with\n  Human Evaluations","comments":"ACL 2023; Github: https://github.com/allenai/mslr-annotated-dataset","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Evaluating multi-document summarization (MDS) quality is difficult. This is\nespecially true in the case of MDS for biomedical literature reviews, where\nmodels must synthesize contradicting evidence reported across different\ndocuments. Prior work has shown that rather than performing the task, models\nmay exploit shortcuts that are difficult to detect using standard n-gram\nsimilarity metrics such as ROUGE. Better automated evaluation metrics are\nneeded, but few resources exist to assess metrics when they are proposed.\nTherefore, we introduce a dataset of human-assessed summary quality facets and\npairwise preferences to encourage and support the development of better\nautomated evaluation methods for literature review MDS. We take advantage of\ncommunity submissions to the Multi-document Summarization for Literature Review\n(MSLR) shared task to compile a diverse and representative sample of generated\nsummaries. We analyze how automated summarization evaluation metrics correlate\nwith lexical features of generated summaries, to other automated metrics\nincluding several we propose in this work, and to aspects of human-assessed\nsummary quality. We find that not only do automated metrics fail to capture\naspects of quality as assessed by humans, in many cases the system rankings\nproduced by these metrics are anti-correlated with rankings according to human\nannotators.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:00:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13694","submitter":"Chunxiang Wang","authors":"Chunxiang Wang, Ran Li, Huanyuan Shan, Weiwei Xu, Ji Yao, Yingjie\n  Jing, Liang Gao, Nan Li, Yushan Xie, Kai Zhu, Hang Yang, Qingze Chen","title":"Assessing Mass Loss and Stellar-to-Halo Mass Ratio of Satellite\n  Galaxies: A Galaxy-Galaxy Lensing Approach Utilizing DECaLS DR8 Data","comments":"14 pages, 9 figures, submitted to MNRAS","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The galaxy-galaxy lensing technique allows us to measure the subhalo mass of\nsatellite galaxies, studying their mass loss and evolution within galaxy\nclusters and providing direct observational validation for theories of galaxy\nformation. In this study, we use the weak gravitational lensing observations\nfrom DECaLS DR8, in combination with the redMaPPer galaxy cluster catalog from\nSDSS DR8 to accurately measure the dark matter halo mass of satellite galaxies.\nWe confirm a significant increase in the stellar-to-halo mass ratio of\nsatellite galaxies with their halo-centric radius, indicating clear evidence of\nmass loss due to tidal stripping. Additionally, we find that this mass loss is\nstrongly dependent on the mass of the satellite galaxies, with satellite\ngalaxies above $10^{11}~{\\rm M_{\\odot}/h}$ experiencing more pronounced mass\nloss compared to lower mass satellites, reaching 86\\% at projected halo-centric\nradius $0.5R_{\\rm 200c}$. The average mass loss rate, when not considering\nhalo-centric radius, displays a U-shaped variation with stellar mass, with\ngalaxies of approximately $4\\times10^{10}~{\\rm M_{\\odot}/h}$ exhibiting the\nleast mass loss, around 60\\%. We compare our results with state-of-the-art\nhydrodynamical numerical simulations and find that the satellite galaxy\nstellar-to-halo mass ratio in the outskirts of galaxy clusters is higher\ncompared to the predictions of the Illustris-TNG project about factor 5.\nFurthermore, the Illustris-TNG project's numerical simulations did not predict\nthe observed dependence of satellite galaxy mass loss rate on satellite galaxy\nmass.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:02:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13695","submitter":"Samuel Barnier","authors":"Samuel Barnier, Pierre-Olivier Petrucci, Jonathan Ferreira, Gregoire\n  Marcel","title":"The jet emitting disk standard accretion disk model applied to the\n  active galactic nuclei ultra violet Xray correlation","comments":"XMM-Newton 2022 conference: Black Hole accretion under the X-ray\n  microscope (June 2022, ESAC, Madrid), proceeding","journal-ref":"Astronomische Nachrichten, Volume 344, Issue 4, Special Issue,\n  Black Hole accretion under the Xray microscope, May 2023","doi":"10.1002/asna.20230020","report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The non linear correlation between the UV and X-ray emission observed in\nActive Galactic Nuclei remains a puzzling question that challenged accretion\nmodels. While the UV emission originates from the cold disk, the X-ray emission\nis emitted by a hot corona whose physical characteristics and geometry are\nstill highly debated. The Jet Emitting Disk - Standard Accretion Disk (JED-SAD)\nis a spectral model stemming from self similar accretion-ejection solutions. It\nis composed of an inner highly magnetized and hot accretion flow launching\njets, the JED, and an outer SAD. The model has been successfully applied to\nX-ray binaries outbursts. The AGN UV X-ray correlation represent another\nessential test for the JED-SAD model. We use multiple AGN samples to explore\nthe parameter space and identify the regions able to reproduce the\nobservations. In this first paper, we show that JED-SAD model is able to\nreproduce the UV--X-ray correlation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:02:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13696","submitter":"Khang Lam","authors":"Khang Nhut Lam and Thieu Gia Doan and Khang Thua Pham and Jugal Kalita","title":"Abstractive Text Summarization Using the BRIO Training Paradigm","comments":"6 pages, Findings of the Association for Computational Linguistics:\n  ACL 2023","journal-ref":"Findings of the Association for Computational Linguistics: ACL\n  2023","doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Summary sentences produced by abstractive summarization models may be\ncoherent and comprehensive, but they lack control and rely heavily on reference\nsummaries. The BRIO training paradigm assumes a non-deterministic distribution\nto reduce the model's dependence on reference summaries, and improve model\nperformance during inference. This paper presents a straightforward but\neffective technique to improve abstractive summaries by fine-tuning pre-trained\nlanguage models, and training them with the BRIO paradigm. We build a text\nsummarization dataset for Vietnamese, called VieSum. We perform experiments\nwith abstractive summarization models trained with the BRIO paradigm on the\nCNNDM and the VieSum datasets. The results show that the models, trained on\nbasic hardware, outperform all existing abstractive summarization models,\nespecially for Vietnamese.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:09:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13697","submitter":"Hao Yang","authors":"Hao Yang, Can Gao, Hao L\\'iu, Xinyan Xiao, Yanyan Zhao, Bing Qin","title":"UNIMO-3: Multi-granularity Interaction for Vision-Language\n  Representation Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vision-and-language (VL) pre-training, which aims to learn a general\nrepresentation of image-text pairs that can be transferred to various\nvision-and-language tasks. Compared with modeling uni-modal data, the main\nchallenge of the VL model is: how to learn the cross-modal interaction from\nmultimodal data, especially the fine-grained interaction. Existing works have\nshown that fully transformer-based models that adopt attention mechanisms to\nlearn in-layer cross-model interaction can demonstrate impressive performance\non various cross-modal downstream tasks. However, they ignored that the\nsemantic information of the different modals at the same layer was not uniform,\nwhich leads to the cross-modal interaction collapsing into a limited\nmulti-modal semantic information interaction. In this work, we propose the\nUNIMO-3 model, which has the capacity to simultaneously learn the multimodal\nin-layer interaction and cross-layer interaction. UNIMO-3 model can establish\neffective connections between different layers in a cross-modal encoder, and\nadaptively capture the interaction between two modalities at different levels.\nThe experimental results show that our model achieves state-of-the-art\nperformance in various downstream tasks, and through ablation study can prove\nthat effective cross-layer learning improves the model's ability of multimodal\nrepresentation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:11:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13698","submitter":"Frederick Riemenschneider","authors":"Frederick Riemenschneider and Anette Frank","title":"Exploring Large Language Models for Classical Philology","comments":"Paper accepted for publication at ACL 2023 Main; 10 pages, 7 appendix\n  pages, 4 figures, 13 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent advances in NLP have led to the creation of powerful language models\nfor many languages including Ancient Greek and Latin. While prior work on\nClassical languages unanimously uses BERT, in this work we create four language\nmodels for Ancient Greek that vary along two dimensions to study their\nversatility for tasks of interest for Classical languages: we explore (i)\nencoder-only and encoder-decoder architectures using RoBERTa and T5 as strong\nmodel types, and create for each of them (ii) a monolingual Ancient Greek and a\nmultilingual instance that includes Latin and English. We evaluate all models\non morphological and syntactic tasks, including lemmatization, which\ndemonstrates the added value of T5's decoding abilities. We further define two\nprobing tasks to investigate the knowledge acquired by models pre-trained on\nClassical texts. Our experiments provide the first benchmarking analysis of\nexisting models of Ancient Greek. Results show that our models provide\nsignificant improvements over the SoTA. The systematic analysis of model types\ncan inform future research in designing language models for Classical\nlanguages, including the development of novel generative tasks. We make all our\nmodels available as community resources, along with a large curated\npre-training corpus for Ancient Greek, to support the creation of a larger,\ncomparable model zoo for Classical Philology. Our models and resources are\navailable at https://github.com/Heidelberg-NLP/ancient-language-models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:21:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13699","submitter":"Peng Zhang","authors":"Peng Zhang, Fa Ge, Yuhong Liu","title":"Achieving Maximum Efficiency in Schnorr-based Multi-signature and\n  Applications in Blockchain","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-signature aggregates signatures from multiple users on the same message\ninto a joint signature, which is widely applied in blockchain to reduce the\npercentage of signatures in blocks and improve the throughput of transactions.\nThe $k$-sum attacks are one of the major challenges to design secure\nmulti-signature schemes. In this work, we address $k$-sum attacks from a novel\nangle by defining a Public Third Party (PTP), which is an automatic process\nthat can be verifiable by the public and restricts the signing phase from\ncontinuing until receiving commitments from all signers. Further, a two-round\nmulti-signature scheme MEMS with PTP is proposed, which is secure based on\ndiscrete logarithm assumption in the random oracle model. As each signer\ncommunicates directly with the PTP instead of other co-signers, the total\namount of communications is significantly reduced. In addition, as PTP\nparticipates in the computation of the aggregation and signing algorithms, the\ncomputation cost left for each signer and verifier remains the same as the\nbasis Schnorr signature. To the best of our knowledge, this is the maximum\nefficiency that a Schnorr-based multi-signature scheme can achieve. Further,\nMEMS is applied in blockchain platform, e.g., Fabric, to improve the\ntransaction efficiency.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:21:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13700","submitter":"Chenglong Wang","authors":"Chenglong Wang, Jiangyan Yi, Jianhua Tao, Chuyuan Zhang, Shuai Zhang\n  and Xun Chen","title":"Detection of Cross-Dataset Fake Audio Based on Prosodic and\n  Pronunciation Features","comments":"Interspeech2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing fake audio detection systems perform well in in-domain testing, but\nstill face many challenges in out-of-domain testing. This is due to the\nmismatch between the training and test data, as well as the poor\ngeneralizability of features extracted from limited views. To address this, we\npropose multi-view features for fake audio detection, which aim to capture more\ngeneralized features from prosodic, pronunciation, and wav2vec dimensions.\nSpecifically, the phoneme duration features are extracted from a pre-trained\nmodel based on a large amount of speech data. For the pronunciation features, a\nConformer-based phoneme recognition model is first trained, keeping the\nacoustic encoder part as a deeply embedded feature extractor. Furthermore, the\nprosodic and pronunciation features are fused with wav2vec features based on an\nattention mechanism to improve the generalization of fake audio detection\nmodels. Results show that the proposed approach achieves significant\nperformance gains in several cross-dataset experiments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:27:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13701","submitter":"Chenglong Wang","authors":"Chenglong Wang, Jiangyan Yi, Jianhua Tao, Chuyuan Zhang, Shuai Zhang,\n  Ruibo Fu and Xun Chen","title":"TO-Rawnet: Improving RawNet with TCN and Orthogonal Regularization for\n  Fake Audio Detection","comments":"Interspeech2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current fake audio detection relies on hand-crafted features, which lose\ninformation during extraction. To overcome this, recent studies use direct\nfeature extraction from raw audio signals. For example, RawNet is one of the\nrepresentative works in end-to-end fake audio detection. However, existing work\non RawNet does not optimize the parameters of the Sinc-conv during training,\nwhich limited its performance. In this paper, we propose to incorporate\northogonal convolution into RawNet, which reduces the correlation between\nfilters when optimizing the parameters of Sinc-conv, thus improving\ndiscriminability. Additionally, we introduce temporal convolutional networks\n(TCN) to capture long-term dependencies in speech signals. Experiments on the\nASVspoof 2019 show that the Our TO-RawNet system can relatively reduce EER by\n66.09\\% on logical access scenario compared with the RawNet, demonstrating its\neffectiveness in detecting fake audio attacks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:30:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13702","submitter":"Shinji Miwa","authors":"Kouta Kondou, Shinji Miwa, Daigo Miyajima","title":"Spontaneous spin selectivity and linear magnetoelectric effect in chiral\n  molecules","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Chirality-induced spin selectivity (CISS) has been extensively studied over\nthe past two decades. While current-induced spin polarization in chiral\nmolecules is widely recognized as the fundamental principle of the CISS, only a\nfew studies have been reported on bias-current-free CISS, where there is no\nbias electric current in chiral molecules. In this paper, we discuss the\nmicroscopic origin of bias-free CISS using chiral molecule/ferromagnet bilayer\nsystems. Recent studies on the chirality-induced exchange bias and\ncurrent-in-plane magnetoresistance (CIP-MR) effects indicate that chiral\nmolecules possess thermally driven broken-time-reversal symmetry at the\ninterface, which induces bias-current-free CISS, i.e. a spontaneous effective\nmagnetic field in the system. We also discuss the possibility of the linear\nmagnetoelectric effect of chiral molecules at the interface and its potential\nimpact on the observed CISS phenomena.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:30:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13703","submitter":"Vered Shwartz","authors":"EunJeong Hwang and Vered Shwartz","title":"MemeCap: A Dataset for Captioning and Interpreting Memes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Memes are a widely popular tool for web users to express their thoughts using\nvisual metaphors. Understanding memes requires recognizing and interpreting\nvisual metaphors with respect to the text inside or around the meme, often\nwhile employing background knowledge and reasoning abilities. We present the\ntask of meme captioning and release a new dataset, MemeCap. Our dataset\ncontains 6.3K memes along with the title of the post containing the meme, the\nmeme captions, the literal image caption, and the visual metaphors. Despite the\nrecent success of vision and language (VL) models on tasks such as image\ncaptioning and visual question answering, our extensive experiments using\nstate-of-the-art VL models show that they still struggle with visual metaphors,\nand perform substantially worse than humans.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:41:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13704","submitter":"Chanuka Wijayakoon","authors":"Thejan Wijesinghe, Chamath Abeysinghe, Chanuka Wijayakoon, Lahiru\n  Jayathilake, Uthayasanker Thayasivam","title":"FlowChroma -- A Deep Recurrent Neural Network for Video Colorization","comments":null,"journal-ref":null,"doi":"10.1007/978-3-030-50347-5_2","report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We develop an automated video colorization framework that minimizes the\nflickering of colors across frames. If we apply image colorization techniques\nto successive frames of a video, they treat each frame as a separate\ncolorization task. Thus, they do not necessarily maintain the colors of a scene\nconsistently across subsequent frames. The proposed solution includes a novel\ndeep recurrent encoder-decoder architecture which is capable of maintaining\ntemporal and contextual coherence between consecutive frames of a video. We use\na high-level semantic feature extractor to automatically identify the context\nof a scenario including objects, with a custom fusion layer that combines the\nspatial and temporal features of a frame sequence. We demonstrate experimental\nresults, qualitatively showing that recurrent neural networks can be\nsuccessfully used to improve color consistency in video colorization.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:41:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13705","submitter":"Lijun Li","authors":"Lijun Li, Li'an Zhuo, Bang Zhang, Liefeng Bo, Chen Chen","title":"DiffHand: End-to-End Hand Mesh Reconstruction via Diffusion Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Hand mesh reconstruction from the monocular image is a challenging task due\nto its depth ambiguity and severe occlusion, there remains a non-unique mapping\nbetween the monocular image and hand mesh. To address this, we develop\nDiffHand, the first diffusion-based framework that approaches hand mesh\nreconstruction as a denoising diffusion process. Our one-stage pipeline\nutilizes noise to model the uncertainty distribution of the intermediate hand\nmesh in a forward process. We reformulate the denoising diffusion process to\ngradually refine noisy hand mesh and then select mesh with the highest\nprobability of being correct based on the image itself, rather than relying on\n2D joints extracted beforehand. To better model the connectivity of hand\nvertices, we design a novel network module called the cross-modality decoder.\nExtensive experiments on the popular benchmarks demonstrate that our method\noutperforms the state-of-the-art hand mesh reconstruction approaches by\nachieving 5.8mm PA-MPJPE on the Freihand test set, 4.98mm PA-MPJPE on the\nDexYCB test set.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:44:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13706","submitter":"Wanchun Liu","authors":"Jiazheng Chen, Wanchun Liu, Daniel Quevedo, Yonghui Li and Branka\n  Vucetic","title":"Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep\n  Reinforcement Learning Approach","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.IT cs.SY eess.SP eess.SY math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For cyber-physical systems in the 6G era, semantic communications connecting\ndistributed devices for dynamic control and remote state estimation are\nrequired to guarantee application-level performance, not merely focus on\ncommunication-centric performance. Semantics here is a measure of the\nusefulness of information transmissions. Semantic-aware transmission scheduling\nof a large system often involves a large decision-making space, and the optimal\npolicy cannot be obtained by existing algorithms effectively. In this paper, we\nfirst investigate the fundamental properties of the optimal semantic-aware\nscheduling policy and then develop advanced deep reinforcement learning (DRL)\nalgorithms by leveraging the theoretical guidelines. Our numerical results show\nthat the proposed algorithms can substantially reduce training time and enhance\ntraining performance compared to benchmark algorithms.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:45:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13707","submitter":"Orevaoghene Ahia","authors":"Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R.\n  Mortensen, Noah A. Smith, Yulia Tsvetkov","title":"Do All Languages Cost the Same? Tokenization in the Era of Commercial\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language models have graduated from being research prototypes to\ncommercialized products offered as web APIs, and recent works have highlighted\nthe multilingual capabilities of these products. The API vendors charge their\nusers based on usage, more specifically on the number of ``tokens'' processed\nor generated by the underlying language models. What constitutes a token,\nhowever, is training data and model dependent with a large variance in the\nnumber of tokens required to convey the same information in different\nlanguages. In this work, we analyze the effect of this non-uniformity on the\nfairness of an API's pricing policy across languages. We conduct a systematic\nanalysis of the cost and utility of OpenAI's language model API on multilingual\nbenchmarks in 22 typologically diverse languages. We show evidence that\nspeakers of a large number of the supported languages are overcharged while\nobtaining poorer results. These speakers tend to also come from regions where\nthe APIs are less affordable to begin with. Through these analyses, we aim to\nincrease transparency around language model APIs' pricing policies and\nencourage the vendors to make them more equitable.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:46:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13708","submitter":"Tetsu Shimomura","authors":"Yoshihiro Mizuta and Tetsu Shimomura","title":"Sobolev type inequalities for fractional maximal functions and Riesz\n  potentials in half spaces","comments":"22 pages, to appear in Studia Math","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we study Sobolev type inequalities for fractional maximal\nfunctions $M_{{\\mathbb H},\\nu}f$ and Riesz potentials $I_{{\\mathbb H},\\alpha}\nf$ of functions in weighted Morrey spaces of the double phase functional\n$\\Phi(x,t) = t^{p} + (b(x) t)^{q}$ in the half space, where $1<p<q$ and\n$b(\\cdot)$ is non-negative, bounded and H\\\"older continuous of order $\\theta\n\\in (0,1]$. We also show that the Riesz potential operator $I_{{\\mathbb\nH},\\alpha}$ embeds from weighted Morrey space of the double phase functional\n$\\Phi(x,t)$ to weighted Campanato spaces. Finally, we treat the similar\nembedding for Sobolev functions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:46:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13709","submitter":"Faisal Javed","authors":"Muhammad Yasir, Xia Tiecheng, Faisal Javed, G. Mustafa","title":"Thermal analysis and Joule-Thomson expansion of black hole exhibiting\n  metric-affine gravity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study examines a recently hypothesized black hole, which is a perfect\nsolution of metric-affine gravity with a positive cosmological constant, and\nits thermodynamic features as well as the Joule-Thomson expansion. We develop\nsome thermodynamical quantities, such as volume, Gibbs free energy, and heat\ncapacity, using the entropy and Hawking temperature. We also examine the first\nlaw of thermodynamics and thermal fluctuations, which might eliminate certain\nblack hole instabilities. In this regard, a phase transition from unstable to\nstable is conceivable when the first law order corrections are present. Besides\nthat, we study the efficiency of this system as a heat engine and the effect of\nmetric-affine gravity for physical parameters $q_e$, $q_m$,\n  $\\kappa_{\\mathrm{s}}$, $\\kappa_{\\mathrm{d}}$ and $\\kappa_{\\mathrm{sh}}$.\nFurther, we study the Joule-Thomson coefficient, and the inversion temperature\nand also observed the isenthalpic curves in the $T_i -P_i$ plane. In\nmetric-affine gravity, a comparison is made between the Van der Waals fluid and\nthe black hole to study their similarities and differences.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:47:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13710","submitter":"Qingyang Wu","authors":"Qingyang Wu, Deema Alnuhait, Derek Chen, Zhou Yu","title":"Using Textual Interface to Align External Knowledge for End-to-End\n  Task-Oriented Dialogue Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:48:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13711","submitter":"Yen-Ting Lin","authors":"Yen-Ting Lin, Yun-Nung Chen","title":"LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain\n  Conversations with Large Language Models","comments":"Accepted at 5th NLP4ConvAI","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose LLM-Eval, a unified multi-dimensional automatic evaluation method\nfor open-domain conversations with large language models (LLMs). Existing\nevaluation methods often rely on human annotations, ground-truth responses, or\nmultiple LLM prompts, which can be expensive and time-consuming. To address\nthese issues, we design a single prompt-based evaluation method that leverages\na unified evaluation schema to cover multiple dimensions of conversation\nquality in a single model call. We extensively evaluate the performance of\nLLM-Eval on various benchmark datasets, demonstrating its effectiveness,\nefficiency, and adaptability compared to state-of-the-art evaluation methods.\nOur analysis also highlights the importance of choosing suitable LLMs and\ndecoding strategies for accurate evaluation results. LLM-Eval offers a\nversatile and robust solution for evaluating open-domain conversation systems,\nstreamlining the evaluation process and providing consistent performance across\ndiverse scenarios.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:57:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13712","submitter":"Alfonso Amayuelas","authors":"Alfonso Amayuelas, Liangming Pan, Wenhu Chen, William Wang","title":"Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper investigates the capabilities of Large Language Models (LLMs) in\nthe context of understanding their own knowledge and measuring their\nuncertainty. We argue this is an important feature for mitigating\nhallucinations. Specifically, we focus on addressing \\textit{known-unknown}\nquestions, characterized by high uncertainty due to the absence of definitive\nanswers. To facilitate our study, we collect a dataset with new Known-Unknown\nQuestions (KUQ) and propose a novel categorization scheme to elucidate the\nsources of uncertainty. Subsequently, we assess the LLMs' ability to\ndifferentiate between known and unknown questions and classify them\naccordingly. Moreover, we evaluate the quality of their answers in an\nOpen-Ended QA setting. To quantify the uncertainty expressed in the answers, we\ncreate a semantic evaluation method that measures the model's accuracy in\nexpressing uncertainty between known vs unknown questions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:59:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13713","submitter":"Yuki Saito","authors":"Yuki Saito, Eiji Iimori, Shinnosuke Takamichi, Kentaro Tachibana,\n  Hiroshi Saruwatari","title":"CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling\n  and Attentive Listening in Customer Center","comments":"5 pages, accepted for INTERSPEECH2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL cs.LG eess.AS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We present CALLS, a Japanese speech corpus that considers phone calls in a\ncustomer center as a new domain of empathetic spoken dialogue. The existing\nSTUDIES corpus covers only empathetic dialogue between a teacher and student in\na school. To extend the application range of empathetic dialogue speech\nsynthesis (EDSS), we designed our corpus to include the same female speaker as\nthe STUDIES teacher, acting as an operator in simulated phone calls. We\ndescribe a corpus construction methodology and analyze the recorded speech. We\nalso conduct EDSS experiments using the CALLS and STUDIES corpora to\ninvestigate the effect of domain differences. The results show that mixing the\ntwo corpora during training causes biased improvements in the quality of\nsynthetic speech due to the different degrees of expressiveness. Our project\npage of the corpus is http://sython.org/Corpus/STUDIES-2.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:04:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13714","submitter":"Alexander Valov","authors":"A.V. Valov, E.V. Dontsov, A.N. Baykin, S.V. Golovin","title":"An implicit level set algorithm for hydraulic fracturing with a\n  stress-layer asymptote","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph cs.CE cs.NA math.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The capability to simulate a hydraulic fracturing process is an essential\ntool that can be used to optimize treatment design and increase the efficiency\nof field operations. In most practical cases, hydraulic fractures propagate in\na multi-layered rock formation. As a result, there is a need to incorporate the\neffect of such heterogeneities in fracturing models to achieve an accurate\nprediction. To capture the layered structure of rocks, a hydraulic fracture\nsimulator typically requires a fine mesh, which leads to a drastic reduction in\ncomputational performance. An alternative is to use more sophisticated models\nthat are capable of providing reasonably accurate predictions even on a\nrelatively coarse mesh. In the case of fracture growth modeling, the pivotal\ncomponent of the simulation is a fracture front tracking algorithm that\naccounts for the layered structure of the formation. Consequently, this paper\naims to extend the established Implicit Level Set Algorithm (ILSA) to account\nfor the effect of multiple stress layers within the tip asymptote. The enhanced\nfront tracking algorithm involves the stress-corrected asymptote that\nincorporates the influence of stress layers within the near-tip region. To\nfurther increase the validity region of the stress-corrected asymptote, the\nstress relaxation factor is introduced, and its accuracy is examined. The\nnumerical algorithm is validated against the reference semi-analytical\nsolutions as well as experimental observations. In addition, we investigate the\nsensitivity of the fracture geometry to mesh size to demonstrate that the front\ntracking algorithm based on the stress-corrected asymptote retains its accuracy\non a coarse mesh.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:06:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13715","submitter":"Insung Kong","authors":"Insung Kong, Yuha Park, Joonhyuk Jung, Kwonsang Lee, Yongdai Kim","title":"Covariate balancing using the integral probability metric for causal\n  inference","comments":"32 pages, ICML 2023 proceedings","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Weighting methods in causal inference have been widely used to achieve a\ndesirable level of covariate balancing. However, the existing weighting methods\nhave desirable theoretical properties only when a certain model, either the\npropensity score or outcome regression model, is correctly specified. In\naddition, the corresponding estimators do not behave well for finite samples\ndue to large variance even when the model is correctly specified. In this\npaper, we consider to use the integral probability metric (IPM), which is a\nmetric between two probability measures, for covariate balancing. Optimal\nweights are determined so that weighted empirical distributions for the treated\nand control groups have the smallest IPM value for a given set of\ndiscriminators. We prove that the corresponding estimator can be consistent\nwithout correctly specifying any model (neither the propensity score nor the\noutcome regression model). In addition, we empirically show that our proposed\nmethod outperforms existing weighting methods with large margins for finite\nsamples.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:06:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13716","submitter":"Yuhao Liang","authors":"Yuhao Liang, Fan Yu, Yangze Li, Pengcheng Guo, Shiliang Zhang, Qian\n  Chen, Lei Xie","title":"BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR","comments":"Accepted by INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The recently proposed serialized output training (SOT) simplifies\nmulti-talker automatic speech recognition (ASR) by generating speaker\ntranscriptions separated by a special token. However, frequent speaker changes\ncan make speaker change prediction difficult. To address this, we propose\nboundary-aware serialized output training (BA-SOT), which explicitly\nincorporates boundary knowledge into the decoder via a speaker change detection\ntask and boundary constraint loss. We also introduce a two-stage connectionist\ntemporal classification (CTC) strategy that incorporates token-level SOT CTC to\nrestore temporal context information. Besides typical character error rate\n(CER), we introduce utterance-dependent character error rate (UD-CER) to\nfurther measure the precision of speaker change prediction. Compared to\noriginal SOT, BA-SOT reduces CER/UD-CER by 5.1%/14.0%, and leveraging a\npre-trained ASR model for BA-SOT model initialization further reduces\nCER/UD-CER by 8.4%/19.9%.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:08:13 GMT"},{"version":"v2","created":"Tue, 30 May 2023 13:45:08 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13717","submitter":"Alejandro Silva","authors":"Alejandro Silva","title":"Application of the Newton Time-Extracting Wavelet Transform as a chirp\n  filter","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The problem of detecting chirps is present in many applications of Signal\nProcessing. Proper denoising, which involves filtering the signals after their\nacquisition, improves the efficacy of their detection. This manuscript\ndescribes how a recently-published method of Time-Frequency Analysis (TFA) with\nreassignment, namely the Newton Time-Extracting Wavelet Transform (NTEWT), can\nbe employed as a highly-performing chirp filter. The proposed methodology has\nthe advantage of denoising chirps without distorting their instantaneous\nphases, as linear convolutional filters do. Numerical experiments have proven\nthe efficacy of the proposed filter. After NTEWT-based filtering, the\nresolution of chirp detection with matched filtering is notably improved, even\nwhen the signals contain white noise. The computation times of the proposed\nnumerical implementation of the NTEWT are lower than those reported in its\nseminar paper.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:12:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13718","submitter":"Fangkai Jiao","authors":"Fangkai Jiao, Zhiyang Teng, Shafiq Joty, Bosheng Ding, Aixin Sun,\n  Zhengyuan Liu, Nancy F. Chen","title":"LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large\n  Language Models","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Existing efforts to improve logical reasoning ability of language models have\npredominantly relied on supervised fine-tuning, hindering generalization to new\ndomains and/or tasks. The development of Large Langauge Models (LLMs) has\ndemonstrated the capacity of compressing abundant knowledge into a single\nproxy, enabling them to tackle multiple tasks effectively. Our preliminary\nexperiments, nevertheless, show that LLMs do not show capability on logical\nreasoning. The performance of LLMs on logical reasoning benchmarks is far\nbehind the existing state-of-the-art baselines. In this paper, we make the\nfirst attempt to investigate the feasibility of incorporating logical knowledge\nthrough self-supervised post-training, and activating it via in-context\nlearning, which we termed as LogicLLM. Specifically, we devise an\nauto-regressive objective variant of MERIt and integrate it with two LLM\nseries, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to\n13 billion. The results on two challenging logical reasoning benchmarks\ndemonstrate the effectiveness of LogicLLM. Besides, we conduct extensive\nablation studies to analyze the key factors in designing logic-oriented proxy\ntasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:13:10 GMT"},{"version":"v2","created":"Wed, 24 May 2023 06:38:41 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13719","submitter":"Bobir Toshmatov","authors":"Bobir Toshmatov, Zden\\v{e}k Stuchl\\'ik, Bobomurat Ahmedov","title":"Can electromagnetic charge inhabit in Rastall gravity?","comments":"7 pages, 1 figure, accepted for publication in Physics of the Dark\n  Universe","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  One of the eminent generalizations of theory of general relativity is the\nRastall gravity which was {constructed} based on the assumption of the\nnon-conserved energy-momentum tensor of the matter field. Despite in the\nliterature several solutions of black holes in the Rastall gravity coupled to\nthe electromagnetic field have been presented, in the current paper we argue\nthat the Rastall gravity with non-conserved energy-momentum tensor (with\n$\\lambda\\neq0$ and $R\\neq0$) cannot couple to the electrodynamics, i.e., the\nelectromagnetically charged black hole solution cannot be obtained in this\ncase. This statement is adequate for both linear and nonlinear electrodynamics\nwith the electric, magnetic, or dyonic charges coupled to the Rastall gravity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:14:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13720","submitter":"Ikboljon Karimjanov","authors":"F.N.Arzikulov, I.A.Karimjanov, S.M.Umrzaqov","title":"Local and 2-local automorphisms of finite-dimensional nilpotent\n  associative algebras","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the present paper automorphisms, local and 2-local automorphisms of\n$n$-dimensional null-filiform and filiform associative algebras are studied.\nNamely, a common form of the matrix of automorphisms and local automorphisms of\nthese algebras is clarified. It turns out that the common form of the matrix of\nan automorphism on these algebras does not coincide with the local\nautomorphism's matrices common form on these algebras. Therefore, these\nassociative algebras have local automorphisms that are not automorphisms. Also,\nthat each 2-local automorphism of these algebras is an automorphism is proved.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:15:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13721","submitter":"Hyundong Cho","authors":"Hyundong Cho, Andrea Madotto, Zhaojiang Lin, Khyathi Raghavi Chandu,\n  Satwik Kottur, Jing Xu, Jonathan May, Chinnadhurai Sankar","title":"Continual Dialogue State Tracking via Example-Guided Question Answering","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dialogue systems are frequently updated to accommodate new services, but\nnaively updating them by continually training with data for new services in\ndiminishing performance on previously learnt services. Motivated by the insight\nthat dialogue state tracking (DST), a crucial component of dialogue systems\nthat estimates the user's goal as a conversation proceeds, is a simple natural\nlanguage understanding task, we propose reformulating it as a bundle of\ngranular example-guided question answering tasks to minimize the task shift\nbetween services and thus benefit continual learning. Our approach alleviates\nservice-specific memorization and teaches a model to contextualize the given\nquestion and example to extract the necessary information from the\nconversation. We find that a model with just 60M parameters can achieve a\nsignificant boost by learning to learn from in-context examples retrieved by a\nretriever trained to identify turns with similar dialogue state changes.\nCombining our method with dialogue-level memory replay, our approach attains\nstate of the art performance on DST continual learning metrics without relying\non any complex regularization or parameter expansion methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:15:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13722","submitter":"Ralf Metzler","authors":"C. Di Bello, A. V. Chechkin, A. K. Hartmann, Z. Palmowski, and R.\n  Metzler","title":"Time-dependent probability density function for partial resetting\n  dynamics","comments":"21 pages, 4 figures, IOPLaTeX","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech math-ph math.MP physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stochastic resetting is a rapidly developing topic in the field of stochastic\nprocesses and their applications. It denotes the occasional reset of a\ndiffusing particle to its starting point and effects, inter alia, optimal\nfirst-passage times to a target. Recently the concept of partial resetting, in\nwhich the particle is reset to a given fraction of the current value of the\nprocess, has been established and the associated search behaviour analysed.\nHere we go one step further and we develop a general technique to determine the\ntime-dependent probability density function (PDF) for Markov processes with\npartial resetting. We obtain an exact representation of the PDF in the case of\ngeneral symmetric L\\'evy flights with stable index $0<\\alpha\\le2$. For Cauchy\nand Brownian motions (i.e., $\\alpha=1,2$), this PDF can be expressed in terms\nof elementary functions in position space. We also determine the stationary\nPDF. Our numerical analysis of the PDF demonstrates intricate crossover\nbehaviours as function of time.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:16:10 GMT"},{"version":"v2","created":"Wed, 24 May 2023 09:24:42 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13723","submitter":"Yunyi Zhang","authors":"Yunyi Zhang, Minhao Jiang, Yu Meng, Yu Zhang, Jiawei Han","title":"PromptClass: Weakly-Supervised Text Classification with Prompting\n  Enhanced Noise-Robust Self-Training","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently proposed weakly-supervised text classification settings train a\nclassifier using the label name of each target class as the only supervision.\nSuch weakly-supervised settings have been gaining increasing attention since\nthey can largely reduce human annotation efforts compared to fully-supervised\nand semi-supervised settings. Most existing methods follow the strategy that\nfirst uses the label names as static features to generate pseudo labels, which\nare then used for classifier training. While reasonable, such a commonly\nadopted framework suffers from two limitations: (1) words can have different\nmeanings in different contexts, so using label names for context-free matching\ncan induce very noisy pseudo labels; and (2) the errors made in the pseudo\nlabel generation stage will directly propagate to the classifier training stage\nwithout a chance of being corrected. In this paper, we propose a new method,\nPromptClass, consisting of two modules: (1) a pseudo label acquisition module\nthat uses zero-shot prompting of pre-trained language models (PLM) to get\npseudo labels based on contextualized text understanding, and (2) a\nnoise-robust self-training module that iteratively trains the classifier and\nupdates pseudo labels by utilizing two PLM fine-tuning strategies that\nregularize each other. Extensive experiments show that PromptClass achieves\noverall better performance than existing strong baselines on four benchmark\ndatasets and even achieves similar performance to fully-supervised classifiers\non sentiment classification tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:19:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13724","submitter":"Yuki Saito","authors":"Yuki Saito, Shinnosuke Takamichi, Eiji Iimori, Kentaro Tachibana,\n  Hiroshi Saruwatari","title":"ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from\n  ChatGPT-derived Context Word Embeddings","comments":"5 pages, accepted for INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL cs.LG eess.AS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS)\nmethod using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that\ncan deeply understand the content and purpose of an input prompt and\nappropriately respond to the user's request. We focus on ChatGPT's reading\ncomprehension and introduce it to EDSS, a task of synthesizing speech that can\nempathize with the interlocutor's emotion. Our method first gives chat history\nto ChatGPT and asks it to generate three words representing the intention,\nemotion, and speaking style for each line in the chat. Then, it trains an EDSS\nmodel using the embeddings of ChatGPT-derived context words as the conditioning\nfeatures. The experimental results demonstrate that our method performs\ncomparably to ones using emotion labels or neural network-derived context\nembeddings learned from chat histories. The collected ChatGPT-derived context\ninformation is available at\nhttps://sarulab-speech.github.io/demo_ChatGPT_EDSS/.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:19:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13725","submitter":"Raghav Gupta","authors":"Raghav Gupta, Renat Aksitov, Samrat Phatale, Simral Chaudhary,\n  Harrison Lee, Abhinav Rastogi","title":"Conversational Recommendation as Retrieval: A Simple, Strong Baseline","comments":"To appear at the 5th NLP4ConvAI workshop","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Conversational recommendation systems (CRS) aim to recommend suitable items\nto users through natural language conversation. However, most CRS approaches do\nnot effectively utilize the signal provided by these conversations. They rely\nheavily on explicit external knowledge e.g., knowledge graphs to augment the\nmodels' understanding of the items and attributes, which is quite hard to\nscale. To alleviate this, we propose an alternative information retrieval\n(IR)-styled approach to the CRS item recommendation task, where we represent\nconversations as queries and items as documents to be retrieved. We expand the\ndocument representation used for retrieval with conversations from the training\nset. With a simple BM25-based retriever, we show that our task formulation\ncompares favorably with much more complex baselines using complex external\nknowledge on a popular CRS benchmark. We demonstrate further improvements using\nuser-centric modeling and data augmentation to counter the cold start problem\nfor CRSs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:21:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13726","submitter":"Melih Is","authors":"Melih \\.Is and \\.Ismet Karaca","title":"Proximal Motion Planning Algorithms","comments":"27 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we transfer the problem of measuring navigational complexity\nin topological spaces to the nearness theory. We investigate the most important\ncomponent of this problem, the topological complexity number (denoted by TC),\nwith its different versions including relative and higher TC, on the proximal\nSchwarz genus as well as the proximal (higher) homotopic distance. We outline\nthe fundamental properties of some concepts related to the proximal (or\ndescriptive proximal) TC numbers. In addition, we provide some instances of\n(descriptive) proximity spaces, specifically on basic robot vacuum cleaners, to\nillustrate the results given on proximal and descriptive proximal TC.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:21:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13727","submitter":"Toshio Miyamachi","authors":"Hiroki Ono, Yoshitaka Umeda, Kaito Yoshida, Kenzaburo Tsutsui, Kohei\n  Yamamoto, Osamu Ishiyama, Hiroshi Iwayama, Eiken Nakamura, Toshihiko\n  Yokoyama, Masaki Mizuguchi, Toshio Miyamachi","title":"Roughness-induced magnetic decoupling at organic-inorganic interface","comments":"5 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have investigated structural, electronic and magnetic properties of\nH$_2$Pc on Fe$_2$N/Fe using low-energy electron diffraction and soft x-ray\nabsorption spectroscopy/x-ray magnetic circular dichroism. Element specific\nmagnetization curves reveal that the magnetic coupling with H$_2$Pc enhances\nthe perpendicular magnetic anisotropy of Fe$_2$N/Fe at the H$_2$Pc coverage of\n1 molecular layer. However, adding two and three molecular layers of H$_2$Pc\nreverts the shape of magnetization curve back to the initial state before\nH$_2$Pc deposition. We successfully link appearance and disappearance of the\nmagnetic coupling at the H$_2$Pc-Fe$_2$N/Fe interface with the change of\nhybridization strength at N sites accompanied by the increase in the H$_2$Pc\ncoverage.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:31:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13728","submitter":"Victor P. Ruban","authors":"Victor P. Ruban","title":"An optical analogue for a rotating binary Bose-Einstein condensate","comments":"6 pages, 8 figures, in Russian, submitted to JETP Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics cond-mat.quant-gas nlin.PS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The coupled nonlinear Schroedinger equations for paraxial optics with two\ncircular light polarizations, in a defocusing Kerr medium with anomalous\ndispersion, coincide in form with the Gross-Pitaevskii equations for a binary\nBose-Einstein condensate of cold atoms in the phase separation regime. A\nhelical symmetry of optical waveguide corresponds to rotation of transverse\npotential confining the condensate. The ``centrifugal force'' makes essential\neffect on propagation of light wave in such system. Numerical simulations for a\nwaveguide of elliptical cross-section revealed previously unknown in optics,\nspecific structures consisting of quantized vortices and domain walls between\ntwo polarizations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:34:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13729","submitter":"Sukmin Cho","authors":"Sukmin Cho, Soyeong Jeong, Jeongyeon Seo and Jong C. Park","title":"Discrete Prompt Optimization via Constrained Generation for Zero-shot\n  Re-ranker","comments":"Findings of ACL 2023 Camera Ready","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Re-rankers, which order retrieved documents with respect to the relevance\nscore on the given query, have gained attention for the information retrieval\n(IR) task. Rather than fine-tuning the pre-trained language model (PLM), the\nlarge-scale language model (LLM) is utilized as a zero-shot re-ranker with\nexcellent results. While LLM is highly dependent on the prompts, the impact and\nthe optimization of the prompts for the zero-shot re-ranker are not explored\nyet. Along with highlighting the impact of optimization on the zero-shot\nre-ranker, we propose a novel discrete prompt optimization method, Constrained\nPrompt generation (Co-Prompt), with the metric estimating the optimum for\nre-ranking. Co-Prompt guides the generated texts from PLM toward optimal\nprompts based on the metric without parameter update. The experimental results\ndemonstrate that Co-Prompt leads to outstanding re-ranking performance against\nthe baselines. Also, Co-Prompt generates more interpretable prompts for humans\nagainst other prompt optimization methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:35:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13730","submitter":"Hieu T. Ngo","authors":"Hieu T. Ngo","title":"A matrix variant of the Erd\\H{o}s-Falconer distance problems over finite\n  field","comments":"17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a matrix analog of the Erd\\H{o}s-Falconer distance problems in\nvector spaces over finite fields. There arises an interesting analysis of\ncertain quadratic matrix Gauss sums.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:35:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13731","submitter":"Jiacheng Li","authors":"Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang,\n  Julian McAuley","title":"Text Is All You Need: Learning Language Representations for Sequential\n  Recommendation","comments":"accepted to KDD 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Sequential recommendation aims to model dynamic user behavior from historical\ninteractions. Existing methods rely on either explicit item IDs or general\ntextual features for sequence modeling to understand user preferences. While\npromising, these approaches still struggle to model cold-start items or\ntransfer knowledge to new datasets. In this paper, we propose to model user\npreferences and item features as language representations that can be\ngeneralized to new items and datasets. To this end, we present a novel\nframework, named Recformer, which effectively learns language representations\nfor sequential recommendation. Specifically, we propose to formulate an item as\na \"sentence\" (word sequence) by flattening item key-value attributes described\nby text so that an item sequence for a user becomes a sequence of sentences.\nFor recommendation, Recformer is trained to understand the \"sentence\" sequence\nand retrieve the next \"sentence\". To encode item sequences, we design a\nbi-directional Transformer similar to the model Longformer but with different\nembedding layers for sequential recommendation. For effective representation\nlearning, we propose novel pretraining and finetuning methods which combine\nlanguage understanding and recommendation tasks. Therefore, Recformer can\neffectively recommend the next item based on language representations.\nExtensive experiments conducted on six datasets demonstrate the effectiveness\nof Recformer for sequential recommendation, especially in low-resource and\ncold-start settings.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:35:46 GMT"},{"version":"v2","created":"Fri, 26 May 2023 22:30:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13732","submitter":"Ao Liu","authors":"Ao Liu, Shaoshi Yang, Jingsheng Tan, Zongze Liang, Jiasen Sun, Tao\n  Wen, Hongyan Yan","title":"Task Containerization and Container Placement Optimization for MEC: A\n  Joint Communication and Computing Perspective","comments":"11 pages, 8 figures","journal-ref":"Processes 2023, 11(5), pp. 1-19, article number: 1560","doi":"10.3390/pr11051560","report-no":null,"categories":"cs.DC cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Containers are used by an increasing number of Internet service providers to\ndeploy their applications in multi-access edge computing (MEC) systems.\nAlthough container-based virtualization technologies significantly increase\napplication availability, they may suffer expensive communication overhead and\nresource use imbalances. However, so far there has been a scarcity of studies\nto conquer these difficulties. In this paper, we design a workflow-based\nmathematical model for applications built upon interdependent multitasking\ncomposition, formulate a multi-objective combinatorial optimization problem\ncomposed of two subproblems -- graph partitioning and multi-choice vector bin\npacking, and propose several joint\ntask-containerization-and-container-placement methods to reduce communication\noverhead and balance multi-type computing resource utilization. The performance\nsuperiority of the proposed algorithms is demonstrated by comparison with the\nstate-of-the-art task and container scheduling schemes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:38:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13733","submitter":"Hongru Wang","authors":"Rui Wang, Hongru Wang, Fei Mi, Yi Chen, Ruifeng Xu, Kam-Fai Wong","title":"Self-Critique Prompting with Large Language Models for Inductive\n  Instructions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Numerous works are proposed to improve or evaluate the capabilities of Large\nlanguage models (LLMs) to fulfill user instructions. However, they neglect the\npossibility that user inputs may inherently contain incorrect information due\nto users' false beliefs or malicious intents. In this way, blindly adhering to\nusers' false content will cause deception and harm. To address this problem, we\npropose a challenging benchmark consisting of Inductive Instructions (INDust)\nto evaluate whether LLMs could resist these instructions. The INDust includes\n15K instructions across three categories: Fact-Checking Instructions, Questions\nbased on False Premises, and Creative Instructions based on False Premises. Our\nexperiments on several strong LLMs reveal that current LLMs can be easily\ndeceived by INDust into generating misleading and malicious statements. Hence\nwe employ Self-Critique prompting to encourage LLMs to not only critique\nthemselves like in previous works but also the users, which show remarkable\nimprovement in handling inductive instructions under both zero-shot and\nfew-shot settings.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:38:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13734","submitter":"Baihong Li","authors":"Baihong Li, Changhua Chen, Boxin Yuan, Xiangying Hao, Rui-Bo Jin","title":"Complete spectral characterization of biphotons by simultaneously\n  determining its frequency sum and difference in a single quantum\n  interferometer","comments":"11 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We theoretically propose a novel quantum interferometer in which the NOON\nstate interferometer (NOONI) is combined with the Hong-Ou-Mandel interferometer\n(HOMI). This interferometer combined the advantages of both the NOONI that\ndepends on biphoton frequency sum, and the HOMI that depends on biphoton\nfrequency difference into a single interferometer. It can thus simultaneously\nobtain the spectral correlation information of biphotons in both frequency sum\nand difference by taking the Fourier transform from a single time-domain\nquantum interferogram, which provides a method for complete spectral\ncharacterization of an arbitrary two-photon state with exchange symmetry. A\ndirect application of such an interferometer can be found in quantum\nFourier-transform spectroscopy where direct spectral measurement is difficult.\nFurthermore, as it can realize the measurement of time intervals on three\nscales at the same time, we expect that it can provide a new method in quantum\nmetrology. Finally, we discuss another potential application of such an\ninterferometer in the generation and characterization of high-dimensional and\nphase-controlled frequency entanglement.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:40:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13735","submitter":"Sungdong Kim","authors":"Sungdong Kim, Sanghwan Bae, Jamin Shin, Soyoung Kang, Donghyun Kwak,\n  Kang Min Yoo, Minjoon Seo","title":"Aligning Large Language Models through Synthetic Feedback","comments":"Preprint, 9 pages (with 10 pages of supplementary)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Aligning large language models (LLMs) to human values has become increasingly\nimportant as it enables sophisticated steering of LLMs, e.g., making them\nfollow given instructions while keeping them less toxic. However, it requires a\nsignificant amount of human demonstrations and feedback. Recently, open-sourced\nmodels have attempted to replicate the alignment learning process by distilling\ndata from already aligned LLMs like InstructGPT or ChatGPT. While this process\nreduces human efforts, constructing these datasets has a heavy dependency on\nthe teacher models. In this work, we propose a novel framework for alignment\nlearning with almost no human labor and no dependency on pre-aligned LLMs.\nFirst, we perform reward modeling (RM) with synthetic feedback by contrasting\nresponses from vanilla LLMs with various sizes and prompts. Then, we use the RM\nfor simulating high-quality demonstrations to train a supervised policy and for\nfurther optimizing the model with reinforcement learning. Our resulting model,\nAligned Language Model with Synthetic Training dataset (ALMoST), outperforms\nopen-sourced models, including Alpaca, Dolly, and OpenAssistant, which are\ntrained on the outputs of InstructGPT or human-annotated instructions. Our\n7B-sized model outperforms the 12-13B models in the A/B tests using GPT-4 as\nthe judge with about 75% winning rate on average.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:41:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13736","submitter":"Antoine Levitt","authors":"Ivan Duchemin (IRIG), Antoine Levitt (LMO)","title":"Computing photoionization spectra in Gaussian basis sets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a method to compute the photoionization spectra of atoms and\nmolecules in linear response time-dependent density functional theory. The\nelectronic orbital variations corresponding to ionized electrons are expanded\non a basis set of delocalized functions obtained as the solution of the\ninhomogeneous Helmholtz equation with gaussian basis set functions as\nright-hand side. The resulting scheme is able to reproduce photoionization\nspectra without any need for artificial regularization or localization. We\ndemonstrate that it is able to produce accurate spectra for semilocal\nexchange-correlation functionals even using relatively small standard gaussian\nbasis sets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:42:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13737","submitter":"Yongqian Han","authors":"Yongqian Han","title":"Symplectic Symmetry and Radial Symmetry Either Persistence or Breaking\n  of Incompressible Fluid","comments":"60 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The incompressible Navier-Stokes equations are considered. We find that these\nequations have symplectic symmetry structures. Two linearly independent\nsymplectic symmetries form moving frame. The velocity vectors possess\nsymplectic representations in this moving frame. The symplectic representations\nof two-dimensional Navier-Stokes equations hold radial symmetry persistence. On\nthe other hand, we establish some results of radial symmetry either persistence\nor breaking for the symplectic representations of three-dimensional\nNavier-Stokes equations. Thanks radial symmetry persistence, we construct\ninfinite non-trivial solutions of static Euler equations with given boundary\ncondition. Therefore the randomness and turbulence of incompressible fluid\nappear provided Navier-Stokes flow converges to static Euler flow.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:44:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13738","submitter":"Yuwei Fang","authors":"Yuwei Fang, Mahmoud Khademi, Chenguang Zhu, Ziyi Yang, Reid Pryzant,\n  Yichong Xu, Yao Qian, Takuya Yoshioka, Lu Yuan, Michael Zeng and Xuedong\n  Huang","title":"i-Code Studio: A Configurable and Composable Framework for Integrative\n  AI","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Artificial General Intelligence (AGI) requires comprehensive understanding\nand generation capabilities for a variety of tasks spanning different\nmodalities and functionalities. Integrative AI is one important direction to\napproach AGI, through combining multiple models to tackle complex multimodal\ntasks. However, there is a lack of a flexible and composable platform to\nfacilitate efficient and effective model composition and coordination. In this\npaper, we propose the i-Code Studio, a configurable and composable framework\nfor Integrative AI. The i-Code Studio orchestrates multiple pre-trained models\nin a finetuning-free fashion to conduct complex multimodal tasks. Instead of\nsimple model composition, the i-Code Studio provides an integrative, flexible,\nand composable setting for developers to quickly and easily compose\ncutting-edge services and technologies tailored to their specific requirements.\nThe i-Code Studio achieves impressive results on a variety of zero-shot\nmultimodal tasks, such as video-to-text retrieval, speech-to-speech\ntranslation, and visual question answering. We also demonstrate how to quickly\nbuild a multimodal agent based on the i-Code Studio that can communicate and\npersonalize for users.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:45:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13739","submitter":"Guodong Li","authors":"Guodong Li, Chao-Wei Tsai, Daniel Stern, Jingwen Wu, Roberto J. Assef,\n  Andrew W. Blain, Tanio D\\'iaz-Santos, Peter R. M. Eisenhardt, Roger L.\n  Griffith, Thomas H. Jarrett, Hyunsung D. Jun, Sean E. Lake, M. Lynne Saade","title":"Discovery of a Low-Redshift Hot Dust-Obscured Galaxy","comments":"19 pages, 6 figures, submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report the discovery of the hyperluminous, highly obscured AGN WISE\nJ190445.04+485308.9 (W1904+4853 hereafter, $L_{bol} = 1.1 \\times 10^{13} \\\nL_{\\odot}$) at z=0.415. Its well-sampled spectral energy distribution (SED) is\ndominated by infrared dust emission, though broad emission lines are detected\nin the optical spectra. These features suggest that W1904+4853 contains an\nactively accreting supermassive black hole hidden in its dusty cocoon,\nresembling the observed properties of Hot Dust-Obscured Galaxies (Hot DOGs), a\npopulation previously only identified at z>1.0. Using the broad component of\nthe MgII emission line, we estimate a black hole mass of $log \\\n(M_{BH}/M_{\\odot}) = 8.4 \\pm 0.3$. The corresponding Eddington ratio of $1.4\n\\pm 0.2$ implies that the central black hole accretion is at the theoretical\nlimit of isotropic accretion. The rest-frame UV-optical SED and [O II] emission\nline also indicate that the host galaxy of W1904+4853 harbors strong star\nformation activity at the rate of up to $\\sim 45 \\ M_{\\odot} \\ yr^{-1}$. With\nan estimated stellar mass of $3 \\times 10^{10} \\ M_{\\odot}$, the host galaxy\nappears to be a starburst system with respect to the main sequence of the\nstar-forming galaxies at the same redshift. Although blueshifted and asymmetric\n[O III] emission provides evidence of an outflow, we estimate it to be an order\nof magnitude smaller than the star formation rate, indicating that the current\nobscured AGN activity at the center has not yet produced significant feedback\non the host galaxy star formation activity. W1904+4853 supports the\ninterpretation that Hot DOGs are a rare transitional phase of AGN accretion in\ngalaxy evolution, a phase that can persist into the present-day Universe.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:46:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13740","submitter":"Yiming Ai","authors":"Yiming Ai, Zhiwei He, Kai Yu, Rui Wang","title":"TeCS: A Dataset and Benchmark for Tense Consistency of Machine\n  Translation","comments":"10 pages, accepted in main conference of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Tense inconsistency frequently occurs in machine translation. However, there\nare few criteria to assess the model's mastery of tense prediction from a\nlinguistic perspective. In this paper, we present a parallel tense test set,\ncontaining French-English 552 utterances. We also introduce a corresponding\nbenchmark, tense prediction accuracy. With the tense test set and the\nbenchmark, researchers are able to measure the tense consistency performance of\nmachine translation systems for the first time.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:51:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13741","submitter":"Kibeom Kim","authors":"Kibeom Kim, Hyundo Lee, Min Whoo Lee, Moonheon Lee, Minsu Lee,\n  Byoung-Tak Zhang","title":"L-SA: Learning Under-Explored Targets in Multi-Target Reinforcement\n  Learning","comments":"17 pages include appendices, it is under-review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Tasks that involve interaction with various targets are called multi-target\ntasks. When applying general reinforcement learning approaches for such tasks,\ncertain targets that are difficult to access or interact with may be neglected\nthroughout the course of training - a predicament we call Under-explored Target\nProblem (UTP). To address this problem, we propose L-SA (Learning by adaptive\nSampling and Active querying) framework that includes adaptive sampling and\nactive querying. In the L-SA framework, adaptive sampling dynamically samples\ntargets with the highest increase of success rates at a high proportion,\nresulting in curricular learning from easy to hard targets. Active querying\nprompts the agent to interact more frequently with under-explored targets that\nneed more experience or exploration. Our experimental results on visual\nnavigation tasks show that the L-SA framework improves sample efficiency as\nwell as success rates on various multi-target tasks with UTP. Also, it is\nexperimentally demonstrated that the cyclic relationship between adaptive\nsampling and active querying effectively improves the sample richness of\nunder-explored targets and alleviates UTP.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:51:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13742","submitter":"Robert Woodward","authors":"P. Gavignet, F. Mondain, E. Pincemin, A. J. Grant, L. Johnson, R. I.\n  Woodward, J. F. Dynes, A. J. Shields","title":"Co-propagation of 6 Tb/s (60*100Gb/s) DWDM & QKD channels with ~17 dBm\n  aggregated WDM power over 50 km standard single mode fiber","comments":"https://opg.optica.org/abstract.cfm?uri=OFC-2023-Tu3H.2","journal-ref":"Optical Fiber Communication Conference (OFC) 2023, Technical\n  Digest Series (Optica Publishing Group, 2023), paper Tu3H.2","doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report the co-propagation, over 50 km of SSMF, of the quantum channel\n(1310 nm) of a QKD system with ~17 dBm total power of DWDM data channels (1550\nnm range). A metric to evaluate Co-propagation Efficiency is proposed.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:53:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13743","submitter":"Partha Sarkar","authors":"Partha Sarkar, Kshitij Khare and Malay Ghosh","title":"High-dimensional Posterior Consistency in Multi-response Regression\n  models with Non-informative Priors for Error Covariance Matrix","comments":"39 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Inverse-Wishart (IW) distribution is a standard and popular choice of\npriors for covariance matrices and has attractive properties such as\nconditional conjugacy. However, the IW family of priors has crucial drawbacks,\nincluding the lack of effective choices for non-informative priors. Several\nclasses of priors for covariance matrices that alleviate these drawbacks, while\npreserving computational tractability, have been proposed in the literature.\nThese priors can be obtained through appropriate scale mixtures of IW priors.\nHowever, the high-dimensional posterior consistency of models which incorporate\nsuch priors has not been investigated. We address this issue for the\nmulti-response regression setting ($q$ responses, $n$ samples) under a wide\nvariety of IW scale mixture priors for the error covariance matrix. Posterior\nconsistency and contraction rates for both the regression coefficient matrix\nand the error covariance matrix are established in the ``large $q$, large $n$\"\nsetting under mild assumptions on the true data-generating covariance matrix\nand relevant hyperparameters. In particular, the number of responses $q_n$ is\nallowed to grow with $n$, but with $q_n = o(n)$. Also, some results related to\nthe inconsistency of posterior mean for $q_n/n \\to \\gamma$, where $\\gamma \\in\n(0,\\infty)$ are provided.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:59:02 GMT"},{"version":"v2","created":"Wed, 31 May 2023 09:47:56 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13744","submitter":"Eytan Grosfeld","authors":"Shimon Arie Haver, Eran Ginossar, Sebastian E. de Graaf, Eytan\n  Grosfeld","title":"Electromagnetic response of the surface states of a topological\n  insulator nanowire embedded within a resonator","comments":null,"journal-ref":"Communications Physics volume 6, Article number: 101 (2023)","doi":"10.1038/s42005-023-01209-w","report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Exploring the interplay between topological phases and photons opens new\navenues for investigating novel quantum states. Here we show that\nsuperconducting resonators can serve as sensitive probes for properties of\ntopological insulator nanowires (TINWs) embedded within them. By combining a\nstatic, controllable magnetic flux threading the TINW with an additional\noscillating electromagnetic field applied perpendicularly, we show that orbital\nresonances can be generated and are reflected in periodic changes of the\nQ-factor of the resonator as a function of the flux. This response probes the\nconfinement of the two-dimensional Dirac orbitals on the surface of the TINW,\nrevealing their density of states and specific transition rules, as well as\ntheir dependence on the applied flux. Our approach represents a promising\ncross-disciplinary strategy for probing topological solid-state materials using\nstate-of-the-art photonic cavities, which would avoid the need for attaching\ncontacts, thereby enabling access to electronic properties closer to the\npristine topological states.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:03:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13745","submitter":"Cunshi Wang","authors":"Cunshi Wang, Yu Bai, Henggeng Han, Huiqin Yang, Jifeng Liu","title":"Transfer Learning Applied to Stellar Light Curve Classification","comments":"30 pages, 19 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Variability carries physical patterns and astronomical information of\nobjects, and stellar light curve variations are essential to understand the\nstellar formation and evolution processes. The studies of variations in stellar\nphotometry have the potential to expand the list of known stars, protostars,\nbinary stars, and compact objects, which could shed more light on stages of\nstellar lifecycles. The progress in machine-learning techniques and\napplications has developed modern algorithms to detect and condense features\nfrom big data, which enables us to classify stellar light curves efficiently\nand effectively. We explore several deep-learning methods on variable star\nclassifications. The sample of light curves is constructed with $\\delta$ Scuti,\n$\\gamma$ Doradus, RR Lyrae, eclipsing binaries, and hybrid variables from\n\\textit{Kepler} observations. Several algorithms are applied to transform the\nlight curves into images, continuous wavelet transform (CWT), Gramian angular\nfields, and recurrent plots. We also explore the representation ability of\nthese algorithms. The processed images are fed to several deep-learning methods\nfor image recognition, including VGG-19, GoogLeNet, Inception-v3, ResNet,\nSqueezeNet, and Xception architectures. The best transformation method is CWT,\nresulting in an average accuracy of 95.6\\%. VGG-19 shows the highest average\naccuracy of 93.25\\% among all architectures, while it shows the highest\naccuracy of 97.2\\% under CWT transformation method. The prediction can reach\n$\\sim1000$ light curves per second by using NVIDIA RTX 3090. Our results\nindicate that the combination of big data and deep learning opens a new path to\nclassify light curves automatically.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:04:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13746","submitter":"Zhenyu Ma","authors":"Zhenyu Ma, Xin Zhang, Pu Liu, Yong Deng, Wenyu Hu, Longqing Chen, Jun\n  Zhu, Sen Chen, Zhengshang Wang, Yuechun Shi, Jian Ma, Xiaoyi Wang, Yang Qiu,\n  Kun Zhang, Xudong Cui, Thomas Walther","title":"Preferential bond formation and interstitial/vacancy annihilation rate\n  drive atomic clustering in gallium ion sputtered compound materials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The investigation of chemical reactions during the ion irradiation is a\nfrontier for the study of the ion-material interaction. In order to derive the\ncontribution of bond formation to chemistry of ion produced nanoclusters, the\nvalence electron energy loss spectroscopy (VEELS) was exploited to investigate\nthe Ga$^+$ ion damage in Al$_2$O$_3$, InP and InGaAs, where each target\nmaterial has been shown to yield different process for altering the clustering\nof recoil atoms: metallic Ga, metallic In and InGaP clusters in Al$_2$O$_3$,\nInP and InGaAs respectively. Supporting simulations based on Monte Carlo and\ncrystal orbital Hamiltonianindicate that the chemical constitution of cascade\ninduced nano-precipitates is a result of a competition between\ninterstitial/vacancy consumption rate and preferential bond formation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:04:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13747","submitter":"Zheqing Zhu","authors":"Ruiyang Xu, Jalaj Bhandari, Dmytro Korenkevych, Fan Liu, Yuchen He,\n  Alex Nikulkov, Zheqing Zhu","title":"Optimizing Long-term Value for Auction-Based Recommender Systems via\n  On-Policy Reinforcement Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Auction-based recommender systems are prevalent in online advertising\nplatforms, but they are typically optimized to allocate recommendation slots\nbased on immediate expected return metrics, neglecting the downstream effects\nof recommendations on user behavior. In this study, we employ reinforcement\nlearning to optimize for long-term return metrics in an auction-based\nrecommender system. Utilizing temporal difference learning, a fundamental\nreinforcement learning algorithm, we implement an one-step policy improvement\napproach that biases the system towards recommendations with higher long-term\nuser engagement metrics. This optimizes value over long horizons while\nmaintaining compatibility with the auction framework. Our approach is grounded\nin dynamic programming ideas which show that our method provably improves upon\nthe existing auction-based base policy. Through an online A/B test conducted on\nan auction-based recommender system which handles billions of impressions and\nusers daily, we empirically establish that our proposed method outperforms the\ncurrent production system in terms of long-term user engagement metrics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:04:38 GMT"},{"version":"v2","created":"Wed, 24 May 2023 01:04:04 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13748","submitter":"Pavel Koten","authors":"Pavel Koten, Luk\\'a\\v{s} Shrben\\'y, Pavel Spurn\\'y, Ji\\v{r}\\'i\n  Borovi\\v{c}ka, Rostislav \\v{S}tork, Tom\\'a\\v{s} Henych, Vlastimil\n  Voj\\'a\\v{c}ek and Jan M\\'anek","title":"Tau-Herculid meteor shower on night 30/31 May, 2022, and properties of\n  the meteoroids","comments":"17 pages, 16 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  A tau-Herculid meteor outburst or even a storm was predicted by several\nmodels to occur around 5~UT on 31~May, 2022 as a consequence of the break-up of\ncomet 73P/Schwassmann-Wachmann 3 in 1995. The multi-instrument and\nmulti-station experiment was carried-out within the Czech Republic to cover\npossible earlier activity of the shower between 21 and 1 UT on 30/31 May.\nMulti-station observations using video and photographic cameras were used for\ncalculation of the atmospheric trajectories and heliocentric orbits of the\nmeteors. Their arrival times are used for determination of the shower activity\nprofile. Physical properties of the meteoroids are evaluated using various\ncriteria based on meteor heights. Evolution of spectra of three meteors are\nstudied as well. This annual but poor meteor shower was active for the whole\nnight many hours before the predicted peak. A comparison with dynamical models\nshows that a mix of older material ejected after 1900 and fresh particles\noriginating from the 1995 comet fragmentation event was observed. Radiant\npositions of both groups of meteors were identified and found to be in good\nagreement with simulated radiants. Meteoroids with masses between 10 mg and 10\nkg were recorded. The mass distribution index was slightly higher than 2. A\nstudy of the physical properties shows that the tau-Herculid meteoroids belong\nto the most fragile particles observed ever, especially among higher masses of\nmeteoroids. Exceptionally bright bolide observed during the dawn represents a\nchallenge for the dynamical simulations as it is necessary to explain how to\ntransfer a half metre body to the vicinity of the Earth at the same time as\nmillimetre sized particles.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:04:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13749","submitter":"Zihan Wang","authors":"Zihan Wang, Jingbo Shang, Ruiqi Zhong","title":"Goal-Driven Explainable Clustering via Language Descriptions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Unsupervised clustering is widely used to explore large corpora, but existing\nformulations neither consider the users' goals nor explain clusters' meanings.\nWe propose a new task formulation, \"Goal-Driven Clustering with Explanations\"\n(GoalEx), which represents both the goal and the explanations as free-form\nlanguage descriptions. For example, to categorize the errors made by a\nsummarization system, the input to GoalEx is a corpus of annotator-written\ncomments for system-generated summaries and a goal description \"cluster the\ncomments based on why the annotators think the summary is imperfect.''; the\noutputs are text clusters each with an explanation (\"this cluster mentions that\nthe summary misses important context information.\"), which relates to the goal\nand precisely explain which comments should (not) belong to a cluster. To\ntackle GoalEx, we prompt a language model with \"[corpus subset] + [goal] +\nBrainstorm a list of explanations each representing a cluster.\"; then we\nclassify whether each sample belongs to a cluster based on its explanation;\nfinally, we use integer linear programming to select a subset of candidate\nclusters to cover most samples while minimizing overlaps. We apply GoalEx\nhierarchically to produce trees of progressively finer-grained clusters,\ninducing taxonomies over debate arguments, customer complaints, and model\nerrors. We release our data and implementation at\nhttps://github.com/ZihanWangKi/GoalEx.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:05:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13750","submitter":"Yu-Ting Cheng","authors":"Y.-T. Cheng, C.-H. Chien, K.-M. Hsieh, Y.-H. Huang, P. Y. Wen, W.-J.\n  Lin, Y. Lu, F. Aziz, C.-P. Lee, K.-T. Lin, C.-Y. Chen, J. C. Chen, C.-S.\n  Chuu, A. F. Kockum, G.-D. Lin, Y.-H. Lin, and I.-C. Hoi","title":"Tuning atom-field interaction via phase shaping","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A coherent electromagnetic field can be described by its amplitude,\nfrequency, and phase. All these properties can influence the interaction\nbetween the field and an atom. Here we demonstrate the phase shaping of\nmicrowaves that are loaded onto a superconducting artificial atom in a\nsemiinfinite 1D transmission line, a setup corresponding to an atom in front of\na mirror. In particular, we input a weak exponentially rising pulse with phase\nmodulation to the atom-mirror system. We observe that field-atom interaction\ncan be tuned from nearly full interaction (loading efficiency, i.e., amount of\nenergy transferred from the field to the atom, of 94.5 %) to effectively no\ninteraction (loading efficiency 3.5 %).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:06:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13751","submitter":"Linghao Jin","authors":"Linghao Jin, Jacqueline He, Jonathan May, Xuezhe Ma","title":"Challenges in Context-Aware Neural Machine Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Context-aware neural machine translation involves leveraging information\nbeyond sentence-level context to resolve inter-sentential discourse\ndependencies and improve document-level translation quality, and has given rise\nto a number of recent techniques. However, despite well-reasoned intuitions,\nmost context-aware translation models show only modest improvements over\nsentence-level systems. In this work, we investigate several challenges that\nimpede progress within this field, relating to discourse phenomena, context\nusage, model architectures, and document-level evaluation. To address these\nproblems, we propose a more realistic setting for document-level translation,\ncalled paragraph-to-paragraph (para2para) translation, and collect a new\ndataset of Chinese-English novels to promote future research.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:08:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13752","submitter":"Haochen Wang","authors":"Haochen Wang and Yujun Shen and Jingjing Fei and Wei Li and Liwei Wu\n  and Yuxi Wang and Zhaoxiang Zhang","title":"Pulling Target to Source: A New Perspective on Domain Adaptive Semantic\n  Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Domain adaptive semantic segmentation aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. However, existing methods\nprimarily focus on directly learning qualified target features, making it\nchallenging to guarantee their discrimination in the absence of target labels.\nThis work provides a new perspective. We observe that the features learned with\nsource data manage to keep categorically discriminative during training,\nthereby enabling us to implicitly learn adequate target representations by\nsimply \\textbf{pulling target features close to source features for each\ncategory}. To this end, we propose T2S-DA, which we interpret as a form of\npulling Target to Source for Domain Adaptation, encouraging the model in\nlearning similar cross-domain features. Also, considering the pixel categories\nare heavily imbalanced for segmentation datasets, we come up with a dynamic\nre-weighting strategy to help the model concentrate on those underperforming\nclasses. Extensive experiments confirm that T2S-DA learns a more discriminative\nand generalizable representation, significantly surpassing the\nstate-of-the-art. We further show that our method is quite qualified for the\ndomain generalization task, verifying its domain-invariant property.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:09:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13753","submitter":"Tianya Li","authors":"Tianya Li, Yongpeng Wu, Wenjun Zhang, Xiang-Gen Xia, Chengshan Xiao","title":"A Graph-Based Collision Resolution Scheme for Asynchronous Unsourced\n  Random Access","comments":"6 pages, 6 figures, submitted to IEEE GLOBECOM 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper investigates the multiple-input-multiple-output (MIMO) massive\nunsourced random access in an asynchronous orthogonal frequency division\nmultiplexing (OFDM) system, with both timing and frequency offsets (TFO) and\nnon-negligible user collisions. The proposed coding framework splits the data\ninto two parts encoded by sparse regression code (SPARC) and low-density parity\ncheck (LDPC) code. Multistage orthogonal pilots are transmitted in the first\npart to reduce collision density. Unlike existing schemes requiring a\nquantization codebook with a large size for estimating TFO, we establish a\n\\textit{graph-based channel reconstruction and collision resolution\n(GB-CR$^2$)} algorithm to iteratively reconstruct channels, resolve collisions,\nand compensate for TFO rotations on the formulated graph jointly among multiple\nstages. We further propose to leverage the geometric characteristics of signal\nconstellations to correct TFO estimations. Exhaustive simulations demonstrate\nremarkable performance superiority in channel estimation and data recovery with\nsubstantial complexity reduction compared to state-of-the-art schemes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:09:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13754","submitter":"Taichi Kato","authors":"Taichi Kato (Kyoto U)","title":"Long-lasting high state of the high-field polar AR UMa","comments":"8 pages, 4 figures, VSOLJ Variable Star Bulletin No. 119","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Using ASAS-SN Sky Patrol Photometic Database and Asteroid Terrestrial-impact\nLast Alert System (ATLAS) data, I found that the high-field polar AR UMa\nentered a long-lasting high state in 2022 October. This object is renowned for\nits small duty cycle, and short-lived high states have only been occasionally\nseen since the discovery. It appears that the present long-lasting high state\nis the first recorded one at least in the last 30 years and probably even more.\nBefore entering the current long-lasting high state, this object showed three\nshort-lived high states, which might have been precursors to the current state.\nBefore these short-lived high states, the object had been in a low state for 8\nyears and probably more. I refined the orbital period to be 0.08050066(1) d.\nThe object is still bright and current phenomenon provides a unique opportunity\nto study accretion processes onto a strongly magnetized white dwarf and to\nstudy the mechanism of maintaining the long-lasting high state.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:12:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13755","submitter":"Feng Jiang","authors":"Feng Jiang, Longwang He, Peifeng Li, Qiaoming Zhu, Haizhou Li","title":"Topic-driven Distant Supervision Framework for Macro-level Discourse\n  Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Discourse parsing, the task of analyzing the internal rhetorical structure of\ntexts, is a challenging problem in natural language processing. Despite the\nrecent advances in neural models, the lack of large-scale, high-quality corpora\nfor training remains a major obstacle. Recent studies have attempted to\novercome this limitation by using distant supervision, which utilizes results\nfrom other NLP tasks (e.g., sentiment polarity, attention matrix, and\nsegmentation probability) to parse discourse trees. However, these methods do\nnot take into account the differences between in-domain and out-of-domain\ntasks, resulting in lower performance and inability to leverage the\nhigh-quality in-domain data for further improvement. To address these issues,\nwe propose a distant supervision framework that leverages the relations between\ntopic structure and rhetorical structure. Specifically, we propose two\ndistantly supervised methods, based on transfer learning and the\nteacher-student model, that narrow the gap between in-domain and out-of-domain\ntasks through label mapping and oracle annotation. Experimental results on the\nMCDTB and RST-DT datasets show that our methods achieve the best performance in\nboth distant-supervised and supervised scenarios.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:13:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13756","submitter":"Bach Kim","authors":"Bach Kim, Jose Dolz, Pierre-Marc Jodoin, Christian Desrosiers","title":"Mixup-Privacy: A simple yet effective approach for privacy-preserving\n  segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Privacy protection in medical data is a legitimate obstacle for centralized\nmachine learning applications. Here, we propose a client-server image\nsegmentation system which allows for the analysis of multi-centric medical\nimages while preserving patient privacy. In this approach, the client protects\nthe to-be-segmented patient image by mixing it to a reference image. As shown\nin our work, it is challenging to separate the image mixture to exact original\ncontent, thus making the data unworkable and unrecognizable for an unauthorized\nperson. This proxy image is sent to a server for processing. The server then\nreturns the mixture of segmentation maps, which the client can revert to a\ncorrect target segmentation. Our system has two components: 1) a segmentation\nnetwork on the server side which processes the image mixture, and 2) a\nsegmentation unmixing network which recovers the correct segmentation map from\nthe segmentation mixture. Furthermore, the whole system is trained end-to-end.\nThe proposed method is validated on the task of MRI brain segmentation using\nimages from two different datasets. Results show that the segmentation accuracy\nof our method is comparable to a system trained on raw images, and outperforms\nother privacy-preserving methods with little computational overhead.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:14:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13757","submitter":"Simon Tarboush","authors":"Simon Tarboush, Anum Ali, Tareq Y. Al-Naffouri","title":"Cross-Field Channel Estimation for Ultra Massive-MIMO THz Systems","comments":"30 pages, 7 pages, journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The large bandwidth combined with ultra-massive multiple-input\nmultiple-output (UM-MIMO) arrays enables terahertz (THz) systems to achieve\nterabits-per-second throughput. The THz systems are expected to operate in the\nnear, intermediate, as well as the far-field. As such, channel estimation\nstrategies suitable for the near, intermediate, or far-field have been\nintroduced in the literature. In this work, we propose a cross-field, i.e.,\nable to operate in near, intermediate, and far-field, compressive channel\nestimation strategy. For an array-of-subarrays (AoSA) architecture, the\nproposed method compares the received signals across the arrays to determine\nwhether a near, intermediate, or far-field channel estimation approach will be\nappropriate. Subsequently, compressed estimation is performed in which the\nproximity of multiple subarrays (SAs) at the transmitter and receiver is\nexploited to reduce computational complexity and increase estimation accuracy.\nNumerical results show that the proposed method can enhance channel estimation\naccuracy and complexity at all distances of interest.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:17:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13758","submitter":"Hyemi Kim","authors":"Hyemi Kim, Jiyun Park, Taegyun Kwon, Dasaem Jeong, Juhan Nam","title":"A study of audio mixing methods for piano transcription in violin-piano\n  ensembles","comments":"To Appear IEEE ICASSP 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  While piano music transcription models have shown high performance for solo\npiano recordings, their performance degrades when applied to ensemble\nrecordings. This study aims to analyze the impact of different data\naugmentation methods on piano transcription performance, specifically focusing\non mixing techniques applied to violin-piano ensembles. We apply mixing methods\nthat consider both harmonic and temporal characteristics of the audio. To\ncreate datasets for this study, we generated the PFVN-synth dataset, which\ncontains 7 hours of violin-piano ensemble audio by rendering MIDI files and\ncorresponding labels, and also collected unaccompanied violin recordings and\nmixed them with the MAESTRO dataset. We evaluated the transcription results on\nboth synthesized and real audio recordings datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:19:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13759","submitter":"Tobias Buck","authors":"Tobias Buck, Aura Obreja, Bridget Ratcliffe, Yuxi (Lucy) Lu, Ivan\n  Minchev, Andrea V. Macci\\`o","title":"The impact of early massive mergers on the chemical evolution of Milky\n  Way-like galaxies: insights from NIHAO-UHD simulations","comments":"13 pages, 10 figures, accepted by MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1503","report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent observations of the Milky Way (MW) found an unexpected steepening of\nthe star-forming gas metallicity gradient around the time of the\nGaia-Sausage-Enceladus (GSE) merger event. Here we investigate the influence of\nearly ($t_{\\mathrm{merger}}\\lesssim5$ Gyr) massive\n($M_{\\mathrm{gas}}^{\\mathrm{merger}}/M_{\\mathrm{gas}}^{\\mathrm{main}}(t_{\\mathrm{merger}})\\gtrsim10\\%$)\nmerger events such as the Gaia-Sausage Enceladus merger in the MW on the\nevolution of the cold gas metallicity gradient. We use the NIHAO-UHD suite of\ncosmological hydrodynamical simulations of MW-mass galaxies to study the\nfrequency of massive early mergers and their detailed impact on the morphology\nand chemistry of the gaseous disks. We find a strong steepening of the\nmetallicity gradient at early times for all four galaxies in our sample which\nis caused by a sudden increase in the cold gas disk size (up to a factor of 2)\nin combination with the supply of un-enriched gas ($\\sim0.75$ dex lower\ncompared to the main galaxy) by the merging dwarf galaxies. The mergers mostly\naffect the galaxy outskirts and lead to an increase in cold gas surface density\nof up to 200% outside of $\\sim8$ kpc. The addition of un-enriched gas breaks\nthe self-similar enrichment of the inter-stellar-medium and causes a dilution\nof the cold gas in the outskirts of the galaxies. The accreted stars and the\nones formed later out of the accreted gas inhabit distinct tracks offset to\nlower [$\\alpha$/Fe] and [Fe/H] values compared to the main galaxy's stars. We\nfind that such mergers can contribute significantly to the formation of a\nsecond, low-$\\alpha$ sequence as is observed in the MW.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:22:48 GMT"},{"version":"v2","created":"Fri, 26 May 2023 12:18:51 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13760","submitter":"Krzysztof Piasecki","authors":"K. Piasecki, P. Piotrowski","title":"Systematics of yields of strange hadrons from heavy-ion collisions\n  around threshold energies","comments":"22 pages, 4 figures, 8 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-ex","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The parametrizations of experimental yields of K$^{\\pm,0}$, $\\phi$ and\n$\\Lambda+\\Sigma^0$ are proposed as function of available energy,\n$\\sqrt{s_\\mathrm{NN}}$, and number of participants, $\\langle A_\\mathrm{part}\n\\rangle_\\mathrm{b}$, for $\\sqrt{s_\\mathrm{NN}}$ from 2.15 to 3 GeV. For all the\ndataset the $\\langle A_\\mathrm{part} \\rangle_\\mathrm{b}$ was extracted using\nthe Glauber Monte Carlo method. The $\\alpha$ exponent of yield dependency on\n$\\langle A_\\mathrm{part} \\rangle_\\mathrm{b}$ appears not to change with beam\nenergy and is found to be 1.30 $\\pm$ 0.02. Our parametrization and the\npredictions of public versions of RQMD.RMF, SMASH and UrQMD transport models\nare compared to the HADES experimental data for Ar+KCl at\n$\\sqrt{s_\\mathrm{NN}}$ of 2.61 GeV. The phenomenological parametrization\ncurrently offers the best overall description of these yields. Predictions are\ngiven for yields from Ag+Ag collisions at available energies of 2.41 and 2.55\nGeV, analysed by HADES, Au+Au experiment at 2.16 and 2.24 GeV planned by this\ncollaboration, some unpublished yields for STAR's Au+Au collisions at 3 GeV,\nand for Au+Au collisions planned by CBM, up to 3.85 GeV.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:25:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13761","submitter":"Salih Kibaro\\u{g}lu","authors":"Salih Kibaro\\u{g}lu","title":"Modified Friedmann Equations from Maxwell-Weyl Gauge Theory","comments":"14 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study investigates the possibility of a homogeneous and isotropic\ncosmological solution within the context of the Maxwell-Weyl gauge theory of\ngravity. To achieve this, we utilize the Einstein-Yang-Mills theory as an\nanalogy and represent the Maxwell gauge field in terms of two time-dependent\nscalar fields. Then, we present the modified Friedmann equations, which\nincorporate the contributions of the Maxwell gauge field, as well as the\neffective cosmological constant, which is a function of the Dirac scalar field.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:25:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13762","submitter":"Narayan Anirudh Palutla","authors":"Anirudh Palutla, Shivansh Seth, S.S. Ashwin, Marimuthu Krishnan","title":"Phase ordering in the near-critical regime of the Alzheimer's and normal\n  brain","comments":"Anirudh Palutla and Shivansh Seth contributed equally to this work","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cond-mat.dis-nn","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Criticality is an emergent phenomenon observed during second-order phase\ntransitions. The brain is increasingly seen as a complex system that operates\nnear criticality, where complex systems exhibit high correlations. When\napproaching criticality, a system shows `domain'-like regions with competing\nphases and increased spatiotemporal correlations that tend to diverge. The\ndynamics of these domains depend on the system's proximity to criticality. By\nmapping fMRI signals from the brain to a spin-lattice model, we can study\nbrain's critical behavior. However, the extent to which the normal and\nAlzheimer's brain exhibit distinct critical ordering based on their proximity\nto criticality remains unclear. In this study, we investigate the domain\nproperties of the spin-lattice model derived from the Alzheimer's and\ncognitively normal subjects.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:25:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13763","submitter":"Anoop Singh","authors":"Mainak Poddar and Anoop Singh","title":"Relative connections on Principal bundles and relative equivariant\n  structures","comments":"17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate relative holomorphic connections on a principal bundle over a\nfamily of compact complex manifolds. A sufficient condition is given for the\nexistence of a relative holomorphic connection on a holomorphic principal\nbundle over a complex analytic family. We also introduce the notion of relative\nequivariant bundles and establish its relation with relative holomorphic\nconnections on principal bundles.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:27:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13764","submitter":"Julian Lienen","authors":"Julian Lienen, Eyke H\\\"ullermeier","title":"Mitigating Label Noise through Data Ambiguation","comments":"20 pages, 9 figures, 11 tables, paper incl. appendix","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Label noise poses an important challenge in machine learning, especially in\ndeep learning, in which large models with high expressive power dominate the\nfield. Models of that kind are prone to memorizing incorrect labels, thereby\nharming generalization performance. Many methods have been proposed to address\nthis problem, including robust loss functions and more complex label correction\napproaches. Robust loss functions are appealing due to their simplicity, but\ntypically lack flexibility, while label correction usually adds substantial\ncomplexity to the training setup. In this paper, we suggest to address the\nshortcomings of both methodologies by \"ambiguating\" the target information,\nadding additional, complementary candidate labels in case the learner is not\nsufficiently convinced of the observed training label. More precisely, we\nleverage the framework of so-called superset learning to construct set-valued\ntargets based on a confidence threshold, which deliver imprecise yet more\nreliable beliefs about the ground-truth, effectively helping the learner to\nsuppress the memorization effect. In an extensive empirical evaluation, our\nmethod demonstrates favorable learning behavior on synthetic and real-world\nnoise, confirming the effectiveness in detecting and correcting erroneous\ntraining labels.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:29:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13765","submitter":"Wasiq Khan Dr","authors":"Luke K. Topham, Wasiq Khan, Dhiya Al-Jumeily, Abir Hussain","title":"Human Body Pose Estimation for Gait Identification: A Comprehensive\n  Survey of Datasets and Models","comments":null,"journal-ref":null,"doi":"10.1145/3533384","report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Person identification is a problem that has received substantial attention,\nparticularly in security domains. Gait recognition is one of the most\nconvenient approaches enabling person identification at a distance without the\nneed of high-quality images. There are several review studies addressing person\nidentification such as the utilization of facial images, silhouette images, and\nwearable sensor. Despite skeleton-based person identification gaining\npopularity while overcoming the challenges of traditional approaches, existing\nsurvey studies lack the comprehensive review of skeleton-based approaches to\ngait identification. We present a detailed review of the human pose estimation\nand gait analysis that make the skeleton-based approaches possible. The study\ncovers various types of related datasets, tools, methodologies, and evaluation\nmetrics with associated challenges, limitations, and application domains.\nDetailed comparisons are presented for each of these aspects with\nrecommendations for potential research and alternatives. A common trend\nthroughout this paper is the positive impact that deep learning techniques are\nbeginning to have on topics such as human pose estimation and gait\nidentification. The survey outcomes might be useful for the related research\ncommunity and other stakeholders in terms of performance analysis of existing\nmethodologies, potential research gaps, application domains, and possible\ncontributions in the future.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:30:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13766","submitter":"Paul Ruet","authors":"\\'Elisabeth Remy, Paul Ruet","title":"From multivalued to Boolean functions: preservation of soft nested\n  canalization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Nested canalization (NC) is a property of Boolean functions which has been\nrecently extended to multivalued functions. We study the effect of the Van Ham\nmapping (from multivalued to Boolean functions) on this property. We introduce\nthe class of softly nested canalizing (SNC) multivalued functions, and prove\nthat the Van Ham mapping sends SNC multivalued functions to NC Boolean\nfunctions. Since NC multivalued functions are SNC, this preservation property\nholds for NC multivalued functions as well. We also study the relevance of SNC\nfunctions in the context of gene regulatory network modelling.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:30:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13767","submitter":"Yuki Wakata","authors":"Yuki Wakata, Xiaoliang Chen, Ning Zhu, Sijia Lyu, Xing Chao, Chao Sun","title":"How roughness and thermal properties of a solid substrate determine the\n  Leidenfrost temperature: Experiments and a model","comments":"6 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this Letter, we systematically investigate the Leidenfrost temperature for\nhot solid substrates with various thermal diffusivities and surface\nroughnesses. Based on the experimental results, we build a phenomenological\nmodel that considers the thermal diffusivity of a solid substrate and derive a\nrelationship between the surface roughness and the resulting vapor film\nthickness. The generality of this model is supported by experimental data for\ndifferent liquids and solid substrates. Our model thus allows for a theoretical\nprediction of the Leidenfrost temperature and develops a comprehensive\nunderstanding of the Leidenfrost effect.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:31:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13768","submitter":"Edouard Pauwels","authors":"J\\'er\\^ome Bolte, Edouard Pauwels, Samuel Vaiter","title":"One-step differentiation of iterative algorithms","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In appropriate frameworks, automatic differentiation is transparent to the\nuser at the cost of being a significant computational burden when the number of\noperations is large. For iterative algorithms, implicit differentiation\nalleviates this issue but requires custom implementation of Jacobian\nevaluation. In this paper, we study one-step differentiation, also known as\nJacobian-free backpropagation, a method as easy as automatic differentiation\nand as performant as implicit differentiation for fast algorithms (e.g.,\nsuperlinear optimization methods). We provide a complete theoretical\napproximation analysis with specific examples (Newton's method, gradient\ndescent) along with its consequences in bilevel optimization. Several numerical\nexamples illustrate the well-foundness of the one-step estimator.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:32:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13769","submitter":"Niccol\\`o Di Marco","authors":"Shayan Alipour, Niccol\\`o Di Marco, Michele Avalle, Gabriele Etta,\n  Matteo Cinelli and Walter Quattrociocchi","title":"The Drivers of Global News Spreading Patterns","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI physics.soc-ph","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The web radically changed the dissemination of information and the global\nspread of news. In this study, we aim to reconstruct the connectivity patterns\nwithin nations shaping news propagation globally in 2022. We do this by\nanalyzing a dataset of unprecedented size, containing 140 million news articles\nfrom 183 countries and related to 37,802 domains in the GDELT database. Unlike\nprevious research, we focus on the sequential mention of events across various\ncountries, thus incorporating a temporal dimension into the analysis of news\ndissemination networks. Our results show a significant imbalance in online news\nspreading. We identify news superspreaders forming a tightly interconnected\nrich club, exerting significant influence on the global news agenda. To further\ninvestigate the mechanisms underlying news dissemination and the shaping of\nglobal public opinion, we model countries' interactions using a gravity model,\nincorporating economic, geographical, and cultural factors. Consistent with\nprevious studies, we find that countries' GDP is one of the main drivers to\nshape the worldwide news agenda.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:34:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13770","submitter":"Yuekun Dai","authors":"Yuekun Dai, Chongyi Li, Shangchen Zhou, Ruicheng Feng, Qingpeng Zhu,\n  Qianhui Sun, Wenxiu Sun, Chen Change Loy, Jinwei Gu","title":"MIPI 2023 Challenge on Nighttime Flare Removal: Methods and Results","comments":"CVPR 2023 Mobile Intelligent Photography and Imaging (MIPI)\n  Workshop--Nighttime Flare Removal Challenge Report. Website:\n  https://mipi-challenge.org/MIPI2023/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Developing and integrating advanced image sensors with novel algorithms in\ncamera systems are prevalent with the increasing demand for computational\nphotography and imaging on mobile platforms. However, the lack of high-quality\ndata for research and the rare opportunity for in-depth exchange of views from\nindustry and academia constrain the development of mobile intelligent\nphotography and imaging (MIPI). With the success of the 1st MIPI Workshop@ECCV\n2022, we introduce the second MIPI challenge including four tracks focusing on\nnovel image sensors and imaging algorithms. In this paper, we summarize and\nreview the Nighttime Flare Removal track on MIPI 2023. In total, 120\nparticipants were successfully registered, and 11 teams submitted results in\nthe final testing phase. The developed solutions in this challenge achieved\nstate-of-the-art performance on Nighttime Flare Removal. A detailed description\nof all models developed in this challenge is provided in this paper. More\ndetails of this challenge and the link to the dataset can be found at\nhttps://mipi-challenge.org/MIPI2023/ .\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:34:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13771","submitter":"Mariusz Tarnopolski","authors":"Anatoliy Tugay and Mariusz Tarnopolski","title":"Continuous Filament Network of the Local Universe","comments":"18 pages, 10 figures; catalog provided as ancillary file; accepted in\n  ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Simulated galaxy distributions are suitable for developing filament detection\nalgorithms. However, samples of observed galaxies, being of limited size, cause\ndifficulties that lead to a discontinuous distribution of filaments. We created\na new galaxy filament catalog composed of a continuous cosmic web with no lone\nfilaments. The core of our approach is a ridge filter used within the framework\nof image analysis. We considered galaxies from the HyperLeda database with\nredshifts $0.02\\leqslant z\\leqslant 0.1$, and in the solid angle\n$120^\\circ\\leqslant {\\rm RA}\\leqslant 240^\\circ$, $0^\\circ\\leqslant {\\rm\nDEC}\\leqslant 60^\\circ$. We divided the sample into 16 two-dimensional\ncelestial projections with redshift bin $\\Delta z=0.005$, and compared our\ncontinuous filament network with a similar recent catalog covering the same\nregion of the sky. We tested our catalog on two application scenarios. First,\nwe compared the distributions of distance to nearest filament of various\nastrophysical sources (Seyfert galaxies and other active galactic nuclei, radio\ngalaxies, low surface brightness galaxies, and dwarf galaxies), and found that\nall source types trace the filaments well, with no systematic differences.\nNext, among the HyperLeda galaxies, we investigated the dependence of $g-r$\ncolor distribution on distance to nearest filament, and confirmed that early\ntype galaxies are located on average further from the filaments than late type\nones.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:38:29 GMT"},{"version":"v2","created":"Sun, 28 May 2023 15:40:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13772","submitter":"Bernhard Maschke","authors":"Bernhard Maschke, Arjan van der Schaft","title":"Linear Boundary Port-Hamiltonian Systems with Implicitly Defined Energy","comments":"23 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we extend the previously introduced class of boundary\nport-Hamiltonian systems to boundary control systems where the variational\nderivative of the Hamiltonian functional is replaced by a pair of reciprocal\ndifferential operators. In physical systems modelling, these differential\noperators naturally represent the constitutive relations associated with the\nimplicitly defined energy of the system and obey Maxwell's reciprocity\nconditions. On top of the boundary variables associated with the Stokes-Dirac\nstructure, this leads to additional boundary port variables and to the new\nnotion of a Stokes-Lagrange subspace. This extended class of boundary\nport-Hamiltonian systems is illustrated by a number of examples in the\nmodelling of elastic rods with local and non-local elasticity relations.\nFinally it shown how a Hamiltonian functional on an extended state space can be\nassociated with the Stokes-Lagrange subspace, and how this leads to an energy\nbalance equation involving the boundary variables of the Stokes-Dirac structure\nas well as of the Stokes-Lagrange subspace.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:40:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13773","submitter":"Dong Wei","authors":"Dong Wei, Xiaoning Sun, Huaijiang Sun, Bin Li, Shengxiang Hu, Weiqing\n  Li, Jianfeng Lu","title":"Understanding Text-driven Motion Synthesis with Keyframe Collaboration\n  via Diffusion Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The emergence of text-driven motion synthesis technique provides animators\nwith great potential to create efficiently. However, in most cases, textual\nexpressions only contain general and qualitative motion descriptions, while\nlack fine depiction and sufficient intensity, leading to the synthesized\nmotions that either (a) semantically compliant but uncontrollable over specific\npose details, or (b) even deviates from the provided descriptions, bringing\nanimators with undesired cases. In this paper, we propose DiffKFC, a\nconditional diffusion model for text-driven motion synthesis with keyframes\ncollaborated. Different from plain text-driven designs, full interaction among\ntexts, keyframes and the rest diffused frames are conducted at training,\nenabling realistic generation under efficient, collaborative dual-level\ncontrol: coarse guidance at semantic level, with only few keyframes for direct\nand fine-grained depiction down to body posture level, to satisfy animator\nrequirements without tedious labor. Specifically, we customize efficient\nDilated Mask Attention modules, where only partial valid tokens participate in\nlocal-to-global attention, indicated by the dilated keyframe mask. For user\nflexibility, DiffKFC supports adjustment on importance of fine-grained keyframe\ncontrol. Experimental results show that our model achieves state-of-the-art\nperformance on text-to-motion datasets HumanML3D and KIT.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:41:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13774","submitter":"Yan Zhao","authors":"Jiangyan Yi, Jianhua Tao, Ruibo Fu, Xinrui Yan, Chenglong Wang, Tao\n  Wang, Chu Yuan Zhang, Xiaohui Zhang, Yan Zhao, Yong Ren, Le Xu, Junzuo Zhou,\n  Hao Gu, Zhengqi Wen, Shan Liang, Zheng Lian, Shuai Nie, Haizhou Li","title":"ADD 2023: the Second Audio Deepfake Detection Challenge","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Audio deepfake detection is an emerging topic in the artificial intelligence\ncommunity. The second Audio Deepfake Detection Challenge (ADD 2023) aims to\nspur researchers around the world to build new innovative technologies that can\nfurther accelerate and foster research on detecting and analyzing deepfake\nspeech utterances. Different from previous challenges (e.g. ADD 2022), ADD 2023\nfocuses on surpassing the constraints of binary real/fake classification, and\nactually localizing the manipulated intervals in a partially fake speech as\nwell as pinpointing the source responsible for generating any fake audio.\nFurthermore, ADD 2023 includes more rounds of evaluation for the fake audio\ngame sub-challenge. The ADD 2023 challenge includes three subchallenges: audio\nfake game (FG), manipulation region location (RL) and deepfake algorithm\nrecognition (AR). This paper describes the datasets, evaluation metrics, and\nprotocols. Some findings are also reported in audio deepfake detection tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:42:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13775","submitter":"Michal \\v{S}tef\\'anik","authors":"Michal \\v{S}tef\\'anik and Marek Kadl\\v{c}\\'ik","title":"Concept-aware Training Improves In-context Learning Ability of Language\n  Models","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many recent language models (LMs) of Transformers family exhibit so-called\nin-context learning (ICL) ability, manifested in the LMs' ability to modulate\ntheir function by a task described in a natural language input. Previous work\ncurating these models assumes that ICL emerges from vast over-parametrization\nor the scale of multi-task training. However, a complementary branch of recent\ntheoretical work attributes ICL emergence to specific properties of training\ndata and creates functional in-context learners in small-scale, synthetic\nsettings.\n  Inspired by recent findings on data properties driving the emergence of ICL,\nwe propose a method to create LMs able to better utilize the in-context\ninformation, by constructing training scenarios where it is beneficial for the\nLM to capture the analogical reasoning concepts. We measure that data sampling\nof Concept-aware Training (CoAT) consistently improves models' reasoning\nability. As a result, the in-context learners trained with CoAT on only two\ndatasets of a single (QA) task perform comparably to larger models trained on\n1600+ tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:44:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13776","submitter":"Rishabh Gupta","authors":"Rishabh Gupta, Shaily Desai, Manvi Goel, Anil Bandhakavi, Tanmoy\n  Chakraborty and Md. Shad Akhtar","title":"Counterspeeches up my sleeve! Intent Distribution Learning and\n  Persistent Fusion for Intent-Conditioned Counterspeech Generation","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Counterspeech has been demonstrated to be an efficacious approach for\ncombating hate speech. While various conventional and controlled approaches\nhave been studied in recent years to generate counterspeech, a counterspeech\nwith a certain intent may not be sufficient in every scenario. Due to the\ncomplex and multifaceted nature of hate speech, utilizing multiple forms of\ncounter-narratives with varying intents may be advantageous in different\ncircumstances. In this paper, we explore intent-conditioned counterspeech\ngeneration. At first, we develop IntentCONAN, a diversified intent-specific\ncounterspeech dataset with 6831 counterspeeches conditioned on five intents,\ni.e., informative, denouncing, question, positive, and humour. Subsequently, we\npropose QUARC, a two-stage framework for intent-conditioned counterspeech\ngeneration. QUARC leverages vector-quantized representations learned for each\nintent category along with PerFuMe, a novel fusion module to incorporate\nintent-specific information into the model. Our evaluation demonstrates that\nQUARC outperforms several baselines by an average of 10% across evaluation\nmetrics. An extensive human evaluation supplements our hypothesis of better and\nmore appropriate responses than comparative systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:45:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13777","submitter":"Jinheng Xie","authors":"Jinheng Xie, Kai Ye, Yudong Li, Yuexiang Li, Kevin Qinghong Lin,\n  Yefeng Zheng, Linlin Shen, Mike Zheng Shou","title":"VisorGPT: Learning Visual Prior via Generative Pre-Training","comments":"Project web-page: https://sierkinhane.github.io/visor-gpt/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Various stuff and things in visual data possess specific traits, which can be\nlearned by deep neural networks and are implicitly represented as the visual\nprior, e.g., object location and shape, in the model. Such prior potentially\nimpacts many vision tasks. For example, in conditional image synthesis, spatial\nconditions failing to adhere to the prior can result in visually inaccurate\nsynthetic results. This work aims to explicitly learn the visual prior and\nenable the customization of sampling. Inspired by advances in language\nmodeling, we propose to learn Visual prior via Generative Pre-Training, dubbed\nVisorGPT. By discretizing visual locations of objects, e.g., bounding boxes,\nhuman pose, and instance masks, into sequences, VisorGPT can model visual prior\nthrough likelihood maximization. Besides, prompt engineering is investigated to\nunify various visual locations and enable customized sampling of sequential\noutputs from the learned prior. Experimental results demonstrate that VisorGPT\ncan effectively model the visual prior, which can be employed for many vision\ntasks, such as customizing accurate human pose for conditional image synthesis\nmodels like ControlNet. Code will be released at\nhttps://github.com/Sierkinhane/VisorGPT.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:45:23 GMT"},{"version":"v2","created":"Wed, 24 May 2023 07:18:13 GMT"},{"version":"v3","created":"Sun, 28 May 2023 11:34:43 GMT"},{"version":"v4","created":"Tue, 30 May 2023 15:12:41 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13778","submitter":"Jianing Li","authors":"Jianing Li and Bowen Chen and Zhiyong Wang and Honghai Liu","title":"Full Resolution Repetition Counting","comments":"12 pages and 4 figures and 17 conferences","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Given an untrimmed video, repetitive actions counting aims to estimate the\nnumber of repetitions of class-agnostic actions. To handle the various length\nof videos and repetitive actions, also optimization challenges in end-to-end\nvideo model training, down-sampling is commonly utilized in recent\nstate-of-the-art methods, leading to ignorance of several repetitive samples.\nIn this paper, we attempt to understand repetitive actions from a full temporal\nresolution view, by combining offline feature extraction and temporal\nconvolution networks. The former step enables us to train repetition counting\nnetwork without down-sampling while preserving all repetition regardless of the\nvideo length and action frequency, and the later network models all frames in a\nflexible and dynamically expanding temporal receptive field to retrieve all\nrepetitions with a global aspect. We experimentally demonstrate that our method\nachieves better or comparable performance in three public datasets, i.e.,\nTransRAC, UCFRep and QUVA. We expect this work will encourage our community to\nthink about the importance of full temporal resolution.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:45:56 GMT"},{"version":"v2","created":"Wed, 24 May 2023 10:52:44 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13779","submitter":"Sooyeob Jung","authors":"Sooyeob Jung, Seongah Jeong, Jinkyu Kang, Joon Gyu Ryu, and Joonhyuk\n  Kang","title":"Transceiver Design and Performance Analysis for LR-FHSS-based\n  Direct-to-Satellite IoT","comments":"5 pages, 6 figures","journal-ref":null,"doi":null,"report-no":"CL2023-1147","categories":"cs.AR eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a novel transceiver design aimed at enabling\nDirect-to-Satellite Internet of Things (DtS-IoT) systems based on long\nrange-frequency hopping spread spectrum (LR-FHSS). Our focus lies in developing\nan accurate transmission method through the analysis of the frame structure and\nkey parameters outlined in Long Range Wide-Area Network (LoRaWAN) [1]. To\naddress the Doppler effect in DtS-IoT networks and simultaneously receive\nnumerous frequency hopping signals, a robust signal detector for the receiver\nis proposed. We verify the performance of the proposed LR-FHSS transceiver\ndesign through simulations conducted in a realistic satellite channel\nenvironment, assessing metrics such as miss detection probability and packet\nerror probability.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:46:19 GMT"},{"version":"v2","created":"Fri, 26 May 2023 02:04:32 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.13780","submitter":"Lisa Barsotti","authors":"Chris Whittle, Ge Yang, Matthew Evans, Lisa Barsotti","title":"Machine Learning for Quantum-Enhanced Gravitational-Wave Observatories","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM gr-qc quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Machine learning has become an effective tool for processing the extensive\ndata sets produced by large physics experiments. Gravitational-wave detectors\nare now listening to the universe with quantum-enhanced sensitivity,\naccomplished with the injection of squeezed vacuum states. Squeezed state\npreparation and injection is operationally complicated, as well as highly\nsensitive to environmental fluctuations and variations in the interferometer\nstate. Achieving and maintaining optimal squeezing levels is a challenging\nproblem and will require development of new techniques to reach the lofty\ntargets set by design goals for future observing runs and next-generation\ndetectors. We use machine learning techniques to predict the squeezing level\nduring the third observing run of the Laser Interferometer Gravitational-Wave\nObservatory (LIGO) based on auxiliary data streams, and offer interpretations\nof our models to identify and quantify salient sources of squeezing\ndegradation. The development of these techniques lays the groundwork for future\nefforts to optimize squeezed state injection in gravitational-wave detectors,\nwith the goal of enabling closed-loop control of the squeezer subsystem by an\nagent based on machine learning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:47:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13781","submitter":"Waleed Esmail","authors":"W. Esmail, A. Hammad and S. Moretti","title":"Sharpening the $A\\to Z^{(*)}h $ Signature of the Type-II 2HDM at the LHC\n  through Advanced Machine Learning","comments":"35 pages, 22 figures, 2 tables, figure 22 updated, typos correction","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The $A\\to Z^{(*)}h$ decay signature has been highlighted as possibly being\nthe first testable probe of the Standard Model (SM) Higgs boson discovered in\n2012 ($h$) interacting with Higgs companion states, such as those existing in a\n2-Higgs Doublet Model (2HDM), chiefly, a CP-odd one ($A$). The production\nmechanism of the latter at the Large Hadron Collider (LHC) takes place via\n$b\\bar b$-annihilation and/or $gg$-fusion, depending on the 2HDM parameters, in\nturn dictated by the Yukawa structure of this Beyond the SM (BSM) scenario.\nAmong the possible incarnations of the 2HDM, we test here the so-called\nType-II, for a twofold reason. On the one hand, it intriguingly offers two very\ndistinct parameter regions compliant with the SM-like Higgs measurements, i.e.,\nwhere the so-called `SM limit' of the 2HDM can be achieved. On the other hand,\nin both configurations, the $AZh$ coupling is generally small, hence the signal\nis strongly polluted by backgrounds, so that the exploitation of Machine\nLearning (ML) techniques becomes extremely useful. Ours approach in this\nrespect is a three-prong one. Firstly, we adjust ML models to analyze all\npossible High Energy Physics (HEP) data types, so as to maximize the amount of\ninput information. Secondly, unlike most `black-box' ML approaches currently in\nuse in the HEP community, we exploit a (linear) Centered Kernel Alignment (CKA)\nsimilarity metric to analyze the learned representations in the hidden layers,\nthereby enabling an interpretative element of our results. Thirdly, we\nemphasise that the proposed ML models are generic and can thus be adopted in\nother physics problems. Concerning the one at hand, by using such advanced ML\nimplementations, we ultimately show that the sensitivity of LHC searches in the\n$l^+l^- b\\bar b$ ($l=e,\\mu$) final state can significantly be improved with\nrespect to traditional cut-and-count analyses and/or, etc\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:50:27 GMT"},{"version":"v2","created":"Wed, 31 May 2023 11:46:26 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13782","submitter":"Sherzod Hakimov","authors":"Sherzod Hakimov, David Schlangen","title":"Images in Language Space: Exploring the Suitability of Large Language\n  Models for Vision & Language Tasks","comments":"Accepted at ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Large language models have demonstrated robust performance on various\nlanguage tasks using zero-shot or few-shot learning paradigms. While being\nactively researched, multimodal models that can additionally handle images as\ninput have yet to catch up in size and generality with language-only models. In\nthis work, we ask whether language-only models can be utilised for tasks that\nrequire visual input -- but also, as we argue, often require a strong reasoning\ncomponent. Similar to some recent related work, we make visual information\naccessible to the language model using separate verbalisation models.\nSpecifically, we investigate the performance of open-source, open-access\nlanguage models against GPT-3 on five vision-language tasks when given\ntextually-encoded visual information. Our results suggest that language models\nare effective for solving vision-language tasks even with limited samples. This\napproach also enhances the interpretability of a model's output by providing a\nmeans of tracing the output back through the verbalised image content.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:50:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13783","submitter":"Guoming Huang","authors":"Guoming Huang, Xiaofang Yuan, Zhixian Liu, Weihua Tan, Xiru Wu, Yaonan\n  Wang","title":"Deep Reinforcement Learning-based Multi-objective Path Planning on the\n  Off-road Terrain Environment for Ground Vehicles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Due to the energy-consumption efficiency between up-slope and down-slope is\nhugely different, a path with the shortest length on a complex off-road terrain\nenvironment (2.5D map) is not always the path with the least energy\nconsumption. For any energy-sensitive vehicles, realizing a good trade-off\nbetween distance and energy consumption on 2.5D path planning is significantly\nmeaningful. In this paper, a deep reinforcement learning-based 2.5D\nmulti-objective path planning method (DMOP) is proposed. The DMOP can\nefficiently find the desired path with three steps: (1) Transform the\nhigh-resolution 2.5D map into a small-size map. (2) Use a trained deep Q\nnetwork (DQN) to find the desired path on the small-size map. (3) Build the\nplanned path to the original high-resolution map using a path enhanced method.\nIn addition, the imitation learning method and reward shaping theory are\napplied to train the DQN. The reward function is constructed with the\ninformation of terrain, distance, border. Simulation shows that the proposed\nmethod can finish the multi-objective 2.5D path planning task. Also, simulation\nproves that the method has powerful reasoning capability that enables it to\nperform arbitrary untrained planning tasks on the same map.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:53:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13784","submitter":"Hiroki Kojima","authors":"Hiroki Kojima and Takashi Ikegami","title":"Implementation of Lenia as a Reaction-Diffusion System","comments":"Accepted to ALIFE 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.CG cs.NE nlin.PS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The relationship between reaction-diffusion (RD) systems, characterized by\ncontinuous spatiotemporal states, and cellular automata (CA), marked by\ndiscrete spatiotemporal states, remains poorly understood. This paper delves\ninto this relationship through an examination of a recently developed CA known\nas Lenia. We demonstrate that asymptotic Lenia, a variant of Lenia, can be\ncomprehensively described by differential equations, and, unlike the original\nLenia, it is independent of time-step ticks. Further, we establish that this\nformulation is mathematically equivalent to a generalization of the\nkernel-based Turing model (KT model). Stemming from these insights, we\nestablish that asymptotic Lenia can be replicated by an RD system composed\nsolely of diffusion and spatially local reaction terms, resulting in the\nsimulated asymptotic Lenia based on an RD system, or \"RD Lenia\". However, our\nRD Lenia cannot be construed as a chemical system since the reaction term fails\nto satisfy mass-action kinetics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:53:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13785","submitter":"Chen Zhang","authors":"Danqing Luo, Chen Zhang, Jiahui Xu, Bin Wang, Yiming Chen, Yan Zhang,\n  Haizhou Li","title":"Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data\n  Augmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training or finetuning large-scale language models (LLMs) such as GPT-3\nrequires substantial computation resources, motivating recent efforts to\nexplore parameter-efficient adaptation to downstream tasks. One practical area\nof research is to treat these models as black boxes and interact with them\nthrough their inference APIs. In this paper, we investigate how to optimize\nfew-shot text classification without accessing the gradients of the LLMs. To\nachieve this, we treat the black-box model as a feature extractor and train a\nclassifier with the augmented text data. Data augmentation is performed using\nprompt-based finetuning on an auxiliary language model with a much smaller\nparameter size than the black-box model. Through extensive experiments on eight\ntext classification datasets, we show that our approach, dubbed BT-Classifier,\nsignificantly outperforms state-of-the-art black-box few-shot learners and\nperforms on par with methods that rely on full-model tuning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:54:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13786","submitter":"Viorica Patraucean Dr","authors":"Viorica P\\u{a}tr\\u{a}ucean, Lucas Smaira, Ankush Gupta, Adri\\`a\n  Recasens Continente, Larisa Markeeva, Dylan Banarse, Skanda Koppula, Joseph\n  Heyward, Mateusz Malinowski, Yi Yang, Carl Doersch, Tatiana Matejovicova,\n  Yury Sulsky, Antoine Miech, Alex Frechette, Hanna Klimczak, Raphael Koster,\n  Junlin Zhang, Stephanie Winkler, Yusuf Aytar, Simon Osindero, Dima Damen,\n  Andrew Zisserman, Jo\\~ao Carreira","title":"Perception Test: A Diagnostic Benchmark for Multimodal Video Models","comments":"25 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a novel multimodal video benchmark - the Perception Test - to\nevaluate the perception and reasoning skills of pre-trained multimodal models\n(e.g. Flamingo, BEiT-3, or GPT-4). Compared to existing benchmarks that focus\non computational tasks (e.g. classification, detection or tracking), the\nPerception Test focuses on skills (Memory, Abstraction, Physics, Semantics) and\ntypes of reasoning (descriptive, explanatory, predictive, counterfactual)\nacross video, audio, and text modalities, to provide a comprehensive and\nefficient evaluation tool. The benchmark probes pre-trained models for their\ntransfer capabilities, in a zero-shot / few-shot or limited finetuning regime.\nFor these purposes, the Perception Test introduces 11.6k real-world videos, 23s\naverage length, designed to show perceptually interesting situations, filmed by\naround 100 participants worldwide. The videos are densely annotated with six\ntypes of labels (multiple-choice and grounded video question-answers, object\nand point tracks, temporal action and sound segments), enabling both language\nand non-language evaluations. The fine-tuning and validation splits of the\nbenchmark are publicly available (CC-BY license), in addition to a challenge\nserver with a held-out test split. Human baseline results compared to\nstate-of-the-art video QA models show a significant gap in performance (91.4%\nvs 43.6%), suggesting that there is significant room for improvement in\nmultimodal video understanding.\n  Dataset, baselines code, and challenge server are available at\nhttps://github.com/deepmind/perception_test\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:54:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13787","submitter":"Julien Toulouse","authors":"Timoth\\'ee Audinet (LCT), Julien Toulouse (LCT, IUF)","title":"Effective quantum electrodynamics: One-dimensional model of the\n  relativistic hydrogen-like atom","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP physics.chem-ph quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a one-dimensional effective quantum electrodynamics (QED) model\nof the relativistic hydrogen-like atom using delta-potential interactions. We\ndiscuss the general exact theory and the Hartree-Fock approximation. The\npresent one-dimensional effective QED model shares the essential physical\nfeature of the three-dimensional theory: the nuclear charge polarizes the\nvacuum state (creation of electron-positron pairs) which results in a QED\nLamb-type shift of the bound-state energy. Yet, this 1D effective QED model\neliminates some of the most serious technical difficulties of the\nthree-dimensional theory coming from renormalization. We show how to calculate\nthe vacuum-polarization density at zeroth order in the two-particle interaction\nand the QED Lamb-type shift of the bound-state energy at first order in the\ntwo-particle interaction. The present work may be considered as a step toward\nthe development of a quantum-chemistry effective QED theory of atoms and\nmolecules.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:55:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13788","submitter":"James Thorne","authors":"Noah Lee, Na Min An and James Thorne","title":"Can Large Language Models Infer and Disagree Like Humans?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large Language Models (LLMs) have shown stellar achievements in solving a\nbroad range of tasks. When generating text, it is common to sample tokens from\nthese models: whether LLMs closely align with the human disagreement\ndistribution has not been well-studied, especially within the scope of Natural\nLanguage Inference (NLI). In this paper, we evaluate the performance and\nalignment of LLM distribution with humans using two different techniques: Monte\nCarlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a\nresult, we show LLMs exhibit limited ability in solving NLI tasks and\nsimultaneously fail to capture human disagreement distribution, raising\nconcerns about their natural language understanding (NLU) ability and their\nrepresentativeness of human users.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:55:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13789","submitter":"Haigang Li","authors":"Haigang Li, Yan Zhao","title":"The interaction between two close-to-touching convex acoustic\n  subwavelength resonators","comments":"22 pages, to appear in SIAM Multiscale Model. Simul. arXiv admin\n  note: substantial text overlap with arXiv:2001.04888 by other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The Minneart resonance is a low frequency resonance in which the wavelength\nis much larger than the size of the resonators. It is interesting to study the\ninteraction between two adjacent bubbles when they are brought close together.\nBecause the bubbles are usually compressible, in this paper we mainly\ninvestigate resonant modes of two general convex resonators with arbitrary\nshapes to extend the results of Ammari, Davies, Yu in [4], where a pair of\nspherical resonators are considered by using bispherical coordinates. We\ncombine the layer potential method for Helmholtz equation in [4,5] and the\nelliptic theory for gradient estimates in [26,30] to calculate the capacitance\ncoefficients for the coupled $C^{2,\\alpha}$ resonators, then show the\nleading-order asymptotic behaviors of two different resonant modes and reveal\nthe dependance of the resonant frequencies on their geometric properties, such\nas convexity, volumes and curvatures. By the way, the blow-up rates of gradient\nof the scattered pressure are also presented.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:56:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13790","submitter":"Gilles Dowek","authors":"Gilles Dowek","title":"Confluence as a cut elimination property","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The goal of this note is to compare two notions, one coming from the theory\nof rewrite systems and the other from proof theory: confluence and cut\nelimination. We show that to each rewrite system on terms, we can associate a\nlogical system: asymmetric deduction modulo this rewrite system and that the\nconfluence property of the rewrite system is equivalent to the cut elimination\nproperty of the associated logical system. This equivalence, however, does not\nextend to rewrite systems directly rewriting atomic propositions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:57:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13791","submitter":"Fabien Le Floc'h","authors":"Fabien Le Floc'h","title":"The Quadratic Local Variance Gamma Model: an arbitrage-free\n  interpolation of class $\\mathcal{C}^3$ for option prices","comments":"arXiv admin note: text overlap with arXiv:2004.08650","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.CP q-fin.MF q-fin.PR q-fin.RM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper generalizes the local variance gamma model of Carr and Nadtochiy,\nto a piecewise quadratic local variance function. The formulation encompasses\nthe piecewise linear Bachelier and piecewise linear Black local variance gamma\nmodels. The quadratic local variance function results in an arbitrage-free\ninterpolation of class $\\mathcal{C}^3$. The increased smoothness over the\npiecewise-constant and piecewise-linear representation allows to reduce the\nnumber of knots when interpolating raw market quotes, thus providing an\ninteresting alternative to regularization while reducing the computational\ncost.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 07:58:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13792","submitter":"Pooria Namyar","authors":"Pooria Namyar, Behnaz Arzani, Daniel Crankshaw, Daniel S. Berger,\n  Kevin Hsieh, Srikanth Kandula, Ramesh Govindan","title":"Mitigating the Performance Impact of Network Failures in Public Clouds","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Some faults in data center networks require hours to days to repair because\nthey may need reboots, re-imaging, or manual work by technicians. To reduce\ntraffic impact, cloud providers \\textit{mitigate} the effect of faults, for\nexample, by steering traffic to alternate paths. The state-of-art in automatic\nnetwork mitigations uses simple safety checks and proxy metrics to determine\nmitigations. SWARM, the approach described in this paper, can pick orders of\nmagnitude better mitigations by estimating end-to-end connection-level\nperformance (CLP) metrics. At its core is a scalable CLP estimator that quickly\nranks mitigations with high fidelity and, on failures observed at a large cloud\nprovider, outperforms the state-of-the-art by over 700$\\times$ in some cases.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:00:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13793","submitter":"Haigang Li","authors":"Haigang Li, Longjuan Xu, Peihao Zhang","title":"Stress blow-up analysis when a suspending rigid particle approaches the\n  boundary in Stokes flow: 2D case","comments":"43 pages, to appear in SIAM J. Math. Anal","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  It is an interesting and important topic to study the motion of small\nparticles in a viscous liquid in current applied research. In this paper we\nassume the particles are convex with arbitrary shapes and mainly investigate\nthe interaction between the rigid particles and the domain boundary when the\ndistance tends to zero. In fact, even though the domain and the prescribed\nboundary data are both smooth, it is possible to cause a definite increase of\nthe blow-up rate of the stress. This problem has the free boundary value\nfeature due to the rigidity assumption on the particle. We find that the\nprescribed local boundary data directly affects on the free boundary value on\nthe particle. Two kinds of boundary data are considered: locally constant\nboundary data and locally polynomial boundary data. For the former we prove the\nfree boundary value is close to the prescribed constant, while for the latter\nwe show the influence on the blow-up rate from the order of growth of the\nprescribed polynomial. Based on pointwise upper bounds in the neck region and\nlower bounds at the midpoint of the shortest line between the particle and the\ndomain boundary, we show that these blow-up rates obtained in this paper are\noptimal. These precise estimates will help us understand the underlying\nmechanism of the hydrodynamic interactions in fluid particle model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:03:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13794","submitter":"Andreas Schwarz","authors":"Andreas Schwarz, Di He, Maarten Van Segbroeck, Mohammed Hethnawi,\n  Ariya Rastrow","title":"Personalized Predictive ASR for Latency Reduction in Voice Assistants","comments":"Accepted for Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize\nprefetching to partially hide the latency of response generation. Prefetching\ninvolves passing a preliminary ASR hypothesis to downstream systems in order to\nprefetch and cache a response. If the final ASR hypothesis after endpoint\ndetection matches the preliminary one, the cached response can be delivered to\nthe user, thus saving latency. In this paper, we extend this idea by\nintroducing predictive automatic speech recognition, where we predict the full\nutterance from a partially observed utterance, and prefetch the response based\non the predicted utterance. We introduce two personalization approaches and\ninvestigate the tradeoff between potential latency gains from successful\npredictions and the cost increase from failed predictions. We evaluate our\nmethods on an internal voice assistant dataset as well as the public SLURP\ndataset.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:05:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13795","submitter":"Sumeet Batra","authors":"Sumeet Batra, Bryon Tjanaka, Matthew C. Fontaine, Aleksei Petrenko,\n  Stefanos Nikolaidis, Gaurav Sukhatme","title":"Proximal Policy Gradient Arborescence for Quality Diversity\n  Reinforcement Learning","comments":"Submitted to Neurips 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Training generally capable agents that perform well in unseen dynamic\nenvironments is a long-term goal of robot learning. Quality Diversity\nReinforcement Learning (QD-RL) is an emerging class of reinforcement learning\n(RL) algorithms that blend insights from Quality Diversity (QD) and RL to\nproduce a collection of high performing and behaviorally diverse policies with\nrespect to a behavioral embedding. Existing QD-RL approaches have thus far\ntaken advantage of sample-efficient off-policy RL algorithms. However, recent\nadvances in high-throughput, massively parallelized robotic simulators have\nopened the door for algorithms that can take advantage of such parallelism, and\nit is unclear how to scale existing off-policy QD-RL methods to these new\ndata-rich regimes. In this work, we take the first steps to combine on-policy\nRL methods, specifically Proximal Policy Optimization (PPO), that can leverage\nmassive parallelism, with QD, and propose a new QD-RL method with these\nhigh-throughput simulators and on-policy training in mind. Our proposed\nProximal Policy Gradient Arborescence (PPGA) algorithm yields a 4x improvement\nover baselines on the challenging humanoid domain.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:05:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13796","submitter":"Zhibin Qiu","authors":"Zhibin Qiu, Mengfan Fu, Fuchun Sun, Gulila Altenbek, Hao Huang","title":"SE-Bridge: Speech Enhancement with Consistent Brownian Bridge","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose SE-Bridge, a novel method for speech enhancement (SE). After\nrecently applying the diffusion models to speech enhancement, we can achieve\nspeech enhancement by solving a stochastic differential equation (SDE). Each\nSDE corresponds to a probabilistic flow ordinary differential equation\n(PF-ODE), and the trajectory of the PF-ODE solution consists of the speech\nstates at different moments. Our approach is based on consistency model that\nensure any speech states on the same PF-ODE trajectory, correspond to the same\ninitial state. By integrating the Brownian Bridge process, the model is able to\ngenerate high-intelligibility speech samples without adversarial training. This\nis the first attempt that applies the consistency models to SE task, achieving\nstate-of-the-art results in several metrics while saving 15 x the time required\nfor sampling compared to the diffusion-based baseline. Our experiments on\nmultiple datasets demonstrate the effectiveness of SE-Bridge in SE.\nFurthermore, we show through extensive experiments on downstream tasks,\nincluding Automatic Speech Recognition (ASR) and Speaker Verification (SV),\nthat SE-Bridge can effectively support multiple downstream tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:06:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13797","submitter":"Hugues Van Assel","authors":"Hugues Van Assel, Titouan Vayer, R\\'emi Flamary, Nicolas Courty","title":"SNEkhorn: Dimension Reduction with Symmetric Entropic Affinities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many approaches in machine learning rely on a weighted graph to encode the\nsimilarities between samples in a dataset. Entropic affinities (EAs), which are\nnotably used in the popular Dimensionality Reduction (DR) algorithm t-SNE, are\nparticular instances of such graphs. To ensure robustness to heterogeneous\nsampling densities, EAs assign a kernel bandwidth parameter to every sample in\nsuch a way that the entropy of each row in the affinity matrix is kept constant\nat a specific value, whose exponential is known as perplexity. EAs are\ninherently asymmetric and row-wise stochastic, but they are used in DR\napproaches after undergoing heuristic symmetrization methods that violate both\nthe row-wise constant entropy and stochasticity properties. In this work, we\nuncover a novel characterization of EA as an optimal transport problem,\nallowing a natural symmetrization that can be computed efficiently using dual\nascent. The corresponding novel affinity matrix derives advantages from\nsymmetric doubly stochastic normalization in terms of clustering performance,\nwhile also effectively controlling the entropy of each row thus making it\nparticularly robust to varying noise levels. Following, we present a new DR\nalgorithm, SNEkhorn, that leverages this new affinity matrix. We show its clear\nsuperiority to state-of-the-art approaches with several indicators on both\nsynthetic and real-world datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:08:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13798","submitter":"Hannes Malcha","authors":"Hannes Malcha","title":"The Nicolai Map and its Application in Supersymmetric Field Theories","comments":"PhD thesis, 174 pages, Humboldt University of Berlin, contains\n  arXiv:2005.12324, arXiv:2006.02457, arXiv:2104.06017 and arXiv:2206.02919","journal-ref":null,"doi":"10.18452/26406","report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this thesis, we study the Nicolai maps of the 2-dimensional Wess-Zumino\nmodel, $\\mathcal{N}=1$ super Yang-Mills and $\\mathcal{N}=4$ super Yang-Mills.\nWe compute the Nicolai map of the 2-dimensional Wess-Zumino model up to the\nfifth order in the coupling. In $\\mathcal{N}=1$ super Yang-Mills, we introduce\nthe notion of on- and off-shell Nicolai maps. The on-shell Nicolai map of\n$\\mathcal{N}=1$ super Yang-Mills exists in d=3, 4, 6 and 10 dimensions but is\nconstrained to the Landau gauge. We compute this map up to the fourth order.\nThe off-shell Nicolai map exists only in d=4 dimensions but for general gauges.\nWe compute it in the axial gauge up to the second order. We show that the\n$\\mathcal{N}=4$ super Yang-Mills Nicolai map can be obtained from the Nicolai\nmap of 10-dimensional $\\mathcal{N}=1$ super Yang-Mills by dimensional\nreduction.\n  Inverse Nicolai maps allow for a fermion (and ghost) free quantization of\nsupersymmetric (gauge) theories. We apply this property to compute the vacuum\nexpectation value of the infinite straight line Maldacena-Wilson loop in\n$\\mathcal{N}=4$ super Yang-Mills to the sixth order.\n  In the second part of this thesis, we derive the explicit field content of\nthe 1/2-BPS stress tensor multiplet in $\\mathcal{N}=4$ super Yang-Mills, which\ncontains the R-symmetry current and the energy-momentum tensor.\n  The original version of this thesis, as submitted in May 2023 to the Humboldt\nUniversity of Berlin, is available under the DOI\nhttps://doi.org/10.18452/26406.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:09:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13799","submitter":"Hongtao Wang","authors":"Hongtao Wang, Jiangshe Zhang, Xiaoli Wei, Li Long, Chunxia Zhang","title":"Leveraging Uncertainty Quantification for Picking Robust First Break\n  Times","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In seismic exploration, the selection of first break times is a crucial\naspect in the determination of subsurface velocity models, which in turn\nsignificantly influences the placement of wells. Many deep neural network\n(DNN)-based automatic first break picking methods have been proposed to speed\nup this picking processing. However, there has been no work on the uncertainty\nof the first picking results of the output of DNN. In this paper, we propose a\nnew framework for first break picking based on a Bayesian neural network to\nfurther explain the uncertainty of the output. In a large number of\nexperiments, we evaluate that the proposed method has better accuracy and\nrobustness than the deterministic DNN-based model. In addition, we also verify\nthat the uncertainty of measurement is meaningful, which can provide a\nreference for human decision-making.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:13:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13800","submitter":"Haiwei Wu","authors":"Haiwei Wu and Jiantao Zhou and Shile Zhang","title":"Generalizable Synthetic Image Detection via Language-guided Contrastive\n  Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The heightened realism of AI-generated images can be attributed to the rapid\ndevelopment of synthetic models, including generative adversarial networks\n(GANs) and diffusion models (DMs). The malevolent use of synthetic images, such\nas the dissemination of fake news or the creation of fake profiles, however,\nraises significant concerns regarding the authenticity of images. Though many\nforensic algorithms have been developed for detecting synthetic images, their\nperformance, especially the generalization capability, is still far from being\nadequate to cope with the increasing number of synthetic models. In this work,\nwe propose a simple yet very effective synthetic image detection method via a\nlanguage-guided contrastive learning and a new formulation of the detection\nproblem. We first augment the training images with carefully-designed textual\nlabels, enabling us to use a joint image-text contrastive learning for the\nforensic feature extraction. In addition, we formulate the synthetic image\ndetection as an identification problem, which is vastly different from the\ntraditional classification-based approaches. It is shown that our proposed\nLanguAge-guided SynThEsis Detection (LASTED) model achieves much improved\ngeneralizability to unseen image generation models and delivers promising\nperformance that far exceeds state-of-the-art competitors by +22.66% accuracy\nand +15.24% AUC. The code is available at https://github.com/HighwayWu/LASTED.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:13:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13801","submitter":"Naoto Ohsaka","authors":"Naoto Ohsaka, Riku Togashi","title":"A Critical Reexamination of Intra-List Distance and Dispersion","comments":"10 pages, to appear in 46th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2023)","journal-ref":null,"doi":"10.1145/3539618.3591623","report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Diversification of recommendation results is a promising approach for coping\nwith the uncertainty associated with users' information needs. Of particular\nimportance in diversified recommendation is to define and optimize an\nappropriate diversity objective. In this study, we revisit the most popular\ndiversity objective called intra-list distance (ILD), defined as the average\npairwise distance between selected items, and a similar but lesser known\nobjective called dispersion, which is the minimum pairwise distance. Owing to\ntheir simplicity and flexibility, ILD and dispersion have been used in a\nplethora of diversified recommendation research. Nevertheless, we do not\nactually know what kind of items are preferred by them.\n  We present a critical reexamination of ILD and dispersion from theoretical\nand experimental perspectives. Our theoretical results reveal that these\nobjectives have potential drawbacks: ILD may select duplicate items that are\nvery close to each other, whereas dispersion may overlook distant item pairs.\nAs a competitor to ILD and dispersion, we design a diversity objective called\nGaussian ILD, which can interpolate between ILD and dispersion by tuning the\nbandwidth parameter. We verify our theoretical results by experimental results\nusing real-world data and confirm the extreme behavior of ILD and dispersion in\npractice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:14:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13802","submitter":"Zerun Wang","authors":"Zerun Wang, Ling Xiao, Liuyu Xiang, Zhaotian Weng, Toshihiko Yamasaki","title":"Online Open-set Semi-supervised Object Detection via Semi-supervised\n  Outlier Filtering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Open-set semi-supervised object detection (OSSOD) methods aim to utilize\npractical unlabeled datasets with out-of-distribution (OOD) instances for\nobject detection. The main challenge in OSSOD is distinguishing and filtering\nthe OOD instances from the in-distribution (ID) instances during\npseudo-labeling. The previous method uses an offline OOD detection network\ntrained only with labeled data for solving this problem. However, the scarcity\nof available data limits the potential for improvement. Meanwhile, training\nseparately leads to low efficiency. To alleviate the above issues, this paper\nproposes a novel end-to-end online framework that improves performance and\nefficiency by mining more valuable instances from unlabeled data. Specifically,\nwe first propose a semi-supervised OOD detection strategy to mine valuable ID\nand OOD instances in unlabeled datasets for training. Then, we constitute an\nonline end-to-end trainable OSSOD framework by integrating the OOD detection\nhead into the object detector, making it jointly trainable with the original\ndetection task. Our experimental results show that our method works well on\nseveral benchmarks, including the partially labeled COCO dataset with open-set\nclasses and the fully labeled COCO dataset with the additional large-scale\nopen-set unlabeled dataset, OpenImages. Compared with previous OSSOD methods,\nour approach achieves the best performance on COCO with OpenImages by +0.94\nmAP, reaching 44.07 mAP.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:15:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13803","submitter":"Anbang Yao","authors":"Xiaolong Liu, Lujun Li, Chao Li, Anbang Yao","title":"NORM: Knowledge Distillation via N-to-One Representation Matching","comments":"The paper of NORM is published at ICLR 2023. Code and models are\n  available at https://github.com/OSVAI/NORM","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing feature distillation methods commonly adopt the One-to-one\nRepresentation Matching between any pre-selected teacher-student layer pair. In\nthis paper, we present N-to-One Representation (NORM), a new two-stage\nknowledge distillation method, which relies on a simple Feature Transform (FT)\nmodule consisting of two linear layers. In view of preserving the intact\ninformation learnt by the teacher network, during training, our FT module is\nmerely inserted after the last convolutional layer of the student network. The\nfirst linear layer projects the student representation to a feature space\nhaving N times feature channels than the teacher representation from the last\nconvolutional layer, and the second linear layer contracts the expanded output\nback to the original feature space. By sequentially splitting the expanded\nstudent representation into N non-overlapping feature segments having the same\nnumber of feature channels as the teacher's, they can be readily forced to\napproximate the intact teacher representation simultaneously, formulating a\nnovel many-to-one representation matching mechanism conditioned on a single\nteacher-student layer pair. After training, such an FT module will be naturally\nmerged into the subsequent fully connected layer thanks to its linear property,\nintroducing no extra parameters or architectural modifications to the student\nnetwork at inference. Extensive experiments on different visual recognition\nbenchmarks demonstrate the leading performance of our method. For instance, the\nResNet18|MobileNet|ResNet50-1/4 model trained by NORM reaches\n72.14%|74.26%|68.03% top-1 accuracy on the ImageNet dataset when using a\npre-trained ResNet34|ResNet50|ResNet50 model as the teacher, achieving an\nabsolute improvement of 2.01%|4.63%|3.03% against the individually trained\ncounterpart. Code is available at https://github.com/OSVAI/NORM\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:15:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13804","submitter":"Sibo Gai","authors":"Sibo Gai, Donglin Wang, Li He","title":"Offline Experience Replay for Continual Offline Reinforcement Learning","comments":"9 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The capability of continuously learning new skills via a sequence of\npre-collected offline datasets is desired for an agent. However, consecutively\nlearning a sequence of offline tasks likely leads to the catastrophic\nforgetting issue under resource-limited scenarios. In this paper, we formulate\na new setting, continual offline reinforcement learning (CORL), where an agent\nlearns a sequence of offline reinforcement learning tasks and pursues good\nperformance on all learned tasks with a small replay buffer without exploring\nany of the environments of all the sequential tasks. For consistently learning\non all sequential tasks, an agent requires acquiring new knowledge and\nmeanwhile preserving old knowledge in an offline manner. To this end, we\nintroduced continual learning algorithms and experimentally found experience\nreplay (ER) to be the most suitable algorithm for the CORL problem. However, we\nobserve that introducing ER into CORL encounters a new distribution shift\nproblem: the mismatch between the experiences in the replay buffer and\ntrajectories from the learned policy. To address such an issue, we propose a\nnew model-based experience selection (MBES) scheme to build the replay buffer,\nwhere a transition model is learned to approximate the state distribution. This\nmodel is used to bridge the distribution bias between the replay buffer and the\nlearned model by filtering the data from offline data that most closely\nresembles the learned model for storage. Moreover, in order to enhance the\nability on learning new tasks, we retrofit the experience replay method with a\nnew dual behavior cloning (DBC) architecture to avoid the disturbance of\nbehavior-cloning loss on the Q-learning process. In general, we call our\nalgorithm offline experience replay (OER). Extensive experiments demonstrate\nthat our OER method outperforms SOTA baselines in widely-used Mujoco\nenvironments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:16:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13805","submitter":"Zilong Wang","authors":"Zilong Wang, Jingbo Shang","title":"Towards Zero-shot Relation Extraction in Web Mining: A Multimodal\n  Approach with Relative XML Path","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The rapid growth of web pages and the increasing complexity of their\nstructure poses a challenge for web mining models. Web mining models are\nrequired to understand the semi-structured web pages, particularly when little\nis known about the subject or template of a new page. Current methods migrate\nlanguage models to the web mining by embedding the XML source code into the\ntransformer or encoding the rendered layout with graph neural networks.\nHowever, these approaches do not take into account the relationships between\ntext nodes within and across pages. In this paper, we propose a new approach,\nReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the\nshortest relative paths in the Document Object Model (DOM) tree which is a more\naccurate and efficient signal for key-value pair extraction within a web page.\nIt also incorporates the popularity of each text node by counting the\noccurrence of the same text node across different web pages. We use the\ncontrastive learning to address the issue of sparsity in relation extraction.\nExtensive experiments on public benchmarks show that our method, ReXMiner,\noutperforms the state-of-the-art baselines in the task of zero-shot relation\nextraction in web mining.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:16:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13806","submitter":"Rakesh Pandey","authors":"Rakesh Pandey, Saurabh Sharma, Lokesh Dewangan, Aayushi Verma, Tapas\n  Baug, Harmeen Kaur and Arpan Ghosh","title":"Investigating star formation activity in the Sh 2-61 H II region","comments":"Paper is accepted for the publication in the Journal of Astrophysics\n  and Astronomy","journal-ref":"Journal of Astrophysics and Astronomy, 2023","doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using the multiwavelength data sets, we studied the star formation activity\nin H II region Sh 2-61 (hereafter S61). We identified a clustering in the\nregion and estimated the membership using the Gaia proper motion data. The\nphysical environment of S61 is inspected using infrared to radio wavelength\nimages. We also determined the Lyman continuum flux associated with the H II\nregion and found that the H II region is formed by at least two massive stars\n(S1 and S2). We also analyzed the 12CO (J =3-2) JCMT data of S61, and a shell\nstructure accompanying three molecular clumps are observed towards S61. We\nfound that the ionized gas in S61 is surrounded by dust and a molecular shell.\nMany young stellar objects and three molecular clumps are observed at the\ninterface of the ionized gas and the surrounding gas. The pressure at the\ninterface is higher than in a typical cool molecular cloud.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:17:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13807","submitter":"Bal\\'azs Keszegh","authors":"Eyal Ackerman, Bal\\'azs Keszegh","title":"On the number of tangencies among 1-intersecting curves","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.CG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $\\cal C$ be a set of curves in the plane such that no three curves in\n$\\cal C$ intersect at a single point and every pair of curves in $\\cal C$\nintersect at exactly one point which is either a crossing or a touching point.\nAccording to a conjecture of J\\'anos Pach the number of pairs of curves in\n$\\cal C$ that touch each other is $O(|{\\cal C}|)$. We prove this conjecture for\n$x$-monotone curves.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:18:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13808","submitter":"Dongryeol Lee","authors":"Dongryeol Lee, Segwang Kim, Minwoo Lee, Hwanhee Lee, Joonsuk Park,\n  Sang-Woo Lee and Kyomin Jung","title":"Asking Clarification Questions to Handle Ambiguity in Open-Domain QA","comments":"15 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ambiguous questions persist in open-domain question answering, because\nformulating a precise question with a unique answer is often challenging.\nPreviously, Min et al. (2020) have tackled this issue by generating\ndisambiguated questions for all possible interpretations of the ambiguous\nquestion. This can be effective, but not ideal for providing an answer to the\nuser. Instead, we propose to ask a clarification question, where the user's\nresponse will help identify the interpretation that best aligns with the user's\nintention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous\nquestions, each with relevant passages, possible answers, and a clarification\nquestion. The clarification questions were efficiently created by generating\nthem using InstructGPT and manually revising them as necessary. We then define\na pipeline of tasks and design appropriate evaluation metrics. Lastly, we\nachieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA,\nproviding strong baselines for future work.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:20:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13809","submitter":"Oliver Lorscheid","authors":"Oliver Lorscheid and Koen Thas","title":"Towards the horizons of Tits's vision -- on band schemes, crowds and\n  F1-structures","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.AG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This text is dedicated to Jacques Tits's ideas on geometry over F1, the field\nwith one element. In a first part, we explain how thin Tits geometries surface\nas rational point sets over the Krasner hyperfield, which links these ideas to\ncombinatorial flag varieties in the sense of Borovik, Gelfand and White and\nF1-geometry in the sense of Connes and Consani. A completely novel feature is\nour approach to algebraic groups over F1 in terms of an alteration of the very\nconcept of a group. In the second part, we study an incidence-geometrical\ncounterpart of (epimorphisms to) thin Tits geometries; we introduce and\nclassify all F1-structures on 3-dimensional projective spaces over finite\nfields. This extends recent work of Thas and Thas on epimorphisms of projective\nplanes (and other rank 2 buildings) to thin planes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:20:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13810","submitter":"Siddhartha Borkotoky","authors":"Shashank M. S. Panga, Siddhartha S. Borkotoky","title":"Leveraging Wake-Up Radios in UAV-Aided LoRa Networks: Some Preliminary\n  Results on a Random-Access Scheme","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a transmission scheme aimed at integrating wake-up radios (WuR)\ninto LoRa sensor networks featuring UAV-mounted gateways. The sensors are\ninformed of the UAV's arrival with the help of WuR, followed by sensor-to-UAV\ndata transfer with frequency and spreading-factor hopping. The proposed scheme\nprovides significant energy savings at the sensors while maintaining similar\nreliability levels compared to a scheme in which Class B LoRa beacons are used\nto perfectly synchronize the sensors with the UAV's data-collection window.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:26:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13811","submitter":"Ignacio Breva Ribes","authors":"Ignacio Breva Ribes and Ra\\'ul Oset Sinha","title":"Augmentation of singularities: $\\mu/\\tau$-type conjectures and\n  simplicity","comments":"37 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For function germs $g:(\\mathbb C^n,0)\\to (\\mathbb C,0)$ it is well known that\n$1\\leq\\frac{\\mu(g)}{\\tau(g)}$ and it has recently been proved by Liu that\n$\\frac{\\mu(g)}{\\tau(g)}\\leq n$. We give an upper bound for the codimension of\nmap-germs $f:(\\mathbb C^n,0)\\to (\\mathbb C^p,0)$ given as augmentations of\nother map-germs with which we prove the analog to the first inequality (known\nas Mond's conjecture) for augmentations $h:(\\mathbb C^n,0)\\to (\\mathbb\nC^{n+1},0)$. Furthermore, we show that the quotient given by the image Milnor\nnumber and the codimension of any augmentation in the pair of dimensions\n$(n,n+1)$ is less than $\\frac{1}{4}(n+1)^2$ and prove the analog to the second\ninequality for map-germs with $n=1$ and augmentations with $n=2,3$. We then\nprove a characterization of when a map-germ is an augmentation, finding a\ncounterexample for the characterization given by Houston. Next, we give\nsufficient conditions for when the augmentation is independent of the choice of\nstable unfolding by studying different notions of equivalence of unfoldings.\nMoreover, these results allow us to give sufficient conditions for the\nsimplicity of an augmentation, providing context to locate the moduli for\nnon-simple augmentations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:27:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13812","submitter":"Harman Singh","authors":"Harman Singh, Pengchuan Zhang, Qifan Wang, Mengjiao Wang, Wenhan\n  Xiong, Jingfei Du, Yu Chen","title":"Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for\n  Improved Vision-Language Compositionality","comments":"16 pages, 12 figures, 7 Tables. Pre-print","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Contrastively trained vision-language models have achieved remarkable\nprogress in vision and language representation learning, leading to\nstate-of-the-art models for various downstream multimodal tasks. However,\nrecent research has highlighted severe limitations of these models in their\nability to perform compositional reasoning over objects, attributes, and\nrelations. Scene graphs have emerged as an effective way to understand images\ncompositionally. These are graph-structured semantic representations of images\nthat contain objects, their attributes, and relations with other objects in a\nscene. In this work, we consider the scene graph parsed from text as a proxy\nfor the image scene graph and propose a graph decomposition and augmentation\nframework along with a coarse-to-fine contrastive learning objective between\nimages and text that aligns sentences of various complexities to the same\nimage. Along with this, we propose novel negative mining techniques in the\nscene graph space for improving attribute binding and relation understanding.\nThrough extensive experiments, we demonstrate the effectiveness of our approach\nthat significantly improves attribute binding, relation understanding,\nsystematic generalization, and productivity on multiple recently proposed\nbenchmarks (For example, improvements upto $18\\%$ for systematic\ngeneralization, $16.5\\%$ for relation understanding over a strong baseline),\nwhile achieving similar or better performance than CLIP on various general\nmultimodal tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:28:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13813","submitter":"Anima Nagar","authors":"Nayan Adhikary and Anima Nagar","title":"Some Variations of Transitivity for CR-dynamical systems","comments":"45 pages. Comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We consider the topological dynamics of closed relations(CR) by studying one\nof the oldest dynamical property - `transitivity'. We investigate the two kinds\nof (closed relation) CR-dynamical systems - $(X,G)$ where the relation $G\n\\subseteq X \\times X$ is closed and $(X,G, \\bullet)$ giving the `suitable\ndynamics' for a suitable closed relation $G$, where $X$ is assumed to be a\ncompact metric space without isolated points.\n  $(X,G)$ gives a general approach to study initial value problems for a set of\ninitial conditions, whereas $(X,G, \\bullet)$ gives a general approach to study\nthe dynamics of both continuous and quasi-continuous maps.\n  We observe that the dynamics of closed relations is richer than the dynamics\nof maps and find that we have much more versions of transitivity for these\nclosed relations than what is known for maps.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:28:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13814","submitter":"Xu Xuecheng","authors":"Xuecheng Xu, Yanmei Jiao, Sha Lu, Xiaqing Ding, Rong Xiong, Yue Wang","title":"Leveraging BEV Representation for 360-degree Visual Place Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  This paper investigates the advantages of using Bird's Eye View (BEV)\nrepresentation in 360-degree visual place recognition (VPR). We propose a novel\nnetwork architecture that utilizes the BEV representation in feature\nextraction, feature aggregation, and vision-LiDAR fusion, which bridges visual\ncues and spatial awareness. Our method extracts image features using standard\nconvolutional networks and combines the features according to pre-defined 3D\ngrid spatial points. To alleviate the mechanical and time misalignments between\ncameras, we further introduce deformable attention to learn the compensation.\nUpon the BEV feature representation, we then employ the polar transform and the\nDiscrete Fourier transform for aggregation, which is shown to be\nrotation-invariant. In addition, the image and point cloud cues can be easily\nstated in the same coordinates, which benefits sensor fusion for place\nrecognition. The proposed BEV-based method is evaluated in ablation and\ncomparative studies on two datasets, including on-the-road and off-the-road\nscenarios. The experimental results verify the hypothesis that BEV can benefit\nVPR by its superior performance compared to baseline methods. To the best of\nour knowledge, this is the first trial of employing BEV representation in this\ntask.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:29:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13815","submitter":"Yan Zhu","authors":"Can Huang, Bingjie Liu, LingZi Jiang, Yanfei Pan, Jiyu Fan, Daning\n  Shi, Chunlan Ma, Qiang Luo, Yan Zhu","title":"Evidence of Kitaev interaction in the monolayer 1T-CrTe$_2$","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The two-dimensional 1T-CrTe$_2$ has been an attractive room-temperature van\nder Waals magnet which has a potential application in spintronic devices.\nAlthough it was recognized as a ferromagnetism in the past, the monolayer\n1T-CrTe$_2$ was recently found to exhibit zigzag antiferromagnetism with the\neasy axis oriented at $70^\\circ$ to the perpendicular direction of the plane.\nTherefore, the origin of the intricate anisotropic magnetic behavior therein is\nwell worthy of thorough exploration. Here, by applying density functional\ntheory with spin spiral method, we demonstrate that the Kitaev interaction,\ntogether with the single-ion anisotropy and other off-diagonal exchanges, is\namenable to explain the magnetic orientation in the metallic 1T-CrTe$_2$.\nMoreover, the Ruderman-Kittle-Kasuya-Yosida interaction can also be extracted\nfrom the dispersion calculations, which explains the metallic behavior of\n1T-CrTe$_2$. Our results demonstrate that 1T-CrTe$_2$ is potentially a rare\nmetallic Kitaev material.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:34:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13816","submitter":"Varun Jindal","authors":"Akshay Kumar and Varun Jindal","title":"Barreled extended locally convex spaces and Uniform boundedness\n  principle","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For an extended locally convex space $(X,\\tau)$, in [8], the authors studied\nthe finest locally convex topology (flc topology) $\\tau_F$ on $X$ coarser than\n$\\tau$. One can often prove facts about $(X, \\tau)$ by applying classical\nlocally convex space theory on $(X, \\tau_F)$. This paper employs the flc\ntopology to analyze barreled extended locally convex spaces and establish the\nuniform boundedness principle in the extended setting. One of the key results\nof this paper is the relationship between the barreledness of an extended\nlocally convex space $(X,\\tau)$ and the barreledness of the associated finest\nlocally convex space $(X, \\tau_F)$. This is achieved by examining the lower\nsemi-continuous seminorms on these spaces.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:34:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13817","submitter":"Christel G\\'erardin","authors":"Christel G\\'erardin, Perceval Wajsb\\\"urt, Basile Dura, Alice Calliger,\n  Alexandre Moucher, Xavier Tannier and Romain Bey","title":"Detecting automatically the layout of clinical documents to enhance the\n  performances of downstream natural language processing","comments":"22 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Objective:Develop and validate an algorithm for analyzing the layout of PDF\nclinical documents to improve the performance of downstream natural language\nprocessing tasks. Materials and Methods: We designed an algorithm to process\nclinical PDF documents and extract only clinically relevant text. The algorithm\nconsists of several steps: initial text extraction using a PDF parser, followed\nby classification into categories such as body text, left notes, and footers\nusing a Transformer deep neural network architecture, and finally an\naggregation step to compile the lines of a given label in the text. We\nevaluated the technical performance of the body text extraction algorithm by\napplying it to a random sample of documents that were annotated. Medical\nperformance was evaluated by examining the extraction of medical concepts of\ninterest from the text in their respective sections. Finally, we tested an\nend-to-end system on a medical use case of automatic detection of acute\ninfection described in the hospital report. Results:Our algorithm achieved\nper-line precision, recall, and F1 score of 98.4, 97.0, and 97.7, respectively,\nfor body line extraction. The precision, recall, and F1 score per document for\nthe acute infection detection algorithm were 82.54 (95CI 72.86-91.60), 85.24\n(95CI 76.61-93.70), 83.87 (95CI 76, 92-90.08) with exploitation of the results\nof the advanced body extraction algorithm, respectively. Conclusion:We have\ndeveloped and validated a system for extracting body text from clinical\ndocuments in PDF format by identifying their layout. We were able to\ndemonstrate that this preprocessing allowed us to obtain better performances\nfor a common downstream task, i.e., the extraction of medical concepts in their\nrespective sections, thus proving the interest of this method on a clinical use\ncase.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:38:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13818","submitter":"Alexander Henzi","authors":"Alexander Henzi and Michael Law","title":"A Rank-Based Sequential Test of Independence","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of independence testing for two univariate random\nvariables in a sequential setting. By leveraging recent developments on safe,\nanytime-valid inference, we propose a test with time-uniform type-I error\ncontrol and derive explicit bounds on the finite sample performance of the test\nand the expected stopping time. We demonstrate the empirical performance of the\nprocedure in comparison to existing sequential and non-sequential independence\ntests. Furthermore, since the proposed test is distribution free under the null\nhypothesis, we empirically simulate the gap due to Ville's inequality, the\nsupermartingale analogue of Markov's inequality, that is commonly applied to\ncontrol type I error in anytime-valid inference, and apply this to construct a\ntruncated sequential test.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:38:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13819","submitter":"Yi Huang","authors":"Yi Huang, Jiancheng Huang, Jianzhuang Liu, Yu Dong, Jiaxi Lv, Shifeng\n  Chen","title":"WaveDM: Wavelet-Based Diffusion Models for Image Restoration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Latest diffusion-based methods for many image restoration tasks outperform\ntraditional models, but they encounter the long-time inference problem. To\ntackle it, this paper proposes a Wavelet-Based Diffusion Model (WaveDM) with an\nEfficient Conditional Sampling (ECS) strategy. WaveDM learns the distribution\nof clean images in the wavelet domain conditioned on the wavelet spectrum of\ndegraded images after wavelet transform, which is more time-saving in each step\nof sampling than modeling in the spatial domain. In addition, ECS follows the\nsame procedure as the deterministic implicit sampling in the initial sampling\nperiod and then stops to predict clean images directly, which reduces the\nnumber of total sampling steps to around 5. Evaluations on four benchmark\ndatasets including image raindrop removal, defocus deblurring, demoir\\'eing,\nand denoising demonstrate that WaveDM achieves state-of-the-art performance\nwith the efficiency that is comparable to traditional one-pass methods and over\n100 times faster than existing image restoration methods using vanilla\ndiffusion models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:41:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13820","submitter":"Laurie Burchell","authors":"Laurie Burchell, Alexandra Birch, Nikolay Bogoychev and Kenneth\n  Heafield","title":"An Open Dataset and Model for Language Identification","comments":"To be published in ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language identification (LID) is a fundamental step in many natural language\nprocessing pipelines. However, current LID systems are far from perfect,\nparticularly on lower-resource languages. We present a LID model which achieves\na macro-average F1 score of 0.93 and a false positive rate of 0.033 across 201\nlanguages, outperforming previous work. We achieve this by training on a\ncurated dataset of monolingual data, the reliability of which we ensure by\nauditing a sample from each source and each language manually. We make both the\nmodel and the dataset available to the research community. Finally, we carry\nout detailed analysis into our model's performance, both in comparison to\nexisting open models and by language class.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:43:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13821","submitter":"Chaoran Chen","authors":"Chaoran Chen, Tanja Stadler","title":"GenSpectrum Chat: Data Exploration in Public Health Using Large Language\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.GN cs.AI cs.IR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Introduction: The COVID-19 pandemic highlighted the importance of making\nepidemiological data and scientific insights easily accessible and explorable\nfor public health agencies, the general public, and researchers.\nState-of-the-art approaches for sharing data and insights included regularly\nupdated reports and web dashboards. However, they face a trade-off between the\nsimplicity and flexibility of data exploration. With the capabilities of recent\nlarge language models (LLMs) such as GPT-4, this trade-off can be overcome.\n  Results: We developed the chatbot \"GenSpectrum Chat\"\n(https://cov-spectrum.org/chat) which uses GPT-4 as the underlying large\nlanguage model (LLM) to explore SARS-CoV-2 genomic sequencing data. Out of 500\ninputs from real-world users, the chatbot provided a correct answer for 453\nprompts; an incorrect answer for 13 prompts, and no answer although the\nquestion was within scope for 34 prompts. We also tested the chatbot with\ninputs from 10 different languages, and despite being provided solely with\nEnglish instructions and examples, it successfully processed prompts in all\ntested languages.\n  Conclusion: LLMs enable new ways of interacting with information systems. In\nthe field of public health, GenSpectrum Chat can facilitate the analysis of\nreal-time pathogen genomic data. With our chatbot supporting interactive\nexploration in different languages, we envision quick and direct access to the\nlatest evidence for policymakers around the world.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:43:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13822","submitter":"Antoine Delattre-Klauser","authors":"Antoine Klauser (1,2,9,10), Bernhard Strasser (1,3), Wolfgang Bogner\n  (3), Lukas Hingerl (3), Sebastien Courvoisier (9,10), Claudiu Schirda (4),\n  Mehran Babolin (1), Jorg Dietrich (5), Isabel Arrillaga-Romany (5), Julie\n  Miller (5), Erik Uhlmann (6), Daniel P. Cahill (7), Tracy T. Batchelor (8),\n  Francois Lazeyras (9,10), Ovidiu C. Andronesi (1) ((1) Athinoula A. Martinos\n  Center for Biomedical Imaging, Department of Radiology, Massachusetts General\n  Hospital, Harvard Medical School, Boston, (2) Advanced Clinical Imaging\n  Technology, Siemens Healthcare AG, Lausanne, Switzerland, (3) High-Field MR\n  Center, Department of Biomedical Imaging and Image-guided Therapy, Medical\n  University of Vienna, Vienna, Austria, (4) Department of Radiology,\n  University of Pittsburgh School of Medicine, Pittsburgh, Pennsylvania, USA,\n  (5) Department of Neurology, Massachusetts General Hospital, Harvard Medical\n  School, Boston, (6) Department of Neurology, Beth Israel Deaconess Medical\n  Center, Harvard Medical School, Boston, (7) Department of Neurosurgery,\n  Massachusetts General Hospital, Harvard Medical School, Boston, (8)\n  Department of Neurology, Brigham and Women, Harvard Medical School, Boston,\n  (9) Department of Radiology and Medical Informatics, University of Geneva,\n  Switzerland, (10) CIBM Center for Biomedical Imaging, Switzerland)","title":"ECCENTRIC: a fast and unrestrained approach for high-resolution in vivo\n  metabolic imaging at ultra-high field MR","comments":"20 pages, 7 figures,2 tables, 10 pages supplementary material","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A novel method for fast and high-resolution metabolic imaging, called\nECcentric Circle ENcoding TRajectorIes for Compressed sensing (ECCENTRIC), has\nbeen developed and implemented on 7 Tesla human MRI. ECCENTRIC is a\nnon-Cartesian spatial-spectral encoding method optimized for random\nundersampling of magnetic resonance spectroscopic imaging (MRSI) at ultra-high\nfield. The approach provides flexible and random (k,t) sampling without\ntemporal interleaving to improve spatial response function and spectral\nquality. ECCENTRIC needs low gradient amplitudes and slew-rates that reduces\nelectrical, mechanical and thermal stress of the scanner hardware, and is\nrobust to timing imperfection and eddy-current delays. Combined with a\nmodel-based low-rank reconstruction, this approach enables simultaneous imaging\nof up to 14 metabolites over the whole-brain at 2-3mm isotropic resolution in\n4-10 minutes with high signal-to-noise ratio. In 20 healthy volunteers and 20\nglioma patients ECCENTRIC demonstrated unprecedented mapping of fine structural\ndetails of metabolism in healthy brains and an extended metabolic\nfingerprinting of glioma tumors.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:45:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13823","submitter":"Zhanwen Zhou","authors":"Zhanwen Zhou, Hankz Hankui Zhuo, Xiaowu Zhang, Qiyuan Deng","title":"XRoute Environment: A Novel Reinforcement Learning Environment for\n  Routing","comments":"arXiv admin note: text overlap with arXiv:1907.11180 by other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Routing is a crucial and time-consuming stage in modern design automation\nflow for advanced technology nodes. Great progress in the field of\nreinforcement learning makes it possible to use those approaches to improve the\nrouting quality and efficiency. However, the scale of the routing problems\nsolved by reinforcement learning-based methods in recent studies is too small\nfor these methods to be used in commercial EDA tools. We introduce the XRoute\nEnvironment, a new reinforcement learning environment where agents are trained\nto select and route nets in an advanced, end-to-end routing framework. Novel\nalgorithms and ideas can be quickly tested in a safe and reproducible manner in\nit. The resulting environment is challenging, easy to use, customize and add\nadditional scenarios, and it is available under a permissive open-source\nlicense. In addition, it provides support for distributed deployment and\nmulti-instance experiments. We propose two tasks for learning and build a\nfull-chip test bed with routing benchmarks of various region sizes. We also\npre-define several static routing regions with different pin density and number\nof nets for easier learning and testing. For net ordering task, we report\nbaseline results for two widely used reinforcement learning algorithms (PPO and\nDQN) and one searching-based algorithm (TritonRoute). The XRoute Environment\nwill be available at https://github.com/xplanlab/xroute_env.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:46:25 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 07:53:23 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13824","submitter":"Chengpeng Hu","authors":"Chengpeng Hu, Ziming Wang, Jialin Liu, Junyi Wen, Bifei Mao, Xin Yao","title":"Constrained Reinforcement Learning for Dynamic Material Handling","comments":"accepted by the 2023 International Joint Conference on Neural\n  Networks (IJCNN)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As one of the core parts of flexible manufacturing systems, material handling\ninvolves storage and transportation of materials between workstations with\nautomated vehicles. The improvement in material handling can impulse the\noverall efficiency of the manufacturing system. However, the occurrence of\ndynamic events during the optimisation of task arrangements poses a challenge\nthat requires adaptability and effectiveness. In this paper, we aim at the\nscheduling of automated guided vehicles for dynamic material handling.\nMotivated by some real-world scenarios, unknown new tasks and unexpected\nvehicle breakdowns are regarded as dynamic events in our problem. We formulate\nthe problem as a constrained Markov decision process which takes into account\ntardiness and available vehicles as cumulative and instantaneous constraints,\nrespectively. An adaptive constrained reinforcement learning algorithm that\ncombines Lagrangian relaxation and invalid action masking, named RCPOM, is\nproposed to address the problem with two hybrid constraints. Moreover, a\ngym-like dynamic material handling simulator, named DMH-GYM, is developed and\nequipped with diverse problem instances, which can be used as benchmarks for\ndynamic material handling. Experimental results on the problem instances\ndemonstrate the outstanding performance of our proposed approach compared with\neight state-of-the-art constrained and non-constrained reinforcement learning\nalgorithms, and widely used dispatching rules for material handling.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:48:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13825","submitter":"Peiyan Zhang","authors":"Peiyan Zhang, Yuchen Yan, Chaozhuo Li, Senzhang Wang, Xing Xie, Guojie\n  Song, Sunghun Kim","title":"Continual Learning on Dynamic Graphs via Parameter Isolation","comments":null,"journal-ref":null,"doi":"10.1145/3539618.3591652","report-no":null,"categories":"cs.LG cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many real-world graph learning tasks require handling dynamic graphs where\nnew nodes and edges emerge. Dynamic graph learning methods commonly suffer from\nthe catastrophic forgetting problem, where knowledge learned for previous\ngraphs is overwritten by updates for new graphs. To alleviate the problem,\ncontinual graph learning methods are proposed. However, existing continual\ngraph learning methods aim to learn new patterns and maintain old ones with the\nsame set of parameters of fixed size, and thus face a fundamental tradeoff\nbetween both goals. In this paper, we propose Parameter Isolation GNN (PI-GNN)\nfor continual learning on dynamic graphs that circumvents the tradeoff via\nparameter isolation and expansion. Our motivation lies in that different\nparameters contribute to learning different graph patterns. Based on the idea,\nwe expand model parameters to continually learn emerging graph patterns.\nMeanwhile, to effectively preserve knowledge for unaffected patterns, we find\nparameters that correspond to them via optimization and freeze them to prevent\nthem from being rewritten. Experiments on eight real-world datasets corroborate\nthe effectiveness of PI-GNN compared to state-of-the-art baselines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:49:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13826","submitter":"Zae Myung Kim","authors":"Zae Myung Kim, David E. Taylor, Dongyeop Kang","title":"\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to\n  Understanding Conversational Implicatures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Conversational implicatures are pragmatic inferences that require listeners\nto deduce the intended meaning conveyed by a speaker from their explicit\nutterances. Although such inferential reasoning is fundamental to human\ncommunication, recent research indicates that large language models struggle to\ncomprehend these implicatures as effectively as the average human. This paper\ndemonstrates that by incorporating Grice's Four Maxims into the model through\nchain-of-thought prompting, we can significantly enhance its performance,\nsurpassing even the average human performance on this task.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:49:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13827","submitter":"Mohsen Rahmani Haghighi","authors":"Mohammad Hossein Zarei and Mohsen Rahmani Haghighi","title":"Layer-by-layer disentangling two-dimensional topological quantum codes","comments":"9 pages, 9 figures, submitted to PRB","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  While local unitary transformations are used for identifying quantum states\nwhich are in the same topological class, non-local unitary transformations are\nalso important for studying the transition between different topological\nclasses. In particular, it is an important task to find suitable non-local\ntransformations that systematically sweep different topological classes. Here,\nregarding the role of dimension in the topological classes, we introduce\npartially local unitary transformations namely Greenberger-Horne-Zeilinger\n(GHZ) disentanglers which reduce the dimension of the initial topological model\nby a layer-by-layer disentangling mechanism. We apply such disentanglers to\ntwo-dimensional (2D) topological quantum codes and show that they are converted\nto many copies of Kitaev's ladders. It implies that the GHZ disentangler causes\na transition from an intrinsic topological phase to a symmetry-protected\ntopological phase. Then, we show that while Kitaev's ladders are building\nblocks of both color code and toric code, there are different patterns of\nentangling ladders in 2D color code and toric code. It shows that different\ntopological features of these topological codes are reflected in different\npatterns of entangling ladders. In this regard, we propose that the\nlayer-by-layer disentangling mechanism can be used as a systematic method for\nclassification of topological orders based on finding different patterns of the\nlong-range entanglement in topological lattice models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:49:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13828","submitter":"Lev Vaidman","authors":"Lev Vaidman","title":"Comment on \"Weak values and the past of a quantum particle\"","comments":"Comment on arXiv:2109.14060v5","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In a recent paper, Hance, Rarity and Ladyman [Phys. Rev. Res. {\\bf 5}, 023048\n(2023)] criticized recent proposals connecting weak values and the past of a\nquantum particle. I argue that their conclusion follows from a conceptual error\nin understanding the approach to the past of the particle they discuss.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:50:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13829","submitter":"Danqing Wang","authors":"Danqing Wang, Lei Li","title":"Learn from Mistakes through Cooperative Interaction with Study Assistant","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models have demonstrated their ability to self-reflect and\nrefine their generation, which can further improve their performance. However,\nthis feedback mechanism faces challenges such as no guarantee of correctness\nand the lack of global insight into the model's weaknesses. In this paper, we\npropose a novel framework, Study Assistant for Large Language Model (SALAM), to\naid LLMs in the reflection and refinement process. Motivated by the human study\nassistant, this framework grades previous responses with the ground truth and\ncollects mistakes in the training phase. During inference, it identifies common\nmisunderstandings based on the mistake collections and provides guidelines for\nthe model to help the model avoid similar mistakes during inference. SALAM is a\nmodel-agnostic framework, focusing on providing general feedback and can adapt\nto any base model. Our evaluation of SALAM on two challenging benchmarks\ndemonstrated a significant improvement over various baselines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:51:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13830","submitter":"Daiki Saito","authors":"Daiki Saito, Tomohiro Harada, Yasutaka Koga and Chul-Moon Yoo","title":"Spins of primordial black holes formed with a soft equation of state","comments":"20 pages, 6 figures, references added","journal-ref":null,"doi":null,"report-no":"RUP-23-11","categories":"gr-qc astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the probability distribution of the spins of primordial black\nholes (PBHs) formed in the universe dominated by a perfect fluid with the\nlinear equation of state $p=w\\rho$, where $p$ and $\\rho$ are the pressure and\nenergy density of the fluid, respectively. We particularly focus on the\nparameter region $0<w\\leq 1/3$ since the larger value of the spin is expected\nfor the softer equation of state than that of the radiation fluid ($w=1/3$).\nThe angular momentum inside the collapsing region is estimated based on the\nlinear perturbation equation at the turn-around time which we define as the\ntime when the linear velocity perturbation in the conformal Newtonian gauge\ntakes the minimum value. The probability distribution is derived based on the\npeak theory with the Gaussian curvature perturbation. We find that the root\nmean square of the non-dimensional Kerr parameter $\\sqrt{\\langle\na_{*}^2\\rangle}$ is approximately proportional to\n$(M/M_{H})^{-1/3}(6w)^{-(1+2w)/(1+3w)}$, where $M$ and $M_{H}$ are the mass of\nthe PBH and the horizon mass at the horizon entry, respectively. Therefore the\ntypical value of the spin parameter decreases with the value of $w$. We also\nevaluate the mass and spin distribution $P(a_{*}, M)$, taking account of the\ncritical phenomena. We find that, while the spin is mostly distributed in the\nrange of $10^{-3.9}\\leq a_{*}\\leq 10^{-1.8}$ for the radiation-dominated\nuniverse, the peak of the spin distribution is shifted to the larger range\n$10^{-3.0}\\leq a_{*}\\leq 10^{-0.7}$ for $w=10^{-3}$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:51:14 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 03:18:30 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13831","submitter":"Wooseok Han","authors":"Minki Kang, Wooseok Han, Sung Ju Hwang, Eunho Yang","title":"ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech\n  Synthesis with Diffusion and Style-based Models","comments":"Accepted by INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Emotional Text-To-Speech (TTS) is an important task in the development of\nsystems (e.g., human-like dialogue agents) that require natural and emotional\nspeech. Existing approaches, however, only aim to produce emotional TTS for\nseen speakers during training, without consideration of the generalization to\nunseen speakers. In this paper, we propose ZET-Speech, a zero-shot adaptive\nemotion-controllable TTS model that allows users to synthesize any speaker's\nemotional speech using only a short, neutral speech segment and the target\nemotion label. Specifically, to enable a zero-shot adaptive TTS model to\nsynthesize emotional speech, we propose domain adversarial learning and\nguidance methods on the diffusion model. Experimental results demonstrate that\nZET-Speech successfully synthesizes natural and emotional speech with the\ndesired emotion for both seen and unseen speakers. Samples are at\nhttps://ZET-Speech.github.io/ZET-Speech-Demo/.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:52:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13832","submitter":"Victor Guadilla","authors":"V. Guadilla, A. Algora, M. Estienne, M. Fallot, W. Gelletly, A. Porta,\n  L.-M. Rigalleau, J.-S. Stutzmann","title":"First measurements with a new $\\beta$-electron detector for spectral\n  shape studies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det nucl-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The shape of the spectrum corresponding to the electrons emitted in $\\beta$\ndecay carries a wealth of information about nuclear structure and fundamental\nphysics. In spite of that, few dedicated measurements have been made of\n$\\beta$-spectrum shapes. In this work we present a newly developed detector for\n$\\beta$ electrons based on a telescope concept. A thick plastic scintillator is\nemployed in coincidence with a thin silicon detector. First measurements\nemploying this detector have been carried out with mono-energetic electrons\nfrom the high-energy resolution electron-beam spectrometer at Bordeaux. Here we\nreport on the good reproduction of the experimental spectra of mono-energetic\nelectrons using Monte Carlo simulations. This is a crucial step for future\nexperiments, where a detailed Monte Carlo characterization of the detector is\nneeded to determine the shape of the $\\beta$-electron spectra by deconvolution\nof the measured spectra with the response function of the detector. A chamber\nto contain two telescope assemblies has been designed for future $\\beta$-decay\nexperiments at the Ion Guide Isotope Separator On-Line facility in\nJyv\\\"askyl\\\"a, aimed at improving our understanding of reactor antineutrino\nspectra.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:52:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13833","submitter":"Qi Jia","authors":"Qi Jia, Haifeng Tang, Kenny Q. Zhu","title":"Reducing Sensitivity on Speaker Names for Text Generation from Dialogues","comments":"findings of ACL'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Changing speaker names consistently throughout a dialogue should not affect\nits meaning and corresponding outputs for text generation from dialogues.\nHowever, pre-trained language models, serving as the backbone for\ndialogue-processing tasks, have shown to be sensitive to nuances. This may\nresult in unfairness in real-world applications. No comprehensive analysis of\nthis problem has been done in the past. In this work, we propose to\nquantitatively measure a model's sensitivity on speaker names, and\ncomprehensively evaluate a number of known methods for reducing speaker name\nsensitivity, including a novel approach of our own. Extensive experiments on\nmultiple datasets provide a benchmark for this problem and show the favorable\nperformance of our approach in sensitivity reduction and quality of generation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:53:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13834","submitter":"Joaquin Gonzalez-Nuevo","authors":"J. Gonz\\'alez-Nuevo, L. Bonavera, M. M. Cueli, D. Crespo and J. M.\n  Casas","title":"Methodological refinement of the submillimeter galaxy magnification\n  bias. Paper I: cross-correlation function measurements","comments":"This work is the first one of a three-paper serie. 14 pages, 9\n  figures, submitted for publication by A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The measurement of the cross-correlation function is crucial to assess\nmagnification bias in galaxy surveys. Previous works used mini-tile\nsubsampling, but accurately determining the integral constraint (IC) correction\nfor unbiased estimation is challenging due to various factors. We present a new\nmethodology for estimating the cross-correlation function, utilizing full field\narea and reducing statistical uncertainty. Covariance matrices were estimated\nby dividing each field into at least five patches using a k-mean clustering\nalgorithm. Robustness was assessed by comparing spectroscopic and photometric\nlens samples, yielding compatible results. Cross-correlation and\nauto-correlation analyses in the GAMA fields revealed a stronger signal in\nGAMA15, likely due to rare large-scale structure combinations. Our findings\nhighlight the robustness of the new methodology and suggest sample-specific\neffects. Subsequent papers in this series will explore other aspects of\nmagnification bias and address potential biases from the GAMA15 signal on\ncosmological parameter constraints.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:55:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13835","submitter":"Marcos Mu\\~niz Cueli","authors":"Marcos M. Cueli, Joaqu\\'in Gonz\\'alez-Nuevo, Laura Bonavera, Andrea\n  Lapi, David Crespo and Jos\\'e Manuel Casas","title":"Methodological refinement of the submillimeter galaxy magnification\n  bias. Paper iI: cosmological analysis with a single redshift bin","comments":"This work is the second one of a three-paper series. Submitted to A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The main goal of this work, the second in a three-paper series, is to test\nthe impact of a methodological improvement in measuring the magnification bias\nsignal on a sample of submillimeter galaxies and its implications for\nconstraining cosmological parameters. The analysis considers the angular\ncross-correlation function between a foreground sample of GAMA galaxies\n($0.2<z<0.8$) and a background sample of H-ATLAS submillimeter galaxies\n($1.2<z<4.0$). A refined methodology, discussed extensively in Paper I, is\nused. By interpreting the weak lensing signal within the halo model and\nemploying an MCMC algorithm, the posterior distribution of the halo occupation\ndistribution (HOD) and cosmological parameters is obtained for a flat\n$\\Lambda$CDM model. The analysis incorporates the foreground angular\nauto-correlation function to account for galaxy clustering. The results\ndemonstrate a remarkable improvement in uncertainties for both HOD and\ncosmological parameters compared to previous studies. However, when using the\ncross-correlation data alone, the estimation of $\\sigma_8$ depends on prior\nknowledge of $\\beta$, the logarithmic slope of the background number counts.\nAssuming a physically motivated prior distribution for $\\beta$, mean values of\n$\\Omega_m=0.18^{+0.03}{-0.03}$ and $\\sigma_8=1.04^{+0.11}{-0.07}$ are obtained.\nThese results may however be subject to an inherent bias in the data due to\nanomalous behavior observed in the G15 field. After excluding the G15 region,\nthe mean values shift to $\\Omega_m=0.30^{+0.05}{-0.06}$ and\n$\\sigma_8=0.92^{+0.07}{-0.07}$. This becomes more apparent when adding the\nclustering of the foreground sample, but the dependence on $\\beta$ information\ndisappears, mitigating the aforementioned issue. Excluding the G15 region, the\njoint analysis yields mean values of $\\Omega_m=0.36^{+0.03}{-0.07}$,\n$\\sigma_8=0.90^{+0.03}{-0.03}$, and $h=0.76^{+0.14}_{-0.14}$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:55:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13836","submitter":"Laura Bonavera","authors":"L. Bonavera, M. M. Cueli, J. Gonz\\'alez-Nuevo, J. M. Casas, D. Crespo","title":"Methodological refinement of the submillimeter galaxy magnification\n  bias. Paper III: cosmological analysis with tomography","comments":"This work is the third of a series of three. 17 pages and 19 figure.\n  submitted to A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is the third in a series on submillimeter galaxy magnification\nbias, focusing on the tomographic scenario. It refines the methodology used to\nconstrain the halo occupation distribution model and cosmological parameters\nwithin a flat $\\Lambda$CDM model, using updated data. The study aims to\noptimize CPU time, explore strategies for analyzing different redshift bins,\nand assess the impact of excluding the GAMA15 field. The tomographic approach\ninvolves dividing the redshift range into bins and analyzing cross-correlation\nmeasurements between submillimeter and foreground galaxies. The results show\ngood agreement between the mean-redshift and full model cases, with an increase\nin the minimum mass of lenses at higher redshifts. The inferred cosmological\nparameters have narrower posterior distributions, indicating reduced\nmeasurement uncertainties compared to previous studies. Excluding the GAMA15\nfield reduces the cross-correlation signal, suggesting sample variance within\nthe large-scale structure. Extending the redshift range improves robustness\nagainst sample variance and produces similar but tighter constraints. The study\nhighlights the importance of sample variance and redshift binning in\ntomographic analyses, and suggests using additional wide-area fields and\nupdated foreground catalogues for more effective implementation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:55:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13837","submitter":"Jiaming Zheng","authors":"John Ellis, Natsumi Nagata, Keith A. Olive, Jiaming Zheng","title":"Electroweak Loop Contributions to the Direct Detection of Wino Dark\n  Matter","comments":"27 pages, 9 figures","journal-ref":null,"doi":null,"report-no":"KCL-PH-TH/2023-27, CERN-PH-TH-2023-083, FTPI-MINN-23/08,\n  UMN-TH-4214/23","categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electroweak loop corrections to the matrix elements for the spin-independent\nscattering of cold dark matter particles on nuclei are generally small,\ntypically below the uncertainty in the local density of cold dark matter.\nHowever, as shown in this paper, there are instances in which the electroweak\nloop corrections are relatively large, and change significantly the\nspin-independent dark matter scattering rate. An important example occurs when\nthe dark matter particle is a wino, e.g., in anomaly-mediated supersymmetry\nbreaking (AMSB) and pure gravity mediation (PGM) models. We find that the\none-loop electroweak corrections to the spin-independent wino LSP scattering\ncross section generally interfere constructively with the tree-level\ncontribution for AMSB models with negative Higgsino mixing, $\\mu < 0$, and in\nPGM-like models for both signs of $\\mu$, lifting the cross section out of the\nneutrino fog and into a range that is potentially detectable in the next\ngeneration of direct searches for cold dark matter scattering.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:59:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13838","submitter":"Francesco Pavese","authors":"Francesco Pavese","title":"On 4-general sets in finite projective spaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A $4$-general set in ${\\rm PG}(n,q)$ is a set of points of ${\\rm PG}(n,q)$\nspanning the whole ${\\rm PG}(n,q)$ and such that no four of them are on a\nplane. Such a pointset is said to be complete if it is not contained in a\nlarger $4$-general set of ${\\rm PG}(n, q)$. In this paper upper and lower\nbounds for the size of the largest and the smallest complete $4$-general set in\n${\\rm PG}(n,q)$, respectively, are investigated. Complete $4$-general sets in\n${\\rm PG}(n,q)$, $q \\in \\{3,4\\}$, whose size is close to the theoretical upper\nbound are provided. Further results are also presented, including a description\nof the complete $4$-general sets in projective spaces of small dimension over\nsmall fields and the construction of a transitive $4$-general set of size $3(q\n+ 1)$ in ${\\rm PG}(5, q)$, $q \\equiv 1 \\pmod{3}$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:01:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13839","submitter":"Jiamin Xu","authors":"Mingjin Zhang, Jiamin Xu, Chengyu He, Wenteng Shang, Yunsong Li, and\n  Xinbo Gao","title":"SAR-to-Optical Image Translation via Thermodynamics-inspired Network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Synthetic aperture radar (SAR) is prevalent in the remote sensing field but\nis difficult to interpret in human visual perception. Recently, SAR-to-optical\n(S2O) image conversion methods have provided a prospective solution for\ninterpretation. However, since there is a huge domain difference between\noptical and SAR images, they suffer from low image quality and geometric\ndistortion in the produced optical images. Motivated by the analogy between\npixels during the S2O image translation and molecules in a heat field,\nThermodynamics-inspired Network for SAR-to-Optical Image Translation (S2O-TDN)\nis proposed in this paper. Specifically, we design a Third-order Finite\nDifference (TFD) residual structure in light of the TFD equation of\nthermodynamics, which allows us to efficiently extract inter-domain invariant\nfeatures and facilitate the learning of the nonlinear translation mapping. In\naddition, we exploit the first law of thermodynamics (FLT) to devise an\nFLT-guided branch that promotes the state transition of the feature values from\nthe unstable diffusion state to the stable one, aiming to regularize the\nfeature diffusion and preserve image structures during S2O image translation.\nS2O-TDN follows an explicit design principle derived from thermodynamic theory\nand enjoys the advantage of explainability. Experiments on the public SEN1-2\ndataset show the advantages of the proposed S2O-TDN over the current methods\nwith more delicate textures and higher quantitative results.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:02:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13840","submitter":"Weifeng Chen","authors":"Weifeng Chen, Jie Wu, Pan Xie, Hefeng Wu, Jiashi Li, Xin Xia, Xuefeng\n  Xiao, Liang Lin","title":"Control-A-Video: Controllable Text-to-Video Generation with Diffusion\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG cs.MM","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper presents a controllable text-to-video (T2V) diffusion model, named\nVideo-ControlNet, that generates videos conditioned on a sequence of control\nsignals, such as edge or depth maps. Video-ControlNet is built on a pre-trained\nconditional text-to-image (T2I) diffusion model by incorporating a\nspatial-temporal self-attention mechanism and trainable temporal layers for\nefficient cross-frame modeling. A first-frame conditioning strategy is proposed\nto facilitate the model to generate videos transferred from the image domain as\nwell as arbitrary-length videos in an auto-regressive manner. Moreover,\nVideo-ControlNet employs a novel residual-based noise initialization strategy\nto introduce motion prior from an input video, producing more coherent videos.\nWith the proposed architecture and strategies, Video-ControlNet can achieve\nresource-efficient convergence and generate superior quality and consistent\nvideos with fine-grained control. Extensive experiments demonstrate its success\nin various video generative tasks such as video editing and video style\ntransfer, outperforming previous methods in terms of consistency and quality.\nProject Page: https://controlavideo.github.io/\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:03:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13841","submitter":"Juan Montes","authors":"Juan Montes Maestre, Yinwei Du, Ronan Hinchet, Stelian Coros, Bernhard\n  Thomaszewski","title":"Differentiable Stripe Patterns for Inverse Design of Structured Surfaces","comments":"14 pages","journal-ref":null,"doi":"10.1145/3592114","report-no":null,"categories":"cs.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stripe patterns are ubiquitous in nature and everyday life. While the\nsynthesis of these patterns has been thoroughly studied in the literature,\ntheir potential to control the mechanics of structured materials remains\nlargely unexplored. In this work, we introduce Differentiable Stripe Patterns\n-- a computational approach for automated design of physical surfaces\nstructured with stripe-shaped bi-material distributions. Our method builds on\nthe work by Knoppel and colleagues for generating globally-continuous and\nequally-spaced stripe patterns. To unlock the full potential of this design\nspace, we propose a gradient-based optimization tool to automatically compute\nstripe patterns that best approximate macromechanical performance goals.\nSpecifically, we propose a computational model that combines solid shell finite\nelements with XFEM for accurate and fully-differentiable modeling of elastic\nbi-material surfaces. To resolve non-uniqueness problems in the original\nmethod, we furthermore propose a robust formulation that yields unique and\ndifferentiable stripe patterns. %Finally, we introduce design space\nregularizers to avoid numerical singularities and improve stripe neatness We\ncombine these components with equilibrium state derivatives into an end-to-end\ndifferentiable pipeline that enables inverse design of mechanical stripe\npatterns. We demonstrate our method on a diverse set of examples that\nillustrate the potential of stripe patterns as a design space for structured\nmaterials. Our simulation results are experimentally validated on physical\nprototypes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:05:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13842","submitter":"Li-Xin Zhang","authors":"Li-Xin Zhang","title":"Asymptotic Properties of Multi-Treatment Covariate Adaptive\n  Randomization Procedures for Balancing Observed and Unobserved Covariates","comments":"102 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Applications of CAR for balancing continuous covariates remain comparatively\nrare, especially in multi-treatment clinical trials, and the theoretical\nproperties of multi-treatment CAR have remained largely elusive for decades. In\nthis paper, we consider a general framework of CAR procedures for\nmulti-treatment clinal trials which can balance general covariate features,\nsuch as quadratic and interaction terms which can be discrete, continuous, and\nmixing. We show that under widely satisfied conditions the proposed procedures\nhave superior balancing properties; in particular, the convergence rate of\nimbalance vectors can attain the best rate $O_P(1)$ for discrete covariates,\ncontinuous covariates, or combinations of both discrete and continuous\ncovariates, and at the same time, the convergence rate of the imbalance of\nunobserved covariates is $O_P(\\sqrt n)$, where $n$ is the sample size. The\ngeneral framework unifies many existing methods and related theories,\nintroduces a much broader class of new and useful CAR procedures, and provides\nnew insights and a complete picture of the properties of CAR procedures. The\nfavorable balancing properties lead to the precision of the treatment effect\ntest in the presence of a heteroscedastic linear model with dependent covariate\nfeatures. As an application, the properties of the test of treatment effect\nwith unobserved covariates are studied under the CAR procedures, and consistent\ntests are proposed so that the test has an asymptotic precise type I error even\nif the working model is wrong and covariates are unobserved in the analysis.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:06:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13843","submitter":"Mingzhu Zhang","authors":"Mingzhu Zhang, Ruiping Yin, Zhen Yang, Yipeng Wang and Kan Li","title":"Advances and Challenges of Multi-task Learning Method in Recommender\n  System: A Survey","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-task learning has been widely applied in computational vision, natural\nlanguage processing and other fields, which has achieved well performance. In\nrecent years, a lot of work about multi-task learning recommender system has\nbeen yielded, but there is no previous literature to summarize these works. To\nbridge this gap, we provide a systematic literature survey about multi-task\nrecommender systems, aiming to help researchers and practitioners quickly\nunderstand the current progress in this direction. In this survey, we first\nintroduce the background and the motivation of the multi-task learning-based\nrecommender systems. Then we provide a taxonomy of multi-task learning-based\nrecommendation methods according to the different stages of multi-task learning\ntechniques, which including task relationship discovery, model architecture and\noptimization strategy. Finally, we raise discussions on the application and\npromising future directions in this area.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:07:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13844","submitter":"Shohei Higashiyama","authors":"Shohei Higashiyama, Hiroki Ouchi, Hiroki Teranishi, Hiroyuki Otomo,\n  Yusuke Ide, Aitaro Yamamoto, Hiroyuki Shindo, Yuki Matsuda, Shoko Wakamiya,\n  Naoya Inoue, Ikuya Yamada, Taro Watanabe","title":"Arukikata Travelogue Dataset with Geographic Entity Mention,\n  Coreference, and Link Annotation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Geoparsing is a fundamental technique for analyzing geo-entity information in\ntext. We focus on document-level geoparsing, which considers geographic\nrelatedness among geo-entity mentions, and presents a Japanese travelogue\ndataset designed for evaluating document-level geoparsing systems. Our dataset\ncomprises 200 travelogue documents with rich geo-entity information: 12,171\nmentions, 6,339 coreference clusters, and 2,551 geo-entities linked to\ngeo-database entries.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:07:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13845","submitter":"Richard Forbes","authors":"Richard G. Forbes, Sergey V. Filippov, Anatoly G. Kolosko, Eugeni O.\n  Popov","title":"Progress on the journey to put field electron emission onto a better\n  scientific basis","comments":"3 pages, 6 tables, 1 figure. Conference paper for IVNC2023 in Boston,\n  Mass., July 2023. To be published electronically by IEEE Explore","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph physics.acc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper forms part of a long-term project to put field electron emission\n(FE) onto a better scientific basis, by seeking reliable quantitative agreement\nbetween theory and experiment, especially as regards emission-current values.\nThe main paper aims are: (1) to respond to remarks made in recent papers; (2)\nto restate the thinking behind our 2022 methodology for choosing between\ndifferent FE models using experiments; (3) to assess progress; and (4) to make\nfurther suggestions about improved approaches.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:07:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13846","submitter":"Francesco Capolupo","authors":"Francesco Capolupo and Antonio Rinalducci","title":"Descent & Landing Trajectory and Guidance Algorithms with Divert\n  Capabilities for Moon Landing","comments":"To be submitted to AIAA for possible publication","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents the preliminary design of the descent and landing\ntrajectory of the ESA Argonaut lunar lander. The mission scenario and driving\nsystem constraints are presented and accounted for in the design of a\nfuel-optimal trajectory that includes divert capabilities, as required to\nachieve a safe landing. A sub-optimal descent and landing trajectory is then\npresented and computed from the optimal one, and the related on-board guidance\nalgorithms are derived. The proposed end-to-end guidance solution represents an\neasily implementable alternative to on-board optimization, minimizing the\nverification & validation effort, computational footprint, and programmatic\nrisk in the development of the related GN&C capabilities. A dedicated off-line\noptimization process is also outlined, and exploited to optimize the propellant\nconsumption of the sub-optimal trajectory and to ensure the fulfillment of\nsystem constraints despite the use of simple algorithms on-board. The\nsub-optimal trajectory is compared to the optimal baseline, and conclusions are\ndrawn on the applicability of the proposed approach to the Argonaut mission.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:10:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13847","submitter":"Henry von Wahl","authors":"Sabine Hittmeir and Philip L. Lederer and Joachim Sch\\\"oberl and Henry\n  von Wahl","title":"A discontinuous Galerkin approach for atmospheric flows with implicit\n  condensation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a discontinuous Galerkin method for moist atmospheric dynamics,\nwith and without warm rain. By considering a combined density for water vapour\nand cloud water, we avoid the need to model and compute a source term for\ncondensation. We recover the vapour and cloud densities by solving a pointwise\nnon-linear problem each time step. Consequently, we enforce the requirement for\nthe water vapour not to be supersaturated implicitly. Together with an explicit\ntime-stepping scheme, the method is highly parallelisable and can utilise\nhigh-performance computing hardware. Furthermore, the discretisation works on\nstructured and unstructured meshes in two and three spatial dimensions. We\nillustrate the performance of our approach using several test cases in two and\nthree spatial dimensions. In the case of a smooth, exact solution, we\nillustrate the optimal higher-order convergence rates of the method.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:11:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13848","submitter":"Amir Fern\\'andez Ouaridi Phd","authors":"Amir Fern\\'andez Ouaridi","title":"On the simple transposed Poisson algebras and Jordan superalgebras","comments":"10 pages, added references, added Theorem 30, minor typos corrected","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that a transposed Poisson algebra is simple if and only if its\nassociated Lie bracket is simple. Consequently, any simple finite-dimensional\ntransposed Poisson algebra over an algebraically closed field of characteristic\nzero is trivial. Similar results are obtained for transposed Poisson\nsuperalgebras. Furthermore, we show that the Kantor double of a transposed\nPoisson algebra is a Jordan superalgebra. Additionally, a simplicity criterion\nfor the Kantor double of a transposed Poisson algebra is obtained.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:14:38 GMT"},{"version":"v2","created":"Sun, 28 May 2023 23:07:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13849","submitter":"Aishwarya Venkataramanan","authors":"Aishwarya Venkataramanan, Assia Benbihi, Martin Laviale, Cedric\n  Pradalier","title":"Self-Supervised Gaussian Regularization of Deep Classifiers for\n  Mahalanobis-Distance-Based Uncertainty Estimation","comments":"24 pages including supplementary material","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent works show that the data distribution in a network's latent space is\nuseful for estimating classification uncertainty and detecting\nOut-of-distribution (OOD) samples. To obtain a well-regularized latent space\nthat is conducive for uncertainty estimation, existing methods bring in\nsignificant changes to model architectures and training procedures. In this\npaper, we present a lightweight, fast, and high-performance regularization\nmethod for Mahalanobis distance-based uncertainty prediction, and that requires\nminimal changes to the network's architecture. To derive Gaussian latent\nrepresentation favourable for Mahalanobis Distance calculation, we introduce a\nself-supervised representation learning method that separates in-class\nrepresentations into multiple Gaussians. Classes with non-Gaussian\nrepresentations are automatically identified and dynamically clustered into\nmultiple new classes that are approximately Gaussian. Evaluation on standard\nOOD benchmarks shows that our method achieves state-of-the-art results on OOD\ndetection with minimal inference time, and is very competitive on predictive\nprobability calibration. Finally, we show the applicability of our method to a\nreal-life computer vision use case on microorganism classification.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:18:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13850","submitter":"Xiangnan Chen","authors":"Xiangnan Chen, Juncheng Li, Duo Dong, Qian Xiao, Jun Lin, Xiaozhong\n  Liu, Siliang Tang","title":"Global Structure Knowledge-Guided Relation Extraction Method for\n  Visually-Rich Document","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Visual relation extraction (VRE) aims to extract relations between entities\nfrom visuallyrich documents. Existing methods usually predict relations for\neach entity pair independently based on entity features but ignore the global\nstructure information, i.e., dependencies between entity pairs. The absence of\nglobal structure information may make the model struggle to learn long-range\nrelations and easily predict conflicted results. To alleviate such limitations,\nwe propose a GlObal Structure knowledgeguided relation Extraction (GOSE)\nframework, which captures dependencies between entity pairs in an iterative\nmanner. Given a scanned image of the document, GOSE firstly generates\npreliminary relation predictions on entity pairs. Secondly, it mines global\nstructure knowledge based on prediction results of the previous iteration and\nfurther incorporates global structure knowledge into entity representations.\nThis \"generate-capture-incorporate\" schema is performed multiple times so that\nentity representations and global structure knowledge can mutually reinforce\neach other. Extensive experiments show that GOSE not only outperforms previous\nmethods on the standard fine-tuning setting but also shows promising\nsuperiority in cross-lingual learning; even yields stronger data-efficient\nperformance in the low-resource setting.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:18:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13851","submitter":"Arman Korajac","authors":"Svjetlana Fajfer, Jernej Fesel Kamenik, Arman Korajac, Nejc Ko\\v{s}nik","title":"Correlating New Physics Effects in Semileptonic $\\Delta C = 1$ and\n  $\\Delta S = 1$ Processes","comments":"18 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present constraints on the left-handed dimension-6 interactions that\ncontribute to semileptonic and leptonic decays of $K$, $D$, pions and to\nnuclear beta decay. We employ the flavour covariant description of the\neffective couplings, identify universal CP phases of New Physics and derive\nconstraints from decay rates and CP-odd quantities. As a result, we can predict\nthe maximal effects of such flavoured NP in $D$ decays from stringent $K$ decay\nconstraints and vice-versa.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:18:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13852","submitter":"Bin Yang","authors":"Bin Yang, Xingche Guo, Ji Meng Loh, Qinxia Wang, Yuanjia Wang","title":"Learning Optimal Biomarker-Guided Treatment Policy for Chronic Disorders","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electroencephalogram (EEG) provides noninvasive measures of brain activity\nand is found to be valuable for diagnosis of some chronic disorders.\nSpecifically, pre-treatment EEG signals in alpha and theta frequency bands have\ndemonstrated some association with anti-depressant response, which is\nwell-known to have low response rate. We aim to design an integrated pipeline\nthat improves the response rate of major depressive disorder patients by\ndeveloping an individualized treatment policy guided by the resting state\npre-treatment EEG recordings and other treatment effects modifiers. We first\ndesign an innovative automatic site-specific EEG preprocessing pipeline to\nextract features that possess stronger signals compared with raw data. We then\nestimate the conditional average treatment effect using causal forests, and use\na doubly robust technique to improve the efficiency in the estimation of the\naverage treatment effect. We present evidence of heterogeneity in the treatment\neffect and the modifying power of EEG features as well as a significant average\ntreatment effect, a result that cannot be obtained by conventional methods.\nFinally, we employ an efficient policy learning algorithm to learn an optimal\ndepth-2 treatment assignment decision tree and compare its performance with\nQ-Learning and outcome-weighted learning via simulation studies and an\napplication to a large multi-site, double-blind randomized controlled clinical\ntrial, EMBARC.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:20:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13853","submitter":"Linjie Zhao","authors":"Cl\\'ement Erignoux and Linjie Zhao","title":"Stationary fluctuations for the facilitated exclusion process","comments":"38pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We derive the stationary fluctuations for the Facilitated Exclusion Process\n(FEP) in one dimension in the symmetric, weakly asymmetric and asymmetric\ncases. Our proof relies on the mapping between the FEP and the zero-range\nprocess, and extends the strategy in \\cite{erignoux2022mapping}, where\nhydrodynamic limits were derived for the FEP, to its stationary fluctuations.\nOur results thus exploit works on the zero-range process's fluctuations\n\\cite{gonccalves2010equilibrium,gonccalves2015stochastic}, but we also provide\na direct proof in the symmetric case, for which we derive a sharp estimate on\nthe equivalence of ensembles for the FEP's stationary states.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:21:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13854","submitter":"Jana Vatter","authors":"Jana Vatter, Ruben Mayer, Hans-Arno Jacobsen","title":"The Evolution of Distributed Systems for Graph Neural Networks and their\n  Origin in Graph Processing and Deep Learning: A Survey","comments":"Accepted at ACM Computing Surveys","journal-ref":null,"doi":"10.1145/3597428","report-no":null,"categories":"cs.DC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph Neural Networks (GNNs) are an emerging research field. This specialized\nDeep Neural Network (DNN) architecture is capable of processing graph\nstructured data and bridges the gap between graph processing and Deep Learning\n(DL). As graphs are everywhere, GNNs can be applied to various domains\nincluding recommendation systems, computer vision, natural language processing,\nbiology and chemistry. With the rapid growing size of real world graphs, the\nneed for efficient and scalable GNN training solutions has come. Consequently,\nmany works proposing GNN systems have emerged throughout the past few years.\nHowever, there is an acute lack of overview, categorization and comparison of\nsuch systems. We aim to fill this gap by summarizing and categorizing important\nmethods and techniques for large-scale GNN solutions. In addition, we establish\nconnections between GNN systems, graph processing systems and DL systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:22:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13855","submitter":"Yanling Chi","authors":"Chi Yanling, Xu Yuyu, Liu Huiying, Wu Xiaoxiang, Liu Zhiqiang, Mao\n  Jiawei, Xu Guibin, Huang Weimin","title":"KidneyRegNet: A Deep Learning Method for 3DCT-2DUS Kidney Registration\n  during Breathing","comments":"15 pages, 8 figures, 9 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This work proposed a novel deep registration pipeline for 3D CT and 2D U/S\nkidney scans of free breathing, which consists of a feature network, and a\n3D-2D CNN-based registration network. The feature network has handcraft texture\nfeature layers to reduce the semantic gap. The registration network is\nencoder-decoder structure with loss of feature-image-motion (FIM), which\nenables hierarchical regression at decoder layers and avoids multiple network\nconcatenation. It was first pretrained with retrospective datasets cum training\ndata generation strategy, then adapted to specific patient data under\nunsupervised one-cycle transfer learning in onsite application. The experiment\nwas on 132 U/S sequences, 39 multiple phase CT and 210 public single phase CT\nimages, and 25 pairs of CT and U/S sequences. It resulted in mean contour\ndistance (MCD) of 0.94 mm between kidneys on CT and U/S images and MCD of 1.15\nmm on CT and reference CT images. For datasets with small transformations, it\nresulted in MCD of 0.82 and 1.02 mm respectively. For large transformations, it\nresulted in MCD of 1.10 and 1.28 mm respectively. This work addressed\ndifficulties in 3DCT-2DUS kidney registration during free breathing via novel\nnetwork structures and training strategy.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:23:05 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13856","submitter":"Yi-Rui Yang","authors":"Yi-Rui Yang, Chang-Wei Shi, Wu-Jun Li","title":"On the Optimal Batch Size for Byzantine-Robust Distributed Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Byzantine-robust distributed learning (BRDL), in which computing devices are\nlikely to behave abnormally due to accidental failures or malicious attacks,\nhas recently become a hot research topic. However, even in the independent and\nidentically distributed (i.i.d.) case, existing BRDL methods will suffer from a\nsignificant drop on model accuracy due to the large variance of stochastic\ngradients. Increasing batch sizes is a simple yet effective way to reduce the\nvariance. However, when the total number of gradient computation is fixed, a\ntoo-large batch size will lead to a too-small iteration number (update number),\nwhich may also degrade the model accuracy. In view of this challenge, we mainly\nstudy the optimal batch size when the total number of gradient computation is\nfixed in this work. In particular, we theoretically and empirically show that\nwhen the total number of gradient computation is fixed, the optimal batch size\nin BRDL increases with the fraction of Byzantine workers. Therefore, compared\nto the case without attacks, the batch size should be set larger when under\nByzantine attacks. However, for existing BRDL methods, large batch sizes will\nlead to a drop on model accuracy, even if there is no Byzantine attack. To deal\nwith this problem, we propose a novel BRDL method, called Byzantine-robust\nstochastic gradient descent with normalized momentum (ByzSGDnm), which can\nalleviate the drop on model accuracy in large-batch cases. Moreover, we\ntheoretically prove the convergence of ByzSGDnm for general non-convex cases\nunder Byzantine attacks. Empirical results show that ByzSGDnm has a comparable\nperformance to existing BRDL methods under bit-flipping failure, but can\noutperform existing BRDL methods under deliberately crafted attacks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:23:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13857","submitter":"Takyoung Kim","authors":"Takyoung Kim, Jamin Shin, Young-Ho Kim, Sanghwan Bae, Sungdong Kim","title":"Revealing User Familiarity Bias in Task-Oriented Dialogue via\n  Interactive Evaluation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Most task-oriented dialogue (TOD) benchmarks assume users that know exactly\nhow to use the system by constraining the user behaviors within the system's\ncapabilities via strict user goals, namely \"user familiarity\" bias. This data\nbias deepens when it combines with data-driven TOD systems, as it is impossible\nto fathom the effect of it with existing static evaluations. Hence, we conduct\nan interactive user study to unveil how vulnerable TOD systems are against\nrealistic scenarios. In particular, we compare users with 1) detailed goal\ninstructions that conform to the system boundaries (closed-goal) and 2) vague\ngoal instructions that are often unsupported but realistic (open-goal). Our\nstudy reveals that conversations in open-goal settings lead to catastrophic\nfailures of the system, in which 92% of the dialogues had significant issues.\nMoreover, we conduct a thorough analysis to identify distinctive features\nbetween the two settings through error annotation. From this, we discover a\nnovel \"pretending\" behavior, in which the system pretends to handle the user\nrequests even though they are beyond the system's capabilities. We discuss its\ncharacteristics and toxicity while emphasizing transparency and a fallback\nstrategy for robust TOD systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:24:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13858","submitter":"Yufei Xie","authors":"Yufei Xie, Shaoman Li and Penghui Lin","title":"Producing a Standard Dataset of Speed Climbing Training Videos Using\n  Deep Learning Techniques","comments":"2023 3rd International Conference on Innovative Talents Training and\n  Sustainable Development","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This dissertation presents a methodology for recording speed climbing\ntraining sessions with multiple cameras and annotating the videos with relevant\ndata, including body position, hand and foot placement, and timing. The\nannotated data is then analyzed using deep learning techniques to create a\nstandard dataset of speed climbing training videos. The results demonstrate the\npotential of the new dataset for improving speed climbing training and\nresearch, including identifying areas for improvement, creating personalized\ntraining plans, and analyzing the effects of different training methods.The\nfindings will also be applied to the training process of the Jiangxi climbing\nteam through further empirical research to test the findings and further\nexplore the feasibility of this study.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:27:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13859","submitter":"Peitian Zhang","authors":"Peitian Zhang, Zheng Liu, Yujia Zhou, Zhicheng Dou, Zhao Cao","title":"Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search\n  Engines","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Auto-regressive search engines emerge as a promising paradigm for next-gen\ninformation retrieval systems. These methods work with Seq2Seq models, where\neach query can be directly mapped to the identifier of its relevant document.\nAs such, they are praised for merits like being end-to-end differentiable.\nHowever, auto-regressive search engines also confront challenges in retrieval\nquality, given the requirement for the exact generation of the document\nidentifier. That's to say, the targeted document will be missed from the\nretrieval result if a false prediction about its identifier is made in any step\nof the generation process. In this work, we propose a novel framework, namely\nAutoTSG (Auto-regressive Search Engine with Term-Set Generation), which is\nfeatured by 1) the unordered term-based document identifier and 2) the\nset-oriented generation pipeline. With AutoTSG, any permutation of the term-set\nidentifier will lead to the retrieval of the corresponding document, thus\nlargely relaxing the requirement of exact generation. Besides, the Seq2Seq\nmodel is enabled to flexibly explore the optimal permutation of the document\nidentifier for the presented query, which may further contribute to the\nretrieval quality. AutoTSG is empirically evaluated with Natural Questions and\nMS MARCO, where notable improvements can be achieved against the existing\nauto-regressive search engines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:30:36 GMT"},{"version":"v2","created":"Wed, 24 May 2023 09:15:28 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13860","submitter":"Yi Liu","authors":"Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang,\n  Lida Zhao, Tianwei Zhang, and Yang Liu","title":"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential\nbut also introduce challenges related to content constraints and potential\nmisuse. Our study investigates three key research questions: (1) the number of\ndifferent prompt types that can jailbreak LLMs, (2) the effectiveness of\njailbreak prompts in circumventing LLM constraints, and (3) the resilience of\nChatGPT against these jailbreak prompts. Initially, we develop a classification\nmodel to analyze the distribution of existing prompts, identifying ten distinct\npatterns and three categories of jailbreak prompts. Subsequently, we assess the\njailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a\ndataset of 3,120 jailbreak questions across eight prohibited scenarios.\nFinally, we evaluate the resistance of ChatGPT against jailbreak prompts,\nfinding that the prompts can consistently evade the restrictions in 40 use-case\nscenarios. The study underscores the importance of prompt structures in\njailbreaking LLMs and discusses the challenges of robust jailbreak prompt\ngeneration and prevention.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:33:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13861","submitter":"Yang-Guang Shan","authors":"Yang-Guang Shan, Zhen-Qiang Yin, Shuang Wang, Wei Chen, De-Yong He,\n  Guang-Can Guo, Zheng-Fu Han","title":"Practical Phase-Coding Side-Channel-Secure Quantum Key Distribution","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  All kinds of device loopholes give rise to a great obstacle to practical\nsecure quantum key distribution (QKD). In this article, inspired by the\noriginal side-channel-secure protocol [Physical Review Applied 12, 054034\n(2019)], a new QKD protocol called phase-coding side-channel-secure (PC-SCS)\nprotocol is proposed. This protocol can be immune to all uncorrelated side\nchannels of the source part and all loopholes of the measurement side. A\nfinite-key security analysis against coherent attack of the new protocol is\ngiven. The proposed protocol only requires modulation of two phases, which can\navoid the challenge of preparing perfect vacuum states. Numerical simulation\nshows that a practical transmission distance of 300 km can be realized by the\nPC-SCS protocol.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:34:47 GMT"},{"version":"v2","created":"Mon, 29 May 2023 01:05:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13862","submitter":"Leonardo Ranaldi Dr","authors":"Leonardo Ranaldi, Elena Sofia Ruzzetti, Davide Venditti, Dario\n  Onorati, Fabio Massimo Zanzotto","title":"A Trip Towards Fairness: Bias and De-Biasing in Large Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An outbreak in the popularity of transformer-based Language Models (such as\nGPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the\ndoors to new Machine Learning applications. In particular, in Natural Language\nProcessing and how pre-training from large text, corpora is essential in\nachieving remarkable results in downstream tasks. However, these Language\nModels seem to have inherent biases toward certain demographics reflected in\ntheir training data. While research has attempted to mitigate this problem,\nexisting methods either fail to remove bias altogether, degrade performance, or\nare expensive. This paper examines the bias produced by promising Language\nModels when varying parameters and pre-training data. Finally, we propose a\nde-biasing technique that produces robust de-bias models that maintain\nperformance on downstream tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:35:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13863","submitter":"Alexandre Pasquiou","authors":"Alexandre Pasquiou, Yair Lakretz, Bertrand Thirion, Christophe Pallier","title":"Probing Brain Context-Sensitivity with Masked-Attention Generation","comments":"2 pages, 2 figures, CCN 2023","journal-ref":"CCN 2023","doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Two fundamental questions in neurolinguistics concerns the brain regions that\nintegrate information beyond the lexical level, and the size of their window of\nintegration. To address these questions we introduce a new approach named\nmasked-attention generation. It uses GPT-2 transformers to generate word\nembeddings that capture a fixed amount of contextual information. We then\ntested whether these embeddings could predict fMRI brain activity in humans\nlistening to naturalistic text. The results showed that most of the cortex\nwithin the language network is sensitive to contextual information, and that\nthe right hemisphere is more sensitive to longer contexts than the left.\nMasked-attention generation supports previous analyses of context-sensitivity\nin the brain, and complements them by quantifying the window size of context\nintegration per voxel.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:36:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13864","submitter":"Qiong Chen","authors":"Yong Yang and Qiong Chen and Yuan Feng and Tianlin Huang","title":"MIANet: Aggregating Unbiased Instance and General Information for\n  Few-Shot Semantic Segmentation","comments":"Accepted to CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Existing few-shot segmentation methods are based on the meta-learning\nstrategy and extract instance knowledge from a support set and then apply the\nknowledge to segment target objects in a query set. However, the extracted\nknowledge is insufficient to cope with the variable intra-class differences\nsince the knowledge is obtained from a few samples in the support set. To\naddress the problem, we propose a multi-information aggregation network\n(MIANet) that effectively leverages the general knowledge, i.e., semantic word\nembeddings, and instance information for accurate segmentation. Specifically,\nin MIANet, a general information module (GIM) is proposed to extract a general\nclass prototype from word embeddings as a supplement to instance information.\nTo this end, we design a triplet loss that treats the general class prototype\nas an anchor and samples positive-negative pairs from local features in the\nsupport set. The calculated triplet loss can transfer semantic similarities\namong language identities from a word embedding space to a visual\nrepresentation space. To alleviate the model biasing towards the seen training\nclasses and to obtain multi-scale information, we then introduce a\nnon-parametric hierarchical prior module (HPM) to generate unbiased\ninstance-level information via calculating the pixel-level similarity between\nthe support and query image features. Finally, an information fusion module\n(IFM) combines the general and instance information to make predictions for the\nquery image. Extensive experiments on PASCAL-5i and COCO-20i show that MIANet\nyields superior performance and set a new state-of-the-art. Code is available\nat https://github.com/Aldrich2y/MIANet.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:36:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13865","submitter":"Da Yu","authors":"Da Yu, Sivakanth Gopi, Janardhan Kulkarni, Zinan Lin, Saurabh Naik,\n  Tomasz Lukasz Religa, Jian Yin, Huishuai Zhang","title":"Selective Pre-training for Private Fine-tuning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Suppose we want to train text prediction models in email clients or word\nprocessors. The models must preserve the privacy of user data and adhere to a\nspecific fixed size to meet memory and inference time requirements. We\nintroduce a generic framework to solve this problem. Specifically, we are given\na public dataset $D_\\text{pub}$ and a private dataset $D_\\text{priv}$\ncorresponding to a downstream task $T$. How should we pre-train a fixed-size\nmodel $M$ on $D_\\text{pub}$ and fine-tune it on $D_\\text{priv}$ such that\nperformance of $M$ with respect to $T$ is maximized and $M$ satisfies\ndifferential privacy with respect to $D_\\text{priv}$? We show that pre-training\non a {\\em subset} of dataset $D_\\text{pub}$ that brings the public distribution\ncloser to the private distribution is a crucial ingredient to maximize the\ntransfer learning abilities of $M$ after pre-training, especially in the\nregimes where model sizes are relatively small. Besides performance\nimprovements, our framework also shows that with careful pre-training and\nprivate fine-tuning, {\\em smaller models} can match the performance of much\nlarger models, highlighting the promise of differentially private training as a\ntool for model compression and efficiency.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:36:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13866","submitter":"Amar Kumar Banerjee","authors":"Amar Kumar Banerjee and Mahendranath Paul","title":"$I^K_{\\nu}$-Convergence of functions in probabilistic normed spaces","comments":"16 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we study $I^K$-convergence of functions with respect to\nprobabilistic norm $\\nu$ which is a generalization of $I^*_{\\nu}$-convergence\nin probabilistic norm spaces. We also study on $I^K$-Cauchy functions and\n$I^K$-limit points with respect to probabilistic norm $\\nu$ in the same space.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:38:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13867","submitter":"Patrick Delorme","authors":"Patrick Delorme","title":"Scattering and a Plancherel formula for real reductive spherical spaces","comments":"93 pages. Notice that in my preprint arXiv:2010.10830 there is a\n  mistake in p.64 l.-10 to l.-7 due to the non canonical identifications there.\n  Here we correct this and generalize to the case of non split groups","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We establish the analog for real homogeneous spherical varieties of the\nScattering Theorem of Sakellaridis and Venkatesh (Periods and harmonic analysis\non spherical varieties, Asterisque 396, (2017), Theorem 7.3.1) for p-adic\nwavefront spherical varieties. We use properties of the Harish-Chandra\nhomomorphism of Knop for invariant differential operators of the variety,\nspecial coverings of the variety and spectral projections. We have to make an\nanalog of the Discrete Series Conjecture of Sakellaridis and Venkatesh (l.c.,\nConjecture 9.4.6).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:38:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13868","submitter":"Charles Vanwynsberghe","authors":"Charles Vanwynsberghe, Jiguang He, Chongwen Huang, and Merouane Debbah","title":"Walsh Meets OAM in Holographic MIMO","comments":"Submission to ICEAA 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Holographic multiple-input multiple-output (MIMO) is deemed as a promising\ntechnique beyond massive MIMO, unleashing near-field communications,\nlocalization, and sensing in the next-generation wireless networks.\nSemi-continuous surface with densely packed elements brings new opportunities\nfor increased spatial degrees of freedom (DoFs) and spectrum efficiency (SE)\neven in the line-of-sight (LoS) condition. In this paper, we analyze\nholographic MIMO performance with disk-shaped large intelligent surfaces (LISs)\naccording to different precoding designs. Beyond the well-known technique of\norbital angular momentum (OAM) of radio waves, we propose a new design based on\npolar Walsh functions. Furthermore, we characterize the performance gap between\nthe proposed scheme and the optimal case with singular value decomposition\n(SVD) alongside perfect channel state information (CSI) as well as other\nbenchmark schemes in terms of channel capacity. It is verified that the\nproposed scheme marginally underperforms the OAM-based approach, while offering\npotential perspectives for reducing implementation complexity and expenditure.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:39:26 GMT"},{"version":"v2","created":"Sat, 27 May 2023 10:15:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13869","submitter":"Xiaolong Chen","authors":"Xiaolong Chen and Xin Qi and Chunguang Su and Yuan He and Zhijun Wang\n  and Kunxiang Sun and Chao Jin and Weilong Chen and Shuhui Liu and Xiaoying\n  Zhao and Duanyang Jia and Man Yi","title":"Trend-Based SAC Beam Control Method with Zero-Shot in Superconducting\n  Linear Accelerator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.acc-ph cs.AI cs.LG cs.SY eess.SY","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The superconducting linear accelerator is a highly flexiable facility for\nmodern scientific discoveries, necessitating weekly reconfiguration and tuning.\nAccordingly, minimizing setup time proves essential in affording users with\nample experimental time. We propose a trend-based soft actor-critic(TBSAC) beam\ncontrol method with strong robustness, allowing the agents to be trained in a\nsimulated environment and applied to the real accelerator directly with\nzero-shot. To validate the effectiveness of our method, two different typical\nbeam control tasks were performed on China Accelerator Facility for Superheavy\nElements (CAFe II) and a light particle injector(LPI) respectively. The orbit\ncorrection tasks were performed in three cryomodules in CAFe II seperately, the\ntime required for tuning has been reduced to one-tenth of that needed by human\nexperts, and the RMS values of the corrected orbit were all less than 1mm. The\nother transmission efficiency optimization task was conducted in the LPI, our\nagent successfully optimized the transmission efficiency of radio-frequency\nquadrupole(RFQ) to over $85\\%$ within 2 minutes. The outcomes of these two\nexperiments offer substantiation that our proposed TBSAC approach can\nefficiently and effectively accomplish beam commissioning tasks while upholding\nthe same standard as skilled human experts. As such, our method exhibits\npotential for future applications in other accelerator commissioning fields.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:39:27 GMT"},{"version":"v2","created":"Thu, 25 May 2023 07:05:28 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13870","submitter":"Aleksey Khlyupin","authors":"Aleksei Cherkasov, Kirill M. Gerke, Aleksey Khlyupin","title":"Towards effective information content assessment: analytical derivation\n  of information loss in the reconstruction of random fields with model\n  uncertainty","comments":"Keywords: correlation functions, structure characterization,\n  structural descriptors, image analysis, information content","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.data-an cond-mat.dis-nn cond-mat.mtrl-sci cs.IT math.IT stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Structures are abundant in both natural and human-made environments and\nusually studied in the form of images or scattering patterns. To characterize\nstructures a huge variety of descriptors is available spanning from porosity to\nradial and correlation functions. In addition to morphological structural\nanalysis, such descriptors are necessary for stochastic reconstructions,\nstationarity and representativity analysis. The most important characteristic\nof any such descriptor is its information content - or its ability to describe\nthe structure at hand. For example, from crystallography it is well known that\nexperimentally measurable $S_2$ correlation function lacks necessary\ninformation content to describe majority of structures. The information content\nof this function can be assessed using Monte-Carlo methods only for very small\n2D images due to computational expenses. Some indirect quantitative approaches\nfor this and other correlation function were also proposed. Yet, to date no\nmethodology to obtain information content for arbitrary 2D or 3D image is\navailable. In this work, we make a step toward developing a general framework\nto perform such computations analytically. We show, that one can assess the\nentropy of a perturbed random field and that stochastic perturbation of fields\ncorrelation function decreases its information content. In addition to\nanalytical expression, we demonstrate that different regions of correlation\nfunction are in different extent informative and sensitive for perturbation.\nProposed model bridges the gap between descriptor-based heterogeneous media\nreconstruction and information theory and opens way for computationally\neffective way to compute information content of any descriptor as applied to\narbitrary structure.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:45:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13871","submitter":"Anke Tang","authors":"Anke Tang, Yong Luo, Han Hu, Fengxiang He, Kehua Su, Bo Du, Yixin\n  Chen, Dacheng Tao","title":"Improving Heterogeneous Model Reuse by Density Estimation","comments":"9 pages, 5 figues. Accepted by IJCAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies multiparty learning, aiming to learn a model using the\nprivate data of different participants. Model reuse is a promising solution for\nmultiparty learning, assuming that a local model has been trained for each\nparty. Considering the potential sample selection bias among different parties,\nsome heterogeneous model reuse approaches have been developed. However,\nalthough pre-trained local classifiers are utilized in these approaches, the\ncharacteristics of the local data are not well exploited. This motivates us to\nestimate the density of local data and design an auxiliary model together with\nthe local classifiers for reuse. To address the scenarios where some local\nmodels are not well pre-trained, we further design a multiparty cross-entropy\nloss for calibration. Upon existing works, we address a challenging problem of\nheterogeneous model reuse from a decision theory perspective and take advantage\nof recent advances in density estimation. Experimental results on both\nsynthetic and benchmark data demonstrate the superiority of the proposed\nmethod.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:46:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13872","submitter":"Yuxiao Li","authors":"Yuxiao Li, Santiago Mazuelas, Yuan Shen","title":"Variational Bayesian Framework for Advanced Image Generation with\n  Domain-Related Variables","comments":"5 pages, 2 figures,","journal-ref":"ICASSP 2022 - 2022 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), Singapore, Singapore, 2022, pp.\n  2684-2688","doi":"10.1109/ICASSP43922.2022.9746364","report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep generative models (DGMs) and their conditional counterparts provide a\npowerful ability for general-purpose generative modeling of data distributions.\nHowever, it remains challenging for existing methods to address advanced\nconditional generative problems without annotations, which can enable multiple\napplications like image-to-image translation and image editing. We present a\nunified Bayesian framework for such problems, which introduces an inference\nstage on latent variables within the learning process. In particular, we\npropose a variational Bayesian image translation network (VBITN) that enables\nmultiple image translation and editing tasks. Comprehensive experiments show\nthe effectiveness of our method on unsupervised image-to-image translation, and\ndemonstrate the novel advanced capabilities for semantic editing and mixed\ndomain translation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:47:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13873","submitter":"Yiting Qu","authors":"Yiting Qu, Xinyue Shen, Xinlei He, Michael Backes, Savvas Zannettou,\n  Yang Zhang","title":"Unsafe Diffusion: On the Generation of Unsafe Images and Hateful Memes\n  From Text-To-Image Models","comments":"To Appear in the ACM Conference on Computer and Communications\n  Security, November 26, 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CR cs.CY cs.LG cs.SI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  State-of-the-art Text-to-Image models like Stable Diffusion and DALLE$\\cdot$2\nare revolutionizing how people generate visual content. At the same time,\nsociety has serious concerns about how adversaries can exploit such models to\ngenerate unsafe images. In this work, we focus on demystifying the generation\nof unsafe images and hateful memes from Text-to-Image models. We first\nconstruct a typology of unsafe images consisting of five categories (sexually\nexplicit, violent, disturbing, hateful, and political). Then, we assess the\nproportion of unsafe images generated by four advanced Text-to-Image models\nusing four prompt datasets. We find that these models can generate a\nsubstantial percentage of unsafe images; across four models and four prompt\ndatasets, 14.56% of all generated images are unsafe. When comparing the four\nmodels, we find different risk levels, with Stable Diffusion being the most\nprone to generating unsafe content (18.92% of all generated images are unsafe).\nGiven Stable Diffusion's tendency to generate more unsafe content, we evaluate\nits potential to generate hateful meme variants if exploited by an adversary to\nattack a specific individual or community. We employ three image editing\nmethods, DreamBooth, Textual Inversion, and SDEdit, which are supported by\nStable Diffusion. Our evaluation result shows that 24% of the generated images\nusing DreamBooth are hateful meme variants that present the features of the\noriginal hateful meme and the target individual/community; these generated\nimages are comparable to hateful meme variants collected from the real world.\nOverall, our results demonstrate that the danger of large-scale generation of\nunsafe images is imminent. We discuss several mitigating measures, such as\ncurating training data, regulating prompts, and implementing safety filters,\nand encourage better safeguard tools to be developed to prevent unsafe\ngeneration.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:48:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13874","submitter":"JingMin Liang","authors":"Zhibin Li, Jingmin Liang, Song He, Li Li","title":"Holographic study of higher-order baryon number susceptibilities at\n  finite temperature and density","comments":"15 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The cumulants of baryon number fluctuations serve as a good probe for\nexperimentally exploring the QCD phase diagram at finite density, giving rise\nto characteristic fluctuation patterns associated with a possible critical\nendpoint (CEP). We compute the higher-order baryon number susceptibilities at\nfinite temperature and baryon chemical potential using a holographic QCD model\nto address the non-perturbative aspect of strongly coupled QCD matter. The\nmodel can accurately confront lattice QCD data on a quantitative level and the\nlocation of the CEP is found to fall within the range accessible to upcoming\nexperimental measurements. The baryon number susceptibilities up to the twelfth\norder are computed, and the collision energy dependence of different ratios of\nthese susceptibilities is examined along the chemical freeze-out line. The\nholographic results show quantitative agreement with experimental data and the\nfunctional renormalization group results in a large collision energy range,\nwith all ratios exhibiting a peak structure around 5-10 GeV. The mismatching\nbetween our holographic results with experimental data for sufficiently low\ncollision energy is possibly due to non-equilibrium effects and complex\nexperimental environments. The future experiments with measurements in the low\ncollision energy range $\\sqrt{S_{NN}}\\approx 1-10~\\text{GeV}$ and reduced\nexperimental uncertainty could reveal more non-monotonic behavior signals which\ncan be used to locate the CEP.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:50:05 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 14:05:52 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13875","submitter":"Ryosuke Sonoda","authors":"Ryosuke Sonoda","title":"Fair Oversampling Technique using Heterogeneous Clusters","comments":null,"journal-ref":"Information Sciences, Volume 640, 2023, 119059, ISSN 0020-0255,","doi":"10.1016/j.ins.2023.119059","report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Class imbalance and group (e.g., race, gender, and age) imbalance are\nacknowledged as two reasons in data that hinder the trade-off between fairness\nand utility of machine learning classifiers. Existing techniques have jointly\naddressed issues regarding class imbalance and group imbalance by proposing\nfair over-sampling techniques. Unlike the common oversampling techniques, which\nonly address class imbalance, fair oversampling techniques significantly\nimprove the abovementioned trade-off, as they can also address group imbalance.\nHowever, if the size of the original clusters is too small, these techniques\nmay cause classifier overfitting. To address this problem, we herein develop a\nfair oversampling technique using data from heterogeneous clusters. The\nproposed technique generates synthetic data that have class-mix features or\ngroup-mix features to make classifiers robust to overfitting. Moreover, we\ndevelop an interpolation method that can enhance the validity of generated\nsynthetic data by considering the original cluster distribution and data noise.\nFinally, we conduct experiments on five realistic datasets and three\nclassifiers, and the experimental results demonstrate the effectiveness of the\nproposed technique in terms of fairness and utility.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:51:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13876","submitter":"Taiki Miyanishi","authors":"Taiki Miyanishi, Daichi Azuma, Shuhei Kurita, Motoki Kawanabe","title":"Cross3DVG: Baseline and Dataset for Cross-Dataset 3D Visual Grounding on\n  Different RGB-D Scans","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present Cross3DVG, a novel task for cross-dataset visual grounding in 3D\nscenes, revealing the limitations of existing 3D visual grounding models using\nrestricted 3D resources and thus easily overfit to a specific 3D dataset. To\nfacilitate Cross3DVG, we have created a large-scale 3D visual grounding dataset\ncontaining more than 63k diverse descriptions of 3D objects within 1,380 indoor\nRGB-D scans from 3RScan with human annotations, paired with the existing 52k\ndescriptions on ScanRefer. We perform Cross3DVG by training a model on the\nsource 3D visual grounding dataset and then evaluating it on the target dataset\nconstructed in different ways (e.g., different sensors, 3D reconstruction\nmethods, and language annotators) without using target labels. We conduct\ncomprehensive experiments using established visual grounding models, as well as\na CLIP-based 2D-3D integration method, designed to bridge the gaps between 3D\ndatasets. By performing Cross3DVG tasks, we found that (i) cross-dataset 3D\nvisual grounding has significantly lower performance than learning and\nevaluation with a single dataset, suggesting much room for improvement in\ncross-dataset generalization of 3D visual grounding, (ii) better detectors and\ntransformer-based localization modules for 3D grounding are beneficial for\nenhancing 3D grounding performance and (iii) fusing 2D-3D data using CLIP\ndemonstrates further performance improvements. Our Cross3DVG task will provide\na benchmark for developing robust 3D visual grounding models capable of\nhandling diverse 3D scenes while leveraging deep language understanding.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:52:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13877","submitter":"Arseny Moskvichev","authors":"Arseny Moskvichev and Ky-Vinh Mai","title":"Narrative XL: A Large-scale Dataset For Long-Term Memory Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Despite their tremendous successes, most large language models do not have\nany long-term memory mechanisms, which restricts their applications. Overcoming\nthis limitation would not only require changes to the typical transformer\narchitectures or training procedures, but also a dataset on which these new\nmodels could be trained and evaluated. We argue that existing resources lack a\nfew key properties, and that at present, there are no naturalistic datasets of\nsufficient scale to train (and not only evaluate) long-term memory language\nmodels. We then present our solution that capitalizes on the advances in\nshort-term memory language models to create such a dataset. Using GPT 3.5, we\nsummarized each scene in 1500 hand-curated books from Project Gutenberg, which\nresulted in approximately 150 scene-level summaries per book. We then created a\nnumber of reading comprehension questions based on these summaries, including\nthree types of multiple-choice scene recognition questions, as well as\nfree-form narrative reconstruction questions. Each book is thus associated with\nmore than 500 reading comprehension questions. Crucially, most questions have a\nknown ``retention demand'', indicating how long-term of a memory is needed to\nanswer it, which should aid long-term memory performance evaluation. We\nvalidate our data in three small-scale experiments: one with human labelers,\nand two with existing language models. We show that our questions 1) adequately\nrepresent the source material 2) can be used to diagnose the model's memory\ncapacity 3) are not trivial for modern language models even when the memory\ndemand does not exceed those models' context lengths. Lastly, we provide our\ncode which can be used to further expand the dataset in an automated manner.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:55:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13878","submitter":"Ayush Kumar Varshney Mr.","authors":"Ayush K. Varshney, Sonakshi Garg, Arka Ghosh, Sargam Gupta","title":"Fair Differentially Private Federated Learning Framework","comments":"Paper report for WASP module 2","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Federated learning (FL) is a distributed machine learning strategy that\nenables participants to collaborate and train a shared model without sharing\ntheir individual datasets. Privacy and fairness are crucial considerations in\nFL. While FL promotes privacy by minimizing the amount of user data stored on\ncentral servers, it still poses privacy risks that need to be addressed.\nIndustry standards such as differential privacy, secure multi-party\ncomputation, homomorphic encryption, and secure aggregation protocols are\nfollowed to ensure privacy in FL. Fairness is also a critical issue in FL, as\nmodels can inherit biases present in local datasets, leading to unfair\npredictions. Balancing privacy and fairness in FL is a challenge, as privacy\nrequires protecting user data while fairness requires representative training\ndata. This paper presents a \"Fair Differentially Private Federated Learning\nFramework\" that addresses the challenges of generating a fair global model\nwithout validation data and creating a globally private differential model. The\nframework employs clipping techniques for biased model updates and Gaussian\nmechanisms for differential privacy. The paper also reviews related works on\nprivacy and fairness in FL, highlighting recent advancements and approaches to\nmitigate bias and ensure privacy. Achieving privacy and fairness in FL requires\ncareful consideration of specific contexts and requirements, taking into\naccount the latest developments in industry standards and techniques.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:58:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13879","submitter":"Kim Jie Koh","authors":"Kim Jie Koh and Fehmi Cirak","title":"Stochastic PDE representation of random fields for large-scale Gaussian\n  process regression and statistical finite element analysis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA physics.comp-ph stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The efficient representation of random fields on geometrically complex\ndomains is crucial for Bayesian modelling in engineering and machine learning.\nToday's prevalent random field representations are restricted to unbounded\ndomains or are too restrictive in terms of possible field properties. As a\nresult, new techniques leveraging the historically established link between\nstochastic PDEs (SPDEs) and random fields are especially appealing for\nengineering applications with complex geometries which already have a finite\nelement discretisation for solving the physical conservation equations. Unlike\nthe dense covariance matrix of a random field, its inverse, the precision\nmatrix, is usually sparse and equal to the stiffness matrix of a Helmholtz-like\nSPDE. In this paper, we use the SPDE representation to develop a scalable\nframework for large-scale statistical finite element analysis (statFEM) and\nGaussian process (GP) regression on geometrically complex domains. We use the\nSPDE formulation to obtain the relevant prior probability densities with a\nsparse precision matrix. The properties of the priors are governed by the\nparameters and possibly fractional order of the Helmholtz-like SPDE so that we\ncan model on bounded domains and manifolds anisotropic, non-homogeneous random\nfields with arbitrary smoothness. We use for assembling the sparse precision\nmatrix the same finite element mesh used for solving the physical conservation\nequations. The observation models for statFEM and GP regression are such that\nthe posterior probability densities are Gaussians with a closed-form mean and\nprecision. The expressions for the mean vector and the precision matrix can be\nevaluated using only sparse matrix operations. We demonstrate the versatility\nof the proposed framework and its convergence properties with one and\ntwo-dimensional Poisson and thin-shell examples.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:59:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13880","submitter":"Yuxiao Li","authors":"Yuxiao Li, Zhiming Wang, Yuan Shen","title":"Generalized Expectation Maximization Framework for Blind Image Super\n  Resolution","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning-based methods for blind single image super resolution (SISR) conduct\nthe restoration by a learned mapping between high-resolution (HR) images and\ntheir low-resolution (LR) counterparts degraded with arbitrary blur kernels.\nHowever, these methods mostly require an independent step to estimate the blur\nkernel, leading to error accumulation between steps. We propose an end-to-end\nlearning framework for the blind SISR problem, which enables image restoration\nwithin a unified Bayesian framework with either full- or semi-supervision. The\nproposed method, namely SREMN, integrates learning techniques into the\ngeneralized expectation-maximization (GEM) algorithm and infers HR images from\nthe maximum likelihood estimation (MLE). Extensive experiments show the\nsuperiority of the proposed method with comparison to existing work and novelty\nin semi-supervised learning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:01:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13881","submitter":"M.A. Moreno-Fr\\'ias","authors":"M.A. Moreno-Fr\\'ias, J.C. Rosales","title":"The covariety of saturated numerical semigroups with fixed Frobenius\n  number","comments":"arXiv admin note: text overlap with arXiv:2303.12470,\n  arXiv:2305.02070","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we will show that if $F$ is a positive integer, then\n${\\mathrm{Sat}}(F)=\\{S\\mid S \\mbox{ is a saturated numerical semigroup with\nFrobenius number } F\\}$ is a covariety. As a consequence, we present two\nalgorithms: one that computes ${\\mathrm{Sat}}(F),$ and the other which computes\nall the elements of ${\\mathrm{Sat}}(F)$ with a fixed genus.\n  If $X\\subseteq S\\backslash \\Delta(F)$ for some $S\\in {\\mathrm{Sat}}(F),$ then\nwe will see that there is the least element of ${\\mathrm{Sat}}(F)$ containing a\n$X$. This element will denote by ${\\mathrm{Sat}}(F)[X].$\n  If $S\\in{\\mathrm{Sat}}(F),$ then we define the ${\\mathrm{Sat}}(F)$-rank of\n$S$ as the minimum of $\\{\\mbox{cardinality}(X)\\mid S={\\mathrm{Sat}}(F)[X]\\}.$\nIn this paper, also we present an algorithm to compute all the element of\n${\\mathrm{Sat}}(F)$ with a given\n  ${\\mathrm{Sat}}(F)$-rank.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:02:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13882","submitter":"Jonas Latz","authors":"Kexin Jin, Chenguang Liu, Jonas Latz","title":"Subsampling Error in Stochastic Gradient Langevin Diffusions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG stat.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to\napproximate Bayesian posterior distributions in statistical learning procedures\nwith large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC)\nalgorithms, SGLD is not stationary with respect to the posterior distribution;\ntwo sources of error appear: The first error is introduced by an\nEuler--Maruyama discretisation of a Langevin diffusion process, the second\nerror comes from the data subsampling that enables its use in large-scale data\nsettings. In this work, we consider an idealised version of SGLD to analyse the\nmethod's pure subsampling error that we then see as a best-case error for\ndiffusion-based subsampling MCMC methods. Indeed, we introduce and study the\nStochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov\nprocess that follows the Langevin diffusion corresponding to a data subset and\nswitches this data subset after exponential waiting times. There, we show that\nthe Wasserstein distance between the posterior and the limiting distribution of\nSGLDiff is bounded above by a fractional power of the mean waiting time.\nImportantly, this fractional power does not depend on the dimension of the\nstate space. We bring our results into context with other analyses of SGLD.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:03:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13883","submitter":"Jade Garcia Bourr\\'ee","authors":"Jade Garcia Bourr\\'ee, Erwan Le Merrer, Gilles Tredan and Beno\\^it\n  Rottembourg","title":"On the relevance of APIs facing fairwashed audits","comments":"18 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent legislation required AI platforms to provide APIs for regulators to\nassess their compliance with the law. Research has nevertheless shown that\nplatforms can manipulate their API answers through fairwashing. Facing this\nthreat for reliable auditing, this paper studies the benefits of the joint use\nof platform scraping and of APIs. In this setup, we elaborate on the use of\nscraping to detect manipulated answers: since fairwashing only manipulates API\nanswers, exploiting scraps may reveal a manipulation. To abstract the wide\nrange of specific API-scrap situations, we introduce a notion of proxy that\ncaptures the consistency an auditor might expect between both data sources. If\nthe regulator has a good proxy of the consistency, then she can easily detect\nmanipulation and even bypass the API to conduct her audit. On the other hand,\nwithout a good proxy, relying on the API is necessary, and the auditor cannot\ndefend against fairwashing.\n  We then simulate practical scenarios in which the auditor may mostly rely on\nthe API to conveniently conduct the audit task, while maintaining her chances\nto detect a potential manipulation. To highlight the tension between the audit\ntask and the API fairwashing detection task, we identify Pareto-optimal\nstrategies in a practical audit scenario.\n  We believe this research sets the stage for reliable audits in practical and\nmanipulation-prone setups.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:06:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13884","submitter":"Thanh Le-Cong Le-Cong Thanh","authors":"Truong Giang Nguyen, Thanh Le-Cong, Hong Jin Kang, Ratnadira\n  Widyasari, Chengran Yang, Zhipeng Zhao, Bowen Xu, Jiayuan Zhou, Xin Xia,\n  Ahmed E. Hassan, Xuan-Bach D. Le, David Lo","title":"Multi-Granularity Detector for Vulnerability Fixes","comments":null,"journal-ref":"IEEE Transactions on Software Engineering, 2023","doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With the increasing reliance on Open Source Software, users are exposed to\nthird-party library vulnerabilities. Software Composition Analysis (SCA) tools\nhave been created to alert users of such vulnerabilities. SCA requires the\nidentification of vulnerability-fixing commits. Prior works have proposed\nmethods that can automatically identify such vulnerability-fixing commits.\nHowever, identifying such commits is highly challenging, as only a very small\nminority of commits are vulnerability fixing. Moreover, code changes can be\nnoisy and difficult to analyze. We observe that noise can occur at different\nlevels of detail, making it challenging to detect vulnerability fixes\naccurately.\n  To address these challenges and boost the effectiveness of prior works, we\npropose MiDas (Multi-Granularity Detector for Vulnerability Fixes). Unique from\nprior works, Midas constructs different neural networks for each level of code\nchange granularity, corresponding to commit-level, file-level, hunk-level, and\nline-level, following their natural organization. It then utilizes an ensemble\nmodel that combines all base models to generate the final prediction. This\ndesign allows MiDas to better handle the noisy and highly imbalanced nature of\nvulnerability-fixing commit data. Additionally, to reduce the human effort\nrequired to inspect code changes, we have designed an effort-aware adjustment\nfor Midas's outputs based on commit length. The evaluation results demonstrate\nthat MiDas outperforms the current state-of-the-art baseline in terms of AUC by\n4.9% and 13.7% on Java and Python-based datasets, respectively. Furthermore, in\nterms of two effort-aware metrics, EffortCost@L and Popt@L, MiDas also\noutperforms the state-of-the-art baseline, achieving improvements of up to\n28.2% and 15.9% on Java, and 60% and 51.4% on Python, respectively.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:06:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13885","submitter":"Jubair Basha N Md","authors":"N Md Jubair Basha, Gopinath Ganapathy, Mohammed Moulana","title":"A Prelimanary Exploration on component based software engineering","comments":null,"journal-ref":null,"doi":"10.22937/IJCSNS.2022.22.9.22","report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Component-based software development (CBD) is a methodology that has been\nembraced by the software industry to accelerate development, save costs and\ntimelines, minimize testing requirements, and boost quality and output.\nCompared to the conventional software development approach, this led to the\nsystem's development being completed more quickly. By choosing components,\nidentifying systems, and evaluating those systems, CBSE contributes\nsignificantly to the software development process. The objective of CBSE is to\ncodify and standardize all disciplines that support CBD-related operations.\nAnalysis of the comparison between component-based and scripting technologies\nreveals that, in terms of qualitative performance, component-based technologies\nscale more effectively. Further study and application of CBSE are directly\nrelated to the CBD approach's success. This paper explores the introductory\nconcepts and comparative analysis related to component-based software\nengineering which have been around for a while, but proper adaption of CBSE are\nstill lacking issues are also focused.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:07:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13886","submitter":"Shoaib Meraj Sami","authors":"Shoaib M. Sami, Nasser M. Nasrabadi, Raghuveer Rao","title":"Deep Transductive Transfer Learning for Automatic Target Recognition","comments":"10 pages, 5 figures","journal-ref":"SPIE Defense & Commercial Sensing 2023, Conference 12521,\n  Automatic target recognition XXXIII, Orlando, Florida","doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One of the major obstacles in designing an automatic target recognition (ATR)\nalgorithm, is that there are often labeled images in one domain (i.e., infrared\nsource domain) but no annotated images in the other target domains (i.e.,\nvisible, SAR, LIDAR). Therefore, automatically annotating these images is\nessential to build a robust classifier in the target domain based on the\nlabeled images of the source domain. Transductive transfer learning is an\neffective way to adapt a network to a new target domain by utilizing a\npretrained ATR network in the source domain. We propose an unpaired\ntransductive transfer learning framework where a CycleGAN model and a\nwell-trained ATR classifier in the source domain are used to construct an ATR\nclassifier in the target domain without having any labeled data in the target\ndomain. We employ a CycleGAN model to transfer the mid-wave infrared (MWIR)\nimages to visible (VIS) domain images (or visible to MWIR domain). To train the\ntransductive CycleGAN, we optimize a cost function consisting of the\nadversarial, identity, cycle-consistency, and categorical cross-entropy loss\nfor both the source and target classifiers. In this paper, we perform a\ndetailed experimental analysis on the challenging DSIAC ATR dataset. The\ndataset consists of ten classes of vehicles at different poses and distances\nranging from 1-5 kilometers on both the MWIR and VIS domains. In our\nexperiment, we assume that the images in the VIS domain are the unlabeled\ntarget dataset. We first detect and crop the vehicles from the raw images and\nthen project them into a common distance of 2 kilometers. Our proposed\ntransductive CycleGAN achieves 71.56% accuracy in classifying the visible\ndomain vehicles in the DSIAC ATR dataset.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:10:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13887","submitter":"Ruiqi Liu","authors":"Ruiqi Liu, Ruyue Yu-Ngok Li, Marco Di Renzo, Lajos Hanzo","title":"A Vision and An Evolutionary Framework for 6G: Scenarios, Capabilities\n  and Enablers","comments":"Submitted to an IEEE Magazine","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.IT math.IT","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  With the standardization and commercialization completed at an unforeseen\npace for the 5th generation (5G) wireless networks, researchers, engineers and\nexecutives from the academia and industry have turned their attention to new\ncandidate technologies that can support the next generation wireless networks\nenabling more advanced capabilities in sophisticated scenarios. Explicitly, the\n6th generation (6G) terrestrial wireless network aims to providing seamless\nconnectivity not only to users but also to machine type devices for the next\ndecade and beyond. This paper describes the progresses moving towards 6G, which\nis officially termed as ``international mobile telecommunications (IMT) for\n2030 and beyond'' in the International Telecommunication Union\nRadiocommunication Sector (ITU-R). Specifically, the usage scenarios, their\nrepresentative capabilities and the supporting technologies are discussed, and\nthe future opportunities and challenges are highlighted.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:11:48 GMT"},{"version":"v2","created":"Wed, 24 May 2023 02:35:50 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13888","submitter":"Xuekai Zhu","authors":"Xuekai Zhu, Biqing Qi, Kaiyan Zhang, Xingwei Long, Bowen Zhou","title":"PaD: Program-aided Distillation Specializes Large Models in Reasoning","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While Large Language Models (LLMs) excel in several natural language\nprocessing tasks, their size and inaccessibility present challenges for\nextensive practical application. Previous studies acquire specialized skills\nthrough distillation on LLMs, which result in trading generic abilities, called\nmodel specialization. As for reasoning ability, chain-of-thought was\nsynthesized to subsequent distillation. However, due to hallucination,\nsynthetic chain-of-thought from LLMs contains faulty reasoning. These incorrect\nreasoning steps damage the reasoning capability. To tackle above issues, we\npropose Program-aided Distillation (PaD), which distills LLMs to obtain\nspecialized small models in reasoning tasks. In PaD, we strengthen specialized\nmodels with program-aided reasoning, and help them overcome faulty reasoning\nsteps with automated error checking. Experimental results demonstrate that, on\nthe GSM8K benchmark, a 0.06B model using PaD can not only outperform certain\nLLMs (e.g., LLaMA), but also achieves a 10% improvement over baselines with a\nsignificantly smaller scale of parameters and data. Data pruning analysis\nreveals that PaD possesses higher training efficiency.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:11:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13889","submitter":"George Osipov","authors":"Konrad K. Dabrowski and Peter Jonsson and Sebastian Ordyniak and\n  George Osipov and Marcin Pilipczuk and Roohani Sharma","title":"Parameterized Complexity Classification for Interval Constraints","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Constraint satisfaction problems form a nicely behaved class of problems that\nlends itself to complexity classification results. From the point of view of\nparameterized complexity, a natural task is to classify the parameterized\ncomplexity of MinCSP problems parameterized by the number of unsatisfied\nconstraints. In other words, we ask whether we can delete at most $k$\nconstraints, where $k$ is the parameter, to get a satisfiable instance. In this\nwork, we take a step towards classifying the parameterized complexity for an\nimportant infinite-domain CSP: Allen's interval algebra (IA). This CSP has\nclosed intervals with rational endpoints as domain values and employs a set $A$\nof 13 basic comparison relations such as ``precedes'' or ``during'' for\nrelating intervals. IA is a highly influential and well-studied formalism\nwithin AI and qualitative reasoning that has numerous applications in, for\ninstance, planning, natural language processing and molecular biology. We\nprovide an FPT vs. W[1]-hard dichotomy for MinCSP$(\\Gamma)$ for all $\\Gamma\n\\subseteq A$. IA is sometimes extended with unions of the relations in $A$ or\nfirst-order definable relations over $A$, but extending our results to these\ncases would require first solving the parameterized complexity of Directed\nSymmetric Multicut, which is a notorious open problem. Already in this limited\nsetting, we uncover connections to new variants of graph cut and separation\nproblems. This includes hardness proofs for simultaneous cuts or feedback arc\nset problems in directed graphs, as well as new tractable cases with algorithms\nbased on the recently introduced flow augmentation technique. Given the\nintractability of MinCSP$(A)$ in general, we then consider (parameterized)\napproximation algorithms and present a factor-$2$ fpt-approximation algorithm.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:13:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13890","submitter":"Arnoldas Deltuva","authors":"A. Deltuva, D. Jur\\v{c}iukonis","title":"Nonlocal optical potential in the inelastic deuteron scattering off\n  $^{24}$Mg","comments":"13 pages, 4 figures, to be published in Phys. Rev. C","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nonlocal nucleon-nucleus optical potential with rotational quadrupole\ndeformation enabling the excitation of the ${}^{24}\\mathrm{Mg}(2^+)$ state is\ndeveloped; it fits well the proton-${}^{24}\\mathrm{Mg}$ elastic and inelastic\ndifferential cross section in the beam energy range from 30 to 45 MeV per\nnucleon. The inelastic deuteron-${}^{24}\\mathrm{Mg}$ scattering leading to the\nexcited ${}^{24}\\mathrm{Mg}(2^+)$ state is studied in the same energy regime by\nsolving the three-body Faddeev-type equations for transition operators. Effects\nof the optical potential nonlocality are evaluated by comparison with local\nmodels. Significant effects on the inelastic differential cross section are\nfound at forward angles up to the first peak and at larger angles beyond the\nsecond peak. Nonlocal optical potential provides a simultaneous reasonable\nreproduction of the experimental data for the elastic and inelastic\nproton-${}^{24}\\mathrm{Mg}$ and deuteron-${}^{24}\\mathrm{Mg}$ scattering, not\nachieved using local potentials.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:14:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13891","submitter":"Sunyou Hwang","authors":"Tom Suys, Sunyou Hwang, Guido C. H. E. de Croon, Bart D. W. Remes","title":"Autonomous Control for Orographic Soaring of Fixed-Wing UAVs","comments":"6+1 pages, 9 figures, accepted to ICRA 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a novel controller for fixed-wing UAVs that enables autonomous\nsoaring in an orographic wind field, extending flight endurance. Our method\nidentifies soaring regions and addresses position control challenges by\nintroducing a target gradient line (TGL) on which the UAV achieves an\nequilibrium soaring position, where sink rate and updraft are balanced.\nExperimental testing validates the controller's effectiveness in maintaining\nautonomous soaring flight without using any thrust in a non-static wind field.\nWe also demonstrate a single degree of control freedom in a soaring position\nthrough manipulation of the TGL.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:14:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13892","submitter":"Balsam Alkouz","authors":"Balsam Alkouz, Athman Bouguettaya, Abdallah Lakhdari","title":"Failure-Sentient Composition For Swarm-Based Drone Services","comments":"11 pages, 14 figures, This paper is accepted in the 2023 IEEE\n  International Conference on Web Services (ICWS 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a novel failure-sentient framework for swarm-based drone delivery\nservices. The framework ensures that those drones that experience a noticeable\ndegradation in their performance (called soft failure) and which are part of a\nswarm, do not disrupt the successful delivery of packages to a consumer. The\nframework composes a weighted continual federated learning prediction module to\naccurately predict the time of failures of individual drones and uptime after\nfailures. These predictions are used to determine the severity of failures at\nboth the drone and swarm levels. We propose a speed-based heuristic algorithm\nwith lookahead optimization to generate an optimal set of services considering\nfailures. Experimental results on real datasets prove the efficiency of our\nproposed approach in terms of prediction accuracy, delivery times, and\nexecution times.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:20:25 GMT"},{"version":"v2","created":"Sat, 27 May 2023 08:27:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13893","submitter":"Jasenka Dizdarevic","authors":"Jasenka Dizdarevic, Marc Michalke and Admela Jukan","title":"Engineering and Experimentally Benchmarking Open Source MQTT Broker\n  Implementations","comments":"This paper is uploaded here for research community, thus it is for\n  non-commercial purposes","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Message Queuing Telemetry Transport (MQTT) protocol is one of the most\nwidely used IoT protocol solutions. In this work, we are especially interested\nin open-source MQTT Broker implementations (such as Mosquitto, EMQX, RabbitMQ,\nVerneMQ, and HiveMQ). To this end, we engineer a network testbed to\nexperimentally benchmark the performance of these implementations in an edge\ncomputing context with constrained devices. In more detail, we engineer an\nautomated deployment and orchestration of the containerized MQTT broker\nimplementations, with support for deployment across either moderately powerful\nAMD64 devices, or more resource constrained ARM64 devices. The proposed MQTT\nimplementations are evaluated in terms of overhead response time and different\npayload sizes. Results showed that the hardware platform used as well as the\nmessage size, and the network parameters (latency, packet loss and jitter) have\na significant impact on the performance differences between the brokers. All\nresults, software tools and code are fully reproducible and free and open\nsource.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:20:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13894","submitter":"Jiajie Mei","authors":"Jiajie Mei","title":"Amplitude Bootstrap in (Anti) de Sitter Space And The Four-Point\n  Graviton from Double Copy","comments":"10 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose studying a new representation of amputated Anti de Sitter (AdS)\namplitude in Mellin Momentum space, where it encodes all the dynamical\ninformation in Cosmological Correlators. At tree level, we demonstrate that\nthis amplitude has a similar analytic structure as the S-matrix, with residues\nof poles made up of on-shell lower-point amplitudes. We use this structure to\nbootstrap 4-point scalar amplitudes with spin-1 and spin-2 exchange. In the\nsecond part of the paper, we develop the Double Copy Bootstrap to construct the\n4-point graviton amplitude in general dimension. This leads us to a novel,\nconcise formula that exhibits the flat space structure. We also verified this\nformula for the case when d=3 with literature.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:21:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13895","submitter":"Nicolas Spyratos","authors":"Nicolas Spyratos","title":"The Context Model: A Graph Database Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the relational model a relation over a set of attributes is defined to be\na (finite) subset of the Cartesian product of the attribute domains, separately\nfrom the functional dependencies that the relation must satisfy in order to be\nconsistent. In this paper we propose to include the functional dependencies in\nthe definition of a relation by introducing a data model based on a graph in\nwhich the nodes are attributes, or Cartesian products of attributes, and the\nedges are the functional dependencies.\n  Such a graph actually represents the datasets of an application and their\nrelationships, so we call it an application context or simply context. We\ndefine a database over a context $\\mathcal C$ to be a function $\\delta$ that\nassociates each node $X$ of $\\mathcal C$ with a finite set of values\n$\\delta(X)$ from the domain of $X$ and each edge $e: X \\to Y$ with a total\nfunction $\\delta(e): \\delta(X) \\to \\delta(Y)$. We combine the nodes and edges\nof a context using a functional algebra in order to define queries; and the set\nof all well-formed expressions of this algebra is the query language of the\ncontext. A relation over attributes $A_1, \\ldots, A_n$ is then defined as a\nquery whose paths form a tree with leaves $A_1, \\ldots, A_n$ and whose root is\nthe key.\n  The main contributions of this paper are as follows: (a) we introduce a novel\ngraph database model, called the context model, (b) we show that a consistent\nrelational database can be embedded in the context model as a view over the\ncontext induced by its functional dependencies, (c) we define analytic queries\nin the query language of a context in a seamless manner - in contrast to the\nrelational model where analytic queries are defined outside the relational\nalgebra, and (d) we show that the context model can be used as a user-friendly\ninterface to a relational database for data analysis purposes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:21:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13896","submitter":"Mounir Bensalem","authors":"Mounir Bensalem, Francisco Carpio and Admela Jukan","title":"Towards Optimal Serverless Function Scaling in Edge Computing Network","comments":"This paper is uploaded here for research community, thus it is for\n  non-commercial purposes","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Serverless computing has emerged as a new execution model which gained a lot\nof attention in cloud computing thanks to the latest advances in\ncontainerization technologies. Recently, serverless has been adopted at the\nedge, where it can help overcome heterogeneity issues, constrained nature and\ndynamicity of edge devices. Due to the distributed nature of edge devices,\nhowever, the scaling of serverless functions presents a major challenge. We\naddress this challenge by studying the optimality of serverless function\nscaling. To this end, we propose Semi-Markov Decision Process-based (SMDP)\ntheoretical model, which yields optimal solutions by solving the serverless\nfunction scaling problem as a decision making problem. We compare the SMDP\nsolution with practical, monitoring-based heuristics. We show that SMDP can be\neffectively used in edge computing networks, and in combination with\nmonitoring-based approaches also in real-world implementations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:21:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13897","submitter":"Kangqiang Li","authors":"Kangqiang Li, Yuxuan Wang","title":"Two Results on Low-Rank Heavy-Tailed Multiresponse Regressions","comments":"17 pages. Due to the limitation in time, this paper remains to be\n  continued to improve in the later days","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper gives two theoretical results on estimating low-rank parameter\nmatrices for linear models with multivariate responses. We first focus on\nrobust parameter estimation of low-rank multi-task learning with heavy-tailed\ndata and quantization scenarios. It comprises two cases: quantization under\nheavy-tailed responses and quantization with both heavy-tailed covariate and\nresponse variables. For each case, our theory shows that the proposed estimator\nhas a minmax near-optimal convergence rate. We then further investigate\nlow-rank linear models with heavy-tailed matrix-type responses. The theory\nshows that when the random noise has only $(2+\\epsilon)$-order moment, our\nrobust estimator still has almost the same statistical convergence rate as that\nof sub-Gaussian data. Moreover, our simulation experiments confirm the\ncorrectness of theories and show the superiority of our estimators.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:22:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13898","submitter":"Abel Peirson V","authors":"Abel L. Peirson, Michela Negro, Ioannis Liodakis, Riccardo Middei,\n  Dawoon E. Kim, Alan P. Marscher, Herman L. Marshall, Luigi Pacciani, Roger W.\n  Romani, Kinwah Wu, Alessandro Di Marco, Niccolo Di Lalla, Nicola Omodei,\n  Svetlana G. Jorstad, Ivan Agudo, Pouya M. Kouch, Elina Lindfors, Francisco\n  Jose Aceituno, Maria I. Bernardos, Giacomo Bonnoli, Victor Casanova, Maya\n  Garcia-Comas, Beatriz Agis-Gonzalez, Cesar Husillos, Alessandro Marchini,\n  Alfredo Sota, Carolina Casadio, Juan Escudero, Ioannis Myserlis, Albrecht\n  Sievers, Mark Gurwell, Ramprasad Rao, Ryo Imazawa, Mahito Sasada, Yasushi\n  Fukazawa, Koji S. Kawabata, Makoto Uemura, Tsunefumi Mizuno, Tatsuya Nakaoka,\n  Hiroshi Akitaya, Yeon Cheong, Hyeon-Woo Jeong, Sincheol Kang, Sang-Hyun Kim,\n  Sang-Sung Lee, Emmanouil Angelakis, Alexander Kraus, Nicolo Cibrario,\n  Immacolata Donnarumma, Juri Poutanen, Fabrizio Tavecchio, Lucio A. Antonelli,\n  Matteo Bachetti, Luca Baldini, Wayne H. Baumgartner, Ronaldo Bellazzini,\n  Stefano Bianchi, Stephen D. Bongiorno, Raffaella Bonino, Alessandro Brez,\n  Niccolo Bucciantini, Fiamma Capitanio, Simone Castellano, Elisabetta\n  Cavazzuti, Chien-Ting Chen, Stefano Ciprini, Enrico Costa, Alessandra De\n  Rosa, Ettore Del Monte, Laura Di Gesu, Victor Doroshenko, Michal Dovciak,\n  Steven R. Ehlert, Teruaki Enoto, Yuri Evangelista, Sergio Fabiani, Riccardo\n  Ferrazzoli, Javier A. Garcia, Shuichi Gunji, Kiyoshi Hayashida, Jeremy Heyl,\n  Wataru Iwakiri, Philip Kaaret, Vladimir Karas, Takao Kitaguchi, Jeffery J.\n  Kolodziejczak, Henric Krawczynski, Fabio La Monaca, Luca Latronico, Grzegorz\n  Madejski, Simone Maldera, Alberto Manfreda, Frederic Marin, Andrea Marinucci,\n  Francesco Massaro, Giorgio Matt, Ikuyuki Mitsuishi, Fabio Muleri, C.-Y. Ng,\n  Stephen L. O'Dell, Chiara Oppedisano, Alessandro Papitto, George G. Pavlov,\n  Matteo Perri, Melissa Pesce-Rollins, Pierre-Olivier Petrucci, Maura Pilia,\n  Andrea Possenti, Simonetta Puccetti, Brian D. Ramsey, John Rankin, Ajay\n  Ratheesh, Oliver J. Roberts, Carmelo Sgro, Patrick Slane, Paolo Soffitta,\n  Gloria Spandre, Douglas A. Swartz, Toru Tamagawa, Roberto Taverna, Yuzuru\n  Tawara, Allyn F. Tennant, Nicholas E. Thomas, Francesco Tombesi, Alessio\n  Trois, Sergey Tsygankov, Roberto Turolla, Jacco Vink, Martin C. Weisskopf,\n  Fei Xie, Silvia Zane","title":"X-ray Polarization of BL Lacertae in Outburst","comments":"Accepted to ApJL. 16 pages, 8 figures","journal-ref":null,"doi":"10.3847/2041-8213/acd242","report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We report the first $> 99\\%$ confidence detection of X-ray polarization in BL\nLacertae. During a recent X-ray/$\\gamma$-ray outburst, a 287 ksec observation\n(2022 November 27-30) was taken using the Imaging X-ray Polarimetry Explorer\n({\\it IXPE}), together with contemporaneous multiwavelength observations from\nthe Neil Gehrels {\\it Swift} observatory and {\\it XMM-Newton} in soft X-rays\n(0.3--10~keV), {\\it NuSTAR} in hard X-rays (3--70~keV), and optical\npolarization from the Calar Alto, and Perkins Telescope observatories. Our\ncontemporaneous X-ray data suggest that the {\\it IXPE} energy band is at the\ncrossover between the low- and high-frequency blazar emission humps. The source\ndisplays significant variability during the observation, and we measure\npolarization in three separate time bins. Contemporaneous X-ray spectra allow\nus to determine the relative contribution from each emission hump. We find\n$>99\\%$ confidence X-ray polarization $\\Pi_{2-4{\\rm keV}} =\n21.7^{+5.6}_{-7.9}\\%$ and electric vector polarization angle $\\psi_{2-4{\\rm\nkeV}} = -28.7 \\pm 8.7^{\\circ}$ in the time bin with highest estimated\nsynchrotron flux contribution. We discuss possible implications of our\nobservations, including previous {\\it IXPE} BL Lacertae pointings, tentatively\nconcluding that synchrotron self-Compton emission dominates over hadronic\nemission processes during the observed epochs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:22:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13899","submitter":"Umberto Cappellazzo","authors":"Umberto Cappellazzo, Muqiao Yang, Daniele Falavigna, Alessio Brutti","title":"Sequence-Level Knowledge Distillation for Class-Incremental End-to-End\n  Spoken Language Understanding","comments":"Accepted at INTERSPEECH 2023. Code available at\n  https://github.com/umbertocappellazzo/SLURP-SeqKD","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ability to learn new concepts sequentially is a major weakness for modern\nneural networks, which hinders their use in non-stationary environments. Their\npropensity to fit the current data distribution to the detriment of the past\nacquired knowledge leads to the catastrophic forgetting issue. In this work we\ntackle the problem of Spoken Language Understanding applied to a continual\nlearning setting. We first define a class-incremental scenario for the SLURP\ndataset. Then, we propose three knowledge distillation (KD) approaches to\nmitigate forgetting for a sequence-to-sequence transformer model: the first KD\nmethod is applied to the encoder output (audio-KD), and the other two work on\nthe decoder output, either directly on the token-level (tok-KD) or on the\nsequence-level (seq-KD) distributions. We show that the seq-KD substantially\nimproves all the performance metrics, and its combination with the audio-KD\nfurther decreases the average WER and enhances the entity prediction metric.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:24:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13900","submitter":"Giulio Ba\\`u","authors":"Giovanni F. Gronchi, Giulio Ba\\`u, Clara Grassi","title":"Revisiting the computation of the critical points of the Keplerian\n  distance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the Keplerian distance $d$ in the case of two elliptic orbits,\ni.e. the distance between one point on the first ellipse and one point on the\nsecond one, assuming they have a common focus. The absolute minimum $d_{\\rm\nmin}$ of this function, called MOID or orbit distance in the literature, is\nrelevant to detect possible impacts between two objects following approximately\nthese elliptic trajectories. We revisit and compare two different approaches to\ncompute the critical points of $d^2$, where we squared the distance $d$ to\ninclude crossing points among the critical ones. One approach uses\ntrigonometric polynomials, the other uses ordinary polynomials. A new way to\ntest the reliability of the computation of $d_{\\rm min}$ is introduced, based\non optimal estimates that can be found in the literature. The planar case is\nalso discussed: in this case we present an estimate for the maximal number of\ncritical points of $d^2$, together with a conjecture supported by numerical\ntests.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:25:08 GMT"},{"version":"v2","created":"Wed, 24 May 2023 06:18:24 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13901","submitter":"Guotao Wang","authors":"Guotao Wang, Chenglizhao Chen, Aimin Hao, Hong Qin, Deng-Ping Fan","title":"WinDB: HMD-free and Distortion-free Panoptic Video Fixation Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  To date, the widely-adopted way to perform fixation collection in panoptic\nvideo is based on a head-mounted display (HMD), where participants' fixations\nare collected while wearing an HMD to explore the given panoptic scene freely.\nHowever, this widely-used data collection method is insufficient for training\ndeep models to accurately predict which regions in a given panoptic are most\nimportant when it contains intermittent salient events. The main reason is that\nthere always exist \"blind zooms\" when using HMD to collect fixations since the\nparticipants cannot keep spinning their heads to explore the entire panoptic\nscene all the time. Consequently, the collected fixations tend to be trapped in\nsome local views, leaving the remaining areas to be the \"blind zooms\".\nTherefore, fixation data collected using HMD-based methods that accumulate\nlocal views cannot accurately represent the overall global importance of\ncomplex panoramic scenes. This paper introduces the auxiliary Window with a\nDynamic Blurring (WinDB) fixation collection approach for panoptic video, which\ndoesn't need HMD and is blind-zoom-free. Thus, the collected fixations can well\nreflect the regional-wise importance degree. Using our WinDB approach, we have\nreleased a new PanopticVideo-300 dataset, containing 300 panoptic clips\ncovering over 225 categories. Besides, we have presented a simple baseline\ndesign to take full advantage of PanopticVideo-300 to handle the\nblind-zoom-free attribute-induced fixation shifting problem.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:25:22 GMT"},{"version":"v2","created":"Sun, 28 May 2023 09:14:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13902","submitter":"Seung Jae Lee","authors":"Hyunwoo Kang, Jaeho Shin, Jaewook Shin, Youngseok Jang, Seung Jae Lee","title":"Design and Operation of Autonomous Wheelchair Towing Robot","comments":"Submitted to Intelligent Service Robotics","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this study, a new concept of a wheelchair-towing robot for the facile\nelectrification of manual wheelchairs is introduced. The development of this\nconcept includes the design of towing robot hardware and an autonomous driving\nalgorithm to ensure the safe transportation of patients to their intended\ndestinations inside the hospital. We developed a novel docking mechanism to\nfacilitate easy docking and separation between the towing robot and the manual\nwheelchair, which is connected to the front caster wheel of the manual\nwheelchair. The towing robot has a mecanum wheel drive, enabling the robot to\nmove with a high degree of freedom in the standalone driving mode while\nadhering to kinematic constraints in the docking mode. Our novel towing robot\nfeatures a camera sensor that can observe the ground ahead which allows the\nrobot to autonomously follow color-coded wayfinding lanes installed in hospital\ncorridors. This study introduces dedicated image processing techniques for\ncapturing the lanes and control algorithms for effectively tracing a path to\nachieve autonomous path following. The autonomous towing performance of our\nproposed platform was validated by a real-world experiment in which a hospital\nenvironment with colored lanes was created.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:25:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13903","submitter":"Vaishnavi Himakunthala","authors":"Vaishnavi Himakunthala, Andy Ouyang, Daniel Rose, Ryan He, Alex Mei,\n  Yujie Lu, Chinmay Sonar, Michael Saxon, William Yang Wang","title":"Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video\n  Infilling and Prediction","comments":"8 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite constituting 65% of all internet traffic in 2023, video content is\nunderrepresented in generative AI research. Meanwhile, recent large language\nmodels (LLMs) have become increasingly integrated with capabilities in the\nvisual modality. Integrating video with LLMs is a natural next step, so how can\nthis gap be bridged? To advance video reasoning, we propose a new research\ndirection of VideoCOT on video keyframes, which leverages the multimodal\ngenerative abilities of vision-language models to enhance video reasoning while\nreducing the computational complexity of processing hundreds or thousands of\nframes. We introduce VIP, an inference-time dataset that can be used to\nevaluate VideoCOT, containing 1) a variety of real-life videos with keyframes\nand corresponding unstructured and structured scene descriptions, and 2) two\nnew video reasoning tasks: video infilling and scene prediction. We benchmark\nvarious vision-language models on VIP, demonstrating the potential to use\nvision-language models and LLMs to enhance video chain of thought reasoning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:26:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13904","submitter":"Yuxiao Li","authors":"Yuxiao Li, Santiago Mazuelas, Yuan Shen","title":"Deep GEM-Based Network for Weakly Supervised UWB Ranging Error\n  Mitigation","comments":"6 pages, 4 figures, Published in: MILCOM 2021 - 2021 IEEE Military\n  Communications Conference (MILCOM)","journal-ref":"MILCOM 2021 - 2021 IEEE Military Communications Conference\n  (MILCOM), San Diego, CA, USA, 2021, pp. 528-532","doi":"10.1109/MILCOM52596.2021.9653015.","report-no":null,"categories":"cs.LG cs.IT math.IT stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Ultra-wideband (UWB)-based techniques, while becoming mainstream approaches\nfor high-accurate positioning, tend to be challenged by ranging bias in harsh\nenvironments. The emerging learning-based methods for error mitigation have\nshown great performance improvement via exploiting high semantic features from\nraw data. However, these methods rely heavily on fully labeled data, leading to\na high cost for data acquisition. We present a learning framework based on weak\nsupervision for UWB ranging error mitigation. Specifically, we propose a deep\nlearning method based on the generalized expectation-maximization (GEM)\nalgorithm for robust UWB ranging error mitigation under weak supervision. Such\nmethod integrate probabilistic modeling into the deep learning scheme, and\nadopt weakly supervised labels as prior information. Extensive experiments in\nvarious supervision scenarios illustrate the superiority of the proposed\nmethod.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:26:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13905","submitter":"Rowel Atienza","authors":"Rowel Atienza","title":"EfficientSpeech: An On-Device Text to Speech Model","comments":"To be presented at ICASSP 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.SD","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  State of the art (SOTA) neural text to speech (TTS) models can generate\nnatural-sounding synthetic voices. These models are characterized by large\nmemory footprints and substantial number of operations due to the long-standing\nfocus on speech quality with cloud inference in mind. Neural TTS models are\ngenerally not designed to perform standalone speech syntheses on\nresource-constrained and no Internet access edge devices. In this work, an\nefficient neural TTS called EfficientSpeech that synthesizes speech on an ARM\nCPU in real-time is proposed. EfficientSpeech uses a shallow non-autoregressive\npyramid-structure transformer forming a U-Network. EfficientSpeech has 266k\nparameters and consumes 90 MFLOPS only or about 1% of the size and amount of\ncomputation in modern compact models such as Mixer-TTS. EfficientSpeech\nachieves an average mel generation real-time factor of 104.3 on an RPi4. Human\nevaluation shows only a slight degradation in audio quality as compared to\nFastSpeech2.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:28:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13906","submitter":"Caspar Schwarz-Schilling","authors":"Benjamin Kraner, Nicol\\`o Vallarano, Claudio J. Tessone, Caspar\n  Schwarz-Schilling","title":"Agent-Based Modelling of Ethereum Consensus","comments":"8 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a study of the Poof-of-Stake (PoW) Ethereum consensus\nprotocol, following the recent switch from Proof-of-Work (PoS) to\nProof-of-Stake within Merge upgrade. The new protocol has resulted in reduced\nenergy consumption and a shift in economic incentives, but it has also\nintroduced new threat sources such as chain reorganizations and balancing\nattacks. Using a simple and flexible agent-based model, this study employs a\ntime-continuous simulation algorithm to analyze the evolution of the blocktree\nand assess the impact of initial conditions on consensus quality. The model\nsimulates validator node behavior and the information propagation throughout\nthe peer-to-peer network of validators to analyze the resulting blockchain\nstructure. Key variables in the model include the topology of the peer-to-peer\nnetwork and average block and attestation latencies. Metrics to evaluate\nconsensus quality are established, and means to observe the model's\nresponsiveness to changes in parameters are provided. The simulations reveal a\nphase transition in which the system switches from a consensus state to a\nnon-consensus state, with a theoretical justification presented for this\nobservation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:29:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13907","submitter":"Martin Moriam\\'e","authors":"Martin Moriam\\'e and Timoteo Carletti","title":"On the location and the strength of controllers to desynchronize coupled\n  Kuramoto oscillators","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS nlin.AO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Synchronization is an ubiquitous phenomenon in dynamical systems of networked\noscillators. While it is often a goal to achieve, in some context one would\nlike to decrease it, e.g., although synchronization is essential to the good\nfunctioning of brain dynamics, hyper-synchronization can induce problems like\nepilepsy seizures. Motivated by this problem, scholars have developed pinning\ncontrol schemes able to decrease synchronization in a system. Focusing on one\nof these methods, the goal of the present work is to analyse which is the best\nway to select the controlled nodes, i.e. the one that guarantees the lower\nsynchronization rate. We show that hubs are generally the most advantageous\nnodes to control, especially when the degree distribution is heterogeneous.\nNevertheless, pinning a too large number of hubs is in general not an\nappropriate choice. Our results are in line with previous works that studied\npinning control aimed to increase synchronization. These observations shed\nlight on an interesting universality of good practice of node selection\ndisregarding the actual goal of the control scheme.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:30:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13908","submitter":"Bogdan Damski","authors":"Bogdan Damski","title":"Non-equilibrium dynamics of dipole-charged fields in the Proca theory","comments":"11 pp","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We discuss the dynamics of field configurations encoded in the certain class\nof electric (magnetic) dipole-charged states in the Proca theory of the real\nmassive vector field. We construct such states so as to ensure that the long\ndistance structure of the mean electromagnetic field in them is initially set\nby the formula describing the electromagnetic field of the electric (magnetic)\ndipole. We analyze then how such a mean electromagnetic field evolves in time.\nWe find that far away from the center of the initial field configuration, the\nlong range component of the mean electromagnetic field harmonically oscillates,\nwhich leads to the phenomenon of the periodic oscillations of the electric\n(magnetic) dipole moment. We also find that near the center of the initial\nfield configuration, the mean electromagnetic field escapes from its initial\narrangement and a spherical shock wave propagating with the speed of light\nappears in the studied system. A curious configuration of the axisymmetric mean\nelectric field is found to accompany the mean magnetic field in magnetic\ndipole-charged states.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:31:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13909","submitter":"Haonan Qiu","authors":"Haonan Qiu, Zeyin Song, Yanqi Chen, Munan Ning, Wei Fang, Tao Sun,\n  Zhengyu Ma, Li Yuan, and Yonghong Tian","title":"Temporal Contrastive Learning for Spiking Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Biologically inspired spiking neural networks (SNNs) have garnered\nconsiderable attention due to their low-energy consumption and spatio-temporal\ninformation processing capabilities. Most existing SNNs training methods first\nintegrate output information across time steps, then adopt the cross-entropy\n(CE) loss to supervise the prediction of the average representations. However,\nin this work, we find the method above is not ideal for the SNNs training as it\nomits the temporal dynamics of SNNs and degrades the performance quickly with\nthe decrease of inference time steps. One tempting method to model temporal\ncorrelations is to apply the same label supervision at each time step and treat\nthem identically. Although it can acquire relatively consistent performance\nacross various time steps, it still faces challenges in obtaining SNNs with\nhigh performance. Inspired by these observations, we propose Temporal-domain\nsupervised Contrastive Learning (TCL) framework, a novel method to obtain SNNs\nwith low latency and high performance by incorporating contrastive supervision\nwith temporal domain information. Contrastive learning (CL) prompts the network\nto discern both consistency and variability in the representation space,\nenabling it to better learn discriminative and generalizable features. We\nextend this concept to the temporal domain of SNNs, allowing us to flexibly and\nfully leverage the correlation between representations at different time steps.\nFurthermore, we propose a Siamese Temporal-domain supervised Contrastive\nLearning (STCL) framework to enhance the SNNs via augmentation, temporal and\nclass constraints simultaneously. Extensive experimental results demonstrate\nthat SNNs trained by our TCL and STCL can achieve both high performance and low\nlatency, achieving state-of-the-art performance on a variety of datasets (e.g.,\nCIFAR-10, CIFAR-100, and DVS-CIFAR10).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:31:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13910","submitter":"Hasan Nayir","authors":"Hasan Nayir, Erhan Karakoca, G\\\"une\\c{s} Karabulut Kurt, Ali\n  G\\\"or\\c{c}in","title":"Experimental Assessment of Misalignment Effects in Terahertz\n  Communications","comments":"6 pages, 6 figures, conference paper","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Terahertz (THz) frequencies are important for next generation wireless\nsystems due to the advantages in terms of large available bandwidths. On the\nother hand, the limited range due to high attenuation in these frequencies can\nbe overcome via densely installed heterogeneous networks also utilizing UAVs in\na three-dimensional hyperspace. Yet, THz communications rely on precise beam\nalignment, if not handled properly results in low signal strength at the\nreceiver which impacts THz signals more than conventional ones. This work\nfocuses on the importance of precise alignment in THz communication systems and\nthe significant effect of proper alignment is validated through comprehensive\nmeasurements conducted through a state-of-the-art measurement setup, which\nenables accurate data collection between 240 GHz to 300 GHz at varying angles\nand distances in an anechoic chamber eliminating reflections. By analyzing the\nchannel frequency and impulse responses of these extensive and particular\nmeasurements, this study provides the first quantifiable results in terms of\nmeasuring the effects of beam misalignment in THz frequencies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:32:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13911","submitter":"Yuxiao Li","authors":"Yuxiao Li, Santiago Mazuelas, Yuan Shen","title":"A Deep Learning Approach for Generating Soft Range Information from RF\n  Data","comments":"Published in: 2021 IEEE Globecom Workshops (GC Wkshps)","journal-ref":"021 IEEE Globecom Workshops (GC Wkshps), Madrid, Spain, 2021, pp.\n  1-5","doi":"10.1109/GCWkshps52748.2021.9681832.","report-no":null,"categories":"cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Radio frequency (RF)-based techniques are widely adopted for indoor\nlocalization despite the challenges in extracting sufficient information from\nmeasurements. Soft range information (SRI) offers a promising alternative for\nhighly accurate localization that gives all probable range values rather than a\nsingle estimate of distance. We propose a deep learning approach to generate\naccurate SRI from RF measurements. In particular, the proposed approach is\nimplemented by a network with two neural modules and conducts the generation\ndirectly from raw data. Extensive experiments on a case study with two public\ndatasets are conducted to quantify the efficiency in different indoor\nlocalization tasks. The results show that the proposed approach can generate\nhighly accurate SRI, and significantly outperforms conventional techniques in\nboth non-line-of-sight (NLOS) detection and ranging error mitigation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:33:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13912","submitter":"Federico Rizzuti","authors":"F. Rizzuti, R. Hirschi, W. D. Arnett, C. Georgy, C. Meakin, A. StJ.\n  Murphy, T. Rauscher, V. Varma","title":"3D stellar evolution: hydrodynamic simulations of a complete burning\n  phase in a massive star","comments":"12 pages, 15 figures. Accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1572","report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Our knowledge of stellar evolution is driven by one-dimensional (1D)\nsimulations. 1D models, however, are severely limited by uncertainties on the\nexact behaviour of many multi-dimensional phenomena occurring inside stars,\naffecting their structure and evolution. Recent advances in computing resources\nhave allowed small sections of a star to be reproduced with multi-D\nhydrodynamic models, with an unprecedented degree of detail and realism. In\nthis work, we present a set of 3D simulations of a convective neon-burning\nshell in a 20 M$_\\odot$ star run for the first time continuously from its early\ndevelopment through to complete fuel exhaustion, using unaltered input\nconditions from a 321D-guided 1D stellar model. These simulations help answer\nsome open questions in stellar physics. In particular, they show that\nconvective regions do not grow indefinitely due to entrainment of fresh\nmaterial, but fuel consumption prevails over entrainment, so when fuel is\nexhausted convection also starts decaying. Our results show convergence between\nthe multi-D simulations and the new 321D-guided 1D model, concerning the amount\nof convective boundary mixing to include in stellar models. The size of the\nconvective zones in a star strongly affects its structure and evolution, thus\nrevising their modelling in 1D will have important implications for the life\nand fate of stars. This will thus affect theoretical predictions related to\nnucleosynthesis, supernova explosions and compact remnants.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:35:37 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13913","submitter":"Yun Li","authors":"Yun Li, Hongwei Liu, Sihem Mesnager","title":"Constructions of Constant Dimension Subspace Codes","comments":"This article was submitted to Designs, Codes and Cryptography on\n  November 22nd, 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.CO math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Subspace codes have important applications in random network coding. It is\ninteresting to construct subspace codes with both sizes, and the minimum\ndistances are as large as possible. In particular, cyclic constant dimension\nsubspaces codes have additional properties which can be used to make encoding\nand decoding more efficient. In this paper, we construct large cyclic constant\ndimension subspace codes with minimum distances $2k-2$ and $2k$. These codes\nare contained in $\\mathcal{G}_q(n, k)$, where $\\mathcal{G}_q(n, k)$ denotes the\nset of all $k$-dimensional subspaces of $\\mathbb{F}_{q^n}$. Consequently, some\nresults in \\cite{FW}, \\cite{NXG}, and \\cite{ZT} are extended.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:37:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13914","submitter":"Maik Sch\\\"unemann","authors":"Maik Sch\\\"unemann and Udo Ernst","title":"Routing by spontaneous synchronization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Selective attention allows to process stimuli which are behaviorally\nrelevant, while attenuating distracting information. However, it is an open\nquestion what mechanisms implement selective routing, and how they are engaged\nin dependence on behavioral need. Here we introduce a novel framework for\nselective processing by spontaneous synchronization. Input signals become\norganized into 'avalanches' of synchronized spikes which propagate to target\npopulations. Selective attention enhances spontaneous synchronization and\nboosts signal transfer by a simple disinhibition of a control population,\nwithout requiring changes in synaptic weights. Our framework is fully\nanalytically tractable and provides a complete understanding of all stages of\nthe routing mechanism, yielding closed-form expressions for input-output\ncorrelations. Interestingly, although gamma oscillations can naturally occur\nthrough a recurrent dynamics, we can formally show that the routing mechanism\nitself does not require such oscillatory activity and works equally well if\nsynchronous events would be randomly shuffled over time. Our framework explains\na large range of physiological findings in a unified framework and makes\nspecific predictions about putative control mechanisms and their effects on\nneural dynamics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:39:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13915","submitter":"Kexin Wang","authors":"Kexin Wang, Nils Reimers, Iryna Gurevych","title":"DAPR: A Benchmark on Document-Aware Passage Retrieval","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Recent neural retrieval mainly focuses on ranking short texts and is\nchallenged with long documents. Existing work mainly evaluates either ranking\npassages or whole documents. However, there are many cases where the users want\nto find a relevant passage within a long document from a huge corpus, e.g.\nlegal cases, research papers, etc. In this scenario, the passage often provides\nlittle document context and thus challenges the current approaches to finding\nthe correct document and returning accurate results. To fill this gap, we\npropose and name this task Document-Aware Passage Retrieval (DAPR) and build a\nbenchmark including multiple datasets from various domains, covering both DAPR\nand whole-document retrieval. In experiments, we extend the state-of-the-art\nneural passage retrievers with document-level context via different approaches\nincluding prepending document summary, pooling over passage representations,\nand hybrid retrieval with BM25. The hybrid-retrieval systems, the overall best,\ncan only improve on the DAPR tasks marginally while significantly improving on\nthe document-retrieval tasks. This motivates further research in developing\nbetter retrieval systems for the new task. The code and the data are available\nat https://github.com/kwang2049/dapr\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:39:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13916","submitter":"Conor Houghton","authors":"Conor Houghton","title":"An Ising-like model for language evolution","comments":"Three page extended abstract, accepted to ALIFE 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  I propose a novel Ising-like model of language evolution. In a simple way,\nIsing-like models represent the countervailing tendencies towards convergence\nand change present in language evolution. In the ordinary Ising-model, a node\non a graph, in this case representing a language speaker, interacts with all\nits neighbors. In contrast, in the model proposed here, a node only interacts\nwith the neighboring node whose state-vector is most similar to its own. This\nreflects the tendency of people to interact with others who speak a similar\nlanguage. Unlike the ordinary Ising model, which tends towards language\ncontinua, this new model allows language boundaries.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:42:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13917","submitter":"Jiacheng Ye","authors":"Jiacheng Ye, Chengzu Li, Lingpeng Kong, Tao Yu","title":"Generating Data for Symbolic Language with Large Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While large language models (LLMs) bring not only performance but also\ncomplexity, recent work has started to turn LLMs into data generators rather\nthan task inferencers, where another affordable task model is trained for\nefficient deployment and inference. However, such an approach has primarily\nbeen applied to natural language tasks and has not yet been explored for\nsymbolic language tasks with complex structured outputs (e.g., semantic parsing\nand code generation). In this paper, we propose SymGen which utilizes LLMs for\ngenerating various annotation-expensive symbolic language data. SymGen consists\nof an informative prompt to steer generation and an agreement-based verifier to\nimprove data correctness. We conduct extensive experiments on six symbolic\nlanguage tasks across various settings. Compared with the LLMs, we demonstrate\nthe 1\\%-sized task model can achieve comparable or better performance, largely\ncutting inference and deployment costs. We also show that generated data with\nonly a few human demonstrations can be as effective as over 10 times the amount\nof human-annotated data when training the task model, saving a considerable\namount of annotation effort. SymGen sheds new light on data generation for\ncomplex tasks, and we release the code at\n\\href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:44:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13919","submitter":"Savvas Papaioannou","authors":"Savvas Papaioannou, Panayiotis Kolios and Georgios Ellinas","title":"Distributed Estimation and Control for Jamming an Aerial Target With\n  Multiple Agents","comments":"IEEE Transactions on Mobile Computing 2023","journal-ref":null,"doi":"10.1109/TMC.2022.3207589","report-no":null,"categories":"cs.SY eess.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This work proposes a distributed estimation and control approach in which a\nteam of aerial agents equipped with radio jamming devices collaborate in order\nto intercept and concurrently track-and-jam a malicious target, while at the\nsame time minimizing the induced jamming interference amongst the team.\nSpecifically, it is assumed that the malicious target maneuvers in 3D space,\navoiding collisions with obstacles and other 3D structures in its way,\naccording to a stochastic dynamical model. Based on this, a track-and-jam\ncontrol approach is proposed which allows a team of distributed aerial agents\nto decide their control actions online, over a finite planning horizon, to\nachieve uninterrupted radio-jamming and tracking of the malicious target, in\nthe presence of jamming interference constraints. The proposed approach is\nformulated as a distributed model predictive control (MPC) problem and is\nsolved using mixed integer quadratic programming (MIQP). Extensive evaluation\nof the system's performance validates the applicability of the proposed\napproach in challenging scenarios with uncertain target dynamics, noisy\nmeasurements, and in the presence of obstacles.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:48:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13921","submitter":"Ruichen Wang","authors":"Ruichen Wang, Zekang Chen, Chen Chen, Jian Ma, Haonan Lu, Xiaodong Lin","title":"Compositional Text-to-Image Synthesis with Attention Map Control of\n  Diffusion Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent text-to-image (T2I) diffusion models show outstanding performance in\ngenerating high-quality images conditioned on textual prompts. However, these\nmodels fail to semantically align the generated images with the text\ndescriptions due to their limited compositional capabilities, leading to\nattribute leakage, entity leakage, and missing entities. In this paper, we\npropose a novel attention mask control strategy based on predicted object boxes\nto address these three issues. In particular, we first train a BoxNet to\npredict a box for each entity that possesses the attribute specified in the\nprompt. Then, depending on the predicted boxes, unique mask control is applied\nto the cross- and self-attention maps. Our approach produces a more\nsemantically accurate synthesis by constraining the attention regions of each\ntoken in the prompt to the image. In addition, the proposed method is\nstraightforward and effective, and can be readily integrated into existing\ncross-attention-diffusion-based T2I generators. We compare our approach to\ncompeting methods and demonstrate that it not only faithfully conveys the\nsemantics of the original text to the generated content, but also achieves high\navailability as a ready-to-use plugin.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:49:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13922","submitter":"Diego Alonso-Or\\'an","authors":"Diego Alonso-Or\\'an, \\'Angel Dur\\'an and Rafael Granero-Belinch\\'on","title":"Derivation and well-posedness for asymptotic models of cold plasmas","comments":"25 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we derive three new asymptotic models for an\nhyperbolic-hyperbolicelliptic system of PDEs describing the motion of a\ncollision-free plasma in a magnetic field. The first of these models takes the\nform of a non-linear and non-local Boussinesq system (for the ionic density and\nvelocity) while the second is a non-local wave equation (for the ionic\ndensity). Moreover, we derive a unidirectional asymptotic model of the later\nwhich is closely related to the well-known Fornberg-Whitham equation. We also\nprovide the well-posedness of these asymptotic models in Sobolev spaces. To\nconclude, we demonstrate the existence of a class of initial data which exhibit\nwave breaking for the unidirectional model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:50:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13923","submitter":"Himanshu Sahu","authors":"Himanshu Sahu, C. M. Chandrashekar","title":"Open system approach to Neutrino oscillations in a quantum walk\n  framework","comments":"10 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Quantum simulation provides a computationally-feasible approach to model and\nstudy many problems in chemistry, condensed-matter physics, or high-energy\nphysics where quantum phenomenon define the systems behaviour. In high-energy\nphysics, quite a few possible applications are investigated in the context of\ngauge theories and their application to dynamic problems, topological problems,\nhigh-baryon density configurations, or collective neutrino oscillations. In\nparticular, schemes for simulating neutrino oscillations are proposed using a\nquantum walk framework. In this study, we approach the problem of simulating\nneutrino oscillation from the perspective of open quantum systems by treating\nthe position space of quantum walk as environment. We have obtained the\nrecurrence relation for Kraus operator which is used to represent the dynamics\nof the neutrino flavor change in the form of reduced coin states. We establish\na connection between the dynamics of reduced coin state and neutrino\nphenomenology, enabling one to fix the simulation parameters for a given\nneutrino experiment and reduces the need for extended position space to\nsimulate neutrino oscillations. We have also studied the behavior of linear\nentropy as a measure of entanglement between different flavors in the same\nframework.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:51:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13924","submitter":"Ruiqi Liu","authors":"Ruiqi Liu, Mengnan Jian, Dawei Chen, Xu Lin, Yichao Cheng, Wei Cheng,\n  Shijun Chen","title":"Integrated Sensing and Communication based Outdoor Multi-Target\n  Detection, Tracking and Localization in Practical 5G Networks","comments":"Submitted to an open access journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The 6th generation (6G) wireless networks will likely to support a variety of\ncapabilities beyond communication, such as sensing and localization, through\nthe use of communication networks empowered by advanced technologies.\nIntegrated sensing and communication (ISAC) has been recognized as a critical\ntechnology as well as an usage scenario for 6G, as widely agreed by leading\nglobal standardization bodies. ISAC utilizes communication infrastructure and\ndevices to provide the capability of sensing the environment with high\nresolution, as well as tracking and localizing moving objects nearby. Meeting\nboth the requirements for communication and sensing simultaneously, ISAC based\napproaches celebrate the advantages of higher spectral and energy efficiency\ncompared to two separate systems to serve two purposes, and potentially lower\ncosts and easy deployment. A key step towards the standardization and\ncommercialization of ISAC is to carry out comprehensive field trials in\npractical networks, such as the 5th generation (5G) network, to demonstrate its\ntrue capacities in practical scenarios. In this paper, an ISAC based outdoor\nmulti-target detection, tracking and localization approach is proposed and\nvalidated in 5G networks. The proposed system comprises of 5G base stations\n(BSs) which serve nearby mobile users normally, while accomplishing the task of\ndetecting, tracking and localizing drones, vehicles and pedestrians\nsimultaneously. Comprehensive trial results demonstrate the relatively high\naccuracy of the proposed method in practical outdoor environment when tracking\nand localizing single targets and multiple targets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:51:38 GMT"},{"version":"v2","created":"Wed, 24 May 2023 02:39:04 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13925","submitter":"Bokai Xu","authors":"Bokai Xu, Jiayi Zhang, Jiaxun Li, Huahua Xiao, and Bo Ai","title":"Jac-PCG Based Low-Complexity Precoding for Extremely Large-Scale MIMO\n  Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Extremely large-scale multiple-input-multipleoutput (XL-MIMO) has been\nreviewed as a promising technology for future sixth-generation (6G) networks to\nachieve higher performance. In practice, various linear precoding schemes, such\nas zero-forcing (ZF) and regularized ZF (RZF) precoding, are sufficient to\nachieve near-optimal performance in traditional massive MIMO (mMIMO) systems.\nIt is critical to note that in large-scale antenna arrays the operation of\nchannel matrix inversion poses a significant computational challenge for these\nprecoders. Therefore, we explore several iterative methods for determining the\nprecoding matrix for XL-MIMO systems instead of direct matrix inversion. Taking\ninto account small- and large-scale fading as well as spatial correlation\nbetween antennas, we study their computational complexity and convergence rate.\nFurthermore, we propose the Jacobi-Preconditioning Conjugate Gradient (Jac-PCG)\niterative inversion method, which enjoys a faster convergence speed than the CG\nmethod. Besides, the closed-form expression of spectral efficiency (SE)\nconsidering the interference between subarrays in downlink XL-MIMO systems is\nderived. In the numerical results, it is shown that the complexity given by the\nJac-PCG algorithm has about 54% reduction than the traditional RZF algorithm at\nbasically the same SE performance.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:51:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13926","submitter":"Sudarsun Santhiappan","authors":"Sudarsun Santhiappan, Nitin Shravan, Balaraman Ravindran","title":"Clustering Indices based Automatic Classification Model Selection","comments":"Submitted to Journal of Data Science and Analytics (JDSA)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Classification model selection is a process of identifying a suitable model\nclass for a given classification task on a dataset. Traditionally, model\nselection is based on cross-validation, meta-learning, and user preferences,\nwhich are often time-consuming and resource-intensive. The performance of any\nmachine learning classification task depends on the choice of the model class,\nthe learning algorithm, and the dataset's characteristics. Our work proposes a\nnovel method for automatic classification model selection from a set of\ncandidate model classes by determining the empirical model-fitness for a\ndataset based only on its clustering indices. Clustering Indices measure the\nability of a clustering algorithm to induce good quality neighborhoods with\nsimilar data characteristics. We propose a regression task for a given model\nclass, where the clustering indices of a given dataset form the features and\nthe dependent variable represents the expected classification performance. We\ncompute the dataset clustering indices and directly predict the expected\nclassification performance using the learned regressor for each candidate model\nclass to recommend a suitable model class for dataset classification. We\nevaluate our model selection method through cross-validation with 60 publicly\navailable binary class datasets and show that our top3 model recommendation is\naccurate for over 45 of 60 datasets. We also propose an end-to-end Automated ML\nsystem for data classification based on our model selection method. We evaluate\nour end-to-end system against popular commercial and noncommercial Automated ML\nsystems using a different collection of 25 public domain binary class datasets.\nWe show that the proposed system outperforms other methods with an excellent\naverage rank of 1.68.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:52:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13928","submitter":"Francesco Ferrante","authors":"M. Mandolino, D. Scholtes, F. Ferrante, G. Rizzello","title":"A Physics-Based Hybrid Dynamical Model of Hysteresis in Polycrystalline\n  Shape Memory Alloy Wire Transducers","comments":"IEEE/ASME Transactions on Mechatronics 2023","journal-ref":null,"doi":"10.1109/TMECH.2023.3253250","report-no":null,"categories":"eess.SY cs.RO cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Shape Memory Alloys (SMAs) are a class of smart materials that exhibit a\nmacroscopic contraction of up to 5% when heated via an electric current. This\neffect can be exploited for the development of novel unconventional actuators.\nDespite having many features such as compactness, lightweight, and high energy\ndensity, commercial SMA wires are characterized by a highly nonlinear behavior,\nwhich manifests itself as a load-, temperature-, and rate-dependent hysteresis\nexhibiting a complex shape and minor loops. Accurate modeling and compensation\nof such hysteresis are fundamental for the development of high-performance SMA\napplications. In this work, we propose a new dynamical model to describe the\ncomplex hysteresis of polycrystalline SMA wires. The approach is based on a\nreformulation of the Muller-Achenbach-Seelecke model for uniaxial SMA wires\nwithin a hybrid dynamical framework. In this way, we can significantly reduce\nthe numerical complexity and computation time without losing accuracy and\nphysical interpretability. After describing the model, an extensive\nexperimental validation campaign is carried out on a 75 {\\mu}m diameter SMA\nwire specimen. The new hybrid model will pave the development of hybrid\ncontrollers and observers for SMA actuators.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:53:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13932","submitter":"Christophe Picouleau","authors":"Niccol\\`o Di Marco, Andrea Frosini, Christophe Picouleau","title":"The Complexity of 2-Intersection Graphs of 3-Hypergraphs Recognition for\n  Claw-free Graphs and triangulated Claw-free Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a 3-uniform hypergraph H, its 2-intersection graph G has for vertex set\nthe hyperedges of H and ee' is an edge of G whenever e and e' have exactly two\ncommon vertices in H. Di Marco et al. prove that deciding wether a graph G is\nthe 2-intersection graph of a 3-uniform hypergraph is NP-complete. The main\nproblems we study concern the class of claw-free graphs. We show that the\nrecognition problem remains NP-complete when G is claw-free graphs but becomes\npolynomial if in addition G is triangulated.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:55:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13933","submitter":"Juan Mera Men\\'endez","authors":"Juan Mera Men\\'endez, Jose Emilio Labra Gayo, Enrique Riesgo Canal,\n  Aitor Echevarr\\'ia Fern\\'andez","title":"A comparison between traditional and Serverless technologies in a\n  microservices setting","comments":"11 pages, 4 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.PF","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Serverless technologies, also known as FaaS (Function as a Service), are\npromoted as solutions that provide dynamic scalability, speed of development,\ncost-per-consumption model, and the ability to focus on the code while taking\nattention away from the infrastructure that is managed by the vendor. A\nmicroservices architecture is defined by the interaction and management of the\napplication state by several independent services, each with a well-defined\ndomain. When implementing software architectures based on microservices, there\nare several decisions to take about the technologies and the possibility of\nadopting Serverless. In this study, we implement 9 prototypes of the same\nmicroservice application using different technologies. Some architectural\ndecisions and their impact on the performance and cost of the result obtained\nare analysed. We use Amazon Web Services and start with an application that\nuses a more traditional deployment environment (Kubernetes) and migration to a\nserverless architecture is performed by combining and analysing the impact\n(both cost and performance) of the use of different technologies such as AWS\nECS Fargate, AWS Lambda, DynamoDB or DocumentDB.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:56:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13940","submitter":"Amnon Aharony","authors":"Amnon Aharony","title":"50 years of correlations with Michael Fisher and the renormalization\n  group","comments":"Added Fig. 4 ad foototes. Pls identify people in Fig 4","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech hep-lat hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper will be published in ``50 years of the renormalization group\",\ndedicated to the memory of Michael E. Fisher, edited by Amnon Aharony, Ora\nEntin-Wohlman, David Huse, and Leo Radzihovsky, World Scientific. I start with\na review of my personal and scientific interactions with Michael E. Fisher, who\nwas my post-doc mentor in 1972-1974. I then describe several recent\nrenormalization group studies, which started during those years, and still\nraise some open issues. These include the magnets with dipole-dipole\ninteractions, the puzzle of the bicritical points and the random field Ising\nmodel.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:01:16 GMT"},{"version":"v2","created":"Mon, 29 May 2023 08:29:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13942","submitter":"Paolo Gandini","authors":"Paolo Gandini (on behalf of the LHCb collaboration)","title":"Heavy flavour spectroscopy at LHCb. Contribution to the 2023 QCD session\n  of the 57th Rencontres de Moriond","comments":"4 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this talk, we present the latest experimental results on heavy flavour\nspectroscopy at the LHCb detector. The first observation of two baryonic\nresonances is reported in the $\\Xi_b^{(-,0)} \\pi^+\\pi^-$ final states and a\nstudy of charmonium decays to $K_s^0 K \\pi$ in $B \\rightarrow (K_s^0 K \\pi) K$\ndecays is presented.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:01:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13943","submitter":"G\\'eza Attila Cs\\\"ornyei","authors":"G. Cs\\\"ornyei, R. I. Anderson, C. Vogl, S. Taubenberger, S. Blondin,\n  B. Leibundgut, W. Hillebrandt","title":"Reeling in the Whirlpool: the distance to M 51 clarified by Cepheids and\n  the Type IIP SN 2005cs","comments":"18 pages, 16 figures, submitted to A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.HE astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite being one of the best-known galaxies, the distance to the Whirlpool\nGalaxy, M 51, is still debated. Current estimates range from 6.02 to 9.09 Mpc,\nand different methods yield discrepant results. No Cepheid distance has been\npublished for M 51 to date. We aim to estimate a more reliable distance to M 51\nthrough two independent methods: Cepheid variables and their period-luminosity\nrelation, and an augmented version of the expanding photosphere method (EPM) on\nthe Type IIP SN 2005cs. For the Cepheid variables, we analyse a recently\npublished HST catalogue of stars in M 51. By applying light curve and\ncolour-magnitude diagram-based filtering, we select a high-quality sample of M\n51 Cepheids to estimate the distance through the period-luminosity relation.\nFor SN 2005cs, an emulator-based spectral fitting technique is applied, which\nallows for the fast and reliable estimation of physical parameters of the\nsupernova atmosphere. We augment the established framework of EPM with these\nspectral models to obtain a precise distance to M 51. The two resulting\ndistance estimates are D_Cep = 7.59 +/- 0.30 Mpc and D_2005cs = 7.34 +/- 0.39\nMpc using the Cepheid period-luminosity relation and the spectral modelling of\nSN 2005cs respectively. This is the first published Cepheid distance for this\ngalaxy. Given that these two estimates are completely independent, one may\ncombine them, which yields D_M51 = 7.50 +/- 0.24 Mpc (3.2% uncertainty). Our\ndistance estimates are in agreement with most of the results obtained\npreviously for M 51, while being more precise than the earlier counterparts.\nThey are however significantly lower than the TRGB estimates, which are often\nadopted for the distance to this galaxy. The results highlight the importance\nof direct cross-checks between independent distance estimates for quantifying\nsystematic uncertainties.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:01:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13944","submitter":"Kosuke Yamada","authors":"Kosuke Yamada, Ryohei Sasano, Koichi Takeda","title":"Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic\n  Frame Induction","comments":"Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The semantic frame induction tasks are defined as a clustering of words into\nthe frames that they evoke, and a clustering of their arguments according to\nthe frame element roles that they should fill. In this paper, we address the\nlatter task of argument clustering, which aims to acquire frame element\nknowledge, and propose a method that applies deep metric learning. In this\nmethod, a pre-trained language model is fine-tuned to be suitable for\ndistinguishing frame element roles through the use of frame-annotated data, and\nargument clustering is performed with embeddings obtained from the fine-tuned\nmodel. Experimental results on FrameNet demonstrate that our method achieves\nsubstantially better performance than existing methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:02:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13945","submitter":"Puyu Yang","authors":"Puyu Yang, Ahad Shoaib, Robert West, Giovanni Colavizza","title":"Wikipedia and open access","comments":"16 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Wikipedia is a well-known platform for disseminating knowledge, and\nscientific sources, such as journal articles, play a critical role in\nsupporting its mission. The open access movement aims to make scientific\nknowledge openly available, and we might intuitively expect open access to help\nfurther Wikipedia's mission. However, the extent of this relationship remains\nlargely unknown. To fill this gap, we analyze a large dataset of citations from\nWikipedia and model the role of open access in Wikipedia's citation patterns.\nWe find that open-access articles are extensively and increasingly more cited\nin Wikipedia. What is more, they show a 15% higher likelihood of being cited in\nWikipedia when compared to closed-access articles, after controlling for\nconfounding factors. This open-access citation effect is particularly strong\nfor articles with low citation counts, including recently published ones. Our\nresults show that open access plays a key role in the dissemination of\nscientific knowledge, including by providing Wikipedia editors timely access to\nnovel results. These findings have important implications for researchers,\npolicymakers, and practitioners in the field of information science and\ntechnology.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:10:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13946","submitter":"Yen-Huan Li","authors":"Chung-En Tsai and Ying-Ting Lin and Yen-Huan Li","title":"Data-Dependent Bounds for Online Portfolio Selection Without\n  Lipschitzness and Smoothness","comments":"34 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work introduces the first small-loss and gradual-variation regret bounds\nfor online portfolio selection, marking the first instances of data-dependent\nbounds for online convex optimization with non-Lipschitz, non-smooth losses.\nThe algorithms we propose exhibit sublinear regret rates in the worst cases and\nachieve logarithmic regrets when the data is \"easy,\" with per-iteration time\nalmost linear in the number of investment alternatives. The regret bounds are\nderived using novel smoothness characterizations of the logarithmic loss, a\nlocal norm-based analysis of following the regularized leader (FTRL) with\nself-concordant regularizers, which are not necessarily barriers, and an\nimplicit variant of optimistic FTRL with the log-barrier.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:16:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13947","submitter":"Wei Chen","authors":"Xiao Gong, Wei Chen, Bo Ai, Geert Leus","title":"Deep-Learning-Aided Alternating Least Squares for Tensor CP\n  Decomposition and Its Application to Massive MIMO Channel Estimation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  CANDECOMP/PARAFAC (CP) decomposition is the mostly used model to formulate\nthe received tensor signal in a multi-domain massive multiple-input\nmultiple-output (MIMO) system, as the receiver generally sums the components\nfrom different paths or users. To achieve accurate and low-latency channel\nestimation, good and fast CP decomposition algorithms are desired. The CP\nalternating least squares (CPALS) is the workhorse algorithm for calculating\nthe CP decomposition. However, its performance depends on the initializations,\nand good starting values can lead to more efficient solutions. Existing\ninitialization strategies are decoupled from the CPALS and are not necessarily\nfavorable for solving the CP decomposition. To enhance the algorithm's speed\nand accuracy, this paper proposes a deep-learning-aided CPALS (DL-CPALS) method\nthat uses a deep neural network (DNN) to generate favorable initializations.\nThe proposed DL-CPALS integrates the DNN and CPALS to a model-based deep\nlearning paradigm, where it trains the DNN to generate an initialization that\nfacilitates fast and accurate CP decomposition. Moreover, benefiting from the\nCP low-rankness, the proposed method is trained using noisy data and does not\nrequire paired clean data. The proposed DL-CPALS is applied to millimeter wave\nMIMO orthogonal frequency division multiplexing (mmWave MIMO-OFDM) channel\nestimation. Experimental results demonstrate the significant improvements of\nthe proposed method in terms of both speed and accuracy for CP decomposition\nand channel estimation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:17:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13948","submitter":"Cui Jiequan","authors":"Jiequan Cui, Zhuotao Tian, Zhisheng Zhong, Xiaojuan Qi, Bei Yu,\n  Hanwang Zhang","title":"Decoupled Kullback-Leibler Divergence Loss","comments":"under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss\nand observe that it is equivalent to the Doupled Kullback-Leibler (DKL)\nDivergence loss that consists of 1) a weighted Mean Square Error (wMSE) loss\nand 2) a Cross-Entropy loss incorporating soft labels. From our analysis of the\nDKL loss, we have identified two areas for improvement. Firstly, we address the\nlimitation of DKL in scenarios like knowledge distillation by breaking its\nasymmetry property in training optimization. This modification ensures that the\nwMSE component is always effective during training, providing extra\nconstructive cues. Secondly, we introduce global information into DKL for\nintra-class consistency regularization. With these two enhancements, we derive\nthe Improved Kullback-Leibler (IKL) Divergence loss and evaluate its\neffectiveness by conducting experiments on CIFAR-10/100 and ImageNet datasets,\nfocusing on adversarial training and knowledge distillation tasks. The proposed\napproach achieves new state-of-the-art performance on both tasks, demonstrating\nthe substantial practical merits. Code and models will be available soon at\nhttps://github.com/jiequancui/DKL.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:17:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13949","submitter":"Thibault Cavali\\'e","authors":"Thibault Cavali\\'e, Jonathan Lunine, Olivier Mousis","title":"A subsolar oxygen abundance or a radiative region deep in Jupiter\n  revealed by thermochemical modelling","comments":"9 pages, 5 figures, paper published in Nature Astronomy","journal-ref":null,"doi":"10.1038/s41550-023-01928-8","report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Jupiter's deep abundances help to constrain the formation history of the\nplanet and the environment of the protoplanetary nebula. Juno recently measured\nJupiter's deep oxygen abundance near the equator to be 2.2$_{-2.1}^{+3.9}$\ntimes the protosolar value (2$\\sigma$ uncertainties). Even if the nominal value\nis supersolar, subsolar abundances cannot be ruled out. Here we use a\nstate-of-the-art one-dimensional thermochemical and diffusion model with\nupdated chemistry to constrain the deep oxygen abundance with upper\ntropospheric CO observations. We find a value of 0.3$_{-0.2}^{+0.5}$ times the\nprotosolar value. This result suggests that Jupiter could have a carbon-rich\nenvelope that accreted in a region where the protosolar nebula was depleted in\nwater. However, our model can also reproduce a solar/supersolar water abundance\nif vertical mixing is reduced in a radiative layer where the deep oxygen\nabundance is obtained. More precise measurements of the deep water abundance\nare needed to discriminate between these two scenarios and understand Jupiter's\ninternal structure and evolution.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:19:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13950","submitter":"Chitrasen Jena","authors":"P. Sinha, V. Bairathi, K. Gopal, C. Jena, and S. Kabana","title":"Effect of nuclear structure on particle production in relativistic\n  heavy-ion collisions using the AMPT model","comments":"14 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex nucl-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We report first study of transverse momentum ($p_\\mathrm{T}$) spectra for\n$\\pi^{\\pm}$, $K^{\\pm}$, $p$, and $\\bar{p}$ in isobar,\n$^{96}_{44}$Ru+$^{96}_{44}$Ru and $^{96}_{40}$Zr+$^{96}_{40}$Zr, collisions at\n$\\sqrt{s_{\\mathrm{NN}}} = 200$ GeV using a multi-phase transport (AMPT) model.\nParticle yields ($dN/dy$), average transverse momenta ($\\langle p_\\mathrm{T}\n\\rangle$), and particle ratios are reported in various collision systems with\ndifferent parameterizations of the Woods-Saxon (WS) distribution. We observed a\nmaximum difference of 5% in the particle yields in peripheral collisions when\nwe included a quadrupole and octupole deformation and a nuclear size difference\nbetween the isobars. The $\\pi^{-}$/$\\pi^{+}$ ratio is smaller in Ru+Ru\ncollisions compared to Zr+Zr collisions indicating an effect of isospin due to\ndifference in number of protons and neutrons between the two nuclei. The\n$K^{-}$/$K^{+}$ ratio is same in both the systems indicating the dominance of\nthe pair production mechanism in the kaon production. The $\\bar{p}/p$ ratio is\nfurther smaller in Ru+Ru collisions than Zr+Zr collisions, indicating the\neffect of baryon stopping in addition to the isospin effect. A system size\ndependence is observed in $dN/dy$ and $\\langle p_\\mathrm{T} \\rangle$ when we\ncompare the results from isobar collisions with Au+Au and U+U collisions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:19:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13951","submitter":"Xing Wang","authors":"Xu-hang Jian, Xing Wang, Li-Lin Yang and Jing-Bang Zhao","title":"$\\varepsilon$-factorized differential equations for two-loop non-planar\n  triangle Feynman integrals with elliptic curves","comments":"43 pages, 9 figures","journal-ref":null,"doi":null,"report-no":"TUM-HEP-1456/23","categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we investigate two-loop non-planar triangle Feynman integrals\ninvolving elliptic curves. In contrast to the Sunrise and Banana integral\nfamilies, the triangle families involve non-trivial sub-sectors. We show that\nthe methodology developed in the context of Banana integrals can also be\nextended to these cases and obtain $\\varepsilon$-factorized differential\nequations for all sectors. The letters are combinations of modular forms on the\ncorresponding elliptic curves and algebraic functions arising from the\nsub-sectors. With uniform transcendental boundary conditions, we express our\nresults in terms of iterated integrals order-by-order in the dimensional\nregulator, which can be evaluated efficiently. Our method can be\nstraightforwardly generalized to other elliptic integral families and have\nimportant applications to precision physics at current and future high-energy\ncolliders.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:25:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13952","submitter":"Gian Paolo Papari Dr","authors":"G. P. Papari and V. M. Fomin","title":"Quantum Interference by Vortex Supercurrents","comments":"15 pages, 6 figures","journal-ref":null,"doi":"10.1002/pssr.202300038","report-no":null,"categories":"cond-mat.supr-con quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We analyze the origin of the parabolic background of magnetoresistance\noscillations measured in finite-width superconducting mesoscopic rings with\ninput and output stubs and in patterned films. The transmission model\nexplaining the sinusoidal oscillation of magnetoresistance is extended to\naddress the parabolic background as a function of the magnetic field. Apart\nfrom the interference mechanism activated by the ring, pinned superconducting\nvortices as topological defects introduce a further interference-based\ndistribution of supercurrents that affects, in turn, the voltmeter-sensed\nquasiparticles. The onset of vortices changes the topology of the\nsuperconducting state in a mesoscopic ring in a such a way that the full\nmagnetoresistance dynamics can be interpreted owing to the interference of the\nconstituents of the order parameter induced by both the ring with its\ndoubly-connected topology and the vortex lattice in it.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:27:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13953","submitter":"Masaki Yama","authors":"M. Yama, M. Matsuo, T. Kato","title":"Theory of inverse Rashba-Edelstein effect induced by spin pumping into a\n  two-dimensional electron gas","comments":"14 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We theoretically consider the inverse Rashba-Edelstein effect (IREE) induced\nby spin pumping from a ferromagnetic insulator (FI) into a two-dimensional\nelectron gas (2DEG) in which the Rashba and Dresselhaus spin-orbit interactions\ncoexist. We clarify that the magnetization and current in the 2DEG generated by\nthe IREE depend on the resonant frequency of the ferromagnetic resonance (FMR)\nand azimuth angle of the spontaneous spin polarization of the FI. We further\nshow that the magnetization and current increase substantially as the ratio of\nmagnitudes of Rashba and Dresselhaus spin-orbit interactions approaches unity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:29:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13954","submitter":"Moxin Li","authors":"Moxin Li, Wenjie Wang, Fuli Feng, Jizhi Zhang, Tat-Seng Chua","title":"Robust Instruction Optimization for Large Language Models with\n  Distribution Shifts","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large Language Models have demonstrated significant ability in accomplishing\na wide range of Natural Language Processing (NLP) tasks. However, their\nperformance is highly sensitive to the even minor changes in the phrasing of\nthe task instructions, leading to a line of research in automatic instruction\noptimization towards better performance for NLP tasks. Unfortunately, existing\nmethods for instruction optimization fail to consider the distribution shift\nbetween the seen training data and the unseen test data, where testing on\nunseen group of data with a different distribution could potentially lead to\nperformance drop. In this paper, we take an initial step of investigating the\nproblem of LLM instruction optimization across data groups with distribution\nshifts. We find that the optimal instructions do encounter performance drops on\nLLM under certain distribution shifts. To this end, we propose a framework to\nderive more robust optimal instructions that improve the performance on the\nunseen data group without large sacrifice on the seen data group. Experimental\nresults demonstrate the effectiveness of our proposed framework.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:30:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13955","submitter":"Viktor Losert","authors":"Viktor Losert","title":"On weak amenability of Fourier algebras","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.GR math.OA math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For a connected Lie group G it was shown by Lee, Ludwig, Samei and Spronk\nthat its Fourier algebra A(G) is weakly amenable only if G is abelian. We\nextend this result to general connected locally compact groups, extending an\napproach developed in special cases by Choi and Ghandehari.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:31:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13956","submitter":"Paola Bel\\'en Manasero","authors":"Noelia Juarez, Paola B. Manasero and Jorge Oviedo","title":"Nash implementation in a many-to-one matching market","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In a many-to-one matching market with substitutable preferences, we analyze\nthe game induced by a stable rule. When both sides of the market play\nstrategically, we show that any stable rule implements, in Nash equilibrium,\nthe individually rational matchings. Also, when only workers play strategically\nand firms' preferences satisfy the law of aggregated demand, we show that any\nstable rule implements, in Nash equilibrium, the stable matchings.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:32:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13957","submitter":"Qiushi Zhu","authors":"Qiushi Zhu, Xiaoying Zhao, Jie Zhang, Yu Gu, Chao Weng, Yuchen Hu","title":"Eeg2vec: Self-Supervised Electroencephalographic Representation Learning","comments":"5 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, many efforts have been made to explore how the brain processes\nspeech using electroencephalographic (EEG) signals, where deep learning-based\napproaches were shown to be applicable in this field. In order to decode speech\nsignals from EEG signals, linear networks, convolutional neural networks (CNN)\nand long short-term memory networks are often used in a supervised manner.\nRecording EEG-speech labeled data is rather time-consuming and laborious, while\nunlabeled EEG data is abundantly available. Whether self-supervised methods are\nhelpful to learn EEG representation to boost the performance of EEG\nauditory-related tasks has not been well explored. In this work, we first\npropose a self-supervised model based on contrastive loss and reconstruction\nloss to learn EEG representations, and then use the obtained pre-trained model\nas a feature extractor for downstream tasks. Second, for two considered\ndownstream tasks, we use CNNs and Transformer networks to learn local features\nand global features, respectively. Finally, the EEG data from other channels\nare mixed into the chosen EEG data for augmentation. The effectiveness of our\nmethod is verified on the EEG match-mismatch and EEG regression tasks of the\nICASSP2023 Auditory EEG Challenge.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:34:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13958","submitter":"Himadri Mukherjee","authors":"Himadri Mukherjee, Gunja Sachdeva","title":"On the Linear Algebraic Monoids Associated to Congruence of Matrices","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA math.AG math.GR math.RT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we consider the general congruence equation $X^tAX=B$, $X \\in\nM_n(k)$, and the resulting monoid $Sol_A$ when $A=B$. We have dealt with the\ncase when the ``coefficient matrix\", $A$ is a nilpotent matrix. We have\ncompletely characterized when the monoid is a Lie group. We have given the\nstructure of the Lie algebra for a subclass of nilpotent matrices. The solution\nof $X^tAX=B$ is discussed with the action of $Sol_A \\times Sol_B$ on it.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:35:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13959","submitter":"Nils Hemmingsson","authors":"Nils Hemmingsson","title":"Equidistribution of iterations of holomorphic correspondences and\n  Hutchinson invariant sets","comments":"Fixed typos, minor change in exposition of the results","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we analyze a certain family of holomorphic correspondences on\n$\\hat{\\mathbb{C}}\\times\\hat{\\mathbb{C}}$ and prove their equidistribution\nproperties. In particular, for any correspondence in this family we prove that\nthe naturally associated multivalued map $F$ is such that for any $a\\in\n\\mathbb{C}$, we have that $(F^n)_*(\\delta_a)$ converges to a probability\nmeasure $\\mu_F$ for which $F_*(\\mu_F)=\\mu_F d$ where $d$ is the degree of $F$.\nThis result is used to show that the minimal Hutchinson invariant set,\nintroduced in [ABS20a], of a large class of operators and for sufficiently\nlarge $n$ exists and is the support of the aforementioned measure. We also\nprove that in this situation the minimal Hutchinson-invariant set is a Cantor\nset.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:37:19 GMT"},{"version":"v2","created":"Tue, 30 May 2023 11:17:42 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13960","submitter":"Ferdinand M\\\"utsch","authors":"Ferdinand M\\\"utsch, Helen Gremmelmaier, Nicolas Becker, Daniel\n  Bogdoll, Marc Ren\\'e Zofka, J. Marius Z\\\"ollner","title":"From Model-Based to Data-Driven Simulation: Challenges and Trends in\n  Autonomous Driving","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Simulation is an integral part in the process of developing autonomous\nvehicles and advantageous for training, validation, and verification of driving\nfunctions. Even though simulations come with a series of benefits compared to\nreal-world experiments, various challenges still prevent virtual testing from\nentirely replacing physical test-drives. Our work provides an overview of these\nchallenges with regard to different aspects and types of simulation and\nsubsumes current trends to overcome them. We cover aspects around perception-,\nbehavior- and content-realism as well as general hurdles in the domain of\nsimulation. Among others, we observe a trend of data-driven, generative\napproaches and high-fidelity data synthesis to increasingly replace model-based\nsimulation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:39:23 GMT"},{"version":"v2","created":"Wed, 31 May 2023 09:55:53 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13961","submitter":"Isabel Funke","authors":"Isabel Funke, Dominik Rivoir and Stefanie Speidel","title":"Metrics Matter in Surgical Phase Recognition","comments":"Code at https://gitlab.com/nct_tso_public/phasemetrics","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Surgical phase recognition is a basic component for different context-aware\napplications in computer- and robot-assisted surgery. In recent years, several\nmethods for automatic surgical phase recognition have been proposed, showing\npromising results. However, a meaningful comparison of these methods is\ndifficult due to differences in the evaluation process and incomplete reporting\nof evaluation details. In particular, the details of metric computation can\nvary widely between different studies. To raise awareness of potential\ninconsistencies, this paper summarizes common deviations in the evaluation of\nphase recognition algorithms on the Cholec80 benchmark. In addition, a\nstructured overview of previously reported evaluation results on Cholec80 is\nprovided, taking known differences in evaluation protocols into account.\nGreater attention to evaluation details could help achieve more consistent and\ncomparable results on the surgical phase recognition task, leading to more\nreliable conclusions about advancements in the field and, finally, translation\ninto clinical practice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:40:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13962","submitter":"Benlai Tang","authors":"Jingning Xu, Benlai Tang, Mingjie Wang, Minghao Li, Meirong Ma","title":"CPNet: Exploiting CLIP-based Attention Condenser and Probability Map\n  Guidance for High-fidelity Talking Face Generation","comments":"Accepted by ICME 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MM cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, talking face generation has drawn ever-increasing attention from\nthe research community in computer vision due to its arduous challenges and\nwidespread application scenarios, e.g. movie animation and virtual anchor.\nAlthough persevering efforts have been undertaken to enhance the fidelity and\nlip-sync quality of generated talking face videos, there is still large room\nfor further improvements of synthesis quality and efficiency. Actually, these\nattempts somewhat ignore the explorations of fine-granularity feature\nextraction/integration and the consistency between probability distributions of\nlandmarks, thereby recurring the issues of local details blurring and degraded\nfidelity. To mitigate these dilemmas, in this paper, a novel CLIP-based\nAttention and Probability Map Guided Network (CPNet) is delicately designed for\ninferring high-fidelity talking face videos. Specifically, considering the\ndemands of fine-grained feature recalibration, a clip-based attention condenser\nis exploited to transfer knowledge with rich semantic priors from the\nprevailing CLIP model. Moreover, to guarantee the consistency in probability\nspace and suppress the landmark ambiguity, we creatively propose the density\nmap of facial landmark as auxiliary supervisory signal to guide the landmark\ndistribution learning of generated frame. Extensive experiments on the\nwidely-used benchmark dataset demonstrate the superiority of our CPNet against\nstate of the arts in terms of image and lip-sync quality. In addition, a cohort\nof studies are also conducted to ablate the impacts of the individual pivotal\ncomponents.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:40:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13963","submitter":"Michael Kenna-Allison","authors":"Callum Hunter, Michael Kenna-Allison","title":"Non-minimal Scalar Effective Cosmology","comments":"13 pages, 0 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we investigate the most general non-minimally coupled\n$\\mathbb{Z}_2$ symmetric scalar-tensor effective field theory (EFT) of gravity\nup to dimension six in the operator expansion. The most general action is\npresented along with its equations of motion both in the covariant form and\nalso in the coordinate form resulting from an FLRW analysis. The pressure and\ndensity of the scalar field are found as well as the equation of state\nparameter and some cosmological parameters. We analyse the background evolution\nof the scalar field within the framework of the slow-roll approximation and\nprovide a brief discussion of $\\mathbb{Z}_2$ symmetry breaking of the scalar\nfield which gives an order of magnitude constraint on one of the coupling\nconstants. To provide a concrete example we choose a couple of potentials for\nthe scalar field and explore the cosmology. Some brief comments on the range of\nvalidity of the EFT are also offered as well as the connections between the\ngeneral model and well-known examples in the literature.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:41:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13964","submitter":"Yeongrak Kim","authors":"Taehyeong Kim, Jeong-Hoon Ju, Yeongrak Kim","title":"Finding tensor decompositions with sparse optimization","comments":"19 pages, 2 figures. This paper supercedes arXiv:2303.07842","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we suggest a new method for a given tensor to find CP\ndecompositions using a less number of rank $1$ tensors. The main ingredient is\nthe Least Absolute Shrinkage and Selection Operator (LASSO) by considering the\ndecomposition problem as a sparse optimization problem. As applications, we\ndesign experiments to find some CP decompositions of the matrix multiplication\nand determinant tensors. In particular, we find a new formula for the $4 \\times\n4$ determinant tensor as a sum of $12$ rank $1$ tensors.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:41:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13965","submitter":"Byungjoon Min","authors":"Byungjoon Min and Maxi San Miguel","title":"Threshold cascade dynamics on coevolving networks","comments":"8 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the coevolutionary dynamics of network topology and social complex\ncontagion using a threshold cascade model. Our coevolving threshold model\nincorporates two mechanisms: the threshold mechanism for the spreading of a\nminority state such as a new opinion, idea, or innovation and the network\nplasticity implemented as rewiring of links to cut the connections between\nnodes in different states. Using numerical simulations and a mean-field\ntheoretical analysis, we demonstrate that the coevolutionary dynamics can\nsignificantly affect the cascades dynamics. The domain of parameters, i.e.,\nthreshold and network mean degree, for which global cascades occur shrinks with\nincreasing network plasticity, indicating that the rewiring process suppresses\nthe onset of global cascades. We also found that during evolution, non-adopted\nnodes form denser connections, resulting in a wider degree distribution and a\nnon-monotonous dependence of cascades sizes with plasticity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:47:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13966","submitter":"Michelle Collins","authors":"Michelle L. M. Collins, Noushin Karim, David Martinez-Delgado, Matteo\n  Monelli, Erik J. Tollerud, Giuseppe Donatiello, Mahdieh Navabi, Emily\n  Charles, Walter Boschin","title":"Pisces VII/Triangulum III -- M33's second dwarf satellite galaxy","comments":"7 pages, 5 figures, to be submitted to MNRAS. Comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Pisces VII/Triangulum III (Pisc~VII) was discovered in the DESI Legacy\nImaging Survey and was shown to be a Local Group dwarf galaxy with follow-up\nimaging from the 4-m Telescopio Nazionale Galileo. However, this imaging was\nunable to reach the horizontal branch of Pisc VII, preventing a precision\ndistance measurement. The distance bound from the red giant branch population\nplaced Pisc VII as either an isolated ultra-faint dwarf galaxy or the second\nknown satellite galaxy of Triangulum (M33). Using deep imaging from Gemini\nGMOS-N, we have resolved the horizontal branch of Pisc VII, and measure a\ndistance of $D=962^{+32}_{-32}$~kpc, making Pisc VII a likely satellite of M33.\nWe also remeasure its size and luminosity from this deeper data, finding\n$r_{\\rm half}=186^{+58}_{-32}$ pc, $M_V=-5.7\\pm0.3$ and\n$L=1.6^{+0.1}_{-0.2}\\times10^4\\,{\\rm L}_\\odot$. Given its position in the M33\nhalo, we argue that Pisc VII could support the theory that M33 is on its first\ninfall to the Andromeda system. We also discuss the presence of blue stars in\nthe colour-magnitude diagram of Pisc VII that are consistent with ages of 1.5\nGyr. If these are truly members of the galaxy, it would transform our\nunderstanding of how reionisation affects the faintest galaxies. However we\ncannot rule out a more ordinary explanation for these with current data. Future\ndeep imaging and dynamics could allow significant insight into both the stellar\npopulations of Pisc VII and the evolution of M33.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:50:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13967","submitter":"Sudip Mittal","authors":"Damodar Panigrahi, William Anderson, Joshua Whitman, Sudip Mittal,\n  Benjamin A Blakely","title":"REGARD: Rules of EngaGement for Automated cybeR Defense to aid in\n  Intrusion Response","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Automated Intelligent Cyberdefense Agents (AICAs) that are part Intrusion\nDetection Systems (IDS) and part Intrusion Response Systems (IRS) are being\ndesigned to protect against sophisticated and automated cyber-attacks. An AICA\nbased on the ideas of Self-Adaptive Autonomic Computing Systems (SA-ACS) can be\nconsidered as a managing system that protects a managed system like a personal\ncomputer, web application, critical infrastructure, etc. An AICA, specifically\nthe IRS components, can compute a wide range of potential responses to meet its\nsecurity goals and objectives, such as taking actions to prevent the attack\nfrom completing, restoring the system to comply with the organizational\nsecurity policy, containing or confining an attack, attack eradication,\ndeploying forensics measures to enable future attack analysis, counterattack,\nand so on. To restrict its activities in order to minimize\ncollateral/organizational damage, such an automated system must have set Rules\nof Engagement (RoE). Automated systems must determine which operations can be\ncompletely automated (and when), which actions require human operator\nconfirmation, and which actions must never be undertaken. In this paper, to\nenable this control functionality over an IRS, we create Rules of EngaGement\nfor Automated cybeR Defense (REGARD) system which holds a set of Rules of\nEngagement (RoE) to protect the managed system according to the instructions\nprovided by the human operator. These rules help limit the action of the IRS on\nthe managed system in compliance with the recommendations of the domain expert.\nWe provide details of execution, management, operation, and conflict resolution\nfor Rules of Engagement (RoE) to constrain the actions of an automated IRS. We\nalso describe REGARD system implementation, security case studies for cyber\ndefense, and RoE demonstrations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:52:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13968","submitter":"Bassam Shehadeh","authors":"Raghad Al-Bakri and Bassam Shehadeh","title":"Nucleon-Nucleon elastic and inelastic scattering using quantum field\n  theory: a comparative study","comments":"24 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th hep-ph physics.comp-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this paper, we use Yukawa theory to calculate differential and total\ncross-sections for elastic and inelastic scattering in nucleon-nucleon\ninteractions. We start from the fundamental Lagrangian and derive the\n$T$-matrix and hence the invariant scattering matrix leading towards the\ndifferential and total cross section. We perform calculations utilizing two\ntypes of Yukawa interaction terms: 1) scalar current, and 2) pseudoscalar\ncurrent. We also carry out calculations in a laboratory frame. Calculated\nresults using scalar current exhibits the exact features of elastic and\ninelastic scattering. The results agree very well with the differential\ncross-sections for experimental data. The pseudoscalar current calculations do\nnot offer reasonable results and features of the NN interactions. The\nsimplicity of the theory makes it all the more impressive, thus it can be used\nin place of more complicated field theories to describe NN interactions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:52:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13969","submitter":"Matej Novosad","authors":"Matej Novosad, Robert Penicka, Vojtech Vonasek","title":"CTopPRM: Clustering Topological PRM for Planning Multiple Distinct Paths\n  in 3D Environments","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we propose a new method called Clustering Topological PRM\n(CTopPRM) for finding multiple homotopically distinct paths in 3D cluttered\nenvironments. Finding such distinct paths, e.g., going around an obstacle from\na different side, is useful in many applications. Among others, using multiple\ndistinct paths is necessary for optimization-based trajectory planners where\nfound trajectories are restricted to only a single homotopy class of a given\npath. Distinct paths can also be used to guide sampling-based motion planning\nand thus increase the effectiveness of planning in environments with narrow\npassages. Graph-based representation called roadmap is a common representation\nfor path planning and also for finding multiple distinct paths. However,\nchallenging environments with multiple narrow passages require a densely\nsampled roadmap to capture the connectivity of the environment. Searching such\na dense roadmap for multiple paths is computationally too expensive. Therefore,\nthe majority of existing methods construct only a sparse roadmap which,\nhowever, struggles to find all distinct paths in challenging environments. To\nthis end, we propose the CTopPRM which creates a sparse graph by clustering an\ninitially sampled dense roadmap. Such a reduced roadmap allows fast\nidentification of homotopically distinct paths captured in the dense roadmap.\nWe show, that compared to the existing methods the CTopPRM improves the\nprobability of finding all distinct paths by almost 20% in tested environments,\nduring same run-time. The source code of our method is released as an\nopen-source package.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:53:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13970","submitter":"Donghyuk Kim","authors":"Donghyuk Kim, Jae-Young Kim, Wontak Han, Jongsoon Won, Haerang Choi,\n  Yongkee Kwon, and Joo-Young Kim","title":"Darwin: A DRAM-based Multi-level Processing-in-Memory Architecture for\n  Data Analytics","comments":"14 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Processing-in-memory (PIM) architecture is an inherent match for data\nanalytics application, but we observe major challenges to address when\naccelerating it using PIM. In this paper, we propose Darwin, a practical\nLRDIMM-based multi-level PIM architecture for data analytics, which fully\nexploits the internal bandwidth of DRAM using the bank-, bank group-, chip-,\nand rank-level parallelisms. Considering the properties of data analytics\noperators and DRAM's area constraints, Darwin maximizes the internal data\nbandwidth by placing the PIM processing units, buffers, and control circuits\nacross the hierarchy of DRAM. More specifically, it introduces the bank\nprocessing unit for each bank in which a single instruction multiple data\n(SIMD) unit handles regular data analytics operators and bank group processing\nunit for each bank group to handle workload imbalance in the condition-oriented\ndata analytics operators. Furthermore, Darwin supports a novel PIM instruction\narchitecture that concatenates instructions for multiple thread executions on\nbank group processing entities, addressing the command bottleneck by enabling\nseparate control of up to 512 different in-memory processing units\nsimultaneously. We build a cycle-accurate simulation framework to evaluate\nDarwin with various DRAM configurations, optimization schemes and workloads.\nDarwin achieves up to 14.7x speedup over the non-optimized version. Finally,\nthe proposed Darwin architecture achieves 4.0x-43.9x higher throughput and\nreduces energy consumption by 85.7% than the baseline CPU system (Intel Xeon\nGold 6226 + 4 channels of DDR4-2933). Compared to the state-of-the-art PIM,\nDarwin achieves up to 7.5x and 7.1x in the basic query operators and TPC-H\nqueries, respectively. Darwin is based on the latest GDDR6 and requires only\n5.6% area overhead, suggesting a promising PIM solution for the future main\nmemory system.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:53:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13971","submitter":"Saibo Geng","authors":"Saibo Geng, Martin Josifosky, Maxime Peyrard, Robert West","title":"Flexible Grammar-Based Constrained Decoding for Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  LLMs have shown impressive few-shot performance across many tasks. However,\nthey still struggle when it comes to reliably generating complex output\nstructures, such as those required for information extraction. This limitation\nstems from the fact that LLMs, without fine-tuning, tend to generate free text\nrather than structures precisely following a specific grammar. In this work, we\npropose to enrich the decoding with formal grammar constraints. More\nconcretely, given Context-Free Grammar(CFG), our framework ensures that the\ntoken generated in each decoding step would lead to a valid continuation\ncompliant with the grammar production rules. This process guarantees the\ngeneration of valid sequences. Importantly, our framework can be readily\ncombined with any CFG or decoding algorithm. We demonstrate that the outputs of\nmany NLP tasks can be represented as formal languages, making them suitable for\ndirect use in our framework. We conducted experiments with two challenging\ntasks involving large alphabets in their grammar (Wikidata entities and\nrelations): information extraction and entity disambiguation. Our results with\nLLaMA models indicate that grammar-constrained decoding substantially\noutperforms unconstrained decoding and even competes with task-specific\nfine-tuned models. These findings suggest that integrating grammar-based\nconstraints during decoding holds great promise in making LLMs reliably produce\nstructured outputs, especially in setting where training data is scarce and\nfine-tuning is expensive.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:54:37 GMT"},{"version":"v2","created":"Wed, 24 May 2023 11:51:52 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13972","submitter":"Chuanyuan Tan","authors":"Chuanyuan Tan, Yuehe Chen, Wenbiao Shao, Wenliang Chen","title":"Make a Choice! Knowledge Base Question Answering with In-Context\n  Learning","comments":"Work in Progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Question answering over knowledge bases (KBQA) aims to answer factoid\nquestions with a given knowledge base (KB). Due to the large scale of KB,\nannotated data is impossible to cover all fact schemas in KB, which poses a\nchallenge to the generalization ability of methods that require a sufficient\namount of annotated data. Recently, LLMs have shown strong few-shot performance\nin many NLP tasks. We expect LLM can help existing methods improve their\ngeneralization ability, especially in low-resource situations. In this paper,\nwe present McL-KBQA, a framework that incorporates the few-shot ability of LLM\ninto the KBQA method via ICL-based multiple choice and then improves the\neffectiveness of the QA tasks. Experimental results on two KBQA datasets\ndemonstrate the competitive performance of McL-KBQA with strong improvements in\ngeneralization. We expect to explore a new way to QA tasks from KBQA in\nconjunction with LLM, how to generate answers normatively and correctly with\nstrong generalization.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:56:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13973","submitter":"Eunbi Choi","authors":"Eunbi Choi, Kyoung-Woon On, Gunsoo Han, Sungwoong Kim, Daniel Wontae\n  Nam, Daejin Jo, Seung Eun Rho, Taehwan Kwon, Minjoon Seo","title":"Effortless Integration of Memory Management into Open-Domain\n  Conversation Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Open-domain conversation systems integrate multiple conversation skills into\na single system through a modular approach. One of the limitations of the\nsystem, however, is the absence of management capability for external memory.\nIn this paper, we propose a simple method to improve BlenderBot3 by integrating\nmemory management ability into it. Since no training data exists for this\npurpose, we propose an automating dataset creation for memory management. Our\nmethod 1) requires little cost for data construction, 2) does not affect\nperformance in other tasks, and 3) reduces external memory. We show that our\nproposed model BlenderBot3-M^3, which is multi-task trained with memory\nmanagement, outperforms BlenderBot3 with a relative 4% performance gain in\nterms of F1 score.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:56:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13974","submitter":"Giovanni Gandolfi","authors":"Giovanni Gandolfi, Balakrishna Sandeep Haridasu, Stefano Liberati,\n  Andrea Lapi","title":"Looking for Traces of Non-minimally Coupled Dark Matter in the X-COP\n  Galaxy Clusters Sample","comments":"15 pages, 6 figures, accepted for publication in the Astrophysical\n  Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We look for possible evidence of a non-minimal coupling (NMC) between dark\nmatter (DM) and gravity using data from the X-COP compilation of galaxy\nclusters. We consider a theoretically motivated NMC that may dynamically arise\nfrom the collective behavior of the coarse-grained DM field (e.g., via\nBose-Einstein condensation) with averaging/coherence length\n$\\L_{\\mathrm{nmc}}$. In the Newtonian limit, the NMC modifies the Poisson\nequation by a term $\\L_{\\mathrm{nmc}}^2 \\nabla^2 \\rho$ proportional to the\nLaplacian of the DM density itself. We show that this term when acting as a\nperturbation over the standard Navarro-Frenk-White (NFW) profile of cold DM\nparticles, can yield DM halo density profiles capable of correctly fitting\ngalaxy clusters' pressure profiles with an accuracy comparable and in some\ncases even better than the standard cold DM NFW profile. We also show that the\nobserved relation between the non-minimal coupling length scale and the virial\nmass found in Gandolfi et al., 2022 for Late Type Galaxies is consistent with\nthe relation we find in the current work, suggesting that the previously\ndetermined power-law scaling law holds up to galaxy cluster mass scales.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:57:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13975","submitter":"Zeqi Zhang Mr","authors":"Zeqi Zhang, Ravindra T. Desai, Oleg Shebanits, Fredrik L. Johansson,\n  Yohei Miyake and Hideyuki Usui","title":"Simulating secondary electron and ion emission from the Cassini\n  spacecraft in Saturn's ionosphere","comments":"Planetary Science Journal Article, accepted 22 May 2023. Preprint\n  contains 10 pages, 4 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.space-ph astro-ph.EP astro-ph.IM physics.plasm-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Cassini spacecraft's Grand Finale flybys through Saturn's ionosphere\nprovided unprecedented insight into the composition and dynamics of the gas\ngiant's upper atmosphere and a novel and complex spacecraft-plasma interaction.\nIn this article, we further study Cassini's interaction with Saturn's\nionosphere using three dimensional Particle-in-Cell simulations. We focus on\nunderstanding how electrons and ions, emitted from spacecraft surfaces due to\nthe high-velocity impact of atmospheric water molecules, could have affected\nthe spacecraft potential and low-energy plasma measurements. The simulations\nshow emitted electrons extend upstream along the magnetic field and, for\nsufficiently high emission rates, charge the spacecraft to positive potentials.\nThe lack of accurate emission rates and characteristics, however, makes\ndifferentiation between the prominence of secondary electron emission and\nionospheric charged dust populations, which induce similar charging effects,\ndifficult for Cassini. These results provide further context for Cassini's\nfinal measurements and highlight the need for future laboratory studies to\nsupport high-velocity flyby missions through planetary and cometary\nionospheres.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:57:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13976","submitter":"Fumihiro Naokawa","authors":"Fumihiro Naokawa, Toshiya Namikawa","title":"Gravitational lensing effect on cosmic birefringence","comments":"9 pages, 6 figures","journal-ref":null,"doi":null,"report-no":"RESCEU-12/23","categories":"astro-ph.CO hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We calculate the effect of gravitational lensing on the parity-odd power\nspectrum of the cosmic microwave background (CMB) polarization induced by\naxionlike particles (ALPs). Several recent works have reported a tantalizing\nhint of cosmic birefringence, a rotation of the linear polarization plane of\nCMB, which ALPs can explain. In future CMB observations, we can measure cosmic\nbirefringence more precisely to get insight into ALPs. We find that the lensing\neffect is necessary to fit the observed EB power spectrum induced by cosmic\nbirefringence in future CMB observations, including Simons Observatory and\nCMB-S4. We also show that the estimated ALPs parameters are biased if we ignore\nthe lensing effect. Therefore, the lensing correction to the parity-odd power\nspectra must be included in future high-resolution CMB experiments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:58:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13977","submitter":"Huajun Long","authors":"Huajun Long, Jie Li, Rui Li, Xinfeng Liu, Jingyuan Cheng","title":"Dual-modality Smart Shoes for Quantitative Assessment of Hemiplegic\n  Patients' Lower Limbs' Muscle Strength","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stroke can lead to the impaired motor ability of the patient's lower limbs\nand hemiplegia. Accurate assessment of the lower limbs' motor ability is\nimportant for diagnosis and rehabilitation. To digitalize such assessment so\nthat each test can be traced back any time and subjectivity can be avoided, we\ntest how dual-modality smart shoes equipped with pressure-sensitive insoles and\ninertial measurement units can be used for this purpose. A 5m walking test\nprotocol, including the left and right turns, is designed. Data are collected\nfrom 23 patients and 17 healthy subjects. For the lower limbs' motor ability,\nthe tests are observed by two physicians and assessed using the five graded\nMedical Research Council scale for muscle examination. The average of two\nphysicians' scores for the same patient is used as the ground truth. Using the\nfeature set we developed, 100\\% accuracy is achieved in classifying the\npatients and healthy subjects. For patients' muscle strength, a mean absolute\nerror of 0.143 and a maximum error of 0.395 is achieved using our feature set\nand the regression method, closer to the ground truth than the scores from each\nphysician (mean absolute error: 0.217, maximum error: 0.5). We thus validate\nthe possibility of using such smart shoes to objectively and accurately\nevaluate the lower limbs' muscle strength of the stroke patients.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:58:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13978","submitter":"Joel Magnusson","authors":"J. Magnusson, T. G. Blackburn, E. Gerstmayr, E. E. Los, M. Marklund,\n  C. P. Ridgers, S. P. D. Mangles","title":"Effect of electron-beam energy chirp on signatures of radiation reaction\n  in laser-based experiments","comments":"8 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph physics.acc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current experiments investigating radiation reaction employ high energy\nelectron beams together with tightly focused laser pulses in order to reach the\nquantum regime, as expressed through the quantum nonlinearity parameter $\\chi$.\nSuch experiments are often complicated by the large number of latent variables,\nincluding the precise structure of the electron bunch. Here we examine a\ncorrelation between the electron spatial and energy distributions, called an\nenergy chirp, investigate its significance to the laser-electron beam\ninteraction and show that the resulting effect cannot be trivially ignored when\nanalysing current experiments. In particular, we show that the energy chirp has\na large effect on the second moment of the electron energy, but a lesser impact\non the first electron energy moment or the photon critical energy. These\nresults show the importance of improved characterisation and control over\nelectron bunch parameters on a shot-to-shot basis in such experiments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:02:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13979","submitter":"Simon Walker-Samuel","authors":"Simon Walker-Samuel","title":"Control of a simulated MRI scanner with deep reinforcement learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG eess.IV physics.bio-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Magnetic resonance imaging (MRI) is a highly versatile and widely used\nclinical imaging tool. The content of MRI images is controlled by an\nacquisition sequence, which coordinates the timing and magnitude of the scanner\nhardware activations, which shape and coordinate the magnetisation within the\nbody, allowing a coherent signal to be produced. The use of deep reinforcement\nlearning (DRL) to control this process, and determine new and efficient\nacquisition strategies in MRI, has not been explored. Here, we take a first\nstep into this area, by using DRL to control a virtual MRI scanner, and framing\nthe problem as a game that aims to efficiently reconstruct the shape of an\nimaging phantom using partially reconstructed magnitude images. Our findings\ndemonstrate that DRL successfully completed two key tasks: inducing the virtual\nMRI scanner to generate useful signals and interpreting those signals to\ndetermine the phantom's shape. This proof-of-concept study highlights the\npotential of DRL in autonomous MRI data acquisition, shedding light on the\nsuitability of DRL for complex tasks, with limited supervision, and without the\nneed to provide human-readable outputs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:02:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13980","submitter":"Alexander E. Holroyd","authors":"Alexander E. Holroyd","title":"Symmetrization for finitely dependent colouring","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove the existence of a finitely dependent proper colouring of the\ninteger lattice Z^d that is fully isometry-invariant in law, for all dimensions\nd. Previously this was known only for d=1, while only translation-invariant\nexamples were known for higher d. Moreover we show that four colours suffice,\nand that the colouring can be expressed as an isometry-equivariant finitary\nfactor of an i.i.d. process, with exponential tail decay on the coding radius.\nOur construction starts from known translation-invariant colourings and applies\na symmetrization technique of possible broader utility.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:02:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13981","submitter":"Ji Qi","authors":"Ji Qi, Chuchun Zhang, Xiaozhi Wang, Kaisheng Zeng, Jifan Yu, Jinxin\n  Liu, Jiuding Sun, Yuxiang Chen, Lei How, Juanzi Li, Bin Xu","title":"Preserving Knowledge Invariance: Rethinking Robustness Evaluation of\n  Open Information Extraction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The robustness to distribution changes ensures that NLP models can be\nsuccessfully applied in the realistic world, especially for information\nextraction tasks. However, most prior evaluation benchmarks have been devoted\nto validating pairwise matching correctness, ignoring the crucial measurement\nof robustness. In this paper, we present the first benchmark that simulates the\nevaluation of open information extraction models in the real world, where the\nsyntactic and expressive distributions under the same knowledge meaning may\ndrift variously. We design and annotate a large-scale testbed in which each\nexample is a knowledge-invariant clique that consists of sentences with\nstructured knowledge of the same meaning but with different syntactic and\nexpressive forms. By further elaborating the robustness metric, a model is\njudged to be robust if its performance is consistently accurate on the overall\ncliques. We perform experiments on typical models published in the last decade\nas well as a popular large language model, the results show that the existing\nsuccessful models exhibit a frustrating degradation, with a maximum drop of\n23.43 F1 score. Our resources and code will be publicly available.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:05:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13982","submitter":"Yang Qi","authors":"Yang Qi, Zhichao Zhu, Yiming Wei, Lu Cao, Zhigang Wang, Wenlian Lu,\n  Jianfeng Feng","title":"Toward spike-based stochastic neural computing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE physics.bio-ph q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Inspired by the highly irregular spiking activity of cortical neurons,\nstochastic neural computing is an attractive theory for explaining the\noperating principles of the brain and the ability to represent uncertainty by\nintelligent agents. However, computing and learning with high-dimensional joint\nprobability distributions of spiking neural activity across large populations\nof neurons present as a major challenge. To overcome this, we develop a novel\nmoment embedding approach to enable gradient-based learning in spiking neural\nnetworks accounting for the propagation of correlated neural variability. We\nshow under the supervised learning setting a spiking neural network trained\nthis way is able to learn the task while simultaneously minimizing uncertainty,\nand further demonstrate its application to neuromorphic hardware. Built on the\nprinciple of spike-based stochastic neural computing, the proposed method opens\nup new opportunities for developing machine intelligence capable of computing\nuncertainty and for designing unconventional computing architectures.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:05:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13983","submitter":"Alexey Zhukov","authors":"A A Zhukov and I E Batov","title":"Regimes of electronic transport in doped InAs nanowire","comments":"19 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We report on the low temperature measurements of the magnetotransport in\nSi-doped InAs quantum wire in the presence of a charged tip of an atomic force\nmicroscope serving as a mobile gate, i.e. scanning gate microscopy (SGM). By\naltering the carrier concentration with back gate voltage, we transfer the wire\nthrough several transport regimes: from residual Coulomb blockade to nonlinear\nresonance regime, followed by linear resonance regime and, finally, to almost\nhomogeneous diffusion regime. We demonstrate direct relations between patterns\nmeasured with scanning gate microscopy and spectra of universal conductance\nfluctuations. A clear sign of fractal behavior of magnetoconductance dependence\nis observed for non-linear and linear resonance transport regimes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:07:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13984","submitter":"Asuka Ito","authors":"Asuka Ito, Kazunori Kohri, Kazunori Nakayama","title":"Probing high frequency gravitational waves with pulsars","comments":"7 pages, 2 figures","journal-ref":null,"doi":null,"report-no":"KEK-QUP-2023-0011, KEK-TH-2529, KEK-Cosmo-0314, TU-1192","categories":"gr-qc astro-ph.CO hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study graviton-photon conversion in magnetosphere of a pulsar and explore\nthe possibility of detecting high frequency gravitational waves with pulsar\nobservations. It is shown that conversion of one polarization mode of photons\ncan be enhanced significantly due to strong magnetic fields around a pulsar. We\nalso constrain stochastic gravitational waves in frequency range of\n$10^{8}-10^{9}\\,$Hz and $10^{13}-10^{27}\\,$Hz by using data of observations of\nthe Crab pulsar and the Geminga pulsar. Our method widely fills the gap among\nexisting high frequency gravitational wave experiments and boosts the frequency\nfrontier in gravitational wave observations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:08:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13985","submitter":"Greta Malaspina","authors":"Dusan Jakovetic, Natasa Krejic, Greta Malaspina","title":"Distributed Inexact Newton Method with Adaptive Step Sizes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider two formulations for distributed optimization wherein $N$ agents\nin a generic connected network solve a problem of common interest: distributed\npersonalized optimization and consensus optimization. A new method termed DINAS\n(Distributed Inexact Newton method with Adaptive Stepsize) is proposed. DINAS\nemploys large adaptively computed step-sizes, requires a reduced global\nparameters knowledge with respect to existing alternatives, and can operate\nwithout any local Hessian inverse calculations nor Hessian communications. When\nsolving personalized distributed learning formulations, DINAS achieves\nquadratic convergence with respect to computational cost and linear convergence\nwith respect to communication cost, the latter rate being independent of the\nlocal functions condition numbers or of the network topology. When solving\nconsensus optimization problems, DINAS is shown to converge to the global\nsolution. Extensive numerical experiments demonstrate significant improvements\nof DINAS over existing alternatives. As a result of independent interest, we\nprovide for the first time convergence analysis of the Newton method with the\nadaptive Polyak's step-size when the Newton direction is computed inexactly in\ncentralized environment.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:11:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13986","submitter":"Claudia Bandiera","authors":"Claudia Bandiera, Richard D. Connors, Francesco Viti","title":"A Multi-Modal Network Equilibrium Model with Interacting Mobility\n  Service Providers'Strategies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A Mathematical Program with Equilibrium Constraints (MPEC) is formulated to\ncapture the relationships between multiple Mobility Service Providers (MSPs)\nand the users of a multi-modal transport network. The network supply structure\nis defined through a novel supernetwork approach where users' daily trip chains\nare represented to model the mobility services used to reach each destination.\nAt the upper level, a profit maximization formulation is introduced to describe\neach MSPs' behaviour. At the lower level, users within a class choose minimum\ncost routes, according to Wardrop's first equilibrium principle. To consider\nthe interactions between modes, non-separable costs between supernetwork links\nare defined, and users' equilibrium conditions are formulated as a Variational\nInequality (VI). To solve the MPEC, an iterative solution algorithm based on a\nModified Projection Method is proposed. Numerical examples are presented to\nillustrate properties of the model, and to examine scenarios showcasing\ncooperation or competition strategies between MSPs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:11:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13987","submitter":"Wenhao Zhu","authors":"Wenhao Zhu, Tianyu Wen, Guojie Song, Liang Wang, Bo Zheng","title":"On Structural Expressive Power of Graph Transformers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph Transformer has recently received wide attention in the research\ncommunity with its outstanding performance, yet its structural expressive power\nhas not been well analyzed. Inspired by the connections between\nWeisfeiler-Lehman (WL) graph isomorphism test and graph neural network (GNN),\nwe introduce \\textbf{SEG-WL test} (\\textbf{S}tructural \\textbf{E}ncoding\nenhanced \\textbf{G}lobal \\textbf{W}eisfeiler-\\textbf{L}ehman test), a\ngeneralized graph isomorphism test algorithm as a powerful theoretical tool for\nexploring the structural discriminative power of graph Transformers. We\ntheoretically prove that the SEG-WL test is an expressivity upper bound on a\nwide range of graph Transformers, and the representational power of SEG-WL test\ncan be approximated by a simple Transformer network arbitrarily under certain\nconditions. With the SEG-WL test, we show how graph Transformers' expressive\npower is determined by the design of structural encodings, and present\nconditions that make the expressivity of graph Transformers beyond WL test and\nGNNs. Moreover, motivated by the popular shortest path distance encoding, we\nfollow the theory-oriented principles and develop a provably stronger\nstructural encoding method, Shortest Path Induced Subgraph (\\textit{SPIS})\nencoding. Our theoretical findings provide a novel and practical paradigm for\ninvestigating the expressive power of graph Transformers, and extensive\nsynthetic and real-world experiments empirically verify the strengths of our\nproposed methods.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:12:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13988","submitter":"Maximilian E. Merkel","authors":"Luca Schaufelberger, Maximilian E. Merkel, Aria Mansouri Tehrani,\n  Nicola A. Spaldin, Claude Ederer","title":"Exploring energy landscapes of charge multipoles using constrained\n  density functional theory","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a method to constrain local charge multipoles within\ndensity-functional theory. Such multipoles quantify the anisotropy of the local\ncharge distribution around atomic sites and can indicate potential hidden\norders. Our method allows selective control of specific multipoles,\nfacilitating a quantitative exploration of the energetic landscape outside of\nlocal minima. Thus, it enables a clear distinction between electronically and\nstructurally driven instabilities. We demonstrate the effectiveness of this\nmethod by applying it to charge quadrupoles in the prototypical orbitally\nordered material KCuF$_3$. We quantify intersite multipole-multipole\ninteractions as well as the energy-lowering related to the formation of an\nisolated local quadrupole. We also map out the energy as a function of the size\nof the local quadrupole moment around its local minimum, enabling\nquantification of multipole fluctuations around their equilibrium value.\nFinally, we study charge quadrupoles in the solid solution\nKCu$_{1-x}$Zn$_x$F$_3$ to characterize the behavior across the\ntetragonal-to-cubic transition. Our method provides a powerful tool for\nstudying symmetry breaking in materials with coupled electronic and structural\ninstabilities and potentially hidden orders.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:12:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13989","submitter":"David Adelani","authors":"Cheikh M. Bamba Dione, David Adelani, Peter Nabende, Jesujoba Alabi,\n  Thapelo Sindane, Happy Buzaaba, Shamsuddeen Hassan Muhammad, Chris Chinenye\n  Emezue, Perez Ogayo, Anuoluwapo Aremu, Catherine Gitau, Derguene Mbaye,\n  Jonathan Mukiibi, Blessing Sibanda, Bonaventure F. P. Dossou, Andiswa Bukula,\n  Rooweither Mabuya, Allahsera Auguste Tapo, Edwin Munkoh-Buabeng, victoire\n  Memdjokam Koagne, Fatoumata Ouoba Kabore, Amelia Taylor, Godson Kalipe,\n  Tebogo Macucwa, Vukosi Marivate, Tajuddeen Gwadabe, Mboning Tchiaze Elvis,\n  Ikechukwu Onyenwe, Gratien Atindogbe, Tolulope Adelani, Idris Akinade,\n  Olanrewaju Samuel, Marien Nahimana, Th\\'eog\\`ene Musabeyezu, Emile\n  Niyomutabazi, Ester Chimhenga, Kudzai Gotosa, Patrick Mizha, Apelete Agbolo,\n  Seydou Traore, Chinedu Uchechukwu, Aliyu Yusuf, Muhammad Abdullahi and\n  Dietrich Klakow","title":"MasakhaPOS: Part-of-Speech Tagging for Typologically Diverse African\n  Languages","comments":"Accepted to ACL 2023 (Main conference)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we present MasakhaPOS, the largest part-of-speech (POS)\ndataset for 20 typologically diverse African languages. We discuss the\nchallenges in annotating POS for these languages using the UD (universal\ndependencies) guidelines. We conducted extensive POS baseline experiments using\nconditional random field and several multilingual pre-trained language models.\nWe applied various cross-lingual transfer models trained with data available in\nUD. Evaluating on the MasakhaPOS dataset, we show that choosing the best\ntransfer language(s) in both single-source and multi-source setups greatly\nimproves the POS tagging performance of the target languages, in particular\nwhen combined with cross-lingual parameter-efficient fine-tuning methods.\nCrucially, transferring knowledge from a language that matches the language\nfamily and morphosyntactic properties seems more effective for POS tagging in\nunseen languages.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:15:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13990","submitter":"Danilo Chamorro","authors":"Danilo Chamorro, Jiahua Zhao, Claire Birnie, Myrna Staring, Fliedner\n  Moritz, Matteo Ravasi","title":"Deep Learning-based extraction of surface wave dispersion curves from\n  seismic shot gathers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-channel Analysis of Surface Waves (MASW) is a seismic method employed\nto obtain useful information about shear-wave velocities in the near surface. A\nfundamental step in this methodology is the extraction of dispersion curves\nfrom dispersion spectra, which are obtained after applying specific processing\nalgorithms onto the recorded shot gathers. Whilst this extraction process can\nbe automated to some extent, it usually requires extensive quality control,\nwhich can be arduous for large datasets. We present a novel approach that\nleverages deep learning to identify a direct mapping between seismic shot\ngathers and their associated dispersion curves (for both fundamental and first\nmodes), by-passing therefore the need to compute dispersion spectra. Given a\nsite of interest, a set of 1D velocity and density models are created using\nprior knowledge of the local geology; pairs of seismic shot gathers and\nRayleigh-wave phase dispersion curves are then numerically modeled and used to\ntrain a simplified residual network. The proposed approach is shown to achieve\nhigh quality predictions of dispersion curves on a synthetic test dataset and\nis, ultimately, successfully deployed on a field dataset. Various uncertainty\nquantification and CNN visualization techniques are also developed to assess\nthe quality of the inference process and better understand the underlying\nlearning process of the network. The predicted dispersion curves are finally\ninverted, and the resulting shear-wave velocity model is shown to be plausible\nand consistent with prior geological knowledge of the area.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:16:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13991","submitter":"Alessandro De Palma","authors":"Alessandro De Palma, Rudy Bunel, Krishnamurthy Dvijotham, M. Pawan\n  Kumar, Robert Stanforth, Alessio Lomuscio","title":"Expressive Losses for Verified Robustness via Convex Combinations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In order to train networks for verified adversarial robustness, previous work\ntypically over-approximates the worst-case loss over (subsets of) perturbation\nregions or induces verifiability on top of adversarial training. The key to\nstate-of-the-art performance lies in the expressivity of the employed loss\nfunction, which should be able to match the tightness of the verifiers to be\nemployed post-training. We formalize a definition of expressivity, and show\nthat it can be satisfied via simple convex combinations between adversarial\nattacks and IBP bounds. We then show that the resulting algorithms, named\nCC-IBP and MTL-IBP, yield state-of-the-art results across a variety of settings\nin spite of their conceptual simplicity. In particular, for $\\ell_\\infty$\nperturbations of radius $\\frac{1}{255}$ on TinyImageNet and downscaled\nImageNet, MTL-IBP improves on the best standard and verified accuracies from\nthe literature by from $1.98\\%$ to $3.92\\%$ points while only relying on\nsingle-step adversarial attacks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:20:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13992","submitter":"Simon Kothe","authors":"Simon Kothe and Peter Kirton","title":"Liouville Space Neural Network Representation of Density Matrices","comments":"12 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural network quantum states as ansatz wavefunctions have shown a lot of\npromise for finding the ground state of spin models. Recently, work has been\nfocused on extending this idea to mixed states for simulating the dynamics of\nopen systems. Most approaches so far have used a purification ansatz where a\ncopy of the system Hilbert space is added which when traced out gives the\ncorrect density matrix. Here, we instead present an extension of the Restricted\nBoltzmann Machine which directly represents the density matrix in Liouville\nspace. This allows the compact representation of states which appear in\nmean-field theory. We benchmark our approach on two different version of the\ndissipative transverse field Ising model which show our ansatz is able to\ncompete with other state-of-the-art approaches.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:21:08 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13993","submitter":"Haoran Xu","authors":"Haoran Xu, Weiting Tan, Shuyue Stella Li, Yunmo Chen, Benjamin Van\n  Durme, Philipp Koehn, Kenton Murray","title":"Condensing Multilingual Knowledge with Lightweight Language-Specific\n  Modules","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Incorporating language-specific (LS) modules is a proven method to boost\nperformance in multilingual machine translation. This approach bears similarity\nto Mixture-of-Experts (MoE) because it does not inflate FLOPs. However, the\nscalability of this approach to hundreds of languages (experts) tends to be\nunmanageable due to the prohibitive number of parameters introduced by\nfull-rank matrices in fully-connected layers. In this work, we introduce the\nLanguage-Specific Matrix Synthesis (LMS) method. This approach constructs LS\nmodules by generating low-rank matrices from two significantly smaller matrices\nto approximate the full-rank matrix. Furthermore, we condense multilingual\nknowledge from multiple LS modules into a single shared module with the Fuse\nDistillation (FD) technique to improve the efficiency of inference and model\nserialization. We show that our LMS method significantly outperforms previous\nLS methods and MoE methods with the same amount of extra parameters, e.g., 1.73\nBLEU points over the Switch Transformer on many-to-many multilingual machine\ntranslation. Importantly, LMS is able to have comparable translation\nperformance with much fewer parameters.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:21:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13994","submitter":"Mitradeep Sarkar","authors":"Mitradeep Sarkar, Michael T. Enders, Mehrdad Shokooh-Saremi, Kenji\n  Watanabe, Takashi Taniguchi, Hanan Herzig Sheinfux, Frank H.L. Koppens and\n  Georgia Theano Papadakis","title":"Retrieving optical parameters of emerging van der Waals flakes","comments":"10 pages, 4 figure and 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  High-quality low-dimensional layered and van der Waals materials are\ntypically exfoliated, with sample cross sectional areas on the order of tens to\nhundreds of microns. The small size of flakes makes the experimental\ncharacterization of their dielectric properties unsuitable with conventional\nspectroscopic ellipsometry, due to beam-sample size mismatch and\nnon-uniformities of the crystal axes. Previously, the experimental measurement\nof the dielectrirc permittivity of such microcrystals was carried out with\nnear-field tip-based scanning probes. These measurements are sensitive to\nexternal conditions like vibrations and temperature, and require\nnon-deterministic numerical fitting to some a priori known model. We present an\nalternative method to extract the in-plane dielectric permittivity of van der\nWaals microcrystals, based on identifying reflectance minima in spectroscopic\nmeasurements. Our method does not require complex fitting algorithms nor near\nfield tip-based measurements and accommodates for small-area samples. We\ndemonstrate the robustness of our method using hexagonal boron nitride and\n{\\alpha}-MoO3, and recover their dielectric permittivities that are close to\nliterature values.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:21:56 GMT"},{"version":"v2","created":"Mon, 29 May 2023 13:17:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13995","submitter":"Akihisa Hayashi","authors":"A. Hayashi","title":"Gauge dependence of the Aharonov-Bohm phase in quantum electrodynamics\n  framework","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Aharonov-Bohm (AB) phase is usually associated with a line integral of\nthe electromagnetic vector potential generated by an external current source,\nsuch as a solenoid. According to this interpretation, the AB phase of a\nnonclosed path cannot be observed, as the integral depends on the gauge choice\nof the vector potential. Recent attempts to explain the AB effect through the\ninteraction between a charged particle and an external current, mediated by the\nexchange of quantum photons, have assumed that the AB phase shift is\nproportional to the change in interaction energy between the charged particle\nand the external current source. As a result, these attempts argue that the AB\nphase change along a path does not depend on the gauge choice, and that the AB\nphase shift for a nonclosed path is in principle measurable. In this paper, we\ncritically examine this claim and demonstrate that the phase obtained through\nthis approach is actually gauge-dependent and not an observable for a nonclosed\npath. We also provide a brief critical discussion of the proposed experiment\nfor observing the AB phase shift of a nonclosed path.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:24:02 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13998","submitter":"Paul Saves","authors":"Paul Saves and Remi Lafage and Nathalie Bartoli and Youssef Diouane\n  and Jasper Bussemaker and Thierry Lefebvre and John T. Hwang and Joseph\n  Morlier and Joaquim R. R. A. Martins","title":"SMT 2.0: A Surrogate Modeling Toolbox with a focus on Hierarchical and\n  Mixed Variables Gaussian Processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.CO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The Surrogate Modeling Toolbox (SMT) is an open-source Python package that\noffers a collection of surrogate modeling methods, sampling techniques, and a\nset of sample problems. This paper presents SMT 2.0, a major new release of SMT\nthat introduces significant upgrades and new features to the toolbox. This\nrelease adds the capability to handle mixed-variable surrogate models and\nhierarchical variables. These types of variables are becoming increasingly\nimportant in several surrogate modeling applications. SMT 2.0 also improves SMT\nby extending sampling methods, adding new surrogate models, and computing\nvariance and kernel derivatives for Kriging. This release also includes new\nfunctions to handle noisy and use multifidelity data. To the best of our\nknowledge, SMT 2.0 is the first open-source surrogate library to propose\nsurrogate models for hierarchical and mixed inputs. This open-source software\nis distributed under the New BSD license.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:27:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13999","submitter":"Zeyu Liu","authors":"Leo Z. Liu, Tim Dettmers, Xi Victoria Lin, Veselin Stoyanov, Xian Li","title":"Towards A Unified View of Sparse Feed-Forward Network in Pretraining\n  Large Language Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large and sparse feed-forward networks (S-FFN) such as Mixture-of-Experts\n(MoE) have demonstrated to be an efficient approach for scaling up Transformers\nmodel size for pretraining large language models. By only activating part of\nthe FFN parameters conditioning on input, S-FFN improves generalization\nperformance while keeping training and inference costs (in FLOPs) fixed. In\nthis work, we analyzed the two major design choices of S-FFN: the memory block\n(or expert) size and the memory block selection method under a general\nconceptual framework of sparse neural memory. Using this unified framework, we\ncompare several S-FFN architectures for language modeling and provide insights\ninto their relative efficacy and efficiency. From our analysis results, we\nfound a simpler selection method -- Avg-K that selects blocks through their\nmean aggregated hidden states, achieves lower perplexity in language modeling\npretraining compared to existing MoE architectures.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:28:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14000","submitter":"Keke Huang","authors":"Keke Huang, Jing Tang, Juncheng Liu, Renchi Yang, Xiaokui Xiao","title":"Node-wise Diffusion for Scalable Graph Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph Neural Networks (GNNs) have shown superior performance for\nsemi-supervised learning of numerous web applications, such as classification\non web services and pages, analysis of online social networks, and\nrecommendation in e-commerce. The state of the art derives representations for\nall nodes in graphs following the same diffusion (message passing) model\nwithout discriminating their uniqueness. However, (i) labeled nodes involved in\nmodel training usually account for a small portion of graphs in the\nsemisupervised setting, and (ii) different nodes locate at different graph\nlocal contexts and it inevitably degrades the representation qualities if\ntreating them undistinguishedly in diffusion.\n  To address the above issues, we develop NDM, a universal node-wise diffusion\nmodel, to capture the unique characteristics of each node in diffusion, by\nwhich NDM is able to yield high-quality node representations. In what follows,\nwe customize NDM for semisupervised learning and design the NIGCN model. In\nparticular, NIGCN advances the efficiency significantly since it (i) produces\nrepresentations for labeled nodes only and (ii) adopts well-designed neighbor\nsampling techniques tailored for node representation generation. Extensive\nexperimental results on various types of web datasets, including citation,\nsocial and co-purchasing graphs, not only verify the state-of-the-art\neffectiveness of NIGCN but also strongly support the remarkable scalability of\nNIGCN. In particular, NIGCN completes representation generation and training\nwithin 10 seconds on the dataset with hundreds of millions of nodes and\nbillions of edges, up to orders of magnitude speedups over the baselines, while\nachieving the highest F1-scores on classification.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:28:43 GMT"},{"version":"v2","created":"Tue, 30 May 2023 02:40:48 GMT"},{"version":"v3","created":"Sat, 3 Jun 2023 08:36:25 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.14001","submitter":"Andrew Eckford","authors":"Dongliang Jing and Andrew W. Eckford","title":"Lightweight Channel Codes for ISI Mitigation in Molecular Communication\n  between Bionanosensors","comments":"Accepted for publication in IEEE Sensors Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Channel memory and inter-symbol interference (ISI) are harmful factors in\ndiffusion-based molecular communication (DBMC) between bionanosensors. To\ntackle these problems, this paper proposes a lightweight ISI-mitigating coding\nscheme to improve the system performance by shaping the signal using a\nconstrained code. To characterize the proposed coding scheme theoretically, we\nderive analytical expressions for the bit error rate (BER) and the achievable\nrate based on Central Limit Theorem. Computer simulations are conducted to\nverify the accuracy of the theoretical results and demonstrate the superiority\nof the proposed coding scheme compared with the existing coding schemes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:28:54 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14002","submitter":"Wenhao Yu","authors":"Wenhao Yu, Zhihan Zhang, Zhenwen Liang, Meng Jiang, Ashish Sabharwal","title":"Improving Language Models via Plug-and-Play Retrieval Feedback","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) exhibit remarkable performance across various\nNLP tasks. However, they often generate incorrect or hallucinated information,\nwhich hinders their practical applicability in real-world scenarios. Human\nfeedback has been shown to effectively enhance the factuality and quality of\ngenerated content, addressing some of these limitations. However, this approach\nis resource-intensive, involving manual input and supervision, which can be\ntime-consuming and expensive. Moreover, it cannot be provided during inference,\nfurther limiting its practical utility in dynamic and interactive applications.\nIn this paper, we introduce ReFeed, a novel pipeline designed to enhance LLMs\nby providing automatic retrieval feedback in a plug-and-play framework without\nthe need for expensive fine-tuning. ReFeed first generates initial outputs,\nthen utilizes a retrieval model to acquire relevant information from large\ndocument collections, and finally incorporates the retrieved information into\nthe in-context demonstration for output refinement, thereby addressing the\nlimitations of LLMs in a more efficient and cost-effective manner. Experiments\non four knowledge-intensive benchmark datasets demonstrate our proposed ReFeed\ncould improve over +6.0% under zero-shot setting and +2.5% under few-shot\nsetting, compared to baselines without using retrieval feedback.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:29:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14003","submitter":"Marco Gallo","authors":"Silvia Cingolani, Marco Gallo, Kazunaga Tanaka","title":"Infinitely many free or prescribed mass solutions for fractional Hartree\n  equations and Pohozaev identities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we study the following nonlinear fractional Hartree (or\nChoquard-Pekar) equation \\begin{equation}\\label{eq_abstract} (-\\Delta)^s u +\n\\mu u =(I_\\alpha*F(u)) F'(u) \\quad \\hbox{in}\\ \\mathbb{R}^N, \\tag{$*$}\n\\end{equation} where $\\mu>0$, $s \\in (0,1)$, $N \\geq 2$, $\\alpha \\in (0,N)$,\n$I_\\alpha \\sim \\frac{1}{|x|^{N-\\alpha}}$ is the Riesz potential, and $F$ is a\ngeneral subcritical nonlinearity. The goal is to prove existence of multiple\n(radially symmetric) solutions $u \\in H^s(\\mathbb{R}^N)$, by assuming $F$ odd\nor even.\n  We consider both the case $\\mu>0$ fixed (and the mass $\\int_{\\mathbb{R}^N}\nu^2$ free) and the case $\\int_{\\mathbb{R}^N} u^2 =m>0$ prescribed (and the\nfrequency $\\mu$ unknown). A key point in the proof is given by the research of\nsuitable multidimensional odd paths, which was done in the local case by\nBerestycki and Lions [ARMA, 1983]. For equation \\eqref{eq_abstract}, the\nnonlocalities play a special role in the construction of such paths. In\nparticular, some properties of these paths are needed in the asymptotic study\n(as $\\mu$ varies) of the mountain pass values of the unconstrained problem:\nthis asymptotic behaviour is then exploited to describe the geometry of the\nconstrained problem and detect infinitely many normalized solutions for any\n$m>0$.\n  The found solutions satisfy in addition a Pohozaev identity: in this paper we\nfurther investigate the validity of this identity for solutions of doubly\nnonlocal equations under a $C^1$-regularity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:30:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14004","submitter":"Ayush Maheshwari","authors":"Ayush Maheshwari, Ashim Gupta, Amrith Krishna, Ganesh Ramakrishnan, G.\n  Anil Kumar, Jitin Singla","title":"S\\={a}mayik: A Benchmark and Dataset for English-Sanskrit Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Sanskrit is a low-resource language with a rich heritage. Digitized Sanskrit\ncorpora reflective of the contemporary usage of Sanskrit, specifically that too\nin prose, is heavily under-represented at present. Presently, no such\nEnglish-Sanskrit parallel dataset is publicly available. We release a dataset,\nS\\={a}mayik, of more than 42,000 parallel English-Sanskrit sentences, from four\ndifferent corpora that aim to bridge this gap. Moreover, we also release\nbenchmarks adapted from existing multilingual pretrained models for\nSanskrit-English translation. We include training splits from our contemporary\ndataset and the Sanskrit-English parallel sentences from the training split of\nItih\\={a}sa, a previously released classical era machine translation dataset\ncontaining Sanskrit.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:32:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14005","submitter":"Paul Leask","authors":"Derek Harland, Paul Leask and Martin Speight","title":"Skyrme crystals with massive pions","comments":"24 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The crystalline structure of nuclear matter is investigated in the standard\nSkyrme model with massive pions. A semi-analytic method is developed to\ndetermine local minima of the static energy functional with respect to\nvariations of both the field and the period lattice of the crystal. Four\ndistinct Skyrme crystals are found. Two of these were already known -- the\ncubic lattice of half-skyrmions and the $\\alpha$-particle crystal -- but two\nare new. These new solutions have lower energy per baryon number and less\nsymmetry, being periodic with respect to trigonal but not cubic period\nlattices. Minimal energy crystals are also constructed under the constraint of\nconstant baryon density, and its shown that the two new non-cubic crystals tend\nto chain and multi-wall solutions at low densities.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:34:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14006","submitter":"Jiangyi Lin","authors":"Jiangyi Lin, Yaxin Fan, Xiaomin Chu, Peifeng Li and Qiaoming Zhu","title":"Multi-Granularity Prompts for Topic Shift Detection in Dialogue","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The goal of dialogue topic shift detection is to identify whether the current\ntopic in a conversation has changed or needs to change. Previous work focused\non detecting topic shifts using pre-trained models to encode the utterance,\nfailing to delve into the various levels of topic granularity in the dialogue\nand understand dialogue contents. To address the above issues, we take a\nprompt-based approach to fully extract topic information from dialogues at\nmultiple-granularity, i.e., label, turn, and topic. Experimental results on our\nannotated Chinese Natural Topic Dialogue dataset CNTD and the publicly\navailable English TIAGE dataset show that the proposed model outperforms the\nbaselines. Further experiments show that the information extracted at different\nlevels of granularity effectively helps the model comprehend the conversation\ntopics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:35:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14007","submitter":"Jingwei Ni","authors":"Jingwei Ni, Zhijing Jin, Qian Wang, Mrinmaya Sachan, Markus Leippold","title":"When Does Aggregating Multiple Skills with Multi-Task Learning Work? A\n  Case Study in Financial NLP","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-task learning (MTL) aims at achieving a better model by leveraging data\nand knowledge from multiple tasks. However, MTL does not always work --\nsometimes negative transfer occurs between tasks, especially when aggregating\nloosely related skills, leaving it an open question when MTL works. Previous\nstudies show that MTL performance can be improved by algorithmic tricks.\nHowever, what tasks and skills should be included is less well explored. In\nthis work, we conduct a case study in Financial NLP where multiple datasets\nexist for skills relevant to the domain, such as numeric reasoning and\nsentiment analysis. Due to the task difficulty and data scarcity in the\nFinancial NLP domain, we explore when aggregating such diverse skills from\nmultiple datasets with MTL can work. Our findings suggest that the key to MTL\nsuccess lies in skill diversity, relatedness between tasks, and choice of\naggregation size and shared capacity. Specifically, MTL works well when tasks\nare diverse but related, and when the size of the task aggregation and the\nshared capacity of the model are balanced to avoid overwhelming certain tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:37:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14008","submitter":"Alvari Sepp\\\"anen","authors":"Alvari Sepp\\\"anen, Risto Ojala, Kari Tammi","title":"Multi-Echo Denoising in Adverse Weather","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Adverse weather can cause noise to light detection and ranging (LiDAR) data.\nThis is a problem since it is used in many outdoor applications, e.g. object\ndetection and mapping. We propose the task of multi-echo denoising, where the\ngoal is to pick the echo that represents the objects of interest and discard\nother echoes. Thus, the idea is to pick points from alternative echoes that are\nnot available in standard strongest echo point clouds due to the noise. In an\nintuitive sense, we are trying to see through the adverse weather. To achieve\nthis goal, we propose a novel self-supervised deep learning method and the\ncharacteristics similarity regularization method to boost its performance.\nBased on extensive experiments on a semi-synthetic dataset, our method achieves\nsuperior performance compared to the state-of-the-art in self-supervised\nadverse weather denoising (23% improvement). Moreover, the experiments with a\nreal multi-echo adverse weather dataset prove the efficacy of multi-echo\ndenoising. Our work enables more reliable point cloud acquisition in adverse\nweather and thus promises safer autonomous driving and driving assistance\nsystems in such conditions. The code is available at\nhttps://github.com/alvariseppanen/SMEDNet\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:40:28 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14009","submitter":"Sebastian Pineda Arango","authors":"Sebastian Pineda Arango, Josif Grabocka","title":"Deep Pipeline Embeddings for AutoML","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Automated Machine Learning (AutoML) is a promising direction for\ndemocratizing AI by automatically deploying Machine Learning systems with\nminimal human expertise. The core technical challenge behind AutoML is\noptimizing the pipelines of Machine Learning systems (e.g. the choice of\npreprocessing, augmentations, models, optimizers, etc.). Existing Pipeline\nOptimization techniques fail to explore deep interactions between pipeline\nstages/components. As a remedy, this paper proposes a novel neural architecture\nthat captures the deep interaction between the components of a Machine Learning\npipeline. We propose embedding pipelines into a latent representation through a\nnovel per-component encoder mechanism. To search for optimal pipelines, such\npipeline embeddings are used within deep-kernel Gaussian Process surrogates\ninside a Bayesian Optimization setup. Furthermore, we meta-learn the parameters\nof the pipeline embedding network using existing evaluations of pipelines on\ndiverse collections of related datasets (a.k.a. meta-datasets). Through\nextensive experiments on three large-scale meta-datasets, we demonstrate that\npipeline embeddings yield state-of-the-art results in Pipeline Optimization.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:40:38 GMT"},{"version":"v2","created":"Wed, 24 May 2023 19:29:19 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.14010","submitter":"Wenhao Yu","authors":"Wenhao Yu, Meng Jiang, Peter Clark, Ashish Sabharwal","title":"IfQA: A Dataset for Open-domain Question Answering under Counterfactual\n  Presuppositions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Although counterfactual reasoning is a fundamental aspect of intelligence,\nthe lack of large-scale counterfactual open-domain question-answering (QA)\nbenchmarks makes it difficult to evaluate and improve models on this ability.\nTo address this void, we introduce the first such dataset, named IfQA, where\neach question is based on a counterfactual presupposition via an \"if\" clause.\nFor example, if Los Angeles was on the east coast of the U.S., what would be\nthe time difference between Los Angeles and Paris? Such questions require\nmodels to go beyond retrieving direct factual knowledge from the Web: they must\nidentify the right information to retrieve and reason about an imagined\nsituation that may even go against the facts built into their parameters. The\nIfQA dataset contains over 3,800 questions that were annotated annotated by\ncrowdworkers on relevant Wikipedia passages. Empirical analysis reveals that\nthe IfQA dataset is highly challenging for existing open-domain QA methods,\nincluding supervised retrieve-then-read pipeline methods (EM score 36.2), as\nwell as recent few-shot approaches such as chain-of-thought prompting with\nGPT-3 (EM score 27.4). The unique challenges posed by the IfQA benchmark will\npush open-domain QA research on both retrieval and counterfactual reasoning\nfronts.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:43:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14011","submitter":"Hugues Meyer","authors":"Hugues Meyer, Heiko Rieger","title":"Alignment interaction and band formation in assemblies of\n  auto-chemorepulsive walkers","comments":"12 pages, 14 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Chemotaxis, i.e. motion generated by chemical gradients, is a motility mode\nshared by many living species that has been developed by evolution to optimize\ncertain biological processes such as foraging or immune response. In\nparticular, auto-chemotaxis refers to chemotaxis mediated by a cue produced by\nthe chemotactic particle itself. Here, we investigate the collective behavior\nof auto-chemotactic particles that are repelled by the cue and therefore\nmigrate preferentially towards low-concentration regions. To this end, we\nintroduce a lattice model inspired by the true self-avoiding walk which reduces\nto the Keller-Segels model in the continuous limit, for which we describe the\nrich phase behavior. We first rationalize a the chemically-mediated alignment\ninteraction between walkers in the limit of stationary concentration fields,\nand then describe the various large-scale structures that can spontaneously\nform and the conditions for them to emerge, among which we find stable bands\ntraveling at constant speed in the direction transverse to the band.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:43:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14012","submitter":"Niyati Bafna","authors":"Niyati Bafna, Cristina Espa\\~na-Bonet, Josef van Genabith, Beno\\^it\n  Sagot, Rachel Bawden","title":"A Simple Method for Unsupervised Bilingual Lexicon Induction for\n  Data-Imbalanced, Closely Related Language Pairs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Existing approaches for unsupervised bilingual lexicon induction (BLI) often\ndepend on good quality static or contextual embeddings trained on large\nmonolingual corpora for both languages. In reality, however, unsupervised BLI\nis most likely to be useful for dialects and languages that do not have\nabundant amounts of monolingual data. We introduce a simple and fast method for\nunsupervised BLI for low-resource languages with a related mid-to-high resource\nlanguage, only requiring inference on the higher-resource language monolingual\nBERT. We work with two low-resource languages ($<5M$ monolingual tokens),\nBhojpuri and Magahi, of the severely under-researched Indic dialect continuum,\nshowing that state-of-the-art methods in the literature show near-zero\nperformance in these settings, and that our simpler method gives much better\nresults. We repeat our experiments on Marathi and Nepali, two higher-resource\nIndic languages, to compare approach performances by resource range. We release\nautomatically created bilingual lexicons for the first time for five languages\nof the Indic dialect continuum.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:49:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14013","submitter":"Thilo Krill","authors":"Thilo Krill and Max Pitz","title":"The number of topological types of trees","comments":"7 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two graphs are of the same topological type if they can be mutually embedded\ninto each other topologically. We show that there are exactly $\\aleph_1$\ndistinct topological types of countable trees. In general, for any infinite\ncardinal $\\kappa$ there are exactly $\\kappa^+$ distinct topological types of\ntrees of size $\\kappa$. This solves a problem of van der Holst from 2005.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:50:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14014","submitter":"Shuai Zhao","authors":"Shuai Zhao, Xiaohan Wang, Linchao Zhu, Yi Yang","title":"CLIP4STR: A Simple Baseline for Scene Text Recognition with Pre-trained\n  Vision-Language Model","comments":"Preprint, work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Pre-trained vision-language models are the de-facto foundation models for\nvarious downstream tasks. However, this trend has not extended to the field of\nscene text recognition (STR), despite the potential of CLIP to serve as a\npowerful scene text reader. CLIP can robustly identify regular (horizontal) and\nirregular (rotated, curved, blurred, or occluded) text in natural images. With\nsuch merits, we introduce CLIP4STR, a simple yet effective STR method built\nupon image and text encoders of CLIP. It has two encoder-decoder branches: a\nvisual branch and a cross-modal branch. The visual branch provides an initial\nprediction based on the visual feature, and the cross-modal branch refines this\nprediction by addressing the discrepancy between the visual feature and text\nsemantics. To fully leverage the capabilities of both branches, we design a\ndual predict-and-refine decoding scheme for inference. CLIP4STR achieves new\nstate-of-the-art performance on 11 STR benchmarks. Additionally, a\ncomprehensive empirical study is provided to enhance the understanding of the\nadaptation of CLIP to STR. We believe our method establishes a simple but\nstrong baseline for future STR research with VL models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:51:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14015","submitter":"Stefan Gerhold","authors":"Benedict Bauer, Stefan Gerhold","title":"The Fan-Taussky-Todd inequalities and the Lumer-Phillips theorem","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We argue that a classical inequality due to Fan, Taussky and Todd (1955) is\nequivalent to the dissipativity of a Jordan block. As the latter can be\ncharacterised via the zeros of Chebyshev polynomials, we obtain a short new\nproof of the inequality. Three other inequalities of Fan-Taussky-Todd are\nreproven similarly. By the Lumer-Phillips theorem, the semigroup defined by the\nJordan block is contractive. This yields new extensions of the classical\nFan-Taussky-Todd inequalities. As an application, we give an estimate for the\npartial sums of a Bessel function.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:52:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14016","submitter":"Minwoo Lee","authors":"Minwoo Lee, Hyukhun Koh, Kang-il Lee, Dongdong Zhang, Minsung Kim,\n  Kyomin Jung","title":"Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in\n  Multilingual Machine Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Gender bias is a significant issue in machine translation, leading to ongoing\nresearch efforts in developing bias mitigation techniques. However, most works\nfocus on debiasing of bilingual models without consideration for multilingual\nsystems. In this paper, we specifically target the unambiguous gender bias\nissue of multilingual machine translation models and propose a new mitigation\nmethod based on a novel perspective on the problem. We hypothesize that the\ngender bias in unambiguous settings is due to the lack of gender information\nencoded into the non-explicit gender words and devise a scheme to encode\ncorrect gender information into their latent embeddings. Specifically, we\nemploy Gender-Aware Contrastive Learning, GACL, based on gender pseudo-labels\nto encode gender information on the encoder embeddings. Our method is\ntarget-language-agnostic and applicable to already trained multilingual machine\ntranslation models through post-fine-tuning. Through multilingual evaluation,\nwe show that our approach improves gender accuracy by a wide margin without\nhampering translation performance. We also observe that incorporated gender\ninformation transfers and benefits other target languages regarding gender\naccuracy. Finally, we demonstrate that our method is applicable and beneficial\nto models of various sizes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:53:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14017","submitter":"Xun Jiang","authors":"Xun Jiang, Zailei Zhou, Xing Xu, Yang Yang, Guoqing Wang, Heng Tao\n  Shen","title":"Faster Video Moment Retrieval with Point-Level Supervision","comments":"10 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Video Moment Retrieval (VMR) aims at retrieving the most relevant events from\nan untrimmed video with natural language queries. Existing VMR methods suffer\nfrom two defects: (1) massive expensive temporal annotations are required to\nobtain satisfying performance; (2) complicated cross-modal interaction modules\nare deployed, which lead to high computational cost and low efficiency for the\nretrieval process. To address these issues, we propose a novel method termed\nCheaper and Faster Moment Retrieval (CFMR), which well balances the retrieval\naccuracy, efficiency, and annotation cost for VMR. Specifically, our proposed\nCFMR method learns from point-level supervision where each annotation is a\nsingle frame randomly located within the target moment. It is 6 times cheaper\nthan the conventional annotations of event boundaries. Furthermore, we also\ndesign a concept-based multimodal alignment mechanism to bypass the usage of\ncross-modal interaction modules during the inference process, remarkably\nimproving retrieval efficiency. The experimental results on three widely used\nVMR benchmarks demonstrate the proposed CFMR method establishes new\nstate-of-the-art with point-level supervision. Moreover, it significantly\naccelerates the retrieval speed with more than 100 times FLOPs compared to\nexisting approaches with point-level supervision.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:53:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14018","submitter":"Xuewu Lin","authors":"Xuewu Lin, Tianwei Lin, Zixiang Pei, Lichao Huang, Zhizhong Su","title":"Sparse4D v2: Recurrent Temporal Fusion with Sparse Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sparse algorithms offer great flexibility for multi-view temporal perception\ntasks. In this paper, we present an enhanced version of Sparse4D, in which we\nimprove the temporal fusion module by implementing a recursive form of\nmulti-frame feature sampling. By effectively decoupling image features and\nstructured anchor features, Sparse4D enables a highly efficient transformation\nof temporal features, thereby facilitating temporal fusion solely through the\nframe-by-frame transmission of sparse features. The recurrent temporal fusion\napproach provides two main benefits. Firstly, it reduces the computational\ncomplexity of temporal fusion from $O(T)$ to $O(1)$, resulting in significant\nimprovements in inference speed and memory usage. Secondly, it enables the\nfusion of long-term information, leading to more pronounced performance\nimprovements due to temporal fusion. Our proposed approach, Sparse4Dv2, further\nenhances the performance of the sparse perception algorithm and achieves\nstate-of-the-art results on the nuScenes 3D detection benchmark. Code will be\navailable at \\url{https://github.com/linxuewu/Sparse4D}.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:53:58 GMT"},{"version":"v2","created":"Wed, 24 May 2023 04:00:55 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14019","submitter":"Kaiyan Chang","authors":"Kaiyan Chang","title":"ChipGPT: How far are we from natural language hardware design","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.AR cs.PL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As large language models (LLMs) like ChatGPT exhibited unprecedented machine\nintelligence, it also shows great performance in assisting hardware engineers\nto realize higher-efficiency logic design via natural language interaction. To\nestimate the potential of the hardware design process assisted by LLMs, this\nwork attempts to demonstrate an automated design environment that explores LLMs\nto generate hardware logic designs from natural language specifications. To\nrealize a more accessible and efficient chip development flow, we present a\nscalable four-stage zero-code logic design framework based on LLMs without\nretraining or finetuning. At first, the demo, ChipGPT, begins by generating\nprompts for the LLM, which then produces initial Verilog programs. Second, an\noutput manager corrects and optimizes these programs before collecting them\ninto the final design space. Eventually, ChipGPT will search through this space\nto select the optimal design under the target metrics. The evaluation sheds\nsome light on whether LLMs can generate correct and complete hardware logic\ndesigns described by natural language for some specifications. It is shown that\nChipGPT improves programmability, and controllability, and shows broader design\noptimization space compared to prior work and native LLMs alone.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:54:02 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 13:24:11 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.14020","submitter":"Bart Holterman","authors":"Bart Holterman and Kees van Deemter","title":"Does ChatGPT have Theory of Mind?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  ``Theory of Mind\" (ToM) is the ability to understand human thinking and\ndecision-making, an ability that plays a crucial role in many types of social\ninteraction between people, including linguistic communication. This paper\ninvestigates to what extent recent Large Language Models in the ChatGPT\ntradition possess ToM. Focussing on six well-known ToM problems, we posed each\nproblem to two versions of ChatGPT and compared the results under a range of\nprompting strategies. While the results concerning ChatGPT-3 were somewhat\ninconclusive, ChatGPT-4 was shown to arrive at the correct answers more often\nthan would be expected based on chance, although correct answers were often\narrived at on the basis of false assumptions or invalid reasoning.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:55:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14021","submitter":"Ming Li","authors":"Ming Li and Youjin Deng","title":"Iterative Percolation on Triangular Lattice","comments":"9 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The site percolation on the triangular lattice is one of few exactly solved\nstatistical systems. Starting from critical percolation clusters of black or\nwhite sites that are randomly placed, we randomly reassign the color of each\npercolation cluster and obtain coarse-grained configurations by merging\nclusters of the same color. It is shown that this process can be infinitely\niterated in the thermodynamic limit, leading to an iterative percolation model.\nFurther, we conjecture from self-matching argument that percolation clusters\nremain fractal for any finite generation, which can even take any real number\nby a generalized process. Extensive simulations are performed, and, from the\ngeneration-dependent fractal dimension, a continuous family of previously\nunknown universalities is revealed. Finally, following a similar process, the\niterative percolation is defined for critical bond-percolation clusters.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:55:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14022","submitter":"Qi Wu","authors":"Qi Wu, Mingyan Han, Ting Jiang, Haoqiang Fan, Bing Zeng, Shuaicheng\n  Liu","title":"Realistic Noise Synthesis with Diffusion Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep learning-based approaches have achieved remarkable performance in\nsingle-image denoising. However, training denoising models typically requires a\nlarge amount of data, which can be difficult to obtain in real-world scenarios.\nFurthermore, synthetic noise used in the past has often produced significant\ndifferences compared to real-world noise due to the complexity of the latter\nand the poor modeling ability of noise distributions of Generative Adversarial\nNetwork (GAN) models, resulting in residual noise and artifacts within\ndenoising models. To address these challenges, we propose a novel method for\nsynthesizing realistic noise using diffusion models. This approach enables us\nto generate large amounts of high-quality data for training denoising models by\ncontrolling camera settings to simulate different environmental conditions and\nemploying guided multi-scale content information to ensure that our method is\nmore capable of generating real noise with multi-frequency spatial\ncorrelations. In particular, we design an inversion mechanism for the setting,\nwhich extends our method to more public datasets without setting information.\nBased on the noise dataset we synthesized, we have conducted sufficient\nexperiments on multiple benchmarks, and experimental results demonstrate that\nour method outperforms state-of-the-art methods on multiple benchmarks and\nmetrics, demonstrating its effectiveness in synthesizing realistic noise for\ntraining denoising models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:56:01 GMT"},{"version":"v2","created":"Tue, 30 May 2023 03:09:37 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.14023","submitter":"Felix Burkhardt","authors":"Aljoscha D\\\"usterh\\\"oft, Felix Burkhardt, Bj\\\"orn W. Schuller","title":"Happy or Evil Laughter? Analysing a Database of Natural Audio Samples","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We conducted a data collection on the basis of the Google AudioSet database\nby selecting a subset of the samples annotated with \\textit{laughter}. The\nselection criterion was to be present a communicative act with clear\nconnotation of being either positive (laughing with) or negative (being laughed\nat). On the basis of this annotated data, we performed two experiments: on the\none hand, we manually extract and analyze phonetic features. On the other hand,\nwe conduct several machine learning experiments by systematically combining\nseveral automatically extracted acoustic feature sets with machine learning\nalgorithms. This shows that the best performing models can achieve and\nunweighted average recall of .7.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:56:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14024","submitter":"Alexandros A. Voudouris","authors":"Elliot Anshelevich, Aris Filos-Ratsikas, Christopher Jerrett,\n  Alexandros A. Voudouris","title":"Improved Metric Distortion via Threshold Approvals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a social choice setting in which agents and alternatives are\nrepresented by points in a metric space, and the cost of an agent for an\nalternative is the distance between the corresponding points in the space. The\ngoal is to choose a single alternative to (approximately) minimize the social\ncost (cost of all agents) or the maximum cost of any agent, when only limited\ninformation about the preferences of the agents is given. Previous work has\nshown that the best possible distortion one can hope to achieve is $3$ when\naccess to the ordinal preferences of the agents is given, even when the\ndistances between alternatives in the metric space are known. We improve upon\nthis bound of $3$ by designing deterministic mechanisms that exploit a bit of\ncardinal information. We show that it is possible to achieve distortion\n$1+\\sqrt{2}$ by using the ordinal preferences of the agents, the distances\nbetween alternatives, and a threshold approval set per agent that contains all\nalternatives for whom her cost is within an appropriately chosen factor of her\ncost for her most-preferred alternative. We show that this bound is the best\npossible for any deterministic mechanism in general metric spaces, and also\nprovide improved bounds for the fundamental case of a line metric.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:58:45 GMT"},{"version":"v2","created":"Wed, 24 May 2023 15:59:51 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14025","submitter":"Sebastian Sapeta","authors":"Tomoki Goda, Krzysztof Kutak, Sebastian Sapeta","title":"Effects of gluon kinematics and the Sudakov form factor on the dipole\n  amplitude","comments":"19 pages, 8 figures; v2: references added","journal-ref":null,"doi":null,"report-no":"IFJPAN-IV-2023-2","categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate effects of exact gluon kinematics on the parameters of the\nGolec-Biernat-W\\\"usthoff, and Bartels-Golec-Biernat-Kowalski saturation models.\nThe resulting fits show some differences, particularly, in the normalization of\nthe dipole cross section $\\sigma_0$. The refitted models are used for the dijet\nproduction process in DIS to investigate effects of the Sudakov form factor at\nElectron Ion Collider energies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:58:52 GMT"},{"version":"v2","created":"Mon, 29 May 2023 14:51:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14026","submitter":"Satya Prakash Nayak","authors":"Ashwani Anand, Satya Prakash Nayak, Anne-Kathrin Schmuck","title":"Synthesizing Permissive Winning Strategy Templates for Parity Games","comments":"CAV'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a novel method to compute \\emph{permissive winning strategies} in\ntwo-player games over finite graphs with $ \\omega $-regular winning conditions.\nGiven a game graph $G$ and a parity winning condition $\\Phi$, we compute a\n\\emph{winning strategy template} $\\Psi$ that collects an infinite number of\nwinning strategies for objective $\\Phi$ in a concise data structure. We use\nthis new representation of sets of winning strategies to tackle two problems\narising from applications of two-player games in the context of cyber-physical\nsystem design -- (i) \\emph{incremental synthesis}, i.e., adapting strategies to\nnewly arriving, \\emph{additional} $\\omega$-regular objectives $\\Phi'$, and (ii)\n\\emph{fault-tolerant control}, i.e., adapting strategies to the occasional or\npersistent unavailability of actuators. The main features of our strategy\ntemplates -- which we utilize for solving these challenges -- are their easy\ncomputability, adaptability, and compositionality. For \\emph{incremental\nsynthesis}, we empirically show on a large set of benchmarks that our technique\nvastly outperforms existing approaches if the number of added specifications\nincreases. While our method is not complete, our prototype implementation\nreturns the full winning region in all 1400 benchmark instances, i.e., handling\na large problem class efficiently in practice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:59:15 GMT"},{"version":"v2","created":"Mon, 29 May 2023 21:03:45 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.14027","submitter":"Guilherme Zeus Dantas E Moura","authors":"Guilherme Zeus Dantas e Moura, Tibor Jord\\'an, Corwin Silverman","title":"On generic universal rigidity on the line","comments":"13 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.MG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A $d$-dimensional bar-and-joint framework $(G,p)$ with underlying graph $G$\nis called universally rigid if all realizations of $G$ with the same edge\nlengths, in all dimensions, are congruent to $(G,p)$. A graph $G$ is said to be\ngenerically universally rigid in $\\mathbb{R}^d$ if every $d$-dimensional\ngeneric framework $(G,p)$ is universally rigid.\n  In this paper we focus on the case $d=1$. We give counterexamples to a\nconjectured characterization of generically universally rigid graphs from R.\nConnelly (2011). We also introduce two new operations that preserve the\nuniversal rigidity of generic frameworks, and the property of being not\nuniversally rigid, respectively. One of these operations is used in the\nanalysis of one of our examples, while the other operation is applied to obtain\na lower bound on the size of generically universally rigid graphs. This bound\ngives a partial answer to a question from T. Jord\\'an and V-H. Nguyen (2015).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:59:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14028","submitter":"Mihail N. Kolountzakis","authors":"Rachel Greenfeld and Mihail N. Kolountzakis","title":"Tiling, spectrality and aperiodicity of connected sets","comments":"20 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let $\\Omega\\subset \\mathbb{R}^d$ be a set of finite measure. The periodic\ntiling conjecture suggests that if $\\Omega$ tiles $\\mathbb{R}^d$ by\ntranslations then it admits at least one periodic tiling. Fuglede's conjecture\nsuggests that $\\Omega$ admits an orthogonal basis of exponential functions if\nand only if it tiles $\\mathbb{R}^d$ by translations. Both conjectures are known\nto be false in sufficiently high dimensions, with all the so-far-known\ncounterexamples being highly disconnected. On the other hand, both conjectures\nare known to be true for convex sets. In this work we study these conjectures\nfor connected sets. We show that the periodic tiling conjecture, as well as\nboth directions of Fuglede's conjecture are false for connected sets in\nsufficiently high dimensions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:59:36 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 16:58:35 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.14029","submitter":"Frederik Banning","authors":"Frederik Banning, Jessica Reale, Michael Roos","title":"The Complexity of Corporate Culture as a Potential Source of Firm Profit\n  Differentials","comments":"34 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.TH","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper proposes an addition to the firm-based perspective on\nintra-industry profitability differentials by modelling a business organisation\nas a complex adaptive system. The presented agent-based model introduces an\nendogenous similarity-based social network and employees' reactions to dynamic\nmanagement strategies informed by key company benchmarks. The value-based\ndecision-making of employees shapes the behaviour of others through their\nperception of social norms from which a corporate culture emerges. These\nelements induce intertwined feedback mechanisms which lead to unforeseen\nprofitability outcomes. The simulations reveal that variants of extreme\nadaptation of management style yield higher profitability in the long run than\nthe more moderate alternatives. Furthermore, we observe convergence towards a\ndominant management strategy with low intensity in monitoring efforts as well\nas high monetary incentivisation of cooperative behaviour. The results suggest\nthat measures increasing the connectedness of the workforce across all four\nvalue groups might be advisable to escape potential lock-in situation and thus\nraise profitability. A further positive impact on profitability can be achieved\nthrough knowledge about the distribution of personal values among a firm's\nemployees. Choosing appropriate and enabling management strategies, and\nsticking to them in the long run, can support the realisation of the inherent\nself-organisational capacities of the workforce, ultimately leading to higher\nprofitability through cultural stability.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:01:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14030","submitter":"Abhinendra Singh","authors":"Abhinendra Singh, Kuniyasu Saitoh","title":"Scaling relations between viscosity and diffusivity in shear-thickening\n  suspensions","comments":"7 pages; 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft physics.flu-dyn physics.geo-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dense suspensions often exhibit a dramatic response to large external\ndeformation. The recent body of work has related this behavior to transition\nfrom an unconstrained lubricated to a constrained frictional state. Here, we\nuse numerical simulations to study the flow behavior and shear-induced\ndiffusion of frictional non-Brownian spheres in two dimensions under simple\nshear flow. We first show that both viscosity $\\eta$ and diffusivity\n$D/\\dot{\\gamma}$ of the particles increase at characteristic shear stress,\nwhich is associated with lubrication to frictional transition. Subsequently, we\npropose a one-to-one relation between viscosity and diffusivity using the\nlength scale $\\xi$ associated with the size of collective motions (rigid\nclusters) of the particles. We demonstrate that $\\eta$ and $D/\\dot{\\gamma}$ are\ncontrolled by $\\xi$ in two distinct flow regimes, i.e. in the frictionless and\nfrictional states, where the one-to-one relation is described as a crossover\nfrom $D/\\dot{\\gamma}\\sim\\eta$ ({frictionless}) to $\\eta^{1/3}$ ({frictional}).\nWe also confirm the proposed power laws are insensitive to the interparticle\nfriction and system size.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:02:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14031","submitter":"Lu Yan","authors":"Zhonghua Li and Lu Yan","title":"Generating functions of multiple $t$-star values of general level","comments":"arXiv admin note: substantial text overlap with arXiv:2212.09070","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we study the explicit expressions of multiple $t$-star values\nof general level. We represent the generating functions of multiple $t$-star\nvalues of level $N$ with an arbitrary number of blocks of twos, which\ngeneralize the results for multiple zeta-star values and multiple $t$-star\nvalues. These generating functions can provide a formula of multiple $t$-star\nvalues of level $N$. As applications, some evaluations of multiple $t$-star\nvalues of level $N$ with one-two-three or more general indices are given.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:04:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14032","submitter":"Sangmin Bae","authors":"Sangmin Bae, June-Woo Kim, Won-Yang Cho, Hyerim Baek, Soyoun Son,\n  Byungjo Lee, Changwan Ha, Kyongpil Tae, Sungnyun Kim, Se-Young Yun","title":"Patch-Mix Contrastive Learning with Audio Spectrogram Transformer on\n  Respiratory Sound Classification","comments":"INTERSPEECH 2023, Code URL:\n  https://github.com/raymin0223/patch-mix_contrastive_learning","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.LG cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Respiratory sound contains crucial information for the early diagnosis of\nfatal lung diseases. Since the COVID-19 pandemic, there has been a growing\ninterest in contact-free medical care based on electronic stethoscopes. To this\nend, cutting-edge deep learning models have been developed to diagnose lung\ndiseases; however, it is still challenging due to the scarcity of medical data.\nIn this study, we demonstrate that the pretrained model on large-scale visual\nand audio datasets can be generalized to the respiratory sound classification\ntask. In addition, we introduce a straightforward Patch-Mix augmentation, which\nrandomly mixes patches between different samples, with Audio Spectrogram\nTransformer (AST). We further propose a novel and effective Patch-Mix\nContrastive Learning to distinguish the mixed representations in the latent\nspace. Our method achieves state-of-the-art performance on the ICBHI dataset,\noutperforming the prior leading score by an improvement of 4.08%.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:04:07 GMT"},{"version":"v2","created":"Sat, 27 May 2023 04:13:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14033","submitter":"Maxim Chernodub","authors":"M. N. Chernodub, V. A. Goy, A. V. Molochkov","title":"Generation of electric current by magnetic field at the boundary:\n  quantum scale anomaly vs. semiclassical Meissner current","comments":"12 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-lat cond-mat.other hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The scale (conformal) anomaly can generate an electric current near the\nboundary of a system in the presence of a static magnetic field. The magnitude\nof this magnetization current, produced at zero temperature and in the absence\nof matter, is proportional to a beta function associated with the\nrenormalization of the electric charge. Using first-principle lattice\nsimulations, we investigate how the breaking of the scale symmetry affects this\n``scale magnetic effect'' near a Dirichlet boundary in scalar QED (Abelian\nHiggs model). We demonstrate the interplay of the generated current with vortex\nexcitations both in symmetric (normal) and broken (superconducting) phases and\ncompare the results with the anomalous current produced in the conformal,\nscale-invariant regime.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:04:27 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14034","submitter":"Garnik F. Mkrtchian","authors":"H.K. Avetissian, A.G. Ghazaryan, Kh.V. Sedrakian, and G.F. Mkrtchian","title":"Long-range correlation-induced effects at high-order harmonic generation\n  on graphene quantum dots","comments":"9 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper focuses on investigating high-order harmonic generation (HHG) in\ngraphene quantum dots (GQDs) under intense near-infrared laser fields. To model\nthe GQD and its interaction with the laser field, we utilize a mean-field\napproach. Our analysis of the HHG power spectrum reveals fine structures and a\nnoticeable enhancement in cutoff harmonics due to the long-range correlations.\nWe also demonstrate the essential role of Coulomb interaction in determining of\nharmonics intensities and cutoff position. Unlike atomic HHG, where the cutoff\nenergy is proportional to the pump wave intensity, in GQDs the cutoff energy\nscales with the square root of the field strength amplitude. A detailed\ntime-frequency analysis of the entire range of HHG spectrum is presented using\na wavelet transform. The analysis reveals intricate details of the spectral and\ntemporal fine structures of HHG, offering insights into the various HHG\nmechanisms in GQDs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:04:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14035","submitter":"Eklavya Sarkar","authors":"Eklavya Sarkar and Mathew Magimai.-Doss","title":"Can Self-Supervised Neural Representations Pre-Trained on Human Speech\n  distinguish Animal Callers?","comments":"Accepted at Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Self-supervised learning (SSL) models use only the intrinsic structure of a\ngiven signal, independent of its acoustic domain, to extract essential\ninformation from the input to an embedding space. This implies that the utility\nof such representations is not limited to modeling human speech alone. Building\non this understanding, this paper explores the cross-transferability of SSL\nneural representations learned from human speech to analyze bio-acoustic\nsignals. We conduct a caller discrimination analysis and a caller detection\nstudy on Marmoset vocalizations using eleven SSL models pre-trained with\nvarious pretext tasks. The results show that the embedding spaces carry\nmeaningful caller information and can successfully distinguish the individual\nidentities of Marmoset callers without fine-tuning. This demonstrates that\nrepresentations pre-trained on human speech can be effectively applied to the\nbio-acoustics domain, providing valuable insights for future investigations in\nthis field.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:06:14 GMT"},{"version":"v2","created":"Wed, 31 May 2023 15:29:26 GMT"},{"version":"v3","created":"Thu, 8 Jun 2023 13:32:43 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.14036","submitter":"Farhad Ghanipoor","authors":"Farhad Ghanipoor, Carlos Murguia, Peyman Mohajerin Esfahani, Nathan\n  van de Wouw","title":"Robust Fault Estimators for Nonlinear Systems: An Ultra-Local Model\n  Design","comments":"arXiv admin note: text overlap with arXiv:2204.01455","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper proposes a nonlinear estimator for the robust reconstruction of\nprocess and sensor faults for a class of uncertain nonlinear systems. The\nproposed fault estimation method augments the system dynamics with an\nultra-local (in time) internal state-space representation (a finite chain of\nintegrators) of the fault vector. Next, a nonlinear state observer is designed\nbased on the known parts of the augmented dynamics. This nonlinear filter\n(observer) reconstructs the fault signal as well as the states of the augmented\nsystem. We provide sufficient conditions that guarantee stability of the\nestimation error dynamics: firstly, asymptotic stability (i.e., perfect fault\nestimation) in the absence of perturbations induced by fault model mismatch\n(mismatch between internal, ultralocal model for the fault and the actual fault\ncharacteristics), uncertainty, external disturbances, and measurement noise\nand, secondly, Input-to-State Stability (ISS) of the estimation error dynamics\nis guaranteed in the presence of these perturbations. In addition, to support\nperformance-based estimator design, we provide Linear Matrix Inequality (LMI)\nconditions for L2-gain and L2 - L_inf induced norm and cast the synthesis of\nthe estimator gains as a semi-definite program where the effect of model\nmismatch and external disturbances on the fault estimation error is minimized\nin the sense of L2-gain, for an acceptable L2 - L_inf induced norm with respect\nto measurement noise. The latter result facilitates a design that explicitly\naddresses the performance trade-off between noise sensitivity and robustness\nagainst model mismatch and external disturbances. Finally, numerical results\nfor a benchmark system illustrate the performance of the proposed\nmethodologies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:08:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14037","submitter":"Julio Backhoff Veraguas","authors":"Julio Backhoff-Veraguas, Mathias Beiglboeck","title":"The most exciting game","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Motivated by a problem posed by Aldous, our goal is to find the\nmaximal-entropy win-martingale:\n  In a sports game between two teams, the chance the home team wins is\ninitially $x_0 \\in (0,1)$ and finally 0 or 1. As an idealization we take a\ncontinuous time interval $[0,1]$ and consider the process $M=(M_t)_{t\\in\n[0,1]}$ giving the probability at time $t$ that the home team wins. This is a\nmartingale which we idealize further to have continuous paths. We consider the\nproblem to find the most random martingale $M$ of this type, where `most\nrandom' is interpreted as a maximal entropy criterion. We observe that this\nmax-entropy win-martingale $M$ also minimizes specific relative entropy with\nrespect to Brownian motion in the sense of Gantert and use this to prove that\n$M$ is characterized by the stochastic differential equation $$ dM_t =\n\\frac{\\sin (\\pi M_t )} {\\pi\\sqrt {1-t}}\\, dB_t.$$ To derive the form of the\noptimizer we use a scaling argument together with a new first order condition\nfor martingale optimal transport which may be of interest in its own right.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:08:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14038","submitter":"Hui Kong","authors":"Yuming Huang, Yi Gu, Chengzhong Xu and Hui Kong","title":"Why semantics matters: A deep study on semantic particle-filtering\n  localization in a LiDAR semantic pole-map","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In most urban and suburban areas, pole-like structures such as tree trunks or\nutility poles are ubiquitous. These structural landmarks are very useful for\nthe localization of autonomous vehicles given their geometrical locations in\nmaps and measurements from sensors. In this work, we aim at creating an\naccurate map for autonomous vehicles or robots with pole-like structures as the\ndominant localization landmarks, hence called pole-map. In contrast to the\nprevious pole-based mapping or localization methods, we exploit the semantics\nof pole-like structures. Specifically, semantic segmentation is achieved by a\nnew mask-range transformer network in a mask-classfication paradigm. With the\nsemantics extracted for the pole-like structures in each frame, a multi-layer\nsemantic pole-map is created by aggregating the detected pole-like structures\nfrom all frames. Given the semantic pole-map, we propose a semantic\nparticle-filtering localization scheme for vehicle localization. Theoretically,\nwe have analyzed why the semantic information can benefit the particle-filter\nlocalization, and empirically it is validated on the public SemanticKITTI\ndataset that the particle-filtering localization with semantics achieves much\nbetter performance than the counterpart without semantics when each particle's\nodometry prediction and/or the online observation is subject to uncertainties\nat significant levels.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:09:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14039","submitter":"Yuantong Zhang","authors":"Yuantong Zhang, Baoxin Teng, Daiqin Yang, Zhenzhong Chen, Haichuan Ma,\n  Gang Li, Wenpeng Ding","title":"Learning a Single Convolutional Layer Model for Low Light Image\n  Enhancement","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Low-light image enhancement (LLIE) aims to improve the illuminance of images\ndue to insufficient light exposure. Recently, various lightweight\nlearning-based LLIE methods have been proposed to handle the challenges of\nunfavorable prevailing low contrast, low brightness, etc. In this paper, we\nhave streamlined the architecture of the network to the utmost degree. By\nutilizing the effective structural re-parameterization technique, a single\nconvolutional layer model (SCLM) is proposed that provides global low-light\nenhancement as the coarsely enhanced results. In addition, we introduce a local\nadaptation module that learns a set of shared parameters to accomplish local\nillumination correction to address the issue of varied exposure levels in\ndifferent image regions. Experimental results demonstrate that the proposed\nmethod performs favorably against the state-of-the-art LLIE methods in both\nobjective metrics and subjective visual effects. Additionally, our method has\nfewer parameters and lower inference complexity compared to other\nlearning-based schemes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:12:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14040","submitter":"Alec McClean","authors":"Leah A. Jacobs, Alec McClean, Zach Branson, Edward H. Kennedy, Alex\n  Fixler","title":"Incremental Propensity Score Effects for Criminology: An Application\n  Assessing the Relationship Between Houselessness, Behavioral Health Problems,\n  and Recidivism","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This study examines the relationship between houselessness and recidivism\namong people on probation with and without behavioral health problems. The\nstudy also illustrates a new way to summarize the effect of an exposure on an\noutcome, the Incremental Propensity Score (IPS), which avoids pitfalls of other\nestimation approaches commonly used in criminology. We assessed the impact of\nhouselessness at probation start on rearrest within one year among a cohort of\npeople on probation (n = 2,453). We estimated IPS effects, considering general\nand crime-specific recidivism if subjects were more or less likely to be\nunhoused and assessed effect variation by psychiatric disorder status. We used\na doubly robust machine learning estimator to flexibly but efficiently estimate\neffects. Decreasing houselessness led to a lower estimated average rate of\nrecidivism. Dividing the odds of houselessness by ten had a significant effect\nwhen compared to multiplying the odds of houselessness by ten, corresponding to\na 9% reduction in the estimated average rate of recidivism (p < 0.05). Milder\ninterventions showed smaller, non-significant effect sizes. Stratifying by\ndiagnoses and re-arrest type led to similar results without statistical\nsignificance. Minding limitations related to observational data and\ngeneralizability, this study supports houselessness as a risk factor for\nrecidivism across populations with a new analytic approach. Efforts to reduce\nrecidivism should include interventions that make houselessness less likely,\nsuch as increasing housing access. Meanwhile, efforts to establish recidivism\nrisk factors should consider alternative effects like IPS effects to maximize\nvalidity and reduce bias.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:12:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14041","submitter":"Alireza Darvishy","authors":"Alireza Darvishy, Rolf Sethe, Ines Engler, Oriane Pierres, Juliet\n  Manning","title":"The state of scientific PDF accessibility in repositories: A survey in\n  Switzerland","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.CY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This survey analyzed the quality of the PDF documents on online repositories\nin Switzerland, examining their accessibility for people with visual\nimpairments. Two minimal accessibility features were analyzed: the PDFs had to\nhave tags and a hierarchical heading structure. The survey also included\ninterviews with the managers or heads of multiple Swiss universities'\nrepositories to assess the general opinion and knowledge of PDF accessibility.\nAn analysis of interviewee responses indicates an overall lack of awareness of\nPDF accessibility, and showed that online repositories currently have no\nconcrete plans to address the issue. This paper concludes by presenting a set\nof recommendations for online repositories to improve the accessibility of\ntheir PDF documents.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:13:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14042","submitter":"Wenbiao Yin","authors":"Wenbiao Yin, Zhicheng Liu, Chengqi Zhao, Tao Wang, Jian Tong, Rong Ye","title":"Improving speech translation by fusing speech and text","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In speech translation, leveraging multimodal data to improve model\nperformance and address limitations of individual modalities has shown\nsignificant effectiveness. In this paper, we harness the complementary\nstrengths of speech and text, which are disparate modalities. We observe three\nlevels of modality gap between them, denoted by Modal input representation,\nModal semantic, and Modal hidden states. To tackle these gaps, we propose\n\\textbf{F}use-\\textbf{S}peech-\\textbf{T}ext (\\textbf{FST}), a cross-modal model\nwhich supports three distinct input modalities for translation: speech, text,\nand fused speech-text. We leverage multiple techniques for cross-modal\nalignment and conduct a comprehensive analysis to assess its impact on speech\ntranslation, machine translation, and fused speech-text translation. We\nevaluate FST on MuST-C, GigaST, and newstest benchmark. Experiments show that\nthe proposed FST achieves an average 34.0 BLEU on MuST-C\nEn$\\rightarrow$De/Es/Fr (vs SOTA +1.1 BLEU). Further experiments demonstrate\nthat FST does not degrade on MT task, as observed in prior works. Instead, it\nyields an average improvement of 3.2 BLEU over the pre-trained MT model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:13:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14043","submitter":"Mykyta Bulakhov","authors":"M. Bulakhov, A.S. Peletminskii, and Yu.V. Slyusarenko","title":"Zero sound in a quantum gas of spin-3/2 atoms with multipole exchange\n  interaction","comments":"21 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the context of quantum gases, we obtain a many-body Hamiltonian for\nspin-3/2 atoms with general multipole (spin, quadrupole, and octupole) exchange\ninteraction by employing the apparatus of irreducible spherical tensor\noperators. This Hamiltonian implies the finite-range interaction, whereas, for\nzero-range (contact) potentials parameterized by the $s$-wave scattering\nlength, the multipole exchange interaction becomes irrelevant. Following the\nreduced description method for quantum systems, we derive the quantum kinetic\nequation for spin-3/2 atoms in a magnetic field and apply it to examine the\nhigh-frequency oscillations known as zero sound.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:14:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14044","submitter":"Yago Fontenla-Seco","authors":"Yago Fontenla-Seco, Alberto Bugar\\'in-Diz, Manuel Lama","title":"Process-To-Text: A Framework for the Quantitative Description of\n  Processes in Natural Language","comments":"This version of the article has been accepted for publication, after\n  peer review and is subject to Springer Nature's AM terms of use, but is not\n  the Version of Record and does not reflect postacceptance improvements, or\n  any corrections. The Version of Record is available online at:\n  http://dx.doi.org/10.1007/978-3-030-73959-1_19","journal-ref":null,"doi":"10.1007/978-3-030-73959-1_19","report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we present the Process-To-Text (P2T) framework for the\nautomatic generation of textual descriptive explanations of processes. P2T\nintegrates three AI paradigms: process mining for extracting temporal and\nstructural information from a process, fuzzy linguistic protoforms for\nmodelling uncertain terms, and natural language generation for building the\nexplanations. A real use-case in the cardiology domain is presented, showing\nthe potential of P2T for providing natural language explanations addressed to\nspecialists.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:14:34 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14045","submitter":"Seungone Kim","authors":"Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye,\n  Jamin Shin, Minjoon Seo","title":"The CoT Collection: Improving Zero-shot and Few-shot Learning of\n  Language Models via Chain-of-Thought Fine-Tuning","comments":"Work in Progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large Language Models (LLMs) have shown enhanced capabilities of solving\nnovel tasks by reasoning step-by-step known as Chain-of-Thought (CoT)\nreasoning; how can we instill the same capability of reasoning step-by-step on\nunseen tasks into LMs that possess less than <100B parameters? To address this\nquestion, we first introduce the CoT Collection, a new instruction-tuning\ndataset that augments 1.88 million CoT rationales across 1,060 tasks. We show\nthat continually fine-tuning Flan-T5 (3B & 11B) with the CoT Collection enables\nthe 3B & 11B LMs to perform CoT better on unseen tasks, leading to an\nimprovement in the average zero-shot accuracy on 27 datasets of the\nBIG-Bench-Hard benchmark by +4.34% and +2.44%, respectively. Furthermore, we\nshow that instruction tuning with CoT allows LMs to possess stronger few-shot\nlearning capabilities, resulting in an improvement of +2.97% and +2.37% on 4\ndomain-specific tasks over Flan-T5 (3B & 11B), respectively. We make our CoT\nCollection data and our trained models publicly available at\nhttps://github.com/kaist-lklab/CoT-Collection.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:14:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14046","submitter":"Kaihua Qin","authors":"Kaihua Qin, Zhe Ye, Zhun Wang, Weilin Li, Liyi Zhou, Chao Zhang, Dawn\n  Song, Arthur Gervais","title":"Towards Automated Security Analysis of Smart Contracts based on\n  Execution Property Graph","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Identifying and mitigating vulnerabilities in smart contracts is crucial,\nespecially considering the rapid growth and increasing complexity of\nDecentralized Finance (DeFi) platforms. To address the challenges associated\nwith securing these contracts, we introduce a versatile dynamic analysis\nframework specifically designed for the Ethereum Virtual Machine (EVM). This\ncomprehensive framework focuses on tracking contract executions, capturing\nvaluable runtime information, while introducing and employing the Execution\nProperty Graph (EPG) to propose a unique graph traversal technique that swiftly\ndetects potential smart contract attacks. Our approach showcases its efficacy\nwith rapid average graph traversal time per transaction and high true positive\nrates. The successful identification of a zero-day vulnerability affecting\nUniswap highlights the framework's potential to effectively uncover smart\ncontract vulnerabilities in complex DeFi systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:16:42 GMT"},{"version":"v2","created":"Thu, 25 May 2023 02:54:09 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.14047","submitter":"Kaiqiang Yu","authors":"Kaiqiang Yu and Cheng Long","title":"Fast Maximal Quasi-clique Enumeration: A Pruning and Branching Co-Design\n  Approach","comments":"This paper has been accepted by SIGMOD 2024","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mining cohesive subgraphs from a graph is a fundamental problem in graph data\nanalysis. One notable cohesive structure is $\\gamma$-quasi-clique (QC), where\neach vertex connects at least a fraction $\\gamma$ of the other vertices inside.\nEnumerating maximal $\\gamma$-quasi-cliques (MQCs) of a graph has been widely\nstudied. One common practice of finding all MQCs is to (1) find a set of QCs\ncontaining all MQCs and then (2) filter out non-maximal QCs. While quite a few\nalgorithms have been developed (which are branch-and-bound algorithms) for\nfinding a set of QCs that contains all MQCs, all focus on sharpening the\npruning techniques and devote little effort to improving the branching part. As\na result, they provide no guarantee on pruning branches and all have the\nworst-case time complexity of $O^*(2^n)$, where $O^*$ suppresses the\npolynomials and $n$ is the number of vertices in the graph. In this paper, we\nfocus on the problem of finding a set of QCs containing all MQCs but deviate\nfrom further sharpening the pruning techniques as existing methods do. We pay\nattention to both the pruning and branching parts and develop new pruning\ntechniques and branching methods that would suit each other better towards\npruning more branches both theoretically and practically. Specifically, we\ndevelop a new branch-and-bound algorithm called FastQC based on newly developed\npruning techniques and branching methods, which improves the worst-case time\ncomplexity to $O^*(\\alpha_k^n)$, where $\\alpha_k$ is a positive real number\nstrictly smaller than 2. Furthermore, we develop a divide-and-conquer strategy\nfor boosting the performance of FastQC. Finally, we conduct extensive\nexperiments on both real and synthetic datasets, and the results show that our\nalgorithms are up to two orders of magnitude faster than the state-of-the-art\non real datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:19:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14048","submitter":"Timothy Sun","authors":"Warren Singh, Timothy Sun","title":"Settling the nonorientable genus of the nearly complete bipartite graphs","comments":"10 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A graph is said to be nearly complete bipartite if it can be obtained by\ndeleting a set of independent edges from a complete bipartite graph. The\nnonorientable genus of such graphs is known except in a few cases where the\nsizes of the partite classes differ by at most one, and a maximum matching is\ndeleted. We resolve these missing cases using three classic tools for\nconstructing genus embeddings of the complete bipartite graphs: current graphs,\ndiamond sums, and the direct rotation systems of Ringel.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:24:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14049","submitter":"TianHao Zhang","authors":"Tian-Hao Zhang, Hai-Bo Qin, Zhi-Hao Lai, Song-Lu Chen, Qi Liu, Feng\n  Chen, Xinyuan Qian, Xu-Cheng Yin","title":"Rethinking Speech Recognition with A Multimodal Perspective via Acoustic\n  and Semantic Cooperative Decoding","comments":"Accepted by Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Attention-based encoder-decoder (AED) models have shown impressive\nperformance in ASR. However, most existing AED methods neglect to\nsimultaneously leverage both acoustic and semantic features in decoder, which\nis crucial for generating more accurate and informative semantic states. In\nthis paper, we propose an Acoustic and Semantic Cooperative Decoder (ASCD) for\nASR. In particular, unlike vanilla decoders that process acoustic and semantic\nfeatures in two separate stages, ASCD integrates them cooperatively. To prevent\ninformation leakage during training, we design a Causal Multimodal Mask.\nMoreover, a variant Semi-ASCD is proposed to balance accuracy and computational\ncost. Our proposal is evaluated on the publicly available AISHELL-1 and\naidatatang_200zh datasets using Transformer, Conformer, and Branchformer as\nencoders, respectively. The experimental results show that ASCD significantly\nimproves the performance by leveraging both the acoustic and semantic\ninformation cooperatively.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:25:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14050","submitter":"Simonas Drauk\\v{s}as","authors":"Simonas Drauk\\v{s}as, Vytautas D\\=ud\\.enas, Lu\\'is Lavoura","title":"Oblique corrections when $m_W \\neq m_Z \\cos{\\theta_W}$ at tree level","comments":"30 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The parametrization of the oblique corrections through $S$, $T$, and $U$ --\nlater extended by $V$, $W$, and $X$ -- is a convenient way of comparing the\npredictions for various electroweak observables at the one-loop level between\nthe Standard Model and its extensions. That parametrization assumes that the\nextensions under consideration have ${SU(2)\\times U(1)}$ gauge symmetry\n\\emph{and} the tree-level relation $m_W = m_Z \\cos{\\theta_W}$ between the\nWeinberg angle and the gauge-boson masses. In models where that relation does\nnot hold at the Lagrangian level, the parameter $T$ is not ultraviolet-finite,\nmaking the parametrization inadequate. We present expressions that parametrize\nthe difference of the various predictions of two models with $m_W \\neq m_Z\n\\cos{\\theta_W}$ in terms of oblique parameters. The parameter $T$ does not play\na role in those expressions. Conveniently, they may be reached, from the ones\nthat were derived for models with tree-level $m_W = m_Z \\cos{\\theta_W}$, by\nperforming a simple substitution for $T$. We also discuss the difficulties in\nusing oblique parameters when comparing a model with $m_W \\neq m_Z\n\\cos{\\theta_W}$ to the Standard Model. Finally, we compute the relevant five\noblique parameters in the SM extended by scalars in both $Y=0$ and $Y=1$\ntriplets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:28:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14051","submitter":"Alberto Rech","authors":"Alberto Rech, Leonardo Badia, Stefano Tomasin, Matteo Pagin, Marco\n  Giordani, Jonathan Gambini, Michele Zorzi","title":"Downlink Clustering-Based Scheduling of IRS-Assisted Communications With\n  Reconfiguration Constraints","comments":"13 pages, 10 figures, journal paper. arXiv admin note: text overlap\n  with arXiv:2301.10738","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Intelligent reflecting surfaces (IRSs) are being widely investigated as a\npotential low-cost and energy-efficient alternative to active relays for\nimproving coverage in next-generation cellular networks. However, technical\nconstraints in the configuration of IRSs should be taken into account in the\ndesign of scheduling solutions and the assessment of their performance. To this\nend, we examine an IRS-assisted time division multiple access (TDMA) cellular\nnetwork where the reconfiguration of the IRS incurs a communication cost; thus,\nwe aim at limiting the number of reconfigurations over time. Along these lines,\nwe propose a clustering-based heuristic scheduling scheme that maximizes the\ncell sum capacity, subject to a fixed number of reconfigurations within a TDMA\nframe. First, the best configuration of each user equipment (UE), in terms of\njoint beamforming and optimal IRS configuration, is determined using an\niterative algorithm. Then, we propose different clustering techniques to divide\nthe UEs into subsets sharing the same sub-optimal IRS configuration, derived\nthrough distance- and capacity-based algorithms. Finally, UEs within the same\ncluster are scheduled accordingly. We provide extensive numerical results for\ndifferent propagation scenarios, IRS sizes, and phase shifters quantization\nconstraints, showing the effectiveness of our approach in supporting multi-user\nIRS systems with practical constraints.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:29:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14052","submitter":"Takuma Iwata","authors":"Takuma Iwata, T. Kousa, Y. Nishioka, K. Ohwada, Kenta Kuroda, H.\n  Iwasawa, M. Arita, S. Kumar, A. Kimura, K. Miyamoto, and T. Okuda","title":"Laser-based angle-resolved photoemission spectroscopy with micrometer\n  spatial resolution and detection of three-dimensional spin vector","comments":"8 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We have developed a state-of-the-art apparatus for laser-based spin- and\nangle-resolved photoemission spectroscopy with micrometer spatial resolution\n(micro-SARPES). This equipment is achieved through the combination of a\nhigh-resolution photoelectron spectrometer, a 6-eV laser with high photon flux\nthat is focused down to a few micrometers, a high-precision sample stage\ncontrol system, and a double very-low-energy-electron-diffraction spin\ndetector. The setup achieves an energy resolution of 1.5 (5.5) meV without\n(with) the spin detection mode, compatible with a spatial resolution better\nthan 10 micrometers. This enables us to probe both spatially-resolved\nelectronic structures and vector information of spin polarization in three\ndimensions. The performance of micro-SARPES apparatus is demonstrated by\npresenting ARPES and SARPES results from topological insulators and Au\nphotolithography patterns on a Si (001) substrate.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:31:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14053","submitter":"James Oldfield","authors":"James Oldfield, Christos Tzelepis, Yannis Panagakis, Mihalis A.\n  Nicolaou, Ioannis Patras","title":"Parts of Speech-Grounded Subspaces in Vision-Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Latent image representations arising from vision-language models have proved\nimmensely useful for a variety of downstream tasks. However, their utility is\nlimited by their entanglement with respect to different visual attributes. For\ninstance, recent work has shown that CLIP image representations are often\nbiased toward specific visual properties (such as objects or actions) in an\nunpredictable manner. In this paper, we propose to separate representations of\nthe different visual modalities in CLIP's joint vision-language space by\nleveraging the association between parts of speech and specific visual modes of\nvariation (e.g. nouns relate to objects, adjectives describe appearance). This\nis achieved by formulating an appropriate component analysis model that learns\nsubspaces capturing variability corresponding to a specific part of speech,\nwhile jointly minimising variability to the rest. Such a subspace yields\ndisentangled representations of the different visual properties of an image or\ntext in closed form while respecting the underlying geometry of the manifold on\nwhich the representations lie. What's more, we show the proposed model\nadditionally facilitates learning subspaces corresponding to specific visual\nappearances (e.g. artists' painting styles), which enables the selective\nremoval of entire visual themes from CLIP-based text-to-image synthesis. We\nvalidate the model both qualitatively, by visualising the subspace projections\nwith a text-to-image model and by preventing the imitation of artists' styles,\nand quantitatively, through class invariance metrics and improvements to\nbaseline zero-shot classification. Our code is available at:\nhttps://github.com/james-oldfield/PoS-subspaces.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:32:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14054","submitter":"Felix K\\\"ung","authors":"Felix K\\\"ung","title":"Algebraic K0 for non-abelian Categories","comments":"Comments welcome at felix.kung@ulb.be","journal-ref":null,"doi":null,"report-no":null,"categories":"math.KT math.GR math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct a natural generalization of the Grothendieck group\n$\\mathrm{K}_0$ to the case of categories admitting pushouts by considering\nheaps. In particular we are able to reconstruct the classical $\\mathrm{K}_0$ of\nan abelian category as the group retract along the isomorphism class of the\nzero object. We finish by applying this construction to construct the integers\nwith addition and multiplication as the decategorification of finite sets and\nshow that in $\\mathrm{K}_0\\left(\\underline{\\mathrm{Top}}\\right)$ one can\nidentify a CW-complex with the iterated product of its cells.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:32:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14055","submitter":"Jie Yan","authors":"Mingjie Hu, Jie Yan, Liting Chen and Qingwei Lin","title":"The Ensemble Approach of Column Generation for Solving Cutting Stock\n  Problems","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper investigates the column generation (CG) for solving cutting stock\nproblems (CSP). Traditional CG method, which repeatedly solves a restricted\nmaster problem (RMP), often suffers from two critical issues in practice -- the\nloss of solution quality introduced by linear relaxation of both feasible\ndomain and objective and the high time cost of last iterations close to\nconvergence. We empirically find that the first issue is common in ordinary\nCSPs with linear cutting constraints, while the second issue is especially\nsevere in CSPs with nonlinear cutting constraints that are often generated by\napproximating chance constraints. We propose an alternative approach, ensembles\nof multiple column generation processes. In particular, we present two methods\n-- \\mc (multi-column) which return multiple feasible columns in each RMP\niteration, and \\mt (multi-path) which restarts the RMP iterations from\ndifferent initialized column sets once the iteration time exceeds a given time\nlimit. The ideas behind are same: leverage the multiple column generation\npathes to compensate the loss induced by relaxation, and add earlier\nsub-optimal columns to accelerate convergence of RMP iterations. Besides, we\ngive theoretical analysis on performance improvement guarantees. Experiments on\ncutting stock problems demonstrate that compared to traditional CG, our method\nachieves significant run-time reduction on CSPs with nonlinear constraints, and\ndramatically improves the ratio of solve-to-optimal on CSPs with linear\nconstraints.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:34:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14056","submitter":"Kirsten Hogenson","authors":"Kirsten Hogenson, Dan Johnston, Suzanne O'Hara","title":"Equitable Choosability of Prism Graphs","comments":"15 pages, 12 figures, submitted for publication in May 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A graph $G$ is equitably $k$-choosable if, for every $k$-uniform list\nassignment $L$, $G$ is $L$-colorable and each color appears on at most\n$\\left\\lceil |V(G)|/k\\right\\rceil$ vertices. Equitable list-coloring was\nintroduced by Kostochka, Pelsmajer, and West in 2003. They conjectured that a\nconnected graph $G$ with $\\Delta(G)\\geq 3$ is equitably $\\Delta(G)$-choosable,\nas long as $G$ is not complete or $K_{d,d}$ for odd $d$. In this paper, we use\na discharging argument to prove their conjecture for the infinite family of\nprism graphs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:36:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14057","submitter":"Lei Li","authors":"Lei Li, Jingjing Xu, Qingxiu Dong, Ce Zheng, Qi Liu, Lingpeng Kong, Xu\n  Sun","title":"Can Language Models Understand Physical Concepts?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language models~(LMs) gradually become general-purpose interfaces in the\ninteractive and embodied world, where the understanding of physical concepts is\nan essential prerequisite. However, it is not yet clear whether LMs can\nunderstand physical concepts in the human world. To investigate this, we design\na benchmark VEC that covers the tasks of (i) Visual concepts, such as the shape\nand material of objects, and (ii) Embodied Concepts, learned from the\ninteraction with the world such as the temperature of objects. Our zero\n(few)-shot prompting results show that the understanding of certain visual\nconcepts emerges as scaling up LMs, but there are still basic concepts to which\nthe scaling law does not apply. For example, OPT-175B performs close to humans\nwith a zero-shot accuracy of 85\\% on the material concept, yet behaves like\nrandom guessing on the mass concept. Instead, vision-augmented LMs such as CLIP\nand BLIP achieve a human-level understanding of embodied concepts. Analysis\nindicates that the rich semantics in visual representation can serve as a\nvaluable source of embodied knowledge. Inspired by this, we propose a\ndistillation method to transfer embodied knowledge from VLMs to LMs, achieving\nperformance gain comparable with that by scaling up the parameters of LMs 134x.\nOur dataset is available at \\url{https://github.com/TobiasLee/VEC}\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:36:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14058","submitter":"Vance Faber","authors":"Vance Faber and Noah Streib","title":"Network Routing on Regular Digraphs and Their Line Graphs","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper concerns all-to-all network routing on regular digraphs. In\nprevious work we focused on efficient routing in highly symmetric digraphs with\nlow diameter for fixed degree. Here, we show that every connected regular\ndigraph has an all-to-all routing scheme and associated schedule with no\nwaiting. In fact, this routing scheme becomes more efficient as the diameter\ngoes down with respect to the degree and number of vertices. Lastly, we examine\nthe simple scheduling algorithm called ``farthest-distance-first'' and prove\nthat it yields optimal schedules for all-to-all communication in networks of\ninterest, including Kautz graphs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:37:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14059","submitter":"Eric Brachmann","authors":"Eric Brachmann, Tommaso Cavallari, Victor Adrian Prisacariu","title":"Accelerated Coordinate Encoding: Learning to Relocalize in Minutes using\n  RGB and Poses","comments":"CVPR 2023 Highlight","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Learning-based visual relocalizers exhibit leading pose accuracy, but require\nhours or days of training. Since training needs to happen on each new scene\nagain, long training times make learning-based relocalization impractical for\nmost applications, despite its promise of high accuracy. In this paper we show\nhow such a system can actually achieve the same accuracy in less than 5\nminutes. We start from the obvious: a relocalization network can be split in a\nscene-agnostic feature backbone, and a scene-specific prediction head. Less\nobvious: using an MLP prediction head allows us to optimize across thousands of\nview points simultaneously in each single training iteration. This leads to\nstable and extremely fast convergence. Furthermore, we substitute effective but\nslow end-to-end training using a robust pose solver with a curriculum over a\nreprojection loss. Our approach does not require privileged knowledge, such a\ndepth maps or a 3D model, for speedy training. Overall, our approach is up to\n300x faster in mapping than state-of-the-art scene coordinate regression, while\nkeeping accuracy on par.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:38:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14060","submitter":"Manel Perucho Pla","authors":"Manel Perucho, Jose L\\'opez-Miralles, Nectaria A.B. Gizani,\n  Jos\\'e-Mar\\'ia Mart\\'i, Bia Boccardi","title":"On the large scale morphology of Hercules A: destabilized hot jets?","comments":"To be published in Monthly Notices of the Royal Astronomical Society","journal-ref":null,"doi":"10.1093/mnras/stad1640","report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Extragalactic jets are generated as bipolar outflows at the nuclei of active\ngalaxies. Depending on their morphology, they are classified as Fanaroff-Riley\ntype I (centre-brightened) and Fanaroff-Riley type II (edge-brightened) radio\njets. However, this division is not sharp and observations of these sources at\nlarge scales often show intermediate jet morphologies or even hybrid jet\nmorphologies with a FRI type jet on one side and a FRII type jet on the other.\nA good example of a radio galaxy that is difficult to classify as FRI or FRII\nis Hercules~A. This source shows jets with bright radio lobes (a common feature\nof FRII type jets) albeit without the hotspots indicative of the violent\ninteraction between the jet and the ambient medium at the impact region,\nbecause the jets seem to be disrupted inside the lobes at a distance from the\nbow shocks surrounding the lobes. In this paper, we explore the jet physics\nthat could trigger this peculiar morphology by means of three-dimensional\nrelativisitic hydrodynamical simulations. Our results show that the large-scale\nmorphological features of Hercules A jets and lobes can be reproduced by the\npropagation of a relativistically hot plasma outflow that is disrupted by\nhelical instability modes, and generates a hot lobe that expands isotropically\nagainst the pressure-decreasing intergalactic medium. We also discuss the\nimplications that this result may have for the host active nucleus in terms of\na possible transition from high-excitation to low-excitation galaxy modes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:38:24 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.14061","submitter":"Aayushya Agarwal","authors":"Aayushya Agarwal, Carmel Fiscko, Soummya Kar, Larry Pileggi, Bruno\n  Sinopoli","title":"An Equivalent Circuit Workflow for Unconstrained Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a new workflow for unconstrained optimization whereby objective\nfunctions are mapped onto a physical domain to more easily design algorithms\nthat are robust to hyperparameters and achieve fast convergence rates.\nSpecifically, we represent optimization problems as an equivalent circuit that\nare then solved solely as nonlinear circuits using robust solution methods. The\nequivalent circuit models the trajectory of component-wise scaled gradient flow\nproblem as the transient response of the circuit for which the steady-state\ncoincides with a critical point of the objective function. The equivalent\ncircuit model leverages circuit domain knowledge to methodically design new\noptimization algorithms that would likely not be developed without a physical\nmodel. We incorporate circuit knowledge into optimization methods by 1)\nenhancing the underlying circuit model for fast numerical analysis, 2)\ncontrolling the optimization trajectory by designing the nonlinear circuit\ncomponents, and 3) solving for step sizes using well-known methods from the\ncircuit simulation. We first establish the necessary conditions that the\ncontrols must fulfill for convergence. We show that existing descent algorithms\ncan be re-derived as special cases of this approach and derive new optimization\nalgorithms that are developed with insights from a circuit-based model. The new\nalgorithms can be designed to be robust to hyperparameters, achieve convergence\nrates comparable or faster than state of the art methods, and are applicable to\noptimizing a variety of both convex and nonconvex problems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:41:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14062","submitter":"Yuyang Miao","authors":"Yuyang Miao, Harry J. Davies, Danilo P. Mandic","title":"Amplitude-Independent Machine Learning for PPG through Visibility Graphs\n  and Transfer Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Photoplethysmography (PPG) signals are omnipresent in wearable devices, as\nthey measure blood volume variations using LED technology. These signals\nprovide insight into the body's circulatory system and can be employed to\nextract various bio-features, such as heart rate and vascular ageing. Although\nseveral algorithms have been proposed for this purpose, many exhibit\nlimitations, including heavy reliance on human calibration, high signal quality\nrequirements, and a lack of generalization. In this paper, we introduce a PPG\nsignal processing framework that integrates graph theory and computer vision\nalgorithms, which is invariant to affine transformations, offers rapid\ncomputation speed, and exhibits robust generalization across tasks and\ndatasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:41:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14063","submitter":"Ryoki Endo","authors":"Ryoki Endo, Xuefeng Liu","title":"Guaranteed estimation of Hadamard shape derivative for clustered\n  eigenvalues","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a guaranteed computation method to evaluate the Hadamard\nshape derivative for repeated eigenvalues. The proposed method enables the\ninvestigation of the behavior of eigenvalue variations around repeated\neigenvalues, and provides rigorous estimation for the range of the Hadamard\nshape derivative in the case of clustered eigenvalues.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:42:22 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14064","submitter":"Hanifa Tidjani","authors":"Hanifa Tidjani, Alberto Tosato, Alexander Ivlev, Corentin D\\'eprez,\n  Stefan Oosterhout, Lucas Stehouwer, Amir Sammak, Giordano Scappucci and Menno\n  Veldhorst","title":"A vertical gate-defined double quantum dot in a strained germanium\n  double quantum well","comments":"12 pages including supplementary material","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Gate-defined quantum dots in silicon-germanium heterostructures have become a\ncompelling platform for quantum computation and simulation. Thus far,\ndevelopments have been limited to quantum dots defined in a single plane. Here,\nwe propose to advance beyond planar systems by exploiting heterostructures with\nmultiple quantum wells. We demonstrate the operation of a gate-defined vertical\ndouble quantum dot in a strained germanium double quantum well. In quantum\ntransport measurements we observe stability diagrams corresponding to a double\nquantum dot system. We analyze the capacitive coupling to the nearby gates and\nfind two quantum dots accumulated under the central plunger gate. We extract\nthe position and estimated size, from which we conclude that the double quantum\ndots are vertically stacked in the two quantum wells. We discuss challenges and\nopportunities and outline potential applications in quantum computing and\nquantum simulation.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:42:36 GMT"},{"version":"v2","created":"Wed, 24 May 2023 16:45:02 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14065","submitter":"Peng Xu","authors":"Peng Xu, Lin Zhang, Xuanzhou Liu, Jiaqi Sun, Yue Zhao, Haiqing Yang,\n  Bei Yu","title":"Do Not Train It: A Linear Neural Architecture Search of Graph Neural\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural architecture search (NAS) for Graph neural networks (GNNs), called\nNAS-GNNs, has achieved significant performance over manually designed GNN\narchitectures. However, these methods inherit issues from the conventional NAS\nmethods, such as high computational cost and optimization difficulty. More\nimportantly, previous NAS methods have ignored the uniqueness of GNNs, where\nGNNs possess expressive power without training. With the randomly-initialized\nweights, we can then seek the optimal architecture parameters via the sparse\ncoding objective and derive a novel NAS-GNNs method, namely neural architecture\ncoding (NAC). Consequently, our NAC holds a no-update scheme on GNNs and can\nefficiently compute in linear time. Empirical evaluations on multiple GNN\nbenchmark datasets demonstrate that our approach leads to state-of-the-art\nperformance, which is up to $200\\times$ faster and $18.8\\%$ more accurate than\nthe strong baselines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:44:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14066","submitter":"Lan Jiang","authors":"Lan Jiang, Haoyang Huang, Dongdong Zhang, Rui Jiang, Furu Wei","title":"One-stop Training of Multiple Capacity Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training models with varying capacities can be advantageous for deploying\nthem in different scenarios. While high-capacity models offer better\nperformance, low-capacity models require fewer computing resources for training\nand inference. In this work, we propose a novel one-stop training framework to\njointly train high-capacity and low-capactiy models. This framework consists of\ntwo composite model architectures and a joint training algorithm called\nTwo-Stage Joint-Training (TSJT). Unlike knowledge distillation, where multiple\ncapacity models are trained from scratch separately, our approach integrates\nsupervisions from different capacity models simultaneously, leading to faster\nand more efficient convergence. Extensive experiments on the multilingual\nmachine translation benchmark WMT10 show that our method outperforms\nlow-capacity baseline models and achieves comparable or better performance on\nhigh-capacity models. Notably, the analysis demonstrates that our method\nsignificantly influences the initial training process, leading to more\nefficient convergence and superior solutions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:44:09 GMT"},{"version":"v2","created":"Wed, 24 May 2023 09:37:47 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14067","submitter":"Yuan Meng","authors":"Zhenshan Bing, Yuan Meng, Yuqi Yun, Hang Su, Xiaojie Su, Kai Huang,\n  Alois Knoll","title":"DIVA: A Dirichlet Process Based Incremental Deep Clustering Algorithm\n  via Variational Auto-Encoder","comments":"9 main pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generative model-based deep clustering frameworks excel in classifying\ncomplex data, but are limited in handling dynamic and complex features because\nthey require prior knowledge of the number of clusters. In this paper, we\npropose a nonparametric deep clustering framework that employs an infinite\nmixture of Gaussians as a prior. Our framework utilizes a memoized online\nvariational inference method that enables the \"birth\" and \"merge\" moves of\nclusters, allowing our framework to cluster data in a \"dynamic-adaptive\"\nmanner, without requiring prior knowledge of the number of features. We name\nthe framework as DIVA, a Dirichlet Process-based Incremental deep clustering\nframework via Variational Auto-Encoder. Our framework, which outperforms\nstate-of-the-art baselines, exhibits superior performance in classifying\ncomplex data with dynamically changing features, particularly in the case of\nincremental features.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:44:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14068","submitter":"Peter Huston","authors":"David Green, Peter Huston, Kyle Kawagoe, David Penneys, Anup Poudel,\n  Sean Sanford","title":"Enriched string-net models and their excitations","comments":"43 pages; numerous figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el math-ph math.CT math.MP math.QA quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Boundaries of Walker-Wang models have been used to construct commuting\nprojector models which realize chiral unitary modular tensor categories (UMTCs)\nas boundary excitations. Given a UMTC $\\mathcal{A}$ representing the Witt class\nof an anomaly, the article [arXiv:2208.14018] gave a commuting projector model\nassociated to an $\\mathcal{A}$-enriched unitary fusion category $\\mathcal{X}$\non a 2D boundary of the 3D Walker-Wang model associated to $\\mathcal{A}$. That\narticle claimed that the boundary excitations were given by the enriched\ncenter/M\\\"uger centralizer $Z^\\mathcal{A}(\\mathcal{X})$ of $\\mathcal{A}$ in\n$Z(\\mathcal{X})$.\n  In this article, we give a rigorous treatment of this 2D boundary model, and\nwe verify this assertion using topological quantum field theory (TQFT)\ntechniques, including skein modules and a certain semisimple algebra whose\nrepresentation category describes boundary excitations. We also use TQFT\ntechniques to show the 3D bulk point excitations of the Walker-Wang bulk are\ngiven by the M\\\"uger center $Z_2(\\mathcal{A})$, and we construct\nbulk-to-boundary hopping operators $Z_2(\\mathcal{A})\\to\nZ^{\\mathcal{A}}(\\mathcal{X})$ reflecting how the UMTC of boundary excitations\n$Z^{\\mathcal{A}}(\\mathcal{X})$ is symmetric-braided enriched in\n$Z_2(\\mathcal{A})$.\n  This article also includes a self-contained comprehensive review of the\nLevin-Wen string net model from a unitary tensor category viewpoint, as opposed\nto the skeletal $6j$ symbol viewpoint.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:45:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14069","submitter":"Shiqi Chen","authors":"Shiqi Chen, Siyang Gao and Junxian He","title":"Evaluating Factual Consistency of Summaries with Large Language Models","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Detecting factual errors in summaries has been an important and challenging\nsubject in summarization research. Inspired by the emergent ability of large\nlanguage models (LLMs), we explore evaluating factual consistency of summaries\nby directly prompting LLMs. We present a comprehensive empirical study to\nassess the ability of LLMs as factual consistency evaluators, which consists of\n(1) analyzing different LLMs such as the GPT model series and Flan-T5; (2)\ninvestigating a variety of prompting methods including vanilla prompting,\nchain-of-thought prompting, and a sentence-by-sentence prompting method to\ntackle long summaries; and (3) evaluating on diverse summaries generated by\nmultiple summarization systems, ranging from pre-transformer methods to SOTA\npretrained models. Our experiments demonstrate that prompting LLMs is able to\noutperform the previous best factuality systems in all settings, by up to 12.2\nabsolute points in terms of the binary classification accuracy on inconsistency\ndetection.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:48:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14070","submitter":"Leonardo Zilio","authors":"Rodrigo Wilkens, Leonardo Zilio and Aline Villavicencio","title":"Assessing Linguistic Generalisation in Language Models: A Dataset for\n  Brazilian Portuguese","comments":"This is the original manuscript that was submitted to LREV. The final\n  version was published recently and can be found at: https://rdcu.be/ddEa6.\n  Language Resources and Evaluation, https://doi.org/10.1007/s10579-023-09664-1","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Much recent effort has been devoted to creating large-scale language models.\nNowadays, the most prominent approaches are based on deep neural networks, such\nas BERT. However, they lack transparency and interpretability, and are often\nseen as black boxes. This affects not only their applicability in downstream\ntasks but also the comparability of different architectures or even of the same\nmodel trained using different corpora or hyperparameters. In this paper, we\npropose a set of intrinsic evaluation tasks that inspect the linguistic\ninformation encoded in models developed for Brazilian Portuguese. These tasks\nare designed to evaluate how different language models generalise information\nrelated to grammatical structures and multiword expressions (MWEs), thus\nallowing for an assessment of whether the model has learned different\nlinguistic phenomena. The dataset that was developed for these tasks is\ncomposed of a series of sentences with a single masked word and a cue phrase\nthat helps in narrowing down the context. This dataset is divided into MWEs and\ngrammatical structures, and the latter is subdivided into 6 tasks: impersonal\nverbs, subject agreement, verb agreement, nominal agreement, passive and\nconnectors. The subset for MWEs was used to test BERTimbau Large, BERTimbau\nBase and mBERT. For the grammatical structures, we used only BERTimbau Large,\nbecause it yielded the best results in the MWE task.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:49:14 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 08:53:08 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.14071","submitter":"Kailai Yang","authors":"Kailai Yang, Tianlin Zhang, Sophia Ananiadou","title":"Disentangled Variational Autoencoder for Emotion Recognition in\n  Conversations","comments":"Accepted by IEEE Transactions on Affective Computing","journal-ref":null,"doi":"10.1109/taffc.2023.3280038","report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In Emotion Recognition in Conversations (ERC), the emotions of target\nutterances are closely dependent on their context. Therefore, existing works\ntrain the model to generate the response of the target utterance, which aims to\nrecognise emotions leveraging contextual information. However, adjacent\nresponse generation ignores long-range dependencies and provides limited\naffective information in many cases. In addition, most ERC models learn a\nunified distributed representation for each utterance, which lacks\ninterpretability and robustness. To address these issues, we propose a\nVAD-disentangled Variational AutoEncoder (VAD-VAE), which first introduces a\ntarget utterance reconstruction task based on Variational Autoencoder, then\ndisentangles three affect representations Valence-Arousal-Dominance (VAD) from\nthe latent space. We also enhance the disentangled representations by\nintroducing VAD supervision signals from a sentiment lexicon and minimising the\nmutual information between VAD distributions. Experiments show that VAD-VAE\noutperforms the state-of-the-art model on two datasets. Further analysis proves\nthe effectiveness of each proposed module and the quality of disentangled VAD\nrepresentations. The code is available at\nhttps://github.com/SteveKGYang/VAD-VAE.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:50:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14072","submitter":"Samarth Bhargav","authors":"Samarth Bhargav, Anne Schuth, Claudia Hauff","title":"When the Music Stops: Tip-of-the-Tongue Retrieval for Music","comments":null,"journal-ref":null,"doi":"10.1145/3539618.3592086","report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a study of Tip-of-the-tongue (ToT) retrieval for music, where a\nsearcher is trying to find an existing music entity, but is unable to succeed\nas they cannot accurately recall important identifying information. ToT\ninformation needs are characterized by complexity, verbosity, uncertainty, and\npossible false memories. We make four contributions. (1) We collect a dataset -\n$ToT_{Music}$ - of 2,278 information needs and ground truth answers. (2) We\nintroduce a schema for these information needs and show that they often involve\nmultiple modalities encompassing several Music IR subtasks such as lyric\nsearch, audio-based search, audio fingerprinting, and text search. (3) We\nunderscore the difficulty of this task by benchmarking a standard text\nretrieval approach on this dataset. (4) We investigate the efficacy of query\nreformulations generated by a large language model (LLM), and show that they\nare not as effective as simply employing the entire information need as a query\n- leaving several open questions for future research.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:50:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14073","submitter":"Jan Nagel","authors":"Jan Nagel","title":"Cohomology of complete intersections of quadrics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that the variable cohomology of a general complete intersection of\nquadrics can be identified with the intersection cohomology of a double\ncovering. As a consequence, we show that the middle cohomology of a general\ncomplete intersection of four quadrics in an odd-dimensional projective space\nis isomorphic to the middle cohomology of a resolution of singularities of a\ndouble solid.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:51:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14074","submitter":"Ke Liang","authors":"Ke Liang, Lingyuan Meng, Sihang Zhou, Siwei Wang, Wenxuan Tu, Yue Liu,\n  Meng Liu, Xinwang Liu","title":"Message Intercommunication for Inductive Relation Reasoning","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inductive relation reasoning for knowledge graphs, aiming to infer missing\nlinks between brand-new entities, has drawn increasing attention. The models\ndeveloped based on Graph Inductive Learning, called GraIL-based models, have\nshown promising potential for this task. However, the uni-directional\nmessage-passing mechanism hinders such models from exploiting hidden mutual\nrelations between entities in directed graphs. Besides, the enclosing subgraph\nextraction in most GraIL-based models restricts the model from extracting\nenough discriminative information for reasoning. Consequently, the expressive\nability of these models is limited. To address the problems, we propose a novel\nGraIL-based inductive relation reasoning model, termed MINES, by introducing a\nMessage Intercommunication mechanism on the Neighbor-Enhanced Subgraph.\nConcretely, the message intercommunication mechanism is designed to capture the\nomitted hidden mutual information. It introduces bi-directed information\ninteractions between connected entities by inserting an undirected/bi-directed\nGCN layer between uni-directed RGCN layers. Moreover, inspired by the success\nof involving more neighbors in other graph-based tasks, we extend the\nneighborhood area beyond the enclosing subgraph to enhance the information\ncollection for inductive relation reasoning. Extensive experiments on twelve\ninductive benchmark datasets demonstrate that our MINES outperforms existing\nstate-of-the-art models, and show the effectiveness of our intercommunication\nmechanism and reasoning on the neighbor-enhanced subgraph.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:51:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14075","submitter":"Giuseppe De Laurentis","authors":"Giuseppe De Laurentis","title":"Lips: p-adic and singular phase space","comments":"6 pages, 2 tables, Proceedings of the 21th International Workshop on\n  Advanced Computing and Analysis Techniques in Physics Research (ACAT 2022)","journal-ref":null,"doi":null,"report-no":"PSI-PR-23-14","categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  I present new features of the open-source Python package lips, which\nleverages the newly developed pyadic and syngular libraries. These developments\nenable the generation and manipulation of massless phase-space configurations\nbeyond real kinematics, defined in terms of four-momenta or Weyl spinors, not\nonly over complex numbers ($\\mathbb{C}$), but now also over finite fields\n($\\mathbb{F}_p$) and p-adic numbers ($\\mathbb{Q}_p$). The package also offers\ntools to evaluate arbitrary spinor-helicity expressions in any of these fields.\nFurthermore, using the algebraic-geometry submodule, which utilizes Singular\n[1] through the Python interface syngular, one can define and manipulate ideals\nin spinor variables, enabling the identification of irreducible surfaces where\nscattering amplitudes have well-defined zeros and poles. As an example\napplication, I demonstrate how to infer valid partial-fraction decompositions\nfrom numerical evaluations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:54:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14076","submitter":"Tianle Liu","authors":"Tianle Liu, Promit Ghosal, Krishnakumar Balasubramanian, Natesh S.\n  Pillai","title":"Towards Understanding the Dynamics of Gaussian-Stein Variational\n  Gradient Descent","comments":"59 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST cs.LG math.PR stat.CO stat.ML stat.TH","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based\ndeterministic sampling algorithm. Despite its wide usage, understanding the\ntheoretical properties of SVGD has remained a challenging problem. For sampling\nfrom a Gaussian target, the SVGD dynamics with a bilinear kernel will remain\nGaussian as long as the initializer is Gaussian. Inspired by this fact, we\nundertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD\nprojected to the family of Gaussian distributions via the bilinear kernel, or\nequivalently Gaussian variational inference (GVI) with SVGD. We present a\ncomplete picture by considering both the mean-field PDE and discrete particle\nsystems. When the target is strongly log-concave, the mean-field Gaussian-SVGD\ndynamics is proven to converge linearly to the Gaussian distribution closest to\nthe target in KL divergence. In the finite-particle setting, there is both\nuniform in time convergence to the mean-field limit and linear convergence in\ntime to the equilibrium if the target is Gaussian. In the general case, we\npropose a density-based and a particle-based implementation of the\nGaussian-SVGD, and show that several recent algorithms for GVI, proposed from\ndifferent perspectives, emerge as special cases of our unified framework.\nInterestingly, one of the new particle-based instance from this framework\nempirically outperforms existing approaches. Our results make concrete\ncontributions towards obtaining a deeper understanding of both SVGD and GVI.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:55:47 GMT"},{"version":"v2","created":"Tue, 30 May 2023 04:11:33 GMT"},{"version":"v3","created":"Fri, 2 Jun 2023 14:36:32 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.14077","submitter":"Moritz Haas","authors":"Moritz Haas, David Holzm\\\"uller, Ulrike von Luxburg, Ingo Steinwart","title":"Mind the spikes: Benign overfitting of kernels and neural networks in\n  fixed dimension","comments":"We provide Python code to reproduce all of our experimental results\n  at https://github.com/moritzhaas/mind-the-spikes","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The success of over-parameterized neural networks trained to near-zero\ntraining error has caused great interest in the phenomenon of benign\noverfitting, where estimators are statistically consistent even though they\ninterpolate noisy training data. While benign overfitting in fixed dimension\nhas been established for some learning methods, current literature suggests\nthat for regression with typical kernel methods and wide neural networks,\nbenign overfitting requires a high-dimensional setting where the dimension\ngrows with the sample size. In this paper, we show that the smoothness of the\nestimators, and not the dimension, is the key: benign overfitting is possible\nif and only if the estimator's derivatives are large enough. We generalize\nexisting inconsistency results to non-interpolating models and more kernels to\nshow that benign overfitting with moderate derivatives is impossible in fixed\ndimension. Conversely, we show that benign overfitting is possible for\nregression with a sequence of spiky-smooth kernels with large derivatives.\nUsing neural tangent kernels, we translate our results to wide neural networks.\nWe prove that while infinite-width networks do not overfit benignly with the\nReLU activation, this can be fixed by adding small high-frequency fluctuations\nto the activation function. Our experiments verify that such neural networks,\nwhile overfitting, can indeed generalize well even on low-dimensional data\nsets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:56:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14078","submitter":"Zirui Zhao","authors":"Zirui Zhao, Wee Sun Lee, David Hsu","title":"Large Language Models as Commonsense Knowledge for Large-Scale Task\n  Planning","comments":"20 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Natural language provides a natural interface for human communication, yet it\nis challenging for robots to comprehend due to its abstract nature and inherent\nambiguity. Large language models (LLMs) contain commonsense knowledge that can\nhelp resolve language ambiguity and generate possible solutions to abstract\nspecifications. While LLMs have shown promise as few-shot planning policies,\ntheir potential for planning complex tasks is not fully tapped. This paper\nshows that LLMs can be used as both the commonsense model of the world and the\nheuristic policy in search algorithms such as Monte Carlo Tree Search (MCTS).\nMCTS explores likely world states sampled from LLMs to facilitate\nbetter-reasoned decision-making. The commonsense policy from LLMs guides the\nsearch to relevant parts of the tree, substantially reducing the search\ncomplexity. We demonstrate the effectiveness of our method in daily\ntask-planning experiments and highlight its advantages over using LLMs solely\nas policies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:56:31 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14079","submitter":"Daisuke Niizumi","authors":"Daisuke Niizumi, Daiki Takeuchi, Yasunori Ohishi, Noboru Harada, and\n  Kunio Kashino","title":"Masked Modeling Duo for Speech: Specializing General-Purpose Audio\n  Representation to Speech using Denoising Distillation","comments":"Interspeech 2023; 5 pages, 2 figures, 6 tables, Code:\n  https://github.com/nttcslab/m2d/tree/master/speech","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Self-supervised learning general-purpose audio representations have\ndemonstrated high performance in a variety of tasks. Although they can be\noptimized for application by fine-tuning, even higher performance can be\nexpected if they can be specialized to pre-train for an application. This paper\nexplores the challenges and solutions in specializing general-purpose audio\nrepresentations for a specific application using speech, a highly demanding\nfield, as an example. We enhance Masked Modeling Duo (M2D), a general-purpose\nmodel, to close the performance gap with state-of-the-art (SOTA) speech models.\nTo do so, we propose a new task, denoising distillation, to learn from\nfine-grained clustered features, and M2D for Speech (M2D-S), which jointly\nlearns the denoising distillation task and M2D masked prediction task.\nExperimental results show that M2D-S performs comparably to or outperforms SOTA\nspeech models on the SUPERB benchmark, demonstrating that M2D can specialize in\na demanding field. Our code is available at:\nhttps://github.com/nttcslab/m2d/tree/master/speech\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:00:39 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 21:34:23 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.14080","submitter":"Efe Bozkir","authors":"Efe Bozkir and S\\\"uleyman \\\"Ozdel and Mengdi Wang and Brendan\n  David-John and Hong Gao and Kevin Butler and Eakta Jain and Enkelejda Kasneci","title":"Eye-tracked Virtual Reality: A Comprehensive Survey on Methods and\n  Privacy Challenges","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.AI cs.CR cs.GR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Latest developments in computer hardware, sensor technologies, and artificial\nintelligence can make virtual reality (VR) and virtual spaces an important part\nof human everyday life. Eye tracking offers not only a hands-free way of\ninteraction but also the possibility of a deeper understanding of human visual\nattention and cognitive processes in VR. Despite these possibilities,\neye-tracking data also reveal privacy-sensitive attributes of users when it is\ncombined with the information about the presented stimulus. To address these\npossibilities and potential privacy issues, in this survey, we first cover\nmajor works in eye tracking, VR, and privacy areas between the years 2012 and\n2022. While eye tracking in the VR part covers the complete pipeline of\neye-tracking methodology from pupil detection and gaze estimation to offline\nuse and analyses, as for privacy and security, we focus on eye-based\nauthentication as well as computational methods to preserve the privacy of\nindividuals and their eye-tracking data in VR. Later, taking all into\nconsideration, we draw three main directions for the research community by\nmainly focusing on privacy challenges. In summary, this survey provides an\nextensive literature review of the utmost possibilities with eye tracking in VR\nand the privacy implications of those possibilities.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:02:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14081","submitter":"Viktor Hangya","authors":"Viktor Hangya, Alexander Fraser","title":"How to Solve Few-Shot Abusive Content Detection Using the Data We\n  Actually Have","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to the broad range of social media platforms and their user groups, the\nrequirements of abusive language detection systems are varied and\never-changing. Already a large set of annotated corpora with different\nproperties and label sets were created, such as hate or misogyny detection, but\nthe form and targets of abusive speech are constantly changing. Since, the\nannotation of new corpora is expensive, in this work we leverage datasets we\nalready have, covering a wide range of tasks related to abusive language\ndetection, in order to build models cheaply for a new target label set and/or\nlanguage, using only a few training examples of the target domain. We propose a\ntwo-step approach: first we train our model in a multitask fashion. We then\ncarry out few-shot adaptation to the target requirements. Our experiments show\nthat by leveraging already existing datasets and only a few-shots of the target\ntask the performance of models can be improved not only monolingually but\nacross languages as well. Our analysis also shows that our models acquire a\ngeneral understanding of abusive language, since they improve the prediction of\nlabels which are present only in the target dataset. We also analyze the\ntrade-off between specializing the already existing datasets to a given target\nsetup for best performance and its negative effects on model adaptability.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:04:12 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14082","submitter":"Zhijie Fan","authors":"Zhijie Fan, Chao Zhang and Youjin Deng","title":"Event-Based Monte Carlo Method for Long-range Interacting Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.comp-ph cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Simulating long-range interacting systems is a challenging task due to its\ncomputational complexity that the computational effort for each local update is\nof order $\\cal{O}$$(N)$, where $N$ is the size of system. Recently, a\ntechnique, called hereby the event-based method, was developed on the basis of\nthe so-called factorized Metropolis filter [Phys. Rev. E 99 010105 (2019)]. In\nthis work, we first explain step by step how the event-based method is\nimplemented to reduce the computational overhead from $\\cal{O}$$(N)$ to\n$\\cal{O}$(1). In particular, the core ingredients, including the concepts of\nbound probabilities and bound rejection events, the tree-like data structure\nand the fast algorithms for sampling an extensive set of discrete and small\nprobabilities, are elaborated. Next, we show how the event-based method can be\nflexibly implemented in various update strategies, like the Metropolis and\nworm-type algorithms, and can be generalized to simulate quantum systems.\nFinally, we demonstrate the high efficiency of the event-based Monte Carlo\n(EBMC) algorithms in the examples of the quantum Ising model and the\nBose-Hubbard model with long-range interactions and/or long-range hopping\namplitudes. We expect that the EBMC algorithms would find broad applications in\nstatistical and condensed-matter physics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:08:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14083","submitter":"Victoria Lin","authors":"Victoria Lin, Louis-Philippe Morency, Dimitrios Dimitriadis, Srinagesh\n  Sharma","title":"Counterfactual Augmentation for Multimodal Learning Under Presentation\n  Bias","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In real-world machine learning systems, labels are often derived from user\nbehaviors that the system wishes to encourage. Over time, new models must be\ntrained as new training examples and features become available. However,\nfeedback loops between users and models can bias future user behavior, inducing\na presentation bias in the labels that compromises the ability to train new\nmodels. In this paper, we propose counterfactual augmentation, a novel causal\nmethod for correcting presentation bias using generated counterfactual labels.\nOur empirical evaluations demonstrate that counterfactual augmentation yields\nbetter downstream performance compared to both uncorrected models and existing\nbias-correction methods. Model analyses further indicate that the generated\ncounterfactuals align closely with true counterfactuals in an oracle setting.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:09:47 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14084","submitter":"Ming Li","authors":"Youwang Xiao, Xinhui Li, Jing Wang, Ming Li, Shao-Ming Fei","title":"Device-independent randomness based on a tight upper bound of the\n  maximal quantum value of chained inequality","comments":"16 pages, 3 figures","journal-ref":"Physical Review A, 107, 052415(2023)","doi":"10.1103/PhysRevA.107.052415","report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The violation of Bell inequality not only provides the most radical departure\nof quantum theory from classical concepts, but also paves the way of\napplications in such as device independent randomness certification. Here, we\nderive the tight upper bound of the maximum quantum value for chained Bell\ninequality with arbitrary number of measurements on each party. \\lxh{ The\nconstraints where the upper bound saturates are also presented. This method\nprovides us the necessary and sufficient conditions for some quantum states to\nviolate the chained Bell inequality with arbitrary number of measurements}.\nBased on the tight upper bound we present the lower bounds on the device\nindependent randomness with respect to the Werner states. \\lxh{In particular,\nwe present lower bounds on the randomness generation rates of chained Bell\ninequality for different number of measurements, which are compared with the\nfamily of Bell inequalities proposed by Wooltorton et al. [Phys. Rev. Lett.\n129, 150403 (2022)]. Our results show that chained Bell inequality with three\nmeasurements has certain advantages at a low level of noise and could be used\nto improve randomness generation rates in practice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:10:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14085","submitter":"Luis Bonilla L.","authors":"R. Gonz\\'alez-Albaladejo and L. L. Bonilla","title":"Mean field theory of chaotic insect swarms","comments":"15 pages, 10 figures, including supplementary material, revtex","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech nlin.CD physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The harmonically confined Vicsek model displays qualitative and quantitative\nfeatures observed in natural insect swarms. It exhibits a scale free transition\nbetween single and multicluster chaotic phases. Finite size scaling indicates\nthat this unusual phase transition occurs at zero confinement [Physical Review\nE 107, 014209 (2023)]. While the evidence of the scale-free-chaos phase\ntransition comes from numerical simulations, here we present its mean field\ntheory. Analytically determined critical exponents are those of the Landau\ntheory of equilibrium phase transitions plus dynamical critical exponent $z=1$\nand a new critical exponent $\\varphi=0.5$ for the largest Lyapunov exponent.\nThe phase transition occurs at zero confinement and noise in the mean field\ntheory. The noise line of zero largest Lyapunov exponents informs observed\nbehavior: (i) the qualitative shape of the swarm (on average, the center of\nmass rotates slowly at the rate marked by the winding number and its trajectory\nfills compactly the space, similarly to the observed condensed nucleus\nsurrounded by vapor), and (ii) the critical exponents resemble those observed\nin natural swarms. Our predictions include power laws for the frequency of the\nmaximal spectral amplitude and the winding number.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:10:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14086","submitter":"Alireza Amirshahi","authors":"Alireza Amirshahi, Nicolas Kirsch, Jonathan Reymond and Saleh\n  Baghersalimi","title":"Predicting Survey Response with Quotation-based Modeling: A Case Study\n  on Favorability towards the United States","comments":"IEEE Swiss Conference on Data Science (SDS) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The acquisition of survey responses is a crucial component in conducting\nresearch aimed at comprehending public opinion. However, survey data collection\ncan be arduous, time-consuming, and expensive, with no assurance of an adequate\nresponse rate. In this paper, we propose a pioneering approach for predicting\nsurvey responses by examining quotations using machine learning. Our\ninvestigation focuses on evaluating the degree of favorability towards the\nUnited States, a topic of interest to many organizations and governments. We\nleverage a vast corpus of quotations from individuals across different\nnationalities and time periods to extract their level of favorability. We\nemploy a combination of natural language processing techniques and machine\nlearning algorithms to construct a predictive model for survey responses. We\ninvestigate two scenarios: first, when no surveys have been conducted in a\ncountry, and second when surveys have been conducted but in specific years and\ndo not cover all the years. Our experimental results demonstrate that our\nproposed approach can predict survey responses with high accuracy. Furthermore,\nwe provide an exhaustive analysis of the crucial features that contributed to\nthe model's performance. This study has the potential to impact survey research\nin the field of data science by substantially decreasing the cost and time\nrequired to conduct surveys while simultaneously providing accurate predictions\nof public opinion.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:11:01 GMT"},{"version":"v2","created":"Sat, 27 May 2023 23:16:51 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14087","submitter":"Xiaoyin Chen","authors":"Xiaoyin Chen and Sam Wiseman","title":"BM25 Query Augmentation Learned End-to-End","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given BM25's enduring competitiveness as an information retrieval baseline,\nwe investigate to what extent it can be even further improved by augmenting and\nre-weighting its sparse query-vector representation. We propose an approach to\nlearning an augmentation and a re-weighting end-to-end, and we find that our\napproach improves performance over BM25 while retaining its speed. We\nfurthermore find that the learned augmentations and re-weightings transfer well\nto unseen datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:11:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14088","submitter":"Enrique Adri\\'an Cabral","authors":"R. Ayala and A. Cabral","title":"Boundedness of fractional operators associated with Schr\\\"odinger\n  operators on weighted variable Lebesgue spaces via extrapolation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work we obtain boundedness results for fractional operators\nassociated with Schr\\\"odinger operators $\\ \\mathcal{L}=-\\Delta+V$ on weighted\nvariable Lebesgue spaces. These operators include fractional integrals and\ntheir respective commutators. Particularly, we obtain weighted inequalities of\nthe type $L^{p(\\cdot)}$-$L^{q(\\cdot)}$ and estimates of the type\n$L^{p(\\cdot)}$-Lipschitz variable integral spaces. For this purpose, we\ndeveloped extrapolation results that allow us to obtain boundedness results of\nthe type described above in the variable setting by starting from analogous\ninequalities in the classical context.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:12:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14089","submitter":"Megumi Harada","authors":"Megumi Harada and Tatsuya Horiguchi","title":"The cohomology rings of regular nilpotent Hessenberg varieties","comments":"58 pages. Very minor expositional differences were made, between the\n  original book chapter and this ArXiv manuscript, in order to make the ArXiv\n  version a stand-alone exposition","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This manuscript is a contributed chapter in the forthcoming CRC Press volume,\ntitled the Handbook of Combinatorial Algebraic Geometry: Subvarieties of the\nFlag Variety. The book, as a whole, is aimed at a diverse audience of\nresearchers and graduate students seeking an expository introduction to the\narea. In our chapter, we give an overview of some of the past research on the\ncohomology rings of regular nilpotent Hessenberg varieties, with no claim to\nbeing exhaustive. For the purposes of this manuscript, we focus mainly on the\ncase of Lie type A, with some brief remarks on the general Lie types. We end\nthe chapter with a selection of topics currently active in this area.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:13:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14090","submitter":"Fabian J. Wagner","authors":"Lennard G\\\"orges, Christoph Nega, Lorenzo Tancredi and Fabian J.\n  Wagner","title":"On a procedure to derive $\\epsilon$-factorised differential equations\n  beyond polylogarithms","comments":"52 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this manuscript, we elaborate on a procedure to derive\n$\\epsilon$-factorised differential equations for multi-scale, multi-loop\nclasses of Feynman integrals that evaluate to special functions beyond multiple\npolylogarithms. We demonstrate the applicability of our approach to diverse\nclasses of problems, by working out $\\epsilon$-factorised differential\nequations for single- and multi-scale problems of increasing complexity. To\nstart we are reconsidering the well-studied equal-mass two-loop sunrise case,\nand move then to study other elliptic two-, three- and four-point problems\ndepending on multiple different scales. Finally, we showcase how the same\napproach allows us to obtain $\\epsilon$-factorised differential equations also\nfor Feynman integrals that involve geometries beyond a single elliptic curve.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:14:59 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14091","submitter":"Ziyin Zhang","authors":"Hai Hu and Ziyin Zhang and Weifang Huang and Jackie Yan-Ki Lai and\n  Aini Li and Yina Ma and Jiahui Huang and Peng Zhang and Rui Wang","title":"Revisiting Acceptability Judgements","comments":"update dataset url","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Years have passed since the NLP community has last focused on linguistic\nacceptability. In this work, we revisit this topic in the context of large\nlanguage models. We introduce CoLAC - Corpus of Linguistic Acceptability in\nChinese, the first large-scale non-English acceptability dataset that is\nverified by native speakers and comes with two sets of labels. Our experiments\nshow that even the largest InstructGPT model performs only at chance level on\nCoLAC, while ChatGPT's performance (48.30 MCC) is also way below supervised\nmodels (59.03 MCC) and human (65.11 MCC). Through cross-lingual transfer\nexperiments and fine-grained linguistic analysis, we demonstrate for the first\ntime that knowledge of linguistic acceptability can be transferred across\ntypologically distinct languages, as well as be traced back to pre-training.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:16:22 GMT"},{"version":"v2","created":"Wed, 24 May 2023 11:20:46 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14092","submitter":"Alessandro Barone","authors":"Alessandro Barone, Shoji Hashimoto, Andreas J\\\"uttner, Takashi Kaneko,\n  Ryan Kellermann","title":"Approaches to inclusive semileptonic $B_{(s)}$-meson decays from Lattice\n  QCD","comments":"43 pages, 18 figures","journal-ref":null,"doi":null,"report-no":"KEK-CP-0394 CERN-TH-2023-087","categories":"hep-lat hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We address the nonperturbative calculation of the inclusive decay rate of\nsemileptonic $B_{(s)}$-meson decays from lattice QCD. Precise Standard-Model\npredictions are key ingredients in searches for new physics, and this type of\ncomputation may eventually provide new insight into the long-standing tension\nbetween the inclusive and exclusive determinations of the\nCabibbo-Kobayashi-Maskawa (CKM) matrix elements $|V_{cb}|$ and $|V_{ub}|$. We\npresent results from a pilot lattice computation for $B_s \\rightarrow X_c\\, l\n\\nu_l$, where the initial $b$ quark described by the relativistic-heavy-quark\n(RHQ) formalism on the lattice and the other valence quarks discretised with\ndomain-wall fermions are simulated approximately at their physical quark\nmasses. We compare two different methods for computing the decay rate from\nlattice data of Euclidean $n$-point functions, namely Chebyshev and\nBackus-Gilbert approaches. We further study how much the ground-state meson\ndominates the inclusive decay rate and indicate our strategy towards a\ncomputation with a more comprehensive systematic error budget.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:16:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14093","submitter":"Kunhao Liu","authors":"Kunhao Liu, Fangneng Zhan, Jiahui Zhang, Muyu Xu, Yingchen Yu,\n  Abdulmotaleb El Saddik, Christian Theobalt, Eric Xing, Shijian Lu","title":"3D Open-vocabulary Segmentation with Foundation Models","comments":"code is available at https://github.com/Kunhao-Liu/3D-OVS","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Open-vocabulary segmentation of 3D scenes is a fundamental function of human\nperception and thus a crucial objective in computer vision research. However,\nthis task is heavily impeded by the lack of large-scale and diverse 3D\nopen-vocabulary segmentation datasets for training robust and generalizable\nmodels. Distilling knowledge from pre-trained 2D open-vocabulary segmentation\nmodels helps but it compromises the open-vocabulary feature significantly as\nthe 2D models are mostly finetuned with close-vocabulary datasets. We tackle\nthe challenges in 3D open-vocabulary segmentation by exploiting the\nopen-vocabulary multimodal knowledge and object reasoning capability of\npre-trained foundation models CLIP and DINO, without necessitating any\nfine-tuning. Specifically, we distill open-vocabulary visual and textual\nknowledge from CLIP into a neural radiance field (NeRF) which effectively lifts\n2D features into view-consistent 3D segmentation. Furthermore, we introduce the\nRelevancy-Distribution Alignment loss and Feature-Distribution Alignment loss\nto respectively mitigate the ambiguities of CLIP features and distill precise\nobject boundaries from DINO features, eliminating the need for segmentation\nannotations during training. Extensive experiments show that our method even\noutperforms fully supervised models trained with segmentation annotations,\nsuggesting that 3D open-vocabulary segmentation can be effectively learned from\n2D images and text-image pairs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:16:49 GMT"},{"version":"v2","created":"Wed, 24 May 2023 09:18:26 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14094","submitter":"Marcello Bullo","authors":"Marcello Bullo, Seifallah Jardak, Pietro Carnelli, Deniz Gunduz","title":"Sustainable Edge Intelligence Through Energy-Aware Early Exiting","comments":"6 pages, submitted to IEEE MLSP 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.AI cs.SY stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep learning (DL) models have emerged as a promising solution for Internet\nof Things (IoT) applications. However, due to their computational complexity,\nDL models consume significant amounts of energy, which can rapidly drain the\nbattery and compromise the performance of IoT devices. For sustainable\noperation, we consider an edge device with a rechargeable battery and energy\nharvesting (EH) capabilities. In addition to the stochastic nature of the\nambient energy source, the harvesting rate is often insufficient to meet the\ninference energy requirements, leading to drastic performance degradation in\nenergy-agnostic devices. To mitigate this problem, we propose energy-adaptive\ndynamic early exiting (EE) to enable efficient and accurate inference in an EH\nedge intelligence system. Our approach derives an energy-aware EE policy that\ndetermines the optimal amount of computational processing on a per-sample\nbasis. The proposed policy balances the energy consumption to match the limited\nincoming energy and achieves continuous availability. Numerical results show\nthat accuracy and service rate are improved up to 25% and 35%, respectively, in\ncomparison with an energy-agnostic policy.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:17:44 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14095","submitter":"Sangwoo Mo","authors":"Sangwoo Mo, Minkyu Kim, Kyungmin Lee, Jinwoo Shin","title":"S-CLIP: Semi-supervised Vision-Language Pre-training using Few\n  Specialist Captions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vision-language models, such as contrastive language-image pre-training\n(CLIP), have demonstrated impressive results in natural image domains. However,\nthese models often struggle when applied to specialized domains like remote\nsensing, and adapting to such domains is challenging due to the limited number\nof image-text pairs available for training. To address this, we propose S-CLIP,\na semi-supervised learning method for training CLIP that utilizes additional\nunpaired images. S-CLIP employs two pseudo-labeling strategies specifically\ndesigned for contrastive learning and the language modality. The caption-level\npseudo-label is given by a combination of captions of paired images, obtained\nby solving an optimal transport problem between unpaired and paired images. The\nkeyword-level pseudo-label is given by a keyword in the caption of the nearest\npaired image, trained through partial label learning that assumes a candidate\nset of labels for supervision instead of the exact one. By combining these\nobjectives, S-CLIP significantly enhances the training of CLIP using only a few\nimage-text pairs, as demonstrated in various specialist domains, including\nremote sensing, fashion, scientific figures, and comics. For instance, S-CLIP\nimproves CLIP by 10% for zero-shot classification and 4% for image-text\nretrieval on the remote sensing benchmark, matching the performance of\nsupervised CLIP while using three times fewer image-text pairs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:18:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14096","submitter":"Matteo Russo","authors":"Georgios Birmpas, Tomer Ezra, Stefano Leonardi, Matteo Russo","title":"Fair Division with Interdependent Values","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce the study of designing allocation mechanisms for fairly\nallocating indivisible goods in settings with interdependent valuation\nfunctions. In our setting, there is a set of goods that needs to be allocated\nto a set of agents (without disposal). Each agent is given a private signal,\nand his valuation function depends on the signals of all agents. Without the\nuse of payments, there are strong impossibility results for designing\nstrategyproof allocation mechanisms even in settings without interdependent\nvalues. Therefore, we turn to design mechanisms that always admit equilibria\nthat are fair with respect to their true signals, despite their potentially\ndistorted perception. To do so, we first extend the definitions of pure Nash\nequilibrium and well-studied fairness notions in literature to the\ninterdependent setting. We devise simple allocation mechanisms that always\nadmit a fair equilibrium with respect to the true signals. We complement this\nresult by showing that, even for very simple cases with binary additive\ninterdependent valuation functions, no allocation mechanism that always admits\nan equilibrium, can guarantee that all equilibria are fair with respect to the\ntrue signals.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:19:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14097","submitter":"Guangke Chen","authors":"Guangke Chen, Yedi Zhang, Zhe Zhao, Fu Song","title":"QFA2SR: Query-Free Adversarial Transfer Attacks to Speaker Recognition\n  Systems","comments":"Accepted by the 32nd USENIX Security Symposium (2023 USENIX\n  Security); Full Version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG cs.MM cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current adversarial attacks against speaker recognition systems (SRSs)\nrequire either white-box access or heavy black-box queries to the target SRS,\nthus still falling behind practical attacks against proprietary commercial APIs\nand voice-controlled devices. To fill this gap, we propose QFA2SR, an effective\nand imperceptible query-free black-box attack, by leveraging the\ntransferability of adversarial voices. To improve transferability, we present\nthree novel methods, tailored loss functions, SRS ensemble, and time-freq\ncorrosion. The first one tailors loss functions to different attack scenarios.\nThe latter two augment surrogate SRSs in two different ways. SRS ensemble\ncombines diverse surrogate SRSs with new strategies, amenable to the unique\nscoring characteristics of SRSs. Time-freq corrosion augments surrogate SRSs by\nincorporating well-designed time-/frequency-domain modification functions,\nwhich simulate and approximate the decision boundary of the target SRS and\ndistortions introduced during over-the-air attacks. QFA2SR boosts the targeted\ntransferability by 20.9%-70.7% on four popular commercial APIs (Microsoft\nAzure, iFlytek, Jingdong, and TalentedSoft), significantly outperforming\nexisting attacks in query-free setting, with negligible effect on the\nimperceptibility. QFA2SR is also highly effective when launched over the air\nagainst three wide-spread voice assistants (Google Assistant, Apple Siri, and\nTMall Genie) with 60%, 46%, and 70% targeted transferability, respectively.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:20:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14098","submitter":"Poushali Sengupta","authors":"Poushali Sengupta, Yan Zhang, Sabita Maharjan, Frank Eliassen","title":"Balancing Explainability-Accuracy of Complex Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Explainability of AI models is an important topic that can have a significant\nimpact in all domains and applications from autonomous driving to healthcare.\nThe existing approaches to explainable AI (XAI) are mainly limited to simple\nmachine learning algorithms, and the research regarding the\nexplainability-accuracy tradeoff is still in its infancy especially when we are\nconcerned about complex machine learning techniques like neural networks and\ndeep learning (DL). In this work, we introduce a new approach for complex\nmodels based on the co-relation impact which enhances the explainability\nconsiderably while also ensuring the accuracy at a high level. We propose\napproaches for both scenarios of independent features and dependent features.\nIn addition, we study the uncertainty associated with features and output.\nFurthermore, we provide an upper bound of the computation complexity of our\nproposed approach for the dependent features. The complexity bound depends on\nthe order of logarithmic of the number of observations which provides a\nreliable result considering the higher dimension of dependent feature space\nwith a smaller number of observations.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:20:38 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14099","submitter":"Zhijun Jiang","authors":"Zhijun Jiang, Zhenlong Zhang, Sergei Prokhorenko, Yousra Nahas, Sergey\n  Prosandeev, Laurent Bellaiche","title":"Energy storage properties of ferroelectric nanocomposites","comments":"7 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An atomistic effective Hamiltonian technique is used to investigate the\nfinite-temperature energy storage properties of a ferroelectric nanocomposite\nconsisting of an array of BaTiO$_{3}$ nanowires embedded in a SrTiO$_{3}$\nmatrix, for electric field applied along the long axis of the nanowires. We\nfind that the energy density \\textit{versus} temperature curve adopts a\nnonlinear, mostly temperature-independent response when the system exhibits\nphases possessing an out-of-plane polarization and vortices while the energy\ndensity more linearly increases with temperature when the nanocomposite either\nonly possesses vortices (and thus no spontaneous polarization) or is in a\nparaelectric and paratoroidic phase for its equilibrium state. Ultrahigh energy\ndensity up to $\\simeq$140 J/cm$^{3}$ and an ideal 100% efficiency are also\npredicted in this nanocomposite. A phenomenological model, involving a coupling\nbetween polarization and toroidal moment, is further proposed to interpret\nthese energy density results.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:22:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14100","submitter":"Ren Li","authors":"Ren Li, Beno\\^it Guillard, Pascal Fua","title":"ISP: Multi-Layered Garment Draping with Implicit Sewing Patterns","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many approaches to draping individual garments on human body models are\nrealistic, fast, and yield outputs that are differentiable with respect to the\nbody shape on which they are draped. However, none of them can handle\nmulti-layered clothing, which is prevalent in everyday dress. In this paper, we\nintroduce a parametric garment representation model that can. As in models used\nby clothing designers, each garment consists of individual 2D panels. Their 2D\nshape is defined by a Signed Distance Function and 3D shape by a 2D to 3D\nmapping. The 2D parameterization enables easy detection of potential collisions\nand the 3D parameterization handles complex shapes effectively. We show that\nthis combination is faster and yields higher quality reconstructions than\npurely implicit surface representations, and makes the recovery of layered\ngarments from images possible thanks to its differentiability. Furthermore, it\nsupports rapid editing of garment shapes and texture by modifying individual 2D\npanels.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:23:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14101","submitter":"Chen Wu","authors":"Bin Hong, ZhongZhou Ren, Chen Wu and XueLing Mu","title":"Impacts of symmetry energy slope on the oscillation frequencies of\n  neutron stars with short-range correlation and admixed dark matter","comments":"18 pages, 13 figures","journal-ref":"Class. Quantum Grav. 40 (2023) 125007","doi":"10.1088/1361-6382/acd516","report-no":null,"categories":"nucl-th gr-qc","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Oscillation modes of compact stars, in general, can serve as a fingerprint in\ndetermining the equation of state (EOS) of dense matter. In this study, we\nexamine the impact of symmetry energy slope ($L$) on the oscillation\nfrequencies of neutron stars (NSs) with nucleon-nucleon short range correlation\n(SRC) and admixed dark matter (DM) for the first time within the relativistic\nmean-field theory. By adjusting the $L$, we revise the EOS and coupling\nparameters in light of the SRC and DM effects, and construct the new sets. The\nresults reveal that NSs containing SRC and DM inside are more likely to satisfy\nthe observational constraints, and we find that smaller $L$ exhibits larger\nfundamental non-radial and radial frequencies, and that the effect on Large\nSeparation (LG) is also mainly concentrated in the low-mass region. Moreover,\nwe update the linear relationship between the non-radial frequency and mean\ndensity, and we further give empirical relations between non-radial and radial\nfrequencies and tidal deformability at different $L$ for 1.4$M_{\\odot}$ and\n2$M_{\\odot}$. These findings will enable us to more effectively confine the NS\nEOSs, in turn, also provide a strategy to place constraints on the $L$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:24:09 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14102","submitter":"Harry J Davies","authors":"Harry J. Davies, Ghena Hammour, Marek Zylinski, Amir Nassibi, Danilo\n  P. Mandic","title":"A Deep Matched Filter For R-Peak Detection in Ear-ECG","comments":"7 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The Ear-ECG provides a continuous Lead I electrocardiogram (ECG) by measuring\nthe potential difference related to heart activity using electrodes that can be\nembedded within earphones. The significant increase in wearability and comfort\nafforded by Ear-ECG is often accompanied by a corresponding degradation in\nsignal quality - a common obstacle that is shared by most wearable\ntechnologies. We aim to resolve this issue by introducing a Deep Matched Filter\n(Deep-MF) for the highly accurate detection of R-peaks in wearable ECG, thus\nenhancing the utility of Ear-ECG in real-world scenarios. The Deep-MF consists\nof an encoder stage (trained as part of an encoder-decoder module to reproduce\nground truth ECG), and an R-peak classifier stage. Through its operation as a\nMatched Filter, the encoder searches for matches with an ECG template pattern\nin the input signal, prior to filtering the matches with the subsequent\nconvolutional layers and selecting peaks corresponding to true ECG matches. The\nso condensed latent representation of R-peak information is then fed into a\nsimple R-peak classifier, of which the output provides precise R-peak\nlocations. The proposed Deep Matched Filter is evaluated using\nleave-one-subject-out cross validation over 36 subjects with an age range of\n18-75, with the Deep-MF outperforming existing algorithms for R-peak detection\nin noisy ECG. The Deep-MF achieves a median R-peak recall of 94.9\\%, a median\nprecision of 91.2\\% and an (AUC) value of 0.97. Furthermore, we demonstrate\nthat the Deep Matched Filter algorithm not only retains the initialised ECG\nkernel structure during the training process, but also amplifies portions of\nthe ECG which it deems most valuable. Overall, the Deep Matched Filter serves\nas a valuable step forward for the real-world functionality of Ear-ECG and,\nthrough its explainable operation, the acceptance of deep learning models in\ne-health.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:24:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14103","submitter":"Guangping Zhang","authors":"Guangping Zhang, Dongsheng Li, Hansu Gu, Tun Lu, Li Shang, Ning Gu","title":"Simulating News Recommendation Ecosystem for Fun and Profit","comments":"This work has been submitted to the IEEE for possible publication.\n  Post-publication copyright may be transferred with notice, after which this\n  version may no longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.HC cs.IR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Understanding the evolution of online news communities is essential for\ndesigning more effective news recommender systems. However, due to the lack of\nappropriate datasets and platforms, the existing literature is limited in\nunderstanding the impact of recommender systems on this evolutionary process\nand the underlying mechanisms, resulting in sub-optimal system designs that may\naffect long-term utilities. In this work, we propose SimuLine, a simulation\nplatform to dissect the evolution of news recommendation ecosystems and present\na detailed analysis of the evolutionary process and underlying mechanisms.\nSimuLine first constructs a latent space well reflecting the human behaviors,\nand then simulates the news recommendation ecosystem via agent-based modeling.\nBased on extensive simulation experiments and the comprehensive analysis\nframework consisting of quantitative metrics, visualization, and textual\nexplanations, we analyze the characteristics of each evolutionary phase from\nthe perspective of life-cycle theory, and propose a relationship graph\nillustrating the key factors and affecting mechanisms. Furthermore, we explore\nthe impacts of recommender system designing strategies, including the\nutilization of cold-start news, breaking news, and promotion, on the\nevolutionary process, which shed new light on the design of recommender\nsystems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:25:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14104","submitter":"Linyi Yang","authors":"Linyi Yang, Yaoxiao Song, Xuan Ren, Chenyang Lyu, Yidong Wang,\n  Lingqiao Liu, Jindong Wang, Jennifer Foster, Yue Zhang","title":"Out-of-Distribution Generalization in Text Classification: Past,\n  Present, and Future","comments":"25 pages, OOD Generalization, Survey","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Machine learning (ML) systems in natural language processing (NLP) face\nsignificant challenges in generalizing to out-of-distribution (OOD) data, where\nthe test distribution differs from the training data distribution. This poses\nimportant questions about the robustness of NLP models and their high accuracy,\nwhich may be artificially inflated due to their underlying sensitivity to\nsystematic biases. Despite these challenges, there is a lack of comprehensive\nsurveys on the generalization challenge from an OOD perspective in text\nclassification. Therefore, this paper aims to fill this gap by presenting the\nfirst comprehensive review of recent progress, methods, and evaluations on this\ntopic. We furth discuss the challenges involved and potential future research\ndirections. By providing quick access to existing work, we hope this survey\nwill encourage future research in this area.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:26:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14105","submitter":"Aswanth Kumar M","authors":"Aswanth Kumar and Anoop Kunchukuttan and Ratish Puduppully and Raj\n  Dabre","title":"In-context Example Selection for Machine Translation Using Multiple\n  Features","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Large language models have demonstrated the capability to perform well on\nmany NLP tasks when the input is prompted with a few examples (in-context\nlearning) including machine translation, which is the focus of this work. The\nquality of translation depends on various features of the selected examples,\nsuch as their quality and relevance. However, previous work has predominantly\nfocused on individual features for example selection. We propose a general\nframework for combining different features influencing example selection. We\nlearn a regression function that selects examples based on multiple features in\norder to maximize the translation quality. On multiple language pairs and\nlanguage models, we show that our example selection method significantly\noutperforms random selection as well as strong single-factor baselines reported\nin the literature. Using our example selection method, we see an improvement of\nover 2.5 COMET points on average with respect to a strong BM25 retrieval-based\nbaseline.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:26:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14106","submitter":"Xingchen Wan","authors":"Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan O. Arik, Tomas Pfister","title":"Better Zero-Shot Reasoning with Self-Adaptive Prompting","comments":"Findings of the Association for Computational Linguistics: ACL 2023.\n  10 pages, 2 tables, 4 figures (20 pages, 8 tables, 7 figures including\n  references and appendices)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modern large language models (LLMs) have demonstrated impressive capabilities\nat sophisticated tasks, often through step-by-step reasoning similar to humans.\nThis is made possible by their strong few and zero-shot abilities -- they can\neffectively learn from a handful of handcrafted, completed responses\n(\"in-context examples\"), or are prompted to reason spontaneously through\nspecially designed triggers. Nonetheless, some limitations have been observed.\nFirst, performance in the few-shot setting is sensitive to the choice of\nexamples, whose design requires significant human effort. Moreover, given the\ndiverse downstream tasks of LLMs, it may be difficult or laborious to handcraft\nper-task labels. Second, while the zero-shot setting does not require\nhandcrafting, its performance is limited due to the lack of guidance to the\nLLMs. To address these limitations, we propose Consistency-based Self-adaptive\nPrompting (COSP), a novel prompt design method for LLMs. Requiring neither\nhandcrafted responses nor ground-truth labels, COSP selects and builds the set\nof examples from the LLM zero-shot outputs via carefully designed criteria that\ncombine consistency, diversity and repetition. In the zero-shot setting for\nthree different LLMs, we show that using only LLM predictions, COSP improves\nperformance up to 15% compared to zero-shot baselines and matches or exceeds\nfew-shot baselines for a range of reasoning tasks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:27:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14107","submitter":"Nan Pu","authors":"Nan Pu and Zhun Zhong and Xinyuan Ji and Nicu Sebe","title":"Federated Generalized Category Discovery","comments":"17 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generalized category discovery (GCD) aims at grouping unlabeled samples from\nknown and unknown classes, given labeled data of known classes. To meet the\nrecent decentralization trend in the community, we introduce a practical yet\nchallenging task, namely Federated GCD (Fed-GCD), where the training data are\ndistributively stored in local clients and cannot be shared among clients. The\ngoal of Fed-GCD is to train a generic GCD model by client collaboration under\nthe privacy-protected constraint. The Fed-GCD leads to two challenges: 1)\nrepresentation degradation caused by training each client model with fewer data\nthan centralized GCD learning, and 2) highly heterogeneous label spaces across\ndifferent clients. To this end, we propose a novel Associated Gaussian\nContrastive Learning (AGCL) framework based on learnable GMMs, which consists\nof a Client Semantics Association (CSA) and a global-local GMM Contrastive\nLearning (GCL). On the server, CSA aggregates the heterogeneous categories of\nlocal-client GMMs to generate a global GMM containing more comprehensive\ncategory knowledge. On each client, GCL builds class-level contrastive learning\nwith both local and global GMMs. The local GCL learns robust representation\nwith limited local data. The global GCL encourages the model to produce more\ndiscriminative representation with the comprehensive category relationships\nthat may not exist in local data. We build a benchmark based on six visual\ndatasets to facilitate the study of Fed-GCD. Extensive experiments show that\nour AGCL outperforms the FedAvg-based baseline on all datasets.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:27:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14108","submitter":"Dimitrie Culcer","authors":"Hong Liu, James H. Cullen, and Dimitrie Culcer","title":"Topological nature of the proper spin current and the spin-Hall torque","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spin currents are key to spin torque devices, but determining the proper spin\ncurrent is non-trivial. Here we derive a general quantum-mechanical formula for\nthe intrinsic proper spin current showing that it is topological and can be\nfinite in the gap. For topological insulators with an out of plane\nmagnetization and the chemical potential in the surface state gap, the net spin\ntorque is determined by the competition between the topological spin-Hall\ntorque due to the bulk and the topological Edelstein effect due to the surface\nstates. We also discuss spin-3/2 hole quantum wells.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:30:36 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 00:40:02 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.14109","submitter":"Mark Deutel","authors":"Mark Deutel, Georgios Kontes, Christopher Mutschler, J\\\"urgen Teich","title":"Augmented Random Search for Multi-Objective Bayesian Optimization of\n  Neural Networks","comments":"14 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deploying Deep Neural Networks (DNNs) on tiny devices is a common trend to\nprocess the increasing amount of sensor data being generated. Multi-objective\noptimization approaches can be used to compress DNNs by applying network\npruning and weight quantization to minimize the memory footprint (RAM), the\nnumber of parameters (ROM) and the number of floating point operations (FLOPs)\nwhile maintaining the predictive accuracy. In this paper, we show that existing\nmulti-objective Bayesian optimization (MOBOpt) approaches can fall short in\nfinding optimal candidates on the Pareto front and propose a novel solver based\non an ensemble of competing parametric policies trained using an Augmented\nRandom Search Reinforcement Learning (RL) agent. Our methodology aims at\nfinding feasible tradeoffs between a DNN's predictive accuracy, memory\nconsumption on a given target system, and computational complexity. Our\nexperiments show that we outperform existing MOBOpt approaches consistently on\ndifferent data sets and architectures such as ResNet-18 and MobileNetV3.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:31:52 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14110","submitter":"Huangjun Zhu","authors":"Huangjun Zhu","title":"Information Theoretic Significance of Projective Measurements","comments":"8+5 pages and 2 figures; comments and suggestions are very welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Projective measurements in quantum theory have a very simple algebraic\ndefinition, but their information theoretic significance is quite elusive. Here\nwe introduce a simple order relation based on the concentration of Fisher\ninformation, which complements the familiar data-processing order. Under this\norder relation, the information theoretic significance of projective\nmeasurements stands out immediately. Notably, projective measurements are\nexactly those quantum measurements whose extracted Fisher information is as\nconcentrated as possible, which we call Fisher-sharp measurements. We also\nintroduce the concept of sharpness index and show that it is completely\ndetermined by the finest projective measurement among the coarse graining of a\ngiven measurement.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:33:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14111","submitter":"Antonio M. Moro","authors":"Jin Lei and Antonio M. Moro","title":"Advancing the IAV Model with CDCC Wave Functions for Realistic\n  Descriptions of Two-Body Projectile Breakup","comments":"16 pages, 7 figures, submitted for publication","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inclusive breakup is an important reaction mechanism of reactions induced by\nweakly bound nuclei. The Ichimura, Austern, and Vincent (IAV) model is widely\nused to analyze inclusive breakup processes and is based on a Distorted Wave\nBorn Approximation (DWBA). However, the validity of the DWBA form for inclusive\nbreakup requires further exploration. In this study, we present a derivation of\nthe IAV model, using the continuum-discretized coupled-channels (CDCC) wave\nfunction, and apply it to the $d+^{93}$Nb reaction. We examine the differences\nbetween the CDCC-IAV and DWBA-IAV models by artificially modifying the binding\nenergy of the deuteron using two distinct types of optical potential. Our\nfindings indicate that the CDCC method potentially provides a more fundamental\ndescription of the $d$+$A$ interaction and may provide a more realistic\ndescription of the interior part of the wave function. This study offers\nsignificant potential in increasing the precision and dependability of weakly\nbound nuclei inclusive breakup process estimation within a fully quantum\nmechanical model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:35:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14112","submitter":"Michal Macek","authors":"Michal Macek, Georgy Zinchenko, Vera Musilova, Pavel Urban, Joerg\n  Schumacher","title":"Assessing non-Oberbeck-Boussinesq effects of convection in cryogenic\n  helium","comments":"10 figures, 16 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The present study investigates the non-Oberbeck-Boussinesq (NOB) effects\nwhich arise due to the temperature dependence of material properties in\ncryogenic helium experiments of turbulent Rayleigh-B\\'enard convection. They\nare manifest as a difference of the measured mean temperature at the center of\nthe closed cell, $T_c$, from the arithmetic mean temperature obtained from the\nprescribed fixed and uniform temperatures at the top and bottom copper plates\nof the apparatus, $T_m = (T_{bot} +T_{top})=2$. Therefore, the material\nproperties such as specific heat at constant pressure, dynamic viscosity,\nthermal conductivity, the isobaric expansivity, and the mass density are\nexpanded into power series with respect to temperature up to the quadratic\norder with coeffcients obtained from the software package HEPAK. A subsequent\nnonlinear regression that uses deep convolutional networks delivers a\ndependence of the strength of non-Oberbeck-Boussinesq effects in the\npressure-temperature parameter plane. Strength of the NOB effects is evaluated\nvia the deviation of the mean temperature profile $\\xi_{NOB} = T_m - T_c$ from\nthe top/bottom-symmetric Oberbeck-Boussinesq case $\\xi_{NOB} = 0$. Training\ndata for the regression task are obtained from 236 individual long-term\nlaboratory measurements at different Rayleigh numbers which span 8 orders of\nmagnitude.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:37:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14113","submitter":"Alaa Maalouf","authors":"Alaa Maalouf and Murad Tukan and Noel Loo and Ramin Hasani and Mathias\n  Lechner and Daniela Rus","title":"On the Size and Approximation Error of Distilled Sets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dataset Distillation is the task of synthesizing small datasets from large\nones while still retaining comparable predictive accuracy to the original\nuncompressed dataset. Despite significant empirical progress in recent years,\nthere is little understanding of the theoretical limitations/guarantees of\ndataset distillation, specifically, what excess risk is achieved by\ndistillation compared to the original dataset, and how large are distilled\ndatasets? In this work, we take a theoretical view on kernel ridge regression\n(KRR) based methods of dataset distillation such as Kernel Inducing Points. By\ntransforming ridge regression in random Fourier features (RFF) space, we\nprovide the first proof of the existence of small (size) distilled datasets and\ntheir corresponding excess risk for shift-invariant kernels. We prove that a\nsmall set of instances exists in the original input space such that its\nsolution in the RFF space coincides with the solution of the original data. We\nfurther show that a KRR solution can be generated using this distilled set of\ninstances which gives an approximation towards the KRR solution optimized on\nthe full input data. The size of this set is linear in the dimension of the RFF\nspace of the input set or alternatively near linear in the number of effective\ndegrees of freedom, which is a function of the kernel, number of datapoints,\nand the regularization parameter $\\lambda$. The error bound of this distilled\nset is also a function of $\\lambda$. We verify our bounds analytically and\nempirically.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:37:43 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14114","submitter":"Sebastiano Battisti","authors":"Sebastiano Battisti, Giorgio De Simoni, Luca Chirolli, Alessandro\n  Braggio, and Francesco Giazotto","title":"Bipolar thermoelectric superconducting single-electron transistor","comments":"4 pages, 4 figures, supplementary material","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Thermoelectric effects in normal metals and superconductors are usually very\nsmall due to the presence of electron-hole symmetry. Here, we show that\nsuperconducting junctions brought out of equilibrium manifest a sizable bipolar\nthermoelectric effect that stems from a strong violation of the detailed\nbalance. To fully control the effect, we consider a thermally biased SIS'IS\njunction where the capacitance of the central S' region is small enough to\nestablish a Coulomb blockade regime. By exploiting charging effects we are able\nto tune the Seebeck voltage, the thermocurrent, and thereby the power output of\nthis structure, via an external gate. We then analyse the main figures of merit\nof bipolar thermoelectricity and we prospect for possible applications.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:38:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14115","submitter":"Eloy Anguiano Batanero","authors":"Eloy Anguiano Batanero, \\'Angela Fern\\'andez Pascual, \\'Alvaro Barbero\n  Jim\\'enez","title":"RLBoost: Boosting Supervised Models using Deep Reinforcement Learning","comments":"25 pages, 14 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Data quality or data evaluation is sometimes a task as important as\ncollecting a large volume of data when it comes to generating accurate\nartificial intelligence models. In fact, being able to evaluate the data can\nlead to a larger database that is better suited to a particular problem because\nwe have the ability to filter out data obtained automatically of dubious\nquality. In this paper we present RLBoost, an algorithm that uses deep\nreinforcement learning strategies to evaluate a particular dataset and obtain a\nmodel capable of estimating the quality of any new data in order to improve the\nfinal predictive quality of a supervised learning model. This solution has the\nadvantage that of being agnostic regarding the supervised model used and,\nthrough multi-attention strategies, takes into account the data in its context\nand not only individually. The results of the article show that this model\nobtains better and more stable results than other state-of-the-art algorithms\nsuch as LOO, DataShapley or DVRL.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:38:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14116","submitter":"Sabine Wollmann","authors":"Sophie Engineer, Ana C. S. Costa, Alexandre C. Orthey Jr., Xiaogang\n  Qiang, Jianwei Wang, Jeremy L. O'Brien, Jonathan C.F. Matthews, Will\n  McCutcheon, Roope Uola, and Sabine Wollmann","title":"Semi-device independent nonlocality certification for near-term quantum\n  networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Verifying entanglement between parties is essential for creating a secure\nquantum network, and Bell tests are the most rigorous method for doing so.\nHowever, if there is any signaling between the parties, then the violation of\nthese inequalities can no longer be used to draw conclusions about the presence\nof entanglement. This is because signaling between the parties allows them to\ncoordinate their measurement settings and outcomes, which can give rise to a\nviolation of Bell inequalities even if the parties are not genuinely entangled.\nThere is a pressing need to examine the role of signaling in quantum\ncommunication protocols from multiple perspectives, including communication\nsecurity, physics foundations, and resource utilization while also promoting\ninnovative technological applications. Here, we propose a semi-device\nindependent protocol that allows us to numerically correct for effects of\ncorrelations in experimental probability distributions, caused by statistical\nfluctuations and experimental imperfections. Our noise robust protocol presents\na relaxation of a tomography-based optimisation method called the steering\nrobustness, that uses semidefinite programming to numerically identify the\noptimal quantum steering inequality without the need for resource-intensive\ntomography. The proposed protocol is numerically and experimentally analyzed in\nthe context of random, misaligned measurements, correcting for signalling where\nnecessary, resulting in a higher probability of violation compared to existing\nstate-of-the-art inequalities. Our work demonstrates the power of semidefinite\nprogramming for entanglement verification and brings quantum networks closer to\npractical applications.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:39:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14117","submitter":"Anfeng Xu","authors":"Anfeng Xu, Rajat Hebbar, Rimita Lahiri, Tiantian Feng, Lindsay Butler,\n  Lue Shen, Helen Tager-Flusberg, Shrikanth Narayanan","title":"Understanding Spoken Language Development of Children with ASD Using\n  Pre-trained Speech Embeddings","comments":"Accepted to Interspeech 2023, 5 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech processing techniques are useful for analyzing speech and language\ndevelopment in children with Autism Spectrum Disorder (ASD), who are often\nvaried and delayed in acquiring these skills. Early identification and\nintervention are crucial, but traditional assessment methodologies such as\ncaregiver reports are not adequate for the requisite behavioral phenotyping.\nNatural Language Sample (NLS) analysis has gained attention as a promising\ncomplement. Researchers have developed benchmarks for spoken language\ncapabilities in children with ASD, obtainable through the analysis of NLS. This\npaper proposes applications of speech processing technologies in support of\nautomated assessment of children's spoken language development by\nclassification between child and adult speech and between speech and nonverbal\nvocalization in NLS, with respective F1 macro scores of 82.6% and 67.8%,\nunderscoring the potential for accurate and scalable tools for ASD research and\nclinical use.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:39:49 GMT"},{"version":"v2","created":"Wed, 31 May 2023 22:32:33 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.14118","submitter":"Jose R. Zubizarreta","authors":"Ambarish Chattopadhyay, Jose R. Zubizarreta","title":"Notes on Causation, Comparison, and Regression","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Comparison and contrast are the basic means to unveil causation and learn\nwhich treatments work. To build good comparisons that isolate the average\neffect of treatment from confounding factors, randomization is key, yet often\ninfeasible. In such non-experimental settings, we illustrate and discuss how\nwell the common linear regression approach to causal inference approximates\nfeatures of randomized experiments, such as covariate balance, study\nrepresentativeness, sample-grounded estimation, and unweighted analyses. We\nalso discuss alternative regression modeling, weighting, and matching\napproaches. We argue they should be given strong consideration in empirical\nwork.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:42:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14119","submitter":"Kasai Hiroto","authors":"Hiroto Kasai, Yuki Takeuchi, Yuichiro Matsuzaki, Yasuhiro Tokura","title":"Anonymous estimation of intensity distribution of magnetic fields with\n  quantum sensing network","comments":"16 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A quantum sensing network is used to simultaneously detect and measure\nphysical quantities, such as magnetic fields, at different locations. However,\nthere is a risk that the measurement data is leaked to the third party during\nthe communication. Many theoretical and experimental efforts have been made to\nrealize a secure quantum sensing network where a high level of security is\nguaranteed. In this paper, we propose a protocol to estimate statistical\nquantities of the target fields at different places without knowing individual\nvalue of the target fields. We generate an enanglement between $L$ quantum\nsensors, let the quantum sensor interact with local fields, and perform\nspecific measurements on them. By calculating the quantum Fisher information to\nestimate the individual value of the magnetic fields, we show that we cannot\nobtain any information of the value of the individual fields in the limit of\nlarge $L$. On the other hand, in our protocol, we can estimate theoretically\nany moment of the field distribution by measuring a specific observable and\nevaluated relative uncertainty of $k$-th ($k=1,2,3,4$) order moment. Our\nresults are a significant step towards using a quantum sensing network with\nsecurity inbuilt.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:43:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14120","submitter":"Julien Martinelli","authors":"Julien Martinelli, Ayush Bharti, S.T. John, Armi Tiihonen, Sabina\n  Sloman, Louis Filstroff and Samuel Kaski","title":"Cost-aware learning of relevant contextual variables within Bayesian\n  optimization","comments":"Preprint. Under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing\nblack-box, expensive-to-evaluate functions with respect to design variables,\nwhile simultaneously efficiently integrating relevant contextual information\nregarding the environment, such as experimental conditions. However, in many\npractical scenarios, the relevance of contextual variables is not necessarily\nknown beforehand. Moreover, the contextual variables can sometimes be optimized\nthemselves, a setting that current CBO algorithms do not take into account.\nOptimizing contextual variables may be costly, which raises the question of\ndetermining a minimal relevant subset. In this paper, we frame this problem as\na cost-aware model selection BO task and address it using a novel method,\nSensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of\ncontext variables by sensitivity analysis of the posterior surrogate model at\nspecific input points, whilst minimizing the cost of optimization by leveraging\nrecent developments on early stopping for BO. We empirically evaluate our\nproposed SADCBO against alternatives on synthetic experiments together with\nextensive ablation studies, and demonstrate a consistent improvement across\nexamples.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:45:03 GMT"},{"version":"v2","created":"Wed, 24 May 2023 17:30:15 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14121","submitter":"Sora Shiratani","authors":"Sora Shiratani and Synge Todo","title":"Stochastic approximation analysis of dynamical quantum critical\n  phenomena in long-range transverse-field Ising chain","comments":"12 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech physics.comp-ph quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The quantum phase transition of the long-range transverse-field Ising model\nis explored by combining a quantum Monte Carlo method with the optimal\ncomputational complexity scaling and stochastic parameter optimization that\nrenders space and imaginary time isotropic, specifically achieved by tuning\ncorrelation lengths. Varying the decay rate of the long-range interaction, we\nexhaustively calculate the dynamical critical exponent and the other exponents\nprecisely in mean-field, nonuniversal, and Ising universality regimes. In our\nsimulations, critical properties are extracted only from a set of simulations\nwith different $L$, significantly improving computational cost compared to the\nstandard finite-size scaling approach based on data collapse. We also perform a\nhypothesis test at the predicted universality boundary, which supports\npreceding reports arguing that conventional theoretical prediction fails to\nlocate the universality boundary.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:46:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14122","submitter":"Daiki Chijiwa","authors":"Daiki Chijiwa","title":"Transferring Learning Trajectories of Neural Networks","comments":"15 pages; comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training deep neural networks (DNNs) is computationally expensive, which is\nproblematic especially when performing duplicated training runs, such as model\nensemble or knowledge distillation. Once we have trained one DNN on some\ndataset, we have its learning trajectory (i.e., a sequence of intermediate\nparameters during training) which may potentially contain useful information\nfor learning the dataset. However, there has been no attempt to utilize such\ninformation of a given learning trajectory for another training. In this paper,\nwe formulate the problem of \"transferring\" a given learning trajectory from one\ninitial parameter to another one, called learning transfer problem, and derive\nthe first algorithm to approximately solve it by matching gradients\nsuccessively along the trajectory via permutation symmetry. We empirically show\nthat the transferred parameters achieve non-trivial accuracy before any direct\ntraining. Also, we analyze the loss landscape property of the transferred\nparameters, especially from a viewpoint of mode connectivity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:46:32 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14123","submitter":"Jianwei Miao","authors":"Saman Moniri, Yao Yang, Yakun Yuan, Jihan Zhou, Long Yang, Fan Zhu,\n  Yuxuan Liao, Yonggang Yao, Liangbing Hu, Peter Ercius, Jun Ding and Jianwei\n  Miao","title":"Three-dimensional atomic positions and local chemical order of medium-\n  and high-entropy alloys","comments":"35 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Medium- and high-entropy alloys (M/HEAs) mix multiple principal elements with\nnear-equiatomic composition and represent a paradigm-shift strategy for\ndesigning new materials for metallurgy, catalysis, and other fields. One of the\ncore hypotheses of M/HEAs is lattice distortion. However, experimentally\ndetermining the 3D local lattice distortion in M/HEAs remains a challenge.\nAdditionally, the presumed random elemental mixing in M/HEAs has been\nquestioned by atomistic simulations, energy dispersive x-ray spectroscopy\n(EDS), and electron diffraction, which suggest the existence of local chemical\norder in M/HEAs. However, the 3D local chemical order has eluded direct\nexperimental observation since the EDS elemental maps integrate the composition\nof atomic columns along the zone axes, and the diffuse reflections/streaks in\nelectron diffraction of M/HEAs may originate from planar defects. Here, we\ndetermine the 3D atomic positions of M/HEA nanocrystals using atomic electron\ntomography, and quantitatively characterize the local lattice distortion,\nstrain tensor, twin boundaries, dislocation cores, and chemical short-range\norder (CSRO) with unprecedented 3D detail. We find that the local lattice\ndistortion and strain tensor in the HEAs are larger and more heterogeneous than\nin the MEAs. We observe CSRO-mediated twinning in the MEAs. that is, twinning\noccurs in energetically unfavoured CSRO regions but not in energetically\nfavoured CSRO ones. This observation confirms the atomistic simulation results\nof the bulk CrCoNi MEA and represents the first experimental evidence of\ncorrelating local chemical order with structural defects in any material\nsystem. We expect that this work will not only expand our fundamental\nunderstanding of this important class of materials, but also could provide the\nfoundation for tailoring M/HEA properties through lattice distortion and local\nchemical order.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:46:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14124","submitter":"Christos Baziotis","authors":"Christos Baziotis, Biao Zhang, Alexandra Birch, Barry Haddow","title":"When Does Monolingual Data Help Multilingual Translation: The Role of\n  Domain and Model Scale","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multilingual machine translation (MMT), trained on a mixture of parallel and\nmonolingual data, is key for improving translation in low-resource language\npairs. However, the literature offers conflicting results on the performance of\ndifferent methods. To resolve this, we examine how denoising autoencoding (DAE)\nand backtranslation (BT) impact MMT under different data conditions and model\nscales. Unlike prior studies, we use a realistic dataset of 100 directions and\nconsider many domain combinations of monolingual and test data. We find that\nmonolingual data generally helps MMT, but models are surprisingly brittle to\ndomain mismatches, especially at smaller model scales. BT is beneficial when\nthe parallel, monolingual, and test data sources are similar but can be\ndetrimental otherwise, while DAE is less effective than previously reported.\nNext, we analyze the impact of scale (from 90M to 1.6B parameters) and find it\nis important for both methods, particularly DAE. As scale increases, DAE\ntransitions from underperforming the parallel-only baseline at 90M to\nconverging with BT performance at 1.6B, and even surpassing it in low-resource.\nThese results offer new insights into how to best use monolingual data in MMT.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:48:42 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14125","submitter":"Federico Echenique","authors":"Federico Echenique and Gerelt Tserenjigmid","title":"Revealed preferences for dynamically inconsistent models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the testable implications of models of dynamically inconsistent\nchoices when planned choices are unobservable, and thus only \"on path\" data is\navailable. First, we discuss the approach in Blow, Browning and Crawford\n(2021), who characterize first-order rationalizability of the model of\nquasi-hyperbolic discounting. We show that the first-order approach does not\nguarantee rationalizability by means of the quasi-hyperbolic model. This\nmotivates consideration of an abstract model of intertemporal choice, under\nwhich we provide a characterization of different behavioral models -- including\nthe naive and sophisticated paradigms of dynamically inconsistent choice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:52:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14126","submitter":"Rui Li","authors":"Rui Li, Xu Chen, Chaozhuo Li, Yanming Shen, Jianan Zhao, Yujing Wang,\n  Weihao Han, Hao Sun, Weiwei Deng, Qi Zhang, Xing Xie","title":"To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge\n  Graph Completion","comments":"Accepted to ACL 2023 Main Conference (Long Paper)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Embedding models have shown great power in knowledge graph completion (KGC)\ntask. By learning structural constraints for each training triple, these\nmethods implicitly memorize intrinsic relation rules to infer missing links.\nHowever, this paper points out that the multi-hop relation rules are hard to be\nreliably memorized due to the inherent deficiencies of such implicit\nmemorization strategy, making embedding models underperform in predicting links\nbetween distant entity pairs. To alleviate this problem, we present Vertical\nLearning Paradigm (VLP), which extends embedding models by allowing to\nexplicitly copy target information from related factual triples for more\naccurate prediction. Rather than solely relying on the implicit memory, VLP\ndirectly provides additional cues to improve the generalization ability of\nembedding models, especially making the distant link prediction significantly\neasier. Moreover, we also propose a novel relative distance based negative\nsampling technique (ReD) for more effective optimization. Experiments\ndemonstrate the validity and generality of our proposals on two standard\nbenchmarks. Our code is available at https://github.com/rui9812/VLP.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:53:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14127","submitter":"Mark Kamsma","authors":"Mark Kamsma","title":"Positive indiscernibles","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We generalise various theorems for finding indiscernible trees and arrays to\npositive logic: based on an existing modelling theorem for s-trees, we prove\nmodelling theorems for str-trees, str$_0$-trees (the reduct of str-trees that\nforgets the length comparison relation) and arrays. In doing so we prove\nstronger versions for basing -- rather than locally basing or EM-basing --\nstr-trees on s-trees and str$_0$-trees on str-trees. As an application we show\nthat a thick positive theory has $k$-TP$_2$ iff it has $2$-TP$_2$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:54:55 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14128","submitter":"Man Luo","authors":"Man Luo, Xin Xu, Zhuyun Dai, Panupong Pasupat, Mehran Kazemi, Chitta\n  Baral, Vaiva Imbrasaite, Vincent Y Zhao","title":"Dr.ICL: Demonstration-Retrieved In-context Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In-context learning (ICL), teaching a large language model (LLM) to perform a\ntask with few-shot demonstrations rather than adjusting the model parameters,\nhas emerged as a strong paradigm for using LLMs. While early studies primarily\nused a fixed or random set of demonstrations for all test queries, recent\nresearch suggests that retrieving semantically similar demonstrations to the\ninput from a pool of available demonstrations results in better performance.\nThis work expands the applicability of retrieval-based ICL approaches by\ndemonstrating that even simple word-overlap similarity measures such as BM25\noutperform randomly selected demonstrations. Furthermore, we extend the success\nof retrieval-based ICL to instruction-finetuned LLMs as well as\nChain-of-Thought (CoT) prompting. For instruction-finetuned LLMs, we find that\nalthough a model has already seen the training data at training time,\nretrieving demonstrations from the training data at test time yields better\nresults compared to using no demonstrations or random demonstrations. Last but\nnot least, we train a task-specific demonstration retriever that outperforms\noff-the-shelf retrievers.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:55:25 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14129","submitter":"Ashish Tiwari","authors":"Priyanshu Gupta, Avishree Khare, Yasharth Bajpai, Saikat Chakraborty,\n  Sumit Gulwani, Aditya Kanade, Arjun Radhakrishna, Gustavo Soares, Ashish\n  Tiwari","title":"GrACE: Generation using Associated Code Edits","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Developers expend a significant amount of time in editing code for a variety\nof reasons such as bug fixing or adding new features. Designing effective\nmethods to predict code edits has been an active yet challenging area of\nresearch due to the diversity of code edits and the difficulty of capturing the\ndeveloper intent. In this work, we address these challenges by endowing\npre-trained large language models (LLMs) of code with the knowledge of prior,\nrelevant edits. The generative capability of the LLMs helps address the\ndiversity in code changes and conditioning code generation on prior edits helps\ncapture the latent developer intent. We evaluate two well-known LLMs, Codex and\nCodeT5, in zero-shot and fine-tuning settings respectively. In our experiments\nwith two datasets, the knowledge of prior edits boosts the performance of the\nLLMs significantly and enables them to generate 29% and 54% more correctly\nedited code in top-1 suggestions relative to the current state-of-the-art\nsymbolic and neural approaches, respectively.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:55:44 GMT"},{"version":"v2","created":"Wed, 24 May 2023 03:25:16 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14130","submitter":"Milad Bader","authors":"Milad Bader, Robert G. Clapp, Kurt T. Nihei, Biondo Biondi","title":"Source footprint elimination in full-waveform inversion by model\n  extension: Application to elastic guided waves recorded by distributed\n  acoustic sensing in unconventional reservoir","comments":"This work has been submitted for publication in Geophysics under the\n  reference GEO-2023-0279","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Source footprints represent an inherent problem to full-waveform inversion\n(FWI). They are caused by the high data sensitivity to the model parameters in\nthe vicinity of the seismic sources and can be exacerbated by source-related\nerrors in the modeling operator. We propose a simple, effective, and efficient\nmethod to remove source footprints in FWI when sources are located near or\ninside the volume of interest while robustly updating the model in their\nvicinity. The method uses illumination redundancy and extends the model along\nsources. Each source updates one component of the extended model, and a\nregularization term ensures that these components are mutually consistent,\nexcept for their respective footprints. We illustrate the effectiveness of our\nmethod on the elastic inversion of synthetic guided waves. We show its\nrobustness in the presence of source-related errors and its superiority over\nother well-known approaches, such as illumination compensation by inverse\npseudo-Hessian and gradient preconditioning. We apply the method to a field\ndistributed acoustic sensing dataset with elastic guided waves generated by\nperforation shots in an unconventional shale reservoir. The method is able to\nretrieve localized reservoir anomalies with higher elastic velocities,\nindicating possible lower pore pressure or tighter shale regions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:55:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14131","submitter":"Andreas Theocharous","authors":"A. Theocharous, G. G. Gregoriou, P. Sapountzis, I. Kontoyiannis","title":"Temporally Causal Discovery Tests for Discrete Time Series and Neural\n  Spike Trains","comments":"30 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME cs.IT math.IT math.ST q-bio.NC stat.TH","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We consider the problem of detecting causal relationships between discrete\ntime series, in the presence of potential confounders. A hypothesis test is\nintroduced for identifying the temporally causal influence of $(x_n)$ on\n$(y_n)$, causally conditioned on a possibly confounding third time series\n$(z_n)$. Under natural Markovian modeling assumptions, it is shown that the\nnull hypothesis, corresponding to the absence of temporally causal influence,\nis equivalent to the underlying `causal conditional directed information rate'\nbeing equal to zero. The plug-in estimator for this functional is identified\nwith the log-likelihood ratio test statistic for the desired test. This\nstatistic is shown that is asymptotically normal under the alternative\nhypothesis and asymptotically $\\chi^2$ distributed under the null, facilitating\nthe computation of $p$-values when used on empirical data. The effectiveness of\nthe resulting hypothesis test is illustrated on simulated data, validating the\nunderlying theory. The test is also employed in the analysis of spike train\ndata recorded from neurons in the V4 and FEF brain regions of behaving animals\nduring a visual attention task. There, the test results are seen to identify\ninteresting and biologically relevant information.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:55:48 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14132","submitter":"Huy Tuan Pham","authors":"David Conlon, Jacob Fox, Huy Tuan Pham, Yufei Zhao","title":"Set-coloring Ramsey numbers and error-correcting codes near the\n  zero-rate threshold","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For positive integers $n,r,s$ with $r > s$, the set-coloring Ramsey number\n$R(n;r,s)$ is the minimum $N$ such that if every edge of the complete graph\n$K_N$ receives a set of $s$ colors from a palette of $r$ colors, then there is\na subset of $n$ vertices where all of the edges between them receive a common\ncolor. If $n$ is fixed and $\\frac{s}{r}$ is less than and bounded away from\n$1-\\frac{1}{n-1}$, then $R(n;r,s)$ is known to grow exponentially in $r$, while\nif $\\frac{s}{r}$ is greater than and bounded away from $1-\\frac{1}{n-1}$, then\n$R(n;r,s)$ is bounded. Here we prove bounds for $R(n;r,s)$ in the intermediate\nrange where $\\frac{s}{r}$ is close to $1 - \\frac{1}{n-1}$ by establishing a\nconnection to the maximum size of error-correcting codes near the zero-rate\nthreshold.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:56:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14133","submitter":"Mhairi Dunion","authors":"Mhairi Dunion, Trevor McInroe, Kevin Sebastian Luck, Josiah P. Hanna,\n  Stefano V. Albrecht","title":"Conditional Mutual Information for Disentangled Representations in\n  Reinforcement Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reinforcement Learning (RL) environments can produce training data with\nspurious correlations between features due to the amount of training data or\nits limited feature coverage. This can lead to RL agents encoding these\nmisleading correlations in their latent representation, preventing the agent\nfrom generalising if the correlation changes within the environment or when\ndeployed in the real world. Disentangled representations can improve\nrobustness, but existing disentanglement techniques that minimise mutual\ninformation between features require independent features, thus they cannot\ndisentangle correlated features. We propose an auxiliary task for RL algorithms\nthat learns a disentangled representation of high-dimensional observations with\ncorrelated features by minimising the conditional mutual information between\nfeatures in the representation. We demonstrate experimentally, using continuous\ncontrol tasks, that our approach improves generalisation under correlation\nshifts, as well as improving the training performance of RL algorithms in the\npresence of correlated features.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:56:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14134","submitter":"Genqian Liu","authors":"Genqian Liu","title":"Remarks on paper \"Two-term spectral asymptotics in linear elasticity''","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.SP math-ph math.AP math.DG math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this note, by pointing out several serious mistakes in \\cite{CaFrLeVa-23}\nwe show that the conclusion published by Matteo Capoferri, Leonid Friedlander,\nMichael Levitin and Dmitri Vassiliev (J Geom Anal (2023)33:242) is completely\nwrong. Then, we explain the correctness of proof of Theorem 1.1 in our paper\n\\cite{Liu-21} by giving some remarks and putting the whole proof in Appendix\n(see also \\cite{Liu-22b} and \\cite{Liu-22c}).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:57:51 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14135","submitter":"Tianhong Li","authors":"Tianhong Li, Vibhaalakshmi Sivaraman, Lijie Fan, Mohammad Alizadeh,\n  Dina Katabi","title":"Reparo: Loss-Resilient Generative Codec for Video Conferencing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Loss of packets in video conferencing often results in poor quality and video\nfreezing. Attempting to retransmit the lost packets is usually not practical\ndue to the requirement for real-time playback. Using Forward Error Correction\n(FEC) to recover the lost packets is challenging since it is difficult to\ndetermine the appropriate level of redundancy. In this paper, we propose a\nframework called Reparo for creating loss-resilient video conferencing using\ngenerative deep learning models. Our approach involves generating missing\ninformation when a frame or part of a frame is lost. This generation is\nconditioned on the data received so far, and the model's knowledge of how\npeople look, dress, and interact in the visual world. Our experiments on\npublicly available video conferencing datasets show that Reparo outperforms\nstate-of-the-art FEC-based video conferencing in terms of both video quality\n(measured by PSNR) and video freezes.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:58:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14136","submitter":"Jes\\'us Due\\~nas","authors":"Jes\\'us Due\\~nas, Iacopo P. Longo and Rafael Obaya","title":"Rate-induced tracking for concave or d-concave transitions in a\n  time-dependent environment with application in ecology","comments":"18 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper investigates biological models that represent the transition\nequation from a system in the past to a system in the future. It is shown that\nfinite-time Lyapunov exponents calculated along a locally pullback attractive\nsolution are efficient indicators (early-warning signals) of the presence of a\ncritical point. Precise time-dependent transitions with concave or d-concave\nvariation in the state variable giving rise to scenarios of rate-induced\ntracking are shown. They are classified depending on the internal dynamics of\nthe set of bounded solutions. Based on this classification, some representative\nfeatures of these models are investigated by means of a careful numerical\nanalysis.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:00:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14137","submitter":"Gaia Grosso","authors":"Gaia Grosso, Marco Letizia, Maurizio Pierini, Andrea Wulzer","title":"Goodness of fit by Neyman-Pearson testing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Neyman-Pearson strategy for hypothesis testing can be employed for\ngoodness of fit if the alternative hypothesis $\\rm H_1$ is generic enough not\nto introduce a significant bias while at the same time avoiding overfitting. A\npractical implementation of this idea (dubbed NPLM) has been developed in the\ncontext of high energy physics, targeting the detection in collider data of new\nphysical effects not foreseen by the Standard Model. In this paper we initiate\na comparison of this methodology with other approaches to goodness of fit, and\nin particular with classifier-based strategies that share strong similarities\nwith NPLM. NPLM emerges from our comparison as more sensitive to small\ndepartures of the data from the expected distribution and not biased towards\ndetecting specific types of anomalies while being blind to others. These\nfeatures make it more suited for agnostic searches for new physics at collider\nexperiments. Its deployment in other contexts should be investigated.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:01:45 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14138","submitter":"Alexandru Chirv\\u{a}situ L.","authors":"A. Chirvasitu and G. Militaru","title":"A universal-algebra and combinatorial approach to the set-theoretic\n  Yang-Baxter equation","comments":"45 pages + references","journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA math.CO math.CT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a new variety of set-theoretic non-associative algebras,\nP{\\l}onka bi-magmas, to describe and classify all solutions of the\nset-theoretic Yang-Baxter (YB) equation of Baaj-Long-Skandalis (BLS) type. We\nalso study new classes of YB-solutions (bi-connected, simple), and classify the\nBLS-solutions that fit into those classes. There are only countably many\nisomorphism classes of simple BLS-solutions, for instance, and they are all\ndescribable in terms of the odometer transformations familiar from ergodic\ntheory.\n  Placing Drinfel'd's problem of classifying the set-theoretic solutions of the\nYang-Baxter equation in a universal-algebra context with a combinatorial\nflavor, we also prove the existence of adjunctions between various categories\nof solutions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:03:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14139","submitter":"Lo\\\"ic Fellay","authors":"L. Fellay and M.-A. Dupret","title":"MoBiDICT: new 3D static models of close, synchronized binaries in\n  hydrostatic equilibrium","comments":"submitted to A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In close binary systems, tidal interactions and rotational effects can\nstrongly influence stellar evolution as a result of mass-transfer, common\nenvelope phases, ... All these aspects can only be treated following\nimprovements of theoretical models, taking into account the breaking of\nspherical symmetry occurring in close binaries. Current models of binary stars\nare relying either on the so-called \"Roche model\" or the perturbative approach\nthat in each case results on several assumptions concerning the gravitational,\ntidal and centrifugal potentials.We developed a new non-perturbative method to\ncompute precise structural deformation of binary system in three dimensions\nthat is valid even in the most distorted cases. We then compared our new method\nto the Roche and perturbative models for different orbital separations and\nbinary components. We found that in the most distorted cases both Roche and\nperturbative models are significantly underestimating the deformation of\nbinaries. The effective gravity and the overall structural deformations are\nalso noticeably different in the most distorted cases leading, for the\ninterpretation of observations, to modifications of the usual gravity darkening\ngenerally obtained through the Roche model. Moreover we found that the dipolar\nterm of the gravitational potential, usually neglected by the perturbative\ntheory, has the same order of magnitude than the leading tidal term in the most\ndistorted cases. We developed a new method that is capable of precisely\ncomputing the deformations of binary system composed of any type of stars, even\ncompact objects. For all stars studied the differences in deformation with\nrespect to the Roche or perturbative models are significant in the most\ndistorted cases impacting both the interpretation of observations and the\ntheoretical structural depiction of these distorted bodies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:04:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14140","submitter":"Diego Portillo-S\\'anchez","authors":"Juan Manuel M\\'arquez, Diego Portillo-S\\'anchez, Gabriel L\\'opez\n  Castro and Pablo Roig","title":"On the Dirac-Majorana neutrinos distinction in four-body decays","comments":"20 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivated by the novel method discussed in arXiv:2106.11785 to differentiate\nthe effects of Dirac and Majorana neutrinos in four-body decays, we propose to\nanalyse radiative leptonic lepton-decays ($\\ell\\to\\ell'\\nu\\bar{\\nu}\\gamma$), as\nan independent alternative process to study the possible Majorana nature of\nneutrinos. Following arXiv:2106.11785, the back-to-back kinematic scenario (for\nthe $\\ell'- \\gamma$ and $\\nu-\\bar{\\nu}$ systems, respectively) supposedly\navoids the constraint imposed by the \"practical Dirac-Majorana confusion\ntheorem\", as one does not need to fully integrate over neutrino and\nantineutrino momenta. Our results show that, in this special kinematic\nconfiguration, the difference between Dirac and Majorana cases vanishes once\nthe inaccessible neutrino angle is integrated out, which seems to be\nincompatible with the proposal in arXiv:2106.11785. We work on that and\nconclude that the discrepancy comes from the kinematic treatment, specifically\nfrom the angular integration and clarify these issues with consistency tests.\nAll this applies in absence of non-standard interactions, which can enhance\ngenerally the sensitivity to the neutrino nature.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:05:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14141","submitter":"Shitian He","authors":"Shitian He, Huanxin Zou, Yingqian Wang, Boyang Li, Xu Cao and Ning\n  Jing","title":"Learning Remote Sensing Object Detection with Single Point Supervision","comments":"13 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pointly Supervised Object Detection (PSOD) has attracted considerable\ninterests due to its lower labeling cost as compared to box-level supervised\nobject detection. However, the complex scenes, densely packed and dynamic-scale\nobjects in Remote Sensing (RS) images hinder the development of PSOD methods in\nRS field. In this paper, we make the first attempt to achieve RS object\ndetection with single point supervision, and propose a PSOD framework tailored\nwith RS images. Specifically, we design a point label upgrader (PLUG) to\ngenerate pseudo box labels from single point labels, and then use the pseudo\nboxes to supervise the optimization of existing detectors. Moreover, to handle\nthe challenge of the densely packed objects in RS images, we propose a sparse\nfeature guided semantic prediction module which can generate high-quality\nsemantic maps by fully exploiting informative cues from sparse objects.\nExtensive ablation studies on the DOTA dataset have validated the effectiveness\nof our method. Our method can achieve significantly better performance as\ncompared to state-of-the-art image-level and point-level supervised detection\nmethods, and reduce the performance gap between PSOD and box-level supervised\nobject detection. Code will be available at https://github.com/heshitian/PLUG.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:06:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14142","submitter":"Xianjie Liu","authors":"Xianjie Liu, Hongwei Shi","title":"A multimodal method based on cross-attention and convolution for\n  postoperative infection diagnosis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Postoperative infection diagnosis is a common and serious complication that\ngenerally poses a high diagnostic challenge. This study focuses on PJI, a type\nof postoperative infection. X-ray examination is an imaging examination for\nsuspected PJI patients that can evaluate joint prostheses and adjacent tissues,\nand detect the cause of pain. Laboratory examination data has high sensitivity\nand specificity and has significant potential in PJI diagnosis. In this study,\nwe proposed a self-supervised masked autoencoder pre-training strategy and a\nmultimodal fusion diagnostic network MED-NVC, which effectively implements the\ninteraction between two modal features through the feature fusion network of\nCrossAttention. We tested our proposed method on our collected PJI dataset and\nevaluated its performance and feasibility through comparison and ablation\nexperiments. The results showed that our method achieved an ACC of 94.71% and\nan AUC of 98.22%, which is better than the latest method and also reduces the\nnumber of parameters. Our proposed method has the potential to provide\nclinicians with a powerful tool for enhancing accuracy and efficiency.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:08:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14143","submitter":"Michel Nowak","authors":"Anne-Sol\\`ene Bornens and Michel Nowak","title":"Variational quantum algorithms on cat qubits","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Variational Quantum Algorithms (VQA) have emerged with a wide variety of\napplications. One question to ask is either they can efficiently be implemented\nand executed on existing architectures. Current hardware suffers from\nuncontrolled noise that can alter the expected results of one calculation. The\nnature of this noise is different from one technology to another. In this work,\nwe chose to investigate a technology that is intrinsically resilient to\nbit-flips: cat qubits. To this end, we implement two noise models. The first\none is hardware-agnostic -- in the sense that it is used in the literature to\ncover different hardware types. The second one is specific to cat qubits. We\nperform simulations on two types of problems that can be formulated with VQAs\n(Quantum Approximate Optimization Algorithm (QAOA) and the Variatinoal Quantum\nLinear Soler (VQLS)), study the impact of noise on the evolution of the cost\nfunction and extract noise level thresholds from which a noise-resilient regime\ncan be considered. By tackling compilation issues, we discuss the need of\nimplementing hardware-specific noise models as hardware-agnostic ones can lead\nto misleading conclusions regarding the regime of noise that is acceptable for\nan algorithm to run.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:09:00 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 12:47:29 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.14144","submitter":"Lucas Palma Conte","authors":"Daniel de Florian, Lucas Palma Conte","title":"QED corrections to parton distributions and Altarelli-Parisi splitting\n  functions in the polarized case","comments":"23 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We discuss the effect of QED corrections in the evolution of polarized parton\ndistributions. We solve the corresponding evolution equations exactly to ${\\cal\nO}(\\alpha )$ and ${\\cal O}(\\alpha_s^2)$ in Mellin $N$-space, extending the\navailable techniques for pure QCD evolution. To accomplish this, we introduce,\nfor the first time, the Altarelli-Parisi polarized kernels at LO in QED.\nFurthermore, we perform a phenomenological analysis of the QED effects on\npolarized parton distributions (pPDFs), proposing different scenarios for the\npolarized photon density. Finally, we quantify the impact of the corresponding\nQED contributions to the polarized structure function $g_1$. We show that the\nrelative corrections to both the pPDFs and the $g_1$ structure function are\napproximately at the few percent level, which is the order of magnitude\nexpected considering the value of $\\alpha$.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:10:33 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14145","submitter":"Kiumars Aryana","authors":"Kiumars Aryana, Hyun Jung Kim, Cosmin-Constantin Popescu, Steven\n  Vitale, Hyung Bin Bae, Taewoo Lee, Tian Gu, and Juejun Hu","title":"Toward accurate thermal modeling of phase change material based photonic\n  devices","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Reconfigurable or programmable photonic devices are rapidly growing and have\nbecome an integral part of many optical systems. The ability to selectively\nmodulate electromagnetic waves through electrical stimuli is crucial in the\nadvancement of a variety of applications from data communication and computing\ndevices to environmental science and space explorations. Chalcogenide-based\nphase change materials (PCMs) are one of the most promising material candidates\nfor reconfigurable photonics due to their large optical contrast between their\ndifferent solid-state structural phases. Although significant efforts have been\ndevoted to accurate simulation of PCM-based devices, in this paper, we\nhighlight three important aspects which have often evaded prior models yet\nhaving significant impacts on the thermal and phase transition behavior of\nthese devices: the enthalpy of fusion, the heat capacity change upon glass\ntransition, as well as the thermal conductivity of liquid-phase PCMs. We\nfurther investigated the important topic of switching energy scaling in PCM\ndevices, which also helps explain why the three above-mentioned effects have\nlong been overlooked in electronic PCM memories but only become important in\nphotonics. Our findings offer insight to facilitate accurate modeling of\nPCM-based photonic devices and can inform the development of more efficient\nreconfigurable optics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:12:24 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14146","submitter":"Qunying Song","authors":"Qunying Song, Emelie Engstr\\\"om, Per Runeson","title":"Industry Practices for Challenging Autonomous Driving Systems with\n  Critical Scenarios","comments":"29 pages, 3 figures, submitted to a journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Testing autonomous driving systems for safety and reliability is extremely\ncomplex. A primary challenge is identifying the relevant test scenarios,\nespecially the critical ones that may expose hazards or risks of harm to\nautonomous vehicles and other road users. There are several proposed methods\nand tools for critical scenario identification, while the industry practices,\nsuch as the selection, implementation, and limitations of the approaches, are\nnot well understood. In this study, we conducted 10 interviews with 13\ninterviewees from 7 companies in autonomous driving in Sweden. We used thematic\nmodeling to analyse and synthesize the interview data. We found there are\nlittle joint efforts in the industry to explore different approaches and tools,\nand every approach has its own limitations and weaknesses. To that end, we\nrecommend combining different approaches available, collaborating among\ndifferent stakeholders, and continuously learning the field of critical\nscenario identification and testing. The contributions of our study are the\nexploration and synthesis of the industry practices and related challenges for\ncritical scenario identification and testing, and the potential increase of the\nindustry relevance for future studies in related topics.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:13:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14147","submitter":"John Wieland","authors":"J. N. Wieland, A. L. Romanov, A. Valishev, G. Stancari, J. D. Jarvis,\n  N. Kuklev, S. Szustkowski, S. Nagaitsev","title":"Improved Measurements of Nonlinear Integrable Optics Invariants at IOTA","comments":"3pgs","journal-ref":null,"doi":null,"report-no":"FERMILAB-CONF-23-186-AD","categories":"physics.acc-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Nonlinear integrable optics (NIO) are a promising novel approach at improving\nthe stability of high intensity beams. Implementations of NIO based on\nspecialized magnetic elements are being tested at the Integrable Optics Test\nAccelerator (IOTA) at Fermilab. One method of verifying proper implementation\nof these solutions is by measuring the analytic invariants predicted by theory.\nThe initial measurements of nonlinear invariants were performed during IOTA run\nin 2019/20, however the covid-19 pandemic prevented the full-scale experimental\nprogram from being completed. Several important improvements were implemented\nin IOTA for the 2022/23 run, including the operation at higher beam energy of\n150 MeV, improved optics control, and chromaticity correction. This report\npresents the results of improved measurements of nonlinear invariants.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:14:06 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14148","submitter":"Daniel Mills","authors":"Pablo Andres-Martinez, Tim Forrer, Daniel Mills, Jun-Yi Wu, Luciana\n  Henaut, Kentaro Yamamoto, Mio Murao, Ross Duncan","title":"Distributing circuits over heterogeneous, modular quantum computing\n  network architectures","comments":"30 pages, 18 figures, comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider a heterogeneous network of quantum computing modules, sparsely\nconnected via Bell states. Operations across these connections constitute a\ncomputational bottleneck and they are likely to add more noise to the\ncomputation than operations performed within a module. We introduce several\ntechniques for transforming a given quantum circuit into one implementable on a\nnetwork of the aforementioned type, minimising the number of Bell states\nrequired to do so.\n  We extend previous works on circuit distribution over fully connected\nnetworks to the case of heterogeneous networks. On the one hand, we extend the\nhypergraph approach of [Andres-Martinez & Heunen. 2019] to arbitrary network\ntopologies. We additionally make use of Steiner trees to find efficient\nrealisations of the entanglement sharing within the network, reusing already\nestablished connections as often as possible. On the other hand, we extend the\nembedding techniques of [Wu, et al. 2022] to networks with more than two\nmodules. Furthermore, we discuss how these two seemingly incompatible\napproaches can be made to cooperate. Our proposal is implemented and\nbenchmarked; the results confirming that, when orchestrated, the two approaches\ncomplement each other's weaknesses.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:14:53 GMT"},{"version":"v2","created":"Wed, 24 May 2023 15:23:13 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14149","submitter":"Roman Andriushchenko","authors":"Roman Andriushchenko, Alexander Bork, Milan \\v{C}e\\v{s}ka, Sebastian\n  Junges, Joost-Pieter Katoen, Filip Mac\\'ak","title":"Search and Explore: Symbiotic Policy Synthesis in POMDPs","comments":"Accepted to CAV 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper marries two state-of-the-art controller synthesis methods for\npartially observable Markov decision processes (POMDPs), a prominent model in\nsequential decision making under uncertainty. A central issue is to find a\nPOMDP controller - that solely decides based on the observations seen so far -\nto achieve a total expected reward objective. As finding optimal controllers is\nundecidable, we concentrate on synthesising good finite-state controllers\n(FSCs). We do so by tightly integrating two modern, orthogonal methods for\nPOMDP controller synthesis: a belief-based and an inductive approach. The\nformer method obtains an FSC from a finite fragment of the so-called belief\nMDP, an MDP that keeps track of the probabilities of equally observable POMDP\nstates. The latter is an inductive search technique over a set of FSCs, e.g.,\ncontrollers with a fixed memory size. The key result of this paper is a\nsymbiotic anytime algorithm that tightly integrates both approaches such that\neach profits from the controllers constructed by the other. Experimental\nresults indicate a substantial improvement in the value of the controllers\nwhile significantly reducing the synthesis time and memory footprint.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:15:09 GMT"},{"version":"v2","created":"Mon, 29 May 2023 08:43:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14150","submitter":"Bo Zhou","authors":"Bo Zhou, Qianglong Chen, Tianyu Wang, Xiaomi Zhong, Yin Zhang","title":"WYWEB: A NLP Evaluation Benchmark For Classical Chinese","comments":"Accepted by ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To fully evaluate the overall performance of different NLP models in a given\ndomain, many evaluation benchmarks are proposed, such as GLUE, SuperGLUE and\nCLUE. The fi eld of natural language understanding has traditionally focused on\nbenchmarks for various tasks in languages such as Chinese, English, and\nmultilingua, however, there has been a lack of attention given to the area of\nclassical Chinese, also known as \"wen yan wen\", which has a rich history\nspanning thousands of years and holds signifi cant cultural and academic value.\nFor the prosperity of the NLP community, in this paper, we introduce the WYWEB\nevaluation benchmark, which consists of nine NLP tasks in classical Chinese,\nimplementing sentence classifi cation, sequence labeling, reading\ncomprehension, and machine translation. We evaluate the existing pre-trained\nlanguage models, which are all struggling with this benchmark. We also\nintroduce a number of supplementary datasets and additional tools to help\nfacilitate further progress on classical Chinese NLU. The github repository is\nhttps://github.com/baudzhou/WYWEB.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:15:11 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14151","submitter":"Theodoros Vlachos","authors":"Marcos Dajczer and Theodoros Vlachos","title":"Ricci pinched compact submanifolds in spheres","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We investigate the topology of the compact submanifolds in round spheres that\nsatisfy a lower bound on the Ricci curvature depending only on the length of\nthe mean curvature vector of the immersion. Just in special cases, the limited\nstrength of the assumption allows some strong additional information on the\nextrinsic geometry of the submanifold. This hints that in the more general\nsituation a full geometric classification may be an unattainable goal.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:16:59 GMT"},{"version":"v2","created":"Wed, 24 May 2023 04:37:02 GMT"},{"version":"v3","created":"Mon, 29 May 2023 15:48:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.14152","submitter":"Jeonghoon Kim","authors":"Jeonghoon Kim, Jung Hyun Lee, Sungdong Kim, Joonsuk Park, Kang Min\n  Yoo, Se Jung Kwon, Dongsoo Lee","title":"Memory-Efficient Fine-Tuning of Compressed Large Language Models via\n  sub-4-bit Integer Quantization","comments":"9 pages, 2 figures, 8 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Parameter-efficient fine-tuning (PEFT) methods have emerged to mitigate the\nprohibitive cost of full fine-tuning large language models (LLMs). Nonetheless,\nthe enormous size of LLMs impedes routine deployment. To address the issue, we\npresent Parameter-Efficient and Quantization-aware Adaptation (PEQA), a novel\nquantization-aware PEFT technique that facilitates model compression and\naccelerates inference. PEQA operates through a dual-stage process: initially,\nthe parameter matrix of each fully-connected layer undergoes quantization into\na matrix of low-bit integers and a scalar vector; subsequently, fine-tuning\noccurs on the scalar vector for each downstream task. Such a strategy\ncompresses the size of the model considerably, leading to a lower inference\nlatency upon deployment and a reduction in the overall memory required. At the\nsame time, fast fine-tuning and efficient task switching becomes possible. In\nthis way, PEQA offers the benefits of quantization, while inheriting the\nadvantages of PEFT. We compare PEQA with competitive baselines in comprehensive\nexperiments ranging from natural language understanding to generation\nbenchmarks. This is done using large language models of up to $65$ billion\nparameters, demonstrating PEQA's scalability, task-specific adaptation\nperformance, and ability to follow instructions, even in extremely low-bit\nsettings.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:20:01 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14153","submitter":"Eric Drebitz","authors":"Lukas-Paul Rausch, Maik Sch\\\"unemann, Eric Drebitz, Daniel Harnack,\n  Udo A. Ernst, Andreas K. Kreiter","title":"Strong attentional modulation of V1/V2 activity implements a robust,\n  contrast-invariant control mechanism for selective information processing","comments":"53 pages, 8 figures, research article","journal-ref":null,"doi":"10.48550/arXiv.2305.14153","report-no":null,"categories":"q-bio.NC","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  When selective attention is devoted to one of multiple stimuli within\nreceptive fields of neurons in visual area V4, cells respond as if only the\nattended stimulus was present. The underlying neural mechanisms are still\ndebated, but computational studies suggest that a small rate advantage for\nneural populations passing the attended signal to V4 suffices to establish such\nselective processing. We challenged this theory by pairing stimuli with\ndifferent luminance contrasts, such that attention on a weak target stimulus\nwould have to overcome a large activation difference to a strong distracter. In\nthis situation we found unexpectedly large attentional target facilitation in\nmacaque V1/V2 which far surpasses known magnitudes of attentional modulation.\nTarget facilitation scales with contrast difference and combines with\ndistracter suppression to achieve the required rate advantage. These effects\ncan be explained by a contrast-independent attentional control mechanism with\nexcitatory centre and suppressive surround targeting divisive normalization\nunits.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:20:28 GMT"},{"version":"v2","created":"Wed, 24 May 2023 13:02:01 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14154","submitter":"Oswin So","authors":"Oswin So, Chuchu Fan","title":"Solving Stabilize-Avoid Optimal Control via Epigraph Form and Deep\n  Reinforcement Learning","comments":"Accepted to Robotics: Science and Systems 2023. Project page can be\n  found at https://mit-realm.github.io/efppo","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Tasks for autonomous robotic systems commonly require stabilization to a\ndesired region while maintaining safety specifications. However, solving this\nmulti-objective problem is challenging when the dynamics are nonlinear and\nhigh-dimensional, as traditional methods do not scale well and are often\nlimited to specific problem structures. To address this issue, we propose a\nnovel approach to solve the stabilize-avoid problem via the solution of an\ninfinite-horizon constrained optimal control problem (OCP). We transform the\nconstrained OCP into epigraph form and obtain a two-stage optimization problem\nthat optimizes over the policy in the inner problem and over an auxiliary\nvariable in the outer problem. We then propose a new method for this\nformulation that combines an on-policy deep reinforcement learning algorithm\nwith neural network regression. Our method yields better stability during\ntraining, avoids instabilities caused by saddle-point finding, and is not\nrestricted to specific requirements on the problem structure compared to more\ntraditional methods. We validate our approach on different benchmark tasks,\nranging from low-dimensional toy examples to an F16 fighter jet with a\n17-dimensional state space. Simulation results show that our approach\nconsistently yields controllers that match or exceed the safety of existing\nmethods while providing ten-fold increases in stability performance from larger\nregions of attraction.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:21:03 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14155","submitter":"Karoly Bezdek","authors":"K\\'aroly Bezdek","title":"On a Blaschke-Santal\\'o-type inequality for $r$-ball bodies","comments":"5 pages. arXiv admin note: text overlap with arXiv:1810.11886","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let ${\\mathbb E}^d$ denote the $d$-dimensional Euclidean space. The $r$-ball\nbody generated by a given set in ${\\mathbb E}^d$ is the intersection of balls\nof radius $r$ centered at the points of the given set. The author [Discrete\nOptimization 44/1 (2022), Paper No. 100539] proved the following\nBlaschke-Santal\\'o-type inequality for $r$-ball bodies: for all $0<k< d$ and\nfor any set of given $d$-dimensional volume in ${\\mathbb E}^d$ the $k$-th\nintrinsic volume of the $r$-ball body generated by the set becomes maximal if\nthe set is a ball. In this note we give a new proof showing also the uniqueness\nof the maximizer. Some applications and related questions are mentioned as\nwell.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:21:23 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14156","submitter":"Michael B. Weissman","authors":"M. B. Weissman, J. M. Robins","title":"Comment on \"Examining the effect of counter-narratives about physics on\n  women's physics career intentions\"","comments":"less than 2000 words","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ed-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A paper evaluating the effects of lessons intended to encourage high school\nstudents to continue physics studies made some important errors. One was to\nunderestimate the width of confidence intervals by failing to use standard\ncluster randomization analysis. Another was to use a missing-data imputation\nprogram that inappropriately assumes that data are missing at random, leading\nto potential bias in estimating the effect. The last was to omit discussion of\nhow the treatment used was likely to produce substantial social desirability\nsurvey response bias, eroding external validity.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:24:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14157","submitter":"Betul Gokkaya","authors":"Betul Gokkaya, Leonardo Aniello, Basel Halak","title":"Software supply chain: review of attacks, risk assessment strategies and\n  security controls","comments":"27 pages, 6 figures, 2 table, review paper, journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.SE","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The software product is a source of cyber-attacks that target organizations\nby using their software supply chain as a distribution vector. As the reliance\nof software projects on open-source or proprietary modules is increasing\ndrastically, SSC is becoming more and more critical and, therefore, has\nattracted the interest of cyber attackers. While existing studies primarily\nfocus on software supply chain attacks' prevention and detection methods, there\nis a need for a broad overview of attacks and comprehensive risk assessment for\nsoftware supply chain security. This study conducts a systematic literature\nreview to fill this gap. We analyze the most common software supply chain\nattacks by providing the latest trend of analyzed attacks, and we identify the\nsecurity risks for open-source and third-party software supply chains.\nFurthermore, this study introduces unique security controls to mitigate\nanalyzed cyber-attacks and risks by linking them with real-life security\nincidence and attacks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:25:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14158","submitter":"Jan K\\'ara","authors":"Jan K\\'ara, Sergey Zharikov, Marek Wolf, Ainash Amantayeva, Gulnur\n  Subebekova, Serik Khokhlov, Aldiyar Agishev and Jaroslav Merc","title":"The Z Camelopardalis-type star AY Piscium: stellar and accretion disk\n  parameters","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a new study of the Z~Cam-type eclipsing cataclysmic variable\nAY~Piscium with the aim of determining the fundamental parameters of the system\nand the structure of the accretion flow therein. We use time-resolved\nphotometric observations supplemented by spectroscopy in the standstill, to\nwhich we applied our light-curve modeling techniques and the Doppler tomography\nmethod, to update system parameters. We found that the system has a massive\nwhite dwarf $M_{\\rm WD}=0.90(4)$ \\ms, a mass ratio $q=0.50(3)$, and the\neffective temperature of a secondary $T_2 = 4100(50)$~K. The system inclination\nis $i=74.^{\\circ}8(7)$. The orbital period of the system\n$P_{\\mathrm{orb}}=0.217320523(8)\\;\\mathrm{d}$ is continuously increasing with\nthe rate of $\\dot{P}_{\\mathrm{orb}} = +7.6(5)\\times10^{-9}$ d year$^{-1}$. The\nmass transfer rate varies between 2.4$\\times$10$^{-10}$ M$_\\odot$ year$^{-1}$\nin quiescence up to 1.36$\\times$10$^{-8}$ M$_\\odot$ year$^{-1}$ in outburst.\nThe accretion disk transitions from the cooler, flared, steady-state disk to a\nwarmer state with a practically constant and relatively high disk height. The\nmass transfer rate is about 1.6$\\times$10$^{-9}$ M$_\\odot$ year$^{-1}$ in the\nstandstill. The Balmer emission lines show a multi-component structure similar\nto that observed in long-orbital-period nova-like systems. Out of standstill,\nthe system exhibits outburst bimodality, with long outbursts being more\nprominent. We conclude that the Balmer emission lines in AY~Psc are formed by\nthe combination of radiation from the irradiated surface of the secondary, from\nthe outflow zone, and from winds originating in the bright spot and the disk's\ninner part.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:26:00 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14159","submitter":"Maximilian Schich","authors":"Mar Canet Sol\\`a, Antonina Korepanova, Ksenia Mukhina, Maximilian\n  Schich","title":"Quantifying Collection Lag in European Modern and Contemporary Art\n  Museums","comments":"13 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI physics.soc-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Museum collection strategies are governed by a variety of factors, including\ntopical focus, acquisition funds, availability of works in the art market,\ndonations and specific coincidental opportunities. Yet, it remains unclear if\nmore fundamental collection patterns emerge, exist, and are shared between\nmuseums, which could for example allow an established artist to estimate when a\ncontemporary art museum would acquire their works. Here we collect and analyze\ndata from 12 European contemporary art museums, taking into account artwork\ncreation dates, collection acquisition dates, and the associated artist age at\nboth points in time. From this simple quantitative construct we are able to\nreveal a striking gradient of museum profiles at the aggregate level. This lag\ncan function to constitute a macroeconomic index of \"mean museum collection\nlag\", ranging from 3 years in the most dynamic cases (Kiasma) to 33 years in\nthe most established institutions (Reina Sofia). Meanwhile, on the granular\nlevel, plotting artist age over collection year, and using artist-age vs\nartwork-collection matrices, a detailed picture becomes evident, where\nindividual museums are characterized by shared patterns and a rich\nheterogeneity of ideographic details. Regularities include continuous\nacquisitions, systematic acquisition of older materials over time, and brief\nbursts, where whole oeuvres of individual artists join specific collections.\nHence, we are able to shed light on the detailed collection history of museums,\ntranscending the anecdotal nature of art historical storytelling via the\nprovision of a quantitative context. Our approach of cultural data analysis\ncombines expertise in art, art history, computational social science, and\ncomputer science. Our joint perspective builds a bridge between and serves an\naudience of museum professionals, art market actors, collectors, and individual\nartists alike.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:26:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14160","submitter":"Lean Wang","authors":"Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie\n  Zhou, Xu Sun","title":"Label Words are Anchors: An Information Flow Perspective for\n  Understanding In-Context Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In-context learning (ICL) emerges as a promising capability of large language\nmodels (LLMs) by providing them with demonstration examples to perform diverse\ntasks. However, the underlying mechanism of how LLMs learn from the provided\ncontext remains under-explored. In this paper, we investigate the working\nmechanism of ICL through an information flow lens. Our findings reveal that\nlabel words in the demonstration examples function as anchors: (1) semantic\ninformation aggregates into label word representations during the shallow\ncomputation layers' processing; (2) the consolidated information in label words\nserves as a reference for LLMs' final predictions. Based on these insights, we\nintroduce an anchor re-weighting method to improve ICL performance, a\ndemonstration compression technique to expedite inference, and an analysis\nframework for diagnosing ICL errors in GPT2-XL. The promising applications of\nour findings again validate the uncovered ICL working mechanism and pave the\nway for future studies.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:26:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14161","submitter":"Lei Zhao","authors":"Xiao Li, Lei Zhao, Daoli Zhu, Anthony Man-Cho So","title":"Revisiting Subgradient Method: Complexity and Convergence Beyond\n  Lipschitz Continuity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The subgradient method is one of the most fundamental algorithmic schemes for\nnonsmooth optimization. The existing complexity and convergence results for\nthis algorithm are mainly derived for Lipschitz continuous objective functions.\nIn this work, we first extend the typical complexity results for the\nsubgradient method to convex and weakly convex minimization without assuming\nLipschitz continuity. Specifically, we establish $\\mathcal{O}(1/\\sqrt{T})$\nbound in terms of the suboptimality gap ``$f(x) - f^*$'' for convex case and\n$\\mathcal{O}(1/{T}^{1/4})$ bound in terms of the gradient of the Moreau\nenvelope function for weakly convex case. Furthermore, we provide convergence\nresults for non-Lipschitz convex and weakly convex objective functions using\nproper diminishing rules on the step sizes. In particular, when $f$ is convex,\nwe show $\\mathcal{O}(\\log(k)/\\sqrt{k})$ rate of convergence in terms of the\nsuboptimality gap. With an additional quadratic growth condition, the rate is\nimproved to $\\mathcal{O}(1/k)$ in terms of the squared distance to the optimal\nsolution set. When $f$ is weakly convex, asymptotic convergence is derived. The\ncentral idea is that the dynamics of properly chosen step sizes rule fully\ncontrols the movement of the subgradient method, which leads to boundedness of\nthe iterates, and then a trajectory-based analysis can be conducted to\nestablish the desired results. To further illustrate the wide applicability of\nour framework, we extend the complexity results to the truncated subgradient,\nthe stochastic subgradient, the incremental subgradient, and the proximal\nsubgradient methods for non-Lipschitz functions.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:26:36 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14162","submitter":"Davide Piccioni","authors":"Davide Piccioni, Christian Apostoli, Federico Becca, Guglielmo\n  Mazzola, Alberto Parola, Sandro Sorella and Giuseppe E. Santoro","title":"A Jastrow wave function for the spin-1 Heisenberg chain: the string\n  order revealed by the mapping to the classical Coulomb gas","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that a two-body Jastrow wave function is able to capture the\nground-state properties of the $S=1$ antiferromagnetic Heisenberg chain with\nthe single-ion anisotropy term, in both the topological and trivial phases.\nHere, the optimized Jastrow pseudo potential assumes a very simple form in\nFourier space, i.e., $v_{q} \\approx 1/q^2$, which is able to give rise to a\nfinite string-order parameter in the topological regime. The results are\nanalysed by using an exact mapping from the quantum expectation values over the\nvariational state to the classical partition function of the one-dimensional\nCoulomb gas of particles with charge $q=\\pm 1$. Here, two phases are present at\nlow temperatures: the first one is a diluted gas of dipoles (bound states of\nparticles with opposite charges), which are randomly oriented (describing the\ntrivial phase); the other one is a dense liquid of dipoles, which are aligned\nthanks to the residual dipole-dipole interactions (describing the topological\nphase, with the finite string order being related to the dipole alignment). Our\nresults provide an insightful interpretation of the ground-state nature of the\nspin-1 antiferromagnetic Heisenberg model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:27:21 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14163","submitter":"David Duki\\'c","authors":"David Duki\\'c, Kiril Gashteovski, Goran Glava\\v{s}, Jan \\v{S}najder","title":"Leveraging Open Information Extraction for Improving Few-Shot Trigger\n  Detection Domain Transfer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Event detection is a crucial information extraction task in many domains,\nsuch as Wikipedia or news. The task typically relies on trigger detection (TD)\n-- identifying token spans in the text that evoke specific events. While the\nnotion of triggers should ideally be universal across domains, domain transfer\nfor TD from high- to low-resource domains results in significant performance\ndrops. We address the problem of negative transfer for TD by coupling triggers\nbetween domains using subject-object relations obtained from a rule-based open\ninformation extraction (OIE) system. We demonstrate that relations injected\nthrough multi-task training can act as mediators between triggers in different\ndomains, enhancing zero- and few-shot TD domain transfer and reducing negative\ntransfer, in particular when transferring from a high-resource source Wikipedia\ndomain to a low-resource target news domain. Additionally, we combine the\nextracted relations with masked language modeling on the target domain and\nobtain further TD performance gains. Finally, we demonstrate that the results\nare robust to the choice of the OIE system.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:27:35 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14164","submitter":"Francesco Pedrotti","authors":"Francesco Pedrotti, Jan Maas, Marco Mondelli","title":"Improved Convergence of Score-Based Diffusion Models via\n  Prediction-Correction","comments":"28 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.ST stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Score-based generative models (SGMs) are powerful tools to sample from\ncomplex data distributions. Their underlying idea is to (i) run a forward\nprocess for time $T_1$ by adding noise to the data, (ii) estimate its score\nfunction, and (iii) use such estimate to run a reverse process. As the reverse\nprocess is initialized with the stationary distribution of the forward one, the\nexisting analysis paradigm requires $T_1\\to\\infty$. This is however\nproblematic: from a theoretical viewpoint, for a given precision of the score\napproximation, the convergence guarantee fails as $T_1$ diverges; from a\npractical viewpoint, a large $T_1$ increases computational costs and leads to\nerror propagation. This paper addresses the issue by considering a version of\nthe popular predictor-corrector scheme: after running the forward process, we\nfirst estimate the final distribution via an inexact Langevin dynamics and then\nrevert the process. Our key technical contribution is to provide convergence\nguarantees in Wasserstein distance which require to run the forward process\nonly for a finite time $T_1$. Our bounds exhibit a mild logarithmic dependence\non the input dimension and the subgaussian norm of the target distribution,\nhave minimal assumptions on the data, and require only to control the $L^2$\nloss on the score approximation, which is the quantity minimized in practice.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:29:09 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14165","submitter":"Chengyin Hu","authors":"Chengyin Hu, Weiwen Shi, Chao Li, Jialiang Sun, Donghua Wang, Junqi\n  Wu, Guijian Tang","title":"Impact of Light and Shadow on Robustness of Deep Neural Networks","comments":"arXiv admin note: substantial text overlap with arXiv:2209.02832,\n  arXiv:2209.02132","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep neural networks (DNNs) have made remarkable strides in various computer\nvision tasks, including image classification, segmentation, and object\ndetection. However, recent research has revealed a vulnerability in advanced\nDNNs when faced with deliberate manipulations of input data, known as\nadversarial attacks. Moreover, the accuracy of DNNs is heavily influenced by\nthe distribution of the training dataset. Distortions or perturbations in the\ncolor space of input images can introduce out-of-distribution data, resulting\nin misclassification. In this work, we propose a brightness-variation dataset,\nwhich incorporates 24 distinct brightness levels for each image within a subset\nof ImageNet. This dataset enables us to simulate the effects of light and\nshadow on the images, so as is to investigate the impact of light and shadow on\nthe performance of DNNs. In our study, we conduct experiments using several\nstate-of-the-art DNN architectures on the aforementioned dataset. Through our\nanalysis, we discover a noteworthy positive correlation between the brightness\nlevels and the loss of accuracy in DNNs. Furthermore, we assess the\neffectiveness of recently proposed robust training techniques and strategies,\nincluding AugMix, Revisit, and Free Normalizer, using the ResNet50 architecture\non our brightness-variation dataset. Our experimental results demonstrate that\nthese techniques can enhance the robustness of DNNs against brightness\nvariation, leading to improved performance when dealing with images exhibiting\nvarying brightness levels.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:30:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14166","submitter":"Itamar Allali","authors":"Itamar J. Allali, Fabrizio Rompineve, Mark P. Hertzberg","title":"Dark Sectors with Mass Thresholds Face Cosmological Datasets","comments":"18 + 18 pages, 38 figures and tables","journal-ref":null,"doi":null,"report-no":"CERN-TH-2023-084","categories":"astro-ph.CO hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Interacting dark sectors may undergo changes in the number of their\nrelativistic species during the early universe, due to a mass threshold $m$\n(similar to changes in the Standard Model bath), and in doing so affect the\ncosmic history. When such changes occur close to recombination, i.e., for\n$m\\sim (0.1-10)~\\text{eV}$, the stringent bound on the effective number of\nneutrino species, $N_{\\text{eff}}$, can be relaxed and the value of the Hubble\nexpansion rate $H_0$ inferred from Cosmic Microwave Background (CMB)\nobservations raised. We search for such sectors (with and without mass\nthresholds) in the latest cosmological datasets, including the full-shape (FS)\nof BOSS DR12 galaxy power spectrum. We perform a detailed analysis, accounting\nfor the choice of prior boundaries and additionally exploring the possible\neffects of dark sector interactions with (a fraction of) the dark matter. We\nfind $\\Delta N_{\\text{eff}}\\leq 0.55\\, (0.46)$ at 95% C.L. with (without) a\nmass threshold. While a significantly larger Hubble rate is achieved in this\nscenario, $H_0=69.01^{+0.66}_{-1.1}$, the overall fit to CMB+FS data does not\nprovide a compelling advantage over the $\\Lambda$CDM model. Furthermore, we\nfind that dark matter interactions with the dark sector do not significantly\nimprove the (matter fluctuations) $S_8$ tension with respect to the\n$\\Lambda$CDM model. Our work provides model-independent constraints on\n(decoupled) dark sectors with mass thresholds around the eV scale.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:33:19 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14167","submitter":"Renjie Pi","authors":"Renjie Pi, Jiahui Gao, Shizhe Diao, Rui Pan, Hanze Dong, Jipeng Zhang,\n  Lewei Yao, Jianhua Han, Hang Xu, Lingpeng Kong, Tong Zhang","title":"DetGPT: Detect What You Need via Reasoning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In recent years, the field of computer vision has seen significant\nadvancements thanks to the development of large language models (LLMs). These\nmodels have enabled more effective and sophisticated interactions between\nhumans and machines, paving the way for novel techniques that blur the lines\nbetween human and machine intelligence. In this paper, we introduce a new\nparadigm for object detection that we call reasoning-based object detection.\nUnlike conventional object detection methods that rely on specific object\nnames, our approach enables users to interact with the system using natural\nlanguage instructions, allowing for a higher level of interactivity. Our\nproposed method, called DetGPT, leverages state-of-the-art multi-modal models\nand open-vocabulary object detectors to perform reasoning within the context of\nthe user's instructions and the visual scene. This enables DetGPT to\nautomatically locate the object of interest based on the user's expressed\ndesires, even if the object is not explicitly mentioned. For instance, if a\nuser expresses a desire for a cold beverage, DetGPT can analyze the image,\nidentify a fridge, and use its knowledge of typical fridge contents to locate\nthe beverage. This flexibility makes our system applicable across a wide range\nof fields, from robotics and automation to autonomous driving. Overall, our\nproposed paradigm and DetGPT demonstrate the potential for more sophisticated\nand intuitive interactions between humans and machines. We hope that our\nproposed paradigm and approach will provide inspiration to the community and\nopen the door to more interative and versatile object detection systems. Our\nproject page is launched at detgpt.github.io.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:37:28 GMT"},{"version":"v2","created":"Wed, 24 May 2023 02:51:37 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14168","submitter":"Zizhuo Wang","authors":"Zizhuo Wang, Ziyang Xu, Xingxing Jia","title":"SXVCS: An XOR-based Visual Cryptography Scheme without Noise via Linear\n  Algebra","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Visual Cryptography Schemes (VCS) based on the \"XOR\" operation (XVCS) exhibit\nsignificantly smaller pixel expansion and higher contrast compared to those\nbased on the \"OR\" operation. Moreover, the \"XOR\" operation appears to possess\nsuperior qualities, as it effectively operates within a binary field, while the\n\"OR\" operation merely functions as a ring with identity. Despite these\nremarkable attributes, our understanding of XVCS remains limited. Especially,\nwe have done little about the noise in the reconstructed image up to now. In\nthis paper, we introduce a novel concept called Static XVCS (SXVCS), which\ncompletely eliminates the noise in the reconstructed image. We also demonstrate\nthat the equivalent condition for perfect white pixel reconstruction is simply\nthe existence of SXVCS. For its application, we naturally propose an efficient\nmethod for determining the existence of XVCS with perfect white pixel\nreconstruction. Furthermore, we apply our theorem to $(2,n)$-XVCS and achieve\nthe optimal state of $(2,n)$-XVCS.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:38:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14169","submitter":"Naihao Deng","authors":"Naihao Deng, Yikai Liu, Mingye Chen, Winston Wu, Siyang Liu, Yulong\n  Chen, Yue Zhang, Rada Mihalcea","title":"EASE: An Easily-Customized Annotation System Powered by Efficiency\n  Enhancement Mechanisms","comments":"20 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The performance of current supervised AI systems is tightly connected to the\navailability of annotated datasets. Annotations are usually collected through\nannotation tools, which are often designed for specific tasks and are difficult\nto customize. Moreover, existing annotation tools with an active learning\nmechanism often only support limited use cases. To address these limitations,\nwe present EASE, an Easily-Customized Annotation System Powered by Efficiency\nEnhancement Mechanisms. \\sysname provides modular annotation units for building\ncustomized annotation interfaces and also provides multiple back-end options\nthat suggest annotations using (1) multi-task active learning; (2) demographic\nfeature based active learning; (3) a prompt system that can query the API of\nlarge language models. We conduct multiple experiments and user studies to\nevaluate our system's flexibility and effectiveness. Our results show that our\nsystem can meet the diverse needs of NLP researchers and significantly\naccelerate the annotation process.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:38:37 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14170","submitter":"Shina Xu","authors":"Qianghui Guo, Yinglie Jin, Lisa H. Sun, Shina Xu","title":"Bijective enumeration of general stacks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO math.AC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Combinatorial enumeration of various RNA secondary structures and protein\ncontact maps, is of great interest for both combinatorists and computational\nbiologists. Enumeration of protein contact maps has considerable difficulties\ndue to the significant higher vertex degree than that of RNA secondary\nstructures. The state of art maximum vertex degree in previous works is two.\nThis paper proposes a solution for counting stacks in protein contact maps with\narbitrary vertex degree upper bound. By establishing bijection between such\ngeneral stacks and $m$-regular $\\Lambda$-avoiding $DLU$ paths, and counting the\npaths using theories of pattern avoiding lattice paths, we obtain a unified\nsystem of equations for generating functions of general stacks. We also show\nthat previous enumeration results for RNA secondary structures and protein\ncontact maps can be derived from the unified equation system as special cases.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:39:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14171","submitter":"Afra Amini","authors":"Afra Amini and Massimiliano Ciaramita","title":"Probing in Context: Toward Building Robust Classifiers via Probing Large\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models are able to learn new tasks in context, where they are\nprovided with instructions and a few annotated examples. However, the\neffectiveness of in-context learning is dependent to the provided context, and\nthe performance on a downstream task can vary a lot depending on the\ninstruction. Importantly, such dependency on the context can happen in\nunpredictable ways, e.g., a seemingly more informative instruction might lead\nto a worse performance. In this paper, we propose an alternative approach,\nwhich we term in-context probing. Similar to in-context learning, we\ncontextualize the representation of the input with an instruction, but instead\nof decoding the output prediction, we probe the contextualized representation\nto predict the label. Through a series of experiments on a diverse set of\nclassification tasks, we show that in-context probing is significantly more\nrobust to changes in instructions. We further show that probing can be\nparticularly helpful to build classifiers on top of smaller models, and with\nonly a hundred training examples.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:43:04 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14172","submitter":"Arash Nikoubashman","authors":"Takahiro Yokoyama and Yusei Kobayashi and Noriyoshi Arai and Arash\n  Nikoubashman","title":"Structure Formation of Amphiphilic Nanocubes at Rest and Under Shear","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the self-assembly of amphiphilic nanocubes under rest and\nshear using molecular dynamics (MD) simulations and kinetic Monte Carlo (KMC)\ncalculations. These particles combine both interaction and shape anisotropy,\nmaking them valuable models for studying folded proteins and DNA-functionalized\nnanoparticles. The nanocubes can self-assemble into various finite-sized\naggregates ranging from rods to self-avoiding random walks, depending on the\nnumber and placement of the hydrophobic faces. Our study focuses on suspensions\ncontaining multi- and one-patch cubes, with their ratio systematically varied.\nWhen the binding energy is comparable to the thermal energy, the aggregates\nconsist of only few cubes that spontaneously associate/dissociate. However,\nhighly stable aggregates emerge when the binding energy exceeds the thermal\nenergy. Generally, the mean aggregation number of the self-assembled clusters\nincreases with the number of hydrophobic faces and decreases with the fraction\nof one-patch cubes. In sheared suspensions, the more frequent collisions\nbetween nanocube clusters lead to faster aggregation dynamics but also to\nsmaller terminal steady-state mean cluster sizes. The MD and KMC simulations\nare in excellent agreement, and the analysis of the rate kernels enables the\nidentification of the primary mechanisms responsible for the (shear-induced)\ncluster growth and breakup.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:43:29 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14173","submitter":"Ziyun Zeng","authors":"Ziyun Zeng, Yixiao Ge, Zhan Tong, Xihui Liu, Shu-Tao Xia, Ying Shan","title":"TVTSv2: Learning Out-of-the-box Spatiotemporal Visual Representations at\n  Scale","comments":"Technical Report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ultimate goal for foundation models is realizing task-agnostic, i.e.,\nsupporting out-of-the-box usage without task-specific fine-tuning. Although\nbreakthroughs have been made in natural language processing and image\nrepresentation learning, it is still challenging for video models to reach it\ndue to the increasing uncertainty of spatiotemporal signals. To ease training,\nexisting works leverage image foundation models' prior knowledge and equip them\nwith efficient temporal modules. Despite the satisfactory fine-tuning\nperformance, we empirically find they fall short of out-of-the-box usage, given\nthe even degraded performance in zero-shot/linear protocols compared to their\nbaseline counterparts. In this work, we analyze the factor that leads to\ndegradation from the perspective of language supervision distortion. We argue\nthat tuning a text encoder end-to-end, as done in previous work, is suboptimal\nsince it may overfit in terms of styles, thereby losing its original\ngeneralization ability to capture the semantics of various language registers.\nThe overfitted text encoder, in turn, provides a harmful supervision signal,\ndegrading the video representation. To tackle this issue, we propose a\ndegradation-free pre-training strategy to retain the generalization ability of\nthe text encoder via freezing shallow layers while enabling the task-related\nsemantics capturing in tunable deep layers. As for the training objective, we\nadopted the transcript sorting task in TVTS incorporated with masking\ntechniques to enable scalable training. As a result, we produce a series of\nmodels, dubbed TVTSv2, with up to one billion parameters. We achieve new\nstate-of-the-arts on various video benchmarks with a frozen backbone,\nsurpassing the recent ImageBind, InternVideo, etc. Code is available at\nhttps://github.com/TencentARC/TVTS.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:44:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14174","submitter":"Dongcheng Zhao","authors":"Dongcheng Zhao, Guobin Shen, Yiting Dong, Yang Li, Yi Zeng","title":"Improving Stability and Performance of Spiking Neural Networks through\n  Enhancing Temporal Consistency","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spiking neural networks have gained significant attention due to their\nbrain-like information processing capabilities. The use of surrogate gradients\nhas made it possible to train spiking neural networks with backpropagation,\nleading to impressive performance in various tasks. However, spiking neural\nnetworks trained with backpropagation typically approximate actual labels using\nthe average output, often necessitating a larger simulation timestep to enhance\nthe network's performance. This delay constraint poses a challenge to the\nfurther advancement of SNNs. Current training algorithms tend to overlook the\ndifferences in output distribution at various timesteps. Particularly for\nneuromorphic datasets, inputs at different timesteps can cause inconsistencies\nin output distribution, leading to a significant deviation from the optimal\ndirection when combining optimization directions from different moments. To\ntackle this issue, we have designed a method to enhance the temporal\nconsistency of outputs at different timesteps. We have conducted experiments on\nstatic datasets such as CIFAR10, CIFAR100, and ImageNet. The results\ndemonstrate that our algorithm can achieve comparable performance to other\noptimal SNN algorithms. Notably, our algorithm has achieved state-of-the-art\nperformance on neuromorphic datasets DVS-CIFAR10 and N-Caltech101, and can\nachieve superior performance in the test phase with timestep T=1.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:50:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14175","submitter":"Stefan Strohauer","authors":"Stefan Strohauer, Fabian Wietschorke, Lucio Zugliani, Rasmus\n  Flaschmann, Christian Schmid, Stefanie Grotowski, Manuel M\\\"uller, Bj\\\"orn\n  Jonas, Matthias Althammer, Rudolf Gross, Kai M\\\"uller, Jonathan J. Finley","title":"Site-Selective Enhancement of Superconducting Nanowire Single-Photon\n  Detectors via Local Helium Ion Irradiation","comments":"12 pages, 11 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mes-hall cond-mat.supr-con physics.ins-det physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Achieving homogeneous performance metrics between nominally identical pixels\nis challenging for the operation of arrays of superconducting nanowire\nsingle-photon detectors (SNSPDs). Here, we utilize local helium ion irradiation\nto post-process and tune single-photon detection efficiency, switching current,\nand critical temperature of individual devices on the same chip. For 12nm thick\nhighly absorptive SNSPDs, which are barely single-photon sensitive prior to\nirradiation, we observe an increase of the system detection efficiency from $<\n0.05\\,\\%$ to $(55.3 \\pm 1.1)\\,\\%$ following irradiation. Moreover, the internal\ndetection efficiency saturates at a temperature of 4.5 K after irradiation with\n$1800\\, \\mathrm{ions}\\, \\mathrm{nm}^{-2}$. For irradiated 10 nm thick detectors\nwe observe a doubling of the switching current (to $20\\, \\mu\\mathrm{A}$)\ncompared to 8 nm SNSPDs of similar detection efficiency, increasing the\namplitude of detection voltage pulses. Investigations of the scaling of\nsuperconducting thin film properties with irradiation up to a fluence of\n$2600\\, \\mathrm{ions}\\, \\mathrm{nm}^{-2}$ revealed an increase of sheet\nresistance and a decrease of critical temperature towards high fluences. A\nphysical model accounting for defect generation and sputtering during helium\nion irradiation is presented and shows good qualitative agreement with\nexperiments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:51:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14176","submitter":"Christian Sch\\\"u{\\ss}ler","authors":"Christian Sch\\\"u{\\ss}ler, Marcel Hoffmann, Vanessa Wirth, Bj\\\"orn\n  Eskofier, Tim Weyrich, Marc Stamminger, Martin Vossiek","title":"Achieving Efficient and Realistic Full-Radar Simulations and Automatic\n  Data Annotation by exploiting Ray Meta Data of a Radar Ray Tracing Simulator","comments":"Accepted for IEEE RadarConf 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work a novel radar simulation concept is introduced that allows to\nsimulate realistic radar data for Range, Doppler, and for arbitrary antenna\npositions in an efficient way. Further, it makes it possible to automatically\nannotate the simulated radar signal by allowing to decompose it into different\nparts. This approach allows not only almost perfect annotations possible, but\nalso allows the annotation of exotic effects, such as multi-path effects or to\nlabel signal parts originating from different parts of an object. This is\npossible by adapting the computation process of a Monte Carlo shooting and\nbouncing rays (SBR) simulator. By considering the hits of each simulated ray,\nvarious meta data can be stored such as hit position, mesh pointer, object IDs,\nand many more. This collected meta data can then be utilized to predict the\nchange of path lengths introduced by object motion to obtain Doppler\ninformation or to apply specific ray filter rules in order obtain radar signals\nthat only fulfil specific conditions, such as multiple bounces or containing\nspecific object IDs. Using this approach, perfect and otherwise almost\nimpossible annotations schemes can be realized.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:55:10 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14177","submitter":"Chris Beeler","authors":"Chris Beeler, Sriram Ganapathi Subramanian, Kyle Sprague, Nouha\n  Chatti, Colin Bellinger, Mitchell Shahen, Nicholas Paquin, Mark Baula,\n  Amanuel Dawit, Zihan Yang, Xinkai Li, Mark Crowley, Isaac Tamblyn","title":"ChemGymRL: An Interactive Framework for Reinforcement Learning for\n  Digital Chemistry","comments":"19 pages, 13 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper provides a simulated laboratory for making use of Reinforcement\nLearning (RL) for chemical discovery. Since RL is fairly data intensive,\ntraining agents `on-the-fly' by taking actions in the real world is infeasible\nand possibly dangerous. Moreover, chemical processing and discovery involves\nchallenges which are not commonly found in RL benchmarks and therefore offer a\nrich space to work in. We introduce a set of highly customizable and\nopen-source RL environments, ChemGymRL, based on the standard Open AI Gym\ntemplate. ChemGymRL supports a series of interconnected virtual chemical\nbenches where RL agents can operate and train. The paper introduces and details\neach of these benches using well-known chemical reactions as illustrative\nexamples, and trains a set of standard RL algorithms in each of these benches.\nFinally, discussion and comparison of the performances of several standard RL\nmethods are provided in addition to a list of directions for future work as a\nvision for the further development and usage of ChemGymRL.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:56:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14178","submitter":"Tugkan Batu","authors":"Tugkan Batu and Chhaya Trehan","title":"A Distributed Conductance Tester Without Global Information Collection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Given an undirected graph $G$ and a conductance parameter $\\alpha$, the\nproblem of testing whether $G$ has conductance at least $\\alpha$ or is far from\nhaving conductance at least $\\Omega(\\alpha^2)$ has been extensively studied for\nbounded-degree graphs in the classic property testing model. In the last few\nyears, the same problem has also been addressed in non-sequential models of\ncomputing such as MPC and distributed CONGEST. However, all the algorithms in\nthese models like their classic counterparts apply an aggregate function over\nsome statistics pertaining to a set of random walks on $G$ as a test criteria.\nThe only distributed CONGEST algorithm for the problem\nby~\\cite{VasudevDistributed} tests conductance of the underlying network in the\nunbounded degree graph model. Their algorithm builds a rooted spanning tree of\nthe underlying network to collect information at the root and then applies an\naggregate function to this information. We ask the question whether the\nparallelism offered by distributed computing can be exploited to avoid\ninformation collection and answer it in affirmative. We propose a new algorithm\nwhich also performs a set of random walks on $G$ but does not collect any\nstatistic at a central node. In fact, we show that for an appropriate\nstatistic, each node has sufficient information to decide on its own whether to\naccept or not. Given an $n$-vertex, $m$-edge undirected, unweighted graph $G$,\na conductance parameter $\\alpha$, and a distance parameter $\\epsilon$, our\ndistributed conductance tester accepts $G$ if $G$ has conductance at least\n$\\alpha$ and rejects $G$ if $G$ is $\\epsilon$-far from having conductance\n$\\Omega(\\alpha^2)$ and does so in $O(\\log n)$ rounds of communication. Unlike\nthe algorithm of \\cite{VasudevDistributed}, our algorithm does not rely on the\nwasteful construction of a spanning tree and information accumulation at its\nroot.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:56:20 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14179","submitter":"Ming Zhang","authors":"Jiayu Yin, Jie Jiang, Ming Zhang","title":"Kinematic topologies of black holes","comments":"5 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We investigate the kinematic topologies of light rings (LRs) and massive\nparticle rings (PRs) encircling spherical and axisymmetric black holes. Our\nresults demonstrate that the global topology number of LRs is consistently -1,\nindependent of the spacetime background's asymptotic property. Additionally, we\nshow that the global topology of PRs varies, with a value of 0 in\nasymptotically flat and Anti-de Sitter spacetime but -1 in asymptotic de Sitter\nspacetime.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:57:56 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14180","submitter":"Antonio Giganti","authors":"Antonio Giganti, Sara Mandelli, Paolo Bestagini, Marco Marcon, Stefano\n  Tubaro","title":"Multi-BVOC Super-Resolution Exploiting Compounds Inter-Connection","comments":"5 pages, 4 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Biogenic Volatile Organic Compounds (BVOCs) emitted from the terrestrial\necosystem into the Earth's atmosphere are an important component of atmospheric\nchemistry. Due to the scarcity of measurement, a reliable enhancement of BVOCs\nemission maps can aid in providing denser data for atmospheric chemical,\nclimate, and air quality models. In this work, we propose a strategy to\nsuper-resolve coarse BVOC emission maps by simultaneously exploiting the\ncontributions of different compounds. To this purpose, we first accurately\ninvestigate the spatial inter-connections between several BVOC species. Then,\nwe exploit the found similarities to build a Multi-Image Super-Resolution\n(MISR) system, in which a number of emission maps associated with diverse\ncompounds are aggregated to boost Super-Resolution (SR) performance. We compare\ndifferent configurations regarding the species and the number of joined BVOCs.\nOur experimental results show that incorporating BVOCs' relationship into the\nprocess can substantially improve the accuracy of the super-resolved maps.\nInterestingly, the best results are achieved when we aggregate the emission\nmaps of strongly uncorrelated compounds. This peculiarity seems to confirm what\nwas already guessed for other data-domains, i.e., joined uncorrelated\ninformation are more helpful than correlated ones to boost MISR performance.\nNonetheless, the proposed work represents the first attempt in SR of BVOC\nemissions through the fusion of multiple different compounds.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:58:53 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14386","submitter":"Zhenwen Liang","authors":"Zhenwen Liang, Wenhao Yu, Tanmay Rajpurohit, Peter Clark, Xiangliang\n  Zhang, Ashwin Kaylan","title":"Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with\n  Customized Exercise Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present a novel approach for distilling math word problem\nsolving capabilities from large language models (LLMs) into smaller, more\nefficient student models. Our approach is designed to consider the student\nmodel's weaknesses and foster a tailored learning experience by generating\ntargeted exercises aligned with educational science principles, such as\nknowledge tracing and personalized learning. Concretely, we let GPT-3 be a math\ntutor and run two steps iteratively: 1) assessing the student model's current\nlearning status on a GPT-generated exercise book, and 2) improving the student\nmodel by training it with tailored exercise samples generated by GPT-3.\nExperimental results reveal that our approach outperforms LLMs (e.g., GPT-3 and\nPaLM) in accuracy across three distinct benchmarks while employing\nsignificantly fewer parameters. Furthermore, we provide a comprehensive\nanalysis of the various components within our methodology to substantiate their\nefficacy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:36:14 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14387","submitter":"Tianyi Zhang","authors":"Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani,\n  Jimmy Ba, Carlos Guestrin, Percy Liang, Tatsunori B. Hashimoto","title":"AlpacaFarm: A Simulation Framework for Methods that Learn from Human\n  Feedback","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models (LLMs) such as ChatGPT have seen widespread adoption\ndue to their ability to follow user instructions well. Developing these LLMs\ninvolves a complex yet poorly understood workflow requiring training with human\nfeedback. Replicating and understanding this instruction-following process\nfaces three major challenges: the high cost of data collection, the lack of\ntrustworthy evaluation, and the absence of reference method implementations. We\naddress these challenges with AlpacaFarm, a simulator that enables research and\ndevelopment for learning from feedback at a low cost. First, we design LLM\nprompts to simulate human feedback that are 45x cheaper than crowdworkers and\ndisplay high agreement with humans. Second, we propose an automatic evaluation\nand validate it against human instructions obtained on real-world interactions.\nThird, we contribute reference implementations for several methods (PPO,\nbest-of-n, expert iteration, and more) that learn from pairwise feedback.\nFinally, as an end-to-end validation of AlpacaFarm, we train and evaluate\neleven models on 10k pairs of real human feedback and show that rankings of\nmodels trained in AlpacaFarm match rankings of models trained on human data. As\na demonstration of the research possible in AlpacaFarm, we find that methods\nthat use a reward model can substantially improve over supervised fine-tuning\nand that our reference PPO implementation leads to a +10% improvement in\nwin-rate against Davinci003. We release all components of AlpacaFarm at\nhttps://github.com/tatsu-lab/alpaca_farm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:55:50 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14388","submitter":"Zuzanna Szyma\\'nska Ph.D.","authors":"Zuzanna Szyma\\'nska and Miros{\\l}aw Lachowicz and Nikolaos Sfakianakis\n  and Mark A. J. Chaplain","title":"Mathematical modelling of cancer invasion: Phenotypic transitioning\n  provides insight into multifocal foci formation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.TO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The transition from the epithelial to mesenchymal phenotype and its reverse\n(from mesenchymal to epithelial) are crucial processes necessary for the\nprogression and spread of cancer. In this paper, we investigate how phenotypic\nswitching at the cancer cell level impacts on behaviour at the tissue level,\nspecifically on the emergence of isolated foci of the invading solid tumour\nmass leading to a multifocal tumour. To this end, we propose a new mathematical\nmodel of cancer invasion that includes the influence of cancer cell phenotype\non the rate of invasion and metastasis. The implications of model are explored\nthrough numerical simulations revealing that the plasticity of tumour cell\nphenotypes appears to be crucial for disease progression and local invasive\nspread. The computational simulations show the progression of the invasive\nspread of a primary cancer reminiscent of in vivo multifocal breast carcinomas,\nwhere multiple, synchronous, ipsilateral neoplastic foci are frequently\nobserved and are associated with a poorer patient prognosis.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 19:43:30 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14389","submitter":"Vardhan Jai","authors":"Jai Vardhan, Ghanta Sai Krishna","title":"Breast Cancer Segmentation using Attention-based Convolutional Network\n  and Explainable AI","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Breast cancer (BC) remains a significant health threat, with no long-term\ncure currently available. Early detection is crucial, yet mammography\ninterpretation is hindered by high false positives and negatives. With BC\nincidence projected to surpass lung cancer, improving early detection methods\nis vital. Thermography, using high-resolution infrared cameras, offers promise,\nespecially when combined with artificial intelligence (AI). This work presents\nan attention-based convolutional neural network for segmentation, providing\nincreased speed and precision in BC detection and classification. The system\nenhances images and performs cancer segmentation with explainable AI. We\npropose a transformer-attention-based convolutional architecture (UNet) for\nfault identification and employ Gradient-weighted Class Activation Mapping\n(Grad-CAM) to analyze areas of bias and weakness in the UNet architecture with\nIRT images. The superiority of our proposed framework is confirmed when\ncompared with existing deep learning frameworks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:49:20 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14390","submitter":"Danielle J. Harper","authors":"Danielle J. Harper, Yongjoo Kim, Alejandra G\\'omez-Ram\\'irez, Benjamin\n  J. Vakoc","title":"Needle guidance with Doppler-tracked polarization-sensitive optical\n  coherence tomography","comments":"11 pages, 4 figures. Supplemental videos can be found here:\n  https://github.com/BenVakocLab/needle_videos","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We demonstrate that a simple, unscanned polarization-sensitive optical\ncoherence tomography needle probe can be used to perform layer identification\nin biological tissues. Broadband light from a laser centered at 1310 nm was\nsent through a fiber that was embedded into a needle, and analysis of the\npolarization state of the returning light after interference coupled with\nDoppler-based tracking allowed the calculation of phase retardation and optic\naxis orientation at each needle location. Proof-of-concept phase retardation\nmapping was shown in Atlantic salmon tissue, while axis orientation mapping was\ndemonstrated in white shrimp tissue. The needle probe was then tested on the ex\nvivo porcine spine, where mock epidural procedures were performed. Our imaging\nresults demonstrate that unscanned, Doppler-tracked polarization-sensitive\noptical coherence tomography imaging successfully identified the skin,\nsubcutaneous tissue, and ligament layers, before successfully reaching the\ntarget of the epidural space. The addition of polarization-sensitive imaging\ninto the bore of a needle probe therefore allows layer identification at deeper\nlocations in the tissue.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:29:51 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14391","submitter":"Xiuwen Zheng","authors":"Xiuwen Zheng, Subhasis Dasgupta, Arun Kumar, Amarnath Gupta","title":"An Optimized Tri-store System for Multi-model Data Analytics","comments":"arXiv admin note: substantial text overlap with arXiv:2112.00833","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data science applications increasingly rely on heterogeneous data sources and\nanalytics. This has led to growing interest in polystore systems, especially\nanalytical polystores. In this work, we focus on a class of emerging multi-data\nmodel analytics workloads that fluidly straddle relational, graph, and text\nanalytics. Instead of a generic polystore, we build a ``tri-store'' system that\nis more aware of the underlying data models to better optimize execution to\nimprove scalability and runtime efficiency. We name our system AWESOME\n(Analytics WorkbEnch for SOcial MEdia). It features a powerful domain-specific\nlanguage named ADIL. ADIL builds on top of underlying query engines (e.g., SQL\nand Cypher) and features native data types for succinctly specifying\ncross-engine queries and NLP operations, as well as automatic in-memory and\nquery optimizations. Using real-world tri-model analytical workloads and\ndatasets, we empirically demonstrate the functionalities of AWESOME for\nscalable data science applications and evaluate its efficiency.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:38:29 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14392","submitter":"Amogh Joshi","authors":"Amogh Joshi, Adarsh Kosta, Wachirawit Ponghiran, Manish Nagaraj,\n  Kaushik Roy","title":"FEDORA: Flying Event Dataset fOr Reactive behAvior","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.ET cs.LG cs.NE cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ability of living organisms to perform complex high speed manoeuvers in\nflight with a very small number of neurons and an incredibly low failure rate\nhighlights the efficacy of these resource-constrained biological systems.\nEvent-driven hardware has emerged, in recent years, as a promising avenue for\nimplementing complex vision tasks in resource-constrained environments.\nVision-based autonomous navigation and obstacle avoidance consists of several\nindependent but related tasks such as optical flow estimation, depth\nestimation, Simultaneous Localization and Mapping (SLAM), object detection, and\nrecognition. To ensure coherence between these tasks, it is imperative that\nthey be trained on a single dataset. However, most existing datasets provide\nonly a selected subset of the required data. This makes inter-network coherence\ndifficult to achieve. Another limitation of existing datasets is the limited\ntemporal resolution they provide. To address these limitations, we present\nFEDORA, a first-of-its-kind fully synthetic dataset for vision-based tasks,\nwith ground truths for depth, pose, ego-motion, and optical flow. FEDORA is the\nfirst dataset to provide optical flow at three different frequencies - 10Hz,\n25Hz, and 50Hz\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:59:05 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14393","submitter":"Robert Reynolds","authors":"Robert Reynolds","title":"Finite Sums and Products involving Special Functions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Various product and sum relationships are established using special\nfunctions, specifically involving Special functions. These relationships are\nderived from formulas inspired by the finite sum that incorporates the\nHurwitz-Lerch zeta function.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 02:48:22 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14394","submitter":"Ashwin Viswanathan Kannan","authors":"Ashwin Viswanathan Kannan, Goutam Mylavarapu and Johnson P Thomas","title":"Unsupervised Spiking Neural Network Model of Prefrontal Cortex to study\n  Task Switching with Synaptic deficiency","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI cs.LG q-bio.NC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we build a computational model of Prefrontal Cortex (PFC)\nusing Spiking Neural Networks (SNN) to understand how neurons adapt and respond\nto tasks switched under short and longer duration of stimulus changes. We also\nexplore behavioral deficits arising out of the PFC lesions by simulating\nlesioned states in our Spiking architecture model. Although there are some\ncomputational models of the PFC, SNN's have not been used to model them. In\nthis study, we use SNN's having parameters close to biologically plausible\nvalues and train the model using unsupervised Spike Timing Dependent Plasticity\n(STDP) learning rule. Our model is based on connectionist architectures and\nexhibits neural phenomena like sustained activity which helps in generating\nshort-term or working memory. We use these features to simulate lesions by\ndeactivating synaptic pathways and record the weight adjustments of learned\npatterns and capture the accuracy of learning tasks in such conditions. All our\nexperiments are trained and recorded using a real-world Fashion MNIST (FMNIST)\ndataset and through this work, we bridge the gap between bio-realistic models\nand those that perform well in pattern recognition tasks\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 05:59:54 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14395","submitter":"Naveed Akhtar Dr.","authors":"Naveed Akhtar, Muhammad A. A. K. Jalwana","title":"Towards credible visual model interpretation with path attribution","comments":"ICML'23 paper (text improved for CV community)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Originally inspired by game-theory, path attribution framework stands out\namong the post-hoc model interpretation tools due to its axiomatic nature.\nHowever, recent developments show that this framework can still suffer from\ncounter-intuitive results. Moreover, specifically for deep visual models, the\nexisting path-based methods also fall short on conforming to the original\nintuitions that are the basis of the claimed axiomatic properties of this\nframework. We address these problems with a systematic investigation, and\npinpoint the conditions in which the counter-intuitive results can be avoided\nfor deep visual model interpretation with the path attribution strategy. We\nalso devise a scheme to preclude the conditions in which visual model\ninterpretation can invalidate the axiomatic properties of path attribution.\nThese insights are combined into a method that enables reliable visual model\ninterpretation. Our findings are establish empirically with multiple datasets,\nmodels and evaluation metrics. Extensive experiments show a consistent\nperformance gain of our method over the baselines.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:23:08 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14396","submitter":"Ying Xiao","authors":"Ying Xiao, Shangwen Wang, Sicen Liu, Dingyuan Xue, Xian Zhan, Yepang\n  Liu","title":"FITNESS: A Causal De-correlation Approach for Mitigating Bias in Machine\n  Learning Software","comments":"12 pages, 7 figures and 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Software built on top of machine learning algorithms is becoming increasingly\nprevalent in a variety of fields, including college admissions, healthcare,\ninsurance, and justice. The effectiveness and efficiency of these systems\nheavily depend on the quality of the training datasets. Biased datasets can\nlead to unfair and potentially harmful outcomes, particularly in such critical\ndecision-making systems where the allocation of resources may be affected. This\ncan exacerbate discrimination against certain groups and cause significant\nsocial disruption. To mitigate such unfairness, a series of bias-mitigating\nmethods are proposed. Generally, these studies improve the fairness of the\ntrained models to a certain degree but with the expense of sacrificing the\nmodel performance. In this paper, we propose FITNESS, a bias mitigation\napproach via de-correlating the causal effects between sensitive features\n(e.g., the sex) and the label. Our key idea is that by de-correlating such\neffects from a causality perspective, the model would avoid making predictions\nbased on sensitive features and thus fairness could be improved. Furthermore,\nFITNESS leverages multi-objective optimization to achieve a better\nperformance-fairness trade-off. To evaluate the effectiveness, we compare\nFITNESS with 7 state-of-the-art methods in 8 benchmark tasks by multiple\nmetrics. Results show that FITNESS can outperform the state-of-the-art methods\non bias mitigation while preserve the model's performance: it improved the\nmodel's fairness under all the scenarios while decreased the model's\nperformance under only 26.67% of the scenarios. Additionally, FITNESS surpasses\nthe Fairea Baseline in 96.72% cases, outperforming all methods we compared.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:24:43 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14397","submitter":"Chenguang Lu","authors":"Chenguang Lu","title":"Reviewing Evolution of Learning Functions and Semantic Information\n  Measures for Understanding Deep Learning","comments":"34 pages, 9 figures. published in Entropy, 2023","journal-ref":null,"doi":"10.3390/e25050802","report-no":null,"categories":"cs.IT cs.LG math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A new trend in deep learning, represented by Mutual Information Neural\nEstimation (MINE) and Information Noise Contrast Estimation (InfoNCE), is\nemerging. In this trend, similarity functions and Estimated Mutual Information\n(EMI) are used as learning and objective functions. Coincidentally, EMI is\nessentially the same as Semantic Mutual Information (SeMI) proposed by the\nauthor 30 years ago. This paper first reviews the evolutionary histories of\nsemantic information measures and learning functions. Then, it briefly\nintroduces the author's semantic information G theory with the rate-fidelity\nfunction R(G) (G denotes SeMI, and R(G) extends R(D)) and its applications to\nmulti-label learning, the maximum Mutual Information (MI) classification, and\nmixture models. Then it discusses how we should understand the relationship\nbetween SeMI and Shan-non's MI, two generalized entropies (fuzzy entropy and\ncoverage entropy), Autoencoders, Gibbs distributions, and partition functions\nfrom the perspective of the R(G) function or the G theory. An important\nconclusion is that mixture models and Restricted Boltzmann Machines converge\nbecause SeMI is maximized, and Shannon's MI is minimized, making information\nefficiency G/R close to 1. A potential opportunity is to simplify deep learning\nby using Gaussian channel mixture models for pre-training deep neural networks'\nlatent layers without considering gradients. It also discusses how the SeMI\nmeasure is used as the reward function (reflecting purposiveness) for\nreinforcement learning. The G theory helps interpret deep learning but is far\nfrom enough. Combining semantic information theory and deep learning will\naccelerate their development.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:32:49 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14398","submitter":"Athanasios Stratikopoulos","authors":"Ales Kubicek, Athanasios Stratikopoulos, Juan Fumero, Nikos Foutris,\n  Christos Kotselidis","title":"TornadoQSim: An Open-source High-Performance and Modular Quantum Circuit\n  Simulation Framework","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.ET","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we present TornadoQSim, an open-source quantum circuit\nsimulation framework implemented in Java. The proposed framework has been\ndesigned to be modular and easily expandable for accommodating different\nuser-defined simulation backends, such as the unitary matrix simulation\ntechnique. Furthermore, TornadoQSim features the ability to interchange\nsimulation backends that can simulate arbitrary quantum circuits. Another novel\naspect of TornadoQSim over other quantum simulators is the transparent hardware\nacceleration of the simulation backends on heterogeneous devices. TornadoQSim\nemploys TornadoVM to automatically compile parts of the simulation backends\nonto heterogeneous hardware, thereby addressing the fragmentation in\ndevelopment due to the low-level heterogeneous programming models. The\nevaluation of TornadoQSim has shown that the transparent utilization of GPU\nhardware can result in up to 506.5$x$ performance speedup when compared to the\nvanilla Java code for a fully entangled quantum circuit of 11 qubits. Other\nevaluated quantum algorithms have been the Deutsch-Jozsa algorithm (493.10$x$\nspeedup for a 11-qubit circuit) and the quantum Fourier transform algorithm\n(518.12$x$ speedup for a 11-qubit circuit). Finally, the best TornadoQSim\nimplementation of unitary matrix has been evaluated against a semantically\nequivalent simulation via Qiskit. The comparative evaluation has shown that the\nsimulation with TornadoQSim is faster for small circuits, while for large\ncircuits Qiskit outperforms TornadoQSim by an order of magnitude.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:41:24 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14399","submitter":"Pin-Jung Chen","authors":"Pin-Jung Chen and Po-Yan Tseng","title":"Type Ia Supernovae Induced by Primordial Black Holes from Dark\n  First-Order Phase Transition","comments":"15 pages, 4 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A primordial black hole (PBH) with mass $10^{-15}\\leq M_{\\rm\nPBH}/M_{\\odot}\\leq 10^{-10}$ is currently beyond the sensitivity of both\nmicrolensing and black hole (BH) evaporation methods. A novel scenario has been\nproposed: When a PBH with mass $10^{-14}\\leq M_{\\rm PBH}/M_{\\odot}\\leq\n10^{-11}$ transits through a white dwarf (WD) made up of carbon and oxygen,\nBondi-Hoyle-Lyttleton (BHL) accretion in a reactive medium creates a shock\nwave, which generates direct detonation ignition in the WD core and then leads\nto thermonuclear supernovae (SNe Ia). The aim of this study is to impose\nconstraints on the PBH to dark matter (DM) abundance fraction, $f_{\\rm PBH}$,\nvia comparing the SN Ia event rates between PBH hypotheses and observational\ndata. For PBH fraction less than unity, we found the observed event rate\nprefers PBH mass region, $7.6\\times 10^{-13}\\leq M_{\\rm PBH}/M_{\\odot}\\leq\n6.1\\times 10^{-12}$, under the Navarro-Frenk-White (NFW) profile. Meanwhile,\nthe aforementioned PBH mass and abundance can be efficiently produced via a\ncosmological first-order phase transition (FOPT) in dark sector which\nassociates with $\\mathcal{O}({\\rm MeV})$ energy scale and thus gives rise to\ncomplementary signals of stochastic gravitational waves (GWs) from $10^{-6}$ Hz\nto $10^{-5}$ Hz peak frequency which can be probed by future $\\mu$Ares GW\ninterferometer.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:54:04 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14400","submitter":"Gopi Kant Goswami Dr","authors":"Anirudh Pradhan, Gopikant Goswami, Syamala Krishnannair","title":"The Reconstruction of Constant Jerk Parameter with $f(R,T)$ Gravity in\n  Bianchi-I spacetime","comments":"19 pages, 19 figures. The European Physical Journal Plus. 2023. arXiv\n  admin note: text overlap with arXiv:2303.14136","journal-ref":null,"doi":"10.1140/epjp/s13360-023-04057-3","report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We have developed a Bianchi I cosmological model of the universe in $f(R,T)$\ngravity theory which fit good with the present day scenario of accelerating\nuniverse. The model displays transition from deceleration in the past to the\nacceleration at the present. As in the $\\Lambda$CDM model, we have defined the\nthree energy parameters $\\Omega_m$, $\\Omega_{\\mu}$ and $\\Omega_{\\sigma}$ such\nthat $\\Omega_m$ + $\\Omega_{\\mu}$ + $\\Omega_{\\sigma}$ = 1. The parameter\n$\\Omega_m$ is the matter energy density (baryons + dark matter), $\\Omega_{\\mu}$\nis the energy density associated with the Ricci scalar $R$ and the trace $T$ of\nthe energy momentum tensor and $\\Omega_{\\sigma}$ is the energy density\nassociated with the anisotropy of the universe. We shall call $\\Omega_{\\mu}$\ndominant over the other two due to its higher value. We find that the\n$\\Omega_{\\mu}$ and the other two in the ratio 3:1. 46 Hubble OHD data set is\nused to estimate present values of Hubble $H_0$, deceleration $q_0$ and jerk\n$j$ parameters. 1$\\sigma$, 2$\\sigma$ and 3$\\sigma$ contour region plots for the\nestimated values of parameters are presented. 580 SNIa supernova distance\nmodulus data set and 66 pantheon SNIa data which include high red shift data in\nthe range $0\\leq z\\leq 2.36$ have been used to draw error bar plots and\nlikelihood probability curves for distance modulus and apparent magnitude of\nSNIa supernova's. We have calculated the pressures and densities associated\nwith the two matter densities, viz., $p_{\\mu}$, $\\rho_{\\mu}$, $p_m$ and\n$\\rho_m$, respectively. The present age of the universe as per our model is\nalso evaluated and it is found at par with the present observed values.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:08:35 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14401","submitter":"Ramachandran S","authors":"Ramachandran S","title":"Isomorphic pastings and the two possible structures for a pair of graphs\n  having the same deck","comments":"20 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  When G denotes a graph, the unlabeled subgraph obtained by deleting a vertex\nfrom G is called a card of G and the collection of all cards of G is the deck\nof G. A graph having the same deck as G is called a hypomorph of G. A graph is\ncalled reconstructible if it is isomorphic to all its hypomorphs.\nReconstruction Conjecture claims that all graphs are reconstructible and it is\nopen. A representation of a hypomorph of G in terms of two of its cards, called\npasting, is introduced. Isomorphic pastings of two cards is defined. In the\ncase of a digraph, a card with which the degree triple of the deleted vertex is\nalso given is called a degree associated card or dacard. Dadeck,\ndareconstructible digraphs, dapastings and isomorphic dapastings based on\ndacards are defined analogously. DARC claims that all digraphs are\ndareconstructible and it is also open. Results: Two hypomorphs G and H of a\ngraph are isomorphic if and only if a pair of cards in their common deck is\npasted isomorphically in both G and H. Either every pair of cards in their\ncommon deck is pasted isomorphically in both G and H, or no pair of cards is\npasted isomorphically in both G and H. Results analogous to the above hold for\ndapastings in dahypomorphs of a digraph. Some results on pastings are proved\nand two graph parameters are reconstructed. The neighborhood degree quintuple\nof a vertex and a new family of digraphs are dareconstructible. New approaches\nfor proving the reconstruction conjecture and DARC by the method of\ncontradiction arise.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:13:42 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14402","submitter":"Thejan Rajapakshe","authors":"Thejan Rajapakshe, Rajib Rana, Sara Khalifa, Berrak Sisman, Bj\\\"orn\n  Schuller","title":"Improving Speech Emotion Recognition Performance using Differentiable\n  Architecture Search","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Speech Emotion Recognition (SER) is a critical enabler of emotion-aware\ncommunication in human-computer interactions. Deep Learning (DL) has improved\nthe performance of SER models by improving model complexity. However, designing\nDL architectures requires prior experience and experimental evaluations.\nEncouragingly, Neural Architecture Search (NAS) allows automatic search for an\noptimum DL model. In particular, Differentiable Architecture Search (DARTS) is\nan efficient method of using NAS to search for optimised models. In this paper,\nwe propose DARTS for a joint CNN and LSTM architecture for improving SER\nperformance. Our choice of the CNN LSTM coupling is inspired by results showing\nthat similar models offer improved performance. While SER researchers have\nconsidered CNNs and RNNs separately, the viability of using DARTs jointly for\nCNN and LSTM still needs exploration. Experimenting with the IEMOCAP dataset,\nwe demonstrate that our approach outperforms best-reported results using DARTS\nfor SER.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:16:08 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14403","submitter":"Siyuan Pan","authors":"Siyuan Pan, Linna Zhang, Jie Zhang, Xiaoshuang Li, Liang Hou, Xiaobing\n  Tu","title":"Layer-adaptive Structured Pruning Guided by Latency","comments":"arXiv admin note: text overlap with arXiv:2010.07611,\n  arXiv:2110.10811 by other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Structured pruning can simplify network architecture and improve inference\nspeed. Combined with the underlying hardware and inference engine in which the\nfinal model is deployed, better results can be obtained by using latency\ncollaborative loss function to guide network pruning together. Existing pruning\nmethods that optimize latency have demonstrated leading performance, however,\nthey often overlook the hardware features and connection in the network. To\naddress this problem, we propose a global importance score SP-LAMP(Structured\nPruning Layer-Adaptive Magnitude-based Pruning) by deriving a global importance\nscore LAMP from unstructured pruning to structured pruning. In SP-LAMP, each\nlayer includes a filter with an SP-LAMP score of 1, and the remaining filters\nare grouped. We utilize a group knapsack solver to maximize the SP-LAMP score\nunder latency constraints. In addition, we improve the strategy of collect the\nlatency to make it more accurate. In particular, for ResNet50/ResNet18 on\nImageNet and CIFAR10, SP-LAMP is 1.28x/8.45x faster with +1.7%/-1.57% top-1\naccuracy changed, respectively. Experimental results in ResNet56 on CIFAR10\ndemonstrate that our algorithm achieves lower latency compared to alternative\napproaches while ensuring accuracy and FLOPs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:18:37 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14404","submitter":"Shuqiang Wang","authors":"Qiankun Zuo, Baiying Lei, Ning Zhong, Yi Pan, Shuqiang Wang","title":"Brain Structure-Function Fusing Representation Learning using\n  Adversarial Decomposed-VAE for Analyzing MCI","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.NC cs.AI cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Integrating the brain structural and functional connectivity features is of\ngreat significance in both exploring brain science and analyzing cognitive\nimpairment clinically. However, it remains a challenge to effectively fuse\nstructural and functional features in exploring the brain network. In this\npaper, a novel brain structure-function fusing-representation learning (BSFL)\nmodel is proposed to effectively learn fused representation from diffusion\ntensor imaging (DTI) and resting-state functional magnetic resonance imaging\n(fMRI) for mild cognitive impairment (MCI) analysis. Specifically, the\ndecomposition-fusion framework is developed to first decompose the feature\nspace into the union of the uniform and the unique spaces for each modality,\nand then adaptively fuse the decomposed features to learn MCI-related\nrepresentation. Moreover, a knowledge-aware transformer module is designed to\nautomatically capture local and global connectivity features throughout the\nbrain. Also, a uniform-unique contrastive loss is further devised to make the\ndecomposition more effective and enhance the complementarity of structural and\nfunctional features. The extensive experiments demonstrate that the proposed\nmodel achieves better performance than other competitive methods in predicting\nand analyzing MCI. More importantly, the proposed model could be a potential\ntool for reconstructing unified brain networks and predicting abnormal\nconnections during the degenerative processes in MCI.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:19:02 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14405","submitter":"Ruiqi Sun","authors":"Ruiqi Sun, Jie Zhao, Xin He, Yiran Li, An Zou","title":"NeuralMatrix: Moving Entire Neural Networks to General Matrix\n  Multiplication for Efficient Inference","comments":"12 pages, 4 figures, Submitted to 37th Conference on Neural\n  Information Processing Systems (NeurIPS 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.AR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we introduce NeuralMatrix, a novel framework that enables the\ncomputation of versatile deep neural networks (DNNs) on a single general matrix\nmultiplication (GEMM) accelerator. The proposed approach overcomes the\nspecificity limitations of ASIC-based accelerators while achieving\napplication-specific acceleration levels compared to general-purpose processors\nsuch as CPUs and GPUs. We address the challenges of mapping both linear and\nnonlinear operations in DNN computation to general matrix multiplications and\nthe impact of using a GEMM accelerator on DNN inference accuracy. Extensive\nexperiments are conducted on various DNN models from three popular categories\n(i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results\ndemonstrate that DNNs suffer only up to a 2.02% accuracy loss after being\nconverted to general matrix multiplication, while achieving 113x to 19.44x\nimprovements in throughput per power compared to CPUs and GPUs.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:03:51 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14406","submitter":"Manuel Kunz","authors":"Manuel Kunz, Stefan Birr, Mones Raslan, Lei Ma, Zhen Li, Adele\n  Gouttes, Mateusz Koren, Tofigh Naghibi, Johannes Stephan, Mariia Bulycheva,\n  Matthias Grzeschik, Armin Keki\\'c, Michael Narodovitch, Kashif Rasul, Julian\n  Sieber, Tim Januschowski","title":"Deep Learning based Forecasting: a case study from the online fashion\n  industry","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Demand forecasting in the online fashion industry is particularly amendable\nto global, data-driven forecasting models because of the industry's set of\nparticular challenges. These include the volume of data, the irregularity, the\nhigh amount of turn-over in the catalog and the fixed inventory assumption.\nWhile standard deep learning forecasting approaches cater for many of these,\nthe fixed inventory assumption requires a special treatment via controlling the\nrelationship between price and demand closely. In this case study, we describe\nthe data and our modelling approach for this forecasting problem in detail and\npresent empirical results that highlight the effectiveness of our approach.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:30:35 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14407","submitter":"Lawrence Paulson","authors":"Lawrence C Paulson","title":"Large-Scale Formal Proof for the Working Mathematician -- Lessons learnt\n  from the ALEXANDRIA Project","comments":"Invited paper for CICM 2023 (Conference on Intelligent Computer\n  Mathematics). This revised version adds two references","journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  ALEXANDRIA is an ERC-funded project that started in 2017, with the aim of\nbringing formal verification to mathematics. The past six years have seen great\nstrides in the formalisation of mathematics and also in some relevant\ntechnologies, above all machine learning. Six years of intensive formalisation\nactivity seem to show that even the most advanced results, drawing on multiple\nfields of mathematics, can be formalised using the tools available today.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:45:34 GMT"},{"version":"v2","created":"Thu, 25 May 2023 10:18:35 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.14408","submitter":"Carolin Geitner","authors":"Carolin M. Geitner (1), Lea J. K\\\"oglmeier (1), In\\'ez Frerichs (2),\n  Patrick Langguth (3), Matthias Lindner (2), Dirk Sch\\\"adler (2), Norbert\n  Weiler (2), Tobias Becher (2), Wolfgang A. Wall (1) ((1) Institute for\n  Computational Mechanics, Technical University of Munich, Garching b.\n  Muenchen, Germany, (2) Department of Anesthesiology and Intensive Care\n  Medicine, University Medical Center Schleswig-Holstein, Campus Kiel, Kiel,\n  Germany, (3) Department of Radiology and Neuroradiology, University Medical\n  Center Schleswig-Holstein, Campus Kiel, Kiel, Germany)","title":"Pressure- and time-dependent alveolar recruitment/derecruitment in a\n  spatially resolved patient-specific computational model for injured human\n  lungs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph cs.CE physics.bio-ph q-bio.TO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a novel approach to computationally model the dynamics of alveolar\nrecruitment/derecruitment (RD), which reproduces the underlying characteristics\ntypically observed in injured lungs. The basic idea is a pressure- and\ntime-dependent variation of the stress-free reference volume in reduced\ndimensional viscoelastic elements representing the acinar tissue. We choose a\nvariable reference volume triggered by critical opening and closing pressures\nin a time-dependent manner from a straightforward mechanical point of view. In\nthe case of (partially and progressively) collapsing alveolar structures, the\nvolume available for expansion during breathing reduces and vice versa,\neventually enabling consideration of alveolar collapse and reopening in our\nmodel. We further introduce a method to patient-specifically determine the\nunderlying critical parameters of the new alveolar RD dynamics when integrated\ninto the tissue elements, referred to as terminal units, of a spatially\nresolved physics-based lung model that simulates the human respiratory system\nin an anatomically correct manner. Relevant patient-specific parameters of the\nterminal units are herein determined based on medical image data and the\nmacromechanical behavior of the lung during artificial ventilation. We test the\nwhole modeling approach for a real-life scenario by applying it to the clinical\ndata of a mechanically ventilated patient. The generated lung model is capable\nto reproduce clinical measurements such as tidal volume and pleural pressure\nduring various ventilation maneuvers. We conclude that this new model is an\nimportant step towards personalized treatment of ARDS patients by considering\npotentially harmful mechanisms - such as cyclic RD and overdistension - and\nmight help to develop relevant protective ventilation strategies to reduce\nventilator-induced lung injury (VILI).\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:37:18 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14409","submitter":"Zhicheng Cai","authors":"Zhicheng Cai","title":"Evolution: A Unified Formula for Feature Operators from a High-level\n  Perspective","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Traditionally, different types of feature operators (e.g., convolution,\nself-attention and involution) utilize different approaches to extract and\naggregate the features. Resemblance can be hardly discovered from their\nmathematical formulas. However, these three operators all serve the same\nparamount purpose and bear no difference in essence. Hence we probe into the\nessence of various feature operators from a high-level perspective, transformed\ntheir components equivalently, and explored their mathematical expressions\nwithin higher dimensions. We raise one clear and concrete unified formula for\ndifferent feature operators termed as Evolution. Evolution utilizes the\nEvolution Function to generate the Evolution Kernel, which extracts and\naggregates the features in certain positions of the input feature map. We\nmathematically deduce the equivalent transformation from the traditional\nformulas of these feature operators to Evolution and prove the unification. In\naddition, we discuss the forms of Evolution Functions and the properties of\ngenerated Evolution Kernels, intending to give inspirations to the further\nresearch and innovations of powerful feature operators.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:55:37 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15110","submitter":"Emily Ren","authors":"Emily Ren","title":"Intersection of Longest Cycle and Largest Bond in 3-Connected Graphs","comments":"16 pages, 19 figures. Paper presented at the 54th Southeastern\n  International Conference on Combinatorics, Graph Theory and Computing (March\n  6-10, 2023); submitted on May 9, 2023 to the conference proceedings book\n  series publication titled \"Springer Proceedings in Mathematics and\n  Statistics\" (PROMS). Paper abstract also on\n  https://www.math.fau.edu/combinatorics/abstracts/ren54.pdf","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  A bond in a graph is a minimal nonempty edge-cut. A connected graph $G$ is\ndual Hamiltonian if the vertex set can be partitioned into two subsets $X$ and\n$Y$ such that the subgraphs induced by $X$ and $Y$ are both trees. There is\nmuch interest in studying the longest cycles and largest bonds in graphs. H. Wu\nconjectured that any longest cycle must meet any largest bond in a simple\n3-connected graph. In this paper, the author proves that the above conjecture\nis true for certain classes of 3-connected graphs: Let $G$ be a simple\n3-connected graph with $n$ vertices and $m$ edges. Suppose $c(G)$ is the size\nof a longest cycle, and $c^*(G)$ is the size of a largest bond. Then each\nlongest cycle meets each largest bond if either $c(G) \\geq n - 3$ or $c^*(G)\n\\geq m - n - 1$. Sanford determined in her Ph.D. thesis the cycle spectrum of\nthe well-known generalized Petersen graph $P(n, 2)$ ($n$ is odd) and $P(n, 3)$\n($n$ is even). Flynn proved in her honors thesis that any generalized Petersen\ngraph $P(n, k)$ is dual Hamiltonian. The author studies the bond spectrum\n(called the co-spectrum) of the generalized Petersen graphs and extends Flynn's\nresult by proving that in any generalized Petersen graph $P(n, k)$, $1 \\leq k <\n\\frac{n}{2}$, the co-spectrum of $P(n, k)$ is $\\{3, 4, 5, ..., n+2\\}$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 23:53:45 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15156","submitter":"Ji Yuanfeng","authors":"Yuanfeng Ji, Yatao Bian, Guoji Fu, Peilin Zhao, Ping Luo","title":"SyNDock: N Rigid Protein Docking via Learnable Group Synchronization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.BM cs.CE cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The regulation of various cellular processes heavily relies on the protein\ncomplexes within a living cell, necessitating a comprehensive understanding of\ntheir three-dimensional structures to elucidate the underlying mechanisms.\nWhile neural docking techniques have exhibited promising outcomes in binary\nprotein docking, the application of advanced neural architectures to multimeric\nprotein docking remains uncertain. This study introduces SyNDock, an automated\nframework that swiftly assembles precise multimeric complexes within seconds,\nshowcasing performance that can potentially surpass or be on par with recent\nadvanced approaches. SyNDock possesses several appealing advantages not present\nin previous approaches. Firstly, SyNDock formulates multimeric protein docking\nas a problem of learning global transformations to holistically depict the\nplacement of chain units of a complex, enabling a learning-centric solution.\nSecondly, SyNDock proposes a trainable two-step SE(3) algorithm, involving\ninitial pairwise transformation and confidence estimation, followed by global\ntransformation synchronization. This enables effective learning for assembling\nthe complex in a globally consistent manner. Lastly, extensive experiments\nconducted on our proposed benchmark dataset demonstrate that SyNDock\noutperforms existing docking software in crucial performance metrics, including\naccuracy and runtime. For instance, it achieves a 4.5% improvement in\nperformance and a remarkable millionfold acceleration in speed.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:57:18 GMT"},{"version":"v2","created":"Thu, 25 May 2023 01:27:47 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15317","submitter":"Liang Chen","authors":"Ying Huang and Liang Chen","title":"On the robust learning mixtures of linear regressions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this note, we consider the problem of robust learning mixtures of linear\nregressions. We connect mixtures of linear regressions and mixtures of\nGaussians with a simple thresholding, so that a quasi-polynomial time algorithm\ncan be obtained under some mild separation condition. This algorithm has\nsignificantly better robustness than the previous result.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:50:56 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15400","submitter":"Vladimir Onoochin","authors":"Vladimir Onoochin","title":"Can exist a function, that transforms electromagnetic potentials from\n  one to other gauge?","comments":"AMS-LaTeX, 6 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, it is analyzed a problem of existence of a function which is\nable to transform electromagnetic potentials defined in one gauge to\ncorresponding potentials defined in the other gauge. It is shown that such a\nfunction cannot exist.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:17:32 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15402","submitter":"Bruno Rizzuti","authors":"Thales B. S. F. Rodrigues and B. F. Rizzuti","title":"On the connection between Lenz's law and relativity","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we demonstrate explicitly the unified nature of electric and\nmagnetic fields, from the principles of special relativity and Lorentz\ntransformations of the electromagnetic field tensor. Using an operational\napproach we construct the tensor and its corresponding transformation law,\nbased on the principle of relativity. Our work helps to elucidate concepts of\nadvanced courses on electromagnetism for primary-level learners and shows an\nalternative path to derive the Lenz's law based solely on relativity arguments.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:47:43 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15432","submitter":"Vivek Pandey","authors":"Vivek Pandey and Sudhir K. Pandey","title":"Existence of nodal-arc and its evolution into Weyl-nodes in the presence\n  of spin-orbit coupling in TaAs & TaP","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we report the existence of nodal-arc, which acts as the\nbuilding block of all the nodal-rings in TaAs & TaP. This nodal-arc is found to\nbe capable of generating all the nodal-rings in these materials upon the\napplication of space-group symmetry operations including time-reversal\nsymmetry. The arcs are obtained to be dispersive with the energy spread of\n$\\sim$109 ($\\sim$204) meV in TaAs (TaP). Also, the orbitals leading to\nbands-inversion and thus the formation of nodal-arcs are found to be Ta-5d &\nAs-4p (P-3p) in TaAs (TaP). The area of nodal-rings is found to be highly\nsensitive to the change in hybridization-strength, where the increase in\nhybridization-strength leads to the decrease in the area of nodal-rings. In the\npresence of spin-orbit coupling (SOC), all the points on these arcs get\ngaped-up and two pairs of Weyl-nodes are found to evolve from them. Out of the\ntwo pair, one is found to be situated close to the joining point of the two\narcs forming a ring. This causes the evolution of each nodal-ring into three\npairs of Weyl-nodes. The coordinates of these Weyl-nodes are found to be robust\nto the increase in SOC-strength from $\\sim$ 0.7-3.5 eV. All the results are\nobtained at the first-principle level. This work provides a clear picture of\nthe existence of nodal-arc due to accidental degeneracy and its evolution into\nWeyl-nodes under the effect of SOC.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 20:47:07 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15433","submitter":"Bence G\\'abor M\\'arkus","authors":"B. G. M\\'arkus, M. Gmitra, B. D\\'ora, G. Cs\\H{o}sz, T. Feh\\'er, P.\n  Szirmai, B. N\\'afr\\'adi, V. Z\\'olyomi, L. Forr\\'o, J. Fabian, F. Simon","title":"Ultralong 100 ns Spin Relaxation Time in Graphite at Room Temperature","comments":null,"journal-ref":"Nature Communications volume 14, Article number: 2831 (2023)","doi":"10.1038/s41467-023-38288-w","report-no":null,"categories":"cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graphite has been intensively studied, yet its electron spins dynamics\nremains an unresolved problem even 70 years after the first experiments. The\ncentral quantities, the longitudinal ($T_1$) and transverse ($T_2$) relaxation\ntimes were postulated to be equal, mirroring standard metals, but $T_1$ has\nnever been measured for graphite. Here, based on a detailed band structure\ncalculation including spin-orbit coupling, we predict an unexpected behavior of\nthe relaxation times. We find, based on saturation ESR measurements, that $T_1$\nis markedly different from $T_2$. Spins injected with perpendicular\npolarization with respect to the graphene plane have an extraordinarily long\nlifetime of $100$ ns at room temperature. This is ten times more than in the\nbest graphene samples. The spin diffusion length across graphite planes is thus\nexpected to be ultralong, on the scale of $\\sim 70~\\mu$m, suggesting that thin\nfilms of graphite -- or multilayer AB graphene stacks -- can be excellent\nplatforms for spintronics applications compatible with 2D van der Waals\ntechnologies. Finally, we provide a qualitative account of the observed spin\nrelaxation based on the anisotropic spin admixture of the Bloch states in\ngraphite obtained from density functional theory calculations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 21:15:16 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15434","submitter":"Ze Li","authors":"Z. Li, Z. Q. Zhao, X. H. Yang, G. B. Zhang, Y. Y. Ma, H. Xu, F. Y. Wu,\n  F. Q. Shao, J. Zhang","title":"Hybrid Optimization of Laser-Driven Fusion Targets and Laser Profiles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quasi-isentropic compression is an effective method to achieve high-density\nand high-temperature implosion in laser-driven inertial confinement fusion\n(ICF). However, it requires precise matching between the laser profile and the\ntarget structure. Designing the optimal laser profile and the corresponding\ntarget for ICF is a challenge due to the large number of parameters involved.\nIn this paper, we present a novel method that combines random walk and Bayesian\noptimization. The basic sampling data for Bayesian optimization are a series of\nlaser pulse profiles and target structures that can produce relatively high\nareal densities obtained by the random walk method. This approach reduces the\nnumber of samples required for Bayesian optimization and mitigates low\nefficiency in the latter stages of the random walk method. The method also\nreduces the randomness in the optimization process and enhances the\noptimization efficiency. It should have important applications in ICF research.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:51:43 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15435","submitter":"Inge S. Helland","authors":"Inge S. Helland","title":"Possible connections between relativity theory and a version of quantum\n  theory based on conceptual variables","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.hist-ph gr-qc quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An alternative approach towards quantum theory is described, and tentative\nattempts to connect his approach to special and general relativity are\ndiscussed. Important concepts ar gauge groups and information/entropy connected\nto some physical systems. Some recent results on information in connection to\nblack holes are touched upon. The discussions here must be considered to be\npreliminary.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:40:34 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15437","submitter":"Abdel Nasser Tawfik","authors":"Antonio Pasqua (University of Trieste, Italy), Surajit Chattopadhyay\n  (Amity University, India), Irina Radinschi (Gheorghe Asach Technical\n  University, Romania), Azzah Aziz Alshehri (University of Hafr Al Batin, KSA),\n  Abdel Nasser Tawfik (Future University in Egypt, Cairo)","title":"Reconstruction of scalar field models for the PLECHDE model with Ricci\n  scalar cut-off","comments":"57 pages, 0 figure, Submitted to IJMPD. arXiv admin note: text\n  overlap with arXiv:gr-qc/0609115 by other authors","journal-ref":null,"doi":null,"report-no":"ECTP-2023-19 and WLCAPP-2023-10 and FUE-2023-10","categories":"gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we study the cosmological properties of the Power Law Entropy\nCorrected Dark Energy (PLECHDE) model with infrared (IR) cut--off given by the\naverage radius of the Ricci scalar curvature $R$ (varying with the Hubble\nparameter $H$ squared), of the time derivative of $H$, and the curvature\nparameter $k$. We derive an Equation of State (EoS) parameter of Dark Energy\n(DE) $\\omega_D$ and the deceleration parameter $q$. We also obtain the\nexpressions of the scale factor $a$ and the Hubble parameter $H$ as functions\nof the cosmic time $t$. Moreover, we study the limiting case corresponding to a\nflat Dark Dominated Universe. Furthermore, we establish a correspondence\nbetween the DE model considered and some scalar fields, in particular the\nGeneralized Chaplygin Gas, the Modified Chaplygin Gas, the Modified Variable\nChaplygin Gas, the New Modified Chaplygin Gas, the Viscous Generalized\nChaplygin Gas, the Dirac-Born-Infeld, the Yang-Mills, and the Non Linear\nElectrodynamics scalar field models.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:08:55 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.15559","submitter":"Shuji Shinohara Shinohara","authors":"Shuji Shinohara, Daiki Morita, Nobuhito Manome, Ryota Hayashi, Toru\n  Moriyama, Hiroshi Okamoto, Pegio-Yukio Gunji, and Ung-il Chung","title":"Inverse square Levy walk emerging universally in goal-oriented tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech cs.AI cs.MA cs.NE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Levy walk in which the frequency of occurrence of step lengths follows a\npower-law distribution, can be observed in the migratory behavior of organisms\nat various levels. Levy walks with power exponents close to 2 are observed, and\nthe reasons are unclear. This study aims to propose a model that universally\ngenerates inverse square Levy walks (called Cauchy walks) and to identify the\nconditions under which Cauchy walks appear. We demonstrate that Cauchy walks\nemerge universally in goal-oriented tasks. We use the term \"goal-oriented\" when\nthe goal is clear, but this can be achieved in different ways, which cannot be\nuniquely determined. We performed a simulation in which an agent observed the\ndata generated from a probability distribution in a two-dimensional space and\nsuccessively estimated the central coordinates of that probability\ndistribution. The agent has a model of probability distribution as a hypothesis\nfor data-generating distribution and can modify the model such that each time a\ndata point is observed, thereby increasing the estimated probability of\noccurrence of the observed data. To achieve this, the center coordinates of the\nmodel must be moved closer to those of the observed data. However, in the case\nof a two-dimensional space, arbitrariness arises in the direction of correction\nof the center; this task is goal oriented. We analyze two cases: a strategy\nthat allocates the amount of modification randomly in the x- and y-directions,\nand a strategy that determines allocation such that movement is minimized. The\nresults reveal that when a random strategy is used, the Cauchy walk appears.\nWhen the minimum strategy is used, the Brownian walk appears. The presence or\nabsence of the constraint of minimizing the amount of movement may be a factor\nthat causes the difference between Brownian and Levy walks.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:18:07 GMT"},{"version":"v2","created":"Mon, 29 May 2023 04:30:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.16333","submitter":"Zhuangqun Huang","authors":"Zhuangqun Huang, Gil Keren, Ziran Jiang, Shashank Jain, David\n  Goss-Grubbs, Nelson Cheng, Farnaz Abtahi, Duc Le, David Zhang, Antony\n  D'Avirro, Ethan Campbell-Taylor, Jessie Salas, Irina-Elena Veliche, Xi Chen","title":"Text Generation with Speech Synthesis for ASR Data Augmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Aiming at reducing the reliance on expensive human annotations, data\nsynthesis for Automatic Speech Recognition (ASR) has remained an active area of\nresearch. While prior work mainly focuses on synthetic speech generation for\nASR data augmentation, its combination with text generation methods is\nconsiderably less explored. In this work, we explore text augmentation for ASR\nusing large-scale pre-trained neural networks, and systematically compare those\nto traditional text augmentation methods. The generated synthetic texts are\nthen converted to synthetic speech using a text-to-speech (TTS) system and\nadded to the ASR training data. In experiments conducted on three datasets, we\nfind that neural models achieve 9%-15% relative WER improvement and outperform\ntraditional methods. We conclude that text augmentation, particularly through\nmodern neural approaches, is a viable tool for improving the accuracy of ASR\nsystems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 18:45:20 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.16334","submitter":"Yuanzhen Xie","authors":"Yuanzhen Xie, Tao Xie, Mingxiong Lin, WenTao Wei, Chenglin Li, Beibei\n  Kong, Lei Chen, Chengxiang Zhuo, Bo Hu, Zang Li","title":"OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In most current research, large language models (LLMs) are able to perform\nreasoning tasks by generating chains of thought through the guidance of\nspecific prompts. However, there still exists a significant discrepancy between\ntheir capability in solving complex reasoning problems and that of humans. At\npresent, most approaches focus on chains of thought (COT) and tool use, without\nconsidering the adoption and application of human cognitive frameworks. It is\nwell-known that when confronting complex reasoning challenges, humans typically\nemploy various cognitive abilities, and necessitate interaction with all\naspects of tools, knowledge, and the external environment information to\naccomplish intricate tasks. This paper introduces a novel intelligent\nframework, referred to as OlaGPT. OlaGPT carefully studied a cognitive\narchitecture framework, and propose to simulate certain aspects of human\ncognition. The framework involves approximating different cognitive modules,\nincluding attention, memory, reasoning, learning, and corresponding scheduling\nand decision-making mechanisms. Inspired by the active learning mechanism of\nhuman beings, it proposes a learning unit to record previous mistakes and\nexpert opinions, and dynamically refer to them to strengthen their ability to\nsolve similar problems. The paper also outlines common effective reasoning\nframeworks for human problem-solving and designs Chain-of-Thought (COT)\ntemplates accordingly. A comprehensive decision-making mechanism is also\nproposed to maximize model accuracy. The efficacy of OlaGPT has been\nstringently evaluated on multiple reasoning datasets, and the experimental\noutcomes reveal that OlaGPT surpasses state-of-the-art benchmarks,\ndemonstrating its superior performance. Our implementation of OlaGPT is\navailable on GitHub: \\url{https://github.com/oladata-team/OlaGPT}.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 09:36:51 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.16335","submitter":"Mengling Hu","authors":"Xiaolin Zheng, Mengling Hu, Weiming Liu, Chaochao Chen, and Xinting\n  Liao","title":"Robust Representation Learning with Reliable Pseudo-labels Generation\n  via Self-Adaptive Optimal Transport for Short Text Clustering","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Short text clustering is challenging since it takes imbalanced and noisy data\nas inputs. Existing approaches cannot solve this problem well, since (1) they\nare prone to obtain degenerate solutions especially on heavy imbalanced\ndatasets, and (2) they are vulnerable to noises. To tackle the above issues, we\npropose a Robust Short Text Clustering (RSTC) model to improve robustness\nagainst imbalanced and noisy data. RSTC includes two modules, i.e.,\npseudo-label generation module and robust representation learning module. The\nformer generates pseudo-labels to provide supervision for the later, which\ncontributes to more robust representations and correctly separated clusters. To\nprovide robustness against the imbalance in data, we propose self-adaptive\noptimal transport in the pseudo-label generation module. To improve robustness\nagainst the noise in data, we further introduce both class-wise and\ninstance-wise contrastive learning in the robust representation learning\nmodule. Our empirical studies on eight short text clustering datasets\ndemonstrate that RSTC significantly outperforms the state-of-the-art models.\nThe code is available at: https://github.com/hmllmh/RSTC.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:43:40 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.16876","submitter":"Aitor Ormazabal","authors":"Aitor Ormazabal, Mikel Artetxe and Eneko Agirre","title":"CombLM: Adapting Black-Box Language Models through Small Fine-Tuned\n  Models","comments":"This previously appeared as arXiv:2205.12213v2, which was submitted\n  as new by mistake","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Methods for adapting language models (LMs) to new tasks and domains have\ntraditionally assumed white-box access to the model, and work by modifying its\nparameters. However, this is incompatible with a recent trend in the field,\nwhere the highest quality models are only available as black-boxes through\ninference APIs. Even when the model weights are available, the computational\ncost of fine-tuning large LMs can be prohibitive for most practitioners. In\nthis work, we present a lightweight method for adapting large LMs to new\ndomains and tasks, assuming no access to their weights or intermediate\nactivations. Our approach fine-tunes a small white-box LM and combines it with\nthe large black-box LM at the probability level through a small network,\nlearned on a small validation set. We validate our approach by adapting a large\nLM (OPT-30B) to several domains and a downstream task (machine translation),\nobserving improved performance in all cases, of up to 9%, while using a domain\nexpert 23x smaller.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 06:32:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17141","submitter":"Da Zeng","authors":"Zeng Da","title":"Research on Multi-Agent Communication and Collaborative Decision-Making\n  Based on Deep Reinforcement Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a multi-agent environment, In order to overcome and alleviate the\nnon-stationarity of the multi-agent environment, the mainstream method is to\nadopt the framework of Centralized Training Decentralized Execution (CTDE).\nThis thesis is based on the framework of CTDE, and studies the cooperative\ndecision-making of multi-agent based on the Multi-Agent Proximal Policy\nOptimization (MAPPO) algorithm for multi-agent proximal policy optimization. In\norder to alleviate the non-stationarity of the multi-agent environment, a\nmulti-agent communication mechanism based on weight scheduling and attention\nmodule is introduced. Different agents can alleviate the non-stationarity\ncaused by local observations through information exchange between agents,\nassisting in the collaborative decision-making of agents. The specific method\nis to introduce a communication module in the policy network part. The\ncommunication module is composed of a weight generator, a weight scheduler, a\nmessage encoder, a message pool and an attention module. Among them, the weight\ngenerator and weight scheduler will generate weights as the selection basis for\ncommunication, the message encoder is used to compress and encode communication\ninformation, the message pool is used to store communication messages, and the\nattention module realizes the interactive processing of the agent's own\ninformation and communication information. This thesis proposes a Multi-Agent\nCommunication and Global Information Optimization Proximal Policy\nOptimization(MCGOPPO)algorithm, and conducted experiments in the SMAC and the\nMPE. The experimental results show that the improvement has achieved certain\neffects, which can better alleviate the non-stationarity of the multi-agent\nenvironment, and improve the collaborative decision-making ability among the\nagents.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 14:20:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18206","submitter":"Yuxiao Li","authors":"Yuxiao Li, Santiago Mazuelas, Yuan Shen","title":"Deep Generative Model for Simultaneous Range Error Mitigation and\n  Environment Identification","comments":"6 pages, 5 figures, Published in: 2021 IEEE Global Communications\n  Conference (GLOBECOM)","journal-ref":"2021 IEEE Global Communications Conference (GLOBECOM), Madrid,\n  Spain, 2021, pp. 1-6","doi":"10.1109/GLOBECOM46510.2021.9685255.","report-no":null,"categories":"eess.SP cs.AI cs.LG stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Received waveforms contain rich information for both range information and\nenvironment semantics. However, its full potential is hard to exploit under\nmultipath and non-line-of-sight conditions. This paper proposes a deep\ngenerative model (DGM) for simultaneous range error mitigation and environment\nidentification. In particular, we present a Bayesian model for the generative\nprocess of the received waveform composed by latent variables for both\nrange-related features and environment semantics. The simultaneous range error\nmitigation and environment identification is interpreted as an inference\nproblem based on the DGM, and implemented in a unique end-to-end learning\nscheme. Comprehensive experiments on a general Ultra-wideband dataset\ndemonstrate the superior performance on range error mitigation, scalability to\ndifferent environments, and novel capability on simultaneous environment\nidentification.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:16:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18208","submitter":"Yuxiao Li","authors":"Yuxiao Li, Santiago Mazuelas, Yuan Shen","title":"A Semi-Supervised Learning Approach for Ranging Error Mitigation Based\n  on UWB Waveform","comments":"5 pages, 3 figures, Published in: MILCOM 2021 - 2021 IEEE Military\n  Communications Conference (MILCOM)","journal-ref":"MILCOM 2021 - 2021 IEEE Military Communications Conference\n  (MILCOM), San Diego, CA, USA, 2021, pp. 533-537","doi":"10.1109/MILCOM52596.2021.9653043.","report-no":null,"categories":"eess.SP cs.AI cs.LG stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Localization systems based on ultra-wide band (UWB) measurements can have\nunsatisfactory performance in harsh environments due to the presence of\nnon-line-of-sight (NLOS) errors. Learning-based methods for error mitigation\nhave shown great performance improvement via directly exploiting the wideband\nwaveform instead of handcrafted features. However, these methods require data\nsamples fully labeled with actual measurement errors for training, which leads\nto time-consuming data collection. In this paper, we propose a semi-supervised\nlearning method based on variational Bayes for UWB ranging error mitigation.\nCombining deep learning techniques and statistic tools, our method can\nefficiently accumulate knowledge from both labeled and unlabeled data samples.\nExtensive experiments illustrate the effectiveness of the proposed method under\ndifferent supervision rates, and the superiority compared to other fully\nsupervised methods even at a low supervision rate.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 10:08:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18220","submitter":"Francisco Javier Vaquero Caballero","authors":"F.J. Vaquero-Caballero, Gernot Goeger, Fabio Pittala, Yabin Ye, and\n  Idelfonso Tafur Monroy","title":"Experimental Demonstration of Stokes Space Equalization for Space\n  Division Multiplexed Signals","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this letter we experimentally validate, for the first time, the Stokes\nspace algorithm (SSA) equalizer for space division multiplexing (SDM)\ntransmission systems. We introduce the frequency domain (FD)-SSA and FD\nleast-mean square (FD-LMS) algorithms, and evaluate their performance for\ndifferent frequency offsets by computer simulations. Our simulations show that\nFD-SSA is insensitive to the frequency offsets, not requiring carrier frequency\nestimation (CFE) before equalization (pre-CFE) or carrier phase estimation\n(CPE) inside the loop (L-CPE). Our experimental results confirm that FD-SSA\npresents the same performance as FD-LMS, where the required digital signal\nprocessing (DSP) stack for FD-SSA is simpler compared to the FDLMS.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:06:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18222","submitter":"Hanno Gottschalk","authors":"Kamil Kowol, Stefan Bracke and Hanno Gottschalk","title":"survAIval: Survival Analysis with the Eyes of AI","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this study, we propose a novel approach to enrich the training data for\nautomated driving by using a self-designed driving simulator and two human\ndrivers to generate safety-critical corner cases in a short period of time, as\nalready presented in~\\cite{kowol22simulator}. Our results show that\nincorporating these corner cases during training improves the recognition of\ncorner cases during testing, even though, they were recorded due to visual\nimpairment. Using the corner case triggering pipeline developed in the previous\nwork, we investigate the effectiveness of using expert models to overcome the\ndomain gap due to different weather conditions and times of day, compared to a\nuniversal model from a development perspective. Our study reveals that expert\nmodels can provide significant benefits in terms of performance and efficiency,\nand can reduce the time and effort required for model training. Our results\ncontribute to the progress of automated driving, providing a pathway for safer\nand more reliable autonomous vehicles on the road in the future.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 15:20:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18322","submitter":"Simerjot Kaur","authors":"Simerjot Kaur, Charese Smiley, Akshat Gupta, Joy Sain, Dongsheng Wang,\n  Suchetha Siddagangappa, Toyin Aguda, Sameena Shah","title":"REFinD: Relation Extraction Financial Dataset","comments":null,"journal-ref":null,"doi":"10.1145/3539618.3591911","report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  A number of datasets for Relation Extraction (RE) have been created to aide\ndownstream tasks such as information retrieval, semantic search, question\nanswering and textual entailment. However, these datasets fail to capture\nfinancial-domain specific challenges since most of these datasets are compiled\nusing general knowledge sources such as Wikipedia, web-based text and news\narticles, hindering real-life progress and adoption within the financial world.\nTo address this limitation, we propose REFinD, the first large-scale annotated\ndataset of relations, with $\\sim$29K instances and 22 relations amongst 8 types\nof entity pairs, generated entirely over financial documents. We also provide\nan empirical evaluation with various state-of-the-art models as benchmarks for\nthe RE task and highlight the challenges posed by our dataset. We observed that\nvarious state-of-the-art deep learning models struggle with numeric inference,\nrelational and directional ambiguity.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 22:40:11 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18323","submitter":"Binfeng Xu","authors":"Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu,\n  Dongkuan Xu","title":"ReWOO: Decoupling Reasoning from Observations for Efficient Augmented\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Augmented Language Models (ALMs) blend the reasoning capabilities of Large\nLanguage Models (LLMs) with tools that allow for knowledge retrieval and action\nexecution. Existing ALM systems trigger LLM thought processes while pulling\nobservations from these tools in an interleaved fashion. Specifically, an LLM\nreasons to call an external tool, gets halted to fetch the tool's response, and\nthen decides the next action based on all preceding response tokens. Such a\nparadigm, though straightforward and easy to implement, often leads to huge\ncomputation complexity from redundant prompts and repeated execution. This\nstudy addresses such challenges for the first time, proposing a modular\nparadigm ReWOO (Reasoning WithOut Observation) that detaches the reasoning\nprocess from external observations, thus significantly reducing token\nconsumption. Comprehensive evaluations across six public NLP benchmarks and a\ncurated dataset reveal consistent performance enhancements with our proposed\nmethodology. Notably, ReWOO achieves 5x token efficiency and 4% accuracy\nimprovement on HotpotQA, a multi-step reasoning benchmark. Furthermore, ReWOO\ndemonstrates robustness under tool-failure scenarios. Beyond prompt efficiency,\ndecoupling parametric modules from non-parametric tool calls enables\ninstruction fine-tuning to offload LLMs into smaller language models, thus\nsubstantially reducing model parameters. Our illustrative work offloads\nreasoning ability from 175B GPT3.5 into 7B LLaMA, demonstrating the significant\npotential for truly efficient and scalable ALM systems.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 00:16:48 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18324","submitter":"Yifan Nie","authors":"Vanessa Liao, Syed Shariyar Murtaza, Yifan Nie, Jimmy Lin","title":"Regex-augmented Domain Transfer Topic Classification based on a\n  Pre-trained Language Model: An application in Financial Domain","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  A common way to use large pre-trained language models for downstream tasks is\nto fine tune them using additional layers. This may not work well if downstream\ndomain is a specialized domain whereas the large language model has been\npre-trained on a generic corpus. In this paper, we discuss the use of regular\nexpression patterns employed as features for domain knowledge during the\nprocess of fine tuning, in addition to domain specific text. Our experiments on\nreal scenario production data show that this method of fine tuning improves the\ndownstream text classification tasks as compared to fine tuning only on domain\nspecific text. We also show that the use of attention network for fine tuning\nimproves results compared to simple linear layers.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:26:32 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18325","submitter":"Duane Loh","authors":"Jiadong Dan and Moaz Waqar and Ivan Erofeev and Kui Yao and John Wang\n  and Stephen J. Pennycook and N. Duane Loh","title":"A multiscale generative model to understand disorder in domain\n  boundaries","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A continuing challenge in atomic resolution microscopy is to identify\nsignificant structural motifs and their assembly rules in synthesized materials\nwith limited observations. Here we propose and validate a simple and effective\nhybrid generative model capable of predicting unseen domain boundaries in a\npotassium sodium niobate thin film from only a small number of observations,\nwithout expensive first-principles calculation. Our results demonstrate that\ncomplicated domain boundary structures can arise from simple interpretable\nlocal rules, played out probabilistically. We also found new significant\ntileable boundary motifs and evidence that our system creates domain boundaries\nwith the highest entropy. More broadly, our work shows that simple yet\ninterpretable machine learning models can help us describe and understand the\nnature and origin of disorder in complex materials.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 03:28:01 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18326","submitter":"Liyan Kang","authors":"Liyan Kang, Luyang Huang, Ningxin Peng, Peihao Zhu, Zewei Sun, Shanbo\n  Cheng, Mingxuan Wang, Degen Huang and Jinsong Su","title":"BigVideo: A Large-scale Video Subtitle Translation Dataset for\n  Multimodal Machine Translation","comments":"Accepted to ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a large-scale video subtitle translation dataset, BigVideo, to\nfacilitate the study of multi-modality machine translation. Compared with the\nwidely used How2 and VaTeX datasets, BigVideo is more than 10 times larger,\nconsisting of 4.5 million sentence pairs and 9,981 hours of videos. We also\nintroduce two deliberately designed test sets to verify the necessity of visual\ninformation: Ambiguous with the presence of ambiguous words, and Unambiguous in\nwhich the text context is self-contained for translation. To better model the\ncommon semantics shared across texts and videos, we introduce a contrastive\nlearning method in the cross-modal encoder. Extensive experiments on the\nBigVideo show that: a) Visual information consistently improves the NMT model\nin terms of BLEU, BLEURT, and COMET on both Ambiguous and Unambiguous test\nsets. b) Visual information helps disambiguation, compared to the strong text\nbaseline on terminology-targeted scores and human evaluation. Dataset and our\nimplementations are available at https://github.com/DeepLearnXMU/BigVideo-VMT.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 08:53:36 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18327","submitter":"Miya Nakajima","authors":"Miya Nakajima, Takahiro Saitoh, Tsuyoshi Kato","title":"A Study on Deep CNN Structures for Defect Detection From Laser\n  Ultrasonic Visualization Testing Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The importance of ultrasonic nondestructive testing has been increasing in\nrecent years, and there are high expectations for the potential of laser\nultrasonic visualization testing, which combines laser ultrasonic testing with\nscattered wave visualization technology. Even if scattered waves are\nvisualized, inspectors still need to carefully inspect the images. To automate\nthis, this paper proposes a deep neural network for automatic defect detection\nand localization in LUVT images. To explore the structure of a neural network\nsuitable to this task, we compared the LUVT image analysis problem with the\ngeneric object detection problem. Numerical experiments using real-world data\nfrom a SUS304 flat plate showed that the proposed method is more effective than\nthe general object detection model in terms of prediction performance. We also\nshow that the computational time required for prediction is faster than that of\nthe general object detection model.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 11:16:41 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18328","submitter":"Louis Ledoux","authors":"Louis Ledoux and Marc Casas","title":"Open-Source GEMM Hardware Kernels Generator: Toward Numerically-Tailored\n  Computations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many scientific computing problems can be reduced to Matrix-Matrix\nMultiplications (MMM), making the General Matrix Multiply (GEMM) kernels in the\nBasic Linear Algebra Subroutine (BLAS) of interest to the high-performance\ncomputing community. However, these workloads have a wide range of numerical\nrequirements. Ill-conditioned linear systems require high-precision arithmetic\nto ensure correct and reproducible results. In contrast, emerging workloads\nsuch as deep neural networks, which can have millions up to billions of\nparameters, have shown resilience to arithmetic tinkering and precision\nlowering.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:47:19 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18569","submitter":"Yunqi Li","authors":"Yunqi Li and Yongfeng Zhang","title":"Fairness of ChatGPT","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Understanding and addressing unfairness in LLMs are crucial for responsible\nAI deployment. However, there is a limited availability of quantitative\nanalyses and in-depth studies regarding fairness evaluations in LLMs,\nespecially when applying LLMs to high-stakes fields. This work aims to fill\nthis gap by providing a systematic evaluation of the effectiveness and fairness\nof LLMs using ChatGPT as a study case. We focus on assessing ChatGPT's\nperformance in high-takes fields including education, criminology, finance and\nhealthcare. To make thorough evaluation, we consider both group fairness and\nindividual fairness and we also observe the disparities in ChatGPT's outputs\nunder a set of biased or unbiased prompts. This work contributes to a deeper\nunderstanding of LLMs' fairness performance, facilitates bias mitigation and\nfosters the development of responsible artificial intelligence systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 17:51:56 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18616","submitter":"Gaoxia Zhu","authors":"Gaoxia Zhu, Xiuyi Fan, Chenyu Hou, Tianlong Zhong, Peter Seow, Annabel\n  Chen Shen-Hsing, Preman Rajalingam, Low Kin Yew, Tan Lay Poh","title":"Embrace Opportunities and Face Challenges: Using ChatGPT in\n  Undergraduate Students' Collaborative Interdisciplinary Learning","comments":"33 pages, 2 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  ChatGPT, launched in November 2022, has gained widespread attention from\nstudents and educators globally, with an online report by Hu (2023) stating it\nas the fastest-growing consumer application in history. While discussions on\nthe use of ChatGPT in higher education are abundant, empirical studies on its\nimpact on collaborative interdisciplinary learning are rare. To investigate its\npotential, we conducted a quasi-experimental study with 130 undergraduate\nstudents (STEM and non-STEM) learning digital literacy with or without ChatGPT\nover two weeks. Weekly surveys were conducted on collaborative\ninterdisciplinary problem-solving, physical and cognitive engagement, and\nindividual reflections on ChatGPT use. Analysis of survey responses showed\nsignificant main effects of topics on collaborative interdisciplinary\nproblem-solving and physical and cognitive engagement, a marginal interaction\neffect between disciplinary backgrounds and ChatGPT conditions for cognitive\nengagement, and a significant interaction effect for physical engagement.\nSentiment analysis of student reflections suggested no significant difference\nbetween STEM and non-STEM students' opinions towards ChatGPT. Qualitative\nanalysis of reflections generated eight positive themes, including efficiency,\naddressing knowledge gaps, and generating human-like responses, and eight\nnegative themes, including generic responses, lack of innovation, and\ncounterproductive to self-discipline and thinking. Our findings suggest that\nChatGPT use needs to be optimized by considering the topics being taught and\nthe disciplinary backgrounds of students rather than applying it uniformly.\nThese findings have implications for both pedagogical research and practices.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 13:14:49 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19275","submitter":"Samuel A. Prieto","authors":"Keyi Wu, Samuel A. Prieto, Eyob Mengiste, Borja Garc\\'ia de Soto","title":"Automated spacing measurement of formwork system members with 3D point\n  cloud data","comments":"24 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The formwork system belonging to the temporary structure plays an important\nrole in the smooth progress and successful completion of a construction\nproject. Ensuring that the formwork system is installed as designed is\nessential for construction safety and quality. The current way to measure the\nspacing between formwork system members is mostly done using manual measuring\ntools. This research proposes a framework to measure the spacing of formwork\nsystem members using 3D point cloud data to enhance the automation of this\nquality inspection. The novelty is not only in the integration of the different\ntechniques used but in the detection and measurement of key members in the\nformwork system without human intervention. The proposed framework was tested\non a real construction site. Five cases were investigated to compare the 3D\npoint cloud data approach to the manual approach with traditional measuring\ntools. The results indicate that the 3D point cloud data approach is a\npromising solution and can potentially be an effective alternative to the\nmanual approach.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 12:17:31 GMT"}],"update_date":"2023-06-01"}
{"id":"2306.01751","submitter":"Ping Li","authors":"Ping Li and Xiaoyun Li","title":"Differential Privacy with Random Projections and Sign Random Projections","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we develop a series of differential privacy (DP) algorithms\nfrom a family of random projections (RP), for general applications in machine\nlearning, data mining, and information retrieval. Among the presented\nalgorithms, \\textbf{iDP-SignRP} is remarkably effective under the setting of\n``individual differential privacy'' (iDP), based on sign random projections\n(SignRP). Also, \\textbf{DP-SignOPORP} considerably improves existing algorithms\nin the literature under the standard DP setting, using ``one permutation + one\nrandom projection'' (OPORP), where OPORP is a variant of the celebrated\ncount-sketch method with fixed-length binning and normalization. Without taking\nsigns, among the DP-RP family, \\textbf{DP-OPORP} achieves the best performance.\n  The concept of iDP (individual differential privacy) is defined only on a\nparticular dataset of interest. While iDP is not strictly DP, iDP might be\nuseful in certain applications, such as releasing a dataset (including sharing\nembeddings across companies or countries). In our study, we find that\n\\textbf{iDP-SignRP} is remarkably effective for search and machine learning\napplications, in that the utilities are exceptionally good even at a very small\nprivacy parameter $\\epsilon$ (e.g., $\\epsilon<0.5$).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:33:23 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01752","submitter":"Felix Denzinger","authors":"Felix Denzinger, Michael Wels, Oliver Taubmann, Florian Kordon, Fabian\n  Wagner, Stephanie Mehltretter, Mehmet A. G\\\"uls\\\"un, Max Sch\\\"obinger,\n  Florian Andr\\'e, Sebastian Buss, Johannes G\\\"orich, Michael S\\\"uhling,\n  Andreas Maier","title":"Handling Label Uncertainty on the Example of Automatic Detection of\n  Shepherd's Crook RCA in Coronary CT Angiography","comments":"Accepted at ISBI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Coronary artery disease (CAD) is often treated minimally invasively with a\ncatheter being inserted into the diseased coronary vessel. If a patient\nexhibits a Shepherd's Crook (SC) Right Coronary Artery (RCA) - an anatomical\nnorm variant of the coronary vasculature - the complexity of this procedure is\nincreased. Automated reporting of this variant from coronary CT angiography\nscreening would ease prior risk assessment. We propose a 1D convolutional\nneural network which leverages a sequence of residual dilated convolutions to\nautomatically determine this norm variant from a prior extracted vessel\ncenterline. As the SC RCA is not clearly defined with respect to concrete\nmeasurements, labeling also includes qualitative aspects. Therefore, 4.23%\nsamples in our dataset of 519 RCA centerlines were labeled as unsure SC RCAs,\nwith 5.97% being labeled as sure SC RCAs. We explore measures to handle this\nlabel uncertainty, namely global/model-wise random assignment, exclusion, and\nsoft label assignment. Furthermore, we evaluate how this uncertainty can be\nleveraged for the determination of a rejection class. With our best\nconfiguration, we reach an area under the receiver operating characteristic\ncurve (AUC) of 0.938 on confident labels. Moreover, we observe an increase of\nup to 0.020 AUC when rejecting 10% of the data and leveraging the labeling\nuncertainty information in the exclusion process.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:56:07 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01753","submitter":"Ehsan Qasemi","authors":"Ehsan Qasemi, Amani R. Maina-Kilaas, Devadutta Dash, Khalid Alsaggaf,\n  Muhao Chen","title":"Preconditioned Visual Language Inference with Weak Supervision","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Humans can infer the affordance of objects by extracting related contextual\npreconditions for each scenario. For example, upon seeing an image of a broken\ncup, we can infer that this precondition prevents the cup from being used for\ndrinking. Reasoning with preconditions of commonsense is studied in NLP where\nthe model explicitly gets the contextual precondition. However, it is unclear\nif SOTA visual language models (VLMs) can extract such preconditions and infer\nthe affordance of objects with them. In this work, we introduce the task of\npreconditioned visual language inference and rationalization (PVLIR). We\npropose a learning resource based on three strategies to retrieve weak\nsupervision signals for the task and develop a human-verified test set for\nevaluation. Our results reveal the shortcomings of SOTA VLM models in the task\nand draw a road map to address the challenges ahead in improving them.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 16:57:52 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01754","submitter":"Roshanak Zilouchian Moghaddam","authors":"Aaron Chan, Anant Kharkar, Roshanak Zilouchian Moghaddam, Yevhen\n  Mohylevskyy, Alec Helyar, Eslam Kamal, Mohamed Elkamhawy, Neel Sundaresan","title":"Transformer-based Vulnerability Detection in Code at EditTime:\n  Zero-shot, Few-shot, or Fine-tuning?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Software vulnerabilities bear enterprises significant costs. Despite\nextensive efforts in research and development of software vulnerability\ndetection methods, uncaught vulnerabilities continue to put software owners and\nusers at risk. Many current vulnerability detection methods require that code\nsnippets can compile and build before attempting detection. This,\nunfortunately, introduces a long latency between the time a vulnerability is\ninjected to the time it is removed, which can substantially increases the cost\nof fixing a vulnerability. We recognize that the current advances in machine\nlearning can be used to detect vulnerable code patterns on syntactically\nincomplete code snippets as the developer is writing the code at EditTime. In\nthis paper we present a practical system that leverages deep learning on a\nlarge-scale data set of vulnerable code patterns to learn complex\nmanifestations of more than 250 vulnerability types and detect vulnerable code\npatterns at EditTime. We discuss zero-shot, few-shot, and fine-tuning\napproaches on state of the art pre-trained Large Language Models (LLMs). We\nshow that in comparison with state of the art vulnerability detection models\nour approach improves the state of the art by 10%. We also evaluate our\napproach to detect vulnerability in auto-generated code by code LLMs.\nEvaluation on a benchmark of high-risk code scenarios shows a reduction of up\nto 90% vulnerability reduction.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 01:21:55 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01755","submitter":"Charles Lovering J","authors":"Charles Lovering and Ellie Pavlick","title":"Training Priors Predict Text-To-Image Model Performance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-to-image models can often generate some relations, i.e., \"astronaut\nriding horse\", but fail to generate other relations composed of the same basic\nparts, i.e., \"horse riding astronaut\". These failures are often taken as\nevidence that the models rely on training priors rather than constructing novel\nimages compositionally. This paper tests this intuition directly on the\nstablediffusion 2.1 text-to-image model. By looking at the subject-verb-object\n(SVO) triads that form the backbone of these prompts (e.g., \"astronaut\",\n\"ride\", \"horse\"), we find that the more often an SVO triad appears in the\ntraining data, the better the model can generate an image aligned with that\ntriad. Here, by aligned we mean that each of the terms appears in the generated\nimage in the proper relation to each other. However, this increased frequency\nalso diminishes how well the model can generate an image aligned with the\nflipped triad. For example, if \"astronaut riding horse\" appears frequently in\nthe training data, the image for \"horse riding astronaut\" will tend to be\npoorly aligned. We also find that models often struggle to generate terms in\natypical roles, e.g., if \"horse\" is more often the semantic patient (object),\nthe model might struggle to visualize it as a semantic agent (subject). Our\nresults thus show that current models are biased to generate images aligned\nwith relations seen in training and provide important new data in the ongoing\ndebate on whether these text-to-image models employ abstract compositional\nstructure in a traditional sense, or rather, interpolate between relations\nexplicitly seen in the training data.\n","versions":[{"version":"v1","created":"Tue, 23 May 2023 04:54:26 GMT"}],"update_date":"2023-06-06"}
