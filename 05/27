{"id":"2305.17050","submitter":"Cunxiang Wang","authors":"Cunxiang Wang, Zhikun Xu, Qipeng Guo, Xiangkun Hu, Xuefeng Bai, Zheng\n  Zhang, Yue Zhang","title":"Exploiting Abstract Meaning Representation for Open-Domain Question\n  Answering","comments":"Accepted by ACL2023 findings, reviewer scores: 4 4 4","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Open-Domain Question Answering (ODQA) task involves retrieving and\nsubsequently generating answers from fine-grained relevant passages within a\ndatabase. Current systems leverage Pretrained Language Models (PLMs) to model\nthe relationship between questions and passages. However, the diversity in\nsurface form expressions can hinder the model's ability to capture accurate\ncorrelations, especially within complex contexts. Therefore, we utilize\nAbstract Meaning Representation (AMR) graphs to assist the model in\nunderstanding complex semantic information. We introduce a method known as\nGraph-as-Token (GST) to incorporate AMRs into PLMs. Results from Natural\nQuestions (NQ) and TriviaQA (TQ) demonstrate that our GST method can\nsignificantly improve performance, resulting in up to 2.44/3.17 Exact Match\nscore improvements on NQ/TQ respectively. Furthermore, our method enhances\nrobustness and outperforms alternative Graph Neural Network (GNN) methods for\nintegrating AMRs. To the best of our knowledge, we are the first to employ\nsemantic graphs in ODQA.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:00:16 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17051","submitter":"Bum Chul Kwon","authors":"Hwiyeon Kim, Joohee Kim, Yunha Han, Hwajung Hong, Oh-Sang Kwon,\n  Young-Woo Park, Niklas Elmqvist, Sungahn Ko, Bum Chul Kwon","title":"Towards Visualization Thumbnail Designs that Entice Reading Data-driven\n  Articles","comments":"To appear in IEEE Transactions on Visualization and Computer\n  Graphics, 16 pages, 6 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:1908.06922","journal-ref":null,"doi":"10.1109/TVCG.2023.3278304","report-no":null,"categories":"cs.HC cs.CY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  As online news increasingly include data journalism, there is a corresponding\nincrease in the incorporation of visualization in article thumbnail images.\nHowever, little research exists on the design rationale for visualization\nthumbnails, such as resizing, cropping, simplifying, and embellishing charts\nthat appear within the body of the associated article. Therefore, in this paper\nwe aim to understand these design choices and determine what makes a\nvisualization thumbnail inviting and interpretable. To this end, we first\nsurvey visualization thumbnails collected online and discuss visualization\nthumbnail practices with data journalists and news graphics designers. Based on\nthe survey and discussion results, we then define a design space for\nvisualization thumbnails and conduct a user study with four types of\nvisualization thumbnails derived from the design space. The study results\nindicate that different chart components play different roles in attracting\nreader attention and enhancing reader understandability of the visualization\nthumbnails. We also find various thumbnail design strategies for effectively\ncombining the charts' components, such as a data summary with highlights and\ndata labels, and a visual legend with text labels and Human Recognizable\nObjects (HROs), into thumbnails. Ultimately, we distill our findings into\ndesign implications that allow effective visualization thumbnail designs for\ndata-rich news articles. Our work can thus be seen as a first step toward\nproviding structured guidance on how to design compelling thumbnails for data\nstories.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:00:49 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17052","submitter":"Xinran Wang","authors":"Xinran Wang, Qi Le, Ahmad Faraz Khan, Jie Ding, Ali Anwar","title":"A Framework for Incentivized Collaborative Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CY cs.GT cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collaborations among various entities, such as companies, research labs, AI\nagents, and edge devices, have become increasingly crucial for achieving\nmachine learning tasks that cannot be accomplished by a single entity alone.\nThis is likely due to factors such as security constraints, privacy concerns,\nand limitations in computation resources. As a result, collaborative learning\n(CL) research has been gaining momentum. However, a significant challenge in\npractical applications of CL is how to effectively incentivize multiple\nentities to collaborate before any collaboration occurs. In this study, we\npropose ICL, a general framework for incentivized collaborative learning, and\nprovide insights into the critical issue of when and why incentives can improve\ncollaboration performance. Furthermore, we show the broad applicability of ICL\nto specific cases in federated learning, assisted learning, and multi-armed\nbandit with both theory and experimental results.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:00:59 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17053","submitter":"Clotilde Fermanian","authors":"Clotilde Fermanian Kammerer, Caroline Lasser, Didier Robert","title":"Asymptotic initial value representation of the solutions of\n  semi-classical systems presenting smooth codimension one crossings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper is devoted to the construction of approximations of the propagator\nassociated with a semi-classical matrix-valued Schr\\\"odinger operator with\nsymbol presenting smooth eigenvalues crossings. Inspired by the approach of the\ntheoretical chemists Herman and Kluk who propagated continuous superpositions\nof Gaussian wave-packets for scalar equations, we consider frozen and thawed\nGaussian initial value representations that incorporate classical transport and\nbranching processes along a hopping hypersurface. Based on the Gaussian\nwave-packet framework, our result relies on an accurate analysis of the\nsolutions of the associated Schr\\\"odinger equation for data that are\nvector-valued wave-packets. We prove that these solutions are asymptotic to\nwavepackets at any order in terms of the semi-classical parameter.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:01:14 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17054","submitter":"Peidi Xu","authors":"Peidi Xu, Olga Sosnovtseva, Charlotte Mehlin S{\\o}rensen, Kenny\n  Erleben, Sune Darkner","title":"Extremely weakly-supervised blood vessel segmentation with\n  physiologically based synthesis and domain adaptation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Accurate analysis and modeling of renal functions require a precise\nsegmentation of the renal blood vessels. Micro-CT scans provide image data at\nhigher resolutions, making more small vessels near the renal cortex visible.\nAlthough deep-learning-based methods have shown state-of-the-art performance in\nautomatic blood vessel segmentations, they require a large amount of labeled\ntraining data. However, voxel-wise labeling in micro-CT scans is extremely\ntime-consuming given the huge volume sizes. To mitigate the problem, we\nsimulate synthetic renal vascular trees physiologically while generating\ncorresponding scans of the simulated trees by training a generative model on\nunlabeled scans. This enables the generative model to learn the mapping\nimplicitly without the need for explicit functions to emulate the image\nacquisition process. We further propose an additional segmentation branch over\nthe generative model trained on the generated scans. We demonstrate that the\nmodel can directly segment blood vessels on real scans and validate our method\non both 3D micro-CT scans of rat kidneys and a proof-of-concept experiment on\n2D retinal images. Code and 3D results are available at\nhttps://github.com/miccai2023anony/RenalVesselSeg\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:01:49 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17055","submitter":"George Filandrianos","authors":"Giorgos Filandrianos, Edmund Dervakos, Orfeas Menis-Mastromichalakis,\n  Chrysoula Zerva, Giorgos Stamou","title":"Counterfactuals of Counterfactuals: a back-translation-inspired approach\n  to analyse counterfactual editors","comments":"Accepted at Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In the wake of responsible AI, interpretability methods, which attempt to\nprovide an explanation for the predictions of neural models have seen rapid\nprogress. In this work, we are concerned with explanations that are applicable\nto natural language processing (NLP) models and tasks, and we focus\nspecifically on the analysis of counterfactual, contrastive explanations. We\nnote that while there have been several explainers proposed to produce\ncounterfactual explanations, their behaviour can vary significantly and the\nlack of a universal ground truth for the counterfactual edits imposes an\ninsuperable barrier on their evaluation. We propose a new back\ntranslation-inspired evaluation methodology that utilises earlier outputs of\nthe explainer as ground truth proxies to investigate the consistency of\nexplainers. We show that by iteratively feeding the counterfactual to the\nexplainer we can obtain valuable insights into the behaviour of both the\npredictor and the explainer models, and infer patterns that would be otherwise\nobscured. Using this methodology, we conduct a thorough analysis and propose a\nnovel metric to evaluate the consistency of counterfactual generation\napproaches with different characteristics across available performance\nindicators.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:04:28 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17056","submitter":"Giuseppe De Laurentis","authors":"Samuel Abreu, Giuseppe De Laurentis, Harald Ita, Maximillian Klinkert,\n  Ben Page, Vasily Sotnikov","title":"Two-Loop QCD Corrections for Three-Photon Production at Hadron Colliders","comments":"38 pages, 5 figures, 6 tables","journal-ref":null,"doi":null,"report-no":"CERN-TH-2023-090, PSI-PR-23-16, ZU-TH 23/23","categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We complete the computation of the two-loop helicity amplitudes for the\nproduction of three photons at hadron colliders, including all contributions\nbeyond the leading-color approximation. We reconstruct the analytic form of the\namplitudes from numerical finite-field samples obtained with the numerical\nunitarity method. This method requires as input surface terms for all relevant\nfive-point non-planar integral topologies, which we obtain by solving the\nassociated syzygy problem in embedding space. The numerical samples are used to\nconstrain compact spinor-helicity ans\\\"atze, which are optimized by taking\nadvantage of the known one-loop analytic structure. We make our analytic\nresults available in a public C++ library, which is suitable for immediate\nphenomenological applications. We estimate that the inclusion of the\nsubleading-color contributions will decrease the size of the two-loop\ncorrections by about 30% to 50% compared to the results in the leading-color\napproximation.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:07:02 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17057","submitter":"Cole Graham","authors":"Julien Berestycki, Cole Graham, Yujin H. Kim, Bastien Mallein","title":"KPP traveling waves in the half-space","comments":"54 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study traveling waves of the KPP equation in the half-space with Dirichlet\nboundary conditions. We show that minimal-speed waves are unique up to\ntranslation and rotation but faster waves are not. We represent our waves as\nLaplace transforms of martingales associated to branching Brownian motion in\nthe half-plane with killing on the boundary. We thereby identify the waves'\nasymptotic behavior and uncover a novel feature of the minimal-speed wave\n$\\Phi$. Far from the boundary, $\\Phi$ converges to a logarithmic shift of the\none-dimensional wave $w$ of the same speed: $\\displaystyle \\lim_{y \\to \\infty}\n\\Phi\\big(x + \\tfrac{1}{\\sqrt{2}}\\log y, y\\big) = w(x)$.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:09:52 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17058","submitter":"Fabian Zaiser","authors":"Fabian Zaiser, Andrzej S. Murawski, Luke Ong","title":"Exact Bayesian Inference on Discrete Models via Probability Generating\n  Functions: A Probabilistic Programming Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.LG stat.CO stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present an exact Bayesian inference method for discrete statistical\nmodels, which can find exact solutions to many discrete inference problems,\neven with infinite support and continuous priors. To express such models, we\nintroduce a probabilistic programming language that supports discrete and\ncontinuous sampling, discrete observations, affine functions, (stochastic)\nbranching, and conditioning on events. Our key tool is probability generating\nfunctions: they provide a compact closed-form representation of distributions\nthat are definable by programs, thus enabling the exact computation of\nposterior probabilities, expectation, variance, and higher moments. Our\ninference method is provably correct, fully automated and uses automatic\ndifferentiation (specifically, Taylor polynomials), but does not require\ncomputer algebra. Our experiments show that its performance on a range of\nreal-world examples is competitive with approximate Monte Carlo methods, while\navoiding approximation errors.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:09:59 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17059","submitter":"Lyubomyr Zdomskyy","authors":"Serhii Bardyla, Fortunato Maesano, Lyubomyr Zdomskyy","title":"Selective separability properties of Fr\\'echet-Urysohn spaces and their\n  products","comments":"31 pages; comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GN math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we study the behaviour of selective separability properties in\nthe class of Frech\\'{e}t-Urysohn spaces. We present two examples, the first one\ngiven in ZFC proves the existence of a countable Frech\\'{e}t-Urysohn (hence\n$R$-separable and selectively separable) space which is not $H$-separable;\nassuming $\\mathfrak{p}=\\mathfrak{c}$, we construct such an example which is\nalso zero-dimensional and $\\alpha_{4}$. Also, motivated by a result of Barman\nand Dow stating that the product of two countable Frech\\'{e}t-Urysohn spaces is\n$M$-separable under PFA, we show that the MA is not sufficient here. In the\nlast section we prove that in the Laver model, the product of any two\n$H$-separable spaces is $mH$-separable.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:10:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17060","submitter":"Ann Wehrle","authors":"Ann E. Wehrle (Space Science Institute), Michael Carini (Western\n  Kentucky University), Paul J. Wiita (The College of New Jersey), Joshua\n  Pepper (Lehigh University), B. Scott Gaudi (The Ohio State University),\n  Richard W. Pogge (The Ohio State Univserity), Keivan G. Stassun (Vanderbilt\n  University), and Steven Villaneuva, Jr. (NASA Goddard Space Flight Center)","title":"K2 Optical Emission from OJ 287 and Other Gamma-Ray Blazars on\n  Hours-to-Weeks Timescales from 2014-2018","comments":"35 pages, 8 figures. Accepted for publication in the Astrophysical\n  Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present second observations by K2 of OJ~287 and 7 other $\\gamma$-ray AGNs\nobtained in 2017-2018, second and third observations of the lobe-dominated,\nsteep spectrum quasar 3C~207, and observations of 9 additional blazars not\npreviously observed with K2. The AGN were observed simultaneously with K2 and\nthe Fermi Large Area Telescope for 51-81 days. Our full sample, observed in\n2014-2018, contained 16 BL Lac objects (BL Lacs), 9 Flat Spectrum Radio Quasars\n(FSRQs), and 4 other $\\gamma$-ray AGNs. Twelve BL Lacs and 7 FSRQs exhibited\nfast, jagged light curves while 4 BL Lacs and 2 FSRQs had slow, smooth light\ncurves. Some objects changed their red-noise character significantly between\nrepeated K2 observations. The optical characteristics of OJ~287 derived from\nthe short-cadence K2 light curves changed between observations made before and\nafter the predicted passage of the suspected secondary supermassive black hole\nthrough the accretion disk of the primary supermassive black hole. The average\nslopes of the periodogram power spectral densities of the BL Lacs' and FSRQs'\nlight curves differed significantly, by $\\approx 12$\\%, with the BL Lac slopes\nbeing steeper, and a KS test with a $p$-value of 0.039 indicates that these\nsamples probably come from different populations; however, this result is not\nas strongly supported by PSRESP analyses. Differences in the origin of the jets\nfrom the ergosphere or accretion disk in these two classes could produce such a\ndisparity, as could different sizes or locations of emission regions within the\njets.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:14:40 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17061","submitter":"Lucas Brivadis","authors":"Lucas Brivadis (L2S), Antoine Chaillet (IUF, L2S), Jean Auriol (L2S)","title":"Adaptive observer and control of spatiotemporal delayed neural fields","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  An adaptive observer is proposed to estimate the synaptic distribution\nbetween neurons asymptotically from the measurement of a part of the neuronal\nactivity and a delayed neural field evolution model. The convergence of the\nobserver is proved under a persistency of excitation condition. Then, the\nobserver is used to derive a feedback law ensuring asymptotic stabilization of\nthe neural fields. Finally, the feedback law is modified to ensure\nsimultaneously practical stabilization of the neural fields and asymptotic\nconvergence of the observer under additional restrictions on the system.\nNumerical simulations confirm the relevance of the approach.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:17:09 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17062","submitter":"Kaho Yoshimura","authors":"Yoshihiko Abe, Toshifumi Noumi, Kaho Yoshimura","title":"Black Hole Extremality in Nonlinear Electrodynamics: A Lesson for Weak\n  Gravity and Festina Lente Bounds","comments":"37 pages, 18 figures","journal-ref":null,"doi":null,"report-no":"KOBE-COSMO-23-06, UT-Komaba/23-4","categories":"hep-th gr-qc hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study black hole extremality in nonlinear electrodynamics motivated by the\nWeak Gravity Conjecture (WGC) and the Festina Lente (FL) bound. For\nillustration, we consider the Euler-Heisenberg model and the Dirac-Born-Infeld\nmodel in asymptotically flat spacetime, de Sitter spacetime, and anti-de Sitter\nspacetime. We find that in all cases the extremal condition enjoys a certain\nmonotonicity expected by the WGC. This provides evidences for the conjecture\nbeyond the leading order corrections to the Einstein-Maxwell theory. We also\nstudy how light charged particles modify the mass-charge relation of Nariai\nblack holes in de Sitter spacetime and discuss possible implications for the FL\nbound. Besides, we point out an interesting similarity between our black hole\nanalysis and gravitational positivity bounds on scattering amplitudes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:18:44 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17063","submitter":"Felix Jimenez","authors":"Felix Jimenez, Matthias Katzfuss","title":"Vecchia Gaussian Process Ensembles on Internal Representations of Deep\n  Neural Networks","comments":"16 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For regression tasks, standard Gaussian processes (GPs) provide natural\nuncertainty quantification, while deep neural networks (DNNs) excel at\nrepresentation learning. We propose to synergistically combine these two\napproaches in a hybrid method consisting of an ensemble of GPs built on the\noutput of hidden layers of a DNN. GP scalability is achieved via Vecchia\napproximations that exploit nearest-neighbor conditional independence. The\nresulting deep Vecchia ensemble not only imbues the DNN with uncertainty\nquantification but can also provide more accurate and robust predictions. We\ndemonstrate the utility of our model on several datasets and carry out\nexperiments to understand the inner workings of the proposed method.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:19:26 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17064","submitter":"Madeleine Kubasch","authors":"Madeleine Kubasch (CMAP, MaIAGE)","title":"Large population limit for a multilayer SIR model including households\n  and workplaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR physics.soc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a multilayer SIR model with two levels of mixing, namely a global\nlevel which is uniformly mixing, and a local level with two layers\ndistinguishing household and workplace contacts, respectively. We establish the\nlarge population convergence of the corresponding stochastic process. For this\npurpose, we use an individual-based model whose state space explicitly takes\ninto account the duration of infectious periods. This allows to deal with the\nnatural correlation of the epidemic states of individuals whose household and\nworkplace share a common infected. In a general setting where a non-exponential\ndistribution of infectious periods may be considered, convergence to the unique\ndeterministic solution of a measurevalued equation is obtained. In the\nparticular case of exponentially distributed infectious periods, we show that\nit is possible to further reduce the obtained deterministic limit, leading to a\nclosed, finite dimensional dynamical system capturing the epidemic dynamics.\nThis model reduction subsequently is studied from a numerical point of view. We\nillustrate that the dynamical system derived from the large population\napproximation is a pertinent model reduction when compared to simulations of\nthe stochastic process or to an alternative edgebased compartmental model, both\nin terms of accuracy and computational cost.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:20:48 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17065","submitter":"Alexander Chaushev","authors":"Alexander Chaushev, Steph Sallum, Julien Lozi, Frantz Martinache,\n  Jeffrey Chilcote, Tyler Groff, Olivier Guyon, N. Jeremy Kasdin, Barnaby\n  Norris, Andy Skemer","title":"Spectrally dispersed kernel phase interferometry with SCExAO/CHARIS:\n  proof of concept and calibration strategies","comments":"18 pages, 12 figures, accepted for publication in JATIS","journal-ref":"J. Astron. Telesc. Instrum. Syst. 9(2), 028004 (2023)","doi":"10.1117/1.JATIS.9.2.028004","report-no":null,"categories":"astro-ph.IM astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Kernel phase interferometry (KPI) is a data processing technique that allows\nfor the detection of asymmetries (such as companions or disks) in high-Strehl\nimages, close to and within the classical diffraction limit. We show that KPI\ncan successfully be applied to hyperspectral image cubes generated from\nintegral field spectrographs (IFSs). We demonstrate this technique of\nspectrally-dispersed kernel phase by recovering a known binary with the\nSCExAO/CHARIS IFS in high-resolution K-band mode. We also explore a spectral\ndifferential imaging (SDI) calibration strategy that takes advantage of the\ninformation available in images from multiple wavelength bins. Such\ncalibrations have the potential to mitigate high-order, residual systematic\nkernel phase errors, which currently limit the achievable contrast of KPI. The\nSDI calibration presented here is applicable to searches for line emission or\nsharp absorption features, and is a promising avenue toward achieving\nphoton-noise-limited kernel phase observations. The high angular resolution and\nspectral coverage provided by dispersed kernel phase offers novel opportunities\nfor science observations which would have been challenging to achieve\notherwise.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:21:20 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17066","submitter":"Dylan Ashley","authors":"Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan R. Ashley,\n  R\\'obert Csord\\'as, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al Kader\n  Hammoud, Vincent Herrmann, Kazuki Irie, Louis Kirsch, Bing Li, Guohao Li,\n  Shuming Liu, Jinjie Mai, Piotr Pi\\k{e}kos, Aditya Ramesh, Imanol Schlag,\n  Weimin Shi, Aleksandar Stani\\'c, Wenyi Wang, Yuhui Wang, Mengmeng Xu,\n  Deng-Ping Fan, Bernard Ghanem, J\\\"urgen Schmidhuber","title":"Mindstorms in Natural Language-Based Societies of Mind","comments":"9 pages in main text + 7 pages of references + 38 pages of\n  appendices, 14 figures in main text + 13 in appendices, 7 tables in\n  appendices","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL cs.CV cs.LG cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Both Minsky's \"society of mind\" and Schmidhuber's \"learning to think\" inspire\ndiverse societies of large multimodal neural networks (NNs) that solve problems\nby interviewing each other in a \"mindstorm.\" Recent implementations of NN-based\nsocieties of minds consist of large language models (LLMs) and other NN-based\nexperts communicating through a natural language interface. In doing so, they\novercome the limitations of single LLMs, improving multimodal zero-shot\nreasoning. In these natural language-based societies of mind (NLSOMs), new\nagents -- all communicating through the same universal symbolic language -- are\neasily added in a modular fashion. To demonstrate the power of NLSOMs, we\nassemble and experiment with several of them (having up to 129 members),\nleveraging mindstorms in them to solve some practical AI tasks: visual question\nanswering, image captioning, text-to-image synthesis, 3D generation, egocentric\nretrieval, embodied AI, and general language-based task solving. We view this\nas a starting point towards much larger NLSOMs with billions of agents-some of\nwhich may be humans. And with this emergence of great societies of\nheterogeneous minds, many new research questions have suddenly become paramount\nto the future of artificial intelligence. What should be the social structure\nof an NLSOM? What would be the (dis)advantages of having a monarchical rather\nthan a democratic structure? How can principles of NN economies be used to\nmaximize the total reward of a reinforcement learning NLSOM? In this work, we\nidentify, discuss, and try to answer some of these questions.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:21:25 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17067","submitter":"Ana Trisovic","authors":"Ana Trisovic","title":"Cluster Analysis of Open Research Data and a Case for Replication\n  Metadata","comments":null,"journal-ref":"2022 IEEE 18th International Conference on e-Science (e-Science),\n  Salt Lake City, UT, USA, 2022, pp. 423-424","doi":"10.1109/eScience55777.2022.00069","report-no":null,"categories":"cs.DL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Research data are often released upon journal publication to enable result\nverification and reproducibility. For that reason, research dissemination\ninfrastructures typically support diverse datasets coming from numerous\ndisciplines, from tabular data and program code to audio-visual files.\nMetadata, or data about data, is critical to making research outputs adequately\ndocumented and FAIR. Aiming to contribute to the discussions on the development\nof metadata for research outputs, I conducted an exploratory analysis to\ndetermine how research datasets cluster based on what researchers organically\ndeposit together. I use the content of over 40,000 datasets from the Harvard\nDataverse research data repository as my sample for the cluster analysis. I\nfind that the majority of the clusters are formed by single-type datasets,\nwhile in the rest of the sample, no meaningful clusters can be identified. For\nthe result interpretation, I use the metadata standard employed by DataCite, a\nleading organization for documenting a scholarly record, and map existing\nresource types to my results. About 65% of the sample can be described with a\nsingle-type metadata (such as Dataset, Software or Report), while the rest\nwould require aggregate metadata types. Though DataCite supports an aggregate\ntype such as a Collection, I argue that a significant number of datasets, in\nparticular those containing both data and code files (about 20% of the sample)\nwould be more accurately described as a Replication resource metadata type.\nSuch resource type would be particularly useful in facilitating research\nreproducibility.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:22:13 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17068","submitter":"Fabio Sailis","authors":"Olalla A. Castro-Alvaredo, Stefano Negro, Fabio Sailis","title":"Completing the Bootstrap Program for\n  $\\mathrm{T}\\bar{\\mathrm{T}}$-Deformed Massive Integrable Quantum Field\n  Theories","comments":"5 pages (letter), 3 pages (supplementary material), 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In recent years a considerable amount of attention has been devoted to the\ninvestigation of 2D quantum field theories perturbed by certain types of\nirrelevant operators. These are the composite field\n$\\mathrm{T}\\bar{\\mathrm{T}}$ - constructed out of the components of the\nstress-energy tensor - and its generalisations - built from higher-spin\nconserved currents. The effect of such perturbations on the infrared and\nultraviolet properties of the theory has been extensively investigated. In the\ncontext of integrable quantum field theories, a fruitful perspective is that of\nfactorised scattering theory. In fact, the above perturbations were shown to\npreserve integrability. The resulting deformed scattering matrices -\nextensively analysed with the thermodynamic Bethe ansatz - provide the first\nstep in the development of a complete bootstrap program. In this letter we\npresent a systematic approach to computing matrix elements of operators in\ngeneralised $\\mathrm{T}\\bar{\\mathrm{T}}$-perturbed models, based on employing\nthe standard form factor program. Our approach is very general and can be\napplied to all theories with diagonal scattering. We show that the deformed\nform factors, just as happens for the $S$-matrix, factorise into the product of\nthe undeformed ones and of a perturbation- and theory-dependent term. From\nthese solutions, correlation functions can be obtained and their asymptotic\nproperties studied. Our results set the foundations of a new research program\nfor massive integrable quantum field theory perturbed by irrelevant operators.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:24:07 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17069","submitter":"Marcus Spradlin","authors":"Luke Lippstreu, Marcus Spradlin, Akshay Yelleshpur Srikant, Anastasia\n  Volovich","title":"Landau Singularities of the 7-Point Ziggurat II","comments":"22 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We solve the Landau equations to find the singularities of nine three-loop\n7-point graphs that arise as relaxations of the \"ziggurat'' graph studied in\narXiv:2211.16425. Along the way we establish that $Y{-}\\Delta$ equivalence\nfails for certain branches of solutions to the Landau equations. We find two\ngraphs with singularities outside the heptagon symbol alphabet; in particular\nthey are not cluster variables of ${\\rm Gr}(4,7)$. We compare maximal residues\nof scalar graphs exhibiting these singularities to those in $\\mathcal{N}=4$\nsuper-Yang-Mills theory in order to probe their cancellation from its\namplitudes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:25:13 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17070","submitter":"Nguyen-Thi Dang","authors":"Nguyen-Thi Dang (LMO), Jialun Li (CMLS)","title":"Equidistribution and counting of periodic tori in the space of Weyl\n  chambers","comments":"arXiv admin note: substantial text overlap with arXiv:2202.08323","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let G be a semisimple Lie group without compact factor and $\\Gamma$ < G a\ntorsion-free, cocompact, irreducible lattice. According to Selberg, periodic\norbits of regular Weyl chamber flows live on tori. We prove that these periodic\ntori equidistribute exponentially fast towards the quotient of the Haar\nmeasure. From the equidistribution formula, we deduce a higher rank prime\ngeodesic theorem.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:28:14 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17071","submitter":"Jinhang Zuo","authors":"Jinhang Zuo, Zhiyao Zhang, Zhiyong Wang, Shuai Li, Mohammad\n  Hajiesmaili, Adam Wierman","title":"Adversarial Attacks on Online Learning to Rank with Click Feedback","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CR cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Online learning to rank (OLTR) is a sequential decision-making problem where\na learning agent selects an ordered list of items and receives feedback through\nuser clicks. Although potential attacks against OLTR algorithms may cause\nserious losses in real-world applications, little is known about adversarial\nattacks on OLTR. This paper studies attack strategies against multiple variants\nof OLTR. Our first result provides an attack strategy against the UCB algorithm\non classical stochastic bandits with binary feedback, which solves the key\nissues caused by bounded and discrete feedback that previous works can not\nhandle. Building on this result, we design attack algorithms against UCB-based\nOLTR algorithms in position-based and cascade models. Finally, we propose a\ngeneral attack strategy against any algorithm under the general click model.\nEach attack algorithm manipulates the learning agent into choosing the target\nattack item $T-o(T)$ times, incurring a cumulative cost of $o(T)$. Experiments\non synthetic and real data further validate the effectiveness of our proposed\nattack algorithms.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:28:26 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17072","submitter":"Eddie Ungless","authors":"Eddie L. Ungless, Bj\\\"orn Ross and Anne Lauscher","title":"Stereotypes and Smut: The (Mis)representation of Non-cisgender\n  Identities by Text-to-Image Models","comments":"Accepted to ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cutting-edge image generation has been praised for producing high-quality\nimages, suggesting a ubiquitous future in a variety of applications. However,\ninitial studies have pointed to the potential for harm due to predictive bias,\nreflecting and potentially reinforcing cultural stereotypes. In this work, we\nare the first to investigate how multimodal models handle diverse gender\nidentities. Concretely, we conduct a thorough analysis in which we compare the\noutput of three image generation models for prompts containing cisgender vs.\nnon-cisgender identity terms. Our findings demonstrate that certain\nnon-cisgender identities are consistently (mis)represented as less human, more\nstereotyped and more sexualised. We complement our experimental analysis with\n(a)~a survey among non-cisgender individuals and (b) a series of interviews, to\nestablish which harms affected individuals anticipate, and how they would like\nto be represented. We find respondents are particularly concerned about\nmisrepresentation, and the potential to drive harmful behaviours and beliefs.\nSimple heuristics to limit offensive content are widely rejected, and instead\nrespondents call for community involvement, curated training data and the\nability to customise. These improvements could pave the way for a future where\nchange is led by the affected community, and technology is used to positively\n``[portray] queerness in ways that we haven't even thought of'' rather than\nreproducing stale, offensive stereotypes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:28:49 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17073","submitter":"Nadir Durrani Dr","authors":"Fahim Dalvi and Hassan Sajjad and Nadir Durrani","title":"NeuroX Library for Neuron Analysis of Deep NLP Models","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Neuron analysis provides insights into how knowledge is structured in\nrepresentations and discovers the role of neurons in the network. In addition\nto developing an understanding of our models, neuron analysis enables various\napplications such as debiasing, domain adaptation and architectural search. We\npresent NeuroX, a comprehensive open-source toolkit to conduct neuron analysis\nof natural language processing models. It implements various interpretation\nmethods under a unified API, and provides a framework for data processing and\nevaluation, thus making it easier for researchers and practitioners to perform\nneuron analysis. The Python toolkit is available at\nhttps://www.github.com/fdalvi/NeuroX. Demo Video available at\nhttps://youtu.be/mLhs2YMx4u8.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:32:56 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17074","submitter":"Spyridon Zafeiris Mr","authors":"Spiros Zafeiris, George Papadakis","title":"An Overset Algorithm for Multiphase Flows using 3D Multiblock Polyhedral\n  Meshes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we present a parallel topology algorithm with a suitable\ninterpolation method for chimera simulations in CFD. The implementation is done\nin the unstructured Finite Volume (FV) framework and special attention is given\nto the numerical algorithm. The aim of the proposed algorithm is to approximate\nfields with discontinuities with application to two-phase incompressible flows.\nFirst, the overset topology problem in partitioned polyhedral meshes is\naddressed, and then a new interpolation algorithm for generally discontinuous\nfields is introduced. We describe how the properties of FV are used in favor of\nthe interpolation algorithm and how this intuitive process helps to achieve\nhigh-resolution results. The performance of the proposed algorithm is\nquantified and tested in various test cases, together with a comparison with an\nalready existing interpolation scheme. Finally, scalability tests are presented\nto prove computational efficiency. The method suggests to be highly accurate in\npropagation cases and performs well in unsteady two-phase problems executed in\nparallel architectures.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:33:17 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17075","submitter":"Marcos Vin\\'icius Treviso","authors":"Marcos Treviso, Alexis Ross, Nuno M. Guerreiro, Andr\\'e F. T. Martins","title":"CREST: A Joint Framework for Rationalization and Counterfactual Text\n  Generation","comments":"Accepted at ACL 2023 (main)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Selective rationales and counterfactual examples have emerged as two\neffective, complementary classes of interpretability methods for analyzing and\ntraining NLP models. However, prior work has not explored how these methods can\nbe integrated to combine their complementary advantages. We overcome this\nlimitation by introducing CREST (ContRastive Edits with Sparse\nraTionalization), a joint framework for selective rationalization and\ncounterfactual text generation, and show that this framework leads to\nimprovements in counterfactual quality, model robustness, and interpretability.\nFirst, CREST generates valid counterfactuals that are more natural than those\nproduced by previous methods, and subsequently can be used for data\naugmentation at scale, reducing the need for human-generated examples. Second,\nwe introduce a new loss function that leverages CREST counterfactuals to\nregularize selective rationales and show that this regularization improves both\nmodel robustness and rationale quality, compared to methods that do not\nleverage CREST counterfactuals. Our results demonstrate that CREST successfully\nbridges the gap between selective rationales and counterfactual examples,\naddressing the limitations of existing methods and providing a more\ncomprehensive view of a model's predictions.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:34:58 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17076","submitter":"Waiss Azizian","authors":"Wa\\\"iss Azizian (DAO), Franck Iutzeler (DAO), J\\'er\\^ome Malick (DAO)","title":"Exact Generalization Guarantees for (Regularized) Wasserstein\n  Distributionally Robust Models","comments":"46 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Wasserstein distributionally robust estimators have emerged as powerful\nmodels for prediction and decision-making under uncertainty. These estimators\nprovide attractive generalization guarantees: the robust objective obtained\nfrom the training distribution is an exact upper bound on the true risk with\nhigh probability. However, existing guarantees either suffer from the curse of\ndimensionality, are restricted to specific settings, or lead to spurious error\nterms. In this paper, we show that these generalization guarantees actually\nhold on general classes of models, do not suffer from the curse of\ndimensionality, and can even cover distribution shifts at testing. We also\nprove that these results carry over to the newly-introduced regularized\nversions of Wasserstein distributionally robust problems.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:35:57 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17077","submitter":"Daman Arora","authors":"Daman Arora and Subbarao Kambhampati","title":"Learning and Leveraging Verifiers to Improve Planning Capabilities of\n  Pre-trained Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  There have been wide spread claims in the literature about the emergent\nreasoning capabilities of Pretrained Large Language Models. However, recent\nstudies, have found that their ability to plan remains questionable. Through\nour experiments using GPT-2, we empirically demonstrate that the performance of\na finetuned baseline remains poor because it violates pre-conditions of actions\nin the plans that it generates. To improve the planning capabilities of a\nfinetuned LLM, we train a verifier, which can classify actions as being valid\nor invalid in a particular state. By randomly sampling actions from the same\ndataset, we generate examples of invalid actions which are then used to train a\nverifier which can check for action applicability. In the presence of diverse\nsampling from a generator and a verifier which can prune invalid trajectories,\nwe show significant gains in the success rate on the Blocksworld domain.\nAdditionally, we show that finetuning the GPT-2 generator itself to create the\nverifier generalizes better than finetuning the base GPT-2. Lastly, we\ninvestigate the role of the sampling temperature which can be used to control\nthe exploration-exploitation tradeoff.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:36:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17078","submitter":"K\\'evin L\\'ev\\^eque-Simon","authors":"K. L\\'ev\\^eque-Simon, A. Camper, R. Ta\\\"ieb, J. Caillat, C.\n  L\\'ev\\^eque, E. Giner","title":"Production of positronium chloride: A study of the charge exchange\n  reaction between Ps and Cl$^{-}$","comments":"12 Pages, 8 Figures, 2 Tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present cross sections for the formation of positronium chloride (PsCl) in\nits ground state from the charge exchange between positronium (Ps) and chloride\n(Cl$^-$) in the range of 10 meV - 100 eV Ps energy. We have used theoretical\nmodels based on the first Born approximation in its three-body formulation. We\nsimulated the collisions between Ps and Cl$^-$ using ab-initio methods at both\nmean-field and correlated levels extrapolated to the complete basis set limit.\nWe have investigated Ps excited states up to ${n=4}$. The results suggest that\nthe channel Ps(${n=2}$) is of particular interest for the production of PsCl in\nthe ground state, and shows that an accurate treatment of the electronic\ncorrelation leads to a significant change in the global shape of the PsCl\nproduction cross section with respect to the mean-field level.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:37:44 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17079","submitter":"Felix Stutz","authors":"Elaine Li, Felix Stutz, Thomas Wies, Damien Zufferey","title":"Complete Multiparty Session Type Projection with Automata","comments":"25 pages, 45 pages including appendix; to appear in CAV 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.FL cs.DC cs.PL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multiparty session types (MSTs) are a type-based approach to verifying\ncommunication protocols. Central to MSTs is a projection operator: a partial\nfunction that maps protocols represented as global types to\ncorrect-by-construction implementations for each participant, represented as a\ncommunicating state machine. Existing projection operators are syntactic in\nnature, and trade efficiency for completeness. We present the first projection\noperator that is sound, complete, and efficient. Our projection separates\nsynthesis from checking implementability. For synthesis, we use a simple\nautomata-theoretic construction; for checking implementability, we present\nsuccinct conditions that summarize insights into the property of\nimplementability. We use these conditions to show that MST implementability is\nPSPACE-complete. This improves upon a previous decision procedure that is in\nEXPSPACE and applies to a smaller class of MSTs. We demonstrate the\neffectiveness of our approach using a prototype implementation, which handles\nglobal types not supported by previous work without sacrificing performance.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:38:37 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17080","submitter":"Yung-Sung Chuang","authors":"Yung-Sung Chuang, Wei Fang, Shang-Wen Li, Wen-tau Yih, James Glass","title":"Expand, Rerank, and Retrieve: Query Reranking for Open-Domain Question\n  Answering","comments":"ACL 2023 long paper (Findings)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose EAR, a query Expansion And Reranking approach for improving\npassage retrieval, with the application to open-domain question answering. EAR\nfirst applies a query expansion model to generate a diverse set of queries, and\nthen uses a query reranker to select the ones that could lead to better\nretrieval results. Motivated by the observation that the best query expansion\noften is not picked by greedy decoding, EAR trains its reranker to predict the\nrank orders of the gold passages when issuing the expanded queries to a given\nretriever. By connecting better the query expansion model and retriever, EAR\nsignificantly enhances a traditional sparse retrieval method, BM25.\nEmpirically, EAR improves top-5/20 accuracy by 3-8 and 5-10 points in in-domain\nand out-of-domain settings, respectively, when compared to a vanilla query\nexpansion model, GAR, and a dense retrieval model, DPR.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:41:03 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17081","submitter":"Wolf-Juergen Beyn","authors":"Wolf-J\\\"urgen Beyn","title":"On a generalized notion of metrics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In these notes we generalize the notion of a (pseudo) metric measuring the\ndistance of two points, to a (pseudo) n-metric which assigns a value to a tuple\nof n points. We present two principles of constructing pseudo n-metrics. The\nfirst one uses the Vandermonde determinant while the second one uses exterior\nproducts and is related to the volume of the simplex spanned by the given\npoints. We show that the second class of examples induces pseudo n-metrics on\nthe unit sphere of a Hilbert space and on matrix manifolds such as the Stiefel\nand the Grassmann manifold. Further, we construct a pseudo n-metric on\nhypergraphs and discuss the problem of generalizing the Hausdorff metric for\nclosed sets to a pseudo n-metric.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:41:17 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17082","submitter":"Marco Berritta MBerritta","authors":"Marco Berritta, Stefano Scali, Federico Cerisola, Janet Anders","title":"Accounting for Quantum Effects in Atomistic Spin Dynamics","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Atomistic spin dynamics (ASD) is a standard tool to model the magnetization\ndynamics of a variety of materials. The fundamental dynamical model underlying\nASD is entirely classical. In this letter, we present two approaches to\neffectively incorporate quantum effects into ASD simulations, thus enhancing\ntheir low temperature predictions. The first allows to simulate the magnetic\nbehavior of a quantum spin system by solving the equations of motions of a\nclassical spin system at an effective temperature. This effective temperature\nis determined a priori from the microscopic properties of the system. The\nsecond approach is based on a semi-classical model where classical spins\ninteract with an environment with a quantum-like power spectrum. The parameters\nthat characterize this model can be calculated ab initio or extracted from\nexperiments. This semi-classical model quantitatively reproduces the\nlow-temperature behavior of a magnetic system, thus accounting for the quantum\nmechanical aspects of its dynamics. The methods presented here can be readily\nimplemented in current ASD simulations with no additional complexity cost.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:45:57 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17083","submitter":"Mao Hong","authors":"Mao Hong, Zhengling Qi, Yanxun Xu","title":"A Policy Gradient Method for Confounded POMDPs","comments":"84 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG econ.EM math.ST stat.ME stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we propose a policy gradient method for confounded partially\nobservable Markov decision processes (POMDPs) with continuous state and\nobservation spaces in the offline setting. We first establish a novel\nidentification result to non-parametrically estimate any history-dependent\npolicy gradient under POMDPs using the offline data. The identification enables\nus to solve a sequence of conditional moment restrictions and adopt the min-max\nlearning procedure with general function approximation for estimating the\npolicy gradient. We then provide a finite-sample non-asymptotic bound for\nestimating the gradient uniformly over a pre-specified policy class in terms of\nthe sample size, length of horizon, concentratability coefficient and the\nmeasure of ill-posedness in solving the conditional moment restrictions.\nLastly, by deploying the proposed gradient estimation in the gradient ascent\nalgorithm, we show the global convergence of the proposed algorithm in finding\nthe history-dependent optimal policy under some technical conditions. To the\nbest of our knowledge, this is the first work studying the policy gradient\nmethod for POMDPs under the offline setting.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:48:05 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17084","submitter":"Francesco Benini","authors":"Jeremias Aguilera Damia, Riccardo Argurio, Francesco Benini, Sergio\n  Benvenuti, Christian Copetti, Luigi Tizzano","title":"Non-invertible symmetries along 4d RG flows","comments":"48 pages + appendices","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We explore novel examples of RG flows preserving a non-invertible duality\nsymmetry. Our main focus is on $\\mathcal{N}=1$ quadratic superpotential\ndeformations of 4d $\\mathcal{N}=4$ super-Yang-Mills theory with gauge algebra\n$\\mathfrak{su}(N)$. A theory that can be obtained in this way is the so-called\n$\\mathcal{N}=1^*$ SYM where all adjoint chiral multiplets have a mass. Such IR\ntheory exhibits a rich structure of vacua which we thoroughly examine. Our\nanalysis elucidates the physics of spontaneous breaking of self-duality\nsymmetry occurring in the degenerate gapped vacua. The construction can be\ngeneralized, taking as UV starting point a theory of class $\\mathcal{S}$, to\ndemonstrate how non-invertible duality symmetries exist in a variety of\n$\\mathcal{N}=1$ SCFTs. We finally apply this understanding to prove that the\nconifold theory has a non-invertible duality symmetry.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:50:09 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17085","submitter":"Yevhen Kushnirenko Dr.","authors":"Yevhen Kushnirenko, Brinda Kuthanazhi, Lin-Lin Wang, Benjamin Schrunk,\n  Evan O'Leary, Andrew Eaton, P. C. Canfield and Adam Kaminski","title":"Directional effects of antiferromagnetic ordering on the electronic\n  structure in NdSb","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The recent discovery of unconventional surface state pairs, which give rise\nto Fermi arcs and spin textures, in antiferromagnetically ordered NdBi raised\nthe interest in rare-earth monopnictides. Several scenarios of\nantiferromagnetic order have been suggested to explain the origin of these\nstates with some of them being consistent with the presence of non-trivial\ntopologies. In this study, we use angle-resolved photoemission spectroscopy\n(ARPES) and density-functional-theory (DFT) calculations to investigate the\nelectronic structure of NdSb. We found the presence of distinct domains that\nhave different electronic structure at the surface. These domains correspond to\ndifferent orientations of magnetic moments in the AFM state with respect to the\nsurface. We demonstrated remarkable agreement between DFT calculations and\nARPES that capture all essential changes in the band structure caused by\ntransition to a magnetically ordered state.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:51:33 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17086","submitter":"Prabir Banik","authors":"Prabir Banik, Arunava Bhadra, and Sanjay K. Ghosh","title":"Sun is a cosmic ray TeVatron","comments":"5 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Very recently, HAWC observatory discovered the high-energy gamma ray emission\nfrom the solar disk during the quiescent stage of the sun, extending the\nFermi-LAT detection of intense, hard emission between 0.1 - 200 GeV to TeV\nenergies. The flux of these observed gamma-rays is significantly higher than\nthat theoretically expected from hadronic interactions of galactic cosmic rays\nwith the solar atmosphere. More importantly, spectral slope of Fermi and HAWC\nobserved gamma ray energy spectra differ significantly from that of galactic\ncosmic rays casting doubt on the prevailing galactic cosmic ray ancestry model\nof solar disk gamma rays. In this letter, we argue that the quiet sun can\naccelerate cosmic rays to TeV energies with an appropriate flux level in the\nsolar chromosphere, as the solar chromosphere in its quiet state probably\npossesses the required characteristics to accelerate cosmic rays to TeV\nenergies. Consequently, the mystery of the origin of observed gamma rays from\nthe solar disc can be resolved consistently through the hadronic interaction of\nthese cosmic rays with solar matter above the photosphere in a quiet state. The\nupcoming IceCube-Gen2 detector should be able to validate the proposed model in\nfuture through observation of TeV muon neutrino flux from the solar disk. The\nproposed idea should have major implications on the origin of galactic cosmic\nrays.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:55:43 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17087","submitter":"Ramviyas Parasuraman","authors":"Ehsan Latif and WenZhan Song and Ramviyas Parasuraman","title":"Communication-Efficient Reinforcement Learning in Swarm Robotic Networks\n  for Maze Exploration","comments":"Accepted to the IEEE INFOCOM 6th International Workshop on WIreless\n  Sensing and Actuating Robotic Networks (WISARN 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.MA cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Smooth coordination within a swarm robotic system is essential for the\neffective execution of collective robot missions. Having efficient\ncommunication is key to the successful coordination of swarm robots. This paper\nproposes a new communication-efficient decentralized cooperative reinforcement\nlearning algorithm for coordinating swarm robots. It is made efficient by\nhierarchically building on the use of local information exchanges. We consider\na case study application of maze solving through cooperation among a group of\nrobots, where the time and costs are minimized while avoiding inter-robot\ncollisions and path overlaps during exploration. With a solid theoretical\nbasis, we extensively analyze the algorithm with realistic CORE network\nsimulations and evaluate it against state-of-the-art solutions in terms of maze\ncoverage percentage and efficiency under communication-degraded environments.\nThe results demonstrate significantly higher coverage accuracy and efficiency\nwhile reducing costs and overlaps even in high packet loss and low\ncommunication range scenarios.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:56:00 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17088","submitter":"Alix McCollam","authors":"Femke Bangma and Lev Levitin and Marijn Lucas and Andrew Casey and Jan\n  Nyeki and Ineke Broeders and Aaron Sutton and Bohdan Andraka and Stephen\n  Julian and John Saunders and Alix McCollam","title":"Diverse influences of hyperfine interactions on strongly correlated\n  electron states","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The motivation to develop materials for quantum technologies has put\nexploration of novel quantum states of matter at the focus of several research\nfields, with particular efforts towards understanding and controlling the\nbehaviour of quantum entangled and other strongly interacting electronic\nstates. Experimental investigation is of primary importance, but requires\nmeasurements at ultra-low temperatures where the quantum states of interest\nhave long lifetimes. Under these conditions, low energy interactions, such as\nhyperfine or nuclear exchange interactions, become relevant, and can modify\nelectronic ground states and their associated excitations in multiple ways that\nare not well understood or characterised. In this work, we use a recently\ndeveloped magnetic susceptibility technique, compatible with ultra-low\ntemperatures and high magnetic fields, to probe the influence of nuclear\ninteractions on superconducting and multipole ordered ground states in the\nstrongly correlated electron system PrOs4Sb12. We find that the multipole order\ndevelops a novel, entangled nuclear-electronic character at the lowest\ntemperatures, which significantly modifies the phase boundary and leads to a\nnuclear quantum critical point. In the superconducting phase, we find that\nhyperfine interactions suppress superconductivity in a manner that provides\nevidence for superconducting pairing mediated by crystal field excitations. Our\nresults on PrOs4Sb12 experimentally establish a new type of non-magnetic,\nnuclear quantum critical point, and give revealing insight into a highly\nunusual superconducting state. They also demonstrate more generally the\nfeasibility of exploiting hyperfine interactions as a tuning parameter for\nexperimental creation and investigation of a variety of quantum states and\nphenomena in correlated electron materials.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:56:04 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17089","submitter":"Ioannis Dalianis","authors":"Ioannis Dalianis, Fotis Farakos and Alex Kehagias","title":"Is Gauge Mediation in the Swampland?","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We note that the typical gauge mediation of supersymmetry breaking is in\ntension with the global limit of the festina lente swampland bound. The\nalternatives are mediation/breaking schemes that decouple together with\ngravity, as for example gravity mediation, for which we highlight some basic\nphenomenological properties. Gauge mediation remains instead a viable mechanism\nonly in models where supersymmetry is restored in the global limit, as for\nexample in no-scale supergravity.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:56:26 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17090","submitter":"Mauricio Garcia Vergara","authors":"Mauricio Garcia-Vergara, Guillaume Dem\\'esy, Andr\\'e Nicolet,\n  Fr\\'ed\\'eric Zolla","title":"Electrodynamics of an oscillating particle without cheating PART I : In\n  vacuo. PART II : Near a dispersive bulk","comments":"40 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, the electromagnetic radiation from an oscillating particle\nplaced in the vicinity of an object of size comparable to the wavelength is\nstudied. Although this problem may seem academic at first sight, the details of\nthe calculations are presented throughout without any detail left under the\ncarpet. A polyharmonic decomposition of the radiation sources allows the\ndiffraction problem to be fully characterised while satisfying energy\nconservation. Finally, the source expressions obtained are suitable for use in\na numerical code. A 3D illustration using finite elements is provided.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:02:10 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17091","submitter":"Zhenchao Jin","authors":"Zhenchao Jin","title":"SSSegmenation: An Open Source Supervised Semantic Segmentation Toolbox\n  Based on PyTorch","comments":"tech report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents SSSegmenation, which is an open source supervised\nsemantic image segmentation toolbox based on PyTorch. The design of this\ntoolbox is motivated by MMSegmentation while it is easier to use because of\nfewer dependencies and achieves superior segmentation performance under a\ncomparable training and testing setup. Moreover, the toolbox also provides\nplenty of trained weights for popular and contemporary semantic segmentation\nmethods, including Deeplab, PSPNet, OCRNet, MaskFormer, \\emph{etc}. We expect\nthat this toolbox can contribute to the future development of semantic\nsegmentation. Codes and model zoos are available at\n\\href{https://github.com/SegmentationBLWX/sssegmentation/}{SSSegmenation}.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:02:42 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17092","submitter":"Aurelien Delphin","authors":"Aur\\'elien Delphin (GIN), Fabien Boux (GIN), Cl\\'ement Brossard (GIN),\n  Thomas Coudert (GIN), Jan M Warnking (GIN), Benjamin Lemasson (GIN), Emmanuel\n  Luc Barbier (GIN), Thomas Christen (GIN)","title":"Enhancing MR vascular Fingerprinting through realistic microvascular\n  geometries","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  MR vascular Fingerprinting proposes to use the MR Fingerprinting framework to\nquantitatively and simultaneously map several microvascular characteristics at\na sub-voxel scale. The initial implementation assessed the local blood\noxygenation saturation (SO 2), blood volume fraction (BVf) and vessel averaged\nradius (R) in humans and rodent brains using simple 2D representations of the\nvascular network during dictionary generation. In order to improve the results\nand possibly extend the approach to pathological environments and other\nbiomarkers, we propose in this study to use 3D realistic vascular geometries in\nthe numerical simulations. 28,000 different synthetic voxels containing\nvascular networks segmented from whole brain healthy mice microscopy images\nwere created. A Bayesian-based regression model was used for map\nreconstruction. We show on 8 healthy and 9 tumor bearing rats that realistic\nvascular representations yield microvascular estimates in better agreement with\nthe literature than 2D or 3D cylindrical models. Furthermore, tumoral blood\noxygenation estimates obtained with the proposed approach are the only ones\ncorrelating with in vivo optic-fiber measurements performed in the same\nanimals.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:04:46 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17093","submitter":"Julien Toulouse","authors":"Diata Traore (LCT), Emmanuel Giner (LCT), Julien Toulouse (LCT, IUF)","title":"Basis-set correction based on density-functional theory: Linear-response\n  formalism for excited-state energies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The basis-set correction method based on density-functional theory consists\nin correcting the energy calculated by a wave-function method with a given\nbasis set by a density functional. This basis-set correction density functional\nincorporates the short-range electron correlation effects missing in the basis\nset. This results in accelerated basis convergences of ground-state energies to\nthe complete-basis-set limit. In this work, we extend the basis-set correction\nmethod to a linear-response formalism for calculating excited-state energies.\nWe give the general linear-response equations, as well as the more specific\nequations for configuration-interaction wave functions. As a proof of concept,\nwe apply this approach to the calculations of excited-state energies in a\none-dimensional two-electron model system with harmonic potential and a\nDirac-delta electron-electron interaction. The results obtained with\nfull-configuration-interaction wave functions expanded in a basis of Hermite\nfunctions and a local-density-approximation basis-set correction functional\nshow that the present approach does not help in accelerating the basis\nconvergence of excitation energies. However, we show that it significantly\naccelerates basis convergences of excited-state total energies.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:05:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17094","submitter":"Piotr Florek","authors":"Piotr Florek, Adam Zagda\\'nski","title":"Benchmarking state-of-the-art gradient boosting algorithms for\n  classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work explores the use of gradient boosting in the context of\nclassification. Four popular implementations, including original GBM algorithm\nand selected state-of-the-art gradient boosting frameworks (i.e. XGBoost,\nLightGBM and CatBoost), have been thoroughly compared on several publicly\navailable real-world datasets of sufficient diversity. In the study, special\nemphasis was placed on hyperparameter optimization, specifically comparing two\ntuning strategies, i.e. randomized search and Bayesian optimization using the\nTree-stuctured Parzen Estimator. The performance of considered methods was\ninvestigated in terms of common classification accuracy metrics as well as\nruntime and tuning time. Additionally, obtained results have been validated\nusing appropriate statistical testing. An attempt was made to indicate a\ngradient boosting variant showing the right balance between effectiveness,\nreliability and ease of use.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:06:15 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17095","submitter":"Samuel Valiquette","authors":"Samuel Valiquette (UPR For\\^ets et Soci\\'et\\'es, IMAG, LEMON, UdeS),\n  Gwladys Toulemonde (IMAG, LEMON), Jean Peyhardi (IMAG), \\'Eric Marchand\n  (UdeS), Fr\\'ed\\'eric Mortier (UPR For\\^ets et Soci\\'et\\'es, GEJP)","title":"Asymptotic tail properties of Poisson mixture distributions","comments":"Stat, In press","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Count data are omnipresent in many applied fields, often with overdispersion.\nWith mixtures of Poisson distributions representing an elegant and appealing\nmodelling strategy, we focus here on how the tail behaviour of the mixing\ndistribution is related to the tail of the resulting Poisson mixture. We define\nfive sets of mixing distributions and we identify for each case whenever the\nPoisson mixture is in, close to or far from a domain of attraction of maxima.\nWe also characterize how the Poisson mixture behaves similarly to a standard\nPoisson distribution when the mixing distribution has a finite support.\nFinally, we study, both analytically and numerically, how goodness-of-fit can\nbe assessed with the inspection of tail behaviour.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:07:25 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17096","submitter":"Tanveer Hannan","authors":"Tanveer Hannan, Rajat Koner, Maximilian Bernhard, Suprosanna Shit,\n  Bjoern Menze, Volker Tresp, Matthias Schubert, Thomas Seidl","title":"GRAtt-VIS: Gated Residual Attention for Auto Rectifying Video Instance\n  Segmentation","comments":"14 pages, 5 tables, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent trends in Video Instance Segmentation (VIS) have seen a growing\nreliance on online methods to model complex and lengthy video sequences.\nHowever, the degradation of representation and noise accumulation of the online\nmethods, especially during occlusion and abrupt changes, pose substantial\nchallenges. Transformer-based query propagation provides promising directions\nat the cost of quadratic memory attention. However, they are susceptible to the\ndegradation of instance features due to the above-mentioned challenges and\nsuffer from cascading effects. The detection and rectification of such errors\nremain largely underexplored. To this end, we introduce \\textbf{GRAtt-VIS},\n\\textbf{G}ated \\textbf{R}esidual \\textbf{Att}ention for \\textbf{V}ideo\n\\textbf{I}nstance \\textbf{S}egmentation. Firstly, we leverage a\nGumbel-Softmax-based gate to detect possible errors in the current frame. Next,\nbased on the gate activation, we rectify degraded features from its past\nrepresentation. Such a residual configuration alleviates the need for dedicated\nmemory and provides a continuous stream of relevant instance features.\nSecondly, we propose a novel inter-instance interaction using gate activation\nas a mask for self-attention. This masking strategy dynamically restricts the\nunrepresentative instance queries in the self-attention and preserves vital\ninformation for long-term tracking. We refer to this novel combination of Gated\nResidual Connection and Masked Self-Attention as \\textbf{GRAtt} block, which\ncan easily be integrated into the existing propagation-based framework.\nFurther, GRAtt blocks significantly reduce the attention overhead and simplify\ndynamic temporal modeling. GRAtt-VIS achieves state-of-the-art performance on\nYouTube-VIS and the highly challenging OVIS dataset, significantly improving\nover previous methods. Code is available at\n\\url{https://github.com/Tanveer81/GRAttVIS}.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:10:24 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17097","submitter":"Boyuan Shi","authors":"Boyuan Shi and Florian Mintert","title":"Quantum simulations of time-dependent Hamiltonians beyond the\n  quasi-static approximation","comments":"8 pages, 2 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing approaches to analogue quantum simulations of time-dependent quantum\nsystems rely on perturbative corrections to the time-independence of the\nsystems to be simulated. We overcome this restriction to perturbative\napproaches and demonstrate the potential of achievable quantum simulations with\nthe pedagogical example of a Lambda-system and the quench in finite time\nthrough a quantum phase transition of a Chern insulator in a driven Hubbard\nsystem.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:12:19 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17098","submitter":"Rongzhen Wang","authors":"Min Zhao, Rongzhen Wang, Fan Bao, Chongxuan Li, Jun Zhu","title":"ControlVideo: Adding Conditional Control for One Shot Text-to-Video\n  Editing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we present ControlVideo, a novel method for text-driven video\nediting. Leveraging the capabilities of text-to-image diffusion models and\nControlNet, ControlVideo aims to enhance the fidelity and temporal consistency\nof videos that align with a given text while preserving the structure of the\nsource video. This is achieved by incorporating additional conditions such as\nedge maps, fine-tuning the key-frame and temporal attention on the source\nvideo-text pair with carefully designed strategies. An in-depth exploration of\nControlVideo's design is conducted to inform future research on one-shot tuning\nvideo diffusion models. Quantitatively, ControlVideo outperforms a range of\ncompetitive baselines in terms of faithfulness and consistency while still\naligning with the textual prompt. Additionally, it delivers videos with high\nvisual realism and fidelity w.r.t. the source content, demonstrating\nflexibility in utilizing controls containing varying degrees of source video\ninformation, and the potential for multiple control combinations. The project\npage is available at\n\\href{https://ml.cs.tsinghua.edu.cn/controlvideo/}{https://ml.cs.tsinghua.edu.cn/controlvideo/}.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:13:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17099","submitter":"Jeffrey Marshall","authors":"Jeffrey Marshall, Namit Anand","title":"Simulation of quantum optics by coherent state decomposition","comments":"23+8 pages. 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce a framework for simulating quantum optics by decomposing the\nsystem into a finite rank (number of terms) superposition of coherent states.\nThis allows us to define a resource theory, where linear optical operations are\n`free' (i.e., do not increase the rank), and the simulation complexity for an\n$m$-mode system scales quadratically in $m$, in stark contrast to the Hilbert\nspace dimension. We outline this approach explicitly in the Fock basis,\nrelevant in particular for Boson sampling, where the simulation time (space)\ncomplexity for computing output amplitudes, to arbitrary accuracy, scales as\n$O(m^2 2^n)$ ($O(m2^n)$), for $n$ photons distributed amongst $m$ modes. We\nadditionally demonstrate linear optical simulations with the $n$ photons\ninitially in the same mode scales efficiently, as $O(m^2 n)$. This paradigm\nprovides a practical notion of `non-classicality', i.e., the classical\nresources required for simulation, which by making connections to the stellar\nformalism, we show this comes from two independent contributions, the number of\nsingle-photon additions, and the amount of squeezing.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:14:27 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17100","submitter":"Kai Zhang","authors":"Kai Zhang, Jun Yu, Zhiling Yan, Yixin Liu, Eashan Adhikarla, Sunyang\n  Fu, Xun Chen, Chen Chen, Yuyin Zhou, Xiang Li, Lifang He, Brian D. Davison,\n  Quanzheng Li, Yong Chen, Hongfang Liu, Lichao Sun","title":"BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained\n  Transformer for Vision, Language, and Multimodal Tasks","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we introduce a unified and generalist Biomedical Generative\nPre-trained Transformer (BiomedGPT) model, which leverages self-supervision on\nlarge and diverse datasets to accept multi-modal inputs and perform a range of\ndownstream tasks. Our experiments demonstrate that BiomedGPT delivers expansive\nand inclusive representations of biomedical data, outperforming the majority of\npreceding state-of-the-art models across five distinct tasks with 20 public\ndatasets spanning over 15 unique biomedical modalities. Through the ablation\nstudy, we also showcase the efficacy of our multi-modal and multi-task\npretraining approach in transferring knowledge to previously unseen data.\nOverall, our work presents a significant step forward in developing unified and\ngeneralist models for biomedicine, with far-reaching implications for improving\nhealthcare outcomes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:14:43 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17101","submitter":"Rakesh Dubey Dr","authors":"K. Czerski, R. Dubey, M. Kaczmarski, A. Kowalska, N. Targosz-Sleczka,\n  G. Das Haridas, M. Valat","title":"First observation of electron emission from the DD threshold resonance","comments":"14 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electron emission in the deuteron-deuteron reaction supporting existence of\nthe single-particle threshold resonance in 4 He has been observed for the first\ntime. The measured electron energy spectrum and the electron-proton branching\nratio agree very well with the assumed electron-positron pair creation decay of\nthe 0+ resonance state to the ground state and the detailed Monte Carlo\nsimulations of the experimental energy spectrum.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:14:54 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17102","submitter":"Jingyang Huo","authors":"Jingyang Huo, Qiang Sun, Boyan Jiang, Haitao Lin, Yanwei Fu","title":"GeoVLN: Learning Geometry-Enhanced Visual Representation with Slot\n  Attention for Vision-and-Language Navigation","comments":"Accepted by CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most existing works solving Room-to-Room VLN problem only utilize RGB images\nand do not consider local context around candidate views, which lack sufficient\nvisual cues about surrounding environment. Moreover, natural language contains\ncomplex semantic information thus its correlations with visual inputs are hard\nto model merely with cross attention. In this paper, we propose GeoVLN, which\nlearns Geometry-enhanced visual representation based on slot attention for\nrobust Visual-and-Language Navigation. The RGB images are compensated with the\ncorresponding depth maps and normal maps predicted by Omnidata as visual\ninputs. Technically, we introduce a two-stage module that combine local slot\nattention and CLIP model to produce geometry-enhanced representation from such\ninput. We employ V&L BERT to learn a cross-modal representation that\nincorporate both language and vision informations. Additionally, a novel\nmultiway attention module is designed, encouraging different phrases of input\ninstruction to exploit the most related features from visual input. Extensive\nexperiments demonstrate the effectiveness of our newly designed modules and\nshow the compelling performance of the proposed method.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:15:22 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17103","submitter":"Luca Giuzzi DPhil","authors":"Angela Aguglia, Bence Csajb\\'ok, Luca Giuzzi","title":"On regular sets of affine type in finite Desarguesian planes and related\n  codes","comments":"16 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider point sets of finite Desarguesian planes whose\nmultisets of intersection numbers with lines is the same for all but one\nexceptional parallel class of lines. We call such sets regular of affine type.\nWhen the lines of the exceptional parallel class have the same intersection\nnumbers, then we call these sets regular of pointed type. Classical examples\nare e.g. unitals; a detailed study and constructions of such sets with few\nintersection numbers is due to Hirschfeld and Sz\\H{o}nyi from 1991. We here\nprovide some general construction methods for regular sets and describe a few\ninfinite families. The members of one of these families have the size of a\nunital and meet affine lines of $\\mathrm{PG}(2, q^2)$ in one of $4$ possible\nintersection numbers, each of them congruent to $1$ modulo $\\sqrt{q}$. As a\nbyproduct, we determine the intersection sizes of the Hermitian curve defined\nover $\\mathrm{GF}(q^2)$ with suitable rational curves of degree $\\sqrt{q}$ and\nwe obtain $\\sqrt{q}$-divisible codes with $5$ non-zero weights. We also\ndetermine the weight enumerator of the codes arising from the general\nconstructions modulus some $q$-powers.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:16:06 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17104","submitter":"Yongliang Shen","authors":"Yongliang Shen, Zeqi Tan, Shuhui Wu, Wenqi Zhang, Rongsheng Zhang,\n  Yadong Xi, Weiming Lu, Yueting Zhuang","title":"PromptNER: Prompt Locating and Typing for Named Entity Recognition","comments":"Accepted to ACL 2023, submission version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Prompt learning is a new paradigm for utilizing pre-trained language models\nand has achieved great success in many tasks. To adopt prompt learning in the\nNER task, two kinds of methods have been explored from a pair of symmetric\nperspectives, populating the template by enumerating spans to predict their\nentity types or constructing type-specific prompts to locate entities. However,\nthese methods not only require a multi-round prompting manner with a high time\noverhead and computational cost, but also require elaborate prompt templates,\nthat are difficult to apply in practical scenarios. In this paper, we unify\nentity locating and entity typing into prompt learning, and design a dual-slot\nmulti-prompt template with the position slot and type slot to prompt locating\nand typing respectively. Multiple prompts can be input to the model\nsimultaneously, and then the model extracts all entities by parallel\npredictions on the slots. To assign labels for the slots during training, we\ndesign a dynamic template filling mechanism that uses the extended bipartite\ngraph matching between prompts and the ground-truth entities. We conduct\nexperiments in various settings, including resource-rich flat and nested NER\ndatasets and low-resource in-domain and cross-domain datasets. Experimental\nresults show that the proposed model achieves a significant performance\nimprovement, especially in the cross-domain few-shot setting, which outperforms\nthe state-of-the-art model by +7.7% on average.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:16:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17105","submitter":"Bartlomiej Wronski","authors":"Karthik Vaidyanathan, Marco Salvi, Bartlomiej Wronski, Tomas\n  Akenine-M\\\"oller, Pontus Ebelin, Aaron Lefohn","title":"Random-Access Neural Compression of Material Textures","comments":"22 pages, accepted to ACM SIGGRAPH 2023 Transactions on Graphics","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GR cs.CV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The continuous advancement of photorealism in rendering is accompanied by a\ngrowth in texture data and, consequently, increasing storage and memory\ndemands. To address this issue, we propose a novel neural compression technique\nspecifically designed for material textures. We unlock two more levels of\ndetail, i.e., 16x more texels, using low bitrate compression, with image\nquality that is better than advanced image compression techniques, such as AVIF\nand JPEG XL. At the same time, our method allows on-demand, real-time\ndecompression with random access similar to block texture compression on GPUs,\nenabling compression on disk and memory. The key idea behind our approach is\ncompressing multiple material textures and their mipmap chains together, and\nusing a small neural network, that is optimized for each material, to\ndecompress them. Finally, we use a custom training implementation to achieve\npractical compression speeds, whose performance surpasses that of general\nframeworks, like PyTorch, by an order of magnitude.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:16:22 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17106","submitter":"Gustavo Pinto","authors":"Danilo Monteiro Ribeiro and Rayfran Rocha Lima and C\\'esar Fran\\c{c}a\n  and Alberto de Souza and Isadora Cardoso-Pereira and Gustavo Pinto","title":"Understanding Self-Efficacy in the Context of Software Engineering: A\n  Qualitative Study in the Industry","comments":"10 pages, 3 figures","journal-ref":"Published at EASE 2023","doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  CONTEXT: Self-efficacy is a concept researched in various areas of knowledge\nthat impacts various factors such as performance, satisfaction, and motivation.\nIn Software Engineering, it has mainly been studied in the academic context,\npresenting results similar to other areas of knowledge. However, it is also\nimportant to understand its impact in the industrial context. OBJECTIVE:\nTherefore, this study aims to understand the impact on the software development\ncontext with a focus on understanding the behavioral signs of self-efficacy in\nsoftware engineers and how self-efficacy can impact the work-day of software\nengineers. METHOD: A qualitative research was conducted using semi-structured\nquestionnaires with 31 interviewees from a software development company located\nin Brazil. The interviewees participated in a Bootcamp and were later assigned\nto software development teams. Thematic analysis was used to analyze the data.\nRESULTS: In the perception of the interviewees, 21 signs were found that are\nrelated to people with high and low self-efficacy. These signs were divided\ninto two dimensions: social and cognitive. Also, 18 situations were found that\ncan lead to an increase or decrease of self-efficacy of software engineers.\nFinally, 12 factors were mentioned that can impact software development teams.\nCONCLUSION: This work evidences a set of behavioral signs that can help team\nleaders to better perceive the self-efficacy of their members. It also presents\na set of situations that both leaders and individuals can use to improve their\nself-efficacy in the development context, and finally, factors that can be\nimpacted by self-efficacy in the software development context are also\npresented. Finally, this work emphasizes the importance of understanding\nself-efficacy in the industrial context.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:16:37 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 18:30:20 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17107","submitter":"Giorgio Gubbiotti","authors":"Giorgio Gubbiotti and Yang Shi","title":"Determination of the symmetry group for some QRT roots","comments":"42 pages, 10 figures, 3 table, comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.SI math-ph math.GR math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We determine the affine Weyl symmetries of some two-dimensional birational\nmaps known as QRT roots arising from Kahan--Hirota--Kimura discretisation of\ntwo different reduced Nahm systems. The main finding is that the symmetry types\nof these discrete systems are subgroups of the Weyl groups for Sakai's discrete\nPainlev\\'e equations to which the QRT maps are the autonomous limits.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:17:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17108","submitter":"Andreu Puy","authors":"Andreu Puy, Palina Bartashevich, Elisabet Gimeno, Jordi Torrents, M.\n  Carmen Miguel, Romualdo Pastor-Satorras, Pawel Romanczuk","title":"Selective social interactions and speed-induced leadership in schooling\n  fish","comments":"Main paper (12 pages) + Supplementary Information (14 pages)","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Animals moving together in groups are believed to interact among each other\nwith effective social forces, such as attraction, repulsion and alignment. Such\nforces can be inferred using 'force maps', i.e. by analysing the dependency of\nthe acceleration of a focal individual on relevant variables. Here we introduce\na force map technique for alignment depending on relative velocities between an\nindividual and its neighbours. After the force map approach is validated with\nan agent-based model, we apply it to experimental data of schooling fish, where\nwe observe signatures of an effective alignment force with faster neighbours,\nand an unexpected anti-alignment with slower neighbours. Instead of an explicit\nanti-alignment behaviour, we suggest that the observed pattern is a result of a\nselective attention mechanism, where fish pay less attention to slower\nneighbours. We present support for this hypothesis both from agent-based\nmodeling, as well as from exploring leader-follower relationships between\nfaster and slower neighbouring fish in the experimental data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:17:35 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17109","submitter":"Tankred Saanum","authors":"Tankred Saanum, No\\'emi \\'Eltet\\H{o}, Peter Dayan, Marcel Binz, Eric\n  Schulz","title":"Reinforcement Learning with Simple Sequence Priors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Everything else being equal, simpler models should be preferred over more\ncomplex ones. In reinforcement learning (RL), simplicity is typically\nquantified on an action-by-action basis -- but this timescale ignores temporal\nregularities, like repetitions, often present in sequential strategies. We\ntherefore propose an RL algorithm that learns to solve tasks with sequences of\nactions that are compressible. We explore two possible sources of simple action\nsequences: Sequences that can be learned by autoregressive models, and\nsequences that are compressible with off-the-shelf data compression algorithms.\nDistilling these preferences into sequence priors, we derive a novel\ninformation-theoretic objective that incentivizes agents to learn policies that\nmaximize rewards while conforming to these priors. We show that the resulting\nRL algorithm leads to faster learning, and attains higher returns than\nstate-of-the-art model-free approaches in a series of continuous control tasks\nfrom the DeepMind Control Suite. These priors also produce a powerful\ninformation-regularized agent that is robust to noisy observations and can\nperform open-loop control.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:18:14 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17110","submitter":"Bingjie Tang","authors":"Bingjie Tang, Michael A. Lin, Iretiayo Akinola, Ankur Handa, Gaurav S.\n  Sukhatme, Fabio Ramos, Dieter Fox, Yashraj Narang","title":"IndustReal: Transferring Contact-Rich Assembly Tasks from Simulation to\n  Reality","comments":"Accepted to Robotics: Science and Systems (RSS) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Robotic assembly is a longstanding challenge, requiring contact-rich\ninteraction and high precision and accuracy. Many applications also require\nadaptivity to diverse parts, poses, and environments, as well as low cycle\ntimes. In other areas of robotics, simulation is a powerful tool to develop\nalgorithms, generate datasets, and train agents. However, simulation has had a\nmore limited impact on assembly. We present IndustReal, a set of algorithms,\nsystems, and tools that solve assembly tasks in simulation with reinforcement\nlearning (RL) and successfully achieve policy transfer to the real world.\nSpecifically, we propose 1) simulation-aware policy updates, 2)\nsigned-distance-field rewards, and 3) sampling-based curricula for robotic RL\nagents. We use these algorithms to enable robots to solve contact-rich pick,\nplace, and insertion tasks in simulation. We then propose 4) a policy-level\naction integrator to minimize error at policy deployment time. We build and\ndemonstrate a real-world robotic assembly system that uses the trained policies\nand action integrator to achieve repeatable performance in the real world.\nFinally, we present hardware and software tools that allow other researchers to\nreproduce our system and results. For videos and additional details, please see\nhttp://sites.google.com/nvidia.com/industreal .\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:20:02 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17111","submitter":"Abhinav K. Jha","authors":"Md Ashequr Rahman, Zekun Li, Zitong Yu, Richard Laforest, Daniel L.J.\n  Thorek and Abhinav K. Jha","title":"A list-mode multi-energy window low-count SPECT reconstruction method\n  for isotopes with multiple emission peaks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  SPECT provides a mechanism to perform absorbed-dose quantification tasks for\n$\\alpha$-particle radiopharmaceutical therapies ($\\alpha$-RPTs). However,\nquantitative SPECT for $\\alpha$-RPT is challenging due to the low number of\ndetected counts, the complex emission spectrum, and other image-degrading\nartifacts. Towards addressing these challenges, we propose a low-count\nquantitative SPECT reconstruction method for isotopes with multiple emission\npeaks.\n  Given the low-count setting, it is important that the reconstruction method\nextract the maximal possible information from each detected photon. Processing\ndata over multiple energy windows and in list-mode (LM) format provide\nmechanisms to achieve that objective. Towards this goal, we propose a list-mode\nmulti-energy window (LM-MEW) OSEM-based SPECT reconstruction method that uses\ndata from multiple energy windows in LM format, and includes the energy\nattribute of each detected photon. For computational efficiency, we developed a\nmulti-GPU-based implementation of this method. The method was evaluated using\n2-D SPECT simulation studies in a single-scatter setting conducted in the\ncontext of imaging [$^{223}$Ra]RaCl${_2}$.\n  The proposed method yielded improved performance on the task of estimating\nactivity uptake within known regions of interest in comparison to approaches\nthat use a single energy window or use binned data. The improved performance\nwas observed in terms of both accuracy and precision and for different sizes of\nthe region of interest.\n  Results of our studies show that the use of multiple energy windows and\nprocessing data in LM format with the proposed LM-MEW method led to improved\nquantification performance in low-count SPECT of isotopes with multiple\nemission peaks. These results motivate further development and validation of\nthe LM-MEW method for such imaging applications, including for $\\alpha$-RPT\nSPECT.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:27:32 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17112","submitter":"Jiaxin Yuan","authors":"Jiaxin Yuan, Amar Shah, Channing Bentz, Maria Cameron","title":"Optimal control for sampling the transition path process and estimating\n  rates","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many processes in nature such as conformal changes in biomolecules and\nclusters of interacting particles, genetic switches, noisy mechanical or\nelectromechanical oscillators, and many others are modeled using stochastic\ndifferential equations with small white noise. The study of rare transitions\nbetween metastable states in such systems is of great interest and importance,\nbut direct simulations are difficult due to long waiting times. Transition path\ntheory is a mathematical framework for the quantitative description of rare\nevents. Its direct implementation the key component of which is the solution of\nthe committor problem, a boundary value problem for the backward Kolmogorov\nequation, is often challenging due to high dimensionality or other numerical\nissues. This work exploits the key fact that the optimal controller constructed\nfrom the committor leads to generation of transition trajectories exclusively.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:28:15 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 10:45:22 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.17113","submitter":"Ningzhi Xie","authors":"Ningzhi Xie, Quentin A. A. Tanguy, Johannes E. Fr\\\"och, Karl F.\n  B\\\"ohringer, Arka Majumdar","title":"Spectrally-encoded non-scanning imaging through a fiber","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  With the advent of neuroimaging and microsurgery, there is a rising need for\ncapturing images through an optical fiber. We present an approach of imaging\nthrough a single fiber without mechanical scanning by implementing\nspatial-spectral encoding. The spectral encoding is achieved through a\nmicrofabricated spectral filter array, where light from different spatial\npixels is coded with a highly orthogonal spectrum. The image is then\ncomputationally recovered via pseudo inverse of the encoding process. We\ndemonstrate imaging of a $4 \\times 4$ binary object at the proximity of the\nspectral filter array using $560-625nm$ wavelength band. The recovered image\nmaintains an error rate of $<11\\%$ when measured using a spectrometer with a\nspectral resolution of $1.5nm$. The image remains unchanged with fiber bending\nor moving. Thus our approach shows a more robust way to image through a single\noptical fiber, with potential applications in compact endoscopes and\nangioscopes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:29:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17114","submitter":"Hao-Jie Xu","authors":"Jian-fei Wang, Hao-jie Xu, Fuqiang Wang","title":"Impact of initial fluctuations and nuclear deformations in isobar\n  collisions","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th nucl-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Relativistic isobar ($^{96}_{44}$Ru+$^{96}_{44}$Ru and\n$^{96}_{40}$Zr+$^{96}_{40}$Zr) collisions have revealed intricate differences\nin their nuclear size and shape, inspiring unconventional studies of nuclear\nstructure using relativistic heavy ion collisions. In this study, we\ninvestigate the relative differences in the mean multiplicity ($R_{\\langle\nN_{\\rm ch}\\rangle}$) and the second- ($R_{\\epsilon_{2}}$) and third-order\neccentricity ($R_{\\epsilon_{3}}$) between isobar collisions using Optical and\nMonte Carlo Glauber models. It is found that initial fluctuations and nuclear\ndeformations have negligible effects on $R_{\\langle N_{\\rm ch}\\rangle}$ in most\ncentral collisions, while both are important for the $R_{\\epsilon_{2}}$ and\n$R_{\\epsilon_{3}}$, the degree of which is sensitive to the underlying\nnucleonic or sub-nucleonic degree of freedom. These features, compared to real\ndata, may probe the particle production mechanism and the physics underlying\nnuclear structure.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:31:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17115","submitter":"Mateo Perez","authors":"Rajeev Alur, Osbert Bastani, Kishor Jothimurugan, Mateo Perez, Fabio\n  Somenzi, Ashutosh Trivedi","title":"Policy Synthesis and Reinforcement Learning for Discounted LTL","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The difficulty of manually specifying reward functions has led to an interest\nin using linear temporal logic (LTL) to express objectives for reinforcement\nlearning (RL). However, LTL has the downside that it is sensitive to small\nperturbations in the transition probabilities, which prevents probably\napproximately correct (PAC) learning without additional assumptions. Time\ndiscounting provides a way of removing this sensitivity, while retaining the\nhigh expressivity of the logic. We study the use of discounted LTL for policy\nsynthesis in Markov decision processes with unknown transition probabilities,\nand show how to reduce discounted LTL to discounted-sum reward via a reward\nmachine when all discount factors are identical.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:32:38 GMT"},{"version":"v2","created":"Mon, 29 May 2023 23:43:19 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17116","submitter":"Brandon Higgs","authors":"David Soong, Sriram Sridhar, Han Si, Jan-Samuel Wagner, Ana Caroline\n  Costa S\\'a, Christina Y Yu, Kubra Karagoz, Meijian Guan, Hisham Hamadeh,\n  Brandon W Higgs","title":"Improving accuracy of GPT-3/4 results on biomedical data using a\n  retrieval-augmented language model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) have made significant advancements in natural\nlanguage processing (NLP). Broad corpora capture diverse patterns but can\nintroduce irrelevance, while focused corpora enhance reliability by reducing\nmisleading information. Training LLMs on focused corpora poses computational\nchallenges. An alternative approach is to use a retrieval-augmentation (RetA)\nmethod tested in a specific domain.\n  To evaluate LLM performance, OpenAI's GPT-3, GPT-4, Bing's Prometheus, and a\ncustom RetA model were compared using 19 questions on diffuse large B-cell\nlymphoma (DLBCL) disease. Eight independent reviewers assessed responses based\non accuracy, relevance, and readability (rated 1-3).\n  The RetA model performed best in accuracy (12/19 3-point scores, total=47)\nand relevance (13/19, 50), followed by GPT-4 (8/19, 43; 11/19, 49). GPT-4\nreceived the highest readability scores (17/19, 55), followed by GPT-3 (15/19,\n53) and the RetA model (11/19, 47). Prometheus underperformed in accuracy (34),\nrelevance (32), and readability (38).\n  Both GPT-3.5 and GPT-4 had more hallucinations in all 19 responses compared\nto the RetA model and Prometheus. Hallucinations were mostly associated with\nnon-existent references or fabricated efficacy data.\n  These findings suggest that RetA models, supplemented with domain-specific\ncorpora, may outperform general-purpose LLMs in accuracy and relevance within\nspecific domains. However, this evaluation was limited to specific questions\nand metrics and may not capture challenges in semantic search and other NLP\ntasks. Further research will explore different LLM architectures, RetA\nmethodologies, and evaluation methods to assess strengths and limitations more\ncomprehensively.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:33:05 GMT"},{"version":"v2","created":"Tue, 30 May 2023 15:37:45 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17117","submitter":"Abhinav K. Jha","authors":"Zekun Li, Nadia Benabdallah, Richard Laforest, Richard L. Wahl, Daniel\n  L. J. Thorek, Abhinav K. Jha","title":"Joint regional uptake quantification of Thorium-227 and Radium-223 using\n  a multiple-energy-window projection-domain quantitative SPECT method","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Thorium-227-based alpha-particle radiopharmaceutical therapies (alpha-RPTs)\nare currently being investigated in several clinical and pre-clinical studies.\nAfter administration, Thorium-227 decays to Radium-223, another\nalpha-particle-emitting isotope, which redistributes within the patient.\nReliable dose quantification of both Thorium-227 and Radium-223 is clinically\nimportant, and SPECT can perform this quantification as these isotopes also\nemit gamma-ray photons. However, reliable quantification is challenging for\nseveral reasons: the orders-of-magnitude lower activity compared to\nconventional SPECT, resulting in a very low number of detected counts, the\npresence of multiple photopeaks and substantial overlap in the emission spectra\nof these isotopes. To address these issues, we propose a multiple-energy-window\nprojection-domain quantification (MEW-PDQ) method that jointly estimates the\nregional activity uptake of both Thorium-227 and Radium-223 directly using the\nSPECT projection data from multiple energy windows. We evaluated the method\nwith realistic simulation studies conducted with anthropomorphic digital\nphantoms, including a virtual imaging trial in the context of imaging patients\nwith bone metastases of prostate cancer who were treated with Thorium-227-based\nalpha-RPTs. The proposed method yielded reliable regional uptake estimates of\nboth isotopes and outperformed state-of-art methods across different lesion\nsizes, contrasts, and varying levels of intra-lesion heterogeneity. This\nsuperior performance was also observed in the virtual imaging trial.\nAdditionally, the variance of the estimated uptake approached the Cram\\'er-Rao\nlower bound-defined theoretical limit. These results provide strong evidence in\nsupport of this method for reliable uptake quantification in Thorium-227-based\nalpha-RPTs.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:38:03 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17118","submitter":"Zichang Liu","authors":"Zichang Liu, Aditya Desai, Fangshuo Liao, Weitao Wang, Victor Xie,\n  Zhaozhuo Xu, Anastasios Kyrillidis, Anshumali Shrivastava","title":"Scissorhands: Exploiting the Persistence of Importance Hypothesis for\n  LLM KV Cache Compression at Test Time","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models(LLMs) have sparked a new wave of exciting AI\napplications. Hosting these models at scale requires significant memory\nresources. One crucial memory bottleneck for the deployment stems from the\ncontext window. It is commonly recognized that model weights are memory hungry;\nhowever, the size of key-value embedding stored during the generation process\n(KV cache) can easily surpass the model size. The enormous size of the KV cache\nputs constraints on the inference batch size, which is crucial for high\nthroughput inference workload. Inspired by an interesting observation of the\nattention scores, we hypothesize the persistence of importance: only pivotal\ntokens, which had a substantial influence at one step, will significantly\ninfluence future generations. Based on our empirical verification and\ntheoretical analysis around this hypothesis, we propose Scissorhands, a system\nthat maintains the memory usage of the KV cache at a fixed budget without\nfinetuning the model. In essence, Scissorhands manages the KV cache by storing\nthe pivotal tokens with a higher probability. We validate that Scissorhands\nreduces the inference memory usage of the KV cache by up to 5X without\ncompromising model quality. We further demonstrate that Scissorhands can be\ncombined with 4-bit quantization, traditionally used to compress model weights,\nto achieve up to 20X compression.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:39:58 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17119","submitter":"Edgar A. Bernal","authors":"Shadi Sartipi and Edgar A. Bernal","title":"Manifold Regularization for Memory-Efficient Training of Deep Neural\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One of the prevailing trends in the machine- and deep-learning community is\nto gravitate towards the use of increasingly larger models in order to keep\npushing the state-of-the-art performance envelope. This tendency makes access\nto the associated technologies more difficult for the average practitioner and\nruns contrary to the desire to democratize knowledge production in the field.\nIn this paper, we propose a framework for achieving improved memory efficiency\nin the process of learning traditional neural networks by leveraging\ninductive-bias-driven network design principles and layer-wise\nmanifold-oriented regularization objectives. Use of the framework results in\nimproved absolute performance and empirical generalization error relative to\ntraditional learning techniques. We provide empirical validation of the\nframework, including qualitative and quantitative evidence of its effectiveness\non two standard image datasets, namely CIFAR-10 and CIFAR-100. The proposed\nframework can be seamlessly combined with existing network compression methods\nfor further memory savings.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:40:15 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17120","submitter":"Claudio Bonanno","authors":"Claudio Bonanno, Francesco D'Angelo, Massimo D'Elia, Lorenzo Maio and\n  Manuel Naviglio","title":"Sphaleron rate from a modified Backus-Gilbert inversion method","comments":"11 pages, 12 eps figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-lat hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We compute the sphaleron rate in quenched QCD for a temperature $T \\simeq\n1.24~T_c$ from the inversion of the Euclidean lattice time correlator of the\ntopological charge density. We explore and compare two different strategies:\none follows a new approach proposed in this study and consists in extracting\nthe rate from finite lattice spacing correlators, and then in taking the\ncontinuum limit at fixed smoothing radius followed by a zero-smoothing\nextrapolation; the other follows the traditional approach of extracting the\nrate after performing such double extrapolation directly on the correlator. In\nboth cases the rate is obtained from a recently-proposed modification of the\nstandard Backus-Gilbert procedure. The two strategies lead to compatible\nestimates within errors, which are then compared to previous results in the\nliterature at the same or similar temperatures; the new strategy permits to\nobtain improved results, in terms of statistical and systematic uncertainties.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:41:40 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17121","submitter":"Alessandro Goffi","authors":"Alessandro Goffi","title":"High-order estimates for fully nonlinear equations under weak concavity\n  assumptions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies a priori and regularity estimates of Evans-Krylov type in\nH\\\"older spaces for fully nonlinear uniformly elliptic and parabolic equations\nof second order when the operator fails to be concave or convex in the space of\nsymmetric matrices. In particular, it is assumed that either the level sets are\nconvex or the operator is concave, convex or close to a linear function near\ninfinity. As a byproduct, these results imply polynomial Liouville theorems for\nentire solutions of elliptic equations and for ancient solutions to parabolic\nproblems.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:42:41 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17122","submitter":"Alessandro Goffi","authors":"Alessandro Goffi","title":"Interior a priori estimates for supersolutions of fully nonlinear\n  subelliptic equations under geometric conditions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we prove interior a priori first- and second-order estimates\nfor solutions of fully nonlinear degenerate elliptic inequalities structured\nover the vector fields of Carnot groups, under the main assumption that $u$ is\nsemiconvex along the fields. These estimates for supersolutions are new even\nfor linear subelliptic inequalities in nondivergence form, whereas in the\nnonlinear setting they do not require neither convexity nor concavity on the\nsecond derivatives. We also exhibit an explicit example showing that horizontal\n$W^{2,q}$ regularity of Calder\\'on-Zygmund type for fully nonlinear subelliptic\nequations posed on the Heisenberg group cannot be in general achieved in the\nrange $q<Q$, $Q$ being the homogeneous dimension of the group.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:43:46 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17123","submitter":"Jason Bernstein","authors":"Jason Bernstein, Alec M. Dunton, Benjamin W. Priest","title":"An Analysis of the Johnson-Lindenstrauss Lemma with the Bivariate Gamma\n  Distribution","comments":"20 pages, 5 figures","journal-ref":null,"doi":"10.2172/1959476","report-no":"LLNL-TR-844277","categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Probabilistic proofs of the Johnson-Lindenstrauss lemma imply that random\nprojection can reduce the dimension of a data set and approximately preserve\npairwise distances. If a distance being approximately preserved is called a\nsuccess, and the complement of this event is called a failure, then such a\nrandom projection likely results in no failures. Assuming a Gaussian random\nprojection, the lemma is proved by showing that the no-failure probability is\npositive using a combination of Bonferroni's inequality and Markov's\ninequality. This paper modifies this proof in two ways to obtain a greater\nlower bound on the no-failure probability. First, Bonferroni's inequality is\napplied to pairs of failures instead of individual failures. Second, since a\npair of projection errors has a bivariate gamma distribution, the probability\nof a pair of successes is bounded using an inequality from Jensen (1969). If\n$n$ is the number of points to be embedded and $\\mu$ is the probability of a\nsuccess, then this leads to an increase in the lower bound on the no-failure\nprobability of $\\frac{1}{2}\\binom{n}{2}(1-\\mu)^2$ if $\\binom{n}{2}$ is even and\n$\\frac{1}{2}\\left(\\binom{n}{2}-1\\right)(1-\\mu)^2$ if $\\binom{n}{2}$ is odd. For\nexample, if $n=10^5$ points are to be embedded in $k=10^4$ dimensions with a\ntolerance of $\\epsilon=0.1$, then the improvement in the lower bound is on the\norder of $10^{-14}$. We also show that further improvement is possible if the\ninequality in Jensen (1969) extends to three successes, though we do not have a\nproof of this result.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:46:23 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17124","submitter":"Andreas Krug","authors":"Andreas Krug","title":"Extension Groups of Tautological Bundles on Punctual Quot Schemes of\n  Curves","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove formulas for the cohomology and the extension groups of tautological\nbundles on punctual Quot schemes over complex smooth projective curves. As a\ncorollary, we show that the tautological bundle determines the isomorphism\nclass of the original vector bundle on the curve. We also give a vanishing\nresult for the push-forward along the Quot--Chow morphism of tensor and wedge\nproducts of duals of tautological bundles.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:49:09 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17125","submitter":"Sebasti\\'an Bordakevich","authors":"Sebasti\\'an Bordakevich, Dudbil Pab\\'on, Lorena Reb\\'on, Silvia\n  Ledesma","title":"Inspecting the use of SLMs for the control of photonic quantum states","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spatial light modulators (SLMs) are widely used to coherently control quantum\nstates of light. When carrying out these experiments, some assumptions are\nmade. For instance, it is supposed that the position-momentum correlations\nbetween twin photon pairs are not affected by the use of a liquid crystal\ndisplay (LCD) as a SLM. Furthermore, it is assumed that the characterization of\nsuch devices performed with an intense laser source, is still valid in the\nsingle photon regime. In this work, we show that such assumptions are\nacceptable, within the experimental uncertainties, for a liquid crystal on\nsilicon (LCoS) display. This is especially important when considering the use\nof this kind of displays for the coherent control of quantum states based on\ntwin photon sources.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:49:23 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17126","submitter":"Tianle Cai","authors":"Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, Denny Zhou","title":"Large Language Models as Tool Makers","comments":"Code available at https://github.com/ctlllll/LLM-ToolMaker","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent research shows the potential of enhancing the problem-solving ability\nof large language models (LLMs) through the use of external tools. However,\nprior work along this line depends on the availability of existing tools. In\nthis work, we take an initial step towards removing this dependency by\nproposing a closed-loop framework, referred to as LLMs As Tool Makers (LATM),\nwhere LLMs create their own reusable tools for problem-solving. Our approach\nconsists of two key phases: 1) tool making: an LLM acts as the tool maker that\ncrafts tools for given tasks, where a tool is implemented as a Python utility\nfunction. 2) tool using: an LLM acts as the tool user, which applies the tool\nbuilt by the tool maker for problem-solving. The tool user can be either the\nsame or a different LLM from the tool maker. Tool-making enables an LLM to\ncontinually generate tools that can be applied to different requests so that\nfuture requests can call the corresponding APIs when beneficial for solving the\ntasks. Furthermore, the division of labor among LLMs for tool-making and\ntool-using phases introduces the opportunity to achieve cost effectiveness\nwithout degrading the quality of generated tools and problem solutions. For\nexample, recognizing that tool-making demands more sophisticated capabilities\nthan tool-using, we can apply a powerful yet resource-intensive model as the\ntool maker, and a lightweight while cost-effective model as the tool user. We\nvalidate the effectiveness of our approach across a variety of complex\nreasoning tasks, including Big-Bench tasks. With GPT-4 as the tool maker and\nGPT-3.5 as the tool user, LATM can achieve performance that is on par with\nusing GPT-4 for both tool making and tool using, while the inference cost is\nsignificantly reduced.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:50:11 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17127","submitter":"Tyler A. Chang","authors":"Tyler A. Chang, Kishaloy Halder, Neha Anna John, Yogarshi Vyas,\n  Yassine Benajiba, Miguel Ballesteros, Dan Roth","title":"Characterizing and Measuring Linguistic Dataset Drift","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  NLP models often degrade in performance when real world data distributions\ndiffer markedly from training data. However, existing dataset drift metrics in\nNLP have generally not considered specific dimensions of linguistic drift that\naffect model performance, and they have not been validated in their ability to\npredict model performance at the individual example level, where such metrics\nare often used in practice. In this paper, we propose three dimensions of\nlinguistic dataset drift: vocabulary, structural, and semantic drift. These\ndimensions correspond to content word frequency divergences, syntactic\ndivergences, and meaning changes not captured by word frequencies (e.g. lexical\nsemantic change). We propose interpretable metrics for all three drift\ndimensions, and we modify past performance prediction methods to predict model\nperformance at both the example and dataset level for English sentiment\nclassification and natural language inference. We find that our drift metrics\nare more effective than previous metrics at predicting out-of-domain model\naccuracies (mean 16.8% root mean square error decrease), particularly when\ncompared to popular fine-tuned embedding distances (mean 47.7% error decrease).\nFine-tuned embedding distances are much more effective at ranking individual\nexamples by expected performance, but decomposing into vocabulary, structural,\nand semantic drift produces the best example rankings of all considered\nmodel-agnostic drift metrics (mean 6.7% ROC AUC increase).\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:50:51 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17128","submitter":"Sergey Frolov Dr.","authors":"Sergey Frolov, Anton Pribytok, Alessandro Sfondrini","title":"Ground state energy of twisted $AdS_{3}\\times S^{3}\\times T^{4}$\n  superstring and the TBA","comments":"31 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We use the lightcone $AdS_{3}\\times S^{3}\\times T^{4}$ superstring sigma\nmodel with fermions and bosons subject to twisted boundary conditions to find\nthe ground state energy in the semi-classical approximation where effective\nstring tension $h$ and the light-cone momentum $L$ are sent to infinity in such\na way that ${\\cal J}\\equiv L/h$ is kept fixed. We then analyse the ground state\nenergy of the model by means of the mirror TBA equations for the $AdS_{3}\\times\nS^{3}\\times T^{4}$ superstring in the pure RR background. The calculation is\nperformed for small twist $\\mu$ with $L$ and $h$ fixed, for large $L$ with\n$\\mu$ and $h$ fixed, and for small $h$ with $\\mu$ and $L$ fixed. In these\nlimits the contribution of the gapless worldsheet modes coming from the $T^4$\nbosons and fermions can be computed exactly, and is shown to be proportional to\n$hL/(4L^2-1)$. Comparison with the semi-classical result shows that the TBA\nequations involve only one $Y_0$-function for massless excitations but not two\nas was conjectured before. Some of the results obtained are generalised to the\nmixed-flux $AdS_{3}\\times S^{3}\\times T^{4}$ superstring.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:51:22 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17129","submitter":"Nicolas Lecoeur","authors":"Eugeny Babichev, Christos Charmousis, Nicolas Lecoeur","title":"Rotating black holes embedded in a cosmological background for\n  scalar-tensor theories","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present solutions of DHOST theories describing a rotating black hole\nembedded in an expanding universe. The solution is constructed by conformal\ntransformation of a stealth Kerr(-de Sitter) black hole. The conformal factor\ndepends explicitly on the scalar field -- but not on its derivative -- and\ndefines the new theory. The scalar field of the stealth Kerr(-de Sitter)\nsolution depends on time, leading to the time-dependence of the obtained\nconformal metric, with cosmological asymptotics at large distances. We study\nthe properties of the obtained metric by considering regular null geodesic\ncongruences, and identify trapping black hole and cosmological horizons.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:52:16 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17130","submitter":"Antonio Rossi","authors":"Antonio Rossi, Riccardo Dettori, Cameron Johnson, Jesse Balgley, John\n  C. Thomas, Luca Francaviglia, Andreas K. Schmid, Kenji Watanabe, Takashi\n  Taniguchi, Matthew Cothrine, David G. Mandrus, Chris Jozwiak, Aaron Bostwick,\n  Erik A. Henriksen, Alexander Weber-Bargioni and Eli Rotenberg","title":"Direct visualization of the charge transfer in\n  Graphene/$\\alpha$-RuCl$_3$ heterostructure","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the electronic properties of a graphene and $\\alpha$-ruthenium\ntrichloride (hereafter RuCl$_3$) heterostructure, using a combination of\nexperimental and theoretical techniques. RuCl$_3$ is a Mott insulator and a\nKitaev material, and its combination with graphene has gained increasing\nattention due to its potential applicability in novel electronic and\noptoelectronic devices. By using a combination of spatially resolved\nphotoemission spectroscopy, low energy electron microscopy, and density\nfunctional theory (DFT) calculations we are able to provide a first direct\nvisualization of the massive charge transfer from graphene to RuCl$_3$, which\ncan modify the electronic properties of both materials, leading to novel\nelectronic phenomena at their interface. The electronic band structure is\ncompared to DFT calculations that confirm the occurrence of a Mott transition\nfor RuCl$_3$. Finally, a measurement of spatially resolved work function allows\nfor a direct estimate of the interface dipole between graphene and RuCl$_3$.\nThe strong coupling between graphene and RuCl$_3$ could lead to new ways of\nmanipulating electronic properties of two-dimensional lateral heterojunction.\nUnderstanding the electronic properties of this structure is pivotal for\ndesigning next generation low-power opto-electronics devices.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:56:03 GMT"},{"version":"v2","created":"Mon, 29 May 2023 08:25:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17131","submitter":"Xing Niu","authors":"Gabriele Sarti, Phu Mon Htut, Xing Niu, Benjamin Hsu, Anna Currey,\n  Georgiana Dinu, Maria Nadejde","title":"RAMP: Retrieval and Attribute-Marking Enhanced Prompting for\n  Attribute-Controlled Translation","comments":"Accepted at ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Attribute-controlled translation (ACT) is a subtask of machine translation\nthat involves controlling stylistic or linguistic attributes (like formality\nand gender) of translation outputs. While ACT has garnered attention in recent\nyears due to its usefulness in real-world applications, progress in the task is\ncurrently limited by dataset availability, since most prior approaches rely on\nsupervised methods. To address this limitation, we propose Retrieval and\nAttribute-Marking enhanced Prompting (RAMP), which leverages large multilingual\nlanguage models to perform ACT in few-shot and zero-shot settings. RAMP\nimproves generation accuracy over the standard prompting approach by (1)\nincorporating a semantic similarity retrieval component for selecting similar\nin-context examples, and (2) marking in-context examples with attribute\nannotations. Our comprehensive experiments show that RAMP is a viable approach\nin both zero-shot and few-shot settings.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:56:53 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17132","submitter":"Anik Halder","authors":"Anik Halder, Zhengyangguang Gong, Alexandre Barreira, Oliver\n  Friedrich, Stella Seitz, Daniel Gruen","title":"Beyond 3$\\times$2-point cosmology: the integrated shear and galaxy\n  3-point correlation functions","comments":"19 pages, 8 figures + appendix. Comments are welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the integrated 3-point correlation functions (3PCF) involving both\nthe cosmic shear and the galaxy density fields. These are a set of higher-order\nstatistics that describe the modulation of local 2-point correlation functions\n(2PCF) by large-scale features in the fields, and which are easy to measure\nfrom galaxy imaging surveys. Based on previous works on the shear-only\nintegrated 3PCF, we develop the theoretical framework for modelling 5 new\nstatistics involving the galaxy field and its cross-correlations with cosmic\nshear. Using realistic galaxy and cosmic shear mocks from simulations, we\ndetermine the regime of validity of our models based on leading-order standard\nperturbation theory with an MCMC analysis that recovers unbiased constraints of\nthe amplitude of fluctuations parameter $A_s$ and the linear and quadratic\ngalaxy bias parameters $b_1$ and $b_2$. Using Fisher matrix forecasts for a\nDES-Y3-like survey, relative to baseline analyses with conventional\n3$\\times$2PCFs, we find that the addition of the shear-only integrated 3PCF can\nimprove cosmological parameter constraints by $20-40\\%$. The subsequent\naddition of the new statistics introduced in this paper can lead to further\nimprovements of $10-20\\%$, even when utilizing only conservatively large scales\nwhere the tree-level models are valid. Our results motivate future work on the\ngalaxy and shear integrated 3PCFs, which offer a practical way to extend\nstandard analyses based on 3$\\times$2PCFs to systematically probe the\nnon-Gaussian information content of cosmic density fields.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:57:01 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17133","submitter":"David Beltran","authors":"David Beltran, Jennifer Duncan, Jonathan Hickman","title":"Off-diagonal estimates for the helical maximal function","comments":"28 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The optimal $L^p \\to L^q$ mapping properties for the (local) helical maximal\nfunction are obtained, except for endpoints. The proof relies on tools from\nmultilinear harmonic analysis and, in particular, a localised version of the\nBennett--Carbery--Tao restriction theorem.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:57:47 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17134","submitter":"Xinyue Wei","authors":"Xinyue Wei, Fanbo Xiang, Sai Bi, Anpei Chen, Kalyan Sunkavalli,\n  Zexiang Xu, Hao Su","title":"NeuManifold: Neural Watertight Manifold Reconstruction with Efficient\n  and High-Quality Rendering Support","comments":"Project page: https://sarahweiii.github.io/neumanifold/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a method for generating high-quality watertight manifold meshes\nfrom multi-view input images. Existing volumetric rendering methods are robust\nin optimization but tend to generate noisy meshes with poor topology.\nDifferentiable rasterization-based methods can generate high-quality meshes but\nare sensitive to initialization. Our method combines the benefits of both\nworlds; we take the geometry initialization obtained from neural volumetric\nfields, and further optimize the geometry as well as a compact neural texture\nrepresentation with differentiable rasterizers. Through extensive experiments,\nwe demonstrate that our method can generate accurate mesh reconstructions with\nfaithful appearance that are comparable to previous volume rendering methods\nwhile being an order of magnitude faster in rendering. We also show that our\ngenerated mesh and neural texture reconstruction is compatible with existing\ngraphics pipelines and enables downstream 3D applications such as simulation.\nProject page: https://sarahweiii.github.io/neumanifold/\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:59:21 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17135","submitter":"Adam Smercina","authors":"Adam Smercina, Eric F. Bell, Paul A. Price, Jeremy Bailin, Julianne J.\n  Dalcanton, Roelof S. de Jong, Richard D'Souza, Katya Gozman, In Sung Jang,\n  Antonela Monachesi, David Nidever, Colin T. Slater","title":"Origins of the Evil Eye: M64's Stellar Halo Reveals the Recent Accretion\n  of an SMC-mass Satellite","comments":"12 pages, 5 figures, accepted for publication in ApJ Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  M64, often called the \"Evil Eye\" galaxy, is unique among local galaxies.\nBeyond its dramatic, dusty nucleus, it also hosts an outer gas disk that\ncounter-rotates relative to its stars. The mass of this outer disk is\ncomparable to the gas content of the Small Magellanic Cloud (SMC), prompting\nthe idea that it was likely accreted in a recent minor merger. Yet, detailed\nfollow-up studies of M64's outer disk have shown no evidence of such an event,\nleading to other interpretations, such as a \"flyby\" interaction with the\ndistant diffuse satellite Coma P. We present Subaru Hyper Suprime-Cam\nobservations of M64's stellar halo, which resolve its stellar populations and\nreveal a spectacular radial shell feature, oriented $\\sim$30$^{\\circ}$ relative\nto the major axis and along the rotation axis of the outer gas disk. The shell\nis $\\sim$45 kpc southeast of M64, while a similar but more diffuse plume to the\nnorthwest extends to $>$100 kpc. We estimate a stellar mass and metallicity for\nthe southern shell of $M_{\\star} {=} 1.80~{\\pm}~0.54{\\times}10^8~M_{\\odot}$ and\n[M/H] $=$ $-$1.0, respectively, and a similar mass of\n$1.42~{\\pm}~0.71{\\times}10^8 M_{\\odot}$ for the northern plume. Taking into\naccount the accreted material in M64's inner disk, we estimate a total stellar\nmass for the progenitor satellite of $M_{\\rm\n\\star,prog}~{\\simeq}~5{\\times}10^8~M_{\\odot}$. These results suggest that M64\nis in the final stages of a minor merger with a gas-rich satellite strikingly\nsimilar to the SMC, in which M64's accreted counter-rotating gas originated,\nand which is responsible for the formation of its dusty inner star-forming\ndisk.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:59:57 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.17156","submitter":"Md Simul Hasan Talukder","authors":"Md. Simul Hasan Talukder, Sharmin Akter","title":"An Improved Model Ensembled of Different Hyper-parameter Tuned Machine\n  Learning Algorithms for Fetal Health Prediction","comments":"23 pages, 6 Tables, 5 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Fetal health is a critical concern during pregnancy as it can impact the\nwell-being of both the mother and the baby. Regular monitoring and timely\ninterventions are necessary to ensure the best possible outcomes. While there\nare various methods to monitor fetal health in the mother's womb, the use of\nartificial intelligence (AI) can improve the accuracy, efficiency, and speed of\ndiagnosis. In this study, we propose a robust ensemble model called ensemble of\ntuned Support Vector Machine and ExtraTrees (ETSE) for predicting fetal health.\nInitially, we employed various data preprocessing techniques such as outlier\nrejection, missing value imputation, data standardization, and data sampling.\nThen, seven machine learning (ML) classifiers including Support Vector Machine\n(SVM), XGBoost (XGB), Light Gradient Boosting Machine (LGBM), Decision Tree\n(DT), Random Forest (RF), ExtraTrees (ET), and K-Neighbors were implemented.\nThese models were evaluated and then optimized by hyperparameter tuning using\nthe grid search technique. Finally, we analyzed the performance of our proposed\nETSE model. The performance analysis of each model revealed that our proposed\nETSE model outperformed the other models with 100% precision, 100% recall, 100%\nF1-score, and 99.66% accuracy. This indicates that the ETSE model can\neffectively predict fetal health, which can aid in timely interventions and\nimprove outcomes for both the mother and the baby.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:40:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17157","submitter":"Sheila Sagear","authors":"Sheila Sagear and Sarah Ballard","title":"The Orbital Eccentricity Distribution of Planets Orbiting M dwarfs","comments":"23 pages, 9 figures, 5 tables. Data and code available at\n  DOI:10.5281/zenodo.7731019. Accepted to PNAS","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the underlying distribution of orbital eccentricities for\nplanets around early-to-mid M dwarf host stars. We employ a sample of 163\nplanets around early- to mid-M dwarfs across 101 systems detected by NASA's\nKepler Mission. We constrain the orbital eccentricity for each planet by\nleveraging the Kepler lightcurve together with a stellar density prior,\nconstructed using metallicity from spectroscopy, Ks magnitude from 2MASS, and\nstellar parallax from Gaia. Within a Bayesian hierarchical framework, we\nextract the underlying eccentricity distribution, assuming alternately\nRayleigh, half-Gaussian, and Beta functions for both single- and multi-transit\nsystems. We describe the eccentricity distribution for apparently\nsingle-transiting planetary systems with a Rayleigh distribution with sigma =\n0.19 (+0.04, -0.03), and for multi-transit systems with sigma = 0.03 (+0.02,\n-0.01). The data suggest the possibility of distinct dynamically warmer and\ncooler sub-populations within the single-transit distribution: The\nsingle-transit data prefer a mixture model composed of two distinct Rayleigh\ndistributions with sigma_1 = 0.02 (+0.11, -0.00) and sigma_2 = 0.24 (+0.20,\n-0.03) over a single Rayleigh distribution, with 7:1 odds. We contextualize our\nfindings within a planet formation framework, by comparing them to analogous\nresults in the literature for planets orbiting FGK stars. By combining our\nderived eccentricity distribution with other M dwarf demographic constraints,\nwe estimate the underlying eccentricity distribution for the population of\nearly- to mid-M dwarf planets in the local neighborhood.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17158","submitter":"Kirk Barrow","authors":"Lillian Santos-Olmsted, Kirk Barrow, Tilman Hartwig","title":"The Galaxy Assembly and Interaction Neural Networks (GAINN) for\n  high-redshift JWST observations","comments":"19 pages, 6 figures, submitted to ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the Galaxy Assembly and Interaction Neural Networks (GAINN), a\nseries of artificial neural networks for predicting the redshift, stellar mass,\nhalo mass, and mass-weighted age of simulated galaxies based on JWST\nphotometry. Our goal is to determine the best neural network for predicting\nthese variables at $11.5 < z < 15$. The parameters of the optimal neural\nnetwork can then be used to estimate these variables for real, observed\ngalaxies. The inputs of the neural networks are JWST filter magnitudes of a\nsubset of five broadband filters (F150W, F200W, F277W, F356W, and F444W) and\ntwo medium-band filters (F162M and F182M). We compare the performance of the\nneural networks using different combinations of these filters, as well as\ndifferent activation functions and numbers of layers. The best neural network\npredicted redshift with normalized root mean squared error NRMS =\n$0.009_{-0.002}^{+0.003}$, stellar mass with RMS = $0.073_{-0.008}^{+0.017}$,\nhalo mass with MSE = $ 0.022_{-0.004}^{+0.006}$, and mass-weighted age with RMS\n= $10.866_{-1.410}^{+3.189}$. We also test the performance of GAINN on real\ndata from MACS0647-JD, an object observed by JWST. Predictions from GAINN for\nthe first projection of the object (JD1) have mean absolute errors $\\langle\n\\Delta z \\rangle <0.00228$, which is significantly smaller than with\ntemplate-fitting methods. We find that the optimal filter combination is F277W,\nF356W, F162M, and F182M when considering both theoretical accuracy and\nobservational resources from JWST.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17159","submitter":"Lakshya Bhardwaj","authors":"Lakshya Bhardwaj, Sakura Schafer-Nameki","title":"Generalized Charges, Part II: Non-Invertible Symmetries and the Symmetry\n  TFT","comments":"140 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th cond-mat.str-el math-ph math.CT math.MP math.QA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Consider a d-dimensional quantum field theory (QFT) $\\mathfrak{T}$, with a\ngeneralized symmetry $\\mathcal{S}$, which may or may not be invertible. We\nstudy the action of $\\mathcal{S}$ on generalized or $q$-charges, i.e.\n$q$-dimensional operators. The main result of this paper is that $q$-charges\nare characterized in terms of the topological defects of the Symmetry\nTopological Field Theory (SymTFT) of $\\mathcal{S}$, also known as the\n``Sandwich Construction''. The SymTFT is a $(d+1)$-dimensional topological\nfield theory, which encodes the symmetry $\\mathcal{S}$ and the physical theory\nin terms of its boundary conditions. Our proposal applies quite generally to\nany finite symmetry $\\mathcal{S}$, including non-invertible, categorical\nsymmetries. Mathematically, the topological defects of the SymTFT form the\nDrinfeld Center of the symmetry category $\\mathcal{S}$. Applied to invertible\nsymmetries, we recover the result of Part I of this series of papers. After\nproviding general arguments for the identification of $q$-charges with the\ntopological defects of the SymTFT, we develop this program in detail for QFTs\nin 2d (for general fusion category symmetries) and 3d (for fusion 2-category\nsymmetries).\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:00 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17160","submitter":"Christopher Dessert","authors":"Christopher Dessert, Orion Ning, Nicholas L. Rodd, Benjamin R. Safdi","title":"Limits from the grave: resurrecting Hitomi for decaying dark matter and\n  forecasting leading sensitivity for XRISM","comments":"7+6 pages, 3+8 figures, supplementary data at\n  https://github.com/bsafdi/Hitomi_BSO_for_DM, video abstract at\n  https://youtu.be/EXBo-WHwwMw","journal-ref":null,"doi":null,"report-no":"CERN-TH-2023-088","categories":"astro-ph.CO astro-ph.HE hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Hitomi X-ray satellite mission carried unique high-resolution\nspectrometers that were set to revolutionize the search for sterile neutrino\ndark matter (DM) by looking for narrow X-ray lines arising from DM decays.\nUnfortunately, the satellite was lost shortly after launch, and to-date the\nonly analysis using Hitomi for DM decay used data taken towards the Perseus\ncluster. In this work we present a significantly more sensitive search from an\nanalysis of archival Hitomi data towards blank sky locations, searching for DM\ndecaying in our own Milky Way. The soon-to-be-launched XRISM satellite will\nhave nearly identical soft-X-ray spectral capabilities to Hitomi; we project\nthe full-mission sensitivity of XRISM for analyses of their future blank-sky\ndata, and we find that XRISM will have the leading sensitivity to decaying DM\nfor masses between roughly 1 to 20 keV, with important implications for sterile\nneutrino and heavy axion-like particle DM scenarios.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17161","submitter":"Jonas Wildberger","authors":"Maximilian Dax, Jonas Wildberger, Simon Buchholz, Stephen R. Green,\n  Jakob H. Macke, Bernhard Sch\\\"olkopf","title":"Flow Matching for Scalable Simulation-Based Inference","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural posterior estimation methods based on discrete normalizing flows have\nbecome established tools for simulation-based inference (SBI), but scaling them\nto high-dimensional problems can be challenging. Building on recent advances in\ngenerative modeling, we here present flow matching posterior estimation (FMPE),\na technique for SBI using continuous normalizing flows. Like diffusion models,\nand in contrast to discrete flows, flow matching allows for unconstrained\narchitectures, providing enhanced flexibility for complex data modalities. Flow\nmatching, therefore, enables exact density evaluation, fast training, and\nseamless scalability to large architectures--making it ideal for SBI. We show\nthat FMPE achieves competitive performance on an established SBI benchmark, and\nthen demonstrate its improved scalability on a challenging scientific problem:\nfor gravitational-wave inference, FMPE outperforms methods based on comparable\ndiscrete flows, reducing training time by 30% with substantially improved\naccuracy. Our work underscores the potential of FMPE to enhance performance in\nchallenging inference scenarios, thereby paving the way for more advanced\napplications to scientific problems.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:01 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17162","submitter":"Josephine Baggen","authors":"Josephine F.W. Baggen, Pieter van Dokkum, Ivo Labbe, Gabriel Brammer,\n  Tim B. Miller, Rachel Bezanson, Joel Leja, Bingjie Wang, Katherine E.\n  Whitaker, Katherine A. Suess, Erica J. Nelson","title":"Sizes and mass profiles of candidate massive galaxies discovered by JWST\n  at 7<z<9: evidence for very early formation of the central ~100 pc of\n  present-day ellipticals","comments":"Submitted to ApJ Letters","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The first JWST data revealed an unexpected population of red galaxies that\nappear to have redshifts of $z\\sim 7-9$ and high masses of $M_*$ $\\sim$\n10$^{10}$ M$_{\\odot}$ (Labb\\'e et al. 2023). Here we fit S\\'ersic profiles to\nthe F200W NIRCam images of the 13 massive galaxy candidates of Labb\\'e et al.,\nto determine their structural parameters. Satisfactory fits were obtained for\nnine galaxies. We find that their effective radii are extremely small, ranging\nfrom $r_{\\rm e}\\sim 80$ pc to $r_{\\rm e} \\sim 300$ pc, with a mean of $\\langle\nr_{\\rm e}\\rangle \\approx 150$ pc. For their apparent stellar masses, the\ngalaxies are smaller than any other galaxy population that has been observed at\nany other redshift. We use the fits to derive circularized three-dimensional\nstellar mass profiles of the galaxies, and compare these to the mass profiles\nof massive quiescent galaxies at $z\\sim$2.3 and nearby elliptical galaxies. We\nfind that, despite the high redshift galaxies having $10-20$ times smaller\nhalf-light radii, the central stellar densities are comparable to those of\ntheir putative descendants at later times. The most straightforward\ninterpretation is that the dense compact inner regions of the most massive\nellipticals today were already in place $\\sim 600$ Myr after the Big Bang. We\ncaution that the redshifts and masses of the galaxies remain to be confirmed,\nand that the complex NIRCam point spread function is not yet fully\ncharacterized.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:02 GMT"},{"version":"v2","created":"Tue, 30 May 2023 20:06:43 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17163","submitter":"Kamil Korzekwa","authors":"Fereshte Shahbeigi, Christopher T. Chubb, Ryszard Kukulski, {\\L}ukasz\n  Pawela, Kamil Korzekwa","title":"Quantum-embeddable stochastic matrices","comments":"14 pages, 3 figures, comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The classical embeddability problem asks whether a given stochastic matrix\n$T$, describing transition probabilities of a $d$-level system, can arise from\nthe underlying homogeneous continuous-time Markov process. Here, we investigate\nthe quantum version of this problem, asking of the existence of a Markovian\nquantum channel generating state transitions described by a given $T$. More\nprecisely, we aim at characterising the set of quantum-embeddable stochastic\nmatrices that arise from memoryless continuous-time quantum evolution. To this\nend, we derive both upper and lower bounds on that set, providing new families\nof stochastic matrices that are quantum-embeddable but not\nclassically-embeddable, as well as families of stochastic matrices that are not\nquantum-embeddable. As a result, we demonstrate that a larger set of transition\nmatrices can be explained by memoryless models if the dynamics is allowed to be\nquantum, but we also identify a non-zero measure set of random processes that\ncannot be explained by either classical or quantum memoryless dynamics.\nFinally, we fully characterise extreme stochastic matrices (with entries given\nonly by zeros and ones) that are quantum-embeddable.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17164","submitter":"Kiryl Pakrouski","authors":"Patrice Kolb, Kiryl Pakrouski","title":"Stability of the many-body scars in fermionic spin-1/2 models","comments":"16 pages, 11 figures; v2: references added, typos corrected","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.quant-gas cond-mat.stat-mech quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the stability of the many-body scars in spin-1/2 fermionic systems\nunder the most typical perturbations in relevant materials. We find that some\nfamilies of scars are completely insensitive to certain perturbations. In some\nother cases they are stable to the first order in perturbation theory. Our\nanalytical results apply to a large class of Hamiltonians that are known\n[arXiv:2106.10300] to support exact many-body scars. For the numerical\ncalculations we choose the deformed $t-J-U$ model that includes both Heisenberg\nand Hubbard interactions. We propose two new stability measures that are based\non physical observables rather than the fidelity to the exact initial\nwavefunction. They enable the experimental detection of scars and are more\nreliable from the theoretical and numerical perspectives. One of these measures\nmay potentially find applications in other systems where the exact many-body\nscars are equally spaced in energy. In small systems and at small\nperturbations, a regime particularly relevant for quantum simulators, we\nidentify and describe an additional stability exhibited by the many-body scars.\nFor larger perturbation strengths we observe a distinct mode of ergodicity\nbreaking that is consistent with many-body localization.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:03 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 16:10:32 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17165","submitter":"Mathew Bullimore","authors":"Thomas Bartsch, Mathew Bullimore, Andrea Grigoletto","title":"Representation theory for categorical symmetries","comments":"84 pages + appendix, 59 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th math-ph math.CT math.MP math.QA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper addresses the question of how categorical symmetries act on\nextended operators in quantum field theory. Building on recent results in two\ndimensions, we introduce higher tube categories and algebras associated to\nhigher fusion category symmetries. We show that twisted sector extended\noperators transform in higher representations of higher tube algebras and\ninterpret this result from the perspective of the sandwich construction of\nfinite symmetries via the Drinfeld center. Focusing on three dimensions, we\ndiscuss a variety of examples to illustrate the general constructions. In the\ncase of invertible symmetries, we show that higher tube algebras are higher\nanalogues of twisted Drinfeld doubles of finite groups, generalising known\nconstructions in two dimensions. Building on this foundation, we discuss\nnon-invertible Ising-like symmetry categories obtained by gauging finite\nsubgroups. We also consider non-invertible topological symmetry lines described\nby braided fusion categories and discuss connections to the M\\\"uger center and\nbraided module categories.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17166","submitter":"Riccardo Gonzo","authors":"Riccardo Gonzo, Anton Ilderton","title":"Wave scattering event shapes at high energies","comments":"37 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the space and properties of global and local observables for\nradiation emitted in the scattering of a massive scalar field in gauge and\ngravitational plane-wave backgrounds, in both the quantum and classical theory.\nWe first compute the radiated momentum and angular momentum flow, demonstrating\nthat they are good local observables determined by the amplitude and phase of\nthe waveform. We then focus on the corresponding global observables, which in\nthe gravitational case requires dealing with the collinear divergence of the\ngravitational Compton cross-section. We show using the KLN theorem that we can\nobtain an infrared-finite cross-section only by summing over forward scattering\ndiagrams; this suggests dressing the initial state in the direction collinear\nto the plane wave in order to be able to compute observables integrated over\nthe celestial sphere. Finally, we explore the high-energy behaviour of our\nobservables. We find that classical global observables generically exhibit a\npower-law mass divergence in electrodynamics and a logarithmic mass divergence\nin gravity, even when radiation reaction is included. We then show explicitly\nhow this is consistently resolved in the full quantum theory.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17167","submitter":"A. J. Barger","authors":"L.L. Cowie, A.J. Barger, F.E. Bauer","title":"2mm Observations and the Search for High-Redshift Dusty Star-forming\n  Galaxies","comments":"14 pages, 8 figures. ApJ, in press","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Finding high-redshift (z>>4) dusty star-forming galaxies is extremely\nchallenging. It has recently been suggested that millimeter selections may be\nthe best approach, since the negative K-correction makes galaxies at a given\nfar-infrared (FIR) luminosity brighter at z>4 than those at z=2-3. Here we\nanalyze this issue using a deep ALMA 2mm sample obtained by targeting ALMA\n870um priors (these priors were the result of targeting SCUBA-2 850um sources)\nin the GOODS-S. We construct the prior-based 2mm galaxy number counts and\ncompare them with published blank field-based 2mm counts, finding good\nagreement down to 0.2mJy. Only a fraction of the current 2mm extragalactic\nbackground light is resolved, and we estimate what observational depths may be\nneeded to resolve it fully. By complementing the 2mm ALMA data with a deep\nSCUBA-2 450um sample in the GOODS-S, we exploit the steep gradient with\nredshift of the 2mm to 450um flux density ratio to estimate redshifts for these\ngalaxies without spectroscopic or robust optical/near-infrared photometric\nredshifts. Our observations measure galaxies with star formation rates in\nexcess of 250 solar masses per year. For these galaxies, the star formation\nrate densities fall by a factor of 9 from z=2-3 to z=5-6.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17168","submitter":"Ruggero Noris","authors":"Laura Andrianopoli, Bianca Letizia Cerchiai, Ruggero Noris, Lucrezia\n  Ravera, Mario Trigiante, Jorge Zanelli","title":"New Torsional Deformations of Locally AdS$_3$ Space","comments":"24 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider general torsion components in three-dimensional Einstein-Cartan\ngravity, providing a geometrical interpretation for matter, and find new\nsolutions of the corresponding equations for the Riemann curvature and torsion.\nThese geometries involve a peculiar interplay between the vector $(\\beta_i)$\nand the singlet $(\\tau)$ irreducible components of the torsion which, under\ngeneral conditions, feature a formal analogy with the equation for a Beltrami\nfluid. Interestingly, we find that the local AdS$_3$ geometry is now deformed\nby effect of the \"Beltrami-torsion\" $\\beta_i$. Some of these new solutions\ndescribe deformations of the BTZ black hole due to the presence of torsion. The\nlatter acts as a geometric flux which, in some cases, removes the causal\nsingularity.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17169","submitter":"Jay Chan","authors":"Jay Chan, Xiangyang Ju, Adam Kania, Benjamin Nachman, Vishnu Sangli\n  and Andrzej Siodmok","title":"Fitting a Deep Generative Hadronization Model","comments":"14 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex physics.data-an","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Hadronization is a critical step in the simulation of high-energy particle\nand nuclear physics experiments. As there is no first principles understanding\nof this process, physically-inspired hadronization models have a large number\nof parameters that are fit to data. Deep generative models are a natural\nreplacement for classical techniques, since they are more flexible and may be\nable to improve the overall precision. Proof of principle studies have shown\nhow to use neural networks to emulate specific hadronization when trained using\nthe inputs and outputs of classical methods. However, these approaches will not\nwork with data, where we do not have a matching between observed hadrons and\npartons. In this paper, we develop a protocol for fitting a deep generative\nhadronization model in a realistic setting, where we only have access to a set\nof hadrons in data. Our approach uses a variation of a Generative Adversarial\nNetwork with a permutation invariant discriminator. We find that this setup is\nable to match the hadronization model in Herwig with multiple sets of\nparameters. This work represents a significant step forward in a longer term\nprogram to develop, train, and integrate machine learning-based hadronization\nmodels into parton shower Monte Carlo programs.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17170","submitter":"Nicholas H. Nelsen","authors":"Samuel Lanthaler, Nicholas H. Nelsen","title":"Error Bounds for Learning with Vector-Valued Random Features","comments":"25 pages, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper provides a comprehensive error analysis of learning with\nvector-valued random features (RF). The theory is developed for RF ridge\nregression in a fully general infinite-dimensional input-output setting, but\nnonetheless applies to and improves existing finite-dimensional analyses. In\ncontrast to comparable work in the literature, the approach proposed here\nrelies on a direct analysis of the underlying risk functional and completely\navoids the explicit RF ridge regression solution formula in terms of random\nmatrices. This removes the need for concentration results in random matrix\ntheory or their generalizations to random operators. The main results\nestablished in this paper include strong consistency of vector-valued RF\nestimators under model misspecification and minimax optimal convergence rates\nin the well-specified setting. The parameter complexity (number of random\nfeatures) and sample complexity (number of labeled data) required to achieve\nsuch rates are comparable with Monte Carlo intuition and free from logarithmic\nfactors.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17171","submitter":"Thomas W. Baumgarte","authors":"Thomas W. Baumgarte, Bernd Br\\\"ugmann, Daniela Cors, Carsten Gundlach,\n  David Hilditch, Anton Khirnov, Tom\\'a\\v{s} Ledvinka, Sarah Renkhoff, and\n  Isabel Su\\'arez Fern\\'andez","title":"Critical phenomena in the collapse of gravitational waves","comments":"6 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fine-tuning generic but smooth spherically-symmetric initial data for general\nrelativity to the threshold of dynamical black hole formation creates\narbitrarily large curvatures, mediated by a universal self-similar solution\nthat acts as an intermediate attractor. For vacuum gravitational waves,\nhowever, these critical phenomena have been elusive. We present, for the first\ntime, excellent agreement among three independent numerical simulations of this\ncollapse. Surprisingly, we find no universality, and observe approximate\nself-similarity for some families of initial data but not for others.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17172","submitter":"Sophia Stuber","authors":"S. K. Stuber, E. Schinnerer, T. G. Williams, M. Querejeta, S. Meidt,\n  E. Emsellem, A. Barnes, R. S. Klessen, A. K. Leroy, J. Neumann, M. C.\n  Sormani, F. Bigiel, M. Chevance, D. Dale, C. Faesi, S. C. O. Glover, K.\n  Grasha, J. M. D. Kruijssen, D. Liu, H. Pan, J. Pety, F. Pinna, T. Saito, A.\n  Usero, E. J. Watkins","title":"The Gas Morphology of Nearby Star-Forming Galaxies","comments":"17 pages, 14 figures (+ Appendix 9 pages, 4 figures). Accepted for\n  publication in A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The morphology of a galaxy stems from secular and environmental processes\nduring its evolutionary history. Thus galaxy morphologies have been a long used\ntool to gain insights on galaxy evolution. We visually classify morphologies on\ncloud-scales based on the molecular gas distribution of a large sample of 79\nnearby main-sequence galaxies, using 1'' resolution CO(2-1) ALMA observations\ntaken as part of the PHANGS survey. To do so, we devise a morphology\nclassification scheme for different types of bars, spiral arms (grand-design,\nflocculent, multi-arm and smooth), rings (central and non-central rings)\nsimilar to the well-established optical ones, and further introduce bar lane\nclasses. In general, our cold gas based morphologies agree well with the ones\nbased on stellar light. Both our bars as well as grand-design spiral arms are\npreferentially found at the higher mass end of our sample. Our gas-based\nclassification indicates a potential for misidentification of unbarred galaxies\nin the optical when massive star formation is present. Central or nuclear rings\nare present in a third of the sample with a strong preferences for barred\ngalaxies (59%). As stellar bars are present in 45$\\pm$5% of our sample\ngalaxies, we explore the utility of molecular gas as tracer of bar lane\nproperties. We find that more curved bar lanes have a shorter radial extent in\nmolecular gas and reside in galaxies with lower molecular to stellar mass\nratios than those with straighter geometries. Galaxies display a wide range of\nCO morphology, and this work provides a catalogue of morphological features in\na representative sample of nearby galaxies.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17173","submitter":"Catherine Heymans","authors":"Dark Energy Survey and Kilo-Degree Survey Collaboration: T. M. C.\n  Abbott, M. Aguena, A. Alarcon, O. Alves, A. Amon, F. Andrade-Oliveira, M.\n  Asgari, S. Avila, D. Bacon, K. Bechtol, M. R. Becker, G. M. Bernstein, E.\n  Bertin, M. Bilicki, J. Blazek, S. Bocquet, D. Brooks, P. Burger, D. L. Burke,\n  H. Camacho, A. Campos, A. Carnero Rosell, M. Carrasco Kind, J. Carretero, F.\n  J. Castander, R. Cawthon, C. Chang, R. Chen, A. Choi, C. Conselice, J.\n  Cordero, L. N. da Costa, M. E. S. Pereira, R. Dalal, C. Davis, J. T. A.\n  deJong, J. DeRose, S. Desai, H. T. Diehl, S. Dodelson, P. Doel, C. Doux, A.\n  Drlica-Wagner, A. Dvornik, K. Eckert, T. F. Eifler, J. Elvin-Poole, S.\n  Everett, X. Fang, I. Ferrero, A. Fert\\'e, B. Flaugher, O. Friedrich, J.\n  Frieman, J. Garc\\'ia-Bellido, M. Gatti, G. Giannini, B. Giblin, D. Gruen, R.\n  A. Gruendl, G. Gutierrez, I. Harrison, W. G. Hartley, K. Herner, C. Heymans,\n  H. Hildebrandt, S. R. Hinton, H. Hoekstra, D. L. Hollowood, K. Honscheid, H.\n  Huang, E. M. Huff, D. Huterer, D. J. James, M. Jarvis, N. Jeffrey, T.\n  Jeltema, B. Joachimi, S. Joudaki, A. Kannawadi, E. Krause, K. Kuehn, K.\n  Kuijken, N. Kuropatkin, P.-F. Leget, P. Lemos, S. Li, X. Li, A. R. Liddle, M.\n  Lima, C.-A Lin, H. Lin, N. MacCrann, C. Mahony, J. L. Marshall, J.\n  McCullough, J. Mena-Fern\\'andez, F. Menanteau, R. Miquel, J. J. Mohr, J.\n  Muir, J. Myles, N. Napolitano, A. Navarro-Alsina, R. L. C. Ogando, A.\n  Palmese, S. Pandey, Y. Park, M. Paterno, J. A. Peacock, D. Petravick, A.\n  Pieres, A. A. Plazas Malag\\'on, A. Porredon, J. Prat, M. Radovich, M. Raveri,\n  R. Reischke, R. P. Rollins, A. K. Romer, A. Roodman, E. S. Rykoff, S.\n  Samuroff, C. S\\'anchez, E. Sanchez, J. Sanchez, P. Schneider, L. F. Secco, I.\n  Sevilla-Noarbe, H. Shan, E. Sheldon, T. Shin, C. Sif\\'on, M. Smith, M.\n  Soares-Santos, B. St\\\"olzner, E. Suchyta, M. E. C. Swanson, G. Tarle, D.\n  Thomas, C. To, M. A. Troxel, T. Tr\\\"oster, I. Tutusaus, J. L. van den Busch,\n  T. N. Varga, A. R. Walker, N. Weaverdyck, R. H. Wechsler, J. Weller, P.\n  Wiseman, A. H. Wright, B. Yanny, B. Yin, M. Yoon, Y. Zhang, J. Zuntz","title":"DES Y3 + KiDS-1000: Consistent cosmology combining cosmic shear surveys","comments":"38 pages, 21 figures, 15 tables, submitted to the Open Journal of\n  Astrophysics. Watch the core team discuss this analysis at\n  https://cosmologytalks.com/2023/05/26/des-kids","journal-ref":null,"doi":null,"report-no":"FERMILAB-PUB-23-267-PPD","categories":"astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a joint cosmic shear analysis of the Dark Energy Survey (DES Y3)\nand the Kilo-Degree Survey (KiDS-1000) in a collaborative effort between the\ntwo survey teams. We find consistent cosmological parameter constraints between\nDES Y3 and KiDS-1000 which, when combined in a joint-survey analysis, constrain\nthe parameter $S_8 = \\sigma_8 \\sqrt{\\Omega_{\\rm m}/0.3}$ with a mean value of\n$0.790^{+0.018}_{-0.014}$. The mean marginal is lower than the maximum a\nposteriori estimate, $S_8=0.801$, owing to skewness in the marginal\ndistribution and projection effects in the multi-dimensional parameter space.\nOur results are consistent with $S_8$ constraints from observations of the\ncosmic microwave background by Planck, with agreement at the $1.7\\sigma$ level.\nWe use a Hybrid analysis pipeline, defined from a mock survey study quantifying\nthe impact of the different analysis choices originally adopted by each survey\nteam. We review intrinsic alignment models, baryon feedback mitigation\nstrategies, priors, samplers and models of the non-linear matter power\nspectrum.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17174","submitter":"Julia Mendelsohn","authors":"Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap","title":"From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language\n  Models","comments":"ACL 2023, see https://dogwhistles.allen.ai/ for the glossary and\n  other materials","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dogwhistles are coded expressions that simultaneously convey one meaning to a\nbroad audience and a second one, often hateful or provocative, to a narrow\nin-group; they are deployed to evade both political repercussions and\nalgorithmic content moderation. For example, in the sentence 'we need to end\nthe cosmopolitan experiment,' the word 'cosmopolitan' likely means 'worldly' to\nmany, but secretly means 'Jewish' to a select few. We present the first\nlarge-scale computational investigation of dogwhistles. We develop a typology\nof dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles\nwith rich contextual information and examples, and analyze their usage in\nhistorical U.S. politicians' speeches. We then assess whether a large language\nmodel (GPT-3) can identify dogwhistles and their meanings, and find that\nGPT-3's performance varies widely across types of dogwhistles and targeted\ngroups. Finally, we show that harmful content containing dogwhistles avoids\ntoxicity detection, highlighting online risks of such coded language. This work\nsheds light on the theoretical and applied importance of dogwhistles in both\nNLP and computational social science, and provides resources for future\nresearch in modeling dogwhistles and mitigating their online harms.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:00:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17175","submitter":"Hanwen Ren","authors":"Hanwen Ren and Ahmed H. Qureshi","title":"Multi-Stage Monte Carlo Tree Search for Non-Monotone Object\n  Rearrangement Planning in Narrow Confined Environments","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-monotone object rearrangement planning in confined spaces such as\ncabinets and shelves is a widely occurring but challenging problem in robotics.\nBoth the robot motion and the available regions for object relocation are\nhighly constrained because of the limited space. This work proposes a\nMulti-Stage Monte Carlo Tree Search (MS-MCTS) method to solve non-monotone\nobject rearrangement planning problems in confined spaces. Our approach\ndecouples the complex problem into simpler subproblems using an object stage\ntopology. A subgoal-focused tree expansion algorithm that jointly considers the\nhigh-level planning and the low-level robot motion is designed to reduce the\nsearch space and better guide the search process. By fitting the task into the\nMCTS paradigm, our method produces optimistic solutions by balancing\nexploration and exploitation. The experiments demonstrate that our method\noutperforms the existing methods regarding the planning time, the number of\nsteps, and the total move distance. Moreover, we deploy our MS-MCTS to a\nreal-world robot system and verify its performance in different confined\nenvironments.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:03:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17176","submitter":"Anthony Noll","authors":"Anthony Noll and S\\'ebastien Deheuvels","title":"How the modeling of mixing and nuclear energy production impacts the\n  extent of convective cores","comments":"10 pages, 11 figures, accepted in A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Convective cores are the hydrogen reservoirs of main sequence stars that are\nmore massive than around 1.2 solar masses. The characteristics of the cores\nhave a strong impact on the evolution and structure of the star. However, such\nresults rely on stellar evolution codes in which simplistic assumptions are\noften made on the physics in the core. Indeed, the mixing is commonly\nconsidered to be instantaneous and the most basic nuclear networks assume\nberyllium at its equilibrium abundance. Those assumptions lead to significant\ndifferences in the central composition of the elements for which the timescale\nto reach nuclear equilibrium is lower than the convective timescale. In this\nwork, we show that those discrepancies impact the nuclear energy production and\ntherefore the size of convective cores in models computed with overshoot. We\nfind that cores computed with instantaneous mixing are up to 30% bigger than\nthose computed with diffusive mixing. Similar differences are found when using\nbasic nuclear networks. Additionally, we observe an extension of the duration\nof the main sequence due to those core size differences. We then investigate\nthe impact of those structural differences on the seismic modeling of\nsolar-like oscillators. Modeling two stars observed by Kepler, we find that the\novershoot parameter of the best models computed with a basic nuclear network is\nsignificantly lower compared to models computed with a full nuclear network.\nThis work is a necessary step for a better modeling of convective cores which\nis key to determine accurate ages in the framework of future space missions\nsuch as Plato.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:04:04 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17177","submitter":"John Stevenson PhD","authors":"John C. Stevenson","title":"Local Sharing and Sociality Effects on Wealth Inequality in a Simple\n  Artificial Society","comments":"2 tables, 1 algorithm PDL, and 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph cs.CE cs.MA econ.GN q-fin.EC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Redistribution of resources within a group as a method to reduce wealth\ninequality is a current area of debate. The evolutionary path to or away from\nwealth sharing is also a subject of active research. In order to investigate\neffects and evolution of wealth sharing, societies are simulated using a\nminimal model of a complex adapting system. These simulations demonstrate, for\nthis artificial foraging society, that local sharing of resources reduces the\neconomy's total wealth and increases wealth inequality. Evolutionary pressures\nstrongly select against local sharing, whether globally or within a\nindividual's clan, and select for asocial behaviors. By holding constant the\ngene for sharing resources among neighbors, from rich to poor, either with\neveryone or only within members of the same clan, social behavior is selected\nbut total wealth and mean age are substantially reduced relative to non-sharing\nsocieties. The Gini coefficient is shown to be ineffective in measuring these\nchanges in total wealth and wealth distributions, and, therefore, individual\nwell-being. Only with sociality do strategies emerge that allow sharing clans\nto exclude or coexist with non-sharing clans. These strategies are based on\nspatial effects, emphasizing the importance of modeling movement mediated\ncommunity assembly and coexistence as well as sociality.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:04:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17178","submitter":"Sibo Zhang","authors":"Sibo Zhang, Bruno Clerckx, David Vargas, Oliver Haffenden, Andrew\n  Murphy","title":"Rate-Splitting Multiple Access: Finite Constellations, Receiver Design,\n  and SIC-free Implementation","comments":"Submitted to IEEE for publication","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rate-Splitting Multiple Access (RSMA) has emerged as a novel multiple access\ntechnique that enlarges the achievable rate region of Multiple-Input\nMultiple-Output (MIMO) broadcast channels with linear precoding. In this work,\nwe jointly address three practical but fundamental questions: (1) How to\nexploit the benefit of RSMA under finite constellations? (2) What are the\npotential and promising ways to implement RSMA receivers? (3) Can RSMA still\nretain its superiority in the absence of successive interference cancellers\n(SIC)? To address these concerns, we first propose low-complexity precoder\ndesigns taking finite constellations into account and show that the potential\nof RSMA is better achieved with such designs than those assuming Gaussian\nsignalling. We then consider some practical receiver designs that can be\napplied to RSMA. We notice that these receiver designs follow one of two\nprinciples: (1) SIC: cancelling upper layer signals before decoding the lower\nlayer and (2) non-SIC: treating upper layer signals as noise when decoding the\nlower layer. In light of this, we propose to alter the precoder design\naccording to the receiver category. Through link-level simulations, the\neffectiveness of the proposed precoder and receiver designs are verified. More\nimportantly, we show that it is possible to preserve the superiority of RSMA\nover Spatial Domain Multiple Access (SDMA), including SDMA with advanced\nreceivers, even without SIC at the receivers. Those results therefore open the\ndoor to competitive implementable RSMA strategies for 6G and beyond\ncommunications.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:05:35 GMT"},{"version":"v2","created":"Tue, 30 May 2023 01:31:58 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17179","submitter":"Tomasz Limisiewicz","authors":"Tomasz Limisiewicz and Ji\\v{r}\\'i Balhar and David Mare\\v{c}ek","title":"Tokenization Impacts Multilingual Language Modeling: Assessing\n  Vocabulary Allocation and Overlap Across Languages","comments":"in ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multilingual language models have recently gained attention as a promising\nsolution for representing multiple languages in a single model. In this paper,\nwe propose new criteria to evaluate the quality of lexical representation and\nvocabulary overlap observed in sub-word tokenizers. Our findings show that the\noverlap of vocabulary across languages can be actually detrimental to certain\ndownstream tasks (POS, dependency tree labeling). In contrast, NER and\nsentence-level tasks (cross-lingual retrieval, NLI) benefit from sharing\nvocabulary. We also observe that the coverage of the language-specific tokens\nin the multilingual vocabulary significantly impacts the word-level tasks. Our\nstudy offers a deeper understanding of the role of tokenizers in multilingual\nlanguage models and guidelines for future model developers to choose the most\nsuitable tokenizer for their specific application before undertaking costly\nmodel pre-training\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:06:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17180","submitter":"Kyle Yoshida","authors":"Kyle T. Yoshida, Joel X. Kiernan, Allison M. Okamura, Cara M. Nunez","title":"Exploring Human Response Times to Combinations of Audio, Haptic, and\n  Visual Stimuli from a Mobile Device","comments":"Accepted to World Haptics Conference 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Auditory, haptic, and visual stimuli provide alerts, notifications, and\ninformation for a wide variety of applications ranging from virtual reality to\nwearable and hand-held devices. Response times to these stimuli have been used\nto assess motor control and design human-computer interaction systems. In this\nstudy, we investigate human response times to 26 combinations of auditory,\nhaptic, and visual stimuli at three levels (high, low, and off). We developed\nan iOS app that presents these stimuli in random intervals and records response\ntimes on an iPhone 11. We conducted a user study with 20 participants and found\nthat response time decreased with more types and higher levels of stimuli. The\nlow visual condition had the slowest mean response time (mean +/- standard\ndeviation, 528 +/- 105 ms) and the condition with high levels of audio, haptic,\nand visual stimuli had the fastest mean response time (320 +/- 43 ms). This\nwork quantifies response times to multi-modal stimuli, identifies interactions\nbetween different stimuli types and levels, and introduces an app-based method\nthat can be widely distributed to measure response time. Understanding\npreferences and response times for stimuli can provide insight into designing\ndevices for human-machine interaction.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:08:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17181","submitter":"Hsu-Kuang Chiu","authors":"Hsu-kuang Chiu and Stephen F. Smith","title":"Selective Communication for Cooperative Perception in End-to-End\n  Autonomous Driving","comments":"Scalable Autonomous Driving Workshop of IEEE International Conference\n  on Robotics and Automation (ICRA Workshop), 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The reliability of current autonomous driving systems is often jeopardized in\nsituations when the vehicle's field-of-view is limited by nearby occluding\nobjects. To mitigate this problem, vehicle-to-vehicle communication to share\nsensor information among multiple autonomous driving vehicles has been\nproposed. However, to enable timely processing and use of shared sensor data,\nit is necessary to constrain communication bandwidth, and prior work has done\nso by restricting the number of other cooperative vehicles and randomly\nselecting the subset of vehicles to exchange information with from all those\nthat are within communication range. Although simple and cost effective from a\ncommunication perspective, this selection approach suffers from its\nsusceptibility to missing those vehicles that possess the perception\ninformation most critical to navigation planning. Inspired by recent\nmulti-agent path finding research, we propose a novel selective communication\nalgorithm for cooperative perception to address this shortcoming. Implemented\nwith a lightweight perception network and a previously developed control\nnetwork, our algorithm is shown to produce higher success rates than a random\nselection approach on previously studied safety-critical driving scenario\nsimulations, with minimal additional communication overhead.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:13:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17182","submitter":"Yihong Liu","authors":"Yihong Liu, Alexandra Chronopoulou, Hinrich Sch\\\"utze, Alexander\n  Fraser","title":"On the Copying Problem of Unsupervised NMT: A Training Schedule with a\n  Language Discriminator Loss","comments":"IWSLT 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although unsupervised neural machine translation (UNMT) has achieved success\nin many language pairs, the copying problem, i.e., directly copying some parts\nof the input sentence as the translation, is common among distant language\npairs, especially when low-resource languages are involved. We find this issue\nis closely related to an unexpected copying behavior during online\nback-translation (BT). In this work, we propose a simple but effective training\nschedule that incorporates a language discriminator loss. The loss imposes\nconstraints on the intermediate translation so that the translation is in the\ndesired language. By conducting extensive experiments on different language\npairs, including similar and distant, high and low-resource languages, we find\nthat our method alleviates the copying problem, thus improving the translation\nperformance on low-resource languages.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:14:23 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 09:41:35 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17183","submitter":"Kai San Chan","authors":"Kai San Chan, Huimiao Chen, Chenyu Jin, Yuxuan Tian, Dingchang Lin","title":"ProGroTrack: Deep Learning-Assisted Tracking of Intracellular Protein\n  Growth Dynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.QM cs.AI eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accurate tracking of cellular and subcellular structures, along with their\ndynamics, plays a pivotal role in understanding the underlying mechanisms of\nbiological systems. This paper presents a novel approach, ProGroTrack, that\ncombines the You Only Look Once (YOLO) and ByteTrack algorithms within the\ndetection-based tracking (DBT) framework to track intracellular protein\nnanostructures. Focusing on iPAK4 protein fibers as a representative case\nstudy, we conducted a comprehensive evaluation of YOLOv5 and YOLOv8 models,\nrevealing the superior performance of YOLOv5 on our dataset. Notably, YOLOv5x\nachieved an impressive mAP50 of 0.839 and F-score of 0.819. To further optimize\ndetection capabilities, we incorporated semi-supervised learning for model\nimprovement, resulting in enhanced performances in all metrics. Subsequently,\nwe successfully applied our approach to track the growth behavior of iPAK4\nprotein fibers, revealing their two distinct growth phases consistent with a\npreviously reported kinetic model. This research showcases the promising\npotential of our approach, extending beyond iPAK4 fibers. It also offers a\nsignificant advancement in precise tracking of dynamic processes in live cells,\nand fostering new avenues for biomedical research.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:15:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17184","submitter":"Gururaj Wagle","authors":"Gururaj A. Wagle, Emmanouil Chatzopoulos, Ryan Wollaeger, Christopher\n  J. Fontes","title":"Monte Carlo Radiation Transport for Astrophysical Transients Powered by\n  Circumstellar Interaction","comments":"Accepted for publication at the Astrophysics Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we introduce \\texttt{SuperLite}, an open-source Monte Carlo\nradiation transport code designed to produce synthetic spectra for\nastrophysical transient phenomena affected by circumstellar interaction.\n\\texttt{SuperLite} utilizes Monte Carlo methods for semi-implicit,\nsemi-relativistic radiation transport in high-velocity shocked outflows,\nemploying multi-group structured opacity calculations. The code enables rapid\npost-processing of hydrodynamic profiles to generate high-quality spectra that\ncan be compared with observations of transient events, including superluminous\nsupernovae, pulsational pair-instability supernovae, and other peculiar\ntransients. We present the methods employed in \\texttt{SuperLite} and compare\nthe code's performance to that of other radiative transport codes, such as\n\\texttt{SuperNu} and CMFGEN. We show that \\texttt{SuperLite} has successfully\npassed standard Monte Carlo radiation transport tests and can reproduce spectra\nof typical supernovae of Type Ia, Type IIP and Type IIn.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:17:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17185","submitter":"Xinge Yang","authors":"Xinge Yang, Qiang Fu, Yunfeng Nie, Wolfgang Heidrich","title":"Image Quality Is Not All You Want: Task-Driven Lens Design for Image\n  Classification","comments":"Use an image classification network to supervise the lens design from\n  scratch. The final designs can achieve higher accuracy with fewer optical\n  elements","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.GR physics.optics","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In computer vision, it has long been taken for granted that high-quality\nimages obtained through well-designed camera lenses would lead to superior\nresults. However, we find that this common perception is not a\n\"one-size-fits-all\" solution for diverse computer vision tasks. We demonstrate\nthat task-driven and deep-learned simple optics can actually deliver better\nvisual task performance. The Task-Driven lens design approach, which relies\nsolely on a well-trained network model for supervision, is proven to be capable\nof designing lenses from scratch. Experimental results demonstrate the designed\nimage classification lens (``TaskLens'') exhibits higher accuracy compared to\nconventional imaging-driven lenses, even with fewer lens elements. Furthermore,\nwe show that our TaskLens is compatible with various network models while\nmaintaining enhanced classification accuracy. We propose that TaskLens holds\nsignificant potential, particularly when physical dimensions and cost are\nseverely constrained.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:20:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17186","submitter":"Sara Saghafi","authors":"Kourosh Nozari, Sara Saghafi and Fateme Aliyan","title":"Accretion onto a static spherically symmetric regular MOG dark compact\n  object","comments":"20 pages, 9 figures. Accepted for publication in Eur. Phys. J. C","journal-ref":"Eur. Phys. J. C, 83, 449 (2023)","doi":"10.1140/epjc/s10052-023-11620-w","report-no":null,"categories":"gr-qc astro-ph.HE hep-ph hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In astrophysics, the process of a massive body acquiring matter is referred\nto as accretion. The extraction of gravitational energy occurs as a result of\nthe infall. Since it converts gravitational energy into radiation, accretion\nonto dark compact objects, e.g. black holes, neutron stars, and white dwarfs is\nan extremely significant process in the astrophysical context. Accretion\nprocess is a fruitful way to explore the features of modified gravity (MOG)\ntheories by testing the behavior of their solutions associated with dark\ncompact objects. In this paper, we study the motion of electrically neutral and\ncharged particles moving in around a regular spherically symmetric MOG dark\ncompact object to explore their related innermost stable circular orbit (ISCO)\nand energy flux. Then, we turn to investigate the accretion of perfect fluid\nonto the regular spherically symmetric MOG dark compact object. We obtain\nanalytical expressions for four-velocity and proper energy density of the\naccreting fluid. We see that the MOG parameter increases the ISCO radius of\neither electrically neutral or charged test particles while it decreases the\ncorresponding energy flux. Moreover, the energy density and the radial\ncomponent of the four-velocity of the infalling fluid decrease by increasing\nthe MOG parameter near the central source.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:22:14 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17187","submitter":"Christopher Harshaw","authors":"Jessica Dai and Paula Gradu and Christopher Harshaw","title":"Clip-OGD: An Experimental Design for Adaptive Neyman Allocation in\n  Sequential Experiments","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  From clinical development of cancer therapies to investigations into partisan\nbias, adaptive sequential designs have become increasingly popular method for\ncausal inference, as they offer the possibility of improved precision over\ntheir non-adaptive counterparts. However, even in simple settings (e.g. two\ntreatments) the extent to which adaptive designs can improve precision is not\nsufficiently well understood. In this work, we study the problem of Adaptive\nNeyman Allocation in a design-based potential outcomes framework, where the\nexperimenter seeks to construct an adaptive design which is nearly as efficient\nas the optimal (but infeasible) non-adaptive Neyman design, which has access to\nall potential outcomes. Motivated by connections to online optimization, we\npropose Neyman Ratio and Neyman Regret as two (equivalent) performance measures\nof adaptive designs for this problem. We present Clip-OGD, an adaptive design\nwhich achieves $\\widetilde{O}(\\sqrt{T})$ expected Neyman regret and thereby\nrecovers the optimal Neyman variance in large samples. Finally, we construct a\nconservative variance estimator which facilitates the development of\nasymptotically valid confidence intervals. To complement our theoretical\nresults, we conduct simulations using data from a microeconomic experiment.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:22:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17188","submitter":"Bidya Binay Karak","authors":"Bidya Binay Karak","title":"Models for the long-term variations of solar activity","comments":"Invited review article for Living Reviews in Solar Physics, in press\n  (53 pages including 25 figures)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.IM physics.space-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One obvious feature of the solar cycle is its variation from one cycle to\nanother. In this article, we review the dynamo models for the long-term\nvariations of the solar cycle. By long-term variations, we mean the cycle\nmodulations beyond the 11-year periodicity and these include, the\nGnevyshev-Ohl/Even-Odd rule, grand minima, grand maxima, Gleissberg cycle, and\nSuess cycles. After a brief review of the observed data, we present the dynamo\nmodels for the solar cycle. By carefully analyzing the dynamo models and the\nobserved data, we identify the following broad causes for the modulation: (i)\nmagnetic feedback on the flow, (ii) stochastic forcing, and (iii) time delays\nin various processes of the dynamo. To demonstrate each of these causes, we\npresent the results from some illustrative models for the cycle modulations and\ndiscuss their strengths and weakness. We also discuss a few critical issues and\ntheir current trends. The article ends with a discussion of our current state\nof ignorance about comparing detailed features of the magnetic cycle and the\nlarge-scale velocity from the dynamo models with robust observations.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:26:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17189","submitter":"Hongyu Lu","authors":"Hongyu Lu, Kai Sun, Zi Yang Meng, and Bin-Bin Chen","title":"Ubiquitous nematic Dirac semimetal emerging from interacting quadratic\n  band touching system","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quadratic band touching (QBT) points are widely observed in 2D and 3D\nmaterials, including bilayer graphene and Luttinger semimetals, and attract\nsignificant attention from theory to experiment. However, even in its simplest\nform, the 2D checkerboard lattice QBT model, the phase diagram characterized by\ntemperature and interaction strength still remains unknown beyond the\nweak-coupling regime. Intense debates persist regarding the existence of\nvarious interaction-driven insulating states in this system [1-7]. To address\nthese uncertainties, we employ thermal tensor network simulations, specifically\nexponential tensor renormalization group [8], along with density matrix\nrenormalization group calculations. Our approach enables us to provide a\ncomprehensive finite-temperature phase diagram for this model and shed light on\nprevious ambiguities. Notably, our findings consistently reveal the emergence\nof a robust bond-nematic Dirac semimetal (BNDS) phase as an intermediate state\nbetween the nematic insulating state and other symmetry broken states. This\npreviously overlooked feature is found to be ubiquitous in interacting QBT\nsystems. We also discuss the implications of these results for experimental\nsystems such as bilayer graphene and iridate compounds.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:27:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17190","submitter":"Atli Kosson","authors":"Atli Kosson, Martin Jaggi","title":"Hardware-Efficient Transformer Training via Piecewise Affine Operations","comments":"16 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multiplications are responsible for most of the computational cost involved\nin neural network training and inference. Recent research has thus looked for\nways to reduce the cost associated with them. Inspired by Mogami (2020), we\nreplace multiplication with a cheap piecewise affine approximation that is\nachieved by adding the bit representation of the floating point numbers\ntogether as integers. We show that transformers can be trained with the\nresulting modified matrix multiplications on both vision and language tasks\nwith little to no performance impact, and without changes to the training\nhyperparameters. We further replace all non-linearities in the networks making\nthem fully and jointly piecewise affine in both inputs and weights. Finally, we\nshow that we can eliminate all multiplications in the entire training process,\nincluding operations in the forward pass, backward pass and optimizer update,\ndemonstrating the first successful training of modern neural network\narchitectures in a fully multiplication-free fashion.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:28:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17192","submitter":"Kyle Boone","authors":"Kyle Boone, Ben Wurster, Seth Thao, and Yu Hen Hu","title":"Live American Sign Language Letter Classification with Convolutional\n  Neural Networks","comments":"10 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.NE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This project is centered around building a neural network that is able to\nrecognize ASL letters in images, particularly within the scope of a live video\nfeed. Initial testing results came up short of expectations when both the\nconvolutional network and VGG16 transfer learning approaches failed to\ngeneralize in settings of different backgrounds. The use of a pre-trained hand\njoint detection model was then adopted with the produced joint locations being\nfed into a fully-connected neural network. The results of this approach\nexceeded those of prior methods and generalized well to a live video feed\napplication.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:29:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17193","submitter":"Ivan Robert Nabi","authors":"Ivan R. Nabi, Ben Cardoen, Ismail M. Khater, Guang Gao, Timothy H.\n  Wong, Ghassan Hamarneh","title":"AI-based analysis of super-resolution microscopy: Biological discovery\n  in the absence of ground truth","comments":"14 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.SC cs.AI cs.CV cs.LG physics.bio-ph q-bio.QM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The nanoscale resolution of super-resolution microscopy has now enabled the\nuse of fluorescent based molecular localization tools to study whole cell\nstructural biology. Machine learning based analysis of super-resolution data\noffers tremendous potential for discovery of new biology, that by definition is\nnot known and lacks ground truth. Herein, we describe the application of weakly\nsupervised learning paradigms to super-resolution microscopy and its potential\nto enable the accelerated exploration of the molecular architecture of\nsubcellular macromolecules and organelles.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:31:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17194","submitter":"Blake Jackson","authors":"Tucker J. Ervin, Blake Jackson","title":"Answering Two OPAC Problems Involving Banff Quivers","comments":"10 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In a post on the Open Problems in Algebraic Combinatorics (OPAC) blog, E.\nBucher and J. Machacek posed three open problems: OPAC-033, OPAC-034, and\nOPAC-035. These three problems deal with the relationships between three\ninfinite classes of quivers: the Banff, Louise, and $\\mathcal{P}$ quivers.\nOPAC-034 asks whether or not every Banff quiver can be verified to be Banff by\nonly considering sources and sinks, and OPAC-035 asks whether or not every\nBanff quiver is contained in the class $\\mathcal{P}$. We give an answer to both\nquestions, showing that every Banff quiver can be verified to be Banff by using\nsources and sinks, and therefore that every Banff quiver lives in the class\n$\\mathcal{P}$. We also make some progress on OPAC-033, showing a result similar\nto our result OPAC-034 for Louise quivers.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:33:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17195","submitter":"Kartik Chandra","authors":"Kartik Chandra, Tony Chen, Tzu-Mao Li, Jonathan Ragan-Kelley, Josh\n  Tenenbaum","title":"Inferring the Future by Imagining the Past","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.GR cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A single panel of a comic book can say a lot: it shows not only where\ncharacters currently are, but also where they came from, what their motivations\nare, and what might happen next. More generally, humans can often infer a\ncomplex sequence of past and future events from a *single snapshot image* of an\nintelligent agent.\n  Building on recent work in cognitive science, we offer a Monte Carlo\nalgorithm for making such inferences. Drawing a connection to Monte Carlo path\ntracing in computer graphics, we borrow ideas that help us dramatically improve\nupon prior work in sample efficiency. This allows us to scale to a wide variety\nof challenging inference problems with only a handful of samples. It also\nsuggests some degree of cognitive plausibility, and indeed we present human\nsubject studies showing that our algorithm matches human intuitions in a\nvariety of domains that previous methods could not scale to.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:38:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17196","submitter":"Agnieszka Lawrynowicz","authors":"Agnieszka Lawrynowicz","title":"A Knowledge Engineering Primer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The aim of this primer is to introduce the subject of knowledge engineering\nin a concise but synthetic way to develop the reader's intuition about the\narea.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:39:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17197","submitter":"Hongyin Luo","authors":"Jiaxin Ge, Hongyin Luo, Yoon Kim, James Glass","title":"Entailment as Robust Self-Learner","comments":"Accepted by ACL 2023 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Entailment has been recognized as an important metric for evaluating natural\nlanguage understanding (NLU) models, and recent studies have found that\nentailment pretraining benefits weakly supervised fine-tuning. In this work, we\ndesign a prompting strategy that formulates a number of different NLU tasks as\ncontextual entailment. This approach improves the zero-shot adaptation of\npretrained entailment models. Secondly, we notice that self-training\nentailment-based models with unlabeled data can significantly improve the\nadaptation performance on downstream tasks. To achieve more stable improvement,\nwe propose the Simple Pseudo-Label Editing (SimPLE) algorithm for better\npseudo-labeling quality in self-training. We also found that both pretrained\nentailment-based models and the self-trained models are robust against\nadversarial evaluation data. Experiments on binary and multi-class\nclassification tasks show that SimPLE leads to more robust self-training\nresults, indicating that the self-trained entailment models are more efficient\nand trustworthy than large language models on language understanding tasks.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:41:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17198","submitter":"Paul Barde","authors":"Paul Barde, Jakob Foerster, Derek Nowrouzezahrai, Amy Zhang","title":"A Model-Based Solution to the Offline Multi-Agent Reinforcement Learning\n  Coordination Problem","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Training multiple agents to coordinate is an important problem with\napplications in robotics, game theory, economics, and social sciences. However,\nmost existing Multi-Agent Reinforcement Learning (MARL) methods are online and\nthus impractical for real-world applications in which collecting new\ninteractions is costly or dangerous. While these algorithms should leverage\noffline data when available, doing so gives rise to the offline coordination\nproblem. Specifically, we identify and formalize the strategy agreement (SA)\nand the strategy fine-tuning (SFT) challenges, two coordination issues at which\ncurrent offline MARL algorithms fail. To address this setback, we propose a\nsimple model-based approach that generates synthetic interaction data and\nenables agents to converge on a strategy while fine-tuning their policies\naccordingly. Our resulting method, Model-based Offline Multi-Agent Proximal\nPolicy Optimization (MOMA-PPO), outperforms the prevalent learning methods in\nchallenging offline multi-agent MuJoCo tasks even under severe partial\nobservability and with learned world models.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:43:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17199","submitter":"Jorge Igor Jaber-Urquiza","authors":"Jorge Jaber-Urquiza and Angel Sanchez","title":"Interaction field strength between a scalar particle and two massless\n  vector bosons in presence of an external magnetic field","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this work we study the interaction strength among a neutral scalar boson\nand two massless vector bosons in presence of an external magnetic field. Based\non global symmetries, we build the general tensor structure amplitude\n$\\mathcal{M}^{\\mu\\nu}$, for the process $V^\\mu+V^\\nu\\longrightarrow\\phi$, in\nterms of the vector bosons polarization states. Then, we present a novel\nmethodology to compute the one-loop amplitude contributions for an homogeneous\nmagnetic field with arbitrary strength. With the obtained results, expressed in\nterms of integrals over Schwinger parameters, we explore its behavior in two\nregions, widely used in the literature, the strong and weak field strength\nregions. The methodology presented in this work can be employed to compute an\narbitrary process in presence of an external magnetic field where the initial\nand final states are neutral.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:48:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17200","submitter":"Taras Banakh","authors":"Taras Banakh, Tetiana Martyniuk, Magdalena Nowak, Filip Strobin","title":"A Controlled Hahn-Mazurkiewicz Theorem and its Applications","comments":"17 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.GN math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For a metric Peano continuum $X$, let $S_X$ be a Sierpi\\'nski function\nassigning to each $\\varepsilon>0$ the smallest cardinality of a cover of $X$ by\nconnected subsets of diameter $\\le \\varepsilon$. We prove that for any\nincreasing function $\\Omega:\\mathbb R_+\\to\\mathbb R_+$ with\n$(0,1]\\subseteq\\Omega[\\mathbb R_+]$ and $s:=\\sum_{n=1}^\\infty\nS_X(2^{-n})\\sum_{m=n}^\\infty\nS_X(2^{-m})\\,\\Omega^{-1}(\\min\\{1,2^{6-m}\\})<\\infty$ there exists a continuous\nsurjective function $f:[0,s]\\to X$ with continuity modulus $\\omega_f\\le\\Omega$.\nThis controlled version of the classical Hahn-Mazurkiewicz Theorem implies that\n$SDim(X)\\le HDim(X)\\le 2{\\cdot}SDim(X)$, where $SDim(X)=\\limsup_{\\varepsilon\\to\n0}\\frac{\\ln(S_X(\\varepsilon))}{\\ln(1/\\varepsilon)}$ is the $S$-dimension of\n$X$, and $HDim(X)=\\inf\\{\\alpha\\in (0,\\infty]:$ there is a~surjective\n$\\frac1\\alpha$-H\\\"older map $f:[0,1]\\to X\\}$ is the $H\\ddot older$ $dimension$\nof $X$.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:49:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17201","submitter":"Tong Zhou","authors":"Tong Zhou","title":"Improved Sales Forecasting using Trend and Seasonality Decomposition\n  with LightGBM","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Retail sales forecasting presents a significant challenge for large retailers\nsuch as Walmart and Amazon, due to the vast assortment of products,\ngeographical location heterogeneity, seasonality, and external factors\nincluding weather, local economic conditions, and geopolitical events. Various\nmethods have been employed to tackle this challenge, including traditional time\nseries models, machine learning models, and neural network mechanisms, but the\ndifficulty persists. Categorizing data into relevant groups has been shown to\nimprove sales forecast accuracy as time series from different categories may\nexhibit distinct patterns. In this paper, we propose a new measure to indicate\nthe unique impacts of the trend and seasonality components on a time series and\nsuggest grouping time series based on this measure. We apply this approach to\nWalmart sales data from 01/29/2011 to 05/22/2016 and generate sales forecasts\nfrom 05/23/2016 to 06/19/2016. Our experiments show that the proposed strategy\ncan achieve improved accuracy. Furthermore, we present a robust pipeline for\nconducting retail sales forecasting.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:49:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17202","submitter":"Antonios Anastasopoulos","authors":"Claytone Sikasote, Eunice Mukonde, Md Mahfuz Ibn Alam, Antonios\n  Anastasopoulos","title":"BIG-C: a Multimodal Multi-Purpose Dataset for Bemba","comments":"accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present BIG-C (Bemba Image Grounded Conversations), a large multimodal\ndataset for Bemba. While Bemba is the most populous language of Zambia, it\nexhibits a dearth of resources which render the development of language\ntechnologies or language processing research almost impossible. The dataset is\ncomprised of multi-turn dialogues between Bemba speakers based on images,\ntranscribed and translated into English. There are more than 92,000\nutterances/sentences, amounting to more than 180 hours of audio data with\ncorresponding transcriptions and English translations. We also provide\nbaselines on speech recognition (ASR), machine translation (MT) and speech\ntranslation (ST) tasks, and sketch out other potential future multimodal uses\nof our dataset. We hope that by making the dataset available to the research\ncommunity, this work will foster research and encourage collaboration across\nthe language, speech, and vision communities especially for languages outside\nthe \"traditionally\" used high-resourced ones. All data and code are publicly\navailable: https://github.com/csikasote/bigc.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:49:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17203","submitter":"Camillo De Lellis","authors":"Alberto Bressan and Camillo De Lellis","title":"A remark on the uniqueness of solutions to hyperbolic conservation laws","comments":"11 pages, 1 figure. arXiv admin note: text overlap with\n  arXiv:2305.10737","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Given a strictly hyperbolic $n\\times n$ system of conservation laws, it is\nwell known that there exists a unique Lipschitz semigroup of weak solutions,\ndefined on a domain of functions with small total variation, which are limits\nof vanishing viscosity approximations. Aim of this note is to prove that every\nweak solution taking values in the domain of the semigroup, and whose shocks\nsatisfy the Liu admissibility conditions, actually coincides with a semigroup\ntrajectory.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:52:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17204","submitter":"Alex Klotz","authors":"Alexander R. Klotz, Caleb J. Anderson","title":"Ropelength and writhe quantization of 12-crossing knots","comments":"6 figures, 10 pages, data files at https://doi.org/10.7910/DVN/6AXP61\n  Second version fixes typos in equations and references","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ropelength of a knot is the minimum length required to tie it.\nComputational upper bounds have previously been computed for every prime knot\nwith up to 11 crossings. Here, we present ropelength measurements for the 2176\nknots with 12 crossings, of which 1288 are alternating and 888 are\nnon-alternating. We report on the distribution of ropelengths within and\nbetween crossing numbers, as well as the space writhe of the tight knot\nconfigurations. It was previously established that tight alternating knots have\na ``quantized'' space writhe close to a multiple of 4/7. Our data supports this\nfor 12-crossing alternating knots and we find that non-alternating knots also\nshow evidence of writhe quantization, falling near integer or half-integer\nmultiples of 4/3, depending on the parity of the crossing number. Finally, we\nexamine correlations between geometric properties and topological invariants of\ntight knots, finding that the ropelength is positively correlated with\nhyperbolic volume and its correlates, and that the space writhe is positively\ncorrelated with the Rasmussen s invariant.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:53:05 GMT"},{"version":"v2","created":"Wed, 31 May 2023 00:36:49 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17205","submitter":"Atli Kosson","authors":"Atli Kosson, Dongyang Fan, Martin Jaggi","title":"Ghost Noise for Regularizing Deep Neural Networks","comments":"13 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Batch Normalization (BN) is widely used to stabilize the optimization process\nand improve the test performance of deep neural networks. The regularization\neffect of BN depends on the batch size and explicitly using smaller batch sizes\nwith Batch Normalization, a method known as Ghost Batch Normalization (GBN),\nhas been found to improve generalization in many settings. We investigate the\neffectiveness of GBN by disentangling the induced \"Ghost Noise\" from\nnormalization and quantitatively analyzing the distribution of noise as well as\nits impact on model performance. Inspired by our analysis, we propose a new\nregularization technique called Ghost Noise Injection (GNI) that imitates the\nnoise in GBN without incurring the detrimental train-test discrepancy effects\nof small batch training. We experimentally show that GNI can provide a greater\ngeneralization benefit than GBN. Ghost Noise Injection can also be beneficial\nin otherwise non-noisy settings such as layer-normalized networks, providing\nadditional evidence of the usefulness of Ghost Noise in Batch Normalization as\na regularizer.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:53:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17206","submitter":"Charles Manski","authors":"Charles F. Manski","title":"Using Limited Trial Evidence to Credibly Choose Treatment Dosage when\n  Efficacy and Adverse Effects Weakly Increase with Dose","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.EM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In medical treatment and elsewhere, it has become standard to base treatment\nintensity (dosage) on evidence in randomized trials. Yet it has been rare to\nstudy how outcomes vary with dosage. In trials to obtain drug approval, the\nnorm has been to specify some dose of a new drug and compare it with an\nestablished therapy or placebo. Design-based trial analysis views each trial\narm as qualitatively different, but it may be highly credible to assume that\nefficacy and adverse effects (AEs) weakly increase with dosage. Optimization of\npatient care requires joint attention to both, as well as to treatment cost.\nThis paper develops methodology to credibly use limited trial evidence to\nchoose dosage when efficacy and AEs weakly increase with dose. I suppose that\ndosage is an integer choice t in (0, 1, . . . , T), T being a specified maximum\ndose. I study dosage choice when trial evidence on outcomes is available for\nonly K dose levels, where K < T + 1. Then the population distribution of dose\nresponse is partially rather than point identified. The identification region\nis a convex polygon determined by linear equalities and inequalities. I\ncharacterize clinical and public-health decision making using the\nminimax-regret criterion. A simple analytical solution exists when T = 2 and\ncomputation is tractable when T is larger.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:58:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17207","submitter":"Yunhao Ge","authors":"Yunhao Ge, Jie Ren, Jiaping Zhao, Kaifeng Chen, Andrew Gallagher,\n  Laurent Itti, Balaji Lakshminarayanan","title":"Building One-class Detector for Anything: Open-vocabulary Zero-shot OOD\n  Detection Using Text-image Models","comments":"16 pages (including appendix and references), 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We focus on the challenge of out-of-distribution (OOD) detection in deep\nlearning models, a crucial aspect in ensuring reliability. Despite considerable\neffort, the problem remains significantly challenging in deep learning models\ndue to their propensity to output over-confident predictions for OOD inputs. We\npropose a novel one-class open-set OOD detector that leverages text-image\npre-trained models in a zero-shot fashion and incorporates various descriptions\nof in-domain and OOD. Our approach is designed to detect anything not in-domain\nand offers the flexibility to detect a wide variety of OOD, defined via fine-\nor coarse-grained labels, or even in natural language. We evaluate our approach\non challenging benchmarks including large-scale datasets containing\nfine-grained, semantically similar classes, distributionally shifted images,\nand multi-object images containing a mixture of in-domain and OOD objects. Our\nmethod shows superior performance over previous methods on all benchmarks. Code\nis available at https://github.com/gyhandy/One-Class-Anything\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:58:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17208","submitter":"Angeline Aguinaldo","authors":"Angeline Aguinaldo, Evan Patterson, James Fairbanks, Jaime Ruiz","title":"A Categorical Representation Language and Computational System for\n  Knowledge-Based Planning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LO math.CT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Classical planning representation languages based on first-order logic have\nbeen extensively used to model and solve planning problems, but they struggle\nto capture implicit preconditions and effects that arise in complex planning\nscenarios. To address this problem, we propose an alternative approach to\nrepresenting and transforming world states during planning. Based on the\ncategory-theoretic concepts of $\\mathsf{C}$-sets and double-pushout rewriting\n(DPO), our proposed representation can effectively handle structured knowledge\nabout world states that support domain abstractions at all levels. It\nformalizes the semantics of predicates according to a user-provided ontology\nand preserves the semantics when transitioning between world states. This\nmethod provides a formal semantics for using knowledge graphs and relational\ndatabases to model world states and updates in planning. In this paper, we\ncompare our category-theoretic representation with the classical planning\nrepresentation. We show that our proposed representation has advantages over\nthe classical representation in terms of handling implicit preconditions and\neffects, and provides a more structured framework in which to model and solve\nplanning problems.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:01:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17209","submitter":"Gavin Kerrigan","authors":"Gavin Kerrigan, Giosue Migliorini, Padhraic Smyth","title":"Functional Flow Matching","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we propose Functional Flow Matching (FFM), a function-space\ngenerative model that generalizes the recently-introduced Flow Matching model\nto operate directly in infinite-dimensional spaces. Our approach works by first\ndefining a path of probability measures that interpolates between a fixed\nGaussian measure and the data distribution, followed by learning a vector field\non the underlying space of functions that generates this path of measures. Our\nmethod does not rely on likelihoods or simulations, making it well-suited to\nthe function space setting. We provide both a theoretical framework for\nbuilding such models and an empirical evaluation of our techniques. We\ndemonstrate through experiments on synthetic and real-world benchmarks that our\nproposed FFM method outperforms several recently proposed function-space\ngenerative models.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:07:47 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17210","submitter":"Antoine Chambert-Loir","authors":"Antoine Chambert-Loir, Camille No\\^us","title":"Potentiel et rationalit\\'e","comments":"in French language","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nous \\'etendons aux courbes de genre arbitraire le th\\'eor\\`eme de\nrationalit\\'e de Cantor, lui-m\\^eme une extension de th\\'eor\\`emes de Borel,\nP\\'olya, Dwork, Bertrandias et Robinson. La d\\'emonstration s'effectue en deux\n\\'etapes. La premi\\`ere est un crit\\`ere d'alg\\'ebricit\\'e, d\\'emontr\\'e par\nune m\\'ethode d'approximation diophantienne. La seconde repose sur le\nth\\'eor\\`eme de l'indice de Hodge en th\\'eorie d'Arakelov.\n  --\n  We extend to algebraic curves of arbitrary genus the rationality theorem of\nCantor, itself an extension of theorems of Borel, P\\'olya, Dwork, Bertrandias\nand Robinson. The proof runs in two steps. The first step is an algebraicity\ncriterion, which is proved using a method of diophantine approximation. The\nsecond step relies on the Hodge index theorem in Arakelov geometry.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:07:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17211","submitter":"Congcong Wang","authors":"Congcong Wang","title":"Coping with low data availability for social media crisis message\n  categorisation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  During crisis situations, social media allows people to quickly share\ninformation, including messages requesting help. This can be valuable to\nemergency responders, who need to categorise and prioritise these messages\nbased on the type of assistance being requested. However, the high volume of\nmessages makes it difficult to filter and prioritise them without the use of\ncomputational techniques. Fully supervised filtering techniques for crisis\nmessage categorisation typically require a large amount of annotated training\ndata, but this can be difficult to obtain during an ongoing crisis and is\nexpensive in terms of time and labour to create.\n  This thesis focuses on addressing the challenge of low data availability when\ncategorising crisis messages for emergency response. It first presents domain\nadaptation as a solution for this problem, which involves learning a\ncategorisation model from annotated data from past crisis events (source\ndomain) and adapting it to categorise messages from an ongoing crisis event\n(target domain). In many-to-many adaptation, where the model is trained on\nmultiple past events and adapted to multiple ongoing events, a multi-task\nlearning approach is proposed using pre-trained language models. This approach\noutperforms baselines and an ensemble approach further improves performance...\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:08:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17212","submitter":"Atli Kosson","authors":"Atli Kosson, Bettina Messmer, Martin Jaggi","title":"Rotational Optimizers: Simple & Robust DNN Training","comments":"23 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The training dynamics of modern deep neural networks depend on complex\ninteractions between the learning rate, weight decay, initialization, and other\nhyperparameters. These interactions can give rise to Spherical Motion Dynamics\nin scale-invariant layers (e.g., normalized layers), which converge to an\nequilibrium state, where the weight norm and the expected rotational update\nsize are fixed. Our analysis of this equilibrium in AdamW, SGD with momentum,\nand Lion provides new insights into the effects of different hyperparameters\nand their interactions on the training process. We propose rotational variants\n(RVs) of these optimizers that force the expected angular update size to match\nthe equilibrium value throughout training. This simplifies the training\ndynamics by removing the transient phase corresponding to the convergence to an\nequilibrium. Our rotational optimizers can match the performance of the\noriginal variants, often with minimal or no tuning of the baseline\nhyperparameters, showing that these transient phases are not needed.\nFurthermore, we find that the rotational optimizers have a reduced need for\nlearning rate warmup and improve the optimization of poorly normalized\nnetworks.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:14:01 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17213","submitter":"Alexander Kuznetsov","authors":"Alexander Kuznetsov and Evgeny Shinder","title":"Derived categories of Fano threefolds and degenerations","comments":"40 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using the technique of categorical absorption of singularities we prove that\nthe nontrivial components of the derived categories of del Pezzo threefolds of\ndegree $d \\in \\{2,3,4,5\\}$ and crepant categorical resolutions of the\nnontrivial components of the derived categories of nodal del Pezzo threefolds\nof degree $d = 1$ can be smoothly deformed to the nontrivial components of the\nderived categories of prime Fano threefolds of genus $g = 2d + 2 \\in\n\\{4,6,8,10,12\\}$. This corrects and proves the Fano threefolds conjecture of\nthe first author from [Kuz09], and opens a way to interesting geometric\napplications, including a relation between the intermediate Jacobians and\nHilbert schemes of curves of the above threefolds. We also describe a\ncompactification of the moduli stack of prime Fano threefolds endowed with an\nappropriate exceptional bundle and its boundary component that corresponds to\ndegenerations associated with del Pezzo threefolds.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:14:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17214","submitter":"Mingxiao Li","authors":"Jingyuan Sun, Mingxiao Li, Zijiao Chen, Yunhao Zhang, Shaonan Wang,\n  Marie-Francine Moens","title":"Contrast, Attend and Diffuse to Decode High-Resolution Images from Brain\n  Activities","comments":"17 pages, 6 figures, conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Decoding visual stimuli from neural responses recorded by functional Magnetic\nResonance Imaging (fMRI) presents an intriguing intersection between cognitive\nneuroscience and machine learning, promising advancements in understanding\nhuman visual perception and building non-invasive brain-machine interfaces.\nHowever, the task is challenging due to the noisy nature of fMRI signals and\nthe intricate pattern of brain visual representations. To mitigate these\nchallenges, we introduce a two-phase fMRI representation learning framework.\nThe first phase pre-trains an fMRI feature learner with a proposed\nDouble-contrastive Mask Auto-encoder to learn denoised representations. The\nsecond phase tunes the feature learner to attend to neural activation patterns\nmost informative for visual reconstruction with guidance from an image\nauto-encoder. The optimized fMRI feature learner then conditions a latent\ndiffusion model to reconstruct image stimuli from brain activities.\nExperimental results demonstrate our model's superiority in generating\nhigh-resolution and semantically accurate images, substantially exceeding\nprevious state-of-the-art methods by 39.34% in the 50-way-top-1 semantic\nclassification accuracy. Our research invites further exploration of the\ndecoding task's potential and contributes to the development of non-invasive\nbrain-machine interfaces.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:16:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17215","submitter":"Swagata Acharya","authors":"Swagata Acharya, Dimitar Pashov, Mikhail I Katsnelson, and Mark van\n  Schilfgaarde","title":"One-particle and excitonic band structure in cubic Boron Arsenide","comments":"4 pages, 2 figures","journal-ref":"Physica Status Solidi, Rapid Research Letters (2023)","doi":"10.1002/pssr.202300156","report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Cubic BAs has received recent attention for its large electron and hole\nmobilities and large thermal conductivity. This is a rare and much desired\ncombination in semiconductor industry: commercial semiconductors typically have\nhigh electron mobilities, or hole mobilities, or large thermal conductivities,\nbut not all of them together. Here we report predictions from an advanced\nself-consistent many body perturbative theory and show that with respect to\none-particle properties, BAs is strikingly similar to Si. There are some\nimportant differences, notably there is an unusually small variation in the\nvalence band masses . With respect to two-particle properties, significant\ndifferences with Si appear. We report the excitonic spectrum for both q=0 and\nfinite q, and show that while the direct gap in cubic BAs is about 4 eV, dark\nexcitons can be observed down to about $\\sim$1.5 eV, which may play a crucial\nrole in application of BAs in optoelectronics.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:21:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17216","submitter":"Jing Yu Koh","authors":"Jing Yu Koh, Daniel Fried, Ruslan Salakhutdinov","title":"Generating Images with Multimodal Language Models","comments":"Project page: http://jykoh.com/gill","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a method to fuse frozen text-only large language models (LLMs)\nwith pre-trained image encoder and decoder models, by mapping between their\nembedding spaces. Our model demonstrates a wide suite of multimodal\ncapabilities: image retrieval, novel image generation, and multimodal dialogue.\nOurs is the first approach capable of conditioning on arbitrarily interleaved\nimage and text inputs to generate coherent image (and text) outputs. To achieve\nstrong performance on image generation, we propose an efficient mapping network\nto ground the LLM to an off-the-shelf text-to-image generation model. This\nmapping network translates hidden representations of text into the embedding\nspace of the visual models, enabling us to leverage the strong text\nrepresentations of the LLM for visual outputs. Our approach outperforms\nbaseline generation models on tasks with longer and more complex language. In\naddition to novel image generation, our model is also capable of image\nretrieval from a prespecified dataset, and decides whether to retrieve or\ngenerate at inference time. This is done with a learnt decision module which\nconditions on the hidden representations of the LLM. Our model exhibits a wider\nrange of capabilities compared to prior multimodal language models. It can\nprocess image-and-text inputs, and produce retrieved images, generated images,\nand generated text -- outperforming non-LLM based generation models across\nseveral text-to-image tasks that measure context dependence.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:22:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17217","submitter":"Karishma Patnaik","authors":"Karishma Patnaik, Aravind Adhith Pandian Saravanakumaran and Wenlong\n  Zhang","title":"To Collide or Not To Collide -- Exploiting Passive Deformable Quadrotors\n  for Contact-Rich Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With an increase in aerial vehicle applications, passive deformable\nquadrotors are getting significant attention in the research community due to\ntheir potential to perform physical interaction tasks. Such quadrotors are\ncapable of undergoing collisions, both planned and unplanned, which are\nharnessed to induce deformation and retain stability by dissipating collision\nenergies. In this article, we utilize one such passive deforming quadrotor,\nXPLORER, to complete various contact-rich tasks by exploiting its compliant\nchassis via various impact-aware planning and control algorithms. At the core\nof these algorithms is a novel external wrench estimation technique developed\nspecifically for the unique multi-linked structure of XPLORER's chassis. The\nexternal wrench information is then employed for designing interaction\ncontrollers to obtain three additional flight modes: static-wrench application,\ndisturbance rejection and yielding to the disturbance. These modes are then\nincorporated into a novel online exploration scheme to enable navigation in\nunknown flight spaces with only tactile feedback and generate a map of the\nenvironment without requiring additional sensors. Experiments show the efficacy\nof this scheme to generate maps of the previously unexplored flight space with\nan accuracy of 96.72%. Finally, we develop a novel collision-aware trajectory\nplanner (CATAAN) to generate minimum time maneuvers for waypoint tracking by\nintegrating collision-induced state jumps for both elastic and inelastic cases.\nWe experimentally validate that minimum time trajectories can be obtained with\nCATAAN leading to a 40.38% reduction of settling time accompanied by improved\ntracking performance of a root mean squared error in position within 0.5cm as\ncompared to 3cm of conventional methods.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:22:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17218","submitter":"Lucius Meredith","authors":"Lucius Gregory Meredith, Ben Goertzel, Jonathan Warrell, and Adam\n  Vandervorst","title":"Meta-MeTTa: an operational semantics for MeTTa","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present an operational semantics for the language MeTTa.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:23:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17219","submitter":"Fnu Mohbat","authors":"Fnu Mohbat, Mohammed J. Zaki, Catherine Finegan-Dollak, Ashish Verma","title":"GVdoc: Graph-based Visual Document Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The robustness of a model for real-world deployment is decided by how well it\nperforms on unseen data and distinguishes between in-domain and out-of-domain\nsamples. Visual document classifiers have shown impressive performance on\nin-distribution test sets. However, they tend to have a hard time correctly\nclassifying and differentiating out-of-distribution examples. Image-based\nclassifiers lack the text component, whereas multi-modality transformer-based\nmodels face the token serialization problem in visual documents due to their\ndiverse layouts. They also require a lot of computing power during inference,\nmaking them impractical for many real-world applications. We propose, GVdoc, a\ngraph-based document classification model that addresses both of these\nchallenges. Our approach generates a document graph based on its layout, and\nthen trains a graph neural network to learn node and graph embeddings. Through\nexperiments, we show that our model, even with fewer parameters, outperforms\nstate-of-the-art models on out-of-distribution data while retaining comparable\nperformance on the in-distribution test set.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:23:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17220","submitter":"Bowen Li","authors":"Bowen Li, Jiashun Wang, Yaoyu Hu, Chen Wang, Sebastian Scherer","title":"VoxDet: Voxel Learning for Novel Instance Detection","comments":"17 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Detecting unseen instances based on multi-view templates is a challenging\nproblem due to its open-world nature. Traditional methodologies, which\nprimarily rely on 2D representations and matching techniques, are often\ninadequate in handling pose variations and occlusions. To solve this, we\nintroduce VoxDet, a pioneer 3D geometry-aware framework that fully utilizes the\nstrong 3D voxel representation and reliable voxel matching mechanism. VoxDet\nfirst ingeniously proposes template voxel aggregation (TVA) module, effectively\ntransforming multi-view 2D images into 3D voxel features. By leveraging\nassociated camera poses, these features are aggregated into a compact 3D\ntemplate voxel. In novel instance detection, this voxel representation\ndemonstrates heightened resilience to occlusion and pose variations. We also\ndiscover that a 3D reconstruction objective helps to pre-train the 2D-3D\nmapping in TVA. Second, to quickly align with the template voxel, VoxDet\nincorporates a Query Voxel Matching (QVM) module. The 2D queries are first\nconverted into their voxel representation with the learned 2D-3D mapping. We\nfind that since the 3D voxel representations encode the geometry, we can first\nestimate the relative rotation and then compare the aligned voxels, leading to\nimproved accuracy and efficiency. Exhaustive experiments are conducted on the\ndemanding LineMod-Occlusion, YCB-video, and the newly built RoboTools\nbenchmarks, where VoxDet outperforms various 2D baselines remarkably with 20%\nhigher recall and faster speed. To the best of our knowledge, VoxDet is the\nfirst to incorporate implicit 3D knowledge for 2D detection tasks.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:25:13 GMT"},{"version":"v2","created":"Tue, 30 May 2023 17:10:58 GMT"},{"version":"v3","created":"Sun, 4 Jun 2023 14:22:17 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17221","submitter":"Tianshu Zhang","authors":"Tianshu Zhang, Changchang Liu, Wei-Han Lee, Yu Su, Huan Sun","title":"Federated Learning for Semantic Parsing: Task Formulation, Evaluation\n  Setup, New Algorithms","comments":"ACL 2023 long paper","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.DB cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies a new task of federated learning (FL) for semantic\nparsing, where multiple clients collaboratively train one global model without\nsharing their semantic parsing data. By leveraging data from multiple clients,\nthe FL paradigm can be especially beneficial for clients that have little\ntraining data to develop a data-hungry neural semantic parser on their own. We\npropose an evaluation setup to study this task, where we re-purpose widely-used\nsingle-domain text-to-SQL datasets as clients to form a realistic heterogeneous\nFL setting and collaboratively train a global model. As standard FL algorithms\nsuffer from the high client heterogeneity in our realistic setup, we further\npropose a novel LOss Reduction Adjusted Re-weighting (Lorar) mechanism to\nmitigate the performance degradation, which adjusts each client's contribution\nto the global model update based on its training loss reduction during each\nround. Our intuition is that the larger the loss reduction, the further away\nthe current global model is from the client's local optimum, and the larger\nweight the client should get. By applying Lorar to three widely adopted FL\nalgorithms (FedAvg, FedOPT and FedProx), we observe that their performance can\nbe improved substantially on average (4%-20% absolute gain under MacroAvg) and\nthat clients with smaller datasets enjoy larger performance gains. In addition,\nthe global model converges faster for almost all the clients.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:25:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17222","submitter":"Midhul Vuppalapati","authors":"Midhul Vuppalapati, Giannis Fikioris, Rachit Agarwal, Asaf Cidon,\n  Anurag Khandelwal, Eva Tardos","title":"Karma: Resource Allocation for Dynamic Demands","comments":"Accepted for publication in USENIX OSDI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.OS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The classical max-min fairness algorithm for resource allocation provides\nmany desirable properties, e.g., Pareto efficiency, strategy-proofness and\nfairness. This paper builds upon the observation that max-min fairness\nguarantees these properties under a strong assumption -- user demands being\nstatic over time -- and that, for the realistic case of dynamic user demands,\nmax-min fairness loses one or more of these properties.\n  We present Karma, a generalization of max-min fairness for dynamic user\ndemands. The key insight in Karma is to introduce \"memory\" into max-min\nfairness -- when allocating resources, Karma takes users' past allocations into\naccount: in each quantum, users donate their unused resources and are assigned\ncredits when other users borrow these resources; Karma carefully orchestrates\nexchange of credits across users (based on their instantaneous demands, donated\nresources and borrowed resources), and performs prioritized resource allocation\nbased on users' credits. We prove theoretically that Karma guarantees Pareto\nefficiency, online strategy-proofness, and optimal fairness for dynamic user\ndemands (without future knowledge of user demands). Empirical evaluations over\nproduction workloads show that these properties translate well into practice:\nKarma is able to reduce disparity in performance across users to a bare minimum\nwhile maintaining Pareto-optimal system-wide performance.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:30:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17223","submitter":"Youngeun Kim","authors":"Youngeun Kim, Yuhang Li, Abhishek Moitra, Priyadarshini Panda","title":"Do We Really Need a Large Number of Visual Prompts?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Due to increasing interest in adapting models on resource-constrained edges,\nparameter-efficient transfer learning has been widely explored. Among various\nmethods, Visual Prompt Tuning (VPT), prepending learnable prompts to input\nspace, shows competitive fine-tuning performance compared to training of full\nnetwork parameters. However, VPT increases the number of input tokens,\nresulting in additional computational overhead. In this paper, we analyze the\nimpact of the number of prompts on fine-tuning performance and self-attention\noperation in a vision transformer architecture. Through theoretical and\nempirical analysis we show that adding more prompts does not lead to linear\nperformance improvement. Further, we propose a Prompt Condensation (PC)\ntechnique that aims to prevent performance degradation from using a small\nnumber of prompts. We validate our methods on FGVC and VTAB-1k tasks and show\nthat our approach reduces the number of prompts by ~70% while maintaining\naccuracy.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:31:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17224","submitter":"Jialun Zhang","authors":"Gavin Zhang, Hong-Ming Chiu, Richard Y. Zhang","title":"Fast and Minimax Optimal Estimation of Low-Rank Matrices via Non-Convex\n  Gradient Descent","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the problem of estimating a low-rank matrix from noisy measurements,\nwith the specific goal of achieving minimax optimal error. In practice, the\nproblem is commonly solved using non-convex gradient descent, due to its\nability to scale to large-scale real-world datasets. In theory, non-convex\ngradient descent is capable of achieving minimax error. But in practice, it\noften converges extremely slowly, such that it cannot even deliver estimations\nof modest accuracy within reasonable time. On the other hand, methods that\nimprove the convergence of non-convex gradient descent, through rescaling or\npreconditioning, also greatly amplify the measurement noise, resulting in\nestimations that are orders of magnitude less accurate than what is\ntheoretically achievable with minimax optimal error. In this paper, we propose\na slight modification to the usual non-convex gradient descent method that\nremedies the issue of slow convergence, while provably preserving its minimax\noptimality. Our proposed algorithm has essentially the same per-iteration cost\nas non-convex gradient descent, but is guaranteed to converge to minimax error\nat a linear rate that is immune to ill-conditioning. Using our proposed\nalgorithm, we reconstruct a 60 megapixel dataset for a medical imaging\napplication, and observe significantly decreased reconstruction error compared\nto previous approaches.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:32:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17225","submitter":"Wendong Liang","authors":"Wendong Liang, Armin Keki\\'c, Julius von K\\\"ugelgen, Simon Buchholz,\n  Michel Besserve, Luigi Gresele, Bernhard Sch\\\"olkopf","title":"Causal Component Analysis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Independent Component Analysis (ICA) aims to recover independent latent\nvariables from observed mixtures thereof. Causal Representation Learning (CRL)\naims instead to infer causally related (thus often statistically dependent)\nlatent variables, together with the unknown graph encoding their causal\nrelationships. We introduce an intermediate problem termed Causal Component\nAnalysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the\ncausal dependence among the latent components, and as a special case of CRL. In\ncontrast to CRL, it presupposes knowledge of the causal graph, focusing solely\non learning the unmixing function and the causal mechanisms. Any impossibility\nresults regarding the recovery of the ground truth in CauCA also apply for CRL,\nwhile possibility results may serve as a stepping stone for extensions to CRL.\nWe characterize CauCA identifiability from multiple datasets generated through\ndifferent types of interventions on the latent causal variables. As a\ncorollary, this interventional perspective also leads to new identifiability\nresults for nonlinear ICA -- a special case of CauCA with an empty graph --\nrequiring strictly fewer datasets than previous results. We introduce a\nlikelihood-based approach using normalizing flows to estimate both the unmixing\nfunction and the causal mechanisms, and demonstrate its effectiveness through\nextensive synthetic experiments in the CauCA and ICA setting.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:34:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17226","submitter":"Aymen Laadhari Dr","authors":"Aymen Laadhari and Ahmad Deeb","title":"A Finite Element Approach For Modeling Biomembranes In Incompressible\n  Power-Law Flow","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GM","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We present a numerical method to model the dynamics of inextensible\nbiomembranes in a quasi-Newtonian incompressible flow, which better describes\nhemorheology in the small vasculature. We consider a level set model for the\nfluid-membrane coupling, while the local inextensibility condition is relaxed\nby introducing a penalty term. The penalty method is straightforward to\nimplement from any Navier-Stokes/level set solver and allows substantial\ncomputational savings over a mixed formulation. A standard Galerkin finite\nelement framework is used with an arbitrarily high order polynomial\napproximation for better accuracy in computing the bending force. The PDE\nsystem is solved using a partitioned strongly coupled scheme based on\nCrank-Nicolson time integration. Numerical experiments are provided to validate\nand assess the main features of the method.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:35:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17227","submitter":"Peter Bl\\\"umler","authors":"Peter Bl\\\"umler and Helmut Soltner","title":"Halbach Magnets for Magnetic Resonance","comments":"37 pages, 17 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This review is a compilation of relevant concepts in designing Halbach\nmultipoles for magnetic resonance applications. The main focus is on providing\npractical guidelines to plan, design and build such magnets. Therefore,\nanalytical equations are presented for estimating the magnetic field from ideal\nto realistic systems. Various strategies of homogenizing magnetic fields are\ndiscussed together with concepts of opening such magnets without force, or\ncombining them for variable fields. Temperature compensation and other\npractical aspects are also reviewed. For magnetic resonance two polarities (di-\nand quadrupole) are of main interest, but higher polarities are also included.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:38:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17228","submitter":"Siddharth Gandhi","authors":"Siddharth Gandhi, Aurora Kesseli, Yapeng Zhang, Amy Louca, Ignas\n  Snellen, Matteo Brogi, Yamila Miguel, N\\'uria Casasayas-Barris, Stefan\n  Pelletier, Rico Landman, Cathal Maguire, Neale P. Gibson","title":"Retrieval survey of metals in six ultra-hot Jupiters: Trends in\n  chemistry, rain-out, ionisation and atmospheric dynamics","comments":"26 pages, 11 figures, 5 tables, published in AJ","journal-ref":"The Astronomical Journal, Volume 165, 242 (2023)","doi":"10.3847/1538-3881/accd65","report-no":null,"categories":"astro-ph.EP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Ground-based high-resolution spectroscopy (HRS) has detected numerous\nchemical species and atmospheric dynamics in exoplanets, most notably ultra-hot\nJupiters (UHJs). However, quantitative estimates on abundances have been\nchallenging but are essential for accurate comparative characterisation and to\ndetermine formation scenarios. In this work we retrieve the atmospheres of six\nUHJs (WASP-76~b, MASCARA-4~b, MASCARA-2~b, WASP-121~b, HAT-P-70~b and\nWASP-189~b) with ESPRESSO and HARPS-N/HARPS observations, exploring trends in\neleven neutral species and dynamics. While Fe abundances agree well with\nstellar values, Mg, Ni, Cr, Mn and V show more variation, highlighting the\ndifficulty in using a single species as a proxy for metallicity. We find that\nCa, Na, Ti and TiO are under-abundant, potentially due to ionisation and/or\nnight-side rain-out. Our retrievals also show that relative abundances between\nspecies are more robust, consistent with previous works. We perform spatially-\nand phase-resolved retrievals for WASP-76~b and WASP-121~b given their high\nsignal-to-noise observations, and find the chemical abundances in each of the\nterminator regions are broadly consistent. We additionally constrain dynamics\nfor our sample through Doppler shifts and broadening of the planetary signals\nduring the primary eclipse, with median blue shifts between $\\sim$0.9-9.0~km/s\ndue to day-night winds. Furthermore, we constrain spectroscopic masses for\nMASCARA-2~b and HAT-P-70~b consistent with their known upper limits, but we\nnote that these may be biased due to degeneracies. This work highlights the\nimportance of future HRS studies to further probe differences and trends\nbetween exoplanets.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:40:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17229","submitter":"Suman Jyoti De","authors":"Suman Jyoti De, Udit Khanna, Sumathi Rao, Sourin Das","title":"Boost driven transition in the superconductivity proximitized edge of a\n  quantum spin Hall insulator","comments":"6 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate the effects of introducing a boost (a Zeeman field parallel to\nthe spin quantization axis) at the proximitized helical edge of a\ntwo-dimensional (2D) quantum spin Hall insulator. Our self-consistent analysis\nfinds that a Fulde-Ferrell-Larkin-Ovchinnikov (FFLO) superconducting phase may\nemerge at the edge when the boost is larger than a critical value tied to the\ninduced pairing gap. A non-trivial consequence of retaining the 2D bulk in the\nmodel is that this boundary FFLO state supports a finite magnetization as well\nas finite current (flowing along the edge). This has implications for a proper\ntreatment of the ultra-violet cutoff in analyses employing the effective\none-dimensional (1D) helical edge model. Our results may be contrasted with\nprevious studies of such 1D models, which found that the FFLO phase either does\nnot appear for any value of the boost (in non-self-consistent calculations), or\nthat it self-consistently appears even for infinitesimal boost, but carries no\ncurrent and magnetization.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:41:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17230","submitter":"Mohammad Noaman","authors":"Mohammad Noaman, Donald W. Booth and James P. Shaffer","title":"Rydberg Atom Sensors in Multichromatic Radio Frequency Fields","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.atom-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Rydberg atom-based sensors are a new type of radio frequency sensor that is\ninherently quantum mechanical. Several configurations of the sensor use a local\noscillator to determine the properties of the target radio frequency field. We\nexplain how the physics of Rydberg atom-based sensors in two or more radio\nfrequency fields can be precisely described by a multiply dressed\nJaynes-Cummings model. Studying Rydberg atom-based sensors in two or more near\nresonant radio frequency fields is important for understanding how interfering\nsignals as well as the local oscillator can affect measurements. Studies, so\nfar, focus on a simplified approximation for the local oscillator-target field\ninteraction that uses an analogy to radio frequency heterodyning. The atom acts\nas a medium for exchanging electromagnetic field excitations of the field modes\nwhose spectrum is a ladder. The Jaynes-Cummings states and their avoided\ncrossings can be used to determine the properties of the radio frequency\nfields. Radio frequency field sensitivity enhancement for non-resonant radio\nfrequencies is achieved and self-calibrated measurements are recovered under\nspecific conditions described by the theory.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:41:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17231","submitter":"Gregoire Misguich","authors":"J\\'er\\^ome Houdayer, Haggai Landa and Gr\\'egoire Misguich","title":"A solvable model for graph state decoherence dynamics","comments":"14 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.other","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present an exactly solvable toy model for the continuous dissipative\ndynamics of permutation-invariant graph states of N qubits. Such states are\nlocally equivalent to an N-qubit Greenberger-Horne-Zeilinger (GHZ) state, a\nfundamental resource in many quantum information processing setups. We focus on\nthe time evolution of the state governed by a Lindblad master equation with the\nthree standard single-qubit jump operators, the Hamiltonian part being set to\nzero. Deriving analytic expressions for the expectation values of observables\nexpanded in the Pauli basis at all times, we analyze the nontrivial\nintermediate-time dynamics. Using a numerical solver based on matrix product\noperators we simulate the time evolution for systems with up to 64 qubits and\nverify a numerically exact agreement with the analytical results. We find that\nthe evolution of the operator space entanglement entropy of a bipartition of\nthe system manifests a plateau whose duration increases logarithmically with\nthe number of qubits, whereas all Pauli-operator products have expectation\nvalues decaying at most in constant time.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:43:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17232","submitter":"Klaus Ziegler","authors":"Klaus Ziegler","title":"Quantum evolution with random phase scattering","comments":"10 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.dis-nn quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the quantum evolution of a fermion-hole pair in a d-dimensional\ngas of non-interacting fermions in the presence of random phase scattering.\nThis system is mapped onto an effective Ising model, which enables us to show\nrigorously that the probability of recombining the fermion and the hole decays\nexponentially with the distance of their initial spatial separation. In the\nabsence of random phase scattering the recombination probability decays like a\npower law, which is reflected by an infinite mean square displacement. The\neffective Ising model is studied within a saddle point approximation and yields\na finite mean square displacement that depends on the evolution time and on the\nspectral properties of the deterministic part of the evolution operator.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:44:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17233","submitter":"Milko Estrada","authors":"Milko Estrada and Rodrigo Aros","title":"A new class of regular Black Holes in Einstein Gauss Bonnet gravity with\n  localized sources of matter","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We provide a new regular black hole solution (RBH) in Einstein Gauss Bonnet\n(EGB) gravity with presence of localized sources of matter in the energy\nmomentum tensor. We determinate the necessary constraints in order that the\nsolution to be regular. Although we use a specific form for the energy density\nas test of prove, these constraints could serve as a recipe for constructing\nseveral new RBH solutions in EGB gravity with localized sourced. Due that the\nusual first law of thermodynamics is not valid for RBH, we rewrite the first\nlaw for EGB, which leads to correct values of entropy and volume. The size of\nthe extremal black hole, whose temperature vanishes, becomes smaller for larger\ndimensions, whose radius could be of order of the Planck units, thus the\nevaporation would stop once the horizon radius contracts up to a value close to\nthe Planck length, which could be related with the apparition of quantum\neffects. Furthermore, the presence of matter fields in the energy momentum\ntensor induces two phase transitions, where there are two regions of stability.\nThis differs from the vacuum EGB solution, where the specific heat is always\nnegative without phase transition as occurs in Schwarzschild black hole.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:44:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17234","submitter":"Majed Alotaibi","authors":"M. O. D. Alotaibi, L. Al Sakkaf, U. Al Khawaja","title":"Unidirectional flow of flat-top solitons","comments":"5 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nlin.PS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We numerically demonstrate the unidirectional flow of flat-top solitons when\ninteracting with two reflectionless potential wells with slightly different\ndepths. The system is described by a nonlinear Schr\\\"{o}dinger equation with\ndual nonlinearity. The results show that for shallow potential wells, the\nvelocity window for unidirectional flow is larger than for deeper potential\nwells. A wider flat-top solitons also have a narrow velocity window for\nunidirectional flow than those for thinner flat-top solitons.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:46:34 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 10:17:20 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17235","submitter":"Jinqi Xiao","authors":"Jinqi Xiao, Miao Yin, Yu Gong, Xiao Zang, Jian Ren, Bo Yuan","title":"COMCAT: Towards Efficient Compression and Customization of\n  Attention-Based Vision Models","comments":"ICML 2023 Poster","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Attention-based vision models, such as Vision Transformer (ViT) and its\nvariants, have shown promising performance in various computer vision tasks.\nHowever, these emerging architectures suffer from large model sizes and high\ncomputational costs, calling for efficient model compression solutions. To\ndate, pruning ViTs has been well studied, while other compression strategies\nthat have been widely applied in CNN compression, e.g., model factorization, is\nlittle explored in the context of ViT compression. This paper explores an\nefficient method for compressing vision transformers to enrich the toolset for\nobtaining compact attention-based vision models. Based on the new insight on\nthe multi-head attention layer, we develop a highly efficient ViT compression\nsolution, which outperforms the state-of-the-art pruning methods. For\ncompressing DeiT-small and DeiT-base models on ImageNet, our proposed approach\ncan achieve 0.45% and 0.76% higher top-1 accuracy even with fewer parameters.\nOur finding can also be applied to improve the customization efficiency of\ntext-to-image diffusion models, with much faster training (up to $2.6\\times$\nspeedup) and lower extra storage cost (up to $1927.5\\times$ reduction) than the\nexisting works.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:50:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17236","submitter":"Maxime Ramzi","authors":"Maxime Ramzi","title":"Separability in homotopical algebra","comments":"89 pages; Comments very welcome !","journal-ref":null,"doi":null,"report-no":"CPH-GEOTOP-DNRF151","categories":"math.AT math.KT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the notion of \\emph{separable algebras} in the context of symmetric\nmonoidal stable $\\infty$-categories. In the first part of this paper, we\ncompare this context to that of tensor-triangulated categories and show that\nseparable algebras and their modules in a symmetric monoidal stable\n$\\infty$-category are, in large parts, controlled by the (tensor-triangulated)\nhomotopy category. We also study a variant of this notion, which we call\nind-separability. Among other things, this provides a partially new proof of\nthe Goerss--Hopkins--Miller theorem about the uniqueness of $\\mathbb\nE_\\infty$-structures on Morava $E$-theory.\n  We later initiate a study of separable algebras \\textit{\\`a la}\nAuslander-Goldman by relating them to Azumaya algebras, and prove in some\nrestrictive cases that centers of separable algebras are separable. Finally, we\nstudy the Hochschild homology of separable algebras and prove some descent\nresults in topological Hochschild homology.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:51:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17237","submitter":"Sara Saghafi","authors":"Kourosh Nozari, Sara Saghafi","title":"Asymptotically locally flat and AdS higher-dimensional black holes of\n  Einstein-Horndeski-Maxwell gravity in the light of EHT observations: shadow\n  behavior and deflection angle","comments":"31 pages, 14 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.HE hep-ph hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Unification of gravity with other interactions, achieving the ultimate\nframework of quantum gravity, and fundamental problems in particle physics and\ncosmology motivate to consider extra spatial dimensions. The impact of these\nextra dimensions on the modified theories of gravity has attracted a lot of\nattention. One way to examine how extra dimensions affect the modified\ngravitational theories is to analytically investigate astrophysical phenomena,\nsuch as black hole shadows. In this study, we aim to investigate the behavior\nof the shadow shapes of higher-dimensional charged black hole solutions\nincluding asymptotically locally flat (ALF) and asymptotically locally AdS\n(ALAdS) in Einstein-Horndeski-Maxwell (EHM) gravitational theory. We utilize\nthe Hamilton-Jacobi method to find photon orbits around these black holes as\nwell as the Carter approach to formulate the geodesic equations. We examine how\nextra dimensions, negative cosmological constant, electric charge, and coupling\nconstants of the EHM gravity affect the shadow size of the black hole. Then, we\nconstrain these parameters by comparing the shadow radius of these black holes\nwith the shadow size of M87* supermassive black hole captured by the Event\nHorizon Telescope (EHT) collaborations. We discover that generally the presence\nof extra dimensions within the EHM gravity results in reducing the shadow size\nof higher-dimensional ALF and ALAdS charged black holes, whereas the impact of\nelectric charge on the shadow of these black holes is suppressible....\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:51:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17238","submitter":"Stefano Dell'Oro","authors":"R. Cerroni, S. Dell'Oro, A. Formicola, S. Ghislandi, L. Ioannucci, M.\n  Laubenstein, B. Lehnert, S.S. Nagorny, S. Nisi, L. Pagnanini","title":"Deep-underground search for the decay of 180m-Ta with an\n  ultra-low-background HPGe detector","comments":"8 pages, 7 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  $^{180m}$Ta is the longest-lived metastable state presently known. Its decay\nhas not been observed yet. In this work, we report a new result on the decay of\n$^{180m}$Ta obtained with a $2015.12$-g tantalum sample measured for $527.7$ d\nwith an ultra-low background HPGe detector in the STELLA laboratory of the\nLaboratori Nazionali del Gran Sasso, in Italy. Before the measurement, the\nsample has been stored deep-underground for ten years, resulting in subdominant\nbackground contributions from cosmogenically activated $^{182}$Ta. We observe\nno signal in the regions of interest and set half-life limits on the process\nfor the two channels EC and $\\beta^-$: $T_{1/2,~\\mathrm{EC}} > 1.6 \\times\n10^{18}$ yr and $T_{1/2,~\\beta^-} > 1.1\\times 10^{18}$ yr ($90$% C. I.),\nrespectively. We also set the limit on the $\\gamma$ de-excitation / IC channel:\n$T_{1/2,~\\mathrm{IC}} > 4.1 \\times 10^{15}$ yr ($90$% C. I.). These are, as of\nnow, the most stringent bounds on the decay of $^{180m}$Ta worldwide.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:52:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17239","submitter":"Sarah Cannon","authors":"Sarah Cannon","title":"Irreducibility of Recombination Markov Chains in the Triangular Lattice","comments":"79 pages, 37 figures. 10-page conference version published in SIAM\n  Conference on Applied and Computational Discrete Algorithms, 2023 (ACDA23)","journal-ref":null,"doi":"10.1137/1.9781611977714.9","report-no":null,"categories":"cs.DM cs.CG cs.DS math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the United States, regions are frequently divided into districts for the\npurpose of electing representatives. How the districts are drawn can affect\nwho's elected, and drawing districts to give an advantage to a certain group is\nknown as gerrymandering. It can be surprisingly difficult to detect\ngerrymandering, but one algorithmic method is to compare a current districting\nplan to a large number of randomly sampled plans to see whether it is an\noutlier. Recombination Markov chains are often used for this random sampling:\nrandomly choose two districts, consider their union, and split this union in a\nnew way. This works well in practice, but the theory behind it remains\nunderdeveloped. For example, it's not known if recombination Markov chains are\nirreducible, that is, if recombination moves suffice to move from any\ndistricting plan to any other.\n  Irreducibility of recombination Markov chains can be formulated as a graph\nproblem: for a graph $G$, is the space of all partitions of $G$ into $k$\nconnected subgraphs ($k$ districts) connected by recombination moves? We\nconsider three simply connected districts and district sizes $k_1\\pm 1$\nvertices, $k_2\\pm 1$ vertices, and $k3\\pm 1$ vertices. We prove for arbitrarily\nlarge triangular regions in the triangular lattice, recombination Markov chains\nare irreducible. This is the first proof of irreducibility under tight district\nsize constraints for recombination Markov chains beyond small or trivial\nexamples.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 19:53:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17240","submitter":"Zehui Lu","authors":"Zehui Lu, Shaoshuai Mou","title":"A Distributed Algorithm for Multi-Agent Optimization under\n  Edge-Agreements","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.MA cs.SY eess.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generalized from the concept of consensus, this paper considers a group of\nedge agreements, i.e. constraints defined for neighboring agents, in which each\npair of neighboring agents is required to satisfy one edge agreement\nconstraint. Edge agreements are defined locally to allow more flexibility than\na global consensus. This work formulates a multi-agent optimization problem\nunder edge agreements and proposes a continuous-time distributed augmented\nLagrangian algorithm. Both analytical proof and numerical examples are provided\nto validate the effectiveness of the proposed distributed algorithm.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:02:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17241","submitter":"Dustin Mixon","authors":"Jameson Cahill, Joseph W. Iverson, Dustin G. Mixon","title":"Bilipschitz group invariants","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA cs.IT math.IT math.MG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Consider the quotient of a real Hilbert space by a subgroup of its orthogonal\ngroup. We study whether this orbit space can be embedded into a Hilbert space\nby a bilipschitz map, and we identify constraints on such embeddings.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:06:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17242","submitter":"Sean Muleady","authors":"Sean R. Muleady, Mingru Yang, Steven R. White, Ana Maria Rey","title":"Validating phase-space methods with tensor networks in two-dimensional\n  spin models with power-law interactions","comments":"6+4 pages, 3+1 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using a recently developed extension of the time-dependent variational\nprinciple for matrix product states, we evaluate the dynamics of 2D power-law\ninteracting XXZ models, implementable in a variety of state-of-the-art\nexperimental platforms. We compute the spin squeezing as a measure of\ncorrelations in the system, and compare to semiclassical phase-space\ncalculations utilizing the discrete truncated Wigner approximation (DTWA). We\nfind the latter efficiently and accurately captures the scaling of entanglement\nwith system size in these systems, despite the comparatively resource-intensive\ntensor network representation of the dynamics. We also compare the steady-state\nbehavior of DTWA to thermal ensemble calculations with tensor networks. Our\nresults open a way to benchmark dynamical calculations for two-dimensional\nquantum systems, and allow us to rigorously validate recent predictions for the\ngeneration of scalable entangled resources for metrology in these systems.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:15:24 GMT"},{"version":"v2","created":"Tue, 30 May 2023 23:04:02 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17243","submitter":"Thomas de Jaeger","authors":"T. de Jaeger and L. Galbany","title":"The pursuit of the Hubble Constant using Type II Supernovae","comments":"Invited chapter for the edited book \"Hubble Constant Tension\" (Eds.\n  E. Di Valentino and D. Brout, Springer Singapore, expected in 2024)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The use of multiple independent methods with their own systematic\nuncertainties is crucial for resolving the ongoing tension between local and\ndistant measurements of the Hubble constant ($H_{0}$). While type Ia supernovae\n(SNe Ia) have historically been the most widely used distance indicators,\nrecent studies have shown that type II supernovae (SNe II) can provide\nindependent measurements of extragalactic distances with different systematic\nuncertainties. Unlike SNe Ia, the progenitors of SNe II are well understood,\narising from the explosion of red supergiants in late-type galaxies via\ncore-collapse. While SNe II do not exhibit the same level of uniformity in peak\nluminosity as SNe Ia, their differences can be calibrated using theoretical or\nempirical methods. Overall, this chapter presents a comprehensive overview of\nthe use of SNe II as extragalactic distance indicators, with a particular focus\non their application to measuring $H_0$ and addressing the Hubble tension. We\ndescribe the underlying theory of each method, discuss the challenges\nassociated with them, including uncertainties in the calibration of the\nsupernova absolute magnitude, and present a comprehensive list of the most\nupdated Hubble constant measurements.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:17:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17244","submitter":"Ketaki Rajiv Joshi","authors":"Ketaki Joshi, Raghavendra Pradyumna Pothukuchi, Andre Wibisono,\n  Abhishek Bhattacharjee","title":"Mitigating Catastrophic Forgetting in Long Short-Term Memory Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Continual learning on sequential data is critical for many machine learning\n(ML) deployments. Unfortunately, LSTM networks, which are commonly used to\nlearn on sequential data, suffer from catastrophic forgetting and are limited\nin their ability to learn multiple tasks continually. We discover that\ncatastrophic forgetting in LSTM networks can be overcome in two novel and\nreadily-implementable ways -- separating the LSTM memory either for each task\nor for each target label. Our approach eschews the need for explicit\nregularization, hypernetworks, and other complex methods. We quantify the\nbenefits of our approach on recently-proposed LSTM networks for computer memory\naccess prefetching, an important sequential learning problem in ML-based\ncomputer system optimization. Compared to state-of-the-art weight\nregularization methods to mitigate catastrophic forgetting, our approach is\nsimple, effective, and enables faster learning. We also show that our proposal\nenables the use of small, non-regularized LSTM networks for complex natural\nlanguage processing in the offline learning scenario, which was previously\nconsidered difficult.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:17:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17245","submitter":"Hamoon Jafarian","authors":"Hamoon Jafarian and Faisal Z. Qureshi","title":"Error Estimation for Single-Image Human Body Mesh Reconstruction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Human pose and shape estimation methods continue to suffer in situations\nwhere one or more parts of the body are occluded. More importantly, these\nmethods cannot express when their predicted pose is incorrect. This has serious\nconsequences when these methods are used in human-robot interaction scenarios,\nwhere we need methods that can evaluate their predictions and flag situations\nwhere they might be wrong. This work studies this problem. We propose a method\nthat combines information from OpenPose and SPIN -- two popular human pose and\nshape estimation methods -- to highlight regions on the predicted mesh that are\nleast reliable. We have evaluated the proposed approach on 3DPW, 3DOH, and\nHuman3.6M datasets, and the results demonstrate our model's effectiveness in\nidentifying inaccurate regions of the human body mesh. Our code is available at\nhttps://github.com/Hamoon1987/meshConfidence.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:18:42 GMT"},{"version":"v2","created":"Wed, 31 May 2023 00:02:39 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17246","submitter":"Jarom\\'ir Janisch","authors":"Jarom\\'ir Janisch, Tom\\'a\\v{s} Pevn\\'y, Viliam Lis\\'y","title":"NASimEmu: Network Attack Simulator & Emulator for Training Agents\n  Generalizing to Novel Scenarios","comments":"NASimEmu is available at https://github.com/jaromiru/NASimEmu and the\n  baseline agents at https://github.com/jaromiru/NASimEmu-agents","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current frameworks for training offensive penetration testing agents with\ndeep reinforcement learning struggle to produce agents that perform well in\nreal-world scenarios, due to the reality gap in simulation-based frameworks and\nthe lack of scalability in emulation-based frameworks. Additionally, existing\nframeworks often use an unrealistic metric that measures the agents'\nperformance on the training data. NASimEmu, a new framework introduced in this\npaper, addresses these issues by providing both a simulator and an emulator\nwith a shared interface. This approach allows agents to be trained in\nsimulation and deployed in the emulator, thus verifying the realism of the used\nabstraction. Our framework promotes the development of general agents that can\ntransfer to novel scenarios unseen during their training. For the simulation\npart, we adopt an existing simulator NASim and enhance its realism. The\nemulator is implemented with industry-level tools, such as Vagrant, VirtualBox,\nand Metasploit. Experiments demonstrate that a simulation-trained agent can be\ndeployed in emulation, and we show how to use the framework to train a general\nagent that transfers into novel, structurally different scenarios. NASimEmu is\navailable as open-source.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:19:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17247","submitter":"Paulina Karczmarek","authors":"The Araucaria Project: G. Pietrzy\\'nski, W. Gieren, P. Karczmarek, M.\n  G\\'orski, B. Zgirski, P. Wielg\\'orski, L. Breuval, K. Suchomska, A. Gallenne,\n  P. Kervella, G. Hajdu, B. Pilecki, J. Storm, N. Nardetto, R. P. Kudritzki, M.\n  Taormina, F. Bresolin, R. Smolec, W. Narloch, C. Ga{\\l}an, M. Lewis, R. Chini","title":"The Araucaria Project: Improving the cosmic distance scale","comments":"114 pages, book published in 2021 on behalf of the Nicolaus\n  Copernicus Astronomical Center of the Polish Academy of Sciences, to\n  celebrate 20 years of the Arauria Project","journal-ref":"Published on behalf of the Nicolaus Copernicus Astronomical Center\n  of the Polish Academy of Sciences. Editors: P. Karczmarek, M. Lewis, G.\n  Pietrzy\\'nski. Publisher: Wydawnictwo Aleksander, Pu{\\l}tusk 2021. ISBN:\n  978-83-66856-07-3","doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.IM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The book consists of a number of short articles that present achievements of\nthe Araucaria members, collaborators, and friends, in various aspects of\ndistance determinations and related topics. It celebrates the 20-year\nanniversary of the Araucaria Project, acknowledges the people who worked for\nits success, and popularises our methods and results among broader readership.\n  This book is a part of a project that has received funding from the European\nUnion's Horizon 2020 research and innovation programme under grant agreement No\n695099.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:28:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17248","submitter":"Fatemeh Rezaei","authors":"Fatemeh Rezaei, Diluka Galappaththige, Chintha Tellambura, Amine\n  Maaref","title":"Time-Spread Pilot-Based Channel Estimation for Backscatter Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current backscatter channel estimators employ an inefficient silent pilot\ntransmission protocol, where tags alternate between silent and active states.\nTo enhance performance, we propose a novel approach where tags remain active\nsimultaneously throughout the entire training phase. This enables a one-shot\nestimation of both the direct and cascaded channels and accommodates various\nbackscatter network configurations. We derive the conditions for optimal pilot\nsequences and also establish that the minimum variance unbiased (MVU) estimator\nattains the Cramer-Rao lower bound. Next, we propose new pilot designs to avoid\npilot contamination. We then present several linear estimation methods,\nincluding least square (LS), scaled LS, and linear minimum mean square error\n(MMSE), to evaluate the performance of our proposed scheme. We also derive the\nanalytical MMSE estimator using our proposed pilot designs. Furthermore, we\nadapt our method for cellular-based passive Internet-of-Things (IoT) networks\nwith multiple tags and cellular users. Extensive numerical results and\nsimulations are provided to validate the effectiveness of our approach.\nNotably, at least 10 dBm and 12 dBm power savings compared to the prior art are\nachieved when estimating the direct and cascaded channels. These findings\nunderscore the practical benefits and superiority of our proposed technique.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:29:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17249","submitter":"Adam Sky","authors":"Adam Sky, Michael Neunteufel, Jack S. Hale and Andreas Zilian","title":"A Reissner-Mindlin plate formulation using symmetric Hu-Zhang elements\n  via polytopal transformations","comments":"Additional implementation material in:\n  https://github.com/Askys/NGSolve_HuZhang_Element","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work we develop new finite element discretisations of the\nshear-deformable Reissner--Mindlin plate problem based on the\nHellinger-Reissner principle of symmetric stresses. Specifically, we use\nconforming Hu-Zhang elements to discretise the bending moments in the space of\nsymmetric square integrable fields with a square integrable divergence\n$\\boldsymbol{M} \\in \\mathcal{HZ} \\subset H^{\\mathrm{sym}}(\\mathrm{Div})$. The\nlatter results in highly accurate approximations of the bending moments\n$\\boldsymbol{M}$ and in the rotation field being in the discontinuous Lebesgue\nspace $\\boldsymbol{\\phi} \\in [L]^2$, such that the Kirchhoff-Love constraint\ncan be satisfied for $t \\to 0$. In order to preserve optimal convergence rates\nacross all variables for the case $t \\to 0$, we present an extension of the\nformulation using Raviart-Thomas elements for the shear stress $\\mathbf{q} \\in\n\\mathcal{RT} \\subset H(\\mathrm{div})$.\n  We prove existence and uniqueness in the continuous setting and rely on exact\ncomplexes for inheritance of well-posedness in the discrete setting.\n  This work introduces an efficient construction of the Hu-Zhang base functions\non the reference element via the polytopal template methodology and Legendre\npolynomials, making it applicable to hp-FEM. The base functions on the\nreference element are then mapped to the physical element using novel polytopal\ntransformations, which are suitable also for curved geometries.\n  The robustness of the formulations and the construction of the Hu-Zhang\nelement are tested for shear-locking, curved geometries and an L-shaped domain\nwith a singularity in the bending moments $\\boldsymbol{M}$. Further, we compare\nthe performance of the novel formulations with the primal-, MITC- and recently\nintroduced TDNNS methods.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:34:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17250","submitter":"Chuning Zhu","authors":"Boyuan Chen, Chuning Zhu, Pulkit Agrawal, Kaiqing Zhang, Abhishek\n  Gupta","title":"Self-Supervised Reinforcement Learning that Transfers using Random\n  Features","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Model-free reinforcement learning algorithms have exhibited great potential\nin solving single-task sequential decision-making problems with\nhigh-dimensional observations and long horizons, but are known to be hard to\ngeneralize across tasks. Model-based RL, on the other hand, learns\ntask-agnostic models of the world that naturally enables transfer across\ndifferent reward functions, but struggles to scale to complex environments due\nto the compounding error. To get the best of both worlds, we propose a\nself-supervised reinforcement learning method that enables the transfer of\nbehaviors across tasks with different rewards, while circumventing the\nchallenges of model-based RL. In particular, we show self-supervised\npre-training of model-free reinforcement learning with a number of random\nfeatures as rewards allows implicit modeling of long-horizon environment\ndynamics. Then, planning techniques like model-predictive control using these\nimplicit models enable fast adaptation to problems with new reward functions.\nOur method is self-supervised in that it can be trained on offline datasets\nwithout reward labels, but can then be quickly deployed on new tasks. We\nvalidate that our proposed method enables transfer across tasks on a variety of\nmanipulation and locomotion domains in simulation, opening the door to\ngeneralist decision-making agents.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:37:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17251","submitter":"Arun Pandey","authors":"Sonny Achten, Arun Pandey, Hannes De Meulemeester, Bart De Moor, Johan\n  A. K. Suykens","title":"Duality in Multi-View Restricted Kernel Machines","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a unifying setting that combines existing restricted kernel\nmachine methods into a single primal-dual multi-view framework for kernel\nprincipal component analysis in both supervised and unsupervised settings. We\nderive the primal and dual representations of the framework and relate\ndifferent training and inference algorithms from a theoretical perspective. We\nshow how to achieve full equivalence in primal and dual formulations by\nrescaling primal variables. Finally, we experimentally validate the equivalence\nand provide insight into the relationships between different methods on a\nnumber of time series data sets by recursively forecasting unseen test data and\nvisualizing the learned features.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:37:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17252","submitter":"Vaibhav Saxena","authors":"Vaibhav Saxena, Kamal Rahimi Malekshan, Linh Tran, Yotto Koga","title":"Generalizable Pose Estimation Using Implicit Scene Representations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  6-DoF pose estimation is an essential component of robotic manipulation\npipelines. However, it usually suffers from a lack of generalization to new\ninstances and object types. Most widely used methods learn to infer the object\npose in a discriminative setup where the model filters useful information to\ninfer the exact pose of the object. While such methods offer accurate poses,\nthe model does not store enough information to generalize to new objects. In\nthis work, we address the generalization capability of pose estimation using\nmodels that contain enough information about the object to render it in\ndifferent poses. We follow the line of work that inverts neural renderers to\ninfer the pose. We propose i-$\\sigma$SRN to maximize the information flowing\nfrom the input pose to the rendered scene and invert them to infer the pose\ngiven an input image. Specifically, we extend Scene Representation Networks\n(SRNs) by incorporating a separate network for density estimation and introduce\na new way of obtaining a weighted scene representation. We investigate several\nways of initial pose estimates and losses for the neural renderer. Our final\nevaluation shows a significant improvement in inference performance and speed\ncompared to existing approaches.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:42:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17253","submitter":"Zikai Xu","authors":"Evan Carollo and Zikai Xu","title":"Reliability Evaluation of Phasor Measurement Unit Considering Failure of\n  Hardware and Software Using Fuzzy Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.SY eess.SY","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The wide-area measurement system (WAMS) consists of the future power system,\nincreasing geographical sprawl which is linked by the Phasor measurement\nunit(PMU). Thus, the failure of PMU will cause severe results, such as a\nblackout of the power system. In this paper, the reliability model of PMU is\nconsidered both hardware and software, where it gives a characteristic of\ncorrelated failure of hardware and software. Markov process is applied to model\nPMU, and reliability parameters are given by using symmetrical triangular\nmembership for Type-1 fuzzy reliability analysis. The paper gives insightful\nresults revealing the effective approach for analyzing the reliability of PMU,\nunder a circumstance which lack of sufficient field data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:45:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17254","submitter":"Wonoo Choo Mr","authors":"Wonoo Choo, Erkan Kayacan","title":"Computationally Efficient Data-Driven MPC for Agile Quadrotor Flight","comments":"6 pages, accepted in ACC 2023 (American Control Conference, 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.SY eess.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper develops computationally efficient data-driven model predictive\ncontrol (MPC) for Agile quadrotor flight. Agile quadrotors in high-speed\nflights can experience high levels of aerodynamic effects. Modeling these\nturbulent aerodynamic effects is a cumbersome task and the resulting model may\nbe overly complex and computationally infeasible. Combining Gaussian Process\n(GP) regression models with a simple dynamic model of the system has\ndemonstrated significant improvements in control performance. However, direct\nintegration of the GP models to the MPC pipeline poses a significant\ncomputational burden to the optimization process. Therefore, we present an\napproach to separate the GP models to the MPC pipeline by computing the model\ncorrections using reference trajectory and the current state measurements prior\nto the online MPC optimization. This method has been validated in the Gazebo\nsimulation environment and has demonstrated of up to $50\\%$ reduction in\ntrajectory tracking error, matching the performance of the direct GP\nintegration method with improved computational efficiency.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:46:47 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17255","submitter":"Michele Lohr","authors":"Michele Lohr, Laurent Younes","title":"FineMorphs: Affine-diffeomorphic sequences for regression","comments":"39 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A multivariate regression model of affine and diffeomorphic transformation\nsequences - FineMorphs - is presented. Leveraging concepts from shape analysis,\nmodel states are optimally \"reshaped\" by diffeomorphisms generated by smooth\nvector fields during learning. Affine transformations and vector fields are\noptimized within an optimal control setting, and the model can naturally reduce\n(or increase) dimensionality and adapt to large datasets via suboptimal vector\nfields. An existence proof of solution and necessary conditions for optimality\nfor the model are derived. Experimental results on real datasets from the UCI\nrepository are presented, with favorable results in comparison with\nstate-of-the-art in the literature and densely-connected neural networks in\nTensorFlow.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:54:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17256","submitter":"Ruixiang Tang","authors":"Ruixiang Tang, Dehan Kong, Longtao Huang, Hui Xue","title":"Large Language Models Can be Lazy Learners: Analyze Shortcuts in\n  In-Context Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models (LLMs) have recently shown great potential for\nin-context learning, where LLMs learn a new task simply by conditioning on a\nfew input-label pairs (prompts). Despite their potential, our understanding of\nthe factors influencing end-task performance and the robustness of in-context\nlearning remains limited. This paper aims to bridge this knowledge gap by\ninvestigating the reliance of LLMs on shortcuts or spurious correlations within\nprompts. Through comprehensive experiments on classification and extraction\ntasks, we reveal that LLMs are \"lazy learners\" that tend to exploit shortcuts\nin prompts for downstream tasks. Additionally, we uncover a surprising finding\nthat larger models are more likely to utilize shortcuts in prompts during\ninference. Our findings provide a new perspective on evaluating robustness in\nin-context learning and pose new challenges for detecting and mitigating the\nuse of shortcuts in prompts.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:56:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17257","submitter":"Timothy Buttsworth","authors":"Timothy Buttsworth and Artem Pulemotov","title":"Local solvability of the Poisson equation for closed $G_2$-structures","comments":"10 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove local solvability of the Poisson equation with a positive or\nnegative right-hand side for closed $G_2$-structures.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:59:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17258","submitter":"Kevin Leahy","authors":"Ho Chit Siu, Kevin Leahy, and Makai Mann","title":"STL: Surprisingly Tricky Logic (for System Validation)","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.HC cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Much of the recent work developing formal methods techniques to specify or\nlearn the behavior of autonomous systems is predicated on a belief that formal\nspecifications are interpretable and useful for humans when checking systems.\nThough frequently asserted, this assumption is rarely tested. We performed a\nhuman experiment (N = 62) with a mix of people who were and were not familiar\nwith formal methods beforehand, asking them to validate whether a set of signal\ntemporal logic (STL) constraints would keep an agent out of harm and allow it\nto complete a task in a gridworld capture-the-flag setting. Validation accuracy\nwas $45\\% \\pm 20\\%$ (mean $\\pm$ standard deviation). The ground-truth validity\nof a specification, subjects' familiarity with formal methods, and subjects'\nlevel of education were found to be significant factors in determining\nvalidation correctness. Participants exhibited an affirmation bias, causing\nsignificantly increased accuracy on valid specifications, but significantly\ndecreased accuracy on invalid specifications. Additionally, participants,\nparticularly those familiar with formal methods, tended to be overconfident in\ntheir answers, and be similarly confident regardless of actual correctness.\n  Our data do not support the belief that formal specifications are inherently\nhuman-interpretable to a meaningful degree for system validation. We recommend\nergonomic improvements to data presentation and validation training, which\nshould be tested before claims of interpretability make their way back into the\nformal methods literature.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:01:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17259","submitter":"Yasir Abdul Qadir","authors":"Yasir Abdul Qadir, Andrei V. Berdyugin, Vilppu Piirola, Takeshi\n  Sakanoi, Masato Kagitani","title":"High-precision broadband linear polarimetry of early-type binaries IV.\n  Binary system of DH Cephei in the open cluster of NGC 7380","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  DH~Cephei is a well known massive O+O-type binary system on the northern sky,\nresiding in the young open cluster NGC~7380. Our high-precision multi-band\npolarimetry has clearly revealed that variations of linear polarizations in\nthis system are synchronous with the phase of the orbital period. We have used\nthe observed variations of Stokes parameters $q$ and $u$ to derive the orbital\ninclination $i$, orientation $\\Omega$, and the direction of rotation. In order\nto determine the contribution from interstellar polarization, we have carried\nout new observations of polarization of field stars with precisely measured\nparallaxes.\n  The variations of Stokes parameters in all three $B$, $V$, and $R$ passbands\nclearly exhibit an unambiguous periodic signal at 1.055 d with the amplitude of\nvariations $\\sim$$0.2\\%$ which corresponds to half of known orbital period of\n2.11 d. This type of polarization variability is expected for a binary system\nwith light scattering material distributed symmetrically with respect to the\norbital plane. Even though most of the observed polarization ($\\sim$2$\\%$) is\nof interstellar origin, about one third of it is due to the intrinsic\ncomponent. In addition to the regular polarization variability, there is a\nnon-periodic component, strongest in the $B$ passband. We obtained in the $V$\npassband our most reliable values for the orbital inclination $i =\n46^{\\circ}+11^{\\circ}/-46^{\\circ}$ and the orientation of the orbit on the sky\n$\\Omega = 105^{\\circ} \\pm 55^{\\circ}$, with 1$\\sigma$ confidence intervals. The\ndirection of the binary system rotation on the plane of the sky is clockwise.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:05:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17260","submitter":"Avinab Saha","authors":"Avinab Saha, Yu-Chih Chen, Chase Davis, Bo Qiu, Xiaoming Wang, Rahul\n  Gowda, Ioannis Katsavounidis, Alan C. Bovik","title":"Study of Subjective and Objective Quality Assessment of Mobile Cloud\n  Gaming Videos","comments":"Accepted to IEEE Transactions on Image Processing, 2023. The database\n  will be publicly available by 1st week of July 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We present the outcomes of a recent large-scale subjective study of Mobile\nCloud Gaming Video Quality Assessment (MCG-VQA) on a diverse set of gaming\nvideos. Rapid advancements in cloud services, faster video encoding\ntechnologies, and increased access to high-speed, low-latency wireless internet\nhave all contributed to the exponential growth of the Mobile Cloud Gaming\nindustry. Consequently, the development of methods to assess the quality of\nreal-time video feeds to end-users of cloud gaming platforms has become\nincreasingly important. However, due to the lack of a large-scale public Mobile\nCloud Gaming Video dataset containing a diverse set of distorted videos with\ncorresponding subjective scores, there has been limited work on the development\nof MCG-VQA models. Towards accelerating progress towards these goals, we\ncreated a new dataset, named the LIVE-Meta Mobile Cloud Gaming (LIVE-Meta-MCG)\nvideo quality database, composed of 600 landscape and portrait gaming videos,\non which we collected 14,400 subjective quality ratings from an in-lab\nsubjective study. Additionally, to demonstrate the usefulness of the new\nresource, we benchmarked multiple state-of-the-art VQA algorithms on the\ndatabase. The new database will be made publicly available on our website:\n\\url{https://live.ece.utexas.edu/research/LIVE-Meta-Mobile-Cloud-Gaming/index.html}\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:08:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17261","submitter":"Hussein Mozannar","authors":"Hussein Mozannar, Yuria Utsumi, Irene Y. Chen, Stephanie S. Gervasi,\n  Michele Ewing, Aaron Smith-McLallen, David Sontag","title":"Closing the Gap in High-Risk Pregnancy Care Using Machine Learning and\n  Human-AI Collaboration","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Health insurers often use algorithms to identify members who would benefit\nfrom care and condition management programs, which provide personalized,\nhigh-touch clinical support. Timely, accurate, and seamless integration between\nalgorithmic identification and clinical intervention depends on effective\ncollaboration between the system designers and nurse care managers. We focus on\na high-risk pregnancy (HRP) program designed to reduce the likelihood of\nadverse prenatal, perinatal, and postnatal events and describe how we overcome\nthree challenges of HRP programs as articulated by nurse care managers; (1)\nearly detection of pregnancy, (2) accurate identification of impactable\nhigh-risk members, and (3) provision of explainable indicators to supplement\npredictions. We propose a novel algorithm for pregnancy identification that\nidentifies pregnancies 57 days earlier than previous code-based models in a\nretrospective study. We then build a model to predict impactable pregnancy\ncomplications that achieves an AUROC of 0.760. Models for pregnancy\nidentification and complications are then integrated into a proposed user\ninterface. In a set of user studies, we collected quantitative and qualitative\nfeedback from nurses on the utility of the predictions combined with clinical\ninformation driving the predictions on triaging members for the HRP program.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:08:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17262","submitter":"Bhishma Dedhia","authors":"Bhishma Dedhia, Michael Chang, Jake C. Snell, Thomas L. Griffiths,\n  Niraj K. Jha","title":"Im-Promptu: In-Context Composition from Image Prompts","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models are few-shot learners that can solve diverse tasks from\na handful of demonstrations. This implicit understanding of tasks suggests that\nthe attention mechanisms over word tokens may play a role in analogical\nreasoning. In this work, we investigate whether analogical reasoning can enable\nin-context composition over composable elements of visual stimuli. First, we\nintroduce a suite of three benchmarks to test the generalization properties of\na visual in-context learner. We formalize the notion of an analogy-based\nin-context learner and use it to design a meta-learning framework called\nIm-Promptu. Whereas the requisite token granularity for language is well\nestablished, the appropriate compositional granularity for enabling in-context\ngeneralization in visual stimuli is usually unspecified. To this end, we use\nIm-Promptu to train multiple agents with different levels of compositionality,\nincluding vector representations, patch representations, and object slots. Our\nexperiments reveal tradeoffs between extrapolation abilities and the degree of\ncompositionality, with non-compositional representations extending learned\ncomposition rules to unseen domains but performing poorly on combinatorial\ntasks. Patch-based representations require patches to contain entire objects\nfor robust extrapolation. At the same time, object-centric tokenizers coupled\nwith a cross-attention module generate consistent and high-fidelity solutions,\nwith these inductive biases being particularly crucial for compositional\ngeneralization. Lastly, we demonstrate a use case of Im-Promptu as an intuitive\nprogramming interface for image generation.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:10:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17263","submitter":"Geoffrey Harrison","authors":"Geoffrey R. Harrison, Tobias Saule, R. Esteban Goetz, George N.\n  Gibson, Anh-Thu Le, and Carlos A. Trallero-Herrero","title":"Generation and control of non-local quantum equivalent extreme\n  ultraviolet photons","comments":"11 pages 5 figures and supplemental materials with 12 pages and 7\n  figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.atm-clus physics.atom-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a high precision, self-referencing, common path XUV interferometer\nsetup to produce pairs of spatially separated and independently controllable\nXUV pulses that are locked in phase and time. The spatial separation is created\nby introducing two equal but opposite wavefront tilts or using superpositions\nof orbital angular momentum. In our approach, we can independently control the\nrelative phase/delay of the two optical beams with a resolution of 52 zs (zs =\nzeptoseconds). In order to explore the level of entanglement between the\nnon-local photons, we compare three different beam modes: Bessel-like, and\nGaussian with or without added orbital angular momentum. By reconstructing\ninterference patterns one or two photons at a time we conclude that the beams\nare not entangled, yet each photon in the attosecond pulse train contains\ninformation about the entire spectrum. Our technique generates non-local,\nquantum equivalent XUV photons with a temporal jitter of 3 zs, just below the\nCompton unit of time of 8 zs. We argue that this new level of temporal\nprecision will open the door for new dynamical QED tests. We also discuss the\npotential impact on other areas, such as imaging, measurements of non-locality,\nand molecular quantum tomography.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:16:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17264","submitter":"Igor Herbut","authors":"Igor F. Herbut, Subrata Mandal","title":"$SO(8)$ unification and the large-N theory of superconductor-insulator\n  transition of two-dimensional Dirac fermions","comments":"9 pages, including 4.5 pages of supplemental material","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.stat-mech cond-mat.supr-con hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electrons on honeycomb or pi-flux lattices obey effective massless Dirac\nequation at low energies and at the neutrality point, and should suffer quantum\nphase transitions into various Mott insulators and superconductors at strong\ntwo-body interactions. We show that 35 out of 36 such order parameters that\nprovide Lorentz-invariant mass-gaps to Dirac fermions can be organized into a\nsingle irreducible tensor representation of the $SO(8)$ symmetry of the\ntwo-dimensional Dirac Hamiltonian for the spin-1/2 lattice fermions. The\nminimal interacting Lagrangian away from the neutrality point has the $SO(8)$\nsymmetry reduced to $U(1) \\times SU(4)$ by finite chemical potential, and it\nallows only two independent interaction terms. When the Lagrangian is nearly\n$SO(8)$-symmetric and the ground state insulating at the neutrality point, we\nargue it turns superconducting at the critical value of the chemical potential\nthrough a ``flop\" between the tensor components. The theory is exactly solvable\nwhen the $SU(4)$ is generalized to $SU(N)$ and $N$ taken large. A lattice\nHamiltonian that may exhibit this transition, parallels with the Gross-Neveu\nmodel, and applicability to related electronic systems are briefly discussed.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:16:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17265","submitter":"Marco Romanelli","authors":"Colin Coane, Marco Romanelli, Giulia Dall'Osto, Rosa Di Felice,\n  Stefano Corni","title":"Unraveling the Mechanism of Tip-Enhanced Molecular Energy Transfer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Electronic Energy Transfer (EET) between chromophores is fundamental in many\nnatural light-harvesting complexes, serving as a critical step for solar energy\nfunneling in photosynthetic plants and bacteria. The complicated role of the\nenvironment in mediating this process in natural architectures has been\naddressed by recent scanning tunneling microscope (STM) experiments involving\nEET between two molecules supported on a solid substrate [Cao, S. et al., Nat.\nChem. 2021, 13, 766-770]. These measurements demonstrated that EET in such\nconditions has peculiar features, such as a steep dependence on the\ndonor-acceptor distance, reminiscent of a short-range mechanism more than of a\nForster-like process. By using state of the art hybrid ab initio\nelectromagnetic modeling, here we provide a comprehensive theoretical analysis\nof tip-enhanced EET. In particular, we show that this process can be understood\nas a complex interplay of electromagnetic-based molecular plasmonic processes,\nwhose result may effectively mimic short range effects. Therefore, the\nestablished identification of an exponential decay with Dexter-like effects\ndoes not hold for tip-enhanced EET, and accurate electromagnetic modeling is\nneeded to identify the EET mechanism.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:18:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17266","submitter":"Daniel Pechi","authors":"Vijeta Deshpande, Dan Pechi, Shree Thatte, Vladislav Lialin, Anna\n  Rumshisky","title":"Honey, I Shrunk the Language: Language Model Behavior at Reduced Scale","comments":"Accepted to ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In recent years, language models have drastically grown in size, and the\nabilities of these models have been shown to improve with scale. The majority\nof recent scaling laws studies focused on high-compute high-parameter count\nsettings, leaving the question of when these abilities begin to emerge largely\nunanswered. In this paper, we investigate whether the effects of pre-training\ncan be observed when the problem size is reduced, modeling a smaller,\nreduced-vocabulary language. We show the benefits of pre-training with masked\nlanguage modeling (MLM) objective in models as small as 1.25M parameters, and\nestablish a strong correlation between pre-training perplexity and downstream\nperformance (GLUE benchmark). We examine downscaling effects, extending scaling\nlaws to models as small as ~1M parameters. At this scale, we observe a break of\nthe power law for compute-optimal models and show that the MLM loss does not\nscale smoothly with compute-cost (FLOPs) below $2.2 \\times 10^{15}$ FLOPs. We\nalso find that adding layers does not always benefit downstream performance.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:22:10 GMT"},{"version":"v2","created":"Tue, 30 May 2023 18:37:32 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17267","submitter":"Sina Ahmadi","authors":"Md Mahfuz Ibn Alam, Sina Ahmadi, Antonios Anastasopoulos","title":"CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine\n  Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neural machine translation (NMT) systems exhibit limited robustness in\nhandling source-side linguistic variations. Their performance tends to degrade\nwhen faced with even slight deviations in language usage, such as different\ndomains or variations introduced by second-language speakers. It is intuitive\nto extend this observation to encompass dialectal variations as well, but the\nwork allowing the community to evaluate MT systems on this dimension is\nlimited. To alleviate this issue, we compile and release \\dataset, a\ncontrastive dialectal benchmark encompassing 882 different variations from nine\ndifferent languages. We also quantitatively demonstrate the challenges large MT\nmodels face in effectively translating dialectal variants. We are releasing all\ncode and data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:24:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17268","submitter":"Yucheng Li","authors":"Yucheng Li, Shun Wang, Chenghua Lin, Guerin Frank","title":"Metaphor Detection via Explicit Basic Meanings Modelling","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One noticeable trend in metaphor detection is the embrace of linguistic\ntheories such as the metaphor identification procedure (MIP) for model\narchitecture design. While MIP clearly defines that the metaphoricity of a\nlexical unit is determined based on the contrast between its \\textit{contextual\nmeaning} and its \\textit{basic meaning}, existing work does not strictly follow\nthis principle, typically using the \\textit{aggregated meaning} to approximate\nthe basic meaning of target words. In this paper, we propose a novel metaphor\ndetection method, which models the basic meaning of the word based on literal\nannotation from the training set, and then compares this with the contextual\nmeaning in a target sentence to identify metaphors. Empirical results show that\nour method outperforms the state-of-the-art method significantly by 1.0\\% in F1\nscore. Moreover, our performance even reaches the theoretical upper bound on\nthe VUA18 benchmark for targets with basic annotations, which demonstrates the\nimportance of modelling basic meanings for metaphor detection.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:25:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17269","submitter":"Noah Forman","authors":"Noah Forman, Soumik Pal, Douglas Rizzolo, Matthias Winkel","title":"The Aldous diffusion: a stationary evolution of the Brownian CRT","comments":"193+vi pages, 26 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Motivated by a down-up Markov chain on cladograms, David Aldous conjectured\nin 1999 that there exists a \"diffusion on continuum trees\" whose mass\npartitions at any finite number of branch points evolve as Wright-Fisher\ndiffusions with some negative mutation rates, until some branch point\ndisappears. Building on previous work on interval-partition-valued processes,\nwe construct this conjectured process via a consistent system of stationary\nevolutions of binary trees with k labeled leaves and edges decorated with\ninterval partitions. The interval partitions are scaled Poisson-Dirichlet\ninterval partitions whose interval lengths record subtree masses. They also\npossess a diversity property that captures certain distances in the continuum\ntree. Continuously evolving diversities give access to continuously evolving\ncontinuum tree distances. The pathwise construction allows us to study this\n\"Aldous diffusion\" in the Gromov-Hausdorff-Prokhorov space of rooted, weighted\nR-trees. We establish the simple Markov property and path-continuity. The\nAldous diffusion is stationary with the distribution of the Brownian continuum\nrandom tree. While the Brownian CRT is a.s. binary, we show that there is a\ndense null set of exceptional times when the Aldous diffusion has a ternary\nbranch point, including stopping times at which the strong Markov property\nfails. Our construction relates to the two-parameter Chinese restaurant\nprocess, branching processes, and stable L\\'evy processes, among other\nconnections. Wright-Fisher diffusions and the aforementioned processes of\nPoisson-Dirichlet interval partitions arise as interesting projections of the\nAldous diffusion. Finally, one can embed Aldous's stationary down-up Markov\nchain on cladograms in the Aldous diffusion and hence address a related\nconjecture by David Aldous by establishing a scaling limit theorem.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:25:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17270","submitter":"Zhenpeng Qin","authors":"Chen Xie, Blake Wilson, Zhenpeng Qin","title":"Regulating nanoscale heat transfer with Janus nanoparticles","comments":"5 figures in the main text, and 9 figures in the supporting\n  information","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Janus nanoparticles (JNPs) with heterogeneous compositions or interfacial\nproperties can exhibit directional heating upon external excitation, such as\nlaser radiation and magnetic field. This directional heating may be harnessed\nfor new nanotechnology and biomedical applications. Understanding thermal\ntransport and temperature control with JNP heating is critical for these\nadvances. Here, we developed a numerical framework to analyze the asymmetric\nthermal transport in JNP heating under photothermal stimulation. We found that\nJNP-induced temperature contrast, defined as the ratio of temperature increase\nin the surrounding water, shows a substantial size and polar angle dependence.\nNotably, we discovered a significant enhancement of the temperature contrast\nunder pulsed heating due to thermal confinement, compared with the continuous\nheating. This work brings new insights into the thermal responses of JNP\nheating and advances the field.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:32:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17271","submitter":"Yongqi Dong","authors":"Ruohan Li, Yongqi Dong","title":"Robust Lane Detection through Self Pre-training with Masked Sequential\n  Autoencoders and Fine-tuning with Customized PolyLoss","comments":"12 pages, 8 figures, under review by journal of IEEE Transactions on\n  Intelligent Transportation Systems","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Lane detection is crucial for vehicle localization which makes it the\nfoundation for automated driving and many intelligent and advanced driving\nassistant systems. Available vision-based lane detection methods do not make\nfull use of the valuable features and aggregate contextual information,\nespecially the interrelationships between lane lines and other regions of the\nimages in continuous frames. To fill this research gap and upgrade lane\ndetection performance, this paper proposes a pipeline consisting of self\npre-training with masked sequential autoencoders and fine-tuning with\ncustomized PolyLoss for the end-to-end neural network models using\nmulti-continuous image frames. The masked sequential autoencoders are adopted\nto pre-train the neural network models with reconstructing the missing pixels\nfrom a random masked image as the objective. Then, in the fine-tuning\nsegmentation phase where lane detection segmentation is performed, the\ncontinuous image frames are served as the inputs, and the pre-trained model\nweights are transferred and further updated using the backpropagation mechanism\nwith customized PolyLoss calculating the weighted errors between the output\nlane detection results and the labeled ground truth. Extensive experiment\nresults demonstrate that, with the proposed pipeline, the lane detection model\nperformance on both normal and challenging scenes can be advanced beyond the\nstate-of-the-art, delivering the best testing accuracy (98.38%), precision\n(0.937), and F1-measure (0.924) on the normal scene testing set, together with\nthe best overall accuracy (98.36%) and precision (0.844) in the challenging\nscene test set, while the training time can be substantially shortened.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:36:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17272","submitter":"Natasa Sesum","authors":"Sigurd Angenent, Panagiota Daskalopoulos, Natasa Sesum","title":"Dynamics of Convex Mean Curvature Flow","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There is an extensive and growing body of work analyzing convex ancient\nsolutions to Mean Curvature Flow (MCF), or equivalently of Rescaled Mean\nCurvature Flow (RMCF). The goal of this paper is to complement the existing\nliterature, which analyzes ancient solutions one at a time, by considering the\nspace X of all convex hypersurfaces M, regard RMCF as a semiflow on this space,\nand study the dynamics of this semiflow. To this end, we first extend the well\nknown existence and uniqueness of solutions to MCF with smooth compact convex\ninitial data to include the case of arbitrary non compact and non smooth\ninitial convex hypersurfaces. We identify a suitable weak topology with good\ncompactness properties on the space X of convex hypersurfaces and show that\nRMCF defines a continuous local semiflow on X whose fixed points are the\nshrinking cylinder solitons, and for which the Huisken energy is a Lyapunov\nfunction. Ancient solutions to MCF are then complete orbits of the RMCF\nsemiflow on X. We consider the set of all hypersurfaces that lie on an ancient\nsolution that in backward time is asymptotic to one of the shrinking cylinder\nsolitons and prove various topological properties of this set. We show that\nthis space is a path connected, compact subset of X, and, considering only\npoint symmetric hypersurfaces, that it is topologically trivial in the sense of\nCech cohomology. We also give a strong evidence in support of the conjecture\nthat the space of all convex ancient solutions with a point symmetry is\nhomeomorphic to an n-1 dimensional simplex.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:37:01 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17273","submitter":"Sadhana Kumaravel","authors":"Sadhana Kumaravel, Tahira Naseem, Ramon Fernandez Astudillo, Radu\n  Florian, Salim Roukos","title":"Slide, Constrain, Parse, Repeat: Synchronous SlidingWindows for Document\n  AMR Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  The sliding window approach provides an elegant way to handle contexts of\nsizes larger than the Transformer's input window, for tasks like language\nmodeling. Here we extend this approach to the sequence-to-sequence task of\ndocument parsing. For this, we exploit recent progress in transition-based\nparsing to implement a parser with synchronous sliding windows over source and\ntarget. We develop an oracle and a parser for document-level AMR by expanding\non Structured-BART such that it leverages source-target alignments and\nconstrains decoding to guarantee synchronicity and consistency across\noverlapping windows. We evaluate our oracle and parser using the Abstract\nMeaning Representation (AMR) parsing 3.0 corpus. On the Multi-Sentence\ndevelopment set of AMR 3.0, we show that our transition oracle loses only 8\\%\nof the gold cross-sentential links despite using a sliding window. In practice,\nthis approach also results in a high-quality document-level parser with\nmanageable memory requirements. Our proposed system performs on par with the\nstate-of-the-art pipeline approach for document-level AMR parsing task on\nMulti-Sentence AMR 3.0 corpus while maintaining sentence-level parsing\nperformance.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:38:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17274","submitter":"Giovanni Pizzi","authors":"Emanuele Bosoni, Louis Beal, Marnik Bercx, Peter Blaha, Stefan\n  Bl\\\"ugel, Jens Br\\\"oder, Martin Callsen, Stefaan Cottenier, Augustin Degomme,\n  Vladimir Dikan, Kristjan Eimre, Espen Flage-Larsen, Marco Fornari, Alberto\n  Garcia, Luigi Genovese, Matteo Giantomassi, Sebastiaan P. Huber, Henning\n  Janssen, Georg Kastlunger, Matthias Krack, Georg Kresse, Thomas D. K\\\"uhne,\n  Kurt Lejaeghere, Georg K. H. Madsen, Martijn Marsman, Nicola Marzari, Gregor\n  Michalicek, Hossein Mirhosseini, Tiziano M. A. M\\\"uller, Guido Petretto,\n  Chris J. Pickard, Samuel Ponc\\'e, Gian-Marco Rignanese, Oleg Rubel, Thomas\n  Ruh, Michael Sluydts, Danny E. P. Vanpoucke, Sudarshan Vijay, Michael\n  Wolloch, Daniel Wortmann, Aliaksandr V. Yakutovich, Jusong Yu, Austin Zadoks,\n  Bonan Zhu, Giovanni Pizzi","title":"How to verify the precision of density-functional-theory implementations\n  via reproducible and universal workflows","comments":"Main text: 23 pages, 4 figures. Supplementary: 68 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.comp-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the past decades many density-functional theory methods and codes adopting\nperiodic boundary conditions have been developed and are now extensively used\nin condensed matter physics and materials science research. Only in 2016,\nhowever, their precision (i.e., to which extent properties computed with\ndifferent codes agree among each other) was systematically assessed on\nelemental crystals: a first crucial step to evaluate the reliability of such\ncomputations. We discuss here general recommendations for verification studies\naiming at further testing precision and transferability of\ndensity-functional-theory computational approaches and codes. We illustrate\nsuch recommendations using a greatly expanded protocol covering the whole\nperiodic table from Z=1 to 96 and characterizing 10 prototypical cubic\ncompounds for each element: 4 unaries and 6 oxides, spanning a wide range of\ncoordination numbers and oxidation states. The primary outcome is a reference\ndataset of 960 equations of state cross-checked between two all-electron codes,\nthen used to verify and improve nine pseudopotential-based approaches. Such\neffort is facilitated by deploying AiiDA common workflows that perform\nautomatic input parameter selection, provide identical input/output interfaces\nacross codes, and ensure full reproducibility. Finally, we discuss the extent\nto which the current results for total energies can be reused for different\ngoals (e.g., obtaining formation energies).\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:40:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17275","submitter":"Guillaume Wang","authors":"Guillaume Wang, L\\'ena\\\"ic Chizat","title":"Local Convergence of Gradient Methods for Min-Max Games under Partial\n  Curvature","comments":"37 pages, 2 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.GT cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the convergence to local Nash equilibria of gradient methods for\ntwo-player zero-sum differentiable games. It is well-known that such dynamics\nconverge locally when $S \\succ 0$ and may diverge when $S=0$, where $S\\succeq\n0$ is the symmetric part of the Jacobian at equilibrium that accounts for the\n\"potential\" component of the game. We show that these dynamics also converge as\nsoon as $S$ is nonzero (partial curvature) and the eigenvectors of the\nantisymmetric part $A$ are in general position with respect to the kernel of\n$S$. We then study the convergence rates when $S \\ll A$ and prove that they\ntypically depend on the average of the eigenvalues of $S$, instead of the\nminimum as an analogy with minimization problems would suggest. To illustrate\nour results, we consider the problem of computing mixed Nash equilibria of\ncontinuous games. We show that, thanks to partial curvature, conic particle\nmethods -- which optimize over both weights and supports of the mixed\nstrategies -- generically converge faster than fixed-support methods. For\nmin-max games, it is thus beneficial to add degrees of freedom \"with\ncurvature\": this can be interpreted as yet another benefit of\nover-parameterization.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:43:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17276","submitter":"Douglas Dow","authors":"Yuri Bakhtin, Douglas Dow","title":"Differentiability of the effective Lagrangian for\n  Hamilton-Jacobi-Bellman equations in dynamic random environments","comments":"27 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove differentiability of the effective Lagrangian for continuous time\nmultidimensional directed variational problems in random dynamic environments\nwith positive dependence range in time. This implies that limiting fundamental\nsolutions in the associated homogenization problems for HJB equations are\nclassical.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:45:57 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17277","submitter":"Chang Deng","authors":"Chang Deng, Kevin Bello, Bryon Aragam, Pradeep Ravikumar","title":"Optimizing NOTEARS Objectives via Topological Swaps","comments":"39 pages, 12 figures, ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, an intriguing class of non-convex optimization problems has emerged\nin the context of learning directed acyclic graphs (DAGs). These problems\ninvolve minimizing a given loss or score function, subject to a non-convex\ncontinuous constraint that penalizes the presence of cycles in a graph. In this\nwork, we delve into the optimization challenges associated with this class of\nnon-convex programs. To address these challenges, we propose a bi-level\nalgorithm that leverages the non-convex constraint in a novel way. The outer\nlevel of the algorithm optimizes over topological orders by iteratively\nswapping pairs of nodes within the topological order of a DAG. A key innovation\nof our approach is the development of an effective method for generating a set\nof candidate swapping pairs for each iteration. At the inner level, given a\ntopological order, we utilize off-the-shelf solvers that can handle linear\nconstraints. The key advantage of our proposed algorithm is that it is\nguaranteed to find a local minimum or a KKT point under weaker conditions\ncompared to previous work and finds solutions with lower scores. Extensive\nexperiments demonstrate that our method outperforms state-of-the-art approaches\nin terms of achieving a better score. Additionally, our method can also be used\nas a post-processing algorithm to significantly improve the score of other\nalgorithms. Code implementing the proposed method is available at\nhttps://github.com/duntrain/topo.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:49:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17278","submitter":"Alexander Kitaev","authors":"A. V. Kitaev and A. Vartanian","title":"One-Parameter Meromorphic Solution of the Degenerate Third Painlev\\'{e}\n  Equation with Formal Monodromy Parameter $a=\\pm i/2$ Vanishing at the Origin","comments":"28 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math-ph math.MP nlin.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove that there exists a one-parameter meromorphic solution $u(\\tau)$\nvanishing at $\\tau=0$ of the degenerate third Painlev\\'e equation,\n\\begin{equation*} u^{\\prime \\prime}(\\tau) \\! = \\!\n\\frac{(u^{\\prime}(\\tau))^{2}}{u(\\tau)} \\! - \\! \\frac{u^{\\prime}(\\tau)}{\\tau} \\!\n+ \\! \\frac{1}{\\tau} \\! \\left(-8 \\varepsilon (u(\\tau))^{2} \\! + \\! 2ab \\right)\n\\! + \\! \\frac{b^{2}}{u(\\tau)},\\qquad \\varepsilon=\\pm1,\\quad\\varepsilon b>0,\n\\end{equation*} for formal monodromy parameter $a=\\pm i/2$. We study\nnumber-theoretic properties of the coefficients of the Taylor-series expansion\nof $u(\\tau)$ at $\\tau=0$ and its asymptotic behaviour as $\\tau\\to+\\infty$.\nThese asymptotics are visualized for generic initial data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:54:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17279","submitter":"Luke Dicks","authors":"Yuchen Wu, Luke Dicks and David J. Wales","title":"Archetypal solution spaces for clustering gene expression datasets in\n  identification of cancer subtypes","comments":"24 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Gene expression profiles are essential in identifying different cancer\nphenotypes. Clustering gene expression datasets can provide accurate\nidentification of cancerous cell lines, but this task is challenging due to the\nsmall sample size and high dimensionality. Using the $K$-means clustering\nalgorithm we determine the organisation of the solution space for a variety of\ngene expression datasets using energy landscape theory. The solution space\nlandscapes allow us to understand $K$-means performance, and guide more\neffective use when varying common dataset properties; number of features,\nnumber of clusters, and cluster distribution. We find that the landscapes have\na single-funnelled structure for the appropriate number of clusters, which is\nlost when the number of clusters deviates from this. We quantify this landscape\nstructure using a frustration metric and show that it may provide a novel\ndiagnostic tool for the appropriate number of cancer subtypes.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:56:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17280","submitter":"Duong Le","authors":"Duong Minh Le, Ruohao Guo, Wei Xu, Alan Ritter","title":"Improved Instruction Ordering in Recipe-Grounded Conversation","comments":"Accepted at ACL 2023 main conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we study the task of instructional dialogue and focus on the\ncooking domain. Analyzing the generated output of the GPT-J model, we reveal\nthat the primary challenge for a recipe-grounded dialog system is how to\nprovide the instructions in the correct order. We hypothesize that this is due\nto the model's lack of understanding of user intent and inability to track the\ninstruction state (i.e., which step was last instructed). Therefore, we propose\nto explore two auxiliary subtasks, namely User Intent Detection and Instruction\nState Tracking, to support Response Generation with improved instruction\ngrounding. Experimenting with our newly collected dataset, ChattyChef, shows\nthat incorporating user intent and instruction state information helps the\nresponse generation model mitigate the incorrect order issue. Furthermore, to\ninvestigate whether ChatGPT has completely solved this task, we analyze its\noutputs and find that it also makes mistakes (10.7% of the responses), about\nhalf of which are out-of-order instructions. We will release ChattyChef to\nfacilitate further research in this area at:\nhttps://github.com/octaviaguo/ChattyChef.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:57:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17281","submitter":"Fani Dosopoulou","authors":"Fani Dosopoulou","title":"Dynamical friction in dark matter spikes: corrections to Chandrasekhar's\n  formula","comments":"6 pages, 4 figures. Submitted. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the intermediate mass-ratio inspiral of a stellar-mass compact\nobject with an intermediate-mass black hole that is surrounded by a dark matter\ndensity spike. The interaction of the inspiraling black hole with the dark\nmatter particles in the spike leads to dynamical friction. This can alter the\ndynamics of the black hole binary, leaving an imprint on the gravitational wave\nsignal. Previous calculations did not include in the evaluation of the\ndynamical friction coefficient the contribution from particles that move faster\nthan the black hole. This term is neglected in the standard Chandrasekhar's\ntreatment where only slower moving particles contribute to the decelerating\ndrag. Here, we demonstrate that dynamical friction produced by the fast moving\nparticles has a significant effect on the evolution of a massive binary within\na dark matter spike. For a density profile $\\rho\\propto r^{-\\gamma}$ with\n$\\gamma\\lesssim 1$, the dephasing of the gravitational waveform can be several\norders of magnitude larger than estimated using the standard treatment. As\n$\\gamma$ approaches $0.5$ the error becomes arbitrarily large. Finally, we show\nthat dynamical friction tends to make the orbit more eccentric for any $\\gamma\n< 1.8$. However, energy loss by gravitational wave radiation is expected to\ndominate the inspiral, leading to orbital circularization in most cases.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:00:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17282","submitter":"Vladimir Pestov","authors":"Sushma Kumari and Vladimir G. Pestov","title":"Universal consistency of the $k$-NN rule in metric spaces and Nagata\n  dimension. II","comments":"Latex 2e, 15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We continue to investigate the $k$ nearest neighbour learning rule in\nseparable metric spaces. Thanks to the results of C\\'erou and Guyader (2006)\nand Preiss (1983), this rule is known to be universally consistent in every\nmetric space $X$ that is sigma-finite dimensional in the sense of Nagata. Here\nwe show that the rule is strongly universally consistent in such spaces in the\nabsence of ties. Under the tie-breaking strategy applied by Devroye,\nGy\\\"{o}rfi, Krzy\\.{z}ak, and Lugosi (1994) in the Euclidean setting, we manage\nto show the strong universal consistency in non-Archimedian metric spaces (that\nis, those of Nagata dimension zero). Combining the theorem of C\\'erou and\nGuyader with results of Assouad and Quentin de Gromard (2006), one deduces that\nthe $k$-NN rule is universally consistent in metric spaces having finite\ndimension in the sense of de Groot. In particular, the $k$-NN rule is\nuniversally consistent in the Heisenberg group which is not sigma-finite\ndimensional in the sense of Nagata as follows from an example independently\nconstructed by Kor\\'anyi and Reimann (1995) and Sawyer and Wheeden (1992).\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:01:47 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17283","submitter":"Aakash Lahoti","authors":"Aakash Lahoti, Spandan Senapati, Ketan Rajawat, Alec Koppel","title":"Sharpened Lazy Incremental Quasi-Newton Method","comments":"39 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the finite sum minimization of $n$ strongly convex and smooth\nfunctions with Lipschitz continuous Hessians in $d$ dimensions. In many\napplications where such problems arise, including maximum likelihood\nestimation, empirical risk minimization, and unsupervised learning, the number\nof observations $n$ is large, and it becomes necessary to use incremental or\nstochastic algorithms whose per-iteration complexity is independent of $n$. Of\nthese, the incremental/stochastic variants of the Newton method exhibit\nsuperlinear convergence, but incur a per-iteration complexity of $O(d^3)$,\nwhich may be prohibitive in large-scale settings. On the other hand, the\nincremental Quasi-Newton method incurs a per-iteration complexity of $O(d^2)$\nbut its superlinear convergence rate has only been characterized\nasymptotically. This work puts forth the Sharpened Lazy Incremental\nQuasi-Newton (SLIQN) method that achieves the best of both worlds: an explicit\nsuperlinear convergence rate with a per-iteration complexity of $O(d^2)$.\nBuilding upon the recently proposed Sharpened Quasi-Newton method, the proposed\nincremental variant incorporates a hybrid update strategy incorporating both\nclassic and greedy BFGS updates. The proposed lazy update rule distributes the\ncomputational complexity between the iterations, so as to enable a\nper-iteration complexity of $O(d^2)$. Numerical tests demonstrate the\nsuperiority of SLIQN over all other incremental and stochastic Quasi-Newton\nvariants.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:06:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17284","submitter":"Jie Chen","authors":"Tianchun Wang, Farzaneh Mirzazadeh, Xiang Zhang, Jie Chen","title":"GC-Flow: A Graph-Based Flow Network for Effective Clustering","comments":"ICML 2023. Code is available at https://github.com/xztcwang/GCFlow","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph convolutional networks (GCNs) are \\emph{discriminative models} that\ndirectly model the class posterior $p(y|\\mathbf{x})$ for semi-supervised\nclassification of graph data. While being effective, as a representation\nlearning approach, the node representations extracted from a GCN often miss\nuseful information for effective clustering, because the objectives are\ndifferent. In this work, we design normalizing flows that replace GCN layers,\nleading to a \\emph{generative model} that models both the class conditional\nlikelihood $p(\\mathbf{x}|y)$ and the class prior $p(y)$. The resulting neural\nnetwork, GC-Flow, retains the graph convolution operations while being equipped\nwith a Gaussian mixture representation space. It enjoys two benefits: it not\nonly maintains the predictive power of GCN, but also produces well-separated\nclusters, due to the structuring of the representation space. We demonstrate\nthese benefits on a variety of benchmark data sets. Moreover, we show that\nadditional parameterization, such as that on the adjacency matrix used for\ngraph convolutions, yields additional improvement in clustering.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:11:38 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17285","submitter":"Diego Garlaschelli","authors":"Andrea Gabrielli, Valentina Macchiati, Diego Garlaschelli","title":"Critical density for network reconstruction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph physics.data-an q-fin.ST","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The structure of many financial networks is protected by privacy and has to\nbe inferred from aggregate observables. Here we consider one of the most\nsuccessful network reconstruction methods, producing random graphs with desired\nlink density and where the observed constraints (related to the market size of\neach node) are replicated as averages over the graph ensemble, but not in\nindividual realizations. We show that there is a minimum critical link density\nbelow which the method exhibits an `unreconstructability' phase where at least\none of the constraints, while still reproduced on average, is far from its\nexpected value in typical individual realizations. We establish the scaling of\nthe critical density for various theoretical and empirical distributions of\ninterbank assets and liabilities, showing that the threshold differs from the\ncritical densities for the onset of the giant component and of the unique\ncomponent in the graph. We also find that, while dense networks are always\nreconstructable, sparse networks are unreconstructable if their structure is\nhomogeneous, while they can display a crossover to reconstructability if they\nhave an appropriate core-periphery or heterogeneous structure. Since the\nreconstructability of interbank networks is related to market clearing, our\nresults suggest that central bank interventions aimed at lowering the density\nof links should take network structure into account to avoid unintentional\nliquidity crises where the supply and demand of all financial institutions\ncannot be matched simultaneously.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:11:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17286","submitter":"Neil Ernst","authors":"Neil A. Ernst and Martin P. Robillard","title":"A Study of Documentation for Software Architecture","comments":"accepted to EMSE J","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Documentation is an important mechanism for disseminating software\narchitecture knowledge. Software project teams can employ vastly different\nformats for documenting software architecture, from unstructured narratives to\nstandardized documents. We explored to what extent this documentation format\nmay matter to newcomers joining a software project and attempting to understand\nits architecture. We conducted a controlled questionnaire-based study wherein\nwe asked 65 participants to answer software architecture understanding\nquestions using one of two randomly-assigned documentation formats: narrative\nessays, and structured documents. We analyzed the factors associated with\nanswer quality using a Bayesian ordered categorical regression and observed no\nsignificant association between the format of architecture documentation and\nperformance on architecture understanding tasks. Instead, prior exposure to the\nsource code of the system was the dominant factor associated with answer\nquality. We also observed that answers to questions that require applying and\ncreating activities were statistically significantly associated with the use of\nthe system's source code to answer the question, whereas the document format or\nlevel of familiarity with the system were not. Subjective sentiment about the\ndocumentation format was comparable: Although more participants agreed that the\nstructured document was easier to navigate and use for writing code, this\nrelation was not statistically significant. We conclude that, in the limited\nexperimental context studied, our results contradict the hypothesis that the\nformat of architectural documentation matters. We surface two more important\nfactors related to effective use of software architecture documentation: prior\nfamiliarity with the source code, and the type of architectural information\nsought.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:14:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17287","submitter":"Michael Zurel","authors":"Michael Zurel, Cihan Okay, Robert Raussendorf","title":"Simulating quantum computation with magic states: how many \"bits\" for\n  \"it\"?","comments":"10 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A recently introduced classical simulation method for universal quantum\ncomputation with magic states operates by repeated sampling from probability\nfunctions [M. Zurel et al. PRL 260404 (2020)]. This method is closely related\nto sampling algorithms based on Wigner functions, with the important\ndistinction that Wigner functions can take negative values obstructing the\nsampling. Indeed, negativity in Wigner functions has been identified as a\nprecondition for a quantum speed-up. However, in the present method of\nclassical simulation, negativity of quasiprobability functions never arises.\nThis model remains probabilistic for all quantum computations. In this paper,\nwe analyze the amount of classical data that the simulation procedure must\ntrack. We find that this amount is small. Specifically, for any number $n$ of\nmagic states, the number of bits that describe the quantum system at any given\ntime is $2n^2+O(n)$.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:15:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17288","submitter":"Sushovan Majhi","authors":"Sushovan Majhi","title":"Demystifying Latschev's Theorem: Manifold Reconstruction from Noisy Data","comments":"arXiv admin note: substantial text overlap with arXiv:2204.14234","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT math.MG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For a closed Riemannian manifold $\\mathcal{M}$ and a metric space $S$ with a\nsmall Gromov$\\unicode{x2013}$Hausdorff distance to it, Latschev's theorem\nguarantees the existence of a sufficiently small scale $\\beta>0$ at which the\nVietoris$\\unicode{x2013}$Rips complex of $S$ is homotopy equivalent to\n$\\mathcal{M}$. Despite being regarded as a stepping stone to the topological\nreconstruction of Riemannian manifolds from a noisy data, the result is only a\nqualitative guarantee. Until now, it had been elusive how to quantitatively\nchoose such a proximity scale $\\beta$ in order to provide sampling conditions\nfor $S$ to be homotopy equivalent to $\\mathcal{M}$. In this paper, we prove a\nstronger and pragmatic version of Latschev's theorem, facilitating a simple\ndescription of $\\beta$ using the sectional curvatures and convexity radius of\n$\\mathcal{M}$ as the sampling parameters. Our study also delves into the\ntopological recovery of a closed Euclidean submanifold from the\nVietoris$\\unicode{x2013}$Rips complexes of a Hausdorff close Euclidean subset.\nAs already known for \\v{C}ech complexes, we show that\nVietoris$\\unicode{x2013}$Rips complexes also provide topologically faithful\nreconstruction guarantees for submanifolds. In the Euclidean case, our sampling\nconditions$\\unicode{x2014}$using only the reach of the\nsubmanifold$\\unicode{x2014}$turns out to be much simpler than the previously\nknown reconstruction results using weak feature size and\n$\\mu\\unicode{x2013}$reach.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:15:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17289","submitter":"Min Zhu","authors":"Min Zhu, Shihang Feng, Youzuo Lin, Lu Lu","title":"Fourier-DeepONet: Fourier-enhanced deep operator networks for full\n  waveform inversion with improved accuracy, generalizability, and robustness","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG physics.comp-ph physics.geo-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Full waveform inversion (FWI) infers the subsurface structure information\nfrom seismic waveform data by solving a non-convex optimization problem.\nData-driven FWI has been increasingly studied with various neural network\narchitectures to improve accuracy and computational efficiency. Nevertheless,\nthe applicability of pre-trained neural networks is severely restricted by\npotential discrepancies between the source function used in the field survey\nand the one utilized during training. Here, we develop a Fourier-enhanced deep\noperator network (Fourier-DeepONet) for FWI with the generalization of seismic\nsources, including the frequencies and locations of sources. Specifically, we\nemploy the Fourier neural operator as the decoder of DeepONet, and we utilize\nsource parameters as one input of Fourier-DeepONet, facilitating the resolution\nof FWI with variable sources. To test Fourier-DeepONet, we develop two new and\nrealistic FWI benchmark datasets (FWI-F and FWI-L) with varying source\nfrequencies and locations. Our experiments demonstrate that compared with\nexisting data-driven FWI methods, Fourier-DeepONet obtains more accurate\npredictions of subsurface structures in a wide range of source parameters.\nMoreover, the proposed Fourier-DeepONet exhibits superior robustness when\ndealing with noisy inputs or inputs with missing traces, paving the way for\nmore reliable and accurate subsurface imaging across diverse real conditions.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:17:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17290","submitter":"Beatrice Andreolli","authors":"Beatrice Andreolli and Karlheinz Gr\\\"ochenig","title":"Variable Bandwidth via Wilson bases","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce a new concept of variable bandwidth that is based on the\ntruncation of Wilson expansions. For this model we derive both (nonuniform)\nsampling theorems, the complete reconstruction of $f$ from its samples, and\nnecessary density conditions for sampling.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:21:27 GMT"},{"version":"v2","created":"Wed, 31 May 2023 09:53:50 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17291","submitter":"Weiqiao Han","authors":"Ashkan Jasour, Weiqiao Han, and Brian Williams","title":"Convex Risk Bounded Continuous-Time Trajectory Planning and Tube Design\n  in Uncertain Nonconvex Environments","comments":"Accepted by IJRR (extension of RSS 2021 paper arXiv:2106.05489\n  invited to IJRR)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.RO math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we address the trajectory planning problem in uncertain\nnonconvex static and dynamic environments that contain obstacles with\nprobabilistic location, size, and geometry. To address this problem, we provide\na risk bounded trajectory planning method that looks for continuous-time\ntrajectories with guaranteed bounded risk over the planning time horizon. Risk\nis defined as the probability of collision with uncertain obstacles. Existing\napproaches to address risk bounded trajectory planning problems either are\nlimited to Gaussian uncertainties and convex obstacles or rely on\nsampling-based methods that need uncertainty samples and time discretization.\nTo address the risk bounded trajectory planning problem, we leverage the notion\nof risk contours to transform the risk bounded planning problem into a\ndeterministic optimization problem. Risk contours are the set of all points in\nthe uncertain environment with guaranteed bounded risk. The obtained\ndeterministic optimization is, in general, nonlinear and nonconvex time-varying\noptimization. We provide convex methods based on sum-of-squares optimization to\nefficiently solve the obtained nonconvex time-varying optimization problem and\nobtain the continuous-time risk bounded trajectories without time\ndiscretization. The provided approach deals with arbitrary (and known)\nprobabilistic uncertainties, nonconvex and nonlinear, static and dynamic\nobstacles, and is suitable for online trajectory planning problems. In\naddition, we provide convex methods based on sum-of-squares optimization to\nbuild the max-sized tube with respect to its parameterization along the\ntrajectory so that any state inside the tube is guaranteed to have bounded\nrisk.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:21:44 GMT"},{"version":"v2","created":"Sun, 4 Jun 2023 04:28:15 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17292","submitter":"Islam Foniqi","authors":"Yago Antol\\'in, Islam Foniqi","title":"Subgroups of even Artin groups of FC-type","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove a Tits alternative theorem for subgroups of finitely generated even\nArtin groups of FC type (EAFC groups), stating that there exists a finite index\nsubgroup such that every subgroup of it is either finitely generated abelian,\nor maps onto a non-abelian free group. Parabolic subgroups play a key role, and\nwe show that parabolic subgroups of EAFC groups are closed under taking roots.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:28:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17293","submitter":"Arianna Cecco","authors":"Arianna Cecco","title":"A categorical approach to injective envelopes","comments":"With an appendix by David P. Blecher","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore functors between operator space categories, some properties of\nthese functors, and establish relations between objects in these categories and\ntheir images under these functors, in particular regarding injectivity and\ninjective envelopes. We also compare the purely categorical definition of\ninjectivity with the `standard' operator theoretical definition. An appendix by\nD. P. Blecher discusses the unitization of an operator space and its injective\nenvelope.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:35:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17294","submitter":"Adam Stinchcombe","authors":"Teemu Tyni, Adam R Stinchcombe, Spyros Alexakis","title":"A boundary integral equation method for the complete electrode model in\n  electrical impedance tomography with tests on real-world data","comments":"27 pages, 14 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We develop a boundary integral equation-based numerical method to solve for\nthe electrostatic potential in two dimensions, inside a medium with piecewise\nconstant conductivity, where the boundary condition is given by the complete\nelectrode model (CEM). The CEM is seen as the most accurate model of the\nphysical setting where electrodes are placed on the surface of an electrically\nconductive body, and currents are injected through the electrodes and the\nresulting voltages are measured again on these same electrodes. The integral\nequation formulation is based on expressing the electrostatic potential as the\nsolution to a finite number of Laplace equations which are coupled through\nboundary matching conditions. This allows us to re-express the solution in\nterms of single layer potentials; the problem is thus re-cast as a system of\nintegral equations on a finite number of smooth curves. We discuss an adaptive\nmethod for the solution of the resulting system of mildly singular integral\nequations. This solver is both fast and accurate. We then present a numerical\ninverse solver for electrical impedance tomography (EIT) which uses our forward\nsolver at its core. To demonstrate the applicability of our results we test our\nnumerical methods on an open electrical impedance tomography data set provided\nby the Finnish Inverse Problems Society.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:35:13 GMT"},{"version":"v2","created":"Tue, 30 May 2023 13:52:05 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17295","submitter":"Alon Harell","authors":"Alon Harell, Yalda Foroutan, Nilesh Ahuja, Parual Datta, Bhavya\n  Kanzariya, V. Srinivasa Somayaulu, Omesh Tickoo, Anderson de Andrade, Ivan V.\n  Bajic","title":"Rate-Distortion Theory in Coding for Machines and its Application","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent years have seen a tremendous growth in both the capability and\npopularity of automatic machine analysis of images and video. As a result, a\ngrowing need for efficient compression methods optimized for machine vision,\nrather than human vision, has emerged. To meet this growing demand, several\nmethods have been developed for image and video coding for machines.\nUnfortunately, while there is a substantial body of knowledge regarding\nrate-distortion theory for human vision, the same cannot be said of machine\nanalysis. In this paper, we extend the current rate-distortion theory for\nmachines, providing insight into important design considerations of\nmachine-vision codecs. We then utilize this newfound understanding to improve\nseveral methods for learnable image coding for machines. Our proposed methods\nachieve state-of-the-art rate-distortion performance on several computer vision\ntasks such as classification, instance segmentation, and object detection.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:36:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17296","submitter":"Jennifer Freedberg","authors":"J. Freedberg, W. Joe Meese, J. He, D. L. Schlagel, E. Dan Dahlberg, R.\n  L. Orbach","title":"On the Nature of Memory and Rejuvenation in Glassy Systems","comments":"11 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.dis-nn cond-mat.mes-hall cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The memory effect in a single crystal spin glass\n($\\mathrm{Cu}_{0.92}\\mathrm{Mn}_{0.08}$) has been measured using $1\n\\mathrm{Hz}$ ac susceptibility techniques over a reduced temperature range of\n$0.4 - 0.7 \\, T_g$ and a model of the memory effect has been developed. A\ndouble-waiting-time protocol is carried out where the spin glass is first\nallowed to age at a temperature below $T_g$, followed by a second aging at a\nlower temperature after it has fully rejuvenated. The model is based on\ncalculating typical coincidences between the growth of correlated regions at\nthe two temperatures. It accounts for the absolute magnitude of the memory\neffect as a function of both waiting times and temperatures. The data can be\nexplained by the memory loss being a function of the relative change in the\ncorrelated volume at the first waiting temperature because of the growth in the\ncorrelations at the second waiting temperature.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:39:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17297","submitter":"Rishi Sonthalia","authors":"Chinmaya Kausik and Kashvi Srivastava and Rishi Sonthalia","title":"Generalization Error without Independence: Denoising, Linear Regression,\n  and Transfer Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.ST stat.ML stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Studying the generalization abilities of linear models with real data is a\ncentral question in statistical learning. While there exist a limited number of\nprior important works (Loureiro et al. (2021A, 2021B), Wei et al. 2022) that do\nvalidate theoretical work with real data, these works have limitations due to\ntechnical assumptions. These assumptions include having a well-conditioned\ncovariance matrix and having independent and identically distributed data.\nThese assumptions are not necessarily valid for real data. Additionally, prior\nworks that do address distributional shifts usually make technical assumptions\non the joint distribution of the train and test data (Tripuraneni et al. 2021,\nWu and Xu 2020), and do not test on real data.\n  In an attempt to address these issues and better model real data, we look at\ndata that is not I.I.D. but has a low-rank structure. Further, we address\ndistributional shift by decoupling assumptions on the training and test\ndistribution. We provide analytical formulas for the generalization error of\nthe denoising problem that are asymptotically exact. These are used to derive\ntheoretical results for linear regression, data augmentation, principal\ncomponent regression, and transfer learning. We validate all of our theoretical\nresults on real data and have a low relative mean squared error of around 1%\nbetween the empirical risk and our estimated risk.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:41:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17298","submitter":"Robert Hildebrand","authors":"Jamie Fravel, Robert Hildebrand, Nicholas Goedert, Laurel Travis, and\n  Matthew Pierson","title":"Dual Bounds for Redistricting Problems with Non-Convex Objectives","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study optimization models for computational redistricting. We focus\nnonconvex objectives that estimate expected black voter representation,\npolitical representation, and Polsby Popper Compactness. All objectives contain\na sum of convolutions with a ratio of variables. The representation objectives\nare a convolution of a ratio of variables with a cumulative distribution\nfunction of a normal distribution, also known as the probit curve, while the\ncompactness objective has a quadratic complication in the ratio. We extend the\nwork of Validi et al. [30], which develops strong optimization models for\ncontiguity constraints and develop mixed integer linear programming models that\ntightly approximate the nonlinear model, and show that our approach creates\ntight bounds on these optimization problems. We develop novel mixed integer\nlinear relaxations to these nonconvex objectives and demonstrate the\neffectiveness of our approaches on county level data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:54:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17299","submitter":"Vassilis Digalakis Jr.","authors":"Dimitris Bertsimas, Vassilis Digalakis Jr","title":"Improving Stability in Decision Tree Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.AI cs.LG math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Owing to their inherently interpretable structure, decision trees are\ncommonly used in applications where interpretability is essential. Recent work\nhas focused on improving various aspects of decision trees, including their\npredictive power and robustness; however, their instability, albeit\nwell-documented, has been addressed to a lesser extent. In this paper, we take\na step towards the stabilization of decision tree models through the lens of\nreal-world health care applications due to the relevance of stability and\ninterpretability in this space. We introduce a new distance metric for decision\ntrees and use it to determine a tree's level of stability. We propose a novel\nmethodology to train stable decision trees and investigate the existence of\ntrade-offs that are inherent to decision tree models - including between\nstability, predictive power, and interpretability. We demonstrate the value of\nthe proposed methodology through an extensive quantitative and qualitative\nanalysis of six case studies from real-world health care applications, and we\nshow that, on average, with a small 4.6% decrease in predictive power, we gain\na significant 38% improvement in the model's stability.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:00:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17300","submitter":"Erik Johnson","authors":"Erik C. Johnson, Brian S. Robinson, Gautam K. Vallabha, Justin Joyce,\n  Jordan K. Matelsky, Raphael Norman-Tenazas, Isaac Western, Marisel\n  Villafa\\~ne-Delgado, Martha Cervantes, Michael S. Robinette, Arun V. Reddy,\n  Lindsey Kitchell, Patricia K. Rivlin, Elizabeth P. Reilly, Nathan Drenkow,\n  Matthew J. Roos, I-Jeng Wang, Brock A. Wester, William R. Gray-Roncal, Joan\n  A. Hoffmann","title":"Exploiting Large Neuroimaging Datasets to Create Connectome-Constrained\n  Approaches for more Robust, Efficient, and Adaptable Artificial Intelligence","comments":"11 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite the progress in deep learning networks, efficient learning at the\nedge (enabling adaptable, low-complexity machine learning solutions) remains a\ncritical need for defense and commercial applications. We envision a pipeline\nto utilize large neuroimaging datasets, including maps of the brain which\ncapture neuron and synapse connectivity, to improve machine learning\napproaches. We have pursued different approaches within this pipeline\nstructure. First, as a demonstration of data-driven discovery, the team has\ndeveloped a technique for discovery of repeated subcircuits, or motifs. These\nwere incorporated into a neural architecture search approach to evolve network\narchitectures. Second, we have conducted analysis of the heading direction\ncircuit in the fruit fly, which performs fusion of visual and angular velocity\nfeatures, to explore augmenting existing computational models with new insight.\nOur team discovered a novel pattern of connectivity, implemented a new model,\nand demonstrated sensor fusion on a robotic platform. Third, the team analyzed\ncircuitry for memory formation in the fruit fly connectome, enabling the design\nof a novel generative replay approach. Finally, the team has begun analysis of\nconnectivity in mammalian cortex to explore potential improvements to\ntransformer networks. These constraints increased network robustness on the\nmost challenging examples in the CIFAR-10-C computer vision robustness\nbenchmark task, while reducing learnable attention parameters by over an order\nof magnitude. Taken together, these results demonstrate multiple potential\napproaches to utilize insight from neural systems for developing robust and\nefficient machine learning techniques.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:04:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17301","submitter":"Taira Tsuchiya","authors":"Taira Tsuchiya, Shinji Ito, Junya Honda","title":"Stability-penalty-adaptive Follow-the-regularized-leader: Sparsity,\n  Game-dependency, and Best-of-both-worlds","comments":"30 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Adaptivity to the difficulties of a problem is a key property in sequential\ndecision-making problems to broaden the applicability of algorithms.\nFollow-the-Regularized-Leader (FTRL) has recently emerged as one of the most\npromising approaches for obtaining various types of adaptivity in bandit\nproblems. Aiming to further generalize this adaptivity, we develop a generic\nadaptive learning rate, called Stability-Penalty-Adaptive (SPA) learning rate\nfor FTRL. This learning rate yields a regret bound jointly depending on\nstability and penalty of the algorithm, into which the regret of FTRL is\ntypically decomposed. With this result, we establish several algorithms with\nthree types of adaptivity: sparsity, game-dependency, and Best-of-Both-Worlds\n(BOBW). Sparsity frequently appears in real-world problems. However, existing\nsparse multi-armed bandit algorithms with $k$-arms assume that the sparsity\nlevel $s \\leq k$ is known in advance, which is often not the case in real-world\nscenarios. To address this problem, with the help of the new learning rate\nframework, we establish $s$-agnostic algorithms with regret bounds of\n$\\tilde{O}(\\sqrt{sT})$ in the adversarial regime for $T$ rounds, which matches\nthe existing lower bound up to a logarithmic factor. Meanwhile, BOBW algorithms\naim to achieve a near-optimal regret in both the stochastic and adversarial\nregimes. Leveraging the new adaptive learning rate framework and a novel\nanalysis to bound the variation in FTRL output in response to changes in a\nregularizer, we establish the first BOBW algorithm with a sparsity-dependent\nbound. Additionally, we explore partial monitoring and demonstrate that the\nproposed learning rate framework allows us to achieve a game-dependent bound\nand the BOBW simultaneously.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:20:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17302","submitter":"Peter Zeman","authors":"Haiyan Li, Ilia Ponomarenko, Peter Zeman","title":"On the Weisfeiler-Leman dimension of some polyhedral graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $m$ be a positive integer, $X$ a graph with vertex set $\\Omega$, and\n${\\rm WL}_m(X)$ the coloring of the Cartesian $m$-power $\\Omega^m$, obtained by\nthe $m$-dimensional Weisfeiler-Leman algorithm. The ${\\rm WL}$-dimension of the\ngraph $X$ is defined to be the smallest $m$ for which the coloring ${\\rm\nWL}_m(X)$ determines $X$ up to isomorphism. It is known that the ${\\rm\nWL}$-dimension of any planar graph is $2$ or $3$, but no planar graph of ${\\rm\nWL}$-dimension $3$ is known. We prove that the ${\\rm WL}$-dimension of a\npolyhedral (i.e., $3$-connected planar) graph $X$ is at most $2$ if the color\nclasses of the coloring ${\\rm WL}_2(X)$ are the orbits of the componentwise\naction of the group ${\\rm Aut}(X)$ on $\\Omega^2$.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:23:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17303","submitter":"Shantanu Ghosh","authors":"Shantanu Ghosh, Ke Yu, Kayhan Batmanghelich","title":"Distilling BlackBox to Interpretable models for Efficient Transfer\n  Learning","comments":"MICCAI, 2023, Early accept","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Building generalizable AI models is one of the primary challenges in the\nhealthcare domain. While radiologists rely on generalizable descriptive rules\nof abnormality, Neural Network (NN) models suffer even with a slight shift in\ninput distribution (e.g., scanner type). Fine-tuning a model to transfer\nknowledge from one domain to another requires a significant amount of labeled\ndata in the target domain. In this paper, we develop an interpretable model\nthat can be efficiently fine-tuned to an unseen target domain with minimal\ncomputational cost. We assume the interpretable component of NN to be\napproximately domain-invariant. However, interpretable models typically\nunderperform compared to their Blackbox (BB) variants. We start with a BB in\nthe source domain and distill it into a \\emph{mixture} of shallow interpretable\nmodels using human-understandable concepts. As each interpretable model covers\na subset of data, a mixture of interpretable models achieves comparable\nperformance as BB. Further, we use the pseudo-labeling technique from\nsemi-supervised learning (SSL) to learn the concept classifier in the target\ndomain, followed by fine-tuning the interpretable models in the target domain.\nWe evaluate our model using a real-life large-scale chest-X-ray (CXR)\nclassification dataset. The code is available at:\n\\url{https://github.com/batmanlab/MICCAI-2023-Route-interpret-repeat-CXRs}.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:23:48 GMT"},{"version":"v2","created":"Wed, 31 May 2023 22:14:57 GMT"},{"version":"v3","created":"Fri, 2 Jun 2023 19:05:36 GMT"},{"version":"v4","created":"Thu, 8 Jun 2023 06:00:55 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.17304","submitter":"Michael Levit","authors":"Michael Levit, Sarangarajan Parthasarathy, Cem Aksoylar, Mohammad\n  Sadegh Rasooli, Shuangyu Chang","title":"External Language Model Integration for Factorized Neural Transducers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose an adaptation method for factorized neural transducers (FNT) with\nexternal language models. We demonstrate that both neural and n-gram external\nLMs add significantly more value when linearly interpolated with predictor\noutput compared to shallow fusion, thus confirming that FNT forces the\npredictor to act like regular language models. Further, we propose a method to\nintegrate class-based n-gram language models into FNT framework resulting in\naccuracy gains similar to a hybrid setup. We show average gains of 18% WERR\nwith lexical adaptation across various scenarios and additive gains of up to\n60% WERR in one entity-rich scenario through a combination of class-based\nn-gram and neural LMs.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:30:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17305","submitter":"Gabriel Oliveira","authors":"Elahe Rahimian, Golara Javadi, Frederick Tung, Gabriel Oliveira","title":"DynaShare: Task and Instance Conditioned Parameter Sharing for\n  Multi-Task Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-task networks rely on effective parameter sharing to achieve robust\ngeneralization across tasks. In this paper, we present a novel parameter\nsharing method for multi-task learning that conditions parameter sharing on\nboth the task and the intermediate feature representations at inference time.\nIn contrast to traditional parameter sharing approaches, which fix or learn a\ndeterministic sharing pattern during training and apply the same pattern to all\nexamples during inference, we propose to dynamically decide which parts of the\nnetwork to activate based on both the task and the input instance. Our approach\nlearns a hierarchical gating policy consisting of a task-specific policy for\ncoarse layer selection and gating units for individual input instances, which\nwork together to determine the execution path at inference time. Experiments on\nthe NYU v2, Cityscapes and MIMIC-III datasets demonstrate the potential of the\nproposed approach and its applicability across problem domains.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:43:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17306","submitter":"Yao Fu","authors":"Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng and Tushar Khot","title":"Chain-of-Thought Hub: A Continuous Effort to Measure Large Language\n  Models' Reasoning Performance","comments":"Preprint. Code at https://github.com/FranxYao/chain-of-thought-hub","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As large language models (LLMs) are continuously being developed, their\nevaluation becomes increasingly important yet challenging. This work proposes\nChain-of-Thought Hub, an open-source evaluation suite on the multi-step\nreasoning capabilities of large language models. We are interested in this\nsetting for two reasons: (1) from the behavior of GPT and PaLM model family, we\nobserve that complex reasoning is likely to be a key differentiator between\nweaker and stronger LLMs; (2) we envisage large language models to become the\nnext-generation computational platform and foster an ecosystem of LLM-based new\napplications, this naturally requires the foundation models to perform complex\ntasks that often involve the composition of linguistic and logical operations.\nOur approach is to compile a suite of challenging reasoning benchmarks to track\nthe progress of LLMs. Our current results show that: (1) model scale clearly\ncorrelates with reasoning capabilities; (2) As of May 2023, Claude-v1.3 and\nPaLM-2 are the only two models that are comparable with GPT-4, while\nopen-sourced models still lag behind; (3) LLaMA-65B performs closely to\ncode-davinci-002, indicating that with successful further development such as\nreinforcement learning from human feedback (RLHF), it has great potential to be\nclose to GPT-3.5-Turbo. Our results also suggest that for the open-source\nefforts to catch up, the community may focus more on building better base\nmodels and exploring RLHF.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:46:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17307","submitter":"Sijie Gao","authors":"Minghao Xia and Sijie Gao","title":"General Proof of the Tolman law","comments":"4 pages, no figure","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Tolman proposed that the proper temper $T$ of a static self-gravitating fluid\nin thermodynamic equilibrium satisfies the relation $\\chi T=constant$, where\n$\\chi$ is the redshift factor of the spacetime. The Tolman law has been proven\nfor radiation in stationary spacetimes and for perfect fluids in stationary,\nasymototically flat and axisymmetric spacetimes. It is unclear whether the\nproof can be extended to more general cases. In this paper, we prove that under\nsome reasonable conditions, the Tolman law always holds for a perfect fluid in\na stationary spacetime. The key assumption in our proof is that the particle\nnumber density $n$ can not be determined by the energy density $\\rho$ and\npressure $p$ via the equations of state. This is true for many known fluids\nwith the equation of state $p=p(\\rho)$. Then, by requiring that the total\nentropy of the fluid is an extremum for the variation of $n$ with a fixed\nmetric, we prove the Tolman law. In our proof, only the conservations of stress\nenergy and the total particle number are used, and no field equations are\ninvolved. Our work suggests that the Tolman law holds for a generic perfect\nfluid in a stationary spacetime, even beyond general relativity.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:51:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17308","submitter":"Habtom Kahsay Gidey","authors":"Habtom Kahsay Gidey, Peter Hillmann, Andreas Karcher, Alois Knoll","title":"Towards Cognitive Bots: Architectural Research Challenges","comments":null,"journal-ref":"In: Hammer, P., Alirezaie, M., Stranneg{\\aa}rd, C. (eds)\n  Artificial General Intelligence. AGI 2023. Lecture Notes in Computer\n  Science(), vol 13921","doi":"10.1007/978-3-031-33469-6_11","report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Software bots operating in multiple virtual digital platforms must understand\nthe platforms' affordances and behave like human users. Platform affordances or\nfeatures differ from one application platform to another or through a life\ncycle, requiring such bots to be adaptable. Moreover, bots in such platforms\ncould cooperate with humans or other software agents for work or to learn\nspecific behavior patterns. However, present-day bots, particularly chatbots,\nother than language processing and prediction, are far from reaching a human\nuser's behavior level within complex business information systems. They lack\nthe cognitive capabilities to sense and act in such virtual environments,\nrendering their development a challenge to artificial general intelligence\nresearch. In this study, we problematize and investigate assumptions in\nconceptualizing software bot architecture by directing attention to significant\narchitectural research challenges in developing cognitive bots endowed with\ncomplex behavior for operation on information systems. As an outlook, we\npropose alternate architectural assumptions to consider in future bot design\nand bot development frameworks.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:51:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17309","submitter":"Wuming Liu","authors":"Hao Zhu, Yong-Yao Li, Wen-Kai Bai, Yan-Mei Yu, Lin Zhuang, and Wu-Ming\n  Liu","title":"Three-dimensional Isotropic Droplets in Rydberg-dressed Bose Gases","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas physics.atom-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We predict a scheme for the creation of isotropic three-dimensional droplets\nin Rydbeg-dressed Bose gases, which contain both repulsive contact interactions\nand attractive van der Waals interactions causing the quantum fluctuation\neffect non-negligible. We present detailed beyond mean-field calculations with\nLee-Huang-Yang correction and demonstrate the existence of isotropic droplets\nunder realistic experimental conditions. Stable droplets possess flat-top\ndensity distribution, and their chemical potentials decrease with the particle\nnumber expansion towarding a critical value. We distinguish droplets from\nbright solitons through peak density, width of condensate and quantum depletion\ncalculations. We summarize a phase diagram of realizing droplets, and\nsubsequently highlight the stability of droplets by real time evolution as well\nas collisions. Our work provides a novel platform for investigating excitation\nspectrum and superfluid nature of droplets.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 23:57:48 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 02:17:26 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.17310","submitter":"Igor Nunes","authors":"Igor Nunes, Mike Heddes, Pere Verg\\'es, Danny Abraham, Alexander\n  Veidenbaum, Alexandru Nicolau, Tony Givargis","title":"DotHash: Estimating Set Similarity Metrics for Link Prediction and\n  Document Deduplication","comments":null,"journal-ref":null,"doi":"10.1145/3580305.3599314","report-no":null,"categories":"cs.SI cs.DS cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Metrics for set similarity are a core aspect of several data mining tasks. To\nremove duplicate results in a Web search, for example, a common approach looks\nat the Jaccard index between all pairs of pages. In social network analysis, a\nmuch-celebrated metric is the Adamic-Adar index, widely used to compare node\nneighborhood sets in the important problem of predicting links. However, with\nthe increasing amount of data to be processed, calculating the exact similarity\nbetween all pairs can be intractable. The challenge of working at this scale\nhas motivated research into efficient estimators for set similarity metrics.\nThe two most popular estimators, MinHash and SimHash, are indeed used in\napplications such as document deduplication and recommender systems where large\nvolumes of data need to be processed. Given the importance of these tasks, the\ndemand for advancing estimators is evident. We propose DotHash, an unbiased\nestimator for the intersection size of two sets. DotHash can be used to\nestimate the Jaccard index and, to the best of our knowledge, is the first\nmethod that can also estimate the Adamic-Adar index and a family of related\nmetrics. We formally define this family of metrics, provide theoretical bounds\non the probability of estimate errors, and analyze its empirical performance.\nOur experimental results indicate that DotHash is more accurate than the other\nestimators in link prediction and detecting duplicate documents with the same\ncomplexity and similar comparison time.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:05:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17311","submitter":"Yuhui Zhang","authors":"Yuhui Zhang, Michihiro Yasunaga, Zhengping Zhou, Jeff Z. HaoChen,\n  James Zou, Percy Liang, Serena Yeung","title":"Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language\n  Models","comments":"Published at ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language models have been shown to exhibit positive scaling, where\nperformance improves as models are scaled up in terms of size, compute, or\ndata. In this work, we introduce NeQA, a dataset consisting of questions with\nnegation in which language models do not exhibit straightforward positive\nscaling. We show that this task can exhibit inverse scaling, U-shaped scaling,\nor positive scaling, and the three scaling trends shift in this order as we use\nmore powerful prompting methods or model families. We hypothesize that solving\nNeQA depends on two subtasks: question answering (task 1) and negation\nunderstanding (task 2). We find that task 1 has linear scaling, while task 2\nhas sigmoid-shaped scaling with an emergent transition point, and composing\nthese two scaling trends yields the final scaling trend of NeQA. Our work\nreveals and provides a way to analyze the complex scaling trends of language\nmodels.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:07:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17312","submitter":"Muhammad Inam","authors":"Muhammad Inam","title":"The word problem for some classes of Adian inverse semigroups-II","comments":"29 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce the notion of a subgraph generated by an $R$-word $r$ of the\nSch\\\"{u}tzenberger graph of a positive word $w$, $S\\Gamma(w)$, where $w$\ncontains $r$ as its subword. We show that the word problem for a finitely\npresented Adian inverse semigroup $Inv\\langle X|R \\rangle$ is decidable if the\nsubgraphs of $S\\Gamma(t)$, for all $t\\in X^+$, generated by all the $R$-words\nover the presentation $\\langle X|R\\rangle$, are finite. As a consequence of\nthis result, we show that the word problem is decidable for some classes of one\nrelation Adian inverse semigroups.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:16:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17313","submitter":"Rayson Laroca","authors":"Valfride Nascimento, Rayson Laroca, Jorge de A. Lambert, William\n  Robson Schwartz, David Menotti","title":"Super-Resolution of License Plate Images Using Attention Modules and\n  Sub-Pixel Convolution Layers","comments":null,"journal-ref":"Computers & Graphics, vol. 113, pp. 69-76, 2023","doi":"10.1016/j.cag.2023.05.005","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent years have seen significant developments in the field of License Plate\nRecognition (LPR) through the integration of deep learning techniques and the\nincreasing availability of training data. Nevertheless, reconstructing license\nplates (LPs) from low-resolution (LR) surveillance footage remains challenging.\nTo address this issue, we introduce a Single-Image Super-Resolution (SISR)\napproach that integrates attention and transformer modules to enhance the\ndetection of structural and textural features in LR images. Our approach\nincorporates sub-pixel convolution layers (also known as PixelShuffle) and a\nloss function that uses an Optical Character Recognition (OCR) model for\nfeature extraction. We trained the proposed architecture on synthetic images\ncreated by applying heavy Gaussian noise to high-resolution LP images from two\npublic datasets, followed by bicubic downsampling. As a result, the generated\nimages have a Structural Similarity Index Measure (SSIM) of less than 0.10. Our\nresults show that our approach for reconstructing these low-resolution\nsynthesized images outperforms existing ones in both quantitative and\nqualitative measures. Our code is publicly available at\nhttps://github.com/valfride/lpr-rsr-ext/\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:17:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17314","submitter":"Zezhen Sun","authors":"Zezhen Sun","title":"Two nonlocal inverse curvature flows of convex closed plane curves","comments":"14 pages. arXiv admin note: text overlap with arXiv:1408.1805 by\n  other authors","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we introduce two $1/\\kappa^{n}$-type ($n\\ge1$) curvature flows\nfor closed convex planar curves. Along the flows the length of the curve is\ndecreasing while the enclosed area is increasing. And finally, the evolving\ncurves converge smoothly to a finite circle if they do not develop singularity\nduring the evolution process.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:20:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17315","submitter":"Mohammad Hesam Soleimani-Babakamali","authors":"Shuochuan Meng, Mohammad Hesam Soleimani-Babakamali, Ertugrul\n  Taciroglu","title":"Automatic Roof Type Classification Through Machine Learning for Regional\n  Wind Risk Assessment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Roof type is one of the most critical building characteristics for wind\nvulnerability modeling. It is also the most frequently missing building feature\nfrom publicly available databases. An automatic roof classification framework\nis developed herein to generate high-resolution roof-type data using machine\nlearning. A Convolutional Neural Network (CNN) was trained to classify roof\ntypes using building-level satellite images. The model achieved an F1 score of\n0.96 on predicting roof types for 1,000 test buildings. The CNN model was then\nused to predict roof types for 161,772 single-family houses in New Hanover\nCounty, NC, and Miami-Dade County, FL. The distribution of roof type in city\nand census tract scales was presented. A high variance was observed in the\ndominant roof type among census tracts. To improve the completeness of the\nroof-type data, imputation algorithms were developed to populate missing roof\ndata due to low-quality images, using critical building attributes and\nneighborhood-level roof characteristics.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:36:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17316","submitter":"Fayin Wang","authors":"Qin Wu, Zhen-Yin Zhao, F. Y. Wang (NJU)","title":"Tidal capture of an asteroid by a magnetar: FRB-like bursts, glitch and\n  anti-glitch","comments":"6 pages, 1 figure, published by MNRAS\n  https://doi.org/10.1093/mnras/stad1585","journal-ref":null,"doi":"10.1093/mnras/stad1585","report-no":null,"categories":"astro-ph.HE astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Recently, remarkable anti-glitch and glitch accompanied by bright radio\nbursts of the Galactic magnetar SGR J1935+2154 were discovered. These two\ninfrequent temporal coincidences between the glitch/anti-glitch and the fast\nradio burst (FRB)-like bursts reveal their physical connection of them. Here we\npropose that the anti-glitch/glitch and FRB-like bursts can be well understood\nby an asteroid tidally captured by a magnetar. In this model, an asteroid is\ntidally captured and disrupted by a magnetar. Then, the disrupted asteroid will\ntransfer the angular momentum to the magnetar producing a sudden change in the\nmagnetar rotational frequency at the magnetosphere radius. If the orbital\nangular momentum of the asteroid is parallel (or anti-parallel) to that of the\nspinning magnetar, a glitch (or anti-glitch) will occur. Subsequently, the\nbound asteroid materials fall back to the pericenter and eventually are\naccreted to the surface of the magnetar. Massive fragments of the asteroid\ncross magnetic field lines and produce bright radio bursts through coherent\ncurvature radiation. Our model can explain the sudden magnetar spin changes and\nFRB-like bursts in a unified way.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:38:07 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.17317","submitter":"Allison Sullivan","authors":"Allison Sullivan","title":"Live Programming for Finite Model Finders","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.FL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Finite model finders give users the ability to specify properties of a system\nin mathematical logic and then automatically find concrete examples, called\nsolutions, that satisfy the properties. These solutions are often viewed as a\nkey benefit of model finders, as they create an exploratory environment for\ndevelopers to engage with their model. In practice, users find less benefit\nfrom these solutions than expected. For years, researchers believed that the\nproblem was that too many solutions are produced. However, a recent user study\nfound that users actually prefer enumerating a broad set of solutions. Inspired\nby a recent user study on Alloy, a modeling language backed by a finite model\nfinder, we believe that the issue is that solutions are too removed from the\nlogical constraints that generate them to help users build an understanding of\nthe constraints themselves. In this paper, we outline a proof-of-concept for\nlive programming of Alloy models in which writing the model and exploring\nsolutions are intertwined. We highlight how this development environment\nenables more productive feedback loops between the developer, the model and the\nsolutions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:46:31 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17318","submitter":"Can Cui","authors":"Can Cui, Yunsheng Ma, Juanwu Lu and Ziran Wang","title":"Radar Enlighten the Dark: Enhancing Low-Visibility Perception for\n  Automated Vehicles with Camera-Radar Fusion","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sensor fusion is a crucial augmentation technique for improving the accuracy\nand reliability of perception systems for automated vehicles under diverse\ndriving conditions. However, adverse weather and low-light conditions remain\nchallenging, where sensor performance degrades significantly, exposing vehicle\nsafety to potential risks. Advanced sensors such as LiDARs can help mitigate\nthe issue but with extremely high marginal costs. In this paper, we propose a\nnovel transformer-based 3D object detection model \"REDFormer\" to tackle low\nvisibility conditions, exploiting the power of a more practical and\ncost-effective solution by leveraging bird's-eye-view camera-radar fusion.\nUsing the nuScenes dataset with multi-radar point clouds, weather information,\nand time-of-day data, our model outperforms state-of-the-art (SOTA) models on\nclassification and detection accuracy. Finally, we provide extensive ablation\nstudies of each model component on their contributions to address the\nabove-mentioned challenges. Particularly, it is shown in the experiments that\nour model achieves a significant performance improvement over the baseline\nmodel in low-visibility scenarios, specifically exhibiting a 31.31% increase in\nrainy scenes and a 46.99% enhancement in nighttime scenes.The source code of\nthis study is publicly available.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:47:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17319","submitter":"Michael Feffer","authors":"Michael Feffer, Hoda Heidari, and Zachary C. Lipton","title":"Moral Machine or Tyranny of the Majority?","comments":"To appear in the proceedings of AAAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.AI cs.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With Artificial Intelligence systems increasingly applied in consequential\ndomains, researchers have begun to ask how these systems ought to act in\nethically charged situations where even humans lack consensus. In the Moral\nMachine project, researchers crowdsourced answers to \"Trolley Problems\"\nconcerning autonomous vehicles. Subsequently, Noothigattu et al. (2018)\nproposed inferring linear functions that approximate each individual's\npreferences and aggregating these linear models by averaging parameters across\nthe population. In this paper, we examine this averaging mechanism, focusing on\nfairness concerns in the presence of strategic effects. We investigate a simple\nsetting where the population consists of two groups, with the minority\nconstituting an {\\alpha} < 0.5 share of the population. To simplify the\nanalysis, we consider the extreme case in which within-group preferences are\nhomogeneous. Focusing on the fraction of contested cases where the minority\ngroup prevails, we make the following observations: (a) even when all parties\nreport their preferences truthfully, the fraction of disputes where the\nminority prevails is less than proportionate in {\\alpha}; (b) the degree of\nsub-proportionality grows more severe as the level of disagreement between the\ngroups increases; (c) when parties report preferences strategically, pure\nstrategy equilibria do not always exist; and (d) whenever a pure strategy\nequilibrium exists, the majority group prevails 100% of the time. These\nfindings raise concerns about stability and fairness of preference vector\naveraging as a mechanism for aggregating diverging voices. Finally, we discuss\nalternatives, including randomized dictatorship and median-based mechanisms.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:49:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17320","submitter":"Joaquim Dias Garcia","authors":"Joaquim Dias Garcia, Guilherme Bodin, Alexandre Street","title":"Comparing BilevelJuMP.jl Formulations: Support Vector Regression\n  Hyperparameter Tuning","comments":"arXiv admin note: substantial text overlap with arXiv:2205.02307","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this technical report, we compare multiple reformulation techniques and\nsolvers that can be used with the Julia package BilevelJuMP. We focus on the\nspecial case of Hyperparameter Tuning for Support Vector Regression. We\ndescribe a bilevel model for the problem in question. Then we present code for\ngenerating data and models that solve the problem. Finally, we present results\nand a brief analysis.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 01:16:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17321","submitter":"Fl\\'avio Rocha","authors":"Fl\\'avio G. C. Rocha, Gabriel M. F. de Almeida, Kleber V. Cardoso,\n  Cristiano B. Both, and Jos\\'e F. de Rezende","title":"Optimal Resource Allocation with Delay Guarantees for Network Slicing in\n  Disaggregated RAN","comments":"21 pages, 10 figures. For the associated GitHub repository, see\n  https://github.com/LABORA-INF-UFG/paper-FGKCJ-2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we propose a novel formulation for the resource allocation\nproblem of a sliced and disaggregated Radio Access Network (RAN) and its\ntransport network. Our proposal assures an end-to-end delay bound for the\nUltra-Reliable and Low-Latency Communication (URLLC) use case while jointly\nconsidering the number of admitted users, the transmission rate allocation per\nslice, the functional split of RAN nodes and the routing paths in the transport\nnetwork. We use deterministic network calculus theory to calculate delay along\nthe transport network connecting disaggregated RANs deploying network functions\nat the Radio Unit (RU), Distributed Unit (DU), and Central Unit (CU) nodes. The\nmaximum end-to-end delay is a constraint in the optimization-based formulation\nthat aims to maximize Mobile Network Operator (MNO) profit, considering a cash\nflow analysis to model revenue and operational costs using data from one of the\nworld's leading MNOs. The optimization model leverages a Flexible Functional\nSplit (FFS) approach to provide a new degree of freedom to the resource\nallocation strategy. Simulation results reveal that, due to its non-linear\nnature, there is no trivial solution to the proposed optimization problem\nformulation. Our proposal guarantees a maximum delay for URLLC services while\nsatisfying minimal bandwidth requirements for enhanced Mobile BroadBand (eMBB)\nservices and maximizing the MNO's profit.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 01:34:37 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 04:09:50 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17322","submitter":"Zi-Ang Hu","authors":"Zi-Ang Hu, Bo Fu, Xiao Li, and Shun-Qing Shen","title":"A Solvable Model for Discrete Time Crystal Enforced by Nonsymmorphic\n  Dynamical Symmetry","comments":"5 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Discrete time crystal is a class of nonequilibrium quantum systems exhibiting\nsubharmonic responses to external periodic driving. Here we propose a class of\ndiscrete time crystals enforced by nonsymmorphic dynamical symmetry. We start\nwith a system with nonsymmorphic dynamical symmetry, in which the instantaneous\neigenstates become M\\\"obius twisted, hence doubling the period of the\ninstantaneous state. The exact solution of the time-dependent Schr\\\"odinger\nequation shows that the system spontaneously exhibits a period extension\nwithout undergoing quantum superposition states for a series of specifc\nevolution frequencies or in the limit of long evolution period. Moreover, in\nsuch case the system gains a {\\pi} Berry phase after two periods' evolution.\nFinally, we show that the subharmonic response is stable even when many-body\ninteractions are introduced, indicating a DTC phase in the thermodynamic limit.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 01:51:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17323","submitter":"Benjamin Grimmer","authors":"Benjamin Grimmer, Danlin Li","title":"Some Primal-Dual Theory for Subgradient Methods for Strongly Convex\n  Optimization","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider (stochastic) subgradient methods for strongly convex but\npotentially nonsmooth non-Lipschitz optimization. We provide new equivalent\ndual descriptions (in the style of dual averaging) for the classic subgradient\nmethod, the proximal subgradient method, and the switching subgradient method.\nThese equivalences enable $O(1/T)$ convergence guarantees in terms of both\ntheir classic primal gap and a not previously analyzed dual gap for strongly\nconvex optimization. Consequently, our theory provides these classic methods\nwith simple, optimal stopping criteria and optimality certificates at no added\ncomputational cost. Our results apply under nearly any stepsize selection and\nfor a range of non-Lipschitz ill-conditioned problems where the early\niterations of the subgradient method may diverge exponentially quickly (a\nphenomenon which, to the best of our knowledge, no prior works address). Even\nin the presence of such undesirable behaviors, our theory still ensures and\nbounds eventual convergence.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 01:56:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17324","submitter":"Soham Mandal","authors":"Soham Mandal, Paul C. Duffell, Abigail Polin, Dan Milisavljevic","title":"A 3D Numerical Study of Anisotropies in Supernova Remnants","comments":"10 pages, 8 figures; submitted to ApJ. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE physics.flu-dyn","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We develop a suite of 3D hydrodynamic models of supernova remnants (SNRs)\nexpanding against the circumstellar medium (CSM). We study the Rayleigh-Taylor\nInstability (RTI) forming at the expansion interface by calculating an angular\npower spectrum for each of these models. The power spectra of young SNRs is\nseen to exhibit a dominant angular mode, which is a diagnostic of their ejecta\ndensity profile as found by previous studies. The steep scaling of power at\nsmaller modes and the time evolution of the spectra is indicative of absence of\na turbulent cascade. Instead, as the time evolution of the spectra suggests,\nthey may be governed by an angular mode dependent net growth rate. We also\nstudy the impact of anisotropies in the ejecta as well as in the CSM on the\npower spectra of velocity and density. We confirm that perturbations in the\ndensity field (whether imposed on the ejecta or the CSM) do not influence the\nanisotropy of the remnant significantly unless they have a very large amplitude\nand form large-scale coherent structures. In any case, these clumps can only\naffect structures on large angular scales. The power spectra on small angular\nscales is completely independent of the initial clumpiness and only governed by\nthe growth and saturation of the Rayleigh-Taylor instability.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 01:56:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17325","submitter":"Tianjian Li","authors":"Tianjian Li and Kenton Murray","title":"Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a\n  Solution","comments":"Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Zero-shot cross-lingual transfer is when a multilingual model is trained to\nperform a task in one language and then is applied to another language.\nAlthough the zero-shot cross-lingual transfer approach has achieved success in\nvarious classification tasks, its performance on natural language generation\ntasks falls short in quality and sometimes outputs an incorrect language. In\nour study, we show that the fine-tuning process learns language invariant\nrepresentations, which is beneficial for classification tasks but harmful for\ngeneration tasks. Motivated by this, we propose a simple method to regularize\nthe model from learning language invariant representations and a method to\nselect model checkpoints without a development set in the target language, both\nresulting in better generation quality. Experiments on three semantically\ndiverse generation tasks show that our method reduces the accidental\ntranslation problem by 68% and improves the ROUGE-L score by 1.5 on average.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:04:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17326","submitter":"Yifan Zhang","authors":"Yifan Zhang, Zhiquan Tan, Jingqin Yang, Yang Yuan","title":"Kernel-SSL: Kernel KL Divergence for Self-Supervised Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Contrastive learning usually compares one positive anchor sample with lots of\nnegative samples to perform Self-Supervised Learning (SSL). Alternatively,\nnon-contrastive learning, as exemplified by methods like BYOL, SimSiam, and\nBarlow Twins, accomplishes SSL without the explicit use of negative samples.\nInspired by the existing analysis for contrastive learning, we provide a\nreproducing kernel Hilbert space (RKHS) understanding of many existing\nnon-contrastive learning methods. Subsequently, we propose a novel loss\nfunction, Kernel-SSL, which directly optimizes the mean embedding and the\ncovariance operator within the RKHS. In experiments, our method Kernel-SSL\noutperforms state-of-the-art methods by a large margin on ImageNet datasets\nunder the linear evaluation settings. Specifically, when performing 100 epochs\npre-training, our method outperforms SimCLR by 4.6%.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:04:25 GMT"},{"version":"v2","created":"Tue, 30 May 2023 15:00:30 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17327","submitter":"Jiayu Chen","authors":"Jiayu Chen, Tian Lan, Vaneet Aggarwal","title":"Hierarchical Deep Counterfactual Regret Minimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Imperfect Information Games (IIGs) offer robust models for scenarios where\ndecision-makers face uncertainty or lack complete information. Counterfactual\nRegret Minimization (CFR) has been one of the most successful family of\nalgorithms for tackling IIGs. The integration of skill-based strategy learning\nwith CFR could potentially enhance learning performance for complex IIGs. For\nthis, a hierarchical strategy needs to be learnt, wherein low-level components\nrepresent specific skills and the high-level component manages the transition\nbetween skills. This hierarchical approach also enhances interpretability,\nhelping humans pinpoint scenarios where the agent is struggling and intervene\nwith targeted expertise. This paper introduces the first hierarchical version\nof Deep CFR (HDCFR), an innovative method that boosts learning efficiency in\ntasks involving extensively large state spaces and deep game trees. A notable\nadvantage of HDCFR over previous research in this field is its ability to\nfacilitate learning with predefined (human) expertise and foster the\nacquisition of transferable skills that can be applied to similar tasks. To\nachieve this, we initially construct our algorithm on a tabular setting,\nencompassing hierarchical CFR updating rules and a variance-reduced Monte-Carlo\nsampling extension, and offer its essential theoretical guarantees. Then, to\nadapt our algorithm for large-scale applications, we employ neural networks as\nfunction approximators and suggest deep learning objectives that coincide with\nthose in the tabular setting while maintaining the theoretical outcomes.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:05:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17328","submitter":"Hongjie Wang","authors":"Hongjie Wang, Bhishma Dedhia, Niraj K. Jha","title":"Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention\n  Graph in Pre-Trained Transformers","comments":"20 pages, 18 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deployment of Transformer models on the edge is increasingly challenging due\nto the exponentially growing model size and inference cost that scales\nquadratically with the number of tokens in the input sequence. Token pruning is\nan emerging solution to address this challenge due to its ease of deployment on\nvarious Transformer backbones. However, most token pruning methods require a\ncomputationally-expensive fine-tuning process after or during pruning, which is\nnot desirable in many cases. Some recent works explore pruning of off-the-shelf\npre-trained Transformers without fine-tuning. However, they only take the\nimportance of tokens into consideration. In this work, we propose Zero-TPrune,\nthe first zero-shot method that considers both the importance and similarity of\ntokens in performing token pruning. Zero-TPrune leverages the attention graph\nof pre-trained Transformer models to produce an importance rank for tokens and\nremoves the less informative tokens. The attention matrix can be thought of as\nan adjacency matrix of a directed graph, to which a graph shift operator can be\napplied iteratively to obtain the importance score distribution. This\ndistribution guides the partition of tokens into two groups and measures\nsimilarity between them. Due to the elimination of the fine-tuning overhead,\nZero-TPrune can easily prune large models and perform hyperparameter tuning\nefficiently. We evaluate the performance of Zero-TPrune on vision tasks by\napplying it to various vision Transformer backbones. Compared with\nstate-of-the-art pruning methods that require fine-tuning, Zero-TPrune not only\neliminates the need for fine-tuning after pruning, but does so with only around\n0.3% accuracy loss. Compared with state-of-the-art fine-tuning-free pruning\nmethods, Zero-TPrune reduces accuracy loss by up to 45% on medium-sized models.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:08:51 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17329","submitter":"Takeshi Suzuki","authors":"Takeshi Suzuki, Yuya Kubota, Natsuki Mitsuishi, Shunsuke Akatsuka,\n  Jumpei Koga, Masato Sakano, Satoru Masubuchi, Yoshikazu Tanaka, Tadashi\n  Togashi, Hiroyuki Ohsumi, Kenji Tamasaku, Makina Yabashi, Hidefumi Takahashi,\n  Shintaro Ishiwata, Tomoki Machida, Iwao Matsuda, Kyoko Ishizaka, Kozo Okazaki","title":"Ultrafast Control of Crystal Structure in a Topological\n  Charge-Density-Wave Material","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Optical control of crystal structures is a promising route to change physical\nproperties including topological nature of a targeting material. Time-resolved\nX-ray diffraction measurements using the X-ray free-electron laser are\nperformed to study the ultrafast lattice dynamics of VTe$_2$, which shows a\nunique charge-density-wave (CDW) ordering coupled to the topological surface\nstates as a first-order phase transition. A significant oscillation of the CDW\namplitude mode is observed at a superlattice reflection as well as Bragg\nreflections. The frequency of the oscillation is independent of the fluence of\nthe pumping laser, which is prominent to the CDW ordering of the first-order\nphase transition. Furthermore, the timescale of the photoinduced\n1$T^{\\prime\\prime}$ to 1$T$ phase transition is independent of the period of\nthe CDW amplitude mode.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:13:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17330","submitter":"Zhengbang Zhu","authors":"Zhengbang Zhu, Minghuan Liu, Liyuan Mao, Bingyi Kang, Minkai Xu, Yong\n  Yu, Stefano Ermon, Weinan Zhang","title":"MADiff: Offline Multi-agent Learning with Diffusion Models","comments":"17 pages, 7 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Diffusion model (DM), as a powerful generative model, recently achieved huge\nsuccess in various scenarios including offline reinforcement learning, where\nthe policy learns to conduct planning by generating trajectory in the online\nevaluation. However, despite the effectiveness shown for single-agent learning,\nit remains unclear how DMs can operate in multi-agent problems, where agents\ncan hardly complete teamwork without good coordination by independently\nmodeling each agent's trajectories. In this paper, we propose MADiff, a novel\ngenerative multi-agent learning framework to tackle this problem. MADiff is\nrealized with an attention-based diffusion model to model the complex\ncoordination among behaviors of multiple diffusion agents. To the best of our\nknowledge, MADiff is the first diffusion-based multi-agent offline RL\nframework, which behaves as both a decentralized policy and a centralized\ncontroller, which includes opponent modeling and can be used for multi-agent\ntrajectory prediction. MADiff takes advantage of the powerful generative\nability of diffusion while well-suited in modeling complex multi-agent\ninteractions. Our experiments show the superior performance of MADiff compared\nto baseline algorithms in a range of multi-agent learning tasks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:14:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17331","submitter":"Zichun Yu","authors":"Zichun Yu, Chenyan Xiong, Shi Yu and Zhiyuan Liu","title":"Augmentation-Adapted Retriever Improves Generalization of Language\n  Models as Generic Plug-In","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Retrieval augmentation can aid language models (LMs) in knowledge-intensive\ntasks by supplying them with external information. Prior works on retrieval\naugmentation usually jointly fine-tune the retriever and the LM, making them\nclosely coupled. In this paper, we explore the scheme of generic retrieval\nplug-in: the retriever is to assist target LMs that may not be known beforehand\nor are unable to be fine-tuned together. To retrieve useful documents for\nunseen target LMs, we propose augmentation-adapted retriever (AAR), which\nlearns LM's preferences obtained from a known source LM. Experiments on the\nMMLU and PopQA datasets demonstrate that our AAR trained with a small source LM\nis able to significantly improve the zero-shot generalization of larger target\nLMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates\nthat the preferences of different LMs overlap, enabling AAR trained with a\nsingle source LM to serve as a generic plug-in for various target LMs. Our code\nis open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:26:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17332","submitter":"Daiwei Chen","authors":"Daiwei Chen, Weikai Chang, Pratik Chaudhari","title":"Learning Capacity: A Measure of the Effective Dimensionality of a Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We exploit a formal correspondence between thermodynamics and inference,\nwhere the number of samples can be thought of as the inverse temperature, to\ndefine a \"learning capacity'' which is a measure of the effective\ndimensionality of a model. We show that the learning capacity is a tiny\nfraction of the number of parameters for many deep networks trained on typical\ndatasets, depends upon the number of samples used for training, and is\nnumerically consistent with notions of capacity obtained from the PAC-Bayesian\nframework. The test error as a function of the learning capacity does not\nexhibit double descent. We show that the learning capacity of a model saturates\nat very small and very large sample sizes; this provides guidelines, as to\nwhether one should procure more data or whether one should search for new\narchitectures, to improve performance. We show how the learning capacity can be\nused to understand the effective dimensionality, even for non-parametric models\nsuch as random forests and $k$-nearest neighbor classifiers.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:27:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17333","submitter":"Tianyu Gao","authors":"Sadhika Malladi, Tianyu Gao, Eshaan Nichani, Alex Damian, Jason D.\n  Lee, Danqi Chen, Sanjeev Arora","title":"Fine-Tuning Language Models with Just Forward Passes","comments":"Code available at https://github.com/princeton-nlp/MeZO","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Fine-tuning language models (LMs) has yielded success on diverse downstream\ntasks, but as LMs grow in size, backpropagation requires a prohibitively large\namount of memory. Zeroth-order (ZO) methods can in principle estimate gradients\nusing only two forward passes but are theorized to be catastrophically slow for\noptimizing large models. In this work, we propose a memory-efficient\nzerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate\nin-place, thereby fine-tuning LMs with the same memory footprint as inference.\nFor example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter\nmodel, whereas fine-tuning with backpropagation can train only a 2.7B LM with\nthe same budget. We conduct comprehensive experiments across model types\n(masked and autoregressive LMs), model scales (up to 66B), and downstream tasks\n(classification, multiple-choice, and generation). Our results demonstrate that\n(1) MeZO significantly outperforms in-context learning and linear probing; (2)\nMeZO achieves comparable performance to fine-tuning with backpropagation across\nmultiple tasks, with up to 12x memory reduction; (3) MeZO is compatible with\nboth full-parameter and parameter-efficient tuning techniques such as LoRA and\nprefix tuning; (4) MeZO can effectively optimize non-differentiable objectives\n(e.g., maximizing accuracy or F1). We support our empirical findings with\ntheoretical insights, highlighting how adequate pre-training and task prompts\nenable MeZO to fine-tune huge models, despite classical ZO analyses suggesting\notherwise.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:28:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17334","submitter":"Youngtak Sohn","authors":"Allan Sly, Youngtak Sohn","title":"Local geometry of NAE-SAT solutions in the condensation regime","comments":"43 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR cond-mat.dis-nn cs.DM math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The local behavior of typical solutions of random constraint satisfaction\nproblems (CSP) describes many important phenomena including clustering\nthresholds, decay of correlations, and the behavior of message passing\nalgorithms. When the constraint density is low, studying the planted model is a\npowerful technique for determining this local behavior which in many examples\nhas a simple Markovian structure. Work of Coja-Oghlan, Kapetanopoulos, Muller\n(2020) showed that for a wide class of models, this description applies up to\nthe so-called condensation threshold.\n  Understanding the local behavior after the condensation threshold is more\ncomplex due to long-range correlations. In this work, we revisit the random\nregular NAE-SAT model in the condensation regime and determine the local weak\nlimit which describes a random solution around a typical variable. This limit\nexhibits a complicated non-Markovian structure arising from the space of\nsolutions being dominated by a small number of large clusters, a result\nrigorously verified by Nam, Sly, Sohn (2021). This is the first\ncharacterization of the local weak limit in the condensation regime for any\nsparse random CSPs in the so-called one-step replica symmetry breaking (1RSB)\nclass.\n  Our result is non-asymptotic, and characterizes the tight fluctuation\n$O(n^{-1/2})$ around the limit. Our proof is based on coupling the local\nneighborhoods of an infinite spin system, which encodes the structure of the\nclusters, to a broadcast model on trees whose channel is given by the 1RSB\nbelief-propagation fixed point. We believe that our proof technique has broad\napplicability to random CSPs in the 1RSB class.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:29:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17335","submitter":"Chen Hu","authors":"Chen Hu, Mit H. Naik, Yang-Hao Chan, Steven G. Louie","title":"Excitonic interactions and mechanism for ultrafast interlayer\n  photoexcited response in van der Waals heterostructures","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Optical dynamics in van der Waals heterobilayers is of fundamental scientific\nand practical interest. Based on a time-dependent adiabatic GW approach, we\ndiscover a new many-electron (excitonic) channel for converting photoexcited\nintralayer to interlayer excitations and the associated ultrafast optical\nresponses in heterobilayers, which is conceptually different from the\nconventional single-particle picture. We find strong electron-hole interactions\ndrive the dynamics and enhance the pump-probe optical responses by an order of\nmagnitude with a rise time of ~300 fs in MoSe$_2$/WSe$_2$ heterobilayers, in\nagreement with experiment.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:30:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17336","submitter":"Matt Menickelly","authors":"Matt Menickelly","title":"Avoiding Geometry Improvement in Derivative-Free Model-Based Methods via\n  Randomization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a technique for model-based derivative-free optimization called\n\\emph{basis sketching}. Basis sketching consists of taking random sketches of\nthe Vandermonde matrix employed in constructing an interpolation model. This\nrandomization enables weakening the general requirement in model-based\nderivative-free methods that interpolation sets contain a full-dimensional set\nof affinely independent points in every iteration. Practically, this weakening\nprovides a theoretically justified means of avoiding potentially expensive\ngeometry improvement steps in many model-based derivative-free methods. We\ndemonstrate this practicality by extending the nonlinear least squares solver,\n\\texttt{POUNDers} to a variant that employs basis sketching and we observe\nencouraging results on higher dimensional problems.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:34:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17337","submitter":"Sijia Wang","authors":"Sijia Wang, Alexander Hanbo Li, Henry Zhu, Sheng Zhang, Chung-Wei\n  Hang, Pramuditha Perera, Jie Ma, William Wang, Zhiguo Wang, Vittorio\n  Castelli, Bing Xiang, Patrick Ng","title":"Benchmarking Diverse-Modal Entity Linking with Generative Models","comments":"15 pages. ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Entities can be expressed in diverse formats, such as texts, images, or\ncolumn names and cell values in tables. While existing entity linking (EL)\nmodels work well on per modality configuration, such as text-only EL, visual\ngrounding, or schema linking, it is more challenging to design a unified model\nfor diverse modality configurations. To bring various modality configurations\ntogether, we constructed a benchmark for diverse-modal EL (DMEL) from existing\nEL datasets, covering all three modalities including text, image, and table. To\napproach the DMEL task, we proposed a generative diverse-modal model (GDMM)\nfollowing a multimodal-encoder-decoder paradigm. Pre-training \\Model with rich\ncorpora builds a solid foundation for DMEL without storing the entire KB for\ninference. Fine-tuning GDMM builds a stronger DMEL baseline, outperforming\nstate-of-the-art task-specific EL models by 8.51 F1 score on average.\nAdditionally, extensive error analyses are conducted to highlight the\nchallenges of DMEL, facilitating future research on this task.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:38:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17338","submitter":"Md Abulkalam Azad","authors":"Md Abulkalam Azad, Ahmed Mohammed, Maryna Waszak, Brian Elves{\\ae}ter\n  and Martin Ludvigsen","title":"Multi-label Video Classification for Underwater Ship Inspection","comments":"Accepted to be presented at OCEANS 2023 Limerick conference and will\n  be published by IEEE","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Today ship hull inspection including the examination of the external coating,\ndetection of defects, and other types of external degradation such as corrosion\nand marine growth is conducted underwater by means of Remotely Operated\nVehicles (ROVs). The inspection process consists of a manual video analysis\nwhich is a time-consuming and labor-intensive process. To address this, we\npropose an automatic video analysis system using deep learning and computer\nvision to improve upon existing methods that only consider spatial information\non individual frames in underwater ship hull video inspection. By exploring the\nbenefits of adding temporal information and analyzing frame-based classifiers,\nwe propose a multi-label video classification model that exploits the\nself-attention mechanism of transformers to capture spatiotemporal attention in\nconsecutive video frames. Our proposed method has demonstrated promising\nresults and can serve as a benchmark for future research and development in\nunderwater video inspection applications.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:38:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17339","submitter":"Martin Saveski","authors":"Martin Saveski, Steven Jecmen, Nihar B. Shah, Johan Ugander","title":"Counterfactual Evaluation of Peer-Review Assignment Policies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.DL stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Peer review assignment algorithms aim to match research papers to suitable\nexpert reviewers, working to maximize the quality of the resulting reviews. A\nkey challenge in designing effective assignment policies is evaluating how\nchanges to the assignment algorithm map to changes in review quality. In this\nwork, we leverage recently proposed policies that introduce randomness in\npeer-review assignment--in order to mitigate fraud--as a valuable opportunity\nto evaluate counterfactual assignment policies. Specifically, we exploit how\nsuch randomized assignments provide a positive probability of observing the\nreviews of many assignment policies of interest. To address challenges in\napplying standard off-policy evaluation methods, such as violations of\npositivity, we introduce novel methods for partial identification based on\nmonotonicity and Lipschitz smoothness assumptions for the mapping between\nreviewer-paper covariates and outcomes. We apply our methods to peer-review\ndata from two computer science venues: the TPDP'21 workshop (95 papers and 35\nreviewers) and the AAAI'22 conference (8,450 papers and 3,145 reviewers). We\nconsider estimates of (i) the effect on review quality when changing weights in\nthe assignment algorithm, e.g., weighting reviewers' bids vs. textual\nsimilarity (between the review's past papers and the submission), and (ii) the\n\"cost of randomization\", capturing the difference in expected quality between\nthe perturbed and unperturbed optimal match. We find that placing higher weight\non text similarity results in higher review quality and that introducing\nrandomization in the reviewer-paper assignment only marginally reduces the\nreview quality. Our methods for partial identification may be of independent\ninterest, while our off-policy approach can likely find use evaluating a broad\nclass of algorithmic matching systems.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:40:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17340","submitter":"Hui Ouyang","authors":"Hui Ouyang","title":"Alternating Proximity Mapping Method for Convex-Concave Saddle-Point\n  Problems","comments":"I misunderstood my coworker. We are doing some related work, so this\n  manuscript is not necessary","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We proposed an iterate scheme for solving convex-concave saddle-point\nproblems associated with general convex-concave functions. We demonstrated that\nwhen our iterate scheme is applied to a special class of convex-concave\nfunctions, which are constructed by a bilinear coupling term plus a difference\nof two convex functions, it becomes a generalization of several popular\nprimal-dual algorithms from constant involved parameters to involved parameters\nas general sequences. For this specific class of convex-concave functions, we\nproved that the sequence of function values, taken over the averages of\niterates generated by our scheme, converges to the value of the function at a\nsaddle-point. Additionally, we provided convergence results for both the\nsequence of averages of our iterates and the sequence of our iterates.\n  In our numerical experiments, we implemented our algorithm in a matrix game,\na linear program in inequality form, and a least-squares problem with\n$\\ell_{1}$ regularization. In these examples, we also compared our algorithm\nwith other primal-dual algorithms where parameters in their iterate schemes\nwere kept constant. Our experimental results validated our theoretical\nfindings. Furthermore, based on our experiments, we observed that when we\nconsider one of the three examples mentioned above, it is either the sequence\nof function evaluations at the averages of iterates or the sequence of function\nevaluations at the iterates outperforms the other, regardless of changes in\niterate schemes, problem data, and initial points. We also noted that certain\ninvolved parameters do not affect convergence rates in some instances, and that\nour algorithm consistently performs very well when compared to various iterate\nschemes with constant involved parameters.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:50:29 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 18:24:39 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.17341","submitter":"Xirong Ma","authors":"Xirong Ma","title":"Improved Privacy-Preserving PCA Using Space-optimized Homomorphic Matrix\n  Multiplication","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Principal Component Analysis (PCA) is a pivotal technique in the fields of\nmachine learning and data analysis. It aims to reduce the dimensionality of a\ndataset while minimizing the loss of information. In recent years, there have\nbeen endeavors to utilize homomorphic encryption in privacy-preserving PCA\nalgorithms. These approaches commonly employ a PCA routine known as\nPowerMethod, which takes the covariance matrix as input and generates an\napproximate eigenvector corresponding to the primary component of the dataset.\nHowever, their performance and accuracy are constrained by the incapability of\nhomomorphic covariance matrix computation and the absence of a universal vector\nnormalization strategy for the PowerMethod algorithm. In this study, we propose\na novel approach to privacy-preserving PCA that addresses these limitations,\nresulting in superior efficiency, accuracy, and scalability compared to\nprevious approaches. We attain such efficiency and precision through the\nfollowing contributions: (i) We implement space optimization techniques for a\nhomomorphic matrix multiplication method (Jiang et al., SIGSAC 2018), making it\nless prone to memory saturation in parallel computation scenarios. (ii)\nLeveraging the benefits of this optimized matrix multiplication, we devise an\nefficient homomorphic circuit for computing the covariance matrix\nhomomorphically. (iii) Utilizing the covariance matrix, we develop a novel and\nefficient homomorphic circuit for the PowerMethod that incorporates a universal\nhomomorphic vector normalization strategy to enhance both its accuracy and\npracticality.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:51:20 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 05:19:18 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.17342","submitter":"Xiangyu Liu","authors":"Xiangyu Liu, Souradip Chakraborty, Yanchao Sun, Furong Huang","title":"Rethinking Adversarial Policies: A Generalized Attack Formulation and\n  Provable Defense in Multi-Agent RL","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Most existing works consider direct perturbations of victim's state/action or\nthe underlying transition dynamics to show vulnerability of reinforcement\nlearning agents under adversarial attacks. However, such direct manipulation\nmay not always be feasible in practice. In this paper, we consider another\ncommon and realistic attack setup: in a multi-agent RL setting with\nwell-trained agents, during deployment time, the victim agent $\\nu$ is\nexploited by an attacker who controls another agent $\\alpha$ to act\nadversarially against the victim using an \\textit{adversarial policy}. Prior\nattack models under such setup do not consider that the attacker can confront\nresistance and thus can only take partial control of the agent $\\alpha$, as\nwell as introducing perceivable ``abnormal'' behaviors that are easily\ndetectable. A provable defense against these adversarial policies is also\nlacking. To resolve these issues, we introduce a more general attack\nformulation that models to what extent the adversary is able to control the\nagent to produce the adversarial policy. Based on such a generalized attack\nframework, the attacker can also regulate the state distribution shift caused\nby the attack through an attack budget, and thus produce stealthy adversarial\npolicies that can exploit the victim agent. Furthermore, we provide the first\nprovably robust defenses with convergence guarantee to the most robust victim\npolicy via adversarial training with timescale separation, in sharp contrast to\nadversarial training in supervised learning which may only provide {\\it\nempirical} defenses.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:54:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17343","submitter":"Yung Hsuan Lai","authors":"Yung-Hsuan Lai, Yen-Chun Chen, Yu-Chiang Frank Wang","title":"Modality-Independent Teachers Meet Weakly-Supervised Audio-Visual Event\n  Parser","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Audio-visual learning has been a major pillar of multi-modal machine\nlearning, where the community mostly focused on its modality-aligned setting,\ni.e., the audio and visual modality are both assumed to signal the prediction\ntarget. With the Look, Listen, and Parse dataset (LLP), we investigate the\nunder-explored unaligned setting, where the goal is to recognize audio and\nvisual events in a video with only weak labels observed. Such weak video-level\nlabels only tell what events happen without knowing the modality they are\nperceived (audio, visual, or both). To enhance learning in this challenging\nsetting, we incorporate large-scale contrastively pre-trained models as the\nmodality teachers. A simple, effective, and generic method, termed Visual-Audio\nLabel Elaboration (VALOR), is innovated to harvest modality labels for the\ntraining events. Empirical studies show that the harvested labels significantly\nimprove an attentional baseline by 8.0 in average F-score (Type@AV).\nSurprisingly, we found that modality-independent teachers outperform their\nmodality-fused counterparts since they are noise-proof from the other\npotentially unaligned modality. Moreover, our best model achieves the new\nstate-of-the-art on all metrics of LLP by a substantial margin (+5.4 F-score\nfor Type@AV). VALOR is further generalized to Audio-Visual Event Localization\nand achieves the new state-of-the-art as well. Code is available at:\nhttps://github.com/Franklin905/VALOR.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:57:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17344","submitter":"Div Bhagia","authors":"Div Bhagia","title":"Duration Dependence and Heterogeneity: Learning from Early Notice of\n  Layoff","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents a novel approach to distinguish the impact of\nduration-dependent forces and adverse selection on the exit rate from\nunemployment by leveraging variation in the length of layoff notices. I\nformulate a Mixed Hazard model in discrete time and specify the conditions\nunder which variation in notice length enables the identification of structural\nduration dependence while allowing for arbitrary heterogeneity across workers.\nUtilizing data from the Displaced Worker Supplement (DWS), I employ the\nGeneralized Method of Moments (GMM) to estimate the model. According to the\nestimates, the decline in the exit rate over the first 48 weeks of unemployment\nis largely due to the worsening composition of surviving jobseekers.\nFurthermore, I find that an individual's likelihood of exiting unemployment\ndecreases initially, then increases until unemployment benefits run out, and\nremains steady thereafter. These findings are consistent with a standard search\nmodel where returns to search decline early in the spell.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:57:54 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17345","submitter":"Quang Nam Nguyen","authors":"Quang-Nam Nguyen, Nicholas Adrian, Quang-Cuong Pham","title":"Task-Space Clustering for Mobile Manipulator Task Sequencing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Mobile manipulators have gained attention for the potential in performing\nlarge-scale tasks which are beyond the reach of fixed-base manipulators. The\nRobotic Task Sequencing Problem for mobile manipulators often requires\noptimizing the motion sequence of the robot to visit multiple targets while\nreducing the number of base placements. A two-step approach to this problem is\nclustering the task-space into clusters of targets before sequencing the robot\nmotion. In this paper, we propose a task-space clustering method which\nformulates the clustering step as a Set Cover Problem using bipartite graph and\nreachability analysis, then solves it to obtain the minimum number of target\nclusters with corresponding base placements. We demonstrated the practical\nusage of our method in a mobile drilling experiment containing hundreds of\ntargets. Multiple simulations were conducted to benchmark the algorithm and\nalso showed that our proposed method found, in practical time, better solutions\nthan the existing state-of-the-art methods.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 02:58:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17346","submitter":"Yuhang Li","authors":"Yuhang Li, Abhishek Moitra, Tamar Geller, Priyadarshini Panda","title":"Input-Aware Dynamic Timestep Spiking Neural Networks for Efficient\n  In-Memory Computing","comments":"Published at Design & Automation Conferences (DAC) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Spiking Neural Networks (SNNs) have recently attracted widespread research\ninterest as an efficient alternative to traditional Artificial Neural Networks\n(ANNs) because of their capability to process sparse and binary spike\ninformation and avoid expensive multiplication operations. Although the\nefficiency of SNNs can be realized on the In-Memory Computing (IMC)\narchitecture, we show that the energy cost and latency of SNNs scale linearly\nwith the number of timesteps used on IMC hardware. Therefore, in order to\nmaximize the efficiency of SNNs, we propose input-aware Dynamic Timestep SNN\n(DT-SNN), a novel algorithmic solution to dynamically determine the number of\ntimesteps during inference on an input-dependent basis. By calculating the\nentropy of the accumulated output after each timestep, we can compare it to a\npredefined threshold and decide if the information processed at the current\ntimestep is sufficient for a confident prediction. We deploy DT-SNN on an IMC\narchitecture and show that it incurs negligible computational overhead. We\ndemonstrate that our method only uses 1.46 average timesteps to achieve the\naccuracy of a 4-timestep static SNN while reducing the energy-delay-product by\n80%.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:01:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17347","submitter":"Nathan Schneider","authors":"Brett Reynolds, Nathan Schneider, Aryaman Arora","title":"CGELBank Annotation Manual v1.0","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  CGELBank is a treebank and associated tools based on a syntactic formalism\nfor English derived from the Cambridge Grammar of the English Language. This\ndocument lays out the particularities of the CGELBank annotation scheme.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:01:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17348","submitter":"Gabe Murray","authors":"Gabe Murray, Jeff Field, Patrick Stockton, Ali Pezeshki, Jeff Squier\n  and Randy Bartels","title":"Super resolution computational saturated absorption microscopy","comments":"26 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.bio-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Imaging beyond the diffraction limit barrier has attracted wide attention due\nto the ability to resolve image features that were previously hidden. Of the\nvarious super-resolution microscopy techniques available, a particularly simple\nmethod called saturated excitation microscopy (SAX) requires only a simple\nmodification of a laser scanning microscope where the illumination beam power\nis sinusoidally modulated and driven into saturation. SAX images are extracted\nfrom harmonics of the modulation frequency and exhibit improved spatial\nresolution. Unfortunately, this elegant strategy is hindered by the incursion\nof shot noise that prevents high resolution imaging in many realistic\nscenarios. Here, we demonstrate a new technique for super resolution imaging\nthat we call computational saturated absorption (CSA) in which a joint\ndeconvolution is applied to a set of images with diversity in spatial frequency\nsupport among the point spread functions used in the image formation with\nsaturated laser scanning fluorescence microscope. CSA microscopy allows access\nto the high spatial frequency diversity in a set of saturated effective point\nspread functions, while avoiding image degradation from shot noise.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:04:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17349","submitter":"Christos Sakaridis","authors":"Christos Sakaridis, David Bruggemann, Fisher Yu, Luc Van Gool","title":"Condition-Invariant Semantic Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Adaptation of semantic segmentation networks to different visual conditions\nfrom those for which ground-truth annotations are available at training is\nvital for robust perception in autonomous cars and robots. However, previous\nwork has shown that most feature-level adaptation methods, which employ\nadversarial training and are validated on synthetic-to-real adaptation, provide\nmarginal gains in normal-to-adverse condition-level adaptation, being\noutperformed by simple pixel-level adaptation via stylization. Motivated by\nthese findings, we propose to leverage stylization in performing feature-level\nadaptation by aligning the deep features extracted by the encoder of the\nnetwork from the original and the stylized view of each input image with a\nnovel feature invariance loss. In this way, we encourage the encoder to extract\nfeatures that are invariant to the style of the input, allowing the decoder to\nfocus on parsing these features and not on further abstracting from the\nspecific style of the input. We implement our method, named Condition-Invariant\nSemantic Segmentation (CISS), on the top-performing domain adaptation\narchitecture and demonstrate a significant improvement over previous\nstate-of-the-art methods both on Cityscapes$\\to$ACDC and Cityscapes$\\to$Dark\nZurich adaptation. In particular, CISS is ranked first among all published\nunsupervised domain adaptation methods on the public ACDC leaderboard. Our\nmethod is also shown to generalize well to domains unseen during training,\noutperforming competing domain adaptation approaches on BDD100K-night and\nNighttime Driving. Code is publicly available at https://github.com/SysCV/CISS .\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:05:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17350","submitter":"Nikhil Krishnaswamy","authors":"Corbyn Terpstra, Ibrahim Khebour, Mariah Bradford, Brett Wisniewski,\n  Nikhil Krishnaswamy, Nathaniel Blanchard","title":"How Good is Automatic Segmentation as a Multimodal Discourse Annotation\n  Aid?","comments":"7 pages, 1 figure, 2 tables, Proceedings of 19th Joint ISO-ACL\n  Workshop on Interoperable Semantic Annotation (ISA 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Collaborative problem solving (CPS) in teams is tightly coupled with the\ncreation of shared meaning between participants in a situated, collaborative\ntask. In this work, we assess the quality of different utterance segmentation\ntechniques as an aid in annotating CPS. We (1) manually transcribe utterances\nin a dataset of triads collaboratively solving a problem involving dialogue and\nphysical object manipulation, (2) annotate collaborative moves according to\nthese gold-standard transcripts, and then (3) apply these annotations to\nutterances that have been automatically segmented using toolkits from Google\nand OpenAI's Whisper. We show that the oracle utterances have minimal\ncorrespondence to automatically segmented speech, and that automatically\nsegmented speech using different segmentation methods is also inconsistent. We\nalso show that annotating automatically segmented speech has distinct\nimplications compared with annotating oracle utterances--since most annotation\nschemes are designed for oracle cases, when annotating automatically-segmented\nutterances, annotators must invoke other information to make arbitrary\njudgments which other annotators may not replicate. We conclude with a\ndiscussion of how future annotation specs can account for these needs.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:06:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17351","submitter":"Jinpeng Zhang","authors":"Jinpeng Zhang, Nini Xiao, Ke Wang, Chuanqi Dong, Xiangyu Duan, Yuqi\n  Zhang, Min Zhang","title":"Disambiguated Lexically Constrained Neural Machine Translation","comments":"Accepted at ACL 2023 as a long paper (Findings), 12 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Lexically constrained neural machine translation (LCNMT), which controls the\ntranslation generation with pre-specified constraints, is important in many\npractical applications. Current approaches to LCNMT typically assume that the\npre-specified lexical constraints are contextually appropriate. This assumption\nlimits their application to real-world scenarios where a source lexicon may\nhave multiple target constraints, and disambiguation is needed to select the\nmost suitable one. In this paper, we propose disambiguated LCNMT (D-LCNMT) to\nsolve the problem. D-LCNMT is a robust and effective two-stage framework that\ndisambiguates the constraints based on contexts at first, then integrates the\ndisambiguated constraints into LCNMT. Experimental results show that our\napproach outperforms strong baselines including existing data augmentation\nbased approaches on benchmark datasets, and comprehensive experiments in\nscenarios where a source lexicon corresponds to multiple target constraints\ndemonstrate the constraint disambiguation superiority of our approach.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:15:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17352","submitter":"Yihe Zhou","authors":"Yihe Zhou, Shunyu Liu, Yunpeng Qing, Kaixuan Chen, Tongya Zheng,\n  Yanhao Huang, Jie Song, Mingli Song","title":"Is Centralized Training with Decentralized Execution Framework\n  Centralized Enough for MARL?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG cs.MA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Centralized Training with Decentralized Execution (CTDE) has recently emerged\nas a popular framework for cooperative Multi-Agent Reinforcement Learning\n(MARL), where agents can use additional global state information to guide\ntraining in a centralized way and make their own decisions only based on\ndecentralized local policies. Despite the encouraging results achieved, CTDE\nmakes an independence assumption on agent policies, which limits agents to\nadopt global cooperative information from each other during centralized\ntraining. Therefore, we argue that existing CTDE methods cannot fully utilize\nglobal information for training, leading to an inefficient joint-policy\nexploration and even suboptimal results. In this paper, we introduce a novel\nCentralized Advising and Decentralized Pruning (CADP) framework for multi-agent\nreinforcement learning, that not only enables an efficacious message exchange\namong agents during training but also guarantees the independent policies for\nexecution. Firstly, CADP endows agents the explicit communication channel to\nseek and take advices from different agents for more centralized training. To\nfurther ensure the decentralized execution, we propose a smooth model pruning\nmechanism to progressively constraint the agent communication into a closed one\nwithout degradation in agent cooperation capability. Empirical evaluations on\nStarCraft II micromanagement and Google Research Football benchmarks\ndemonstrate that the proposed framework achieves superior performance compared\nwith the state-of-the-art counterparts. Our code will be made publicly\navailable.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:15:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17353","submitter":"Huixue Zhou","authors":"Huixue Zhou, Robin Austin, Sheng-Chieh Lu, Greg Silverman, Yuqi Zhou,\n  Halil Kilicoglu, Hua Xu, Rui Zhang","title":"Complementary and Integrative Health Lexicon (CIHLex) and Entity\n  Recognition in the Literature","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Objective: Our study aimed to construct an exhaustive Complementary and\nIntegrative Health (CIH) Lexicon (CIHLex) to better represent the often\nunderrepresented physical and psychological CIH approaches in standard\nterminologies. We also intended to apply advanced Natural Language Processing\n(NLP) models such as Bidirectional Encoder Representations from Transformers\n(BERT) and GPT-3.5 Turbo for CIH named entity recognition, evaluating their\nperformance against established models like MetaMap and CLAMP. Materials and\nMethods: We constructed the CIHLex by integrating various resources, compiling\nand integrating data from biomedical literature and relevant knowledge bases.\nThe Lexicon encompasses 198 unique concepts with 1090 corresponding unique\nterms. We matched these concepts to the Unified Medical Language System (UMLS).\nAdditionally, we developed and utilized BERT models and compared their\nefficiency in CIH named entity recognition to that of other models such as\nMetaMap, CLAMP, and GPT3.5-turbo. Results: From the 198 unique concepts in\nCIHLex, 62.1% could be matched to at least one term in the UMLS. Moreover,\n75.7% of the mapped UMLS Concept Unique Identifiers (CUIs) were categorized as\n\"Therapeutic or Preventive Procedure.\" Among the models applied to CIH named\nentity recognition, BLUEBERT delivered the highest macro average F1-score of\n0.90, surpassing other models. Conclusion: Our CIHLex significantly augments\nrepresentation of CIH approaches in biomedical literature. Demonstrating the\nutility of advanced NLP models, BERT notably excelled in CIH entity\nrecognition. These results highlight promising strategies for enhancing\nstandardization and recognition of CIH terminology in biomedical contexts.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:21:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17354","submitter":"Matthias Kramer","authors":"Matthias Kramer and Daniel Valero","title":"Linking turbulent waves and bubble diffusion in self-aerated\n  open-channel flows: Two-state air concentration","comments":"47 pages, 7 figures, includes supplemental material, accepted for\n  publication in Journal of Fluid Mechanics","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  High Froude-number flows become self-aerated when the destabilizing effect of\nturbulence overcomes gravity and surface tension forces. Traditionally, the\nresulting air concentration profile has been explained using single-layer\napproaches that invoke solutions of the advection-diffusion equation for air in\nwater, i.e., bubbles' dispersion. Based on a wide range of experimental\nevidences, we argue that the complete air concentration profile shall be\nexplained through the weak interaction of different canonical turbulent flows,\nnamely a Turbulent Boundary Layer (TBL) and a Turbulent Wavy Layer (TWL).\nMotivated by a decomposition of the streamwise velocity into a pure wall flow\nand a free-stream flow [Krug et al., J. Fluid Mech. (2017), vol. 811, pp.\n421--435], we present a physically consistent two-state formulation of the\nstructure of a self-aerated flow. The air concentration is mathematically built\nupon a modified Rouse profile and a Gaussian error function, resembling\nvertical mass transport in the TBL and the TWL. We apply our air concentration\ntheory to over 500 profiles from different data sets, featuring excellent\nagreement. Finally, we show that the turbulent Schmidt number, characterizing\nthe momentum-mass transfer, ranges between 0.2 to 1, which is consistent with\nprevious mass-transfer experiments in TBLs. Altogether, the proposed flow\nconceptualization sets the scene for more physically-based numerical modelling\nof turbulent mass diffusion in self-aerated flows.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:35:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17355","submitter":"Jun Yang","authors":"Feiyu Li, Jun Yang","title":"Rethinking PRL: A Multiscale Progressively Residual Learning Network for\n  Inverse Halftoning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Image inverse halftoning is a classic image restoration task, aiming to\nrecover continuous-tone images from halftone images with only bilevel pixels.\nBecause the halftone images lose much of the original image content, inverse\nhalftoning is a classic ill-problem. Although existing inverse halftoning\nalgorithms achieve good performance, their results lose image details and\nfeatures. Therefore, it is still a challenge to recover high-quality\ncontinuous-tone images. In this paper, we propose an end-to-end multiscale\nprogressively residual learning network (MSPRL), which has a UNet architecture\nand takes multiscale input images. To make full use of different input image\ninformation, we design a shallow feature extraction module to capture similar\nfeatures between images of different scales. We systematically study the\nperformance of different methods and compare them with our proposed method. In\naddition, we employ different training strategies to optimize the model, which\nis important for optimizing the training process and improving performance.\nExtensive experiments demonstrate that our MSPRL model obtains considerable\nperformance gains in detail restoration.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:37:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17356","submitter":"Chen Xu","authors":"Chen Xu, Yuhao Zhang, Chengbo Jiao, Xiaoqian Liu, Chi Hu, Xin Zeng,\n  Tong Xiao, Anxiang Ma, Huizhen Wang, JingBo Zhu","title":"Bridging the Granularity Gap for Acoustic Modeling","comments":"ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  While Transformer has become the de-facto standard for speech, modeling upon\nthe fine-grained frame-level features remains an open challenge of capturing\nlong-distance dependencies and distributing the attention weights. We propose\n\\textit{Progressive Down-Sampling} (PDS) which gradually compresses the\nacoustic features into coarser-grained units containing more complete semantic\ninformation, like text-level representation. In addition, we develop a\nrepresentation fusion method to alleviate information loss that occurs\ninevitably during high compression. In this way, we compress the acoustic\nfeatures into 1/32 of the initial length while achieving better or comparable\nperformances on the speech recognition task. And as a bonus, it yields\ninference speedups ranging from 1.20$\\times$ to 1.47$\\times$. By reducing the\nmodeling burden, we also achieve competitive results when training on the more\nchallenging speech translation task.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:52:52 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17357","submitter":"Yong-Liang Ma","authors":"Jun-Shuai Wang, Yong-Liang Ma","title":"Vector meson effects on the multi-skyrmion states from the rational map\n  ansatz","comments":"6 figures, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The roles of the lightest vector mesons $\\rho$ and $\\omega$ in the\nmulti-skyrmion states are studied using the hidden local symmetry approach upto\nthe next to leading order including the homogeneous Wess-Zumino terms. The low\nenergy constants in the effective field theory are determined by using the\nSakai-Sugimoto model and the flat-space five-dimensional Yang-Mills action.\nWith only two inputs, $m_\\rho$, and $f_\\pi$, all the low energy constants can\nbe determined without ambiguity. The vector meson effects can be investigated\nby integrating them in order and the influence from the geometry can be\nclarified by comparing the results using the low energy constants estimated\nfrom the Sakai-Sugimoto model and the flat-space five-dimensional Yang-Mills\naction. We find that the $\\rho$ meson reduces the masses of the multi-skyrmion\nstates and increases the overlaps of the constituents of the multi-skyrmion\nstates while the $\\omega$ meson repulses the constituents of the multi-skyrmion\nstates and increases their masses, therefore these vector mesons are important\nin Skyrme model approach to nuclei. we also find that the warping factor which\nis an essential element in the holographic model of QCD affects the properties\nof the multi-skyrmion states and cannot be ignored.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:54:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17358","submitter":"Chen Xu","authors":"Chen Xu, Xiaoqian Liu, Xiaowen Liu, Qingxuan Sun, Yuhao Zhang, Murun\n  Yang, Qianqian Dong, Tom Ko, Mingxuan Wang, Tong Xiao, Anxiang Ma and Jingbo\n  Zhu","title":"CTC-based Non-autoregressive Speech Translation","comments":"ACL 2023 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Combining end-to-end speech translation (ST) and non-autoregressive (NAR)\ngeneration is promising in language and speech processing for their advantages\nof less error propagation and low latency. In this paper, we investigate the\npotential of connectionist temporal classification (CTC) for non-autoregressive\nspeech translation (NAST). In particular, we develop a model consisting of two\nencoders that are guided by CTC to predict the source and target texts,\nrespectively. Introducing CTC into NAST on both language sides has obvious\nchallenges: 1) the conditional independent generation somewhat breaks the\ninterdependency among tokens, and 2) the monotonic alignment assumption in\nstandard CTC does not hold in translation tasks. In response, we develop a\nprediction-aware encoding approach and a cross-layer attention approach to\naddress these issues. We also use curriculum learning to improve convergence of\ntraining. Experiments on the MuST-C ST benchmarks show that our NAST model\nachieves an average BLEU score of 29.5 with a speed-up of 5.67$\\times$, which\nis comparable to the autoregressive counterpart and even outperforms the\nprevious best result of 0.9 BLEU points.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:54:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17359","submitter":"Xianjun Yang","authors":"Xianjun Yang, Wei Cheng, Linda Petzold, William Yang Wang, Haifeng\n  Chen","title":"DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of\n  GPT-Generated Text","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we can clearly illustrate significant discrepancies between\nmachine-generated and human-written text. We conducted extensive experiments on\nthe most advanced LLMs from OpenAI, including text-davinci-003, GPT-3.5-turbo,\nand GPT-4, as well as open-source models such as GPT-NeoX-20B and LLaMa-13B.\nResults show that our zero-shot approach exhibits state-of-the-art performance\nin distinguishing between human and GPT-generated text on four English and one\nGerman dataset, outperforming OpenAI's own classifier, which is trained on\nmillions of text. Additionally, our methods provide reasonable explanations and\nevidence to support our claim, which is a unique feature of explainable\ndetection. Our method is also robust under the revised text attack and can\nadditionally solve model sourcing. Codes are available at\nhttps://github.com/Xianjun-Yang/DNA-GPT.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:58:29 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17360","submitter":"Donglei Yang","authors":"Ming Chen, Jie Han, Yantao Tang, Donglei Yang","title":"On powers of Hamilton cycles in Ramsey-Tur\\'{a}n Theory","comments":"19 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove that for $r\\in \\mathbb{N}$ with $r\\geq 2$ and $\\mu>0$, there exist\n$\\alpha>0$ and $n_{0}$ such that for every $n\\geq n_{0}$, every $n$-vertex\ngraph $G$ with $\\delta(G)\\geq \\left(1-\\frac{1}{r}+\\mu\\right)n$ and\n$\\alpha(G)\\leq \\alpha n$ contains an $r$-th power of a Hamilton cycle. We also\nshow that the minimum degree condition is asymptotically sharp for $r=2, 3$ and\nthe $r=2$ case was recently conjectured by Staden and Treglown.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:08:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17361","submitter":"Qichen Huang","authors":"Qichen Huang, Biwei Jiang, Dingshan Deng, Bin Yu, Albert Zijlstra","title":"Estimation of the flux at 1450MHz of OB stars for FAST and SKA","comments":"15 pages. 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Radio observation is crucial to understanding the wind mechanism of OB stars\nbut very scarce. This work estimates the flux at 1450MHz ($S_{\\rm 1.4GHz}$) of\nabout 5,000 OB stars identified by the LAMOST spectroscopic survey and\nconfirmed by the Gaia astrometric as well as astrophysical measurements. The\ncalculation is performed under the free-free emission mechanism for wind with\nthe mass loss rate derived from stellar parameters. The estimated $S_{\\rm\n1.4GHz}$ distributes from $10^{-11}$Jy to $10^{-3}$Jy with the peak at about\n$10^{-8}$Jy. This implies that the complete SKA-II can detect more than half of\nthem, and some tens of objects are detectable by FAST without considering\nsource confusion. An array of FAST would increase the detectable sample by two\norders of magnitude.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:08:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17362","submitter":"Fayez Abu-Ajamieh","authors":"Fayez Abu-Ajamieh, Marco Frasca, Sudhir K. Vempati","title":"Flavor Violating Di- Higgs Coupling","comments":"33 pages, 11 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Di-Higgs couplings to fermions of the form $h^{2}\\overline{f}f$ are absent in\nthe Standard Model, however, they are present in several physics Beyond\nStandard Model (BSM) extensions, including those with vector-like fermions. In\nEffective Field Theories (EFTs), such as the Standard Model Effective Field\nTheory (SMEFT) and the Higgs Effective Field Theory (HEFT), these couplings\nappear at dimension 6 and can in general, be flavour-violating (FV). In the\npresent work, we employ a bottom-up approach to investigate the FV in the\nlepton and quarks sectors through the di-Higgs effective couplings. We assume\nthat all FV arises from this type of couplings and assume that the Yukawa\ncouplings $Y_{ij}$ are given by their SM values, i.e. $Y_{ij} =\n\\sqrt{2}m_{i}\\delta_{ij}/v$. In the lepton sector, we set upper limits on the\nWilson coefficients $C_{ll'}$ from $l \\rightarrow 3l'$ decays, $l \\rightarrow\nl\\gamma$ decays, muonium oscillations, the $(g-2)_{\\mu}$ anomaly, LEP searches,\nmuon conversion in nuclei, FV Higgs decays, and $Z$ decays. We also make\nprojections on some of these coefficients from Belle II, the Mu2e experiment\nand the LHC's High Luminosity (HL) run. In the quark sector, we set upper\nlimits on the Wilson coefficients $C_{qq'}$ from meson oscillations and from\n$B$-physics searches. A key takeaway from this study is that current and future\nexperiments should set out to measure the effective di-Higgs couplings\n$C_{ff'}$, whether these couplings are FV or flavour-conserving. We also\npresent a matching between our formalism and the SMEFT operators and show the\nbounds in both bases.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:14:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17363","submitter":"Shanshan Chen","authors":"Shanshan Chen, Yihuan Sun","title":"Hopf bifurcation and periodic solutions in a coupled Brusselator model\n  of chemical reactions","comments":"34 pages, 9 figures, references added","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider a coupled Brusselator model of chemical reactions,\nfor which no symmetry for the coupling matrices is assumed. We show that the\nmodel can undergoes a Hopf bifurcation, and consequently periodic solutions can\narise when the dispersal rates are large. Moreover, the effect of the coupling\nmatrices on the Hopf bifurcation value is considered for a special case.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:16:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17364","submitter":"Asma Ben Abacha","authors":"Asma Ben Abacha and Wen-wai Yim and George Michalopoulos and Thomas\n  Lin","title":"An Investigation of Evaluation Metrics for Automated Medical Note\n  Generation","comments":"Accepted to ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent studies on automatic note generation have shown that doctors can save\nsignificant amounts of time when using automatic clinical note generation\n(Knoll et al., 2022). Summarization models have been used for this task to\ngenerate clinical notes as summaries of doctor-patient conversations (Krishna\net al., 2021; Cai et al., 2022). However, assessing which model would best\nserve clinicians in their daily practice is still a challenging task due to the\nlarge set of possible correct summaries, and the potential limitations of\nautomatic evaluation metrics. In this paper, we study evaluation methods and\nmetrics for the automatic generation of clinical notes from medical\nconversations. In particular, we propose new task-specific metrics and we\ncompare them to SOTA evaluation metrics in text summarization and generation,\nincluding: (i) knowledge-graph embedding-based metrics, (ii) customized\nmodel-based metrics, (iii) domain-adapted/fine-tuned metrics, and (iv) ensemble\nmetrics. To study the correlation between the automatic metrics and manual\njudgments, we evaluate automatic notes/summaries by comparing the system and\nreference facts and computing the factual correctness, and the hallucination\nand omission rates for critical medical facts. This study relied on seven\ndatasets manually annotated by domain experts. Our experiments show that\nautomatic evaluation metrics can have substantially different behaviors on\ndifferent types of clinical notes datasets. However, the results highlight one\nstable subset of metrics as the most correlated with human judgments with a\nrelevant aggregation of different evaluation criteria.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:34:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17365","submitter":"Songhao Liu","authors":"Xiao Fang, Yuta Koike, Song-Hao Liu, Yi-Kun Zhao","title":"High-dimensional Central Limit Theorems by Stein's Method in the\n  Degenerate Case","comments":"32 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the literature of high-dimensional central limit theorems, there is a gap\nbetween results for general limiting correlation matrix $\\Sigma$ and the\nstrongly non-degenerate case. For the general case where $\\Sigma$ may be\ndegenerate, under certain light-tail conditions, when approximating a\nnormalized sum of $n$ independent random vectors by the Gaussian distribution\n$N(0,\\Sigma)$ in multivariate Kolmogorov distance, the best-known error rate\nhas been $O(n^{-1/4})$, subject to logarithmic factors of the dimension. For\nthe strongly non-degenerate case, that is, when the minimum eigenvalue of\n$\\Sigma$ is bounded away from 0, the error rate can be improved to\n$O(n^{-1/2})$ up to a $\\log n$ factor. In this paper, we show that the\n$O(n^{-1/2})$ rate up to a $\\log n$ factor can still be achieved in the\ndegenerate case, provided that the minimum eigenvalue of the limiting\ncorrelation matrix of any three components is bounded away from 0. We prove our\nmain results using Stein's method in conjunction with previously unexplored\ninequalities for the integral of the first three derivatives of the standard\nGaussian density over convex polytopes. These inequalities were previously\nknown only for hyperrectangles. Our proof demonstrates the connection between\nthe three-components condition and the third moment Berry--Esseen bound.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:42:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17366","submitter":"Yinpeng Hu","authors":"Yinpeng Hu, Yi Sun, Ye Lu, Huan Li, Liu Liu, Yaocheng Shi and Daoxin\n  Dai","title":"Silicon photonic MEMS switches based on split waveguide crossings","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The continuous push for high-performance photonic switches is one of the most\ncrucial premises for the sustainable scaling of programmable and reconfigurable\nphotonic circuits for a wide spectrum of applications. Large-scale photonic\nswitches constructed with a large number of 2$\\times$2 elementary switches\nimpose stringent requirements on the elementary switches. In contrast to\nconventional elementary switches based on mode interference or mode coupling,\nhere we propose and realize a brand-new silicon MEMS 2$\\times$2 elementary\nswitch based on a split waveguide crossing (SWX) consisting of two halves. With\nthis structure, the propagation direction of the incident light can be\nmanipulated to implement the OFF and ON states by splitting or combining the\ntwo halves of the SWX, respectively. More specifically, we introduce\nrefractive-index engineering by incorporating subwavelength-tooth (SWT)\nstructures on both reflecting facets to further reduce the excess loss in the\nON state. Such a unique switching mechanism features a compact footprint on a\nstandard SOI wafer and enables excellent photonic performance with low excess\nloss of 0.1-0.52/0.1-0.47dB and low crosstalk of $\\lt$-37/-22.5dB over an\nultrawide bandwidth of 1400-1700nm for the OFF/ON states in simulation, while\nin experiment, excess loss of 0.15-0.52/0.42-0.66dB and crosstalk of\n$\\lt$-45.5/-25dB over the bandwidth of 1525-1605 nm for the OFF/ON states have\nbeen measured.Furthermore, excellent MEMS characteristics such as near-zero\nsteady-state power consumption, low switching energy of sub-pJ, switching speed\nof {\\mu}s-scale, durability beyond 10^9 switching cycles, and overall device\nrobustness have been achieved. Finally, a 16$\\times$16 switch using Benes\ntopology has also been fabricated and characterized as a proof of concept,\nfurther validating the suitability of the SWX switches for large-scale\nintegration.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:45:45 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 03:21:05 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17367","submitter":"Yongyu Mu","authors":"Yongyu Mu, Abudurexiti Reheman, Zhiquan Cao, Yuchun Fan, Bei Li,\n  Yinqiao Li, Tong Xiao, Chunliang Zhang, Jingbo Zhu","title":"Augmenting Large Language Model Translators via Translation Memories","comments":"Accepted to Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Using translation memories (TMs) as prompts is a promising approach to\nin-context learning of machine translation models. In this work, we take a step\ntowards prompting large language models (LLMs) with TMs and making them better\ntranslators. We find that the ability of LLMs to ``understand'' prompts is\nindeed helpful for making better use of TMs. Experiments show that the results\nof a pre-trained LLM translator can be greatly improved by using high-quality\nTM-based prompts. These results are even comparable to those of the\nstate-of-the-art NMT systems which have access to large-scale in-domain\nbilingual data and are well tuned on the downstream tasks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:47:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17368","submitter":"Minghao Fu","authors":"Minghao Fu, Ke Zhu, Jianxin Wu","title":"Instance-based Max-margin for Practical Few-shot Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In order to mimic the human few-shot learning (FSL) ability better and to\nmake FSL closer to real-world applications, this paper proposes a practical FSL\n(pFSL) setting. pFSL is based on unsupervised pretrained models (analogous to\nhuman prior knowledge) and recognizes many novel classes simultaneously.\nCompared to traditional FSL, pFSL is simpler in its formulation, easier to\nevaluate, more challenging and more practical. To cope with the rarity of\ntraining examples, this paper proposes IbM2, an instance-based max-margin\nmethod not only for the new pFSL setting, but also works well in traditional\nFSL scenarios. Based on the Gaussian Annulus Theorem, IbM2 converts random\nnoise applied to the instances into a mechanism to achieve maximum margin in\nthe many-way pFSL (or traditional FSL) recognition task. Experiments with\nvarious self-supervised pretraining methods and diverse many- or few-way FSL\ntasks show that IbM2 almost always leads to improvements compared to its\nrespective baseline methods, and in most cases the improvements are\nsignificant. With both the new pFSL setting and novel IbM2 method, this paper\nshows that practical few-shot learning is both viable and promising.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 04:55:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17369","submitter":"Rui Cao","authors":"Rui Cao and Jing Jiang","title":"Modularized Zero-shot VQA with Pre-trained Models","comments":"accepted as Findings in ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large-scale pre-trained models (PTMs) show great zero-shot capabilities. In\nthis paper, we study how to leverage them for zero-shot visual question\nanswering (VQA). Our approach is motivated by a few observations. First, VQA\nquestions often require multiple steps of reasoning, which is still a\ncapability that most PTMs lack. Second, different steps in VQA reasoning chains\nrequire different skills such as object detection and relational reasoning, but\na single PTM may not possess all these skills. Third, recent work on zero-shot\nVQA does not explicitly consider multi-step reasoning chains, which makes them\nless interpretable compared with a decomposition-based approach. We propose a\nmodularized zero-shot network that explicitly decomposes questions into sub\nreasoning steps and is highly interpretable. We convert sub reasoning tasks to\nacceptable objectives of PTMs and assign tasks to proper PTMs without any\nadaptation. Our experiments on two VQA benchmarks under the zero-shot setting\ndemonstrate the effectiveness of our method and better interpretability\ncompared with several baselines.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:00:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17370","submitter":"Neel Kanwal","authors":"Neel Kanwal and Trygve Eftestol and Farbod Khoraminia and Tahlita CM\n  Zuiverloon and Kjersti Engan","title":"Vision Transformers for Small Histological Datasets Learned through\n  Knowledge Distillation","comments":"Accepted at PAKDD 2023","journal-ref":null,"doi":"10.1007/978-3-031-33380-4_13","report-no":"Lecture Notes in Computer Science book series (LNAI,volume 13937)","categories":"cs.CV cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Computational Pathology (CPATH) systems have the potential to automate\ndiagnostic tasks. However, the artifacts on the digitized histological glass\nslides, known as Whole Slide Images (WSIs), may hamper the overall performance\nof CPATH systems. Deep Learning (DL) models such as Vision Transformers (ViTs)\nmay detect and exclude artifacts before running the diagnostic algorithm. A\nsimple way to develop robust and generalized ViTs is to train them on massive\ndatasets. Unfortunately, acquiring large medical datasets is expensive and\ninconvenient, prompting the need for a generalized artifact detection method\nfor WSIs. In this paper, we present a student-teacher recipe to improve the\nclassification performance of ViT for the air bubbles detection task. ViT,\ntrained under the student-teacher framework, boosts its performance by\ndistilling existing knowledge from the high-capacity teacher model. Our\nbest-performing ViT yields 0.961 and 0.911 F1-score and MCC, respectively,\nobserving a 7% gain in MCC against stand-alone training. The proposed method\npresents a new perspective of leveraging knowledge distillation over transfer\nlearning to encourage the use of customized transformers for efficient\npreprocessing pipelines in the CPATH systems.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:09:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17371","submitter":"Yi Liu","authors":"Yi Liu, Yuan Tian, Jianxun Lian, Xinlong Wang, Yanan Cao, Fang Fang,\n  Wen Zhang, Haizhen Huang, Denvy Deng and Qi Zhang","title":"Towards Better Entity Linking with Multi-View Enhanced Distillation","comments":"Accepted by ACL 2023 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Dense retrieval is widely used for entity linking to retrieve entities from\nlarge-scale knowledge bases. Mainstream techniques are based on a dual-encoder\nframework, which encodes mentions and entities independently and calculates\ntheir relevances via rough interaction metrics, resulting in difficulty in\nexplicitly modeling multiple mention-relevant parts within entities to match\ndivergent mentions. Aiming at learning entity representations that can match\ndivergent mentions, this paper proposes a Multi-View Enhanced Distillation\n(MVD) framework, which can effectively transfer knowledge of multiple\nfine-grained and mention-relevant parts within entities from cross-encoders to\ndual-encoders. Each entity is split into multiple views to avoid irrelevant\ninformation being over-squashed into the mention-relevant view. We further\ndesign cross-alignment and self-alignment mechanisms for this framework to\nfacilitate fine-grained knowledge distillation from the teacher model to the\nstudent model. Meanwhile, we reserve a global-view that embeds the entity as a\nwhole to prevent dispersal of uniform information. Experiments show our method\nachieves state-of-the-art performance on several entity linking benchmarks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:15:28 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17372","submitter":"Jueming Hu","authors":"Jueming Hu, Jean-Rapha\\\"el Gaglione, Yanze Wang, Zhe Xu, Ufuk Topcu,\n  and Yongming Liu","title":"Reinforcement Learning With Reward Machines in Stochastic Games","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.MA cs.AI cs.GT cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We investigate multi-agent reinforcement learning for stochastic games with\ncomplex tasks, where the reward functions are non-Markovian. We utilize reward\nmachines to incorporate high-level knowledge of complex tasks. We develop an\nalgorithm called Q-learning with reward machines for stochastic games (QRM-SG),\nto learn the best-response strategy at Nash equilibrium for each agent. In\nQRM-SG, we define the Q-function at a Nash equilibrium in augmented state\nspace. The augmented state space integrates the state of the stochastic game\nand the state of reward machines. Each agent learns the Q-functions of all\nagents in the system. We prove that Q-functions learned in QRM-SG converge to\nthe Q-functions at a Nash equilibrium if the stage game at each time step\nduring learning has a global optimum point or a saddle point, and the agents\nupdate Q-functions based on the best-response strategy at this point. We use\nthe Lemke-Howson method to derive the best-response strategy given current\nQ-functions. The three case studies show that QRM-SG can learn the\nbest-response strategies effectively. QRM-SG learns the best-response\nstrategies after around 7500 episodes in Case Study I, 1000 episodes in Case\nStudy II, and 1500 episodes in Case Study III, while baseline methods such as\nNash Q-learning and MADDPG fail to converge to the Nash equilibrium in all\nthree case studies.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:32:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17373","submitter":"Zhenrui Yue","authors":"Zhenrui Yue, Huimin Zeng, Mengfei Lan, Heng Ji, Dong Wang","title":"Zero- and Few-Shot Event Detection via Prompt-Based Meta Learning","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With emerging online topics as a source for numerous new events, detecting\nunseen / rare event types presents an elusive challenge for existing event\ndetection methods, where only limited data access is provided for training. To\naddress the data scarcity problem in event detection, we propose MetaEvent, a\nmeta learning-based framework for zero- and few-shot event detection.\nSpecifically, we sample training tasks from existing event types and perform\nmeta training to search for optimal parameters that quickly adapt to unseen\ntasks. In our framework, we propose to use the cloze-based prompt and a\ntrigger-aware soft verbalizer to efficiently project output to unseen event\ntypes. Moreover, we design a contrastive meta objective based on maximum mean\ndiscrepancy (MMD) to learn class-separating features. As such, the proposed\nMetaEvent can perform zero-shot event detection by mapping features to event\ntypes without any prior knowledge. In our experiments, we demonstrate the\neffectiveness of MetaEvent in both zero-shot and few-shot scenarios, where the\nproposed method achieves state-of-the-art performance in extensive experiments\non benchmark datasets FewEvent and MAVEN.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:36:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17374","submitter":"Yongbiao Xiao","authors":"Yongbiao Xiao, Hui Li, Chunyang Cheng, and Xiaoning Song","title":"LE2Fusion: A novel local edge enhancement module for infrared and\n  visible image fusion","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Infrared and visible image fusion task aims to generate a fused image which\ncontains salient features and rich texture details from multi-source images.\nHowever, under complex illumination conditions, few algorithms pay attention to\nthe edge information of local regions which is crucial for downstream tasks. To\nthis end, we propose a fusion network based on the local edge enhancement,\nnamed LE2Fusion. Specifically, a local edge enhancement (LE2) module is\nproposed to improve the edge information under complex illumination conditions\nand preserve the essential features of image. For feature extraction, a\nmulti-scale residual attention (MRA) module is applied to extract rich\nfeatures. Then, with LE2, a set of enhancement weights are generated which are\nutilized in feature fusion strategy and used to guide the image reconstruction.\nTo better preserve the local detail information and structure information, the\npixel intensity loss function based on the local region is also presented. The\nexperiments demonstrate that the proposed method exhibits better fusion\nperformance than the state-of-the-art fusion methods on public datasets.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:37:02 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17375","submitter":"Dianbo Liu Dr","authors":"Dianbo Liu, Samuele Bolotta, He Zhu, Yoshua Bengio, Guillaume Dumas","title":"Attention Schema in Neural Agents","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Attention has become a common ingredient in deep learning architectures. It\nadds a dynamical selection of information on top of the static selection of\ninformation supported by weights. In the same way, we can imagine a\nhigher-order informational filter built on top of attention: an Attention\nSchema (AS), namely, a descriptive and predictive model of attention. In\ncognitive neuroscience, Attention Schema Theory (AST) supports this idea of\ndistinguishing attention from AS. A strong prediction of this theory is that an\nagent can use its own AS to also infer the states of other agents' attention\nand consequently enhance coordination with other agents. As such, multi-agent\nreinforcement learning would be an ideal setting to experimentally test the\nvalidity of AST. We explore different ways in which attention and AS interact\nwith each other. Our preliminary results indicate that agents that implement\nthe AS as a recurrent internal control achieve the best performance. In\ngeneral, these exploratory experiments suggest that equipping artificial agents\nwith a model of attention can enhance their social intelligence.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:40:34 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 05:09:23 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17376","submitter":"Yongbiao Xiao","authors":"Hui Li, Yongbiao Xiao, Chunyang Cheng, Zhongwei Shen, Xiaoning Song","title":"WavePF: A Novel Fusion Approach based on Wavelet-guided Pooling for\n  Infrared and Visible Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Infrared and visible image fusion aims to generate synthetic images\nsimultaneously containing salient features and rich texture details, which can\nbe used to boost downstream tasks. However, existing fusion methods are\nsuffering from the issues of texture loss and edge information deficiency,\nwhich result in suboptimal fusion results. Meanwhile, the straight-forward\nup-sampling operator can not well preserve the source information from\nmulti-scale features. To address these issues, a novel fusion network based on\nthe wavelet-guided pooling (wave-pooling) manner is proposed, termed as WavePF.\nSpecifically, a wave-pooling based encoder is designed to extract multi-scale\nimage and detail features of source images at the same time. In addition, the\nspatial attention model is used to aggregate these salient features. After\nthat, the fused features will be reconstructed by the decoder, in which the\nup-sampling operator is replaced by the wave-pooling reversed operation.\nDifferent from the common max-pooling technique, image features after the\nwave-pooling layer can retain abundant details information, which can benefit\nthe fusion process. In this case, rich texture details and multi-scale\ninformation can be maintained during the reconstruction phase. The experimental\nresults demonstrate that our method exhibits superior fusion performance over\nthe state-of-the-arts on multiple image fusion benchmarks\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:47:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17377","submitter":"Haoxiang Luo","authors":"Haoxiang Luo, Jin Zhang, Xinling Li, Zonghang Li, Hongfang Yu, Gang\n  Sun, Dusit Niyato","title":"ESIA: An Efficient and Stable Identity Authentication for Internet of\n  Vehicles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decentralized, tamper-proof blockchain is regarded as a solution to a\nchallenging authentication issue in the Internet of Vehicles (IoVs). However,\nthe consensus time and communication overhead of blockchain increase\nsignificantly as the number of vehicles connected to the blockchain. To address\nthis issue, vehicular fog computing has been introduced to improve efficiency.\nHowever, existing studies ignore several key factors such as the number of\nvehicles in the fog computing system, which can impact the consensus\ncommunication overhead. Meanwhile, there is no comprehensive study on the\nstability of vehicular fog composition. The vehicle movement will lead to\ndynamic changes in fog. If the composition of vehicular fog is unstable, the\nblockchain formed by this fog computing system will be unstable, which can\naffect the consensus efficiency. With the above considerations, we propose an\nefficient and stable identity authentication (ESIA) empowered by hierarchical\nblockchain and fog computing. By grouping vehicles efficiently, ESIA has low\ncommunication complexity and achieves high stability. Moreover, to enhance the\nconsensus security of the hierarchical blockchain, the consensus process is\nfrom the bottom layer to the up layer (bottom-up), which we call B2UHChain.\nThrough theoretical analysis and simulation verification, our scheme achieves\nthe design goals of high efficiency and stability while significantly improving\nthe IoV scalability to the power of 1.5 (^1.5) under similar security to a\nsingle-layer blockchain. In addition, ESIA has less communication and\ncomputation overhead, lower latency, and higher throughput than other baseline\nauthentication schemes.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:01:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17378","submitter":"Daking Rai Mr","authors":"Daking Rai, Bailin Wang, Yilun Zhou and Ziyu Yao","title":"Improving Generalization in Language Model-Based Text-to-SQL Semantic\n  Parsing: Two Simple Semantic Boundary-Based Techniques","comments":"9 pages, to be published in ACL2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Compositional and domain generalization present significant challenges in\nsemantic parsing, even for state-of-the-art semantic parsers based on\npre-trained language models (LMs). In this study, we empirically investigate\nimproving an LM's generalization in semantic parsing with two simple\ntechniques: at the token level, we introduce a token preprocessing method to\npreserve the semantic boundaries of tokens produced by LM tokenizers; at the\nsequence level, we propose to use special tokens to mark the boundaries of\ncomponents aligned between input and output. Our experimental results on two\ntext-to-SQL semantic parsing datasets show that our token preprocessing,\nalthough simple, can substantially improve the LM performance on both types of\ngeneralization, and our component boundary marking method is particularly\nhelpful for compositional generalization.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:09:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17379","submitter":"Basant Lal Sharma","authors":"Sanjay Dharmavaram and Basant Lal Sharma","title":"Generalizing Parametrization Invariance in the Calculus of Variations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math-ph math.MP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We revisit the notion of parametrization invariance while introducing certain\nweakened notions of invariance in the calculus of variations. In this work, we\nemploy a straightforward approach in the classical setting and mostly restrict\nattention to functionals on one-dimensional domains. We establish a connection\nbetween parametrization invariant functionals and functionals embodying a\nweaker notion of invariance of their Lagrangian; we term this notion as\nT-Lagrangian analogous to the well-known idea of null Lagrangian. However, the\nEuler-Lagrange operator of a T-Lagrangian vanishes only along the tangential\ndirection in the configuration space. On one-dimensional domain and for first-\nand second-order theories, we show that functional described by such a\nLagrangian is necessarily a parametrization invariant functional modulo null\nLagrangian. Keeping the motivation for partial differential equations, we also\nintroduce and explore the notion of N-Lagrangian, with an invariance\ncomplementary to the case of T-Lagrangian, whose Euler-Lagrange operator\nvanishes along normal directions. We find that in a one-dimensional setting,\nevery N-Lagrangian is simply a null Lagrangian.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:09:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17380","submitter":"Chen-Yu Wei","authors":"Tiancheng Jin, Junyan Liu, Chlo\\'e Rouyer, William Chang, Chen-Yu Wei,\n  Haipeng Luo","title":"No-Regret Online Reinforcement Learning with Adversarial Losses and\n  Transitions","comments":"66 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing online learning algorithms for adversarial Markov Decision Processes\nachieve ${O}(\\sqrt{T})$ regret after $T$ rounds of interactions even if the\nloss functions are chosen arbitrarily by an adversary, with the caveat that the\ntransition function has to be fixed. This is because it has been shown that\nadversarial transition functions make no-regret learning impossible. Despite\nsuch impossibility results, in this work, we develop algorithms that can handle\nboth adversarial losses and adversarial transitions, with regret increasing\nsmoothly in the degree of maliciousness of the adversary. More concretely, we\nfirst propose an algorithm that enjoys $\\widetilde{{O}}(\\sqrt{T} +\nC^{\\textsf{P}})$ regret where $C^{\\textsf{P}}$ measures how adversarial the\ntransition functions are and can be at most ${O}(T)$. While this algorithm\nitself requires knowledge of $C^{\\textsf{P}}$, we further develop a black-box\nreduction approach that removes this requirement. Moreover, we also show that\nfurther refinements of the algorithm not only maintains the same regret bound,\nbut also simultaneously adapts to easier environments (where losses are\ngenerated in a certain stochastically constrained manner as in Jin et al.\n[2021]) and achieves $\\widetilde{{O}}(U + \\sqrt{UC^{\\textsf{L}}} +\nC^{\\textsf{P}})$ regret, where $U$ is some standard gap-dependent coefficient\nand $C^{\\textsf{L}}$ is the amount of corruption on losses.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:10:17 GMT"},{"version":"v2","created":"Tue, 30 May 2023 04:36:32 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17381","submitter":"Tian Shang","authors":"T. Shang, J. Z. Zhao, Lun-Hui Hu, D. J. Gawryluk, X. Y. Zhu, H. Zhang,\n  J. Meng, Z. X. Zhen, B. C. Yu, Z. Zhou, Y. Xu, Q. F. Zhan, E. Pomjakushina,\n  and T. Shiroka","title":"Fully-gapped superconductivity and topological aspects of the\n  noncentrosymmetric TaReSi superconductor","comments":"9 pages, 9 figures; accepted by Phys. Rev. B","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mtrl-sci cond-mat.str-el","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report a study of the noncentrosymmetric TaReSi superconductor by means of\nmuon-spin rotation and relaxation ($\\mu$SR) technique, complemented by\nelectronic band-structure calculations. Its superconductivity, with $T_c$ = 5.5\nK and upper critical field $\\mu_0H_\\mathrm{c2}(0)$ $\\sim$ 3.4 T, was\ncharacterized via electrical-resistivity- and magnetic-susceptibility\nmeasurements. The temperature-dependent superfluid density, obtained from\ntransverse-field $\\mu$SR, suggests a fully-gapped superconducting state in\nTaReSi, with an energy gap $\\Delta_0$ = 0.79 meV and a magnetic penetration\ndepth $\\lambda_0$ = 562 nm. The absence of a spontaneous magnetization below\n$T_c$, as confirmed by zero-field $\\mu$SR, indicates a preserved time-reversal\nsymmetry in the superconducting state. The density of states near the Fermi\nlevel is dominated by the Ta- and Re-5$d$ orbitals, which account for the\nrelatively large band splitting due to the antisymmetric spin-orbit coupling.\nIn its normal state, TaReSi behaves as a three-dimensional Kramers nodal-line\nsemimetal, characterized by an hourglass-shaped dispersion protected by glide\nreflection. By combining non\\-triv\\-i\\-al electronic bands with intrinsic\nsuperconductivity, TaReSi is a promising material for investigating the\ntopological aspects of noncentrosymmetric superconductors.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:24:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17382","submitter":"Xuhai Chen","authors":"Xuhai Chen, Yue Han, Jiangning Zhang","title":"A Zero-/Few-Shot Anomaly Classification and Segmentation Method for CVPR\n  2023 VAND Workshop Challenge Tracks 1&2: 1st Place on Zero-shot AD and 4th\n  Place on Few-shot AD","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this technical report, we briefly introduce our solution for the\nZero/Few-shot Track of the Visual Anomaly and Novelty Detection (VAND) 2023\nChallenge. For industrial visual inspection, building a single model that can\nbe rapidly adapted to numerous categories without or with only a few normal\nreference images is a promising research direction. This is primarily because\nof the vast variety of the product types. For the zero-shot track, we propose a\nsolution based on the CLIP model by adding extra linear layers. These layers\nare used to map the image features to the joint embedding space, so that they\ncan compare with the text features to generate the anomaly maps. Besides, when\nthe reference images are available, we utilize multiple memory banks to store\ntheir features and compare them with the features of the test images during the\ntesting phase. In this challenge, our method achieved first place in the\nzero-shot track, especially excelling in segmentation with an impressive F1\nscore improvement of 0.0489 over the second-ranked participant. Furthermore, in\nthe few-shot track, we secured the fourth position overall, with our\nclassification F1 score of 0.8687 ranking first among all participating teams.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:24:43 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17383","submitter":"WooCheol Choi","authors":"Woocheol Choi","title":"On the convergence of the distributed proximal point algorithm","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC eess.SP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we establish convergence results for the distributed proximal\npoint algorithm (DPPA) for distributed optimization problems. We consider the\nproblem on the whole domain Rd and find a general condition on the stepsize and\ncost functions such that the DPPA is stable. We prove that the DPPA with\nstepsize $\\eta > 0$ exponentially converges to an $O(\\eta)$-neighborhood of the\noptimizer. Our result clearly explains the advantage of the DPPA with respect\nto the convergence and stability in comparison with the distributed gradient\ndescent algorithm. We also provide numerical tests supporting the theoretical\nresults.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:32:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17384","submitter":"Zhuo Li","authors":"Zhuo Li, Huangzhao Zhang, Zhi Jin, Ge Li","title":"WELL: Applying Bug Detectors to Bug Localization via Weakly Supervised\n  Learning","comments":"(Preprint) Software Engineer; Deep Learning; Bug Detection &\n  Localization","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bug localization, which is used to help programmers identify the location of\nbugs in source code, is an essential task in software development. Researchers\nhave already made efforts to harness the powerful deep learning (DL) techniques\nto automate it. However, training bug localization model is usually challenging\nbecause it requires a large quantity of data labeled with the bug's exact\nlocation, which is difficult and time-consuming to collect. By contrast,\nobtaining bug detection data with binary labels of whether there is a bug in\nthe source code is much simpler. This paper proposes a WEakly supervised bug\nLocaLization (WELL) method, which only uses the bug detection data with binary\nlabels to train a bug localization model. With CodeBERT finetuned on the\nbuggy-or-not binary labeled data, WELL can address bug localization in a weakly\nsupervised manner. The evaluations on three method-level synthetic datasets and\none file-level real-world dataset show that WELL is significantly better than\nthe existing SOTA model in typical bug localization tasks such as variable\nmisuse and other programming bugs.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:34:26 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 13:30:54 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.17385","submitter":"Stefano Leucci","authors":"Davide Bil\\`o, Luciano Gual\\`a, Stefano Leucci, Luca Pep\\`e Sciarria","title":"Finding Diameter-Reducing Shortcuts in Trees","comments":"22 pages, 6 figures, WADS 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the \\emph{$k$-Diameter-Optimally Augmenting Tree Problem} we are given a\ntree $T$ of $n$ vertices as input. The tree is embedded in an unknown\n\\emph{metric} space and we have unlimited access to an oracle that, given two\ndistinct vertices $u$ and $v$ of $T$, can answer queries reporting the cost of\nthe edge $(u,v)$ in constant time. We want to augment $T$ with $k$ shortcuts in\norder to minimize the diameter of the resulting graph.\n  For $k=1$, $O(n \\log n)$ time algorithms are known both for paths [Wang, CG\n2018] and trees [Bil\\`o, TCS 2022]. In this paper we investigate the case of\nmultiple shortcuts. We show that no algorithm that performs $o(n^2)$ queries\ncan provide a better than $10/9$-approximate solution for trees for $k\\geq 3$.\nFor any constant $\\varepsilon > 0$, we instead design a linear-time\n$(1+\\varepsilon)$-approximation algorithm for paths and $k = o(\\sqrt{\\log n})$,\nthus establishing a dichotomy between paths and trees for $k\\geq 3$. We achieve\nthe claimed running time by designing an ad-hoc data structure, which also\nserves as a key component to provide a linear-time $4$-approximation algorithm\nfor trees, and to compute the diameter of graphs with $n + k - 1$ edges in time\n$O(n k \\log n)$ even for non-metric graphs. Our data structure and the latter\nresult are of independent interest.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:35:09 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17386","submitter":"Kaize Ding","authors":"Kaize Ding, Albert Jiongqian Liang, Bryan Perrozi, Ting Chen, Ruoxi\n  Wang, Lichan Hong, Ed H. Chi, Huan Liu, Derek Zhiyuan Cheng","title":"HyperFormer: Learning Expressive Sparse Feature Representations via\n  Hypergraph Transformer","comments":"Accepted by SIGIR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Learning expressive representations for high-dimensional yet sparse features\nhas been a longstanding problem in information retrieval. Though recent deep\nlearning methods can partially solve the problem, they often fail to handle the\nnumerous sparse features, particularly those tail feature values with\ninfrequent occurrences in the training data. Worse still, existing methods\ncannot explicitly leverage the correlations among different instances to help\nfurther improve the representation learning on sparse features since such\nrelational prior knowledge is not provided. To address these challenges, in\nthis paper, we tackle the problem of representation learning on feature-sparse\ndata from a graph learning perspective. Specifically, we propose to model the\nsparse features of different instances using hypergraphs where each node\nrepresents a data instance and each hyperedge denotes a distinct feature value.\nBy passing messages on the constructed hypergraphs based on our Hypergraph\nTransformer (HyperFormer), the learned feature representations capture not only\nthe correlations among different instances but also the correlations among\nfeatures. Our experiments demonstrate that the proposed approach can\neffectively improve feature representation learning on sparse features.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:35:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17387","submitter":"Ehsan Saleh","authors":"Ehsan Saleh, Saba Ghaffari, Timothy Bretl, Luke Olson, Matthew West","title":"Learning from Integral Losses in Physics Informed Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work proposes a solution for the problem of training physics informed\nnetworks under partial integro-differential equations. These equations require\ninfinite or a large number of neural evaluations to construct a single residual\nfor training. As a result, accurate evaluation may be impractical, and we show\nthat naive approximations at replacing these integrals with unbiased estimates\nlead to biased loss functions and solutions. To overcome this bias, we\ninvestigate three types of solutions: the deterministic sampling approach, the\ndouble-sampling trick, and the delayed target method. We consider three classes\nof PDEs for benchmarking; one defining a Poisson problem with singular charges\nand weak solutions, another involving weak solutions on electro-magnetic fields\nand a Maxwell equation, and a third one defining a Smoluchowski coagulation\nproblem. Our numerical results confirm the existence of the aforementioned bias\nin practice, and also show that our proposed delayed target approach can lead\nto accurate solutions with comparable quality to ones estimated with a large\nnumber of samples. Our implementation is open-source and available at\nhttps://github.com/ehsansaleh/btspinn.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:46:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17388","submitter":"Jaewoo Ahn","authors":"Jaewoo Ahn, Yeda Song, Sangdoo Yun, Gunhee Kim","title":"MPCHAT: Towards Multimodal Persona-Grounded Conversation","comments":"Accepted at ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In order to build self-consistent personalized dialogue agents, previous\nresearch has mostly focused on textual persona that delivers personal facts or\npersonalities. However, to fully describe the multi-faceted nature of persona,\nimage modality can help better reveal the speaker's personal characteristics\nand experiences in episodic memory (Rubin et al., 2003; Conway, 2009). In this\nwork, we extend persona-based dialogue to the multimodal domain and make two\nmain contributions. First, we present the first multimodal persona-based\ndialogue dataset named MPCHAT, which extends persona with both text and images\nto contain episodic memories. Second, we empirically show that incorporating\nmultimodal persona, as measured by three proposed multimodal persona-grounded\ndialogue tasks (i.e., next response prediction, grounding persona prediction,\nand speaker identification), leads to statistically significant performance\nimprovements across all tasks. Thus, our work highlights that multimodal\npersona is crucial for improving multimodal dialogue comprehension, and our\nMPCHAT serves as a high-quality resource for this research.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:46:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17389","submitter":"K. J. Kevin Feng","authors":"K. J. Kevin Feng, Maxwell James Coppock, David W. McDonald","title":"How Do UX Practitioners Communicate AI as a Design Material? Artifacts,\n  Conceptions, and Propositions","comments":null,"journal-ref":null,"doi":"10.1145/3563657.3596101","report-no":null,"categories":"cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  UX practitioners (UXPs) face novel challenges when working with and\ncommunicating artificial intelligence (AI) as a design material. We explore how\nUXPs communicate AI concepts when given hands-on experience training and\nexperimenting with AI models. To do so, we conducted a task-based design study\nwith 27 UXPs in which they prototyped and created a design presentation for a\nAI-enabled interface while having access to a simple AI model training tool.\nThrough analyzing UXPs' design presentations and post-activity interviews, we\nfound that although UXPs struggled to clearly communicate some AI concepts,\ntinkering with AI broadened common ground when communicating with technical\nstakeholders. UXPs also identified key risks and benefits of AI in their\ndesigns, and proposed concrete next steps for both UX and AI work. We conclude\nwith a sensitizing concept and recommendations for design and AI tools to\nenhance multi-stakeholder communication and collaboration when crafting\nhuman-centered AI experiences.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:57:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17390","submitter":"Bill Yuchen Lin","authors":"Bill Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu,\n  Faeze Brahman, Shiyu Huang, Chandra Bhagavatula, Yejin Choi, Xiang Ren","title":"SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex\n  Interactive Tasks","comments":"Project website: https://yuchenlin.xyz/swiftsage/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG cs.MA cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce SwiftSage, a novel agent framework inspired by the dual-process\ntheory of human cognition, designed to excel in action planning for complex\ninteractive reasoning tasks. SwiftSage integrates the strengths of behavior\ncloning and prompting large language models (LLMs) to enhance task completion\nperformance. The framework comprises two primary modules: the Swift module,\nrepresenting fast and intuitive thinking, and the Sage module, emulating\ndeliberate thought processes. The Swift module is a small encoder-decoder LM\nfine-tuned on the oracle agent's action trajectories, while the Sage module\nemploys LLMs such as GPT-4 for subgoal planning and grounding. We develop a\nheuristic method to harmoniously integrate the two modules, resulting in a more\nefficient and robust problem-solving process. In 30 tasks from the ScienceWorld\nbenchmark, SwiftSage significantly outperforms other methods such as SayCan,\nReAct, and Reflexion, demonstrating its effectiveness in solving complex\nreal-world tasks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:04:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17391","submitter":"Zhi-An Wang","authors":"Hai-Yang Jin, Zhi-An Wang, Leyun Wu","title":"Global solvability and stability of an alarm-taxis system","comments":null,"journal-ref":null,"doi":"10.1137/22M1477143","report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is concerned with the global boundedness and stability of\nclassical solutions to an alarm-taxis system describing the burglar alarm\nhypothesis as an important mechanism of anti-predation behavior when species\nare threaten by predators. Compared to the existing prey-taxis systems, the\nalarm-taxis system has more complicated coupling structure and additionally\nrequires the gradient estimate of the primary predator density to attain the\nglobal boundedness of solutions. By the sophisticated coupling energy estimates\nbased on the Neumann semigroup smoothing properties, we establish the existence\nof globally bounded solutions in two dimensions with Neumann boundary\nconditions and furthermore prove the global stability of co-existence\nhomogeneous steady states under certain conditions on the system parameters.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:17:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17392","submitter":"Aymen Laadhari Dr","authors":"Aymen Laadhari and Ahmad Deeb","title":"Numerical Approach Based on the Composition of One-Step Time-Integration\n  Schemes For Highly Deformable Interfaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this work, we propose a numerical approach for simulations of large\ndeformations of interfaces in a level set framework. To obtain a fast and\nviable numerical solution in both time and space, temporal discretization is\nbased on the composition of one-step methods exhibiting higher orders and\nstability, especially in the case of stiff problems with strongly oscillatory\nsolutions. Numerical results are provided in the case of ordinary and partial\ndifferential equations to show the main features and demonstrate the\nperformance of the method. Convergence properties and efficiency in terms of\ncomputational cost are also investigated.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:18:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17393","submitter":"Zhiyu Chen","authors":"Pedro Faustini, Zhiyu Chen, Besnik Fetahu, Oleg Rokhlenko and Shervin\n  Malmasi","title":"Answering Unanswered Questions through Semantic Reformulations in Spoken\n  QA","comments":"ACL 2023 Industry Track","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spoken Question Answering (QA) is a key feature of voice assistants, usually\nbacked by multiple QA systems. Users ask questions via spontaneous speech which\ncan contain disfluencies, errors, and informal syntax or phrasing. This is a\nmajor challenge in QA, causing unanswered questions or irrelevant answers, and\nleading to bad user experiences. We analyze failed QA requests to identify core\nchallenges: lexical gaps, proposition types, complex syntactic structure, and\nhigh specificity. We propose a Semantic Question Reformulation (SURF) model\noffering three linguistically-grounded operations (repair, syntactic reshaping,\ngeneralization) to rewrite questions to facilitate answering. Offline\nevaluation on 1M unanswered questions from a leading voice assistant shows that\nSURF significantly improves answer rates: up to 24% of previously unanswered\nquestions obtain relevant answers (75%). Live deployment shows positive impact\nfor millions of customers with unanswered questions; explicit relevance\nfeedback shows high user satisfaction.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:19:27 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 05:40:25 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.17394","submitter":"Jungwoo Heo","authors":"Jungwoo Heo and Chan-yeong Lim and Ju-ho Kim and Hyun-seo Shin and\n  Ha-Jin Yu","title":"One-Step Knowledge Distillation and Fine-Tuning in Using Large\n  Pre-Trained Self-Supervised Learning Models for Speaker Verification","comments":"ISCA INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  The application of speech self-supervised learning (SSL) models has achieved\nremarkable performance in speaker verification (SV). However, there is a\ncomputational cost hurdle in employing them, which makes development and\ndeployment difficult. Several studies have simply compressed SSL models through\nknowledge distillation (KD) without considering the target task. Consequently,\nthese methods could not extract SV-tailored features. This paper suggests\nOne-Step Knowledge Distillation and Fine-Tuning (OS-KDFT), which incorporates\nKD and fine-tuning (FT). We optimize a student model for SV during KD training\nto avert the distillation of inappropriate information for the SV. OS-KDFT\ncould downsize Wav2Vec 2.0 based ECAPA-TDNN size by approximately 76.2%, and\nreduce the SSL model's inference time by 79% while presenting an EER of 0.98%.\nThe proposed OS-KDFT is validated across VoxCeleb1 and VoxCeleb2 datasets and\nW2V2 and HuBERT SSL models. Experiments are available on our GitHub.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:20:54 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 03:41:32 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.17395","submitter":"Subhendu Das","authors":"Subhendu Das and Sridhar Tripathy and Jaydeep Datta and Sandip Sarkar\n  and Nayana Majumdar and Supratik Mukhopadhyay","title":"Data acquisition system for muon tracking in a muon scattering\n  tomography setup","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We report here the development of a multi-channel DAQ system for muon\ntracking in a muon scattering tomography setup. The salient features of the\nproposed DAQ system are direct acquisition and processing of LVDS signals, 500\nMHz sampling frequency and scalability. It consists of front-end electronics\nstage built around NINO ASIC. The back-end electronics is configured with\nIntel/Altera MAX-10 FPGA development board which transmits data to the storage\nfollowing UART protocol. The proposed DAQ system has been tested for its\nperformance using a position sensitive glass RPC detector with two-dimensional\n8X8 readout strip configuration.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:27:01 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17396","submitter":"Masahiro Asada","authors":"Masahiro Asada and Safumi Suzuki","title":"Simple model for frequency response of a resonant tunneling diode caused\n  by potential change of quantum well due to electron charge","comments":"5 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.app-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The frequency dependence of negative differential conductance (NDC) is an\nimportant property for the resonant-tunneling-diode terahertz source. Among\nseveral phenomena determining the frequency dependence, this paper shows that\nthe effect of potential change of the quantum well due to electron charge can\nbe analyzed with a simple and tractable model based on the tunneling admittance\nand capacitance. The result is identical to that of Feiginov's analysis based\non more fundamental equations, showing a one-to-one correspondence between the\nparameters of the two analyses. Similar to Feiginov's analysis, our analysis\nalso shows that NDC remains finite even at infinitely high frequency. It is\nshown in our model that this result is attributed to neglecting the tunneling\ntime at the emitter barrier. Comprehensive analysis of the frequency dependence\nof NDC will be possible by incorporating the tunneling time into the present\nmodel.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:28:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17397","submitter":"Gonzalo L\\'opez","authors":"Gonzalo Maximiliano Lopez and Juan Pablo Aparicio","title":"Mathematical model of mating probability and fertilized egg production\n  in helminth parasites","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.PE stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In the modeling of parasite transmission dynamics, understanding the\nreproductive characteristics of these parasites is crucial.\n  This paper presents a mathematical model that explores the reproductive\nbehavior of dioecious parasites and its impact on transmission dynamics.\n  Specifically, the study focuses on the investigation of various reproductive\nvariables such as the mating probability and the fertilized egg production in\nthe case of helminth parasites.\n  While previous studies have commonly assumed Poisson and negative binomial\ndistributions to describe the distribution of parasites among hosts, this study\nadopts an arbitrary distribution model and examines its consequences on some\nreproductive variables. These variables include mean number of fertile females,\nmean egg production, mating probability and mean fertilized egg production.\n  In addition, the study of these variables takes into account the sex\ndistribution of the parasites and whether male and female parasites are\nconsidered to be distributed together or separately.\n  We show that the models obtained for the case of male and female parasites\ndistributed separately in the hosts are ecologically unrealistic.\n  We present the results obtained for some specific models and we tested the\nmodels obtained in this work using Monte Carlo simulations.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:38:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17398","submitter":"Yuan Liu","authors":"Yuan Liu and Peng Wang and Cheng Lin and Xiaoxiao Long and Jiepeng\n  Wang and Lingjie Liu and Taku Komura and Wenping Wang","title":"NeRO: Neural Geometry and BRDF Reconstruction of Reflective Objects from\n  Multiview Images","comments":"Accepted to SIGGRAPH 2023. Project page:\n  https://liuyuan-pal.github.io/NeRO/ Codes:\n  https://github.com/liuyuan-pal/NeRO","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.GR","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We present a neural rendering-based method called NeRO for reconstructing the\ngeometry and the BRDF of reflective objects from multiview images captured in\nan unknown environment. Multiview reconstruction of reflective objects is\nextremely challenging because specular reflections are view-dependent and thus\nviolate the multiview consistency, which is the cornerstone for most multiview\nreconstruction methods. Recent neural rendering techniques can model the\ninteraction between environment lights and the object surfaces to fit the\nview-dependent reflections, thus making it possible to reconstruct reflective\nobjects from multiview images. However, accurately modeling environment lights\nin the neural rendering is intractable, especially when the geometry is\nunknown. Most existing neural rendering methods, which can model environment\nlights, only consider direct lights and rely on object masks to reconstruct\nobjects with weak specular reflections. Therefore, these methods fail to\nreconstruct reflective objects, especially when the object mask is not\navailable and the object is illuminated by indirect lights. We propose a\ntwo-step approach to tackle this problem. First, by applying the split-sum\napproximation and the integrated directional encoding to approximate the\nshading effects of both direct and indirect lights, we are able to accurately\nreconstruct the geometry of reflective objects without any object masks. Then,\nwith the object geometry fixed, we use more accurate sampling to recover the\nenvironment lights and the BRDF of the object. Extensive experiments\ndemonstrate that our method is capable of accurately reconstructing the\ngeometry and the BRDF of reflective objects from only posed RGB images without\nknowing the environment lights and the object masks. Codes and datasets are\navailable at https://github.com/liuyuan-pal/NeRO.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:40:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17399","submitter":"Sumit Kumar Upadhyay","authors":"Amit Kumar, Mani Shankar Pandey and Sumit Kumar Upadhyay","title":"Nilpotency and Capability in multiplicative Lie algebras","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper aims to introduce the concept of nilpotency and capability in\nmultiplicative Lie algebras. Also, we see the existence of covers of a\nmultiplicative Lie algebra and thoroughly examine their relationships with\ncapable and perfect multiplicative Lie algebras.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:46:06 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17400","submitter":"Xiao Hu","authors":"Xiao Hu, Jianxiong Li, Xianyuan Zhan, Qing-Shan Jia, Ya-Qin Zhang","title":"Query-Policy Misalignment in Preference-Based Reinforcement Learning","comments":"The first two authors contributed equally","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Preference-based reinforcement learning (PbRL) provides a natural way to\nalign RL agents' behavior with human desired outcomes, but is often restrained\nby costly human feedback. To improve feedback efficiency, most existing PbRL\nmethods focus on selecting queries to maximally improve the overall quality of\nthe reward model, but counter-intuitively, we find that this may not\nnecessarily lead to improved performance. To unravel this mystery, we identify\na long-neglected issue in the query selection schemes of existing PbRL studies:\nQuery-Policy Misalignment. We show that the seemingly informative queries\nselected to improve the overall quality of reward model actually may not align\nwith RL agents' interests, thus offering little help on policy learning and\neventually resulting in poor feedback efficiency. We show that this issue can\nbe effectively addressed via near on-policy query and a specially designed\nhybrid experience replay, which together enforce the bidirectional query-policy\nalignment. Simple yet elegant, our method can be easily incorporated into\nexisting approaches by changing only a few lines of code. We showcase in\ncomprehensive experiments that our method achieves substantial gains in both\nhuman feedback and RL sample efficiency, demonstrating the importance of\naddressing query-policy misalignment in PbRL tasks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:55:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17401","submitter":"Jinghong Li","authors":"Jinghong Li, Koichi Ota, Wen Gu, Shinobu Hasegawa","title":"A Framework For Refining Text Classification and Object Recognition from\n  Academic Articles","comments":"This paper will be submitted to 'The International Symposium on\n  Innovations in Intelligent SysTems and Applications 2023 (INISTA 2023)'","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the widespread use of the internet, it has become increasingly crucial\nto extract specific information from vast amounts of academic articles\nefficiently. Data mining techniques are generally employed to solve this issue.\nHowever, data mining for academic articles is challenging since it requires\nautomatically extracting specific patterns in complex and unstructured layout\ndocuments. Current data mining methods for academic articles employ\nrule-based(RB) or machine learning(ML) approaches. However, using rule-based\nmethods incurs a high coding cost for complex typesetting articles. On the\nother hand, simply using machine learning methods requires annotation work for\ncomplex content types within the paper, which can be costly. Furthermore, only\nusing machine learning can lead to cases where patterns easily recognized by\nrule-based methods are mistakenly extracted. To overcome these issues, from the\nperspective of analyzing the standard layout and typesetting used in the\nspecified publication, we emphasize implementing specific methods for specific\ncharacteristics in academic articles. We have developed a novel Text Block\nRefinement Framework (TBRF), a machine learning and rule-based scheme hybrid.\nWe used the well-known ACL proceeding articles as experimental data for the\nvalidation experiment. The experiment shows that our approach achieved over 95%\nclassification accuracy and 90% detection accuracy for tables and figures.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:59:49 GMT"},{"version":"v2","created":"Wed, 31 May 2023 06:33:41 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17402","submitter":"Simina Br\\^anzei","authors":"Simina Br\\^anzei and Mahsa Derakhshan and Negin Golrezaei and Yanjun\n  Han","title":"Online Learning in Multi-unit Auctions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider repeated multi-unit auctions with uniform pricing, which are\nwidely used in practice for allocating goods such as carbon licenses. In each\nround, $K$ identical units of a good are sold to a group of buyers that have\nvaluations with diminishing marginal returns. The buyers submit bids for the\nunits, and then a price $p$ is set per unit so that all the units are sold. We\nconsider two variants of the auction, where the price is set to the $K$-th\nhighest bid and $(K+1)$-st highest bid, respectively.\n  We analyze the properties of this auction in both the offline and online\nsettings. In the offline setting, we consider the problem that one player $i$\nis facing: given access to a data set that contains the bids submitted by\ncompetitors in past auctions, find a bid vector that maximizes player $i$'s\ncumulative utility on the data set. We design a polynomial time algorithm for\nthis problem, by showing it is equivalent to finding a maximum-weight path on a\ncarefully constructed directed acyclic graph.\n  In the online setting, the players run learning algorithms to update their\nbids as they participate in the auction over time. Based on our offline\nalgorithm, we design efficient online learning algorithms for bidding. The\nalgorithms have sublinear regret, under both full information and bandit\nfeedback structures. We complement our online learning algorithms with regret\nlower bounds.\n  Finally, we analyze the quality of the equilibria in the worst case through\nthe lens of the core solution concept in the game among the bidders. We show\nthat the $(K+1)$-st price format is susceptible to collusion among the bidders;\nmeanwhile, the $K$-th price format does not have this issue.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:00:49 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17403","submitter":"Osman Berke Guney","authors":"Osman Berke Guney, Deniz Kucukahmetler and Huseyin Ozkan","title":"Source Free Domain Adaptation of a DNN for SSVEP-based Brain-Computer\n  Interfaces","comments":"11 pages (including one page appendix), 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a source free domain adaptation method for steady-state\nvisually evoked potential (SSVEP) based brain-computer interface (BCI)\nspellers. SSVEP-based BCI spellers help individuals experiencing speech\ndifficulties, enabling them to communicate at a fast rate. However, achieving a\nhigh information transfer rate (ITR) in the current methods requires an\nextensive calibration period before using the system, leading to discomfort for\nnew users. We address this issue by proposing a method that adapts the deep\nneural network (DNN) pre-trained on data from source domains (participants of\nprevious experiments conducted for labeled data collection), using only the\nunlabeled data of the new user (target domain). This adaptation is achieved by\nminimizing our proposed custom loss function composed of self-adaptation and\nlocal-regularity loss terms. The self-adaptation term uses the pseudo-label\nstrategy, while the novel local-regularity term exploits the data structure and\nforces the DNN to assign the same labels to adjacent instances. Our method\nachieves striking 201.15 bits/min and 145.02 bits/min ITRs on the benchmark and\nBETA datasets, respectively, and outperforms the state-of-the-art alternative\ntechniques. Our approach alleviates user discomfort and shows excellent\nidentification performance, so it would potentially contribute to the broader\napplication of SSVEP-based BCI systems in everyday life.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:02:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17404","submitter":"Atnafu Lambebo Tonja","authors":"Atnafu Lambebo Tonja, Christian Maldonado-Sifuentes, David Alejandro\n  Mendoza Castillo, Olga Kolesnikova, No\\'e Castro-S\\'anchez, Grigori Sidorov,\n  Alexander Gelbukh","title":"Parallel Corpus for Indigenous Language Translation: Spanish-Mazatec and\n  Spanish-Mixtec","comments":"Accepted to Third Workshop on NLP for Indigenous Languages of the\n  Americas","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we present a parallel Spanish-Mazatec and Spanish-Mixtec\ncorpus for machine translation (MT) tasks, where Mazatec and Mixtec are two\nindigenous Mexican languages. We evaluated the usability of the collected\ncorpus using three different approaches: transformer, transfer learning, and\nfine-tuning pre-trained multilingual MT models. Fine-tuning the Facebook\nM2M100-48 model outperformed the other approaches, with BLEU scores of 12.09\nand 22.25 for Mazatec-Spanish and Spanish-Mazatec translations, respectively,\nand 16.75 and 22.15 for Mixtec-Spanish and Spanish-Mixtec translations,\nrespectively. The findings show that the dataset size (9,799 sentences in\nMazatec and 13,235 sentences in Mixtec) affects translation performance and\nthat indigenous languages work better when used as target languages. The\nfindings emphasize the importance of creating parallel corpora for indigenous\nlanguages and fine-tuning models for low-resource translation tasks. Future\nresearch will investigate zero-shot and few-shot learning approaches to further\nimprove translation performance in low-resource settings. The dataset and\nscripts are available at\n\\url{https://github.com/atnafuatx/Machine-Translation-Resources}\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:03:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17405","submitter":"Janusz Petkowski","authors":"William Bains, Matthew A. Pasek, Sukrit Ranjan, Janusz J. Petkowski,\n  Arthur Omran, Sara Seager","title":"Large Uncertainties in the Thermodynamics of Phosphorus (III) Oxide\n  (P$_4$O$_6$) Have Significant Implications for Phosphorus Species in\n  Planetary Atmospheres","comments":"Article published in ACS Earth Space Chem.\n  https://pubs.acs.org/doi/full/10.1021/acsearthspacechem.3c00016","journal-ref":"ACS Earth Space Chem. May 22, 2023","doi":"10.1021/acsearthspacechem.3c00016","report-no":null,"categories":"astro-ph.EP astro-ph.IM physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Phosphorus (III) oxide (P$_4$O$_6$) has been suggested to be a major\ncomponent of the gas phase phosphorus chemistry in the atmospheres of gas giant\nplanets and of Venus. However, P$_4$O$_6$'s proposed role is based on\nthermodynamic modeling, itself based on values for the free energy of formation\nof P$_4$O$_6$ estimated from limited experimental data. Values of the standard\nGibbs free energy of formation ($\\Delta$Go(g)) of P$_4$O$_6$ in the literature\ndiffer by up to ~656 kJ/mol, a huge range. Depending on which value is assumed,\nP$_4$O$_6$ may either be the majority phosphorus species present or be\ncompletely absent from modeled atmospheres. Here, we critically review the\nliterature thermodynamic values and compare their predictions to observed\nconstraints on P$_4$O$_6$ geochemistry. We conclude that the widely used values\nfrom the NIST/JANAF database are almost certainly too low (predicting that\nP$_4$O$_6$ is more stable than is plausible). We show that, regardless of the\nvalue of $\\Delta$Go(g) for P$_4$O$_6$ assumed, the formation of phosphine from\nP$_4$O$_6$ in the Venusian atmosphere is thermodynamically unfavorable. We\nconclude that there is a need for more robust data on both the thermodynamics\nof phosphorus chemistry for astronomical and geological modeling in general and\nfor understanding the atmosphere of Venus and the gas giant planets in\nparticular.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:07:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17406","submitter":"Atnafu Lambebo Tonja","authors":"Atnafu Lambebo Tonja, Hellina Hailu Nigatu, Olga Kolesnikova, Grigori\n  Sidorov, Alexander Gelbukh, Jugal Kalita","title":"Enhancing Translation for Indigenous Languages: Experiments with\n  Multilingual Models","comments":"Accepted to Third Workshop on NLP for Indigenous Languages of the\n  Americas","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper describes CIC NLP's submission to the AmericasNLP 2023 Shared Task\non machine translation systems for indigenous languages of the Americas. We\npresent the system descriptions for three methods. We used two multilingual\nmodels, namely M2M-100 and mBART50, and one bilingual (one-to-one) -- Helsinki\nNLP Spanish-English translation model, and experimented with different transfer\nlearning setups. We experimented with 11 languages from America and report the\nsetups we used as well as the results we achieved. Overall, the mBART setup was\nable to improve upon the baseline for three out of the eleven languages.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:10:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17407","submitter":"Jose Manuel Torralba Prof.","authors":"S Venkatesh Kumaran, Dariusz Garbiec and Jos\\'e Manuel Torralba","title":"A novel and sustainable method to develop non-equiatomic CoCrFeNiMox\n  high entropy alloys via spark plasma sintering using commercial commodity\n  powders and evaluation of its mechanical behaviour","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A novel approach to developing high entropy alloys (HEAs) using spark plasma\nsintering (SPS) was explored in this work where a mix of commercial commodity\npowders like Ni625, CoCrF75, and 316L was used instead of pre-alloyed powders\navoiding the expensive pre-alloying steps like mechanical alloying or gas\natomizing. Three non-equiatomic HEAs, based on Co, Cr, Fe, Ni, and Mo were\ndesigned and developed by blending the powders which were sintered via SPS and\nresulted in a single FCC phase after homogenization. The HEAs were\nmicrostructurally and mechanically characterized with tensile and hot\ncompression tests up to a temperature of 750oC showing excellent properties.\nThe maximum room temperature tensile strength and ductility demonstrated was\n712 MPa and 62% respectively, by the alloy Co23.28Cr28.57Fe25.03Ni21.01Mo2.1.\nMoreover, the same alloy exhibited a compression strength greater than 640 MPa\nwith a ductility above 45% at a temperature of 750oC. Also, this study paves\nthe way for a novel fabrication route that offers more flexibility to develop\nnew HEAs cost-effectively and efficiently which is crucial for the discovery of\nnew materials over high-throughput techniques. Using such commodity alloys also\nopens the possibility of developing ingot casting from recycled scraps avoiding\nthe direct use of critical metals.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:16:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17408","submitter":"Yangjie Zhou","authors":"Yangjie Zhou, Yaoxu Song, Jingwen Leng, Zihan Liu, Weihao Cui,\n  Zhendong Zhang, Cong Guo, Quan Chen, Li Li, Minyi Guo","title":"AdaptGear: Accelerating GNN Training via Adaptive Subgraph-Level Kernels\n  on GPUs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph neural networks (GNNs) are powerful tools for exploring and learning\nfrom graph structures and features. As such, achieving high-performance\nexecution for GNNs becomes crucially important. Prior works have proposed to\nexplore the sparsity (i.e., low density) in the input graph to accelerate GNNs,\nwhich uses the full-graph-level or block-level sparsity format. We show that\nthey fail to balance the sparsity benefit and kernel execution efficiency. In\nthis paper, we propose a novel system, referred to as AdaptGear, that addresses\nthe challenge of optimizing GNNs performance by leveraging kernels tailored to\nthe density characteristics at the subgraph level. Meanwhile, we also propose a\nmethod that dynamically chooses the optimal set of kernels for a given input\ngraph. Our evaluation shows that AdaptGear can achieve a significant\nperformance improvement, up to $6.49 \\times$ ($1.87 \\times$ on average), over\nthe state-of-the-art works on two mainstream NVIDIA GPUs across various\ndatasets.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:22:12 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17409","submitter":"Omkar Ranadive","authors":"Omkar Ranadive, Nikhil Thakurdesai, Ari S Morcos, Matthew Leavitt,\n  St\\'ephane Deny","title":"On the special role of class-selective neurons in early training","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is commonly observed that deep networks trained for classification exhibit\nclass-selective neurons in their early and intermediate layers. Intriguingly,\nrecent studies have shown that these class-selective neurons can be ablated\nwithout deteriorating network function. But if class-selective neurons are not\nnecessary, why do they exist? We attempt to answer this question in a series of\nexperiments on ResNet-50s trained on ImageNet. We first show that\nclass-selective neurons emerge during the first few epochs of training, before\nreceding rapidly but not completely; this suggests that class-selective neurons\nfound in trained networks are in fact vestigial remains of early training. With\nsingle-neuron ablation experiments, we then show that class-selective neurons\nare important for network function in this early phase of training. We also\nobserve that the network is close to a linear regime in this early phase; we\nthus speculate that class-selective neurons appear early in training as\nquasi-linear shortcut solutions to the classification task. Finally, in causal\nexperiments where we regularize against class selectivity at different points\nin training, we show that the presence of class-selective neurons early in\ntraining is critical to the successful training of the network; in contrast,\nclass-selective neurons can be suppressed later in training with little effect\non final accuracy. It remains to be understood by which mechanism the presence\nof class-selective neurons in the early phase of training contributes to the\nsuccessful training of networks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:22:34 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17410","submitter":"Yue Chen","authors":"Dongxiang Yan, Changhong Zhao, Tongxin Li, Yue Chen","title":"Nested Game for Coupled Power System with Energy Sharing and\n  Transportation System","comments":"12 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The wide deployment of distributed renewable energy sources and electric\nvehicles can help mitigate climate change. This necessitates new business\nmodels in the power sector to hedge against uncertainties while imposing a\nstrong coupling between the connected power and transportation networks. To\naddress these challenges, this paper first proposes an energy sharing mechanism\nconsidering AC power network constraints to encourage local energy exchange in\nthe power system. Under the proposed mechanism, all prosumers play a\ngeneralized Nash game. We prove that the energy sharing equilibrium exists and\nis social optimal. Furthermore, a nested game is built to characterize the\ninteractions both inside and between the power and transportation systems.\nExternally, the two systems are engaged in a Nash game because traffic flows\nserve as electric demands as a result of charging behaviors, and each driver\npays the energy sharing price for charging. The nested game is then converted\ninto a mixed-integer linear program (MILP) with the help of optimality\nconditions and linearization techniques. Numerical experiments validate the\ntheoretical results and show the mutual impact between the two systems.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:32:44 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17411","submitter":"Yiqian Chen","authors":"Yiqian Chen, Peng Wang, Houwen Wu, Haitang Yang","title":"Gravitational Lensing by Born-Infeld Naked Singularities","comments":"7 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We examine the gravitational lensing phenomenon caused by photon spheres in\nthe Born-Infeld naked singularity spacetime, where gravity is coupled with\nBorn-Infeld electrodynamics. Specifically, our focus lies on relativistic\nimages originating from a point-like light source generated by strong\ngravitational lensing near photon spheres, as well as images of a luminous\ncelestial sphere. It shows that Born-Infeld naked singularities consistently\nexhibit one or two photon spheres, which project onto one or two critical\ncurves on the image plane. Interestingly, we discover that the nonlinearity\nnature of the Born-Infeld electrodynamics enables photons to traverse the\nsingularity, leading to the emergence of new relativistic images within the\ninnermost critical curve. Furthermore, the presence of two photon spheres\ndoubles the number of relativistic images compared to the scenario with only a\nsingle photon sphere. Additionally, the transparency inherent to Born-Infeld\nnaked singularities results in the absence of a central shadow in the images of\ncelestial spheres.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:34:00 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17412","submitter":"Laxman Goswami","authors":"Laxman Prasad Goswami, Amita Das, Rohit Juneja, Trishul Dhalia, Anuj\n  Vijay","title":"Two dimensional effects of laser interacting with magnetized plasma","comments":"15 pages, 12 figures, 12 equations","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent advancements in low-frequency short-pulse $CO_2$ lasers and the\nproduction of strong magnetic fields have made experimental studies on laser\ninteractions with magnetized plasma a near-future possibility. Therefore,\ntheoretical and numerical simulation studies have been pursued lately in this\ndirection [A. Das, Review of Modern Plasma Physics 4, 1 (2020)] illustrating a\nhost of novel phenomena related to laser energy absorption [Vashistha et al.,\nNew Journal of Physics, 22(6):063023 (2020); Goswami et al., Plasma Physics and\nControlled Fusion 63, 115003 (2021)], harmonic generation [Maity et al.,\nJournal of Plasma Physics, 87(5) (2021)], etc. However, most of these studies\nhave been carried out in one-dimensional geometry with the laser having\ninfinite transverse extent, and the plasma target was considered cold. This\nmanuscript explores the manifestation of the 2-D and thermal effects on the\nproblem of a laser interacting with magnetized plasma. As expected, additional\ntransverse ponderomotive force is shown to be operative. A finite temperature\nof the target, along with transverse density stratification generates, leads to\ndiamagnetic drift for the two plasma species. The imbalance of this drift\nbetween the two species can be an additional effect leading to an enhancement\nof laser energy absorption. The Particle - In - Cell (PIC) simulations with the\nOSIRIS4.0 platform is used to explore these features.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:34:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17413","submitter":"J. W. van Holten","authors":"J.W. van Holten","title":"Dynamics of cosmological scalar fields","comments":"14 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.CO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper reviews the dynamics of an isotropic and homogeneous cosmological\nscalar field. A general approach to the solution of the Einstein-Klein-Gordon\nequations is developed, which does not require slow-roll or other\napproximations. General conclusions about the qualitative behaviour of the\nsolutions can be drawn, and examples of explicit solutions for some interesting\ncases are given. It is also shown how to find scalar potentials giving rise to\na predetermined scalar field behaviour and associated evolution of the scale\nfactor.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:35:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17414","submitter":"Quan Quan","authors":"Quan Quan, Runxiao Liu, Hao Liu, Zeqing Ma, Jinrui Ren","title":"An Image Based Visual Servo Method for Probe-and-Drogue Autonomous\n  Aerial Refueling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  With the high focus on autonomous aerial refueling recently, it becomes\nincreasingly urgent to design efficient methods or algorithms to solve AAR\nproblems in complicated aerial environments. Apart from the complex aerodynamic\ndisturbance, another problem is the pose estimation error caused by the camera\ncalibration error, installation error, or 3D object modeling error, which may\nnot satisfy the highly accurate docking. The main objective of the effort\ndescribed in this paper is the implementation of an image-based visual servo\ncontrol method, which contains the establishment of an image-based visual servo\nmodel involving the receiver's dynamics and the design of the corresponding\ncontroller. Simulation results indicate that the proposed method can make the\nsystem dock successfully under complicated conditions and improve the\nrobustness against pose estimation error.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:37:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17415","submitter":"Zhibin Lan","authors":"Zhibin Lan, Jiawei Yu, Xiang Li, Wen Zhang, Jian Luan, Bin Wang, Degen\n  Huang, Jinsong Su","title":"Exploring Better Text Image Translation with Multimodal Codebook","comments":"Accepted by ACL 2023 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Text image translation (TIT) aims to translate the source texts embedded in\nthe image to target translations, which has a wide range of applications and\nthus has important research value. However, current studies on TIT are\nconfronted with two main bottlenecks: 1) this task lacks a publicly available\nTIT dataset, 2) dominant models are constructed in a cascaded manner, which\ntends to suffer from the error propagation of optical character recognition\n(OCR). In this work, we first annotate a Chinese-English TIT dataset named\nOCRMT30K, providing convenience for subsequent studies. Then, we propose a TIT\nmodel with a multimodal codebook, which is able to associate the image with\nrelevant texts, providing useful supplementary information for translation.\nMoreover, we present a multi-stage training framework involving text machine\ntranslation, image-text alignment, and TIT tasks, which fully exploits\nadditional bilingual texts, OCR dataset and our OCRMT30K dataset to train our\nmodel. Extensive experiments and in-depth analyses strongly demonstrate the\neffectiveness of our proposed model and training framework.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:41:18 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 12:38:37 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.17416","submitter":"Asahi Ushio","authors":"Asahi Ushio and Fernando Alva-Manchego and Jose Camacho-Collados","title":"A Practical Toolkit for Multilingual Question and Answer Generation","comments":"Accepted by ACL 2023 System Demonstration","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generating questions along with associated answers from a text has\napplications in several domains, such as creating reading comprehension tests\nfor students, or improving document search by providing auxiliary questions and\nanswers based on the query. Training models for question and answer generation\n(QAG) is not straightforward due to the expected structured output (i.e. a list\nof question and answer pairs), as it requires more than generating a single\nsentence. This results in a small number of publicly accessible QAG models. In\nthis paper, we introduce AutoQG, an online service for multilingual QAG, along\nwith lmqg, an all-in-one Python package for model fine-tuning, generation, and\nevaluation. We also release QAG models in eight languages fine-tuned on a few\nvariants of pre-trained encoder-decoder language models, which can be used\nonline via AutoQG or locally via lmqg. With these resources, practitioners of\nany level can benefit from a toolkit that includes a web interface for end\nusers, and easy-to-use code for developers who require custom models or\nfine-grained controls for generation.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:42:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17417","submitter":"Hao Geng","authors":"Hao Geng, Deqing Wang, Fuzhen Zhuang, Xuehua Ming, Chenguang Du, Ting\n  Jiang, Haolong Guo, Rui Liu","title":"Modeling Dynamic Heterogeneous Graph and Node Importance for Future\n  Citation Prediction","comments":"Accepted by CIKM'2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DL cs.LG physics.soc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accurate citation count prediction of newly published papers could help\neditors and readers rapidly figure out the influential papers in the future.\nThough many approaches are proposed to predict a paper's future citation, most\nignore the dynamic heterogeneous graph structure or node importance in academic\nnetworks. To cope with this problem, we propose a Dynamic heterogeneous Graph\nand Node Importance network (DGNI) learning framework, which fully leverages\nthe dynamic heterogeneous graph and node importance information to predict\nfuture citation trends of newly published papers. First, a dynamic\nheterogeneous network embedding module is provided to capture the dynamic\nevolutionary trends of the whole academic network. Then, a node importance\nembedding module is proposed to capture the global consistency relationship to\nfigure out each paper's node importance. Finally, the dynamic evolutionary\ntrend embeddings and node importance embeddings calculated above are combined\nto jointly predict the future citation counts of each paper, by a log-normal\ndistribution model according to multi-faced paper node representations.\nExtensive experiments on two large-scale datasets demonstrate that our model\nsignificantly improves all indicators compared to the SOTA models.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:53:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17418","submitter":"Klaus Bongartz","authors":"Klaus Bongartz","title":"On representation-finite selfinjective algebras, coverings,\n  multiplicative bases ...","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give a simplified complete proof for the classification of the\nselfinjective representation-finite algebras of finite dimension over an\nalgebraically closed field. We explain the relations between the two different\napproaches and also to further developments. Many historical remarks are made.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:54:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17419","submitter":"Ben Moews PhD","authors":"Ben Moews","title":"On random number generators and practical market efficiency","comments":"Preprint, accepted for publication in Journal of the Operational\n  Research Society","journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.ST q-fin.CP stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Modern mainstream financial theory is underpinned by the efficient market\nhypothesis, which posits the rapid incorporation of relevant information into\nasset pricing. Limited prior studies in the operational research literature\nhave investigated the use of tests designed for random number generators to\ncheck for these informational efficiencies. Treating binary daily returns as a\nhardware random number generator analogue, tests of overlapping permutations\nhave indicated that these time series feature idiosyncratic recurrent patterns.\nContrary to prior studies, we split our analysis into two streams at the annual\nand company level, and investigate longer-term efficiency over a larger time\nframe for Nasdaq-listed public companies to diminish the effects of trading\nnoise and allow the market to realistically digest new information. Our results\ndemonstrate that information efficiency varies across different years and\nreflects large-scale market impacts such as financial crises. We also show the\nproximity to results of a logistic map comparison, discuss the distinction\nbetween theoretical and practical market efficiency, and find that the\nstatistical qualification of stock-separated returns in support of the\nefficient market hypothesis is dependent on the driving factor of small\ninefficient subsets that skew market assessments.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:55:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17420","submitter":"RuiYang Ju","authors":"Rui-Yang Ju, Yu-Shian Lin, Jen-Shiun Chiang, Chih-Chia Chen, Wei-Han\n  Chen, Chun-Tse Chien","title":"CCDWT-GAN: Generative Adversarial Networks Based on Color Channel Using\n  Discrete Wavelet Transform for Document Image Binarization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To efficiently extract the textual information from color degraded document\nimages is an important research topic. Long-term imperfect preservation of\nancient documents has led to various types of degradation such as page\nstaining, paper yellowing, and ink bleeding; these degradations badly impact\nthe image processing for information extraction. In this paper, we present\nCCDWT-GAN, a generative adversarial network (GAN) that utilizes the discrete\nwavelet transform (DWT) on RGB (red, green, blue) channel splited images. The\nproposed method comprises three stages: image preprocessing, image enhancement,\nand image binarization. This work conducts comparative experiments in the image\npreprocessing stage to determine the optimal selection of DWT with\nnormalization. Additionally, we perform an ablation study on the results of the\nimage enhancement stage and the image binarization stage to validate their\npositive effect on the model performance. This work compares the performance of\nthe proposed method with other state-of-the-art (SOTA) methods on DIBCO and\nH-DIBCO ((Handwritten) Document Image Binarization Competition) datasets. The\nexperimental results demonstrate that CCDWT-GAN achieves a top two performance\non multiple benchmark datasets, and outperforms other SOTA methods.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:55:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17421","submitter":"Marawan Elbatel","authors":"Marawan Elbatel, Robert Mart\\'i, and Xiaomeng Li","title":"FoPro-KD: Fourier Prompted Effective Knowledge Distillation for\n  Long-Tailed Medical Image Recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transfer learning is a promising technique for medical image classification,\nparticularly for long-tailed datasets. However, the scarcity of data in medical\nimaging domains often leads to overparameterization when fine-tuning large\npublicly available pre-trained models. Moreover, these large models are\nineffective in deployment in clinical settings due to their computational\nexpenses. To address these challenges, we propose FoPro-KD, a novel approach\nthat unleashes the power of frequency patterns learned from frozen publicly\navailable pre-trained models to enhance their transferability and compression.\nFoPro-KD comprises three modules: Fourier prompt generator (FPG), effective\nknowledge distillation (EKD), and adversarial knowledge distillation (AKD). The\nFPG module learns to generate targeted perturbations conditional on a target\ndataset, exploring the representations of a frozen pre-trained model, trained\non natural images. The EKD module exploits these generalizable representations\nthrough distillation to a smaller target model, while the AKD module further\nenhances the distillation process. Through these modules, FoPro-KD achieves\nsignificant improvements in performance on long-tailed medical image\nclassification benchmarks, demonstrating the potential of leveraging the\nlearned frequency patterns from pre-trained models to enhance transfer learning\nand compression of large pre-trained models for feasible deployment.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:01:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17422","submitter":"Gabriel Roccabruna","authors":"Gabriel Roccabruna, Seyed Mahed Mousavi, Giuseppe Riccardi","title":"Understanding Emotion Valence is a Joint Deep Learning Task","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The valence analysis of speakers' utterances or written posts helps to\nunderstand the activation and variations of the emotional state throughout the\nconversation. More recently, the concept of Emotion Carriers (EC) has been\nintroduced to explain the emotion felt by the speaker and its manifestations.\nIn this work, we investigate the natural inter-dependency of valence and ECs\nvia a multi-task learning approach. We experiment with Pre-trained Language\nModels (PLM) for single-task, two-step, and joint settings for the valence and\nEC prediction tasks. We compare and evaluate the performance of generative\n(GPT-2) and discriminative (BERT) architectures in each setting. We observed\nthat providing the ground truth label of one task improves the prediction\nperformance of the models in the other task. We further observed that the\ndiscriminative model achieves the best trade-off of valence and EC prediction\ntasks in the joint prediction setting. As a result, we attain a single model\nthat performs both tasks, thus, saving computation resources at training and\ninference times.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:07:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17423","submitter":"Zihao Yu","authors":"Zihao Yu, Haoyang Li, Fangcheng Fu, Xupeng Miao, Bin Cui","title":"FISEdit: Accelerating Text-to-image Editing via Cache-enabled Sparse\n  Diffusion Inference","comments":"12 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to the recent success of diffusion models, text-to-image generation is\nbecoming increasingly popular and achieves a wide range of applications. Among\nthem, text-to-image editing, or continuous text-to-image generation, attracts\nlots of attention and can potentially improve the quality of generated images.\nIt's common to see that users may want to slightly edit the generated image by\nmaking minor modifications to their input textual descriptions for several\nrounds of diffusion inference. However, such an image editing process suffers\nfrom the low inference efficiency of many existing diffusion models even using\nGPU accelerators. To solve this problem, we introduce Fast Image Semantically\nEdit (FISEdit), a cached-enabled sparse diffusion model inference engine for\nefficient text-to-image editing. The key intuition behind our approach is to\nutilize the semantic mapping between the minor modifications on the input text\nand the affected regions on the output image. For each text editing step,\nFISEdit can automatically identify the affected image regions and utilize the\ncached unchanged regions' feature map to accelerate the inference process.\nExtensive empirical results show that FISEdit can be $3.4\\times$ and\n$4.4\\times$ faster than existing methods on NVIDIA TITAN RTX and A100 GPUs\nrespectively, and even generates more satisfactory images.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:14:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17424","submitter":"Zhao Wu","authors":"Yonglin Yu, Shuo Xu, Lei Zhang, Ziqian Shang, Chenglong Qiao, Shuqi\n  Li, Zhao Wu, Yanrui Su, Hongqiang Song, Yao Chen and Fabao Yan","title":"Two-element interferometer for millimeter-wave solar flare observations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper, we present the design and implementation of a two-element\ninterferometer working in the millimeter wave band (39.5 GHz - 40 GHz) for\nobserving solar radio emissions through nulling interference. The system is\ncomposed of two 50 cm aperture Cassegrain antennas mounted on a common\nequatorial mount, with a separation of 230 wavelengths. The cross-correlation\nof the received signals effectively cancels the quiet solar component of the\nlarge flux density (~3000 sfu) that reduces the detection limit due to\natmospheric fluctuations. The system performance is obtained as follows: the\nnoise factor of the AFE in the observation band is less than 2.1 dB, system\nsensitivity is approximately 12.4 K (~34 sfu) with an integration time constant\nof 0.1 ms (default), the frequency resolution is 153 kHz, and the dynamic range\nis larger than 30 dB. Through actual testing, the nulling interferometer\nobserves a quiet sun with a low level of output fluctuations (of up to 50 sfu)\nand has a significantly lower radiation flux variability (of up to 190 sfu)\nthan an equivalent single-antenna system, even under thick cloud cover. As a\nresult, this new design can effectively improve observation sensitivity by\nreducing the impact of atmospheric and system fluctuations during observation.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:14:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17425","submitter":"Olivier Bernard","authors":"Olivier Bernard, Pierre-Alain Fouque and Andrea Lesavourey","title":"Computing $e$-th roots in number fields","comments":"9 pages, 4 figures. Associated experimental code provided at\n  https://github.com/ob3rnard/eth-roots","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We describe several algorithms for computing $e$-th roots of elements in a\nnumber field $K$, where $e$ is an odd prime-power integer. In particular we\ngeneralize Couveignes' and Thom\\'e's algorithms originally designed to compute\nsquare-roots in the Number Field Sieve algorithm for integer factorization. Our\nalgorithms cover most cases of $e$ and $K$ and allow to obtain reasonable\ntimings even for large degree number fields and large exponents $e$. The\ncomplexity of our algorithms is better than general root finding algorithms and\nour implementation compared well in performance to these algorithms implemented\nin well-known computer algebra softwares. One important application of our\nalgorithms is to compute the saturation phase in the Twisted-PHS algorithm for\ncomputing the Ideal-SVP problem over cyclotomic fields in post-quantum\ncryptography.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:19:29 GMT"},{"version":"v2","created":"Tue, 30 May 2023 10:45:23 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17426","submitter":"Jane Y.X. Yang","authors":"X. Gao, F.Z.K. Li, L. Wan, J.Y.X. Yang","title":"On the combinatorics of descents and inverse descents in the\n  hyperoctahedral group","comments":"41 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The elements in the hyperoctahedral group $\\mathfrak{B}_n$ can be treated as\nsigned permutations with the natural order $\\cdots<-2<-1<0<1<2<\\cdots$, or as\ncolored permutations with the $r$-order\n$-1<_r-2<_r\\cdots<_r0<_r1<_r2<_r\\cdots$. For any $\\pi\\in\\mathfrak{B}_n$, let\n$\\operatorname{des}^B(\\pi)$ and $\\operatorname{ides}^B(\\pi)$ be the number of\ndescents and inverse descents in $\\pi$ under the natural order, and let\n$\\operatorname{des}_B(\\pi)$ and $\\operatorname{ides}_B(\\pi)$ be the number of\ndescents and inverse descents in $\\pi$ under the $r$-order. In this paper, by\ninvestigating signed permutation grids under both the natural order and the\n$r$-order, we give combinatorial proofs for six recurrence formulas of the\njoint distribution of descents and inverse descents over the hyperoctahedral\ngroup $\\mathfrak{B}_n$, the set in involutions of $\\mathfrak{B}_n$ denoted by\n$\\mathcal{I}_n^B$, and the set of fixed-point free involutions in\n$\\mathfrak{B}_n$ denoted by $\\mathcal{J}_n^B$, respectively. Some of these six\nformulas are new, and some reveal the combinatorial essences of the results\nobtained by Visontai, Moustakas and Cao-Liu through algebraic approaches such\nas quasisymmetric functions. Furthermore, from these formulas, we conclude that\n$(\\operatorname{des}^B,\\operatorname{ides}^B)$ and\n$(\\operatorname{des}_B,\\operatorname{ides}_B)$ are equidistributed over both\n$\\mathfrak{B}_n$ and $\\mathcal{I}_n^B$, but not on $\\mathcal{J}_n^B$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:20:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17427","submitter":"Dag Evensberget","authors":"Dag Evensberget, Stephen C. Marsden, Bradley D. Carter, Raquel\n  Salmeron, Aline A. Vidotto, Colin P. Folsom, Robert D. Kavanagh, Florian A.\n  Driessen, K. Markus Strickert","title":"The winds of young Solar-type stars in the Pleiades, AB Doradus, Columba\n  and $\\beta$ Pictoris","comments":"19 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Solar-type stars, which shed angular momentum via magnetised stellar winds,\nenter the main sequence with a wide range of rotational periods $P_\\text{rot}$.\nThis initially wide range of rotational periods contracts and has mostly\nvanished by a stellar age $t\\sim0.6$ Gyr, after which Solar-type stars spin\naccording to the Skumanich relation $P_\\text{rot}\\propto\\sqrt t$.\nMagnetohydrodynamic stellar wind models can improve our understanding of this\nconvergence of rotation periods. We present wind models of fifteen young\nSolar-type stars aged from 24 Myr to 0.13 Gyr. With our previous wind models of\nstars aged 0.26 Gyr and 0.6 Gyr we obtain thirty consistent three-dimensional\nwind models of stars mapped with Zeeman-Doppler imaging - the largest such set\nto date. The models provide good cover of the pre-Skumanich phase of stellar\nspin-down in terms of rotation, magnetic field, and age. We find that the mass\nloss rate $\\dot M\\propto\\Phi^{0.9\\pm0.1}$ with a residual spread of 150% and\nthat the wind angular momentum loss rate $\\dot J\\propto{}P_\\text{rot}^{-1}\n\\Phi^{1.3\\pm0.2}$ with a residual spread of 500% where $\\Phi$ is the unsigned\nsurface magnetic flux. When comparing different magnetic field scalings for\neach single star we find a gradual reduction in the power-law exponent with\nincreasing magnetic field strength.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:22:27 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17428","submitter":"Smitha Milli","authors":"Smitha Milli, Emma Pierson, Nikhil Garg","title":"Choosing the Right Weights: Balancing Value, Strategy, and Noise in\n  Recommender Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Many recommender systems are based on optimizing a linear weighting of\ndifferent user behaviors, such as clicks, likes, shares, etc. Though the choice\nof weights can have a significant impact, there is little formal study or\nguidance on how to choose them. We analyze the optimal choice of weights from\nthe perspectives of both users and content producers who strategically respond\nto the weights. We consider three aspects of user behavior: value-faithfulness\n(how well a behavior indicates whether the user values the content),\nstrategy-robustness (how hard it is for producers to manipulate the behavior),\nand noisiness (how much estimation error there is in predicting the behavior).\nOur theoretical results show that for users, upweighting more value-faithful\nand less noisy behaviors leads to higher utility, while for producers,\nupweighting more value-faithful and strategy-robust behaviors leads to higher\nwelfare (and the impact of noise is non-monotonic). Finally, we discuss how our\nresults can help system designers select weights in practice.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:37:58 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17429","submitter":"Richeek Das","authors":"Richeek Das, Aaron Jerry Ninan, Adithya Bhaskar, Ajit Rajwade","title":"Performance Bounds for LASSO under Multiplicative Noise: Applications to\n  Pooled RT-PCR Testing","comments":"Signal Processing Journal under review","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Group testing is a technique which avoids individually testing $n$ samples\nfor a rare disease and instead tests $n < p$ pools, where a pool consists of a\nmixture of small, equal portions of a subset of the $p$ samples. Group testing\nsaves testing time and resources in many applications, including RT-PCR, with\nguarantees for the recovery of the status of the $p$ samples from results on\n$n$ pools. The noise in quantitative RT- PCR is inherently known to follow a\nmultiplicative data-dependent model. In recent literature, the corresponding\nlinear systems for inferring the health status of $p$ samples from results on\n$n$ pools have been solved using the Lasso estimator and its variants, which\nhave been typically used in additive Gaussian noise settings. There is no\nexisting literature which establishes performance bounds for Lasso for the\nmultiplicative noise model associated with RT-PCR. After noting that a recent\ngeneral technique, Hunt et al., works for Poisson inverse problems, we adapt it\nto handle sparse signal reconstruction from compressive measurements with\nmultiplicative noise: we present high probability performance bounds and\ndata-dependent weights for the Lasso and its weighted version. We also show\nnumerical results on simulated pooled RT-PCR data to empirically validate our\nbounds.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:41:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17430","submitter":"Lena Patterer Ms.","authors":"Lena Patterer, Pavel Ondra\\v{c}ka, Dimitri Bogdanovski, Stanislav\n  Mr\\'az, Peter J. P\\\"ollmann, Soheil Karimi Aghda, Petr Va\\v{s}ina, Jochen M.\n  Schneider","title":"Bond formation at polycarbonate | X interfaces (X = Al$_2$O$_3$,\n  TiO$_2$, TiAlO$_2$) studied by theory and experiments","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Interfacial bond formation during sputter deposition of metal oxide thin\nfilms onto polycarbonate (PC) is investigated by ab initio molecular dynamics\nsimulations and X-ray photoelectron spectroscopy (XPS) analysis of PC | X\ninterfaces (X = Al$_2$O$_3$, TiO$_2$, TiAlO$_2$). Generally, the predicted bond\nformation is consistent with the experimental data. For all three interfaces,\nthe majority of bonds identified by XPS are (C-O)-metal bonds, whereas C-metal\nbonds are the minority. Compared to the PC | Al$_2$O$_3$ interface, the PC |\nTiO$_2$ and PC | TiAlO$_2$ interfaces exhibit a reduction in the measured\ninterfacial bond density by ~ 75 and ~ 65%, respectively. Multiplying the\npredicted bond strength with the corresponding experimentally determined\ninterfacial bond density shows that Al$_2$O$_3$ exhibits the strongest\ninterface with PC, while TiO$_2$ and TiAlO$_2$ exhibit ~ 70 and ~ 60% weaker\ninterfaces, respectively. This can be understood by considering the complex\ninterplay between the metal oxide composition, the bond strength as well as the\npopulation of bonds that are formed across the interface.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 09:53:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17431","submitter":"Zicheng Zhang","authors":"Zicheng Zhang, Bonan Li, Xuecheng Nie, Congying Han, Tiande Guo, Luoqi\n  Liu","title":"Towards Consistent Video Editing with Text-to-Image Diffusion Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing works have advanced Text-to-Image (TTI) diffusion models for video\nediting in a one-shot learning manner. Despite their low requirements of data\nand computation, these methods might produce results of unsatisfied consistency\nwith text prompt as well as temporal sequence, limiting their applications in\nthe real world. In this paper, we propose to address the above issues with a\nnovel EI$^2$ model towards \\textbf{E}nhancing v\\textbf{I}deo \\textbf{E}diting\ncons\\textbf{I}stency of TTI-based frameworks. Specifically, we analyze and find\nthat the inconsistent problem is caused by newly added modules into TTI models\nfor learning temporal information. These modules lead to covariate shift in the\nfeature space, which harms the editing capability. Thus, we design EI$^2$ to\ntackle the above drawbacks with two classical modules: Shift-restricted\nTemporal Attention Module (STAM) and Fine-coarse Frame Attention Module (FFAM).\nFirst, through theoretical analysis, we demonstrate that covariate shift is\nhighly related to Layer Normalization, thus STAM employs a \\textit{Instance\nCentering} layer replacing it to preserve the distribution of temporal\nfeatures. In addition, {STAM} employs an attention layer with normalized\nmapping to transform temporal features while constraining the variance shift.\nAs the second part, we incorporate {STAM} with a novel {FFAM}, which\nefficiently leverages fine-coarse spatial information of overall frames to\nfurther enhance temporal consistency. Extensive experiments demonstrate the\nsuperiority of the proposed EI$^2$ model for text-driven video editing.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:03:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17432","submitter":"Yushan Zhang","authors":"Yushan Zhang, Johan Edstedt, Bastian Wandt, Per-Erik Forss\\'en, Maria\n  Magnusson, Michael Felsberg","title":"GMSF: Global Matching Scene Flow","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We tackle the task of scene flow estimation from point clouds. Given a source\nand a target point cloud, the objective is to estimate a translation from each\npoint in the source point cloud to the target, resulting in a 3D motion vector\nfield. Previous dominant scene flow estimation methods require complicated\ncoarse-to-fine or recurrent architectures as a multi-stage refinement. In\ncontrast, we propose a significantly simpler single-scale one-shot global\nmatching to address the problem. Our key finding is that reliable feature\nsimilarity between point pairs is essential and sufficient to estimate accurate\nscene flow. To this end, we propose to decompose the feature extraction step\nvia a hybrid local-global-cross transformer architecture which is crucial to\naccurate and robust feature representations. Extensive experiments show that\nGMSF sets a new state-of-the-art on multiple scene flow estimation benchmarks.\nOn FlyingThings3D, with the presence of occlusion points, GMSF reduces the\noutlier percentage from the previous best performance of 27.4% to 11.7%. On\nKITTI Scene Flow, without any fine-tuning, our proposed method shows\nstate-of-the-art performance.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:04:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17433","submitter":"Avinash Madasu","authors":"Mauajama Firdaus, Avinash Madasu, Asif Ekbal","title":"A Unified Framework for Slot based Response Generation in a Multimodal\n  Dialogue System","comments":"Published in the journal Multimedia Tools and Applications","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Natural Language Understanding (NLU) and Natural Language Generation (NLG)\nare the two critical components of every conversational system that handles the\ntask of understanding the user by capturing the necessary information in the\nform of slots and generating an appropriate response in accordance with the\nextracted information. Recently, dialogue systems integrated with complementary\ninformation such as images, audio, or video have gained immense popularity. In\nthis work, we propose an end-to-end framework with the capability to extract\nnecessary slot values from the utterance and generate a coherent response,\nthereby assisting the user to achieve their desired goals in a multimodal\ndialogue system having both textual and visual information. The task of\nextracting the necessary information is dependent not only on the text but also\non the visual cues present in the dialogue. Similarly, for the generation, the\nprevious dialog context comprising multimodal information is significant for\nproviding coherent and informative responses. We employ a multimodal\nhierarchical encoder using pre-trained DialoGPT and also exploit the knowledge\nbase (Kb) to provide a stronger context for both the tasks. Finally, we design\na slot attention mechanism to focus on the necessary information in a given\nutterance. Lastly, a decoder generates the corresponding response for the given\ndialogue context and the extracted slot values. Experimental results on the\nMultimodal Dialogue Dataset (MMD) show that the proposed framework outperforms\nthe baselines approaches in both the tasks. The code is available at\nhttps://github.com/avinashsai/slot-gpt.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:06:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17434","submitter":"Kento Sasaki","authors":"Kento Sasaki, Yuki Nakamura, Tokuyuki Teraji, Takashi Oka, Kensuke\n  Kobayashi","title":"Demonstration of geometric diabatic control of quantum states","comments":null,"journal-ref":"Phys. Rev. A 107, 053113 (2023)","doi":"10.1103/PhysRevA.107.053113","report-no":null,"categories":"quant-ph cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Geometric effects can play a pivotal role in streamlining quantum\nmanipulation. We demonstrate a geometric diabatic control, that is, perfect\ntunneling between spin states in a diamond by a quadratic sweep of a driving\nfield. The field sweep speed for the perfect tunneling is determined by the\ngeometric amplitude factor and can be tuned arbitrarily. Our results are\nobtained by testing a quadratic version of Berry's twisted Landau-Zener model.\nThis geometric tuning is robust over a wide parameter range. Our work provides\na basis for quantum control in various systems, including condensed matter\nphysics, quantum computation, and nuclear magnetic resonance.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:07:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17435","submitter":"Elad Romanov","authors":"Elad Romanov","title":"On the Noise Sensitivity of the Randomized SVD","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.NA math.IT math.NA math.ST stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The randomized singular value decomposition (R-SVD) is a popular\nsketching-based algorithm for efficiently computing the partial SVD of a large\nmatrix. When the matrix is low-rank, the R-SVD produces its partial SVD\nexactly; but when the rank is large, it only yields an approximation.\n  Motivated by applications in data science and principal component analysis\n(PCA), we analyze the R-SVD under a low-rank signal plus noise measurement\nmodel; specifically, when its input is a spiked random matrix. The singular\nvalues produced by the R-SVD are shown to exhibit a BBP-like phase transition:\nwhen the SNR exceeds a certain detectability threshold, that depends on the\ndimension reduction factor, the largest singular value is an outlier; below the\nthreshold, no outlier emerges from the bulk of singular values. We further\ncompute asymptotic formulas for the overlap between the ground truth signal\nsingular vectors and the approximations produced by the R-SVD.\n  Dimensionality reduction has the adverse affect of amplifying the noise in a\nhighly nonlinear manner. Our results demonstrate the statistical advantage --\nin both signal detection and estimation -- of the R-SVD over more naive\nsketched PCA variants; the advantage is especially dramatic when the sketching\ndimension is small. Our analysis is asymptotically exact, and substantially\nmore fine-grained than existing operator-norm error bounds for the R-SVD, which\nlargely fail to give meaningful error estimates in the moderate SNR regime. It\napplies for a broad family of sketching matrices previously considered in the\nliterature, including Gaussian i.i.d. sketches, random projections, and the\nsub-sampled Hadamard transform, among others.\n  Lastly, we derive an optimal singular value shrinker for singular values and\nvectors obtained through the R-SVD, which may be useful for applications in\nmatrix denoising.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:15:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17436","submitter":"Yusheng Tian","authors":"Yusheng Tian, Guangyan Zhang, Tan Lee","title":"Creating Personalized Synthetic Voices from Post-Glossectomy Speech with\n  Guided Diffusion Models","comments":"submitted to INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper is about developing personalized speech synthesis systems with\nrecordings of mildly impaired speech. In particular, we consider consonant and\nvowel alterations resulted from partial glossectomy, the surgical removal of\npart of the tongue. The aim is to restore articulation in the synthesized\nspeech and maximally preserve the target speaker's individuality. We propose to\ntackle the problem with guided diffusion models. Specifically, a\ndiffusion-based speech synthesis model is trained on original recordings, to\ncapture and preserve the target speaker's original articulation style. When\nusing the model for inference, a separately trained phone classifier will guide\nthe synthesis process towards proper articulation. Objective and subjective\nevaluation results show that the proposed method substantially improves\narticulation in the synthesized speech over original recordings, and preserves\nmore of the target speaker's individuality than a voice conversion baseline.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:17:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17437","submitter":"Furao Shen","authors":"Xin Xiong (1), Furao Shen (1), Xiangyu Wang (1), Jian Zhao (2) ((1)\n  School of Artificial Intelligence, Nanjing University, (2) School of\n  Electronic Science and Engineering, Nanjing University)","title":"GIMM: InfoMin-Max for Automated Graph Contrastive Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph contrastive learning (GCL) shows great potential in unsupervised graph\nrepresentation learning. Data augmentation plays a vital role in GCL, and its\noptimal choice heavily depends on the downstream task. Many GCL methods with\nautomated data augmentation face the risk of insufficient information as they\nfail to preserve the essential information necessary for the downstream task.\nTo solve this problem, we propose InfoMin-Max for automated Graph contrastive\nlearning (GIMM), which prevents GCL from encoding redundant information and\nlosing essential information. GIMM consists of two major modules: (1) automated\ngraph view generator, which acquires the approximation of InfoMin's optimal\nviews through adversarial training without requiring task-relevant information;\n(2) view comparison, which learns an excellent encoder by applying InfoMax to\nview representations. To the best of our knowledge, GIMM is the first method\nthat combines the InfoMin and InfoMax principles in GCL. Besides, GIMM\nintroduces randomness to augmentation, thus stabilizing the model against\nperturbations. Extensive experiments on unsupervised and semi-supervised\nlearning for node and graph classification demonstrate the superiority of our\nGIMM over state-of-the-art GCL methods with automated and manual data\naugmentation.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:24:22 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17438","submitter":"Xiao Li","authors":"Xiao Li and Hang Chen and Xiaolin Hu","title":"On the Importance of Backbone to the Adversarial Robustness of Object\n  Detectors","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Object detection is a critical component of various security-sensitive\napplications, such as autonomous driving and video surveillance. However,\nexisting deep learning-based object detectors are vulnerable to adversarial\nattacks, which poses a significant challenge to their reliability and safety.\nThrough experiments, we found that existing works on improving the adversarial\nrobustness of object detectors have given a false sense of security. We argue\nthat using adversarially pre-trained backbone networks is essential for\nenhancing the adversarial robustness of object detectors. We propose a simple\nyet effective recipe for fast adversarial fine-tuning on object detectors with\nadversarially pre-trained backbones. Without any modifications to the structure\nof object detectors, our recipe achieved significantly better adversarial\nrobustness than previous works. Moreover, we explore the potential of different\nmodern object detectors to improve adversarial robustness using our recipe and\ndemonstrate several interesting findings. Our empirical results set a new\nmilestone and deepen the understanding of adversarially robust object\ndetection. Code and trained checkpoints will be publicly available.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:26:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17439","submitter":"Samuele Mongodi","authors":"Gian Maria Dall'Ara, Samuele Mongodi","title":"Remarks on the Levi core","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV math.GN","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate a few aspects of the notion of Levi core, introduced by the\nauthors in a previous work: a basic finiteness question, the connections with\nKohn's algorithm and with Catlin's property (P).\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:32:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17440","submitter":"Sijie Cheng","authors":"Xuanjie Fang, Sijie Cheng, Yang Liu, Wei Wang","title":"Modeling Adversarial Attack on Pre-trained Language Models as Sequential\n  Decision Making","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained language models (PLMs) have been widely used to underpin various\ndownstream tasks. However, the adversarial attack task has found that PLMs are\nvulnerable to small perturbations. Mainstream methods adopt a detached\ntwo-stage framework to attack without considering the subsequent influence of\nsubstitution at each step. In this paper, we formally model the adversarial\nattack task on PLMs as a sequential decision-making problem, where the whole\nattack process is sequential with two decision-making problems, i.e., word\nfinder and word substitution. Considering the attack process can only receive\nthe final state without any direct intermediate signals, we propose to use\nreinforcement learning to find an appropriate sequential attack path to\ngenerate adversaries, named SDM-Attack. Extensive experimental results show\nthat SDM-Attack achieves the highest attack success rate with a comparable\nmodification rate and semantic similarity to attack fine-tuned BERT.\nFurthermore, our analyses demonstrate the generalization and transferability of\nSDM-Attack. The code is available at https://github.com/fduxuan/SDM-Attack.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:33:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17441","submitter":"Bernhard M\\\"uller","authors":"Thomas Maunder (1), Bernhard M\\\"uller (1), Fionntan Callan (2), Stuart\n  Sim (2), Alexander Heger (2), ((1) Monash University, (2) Queen's University\n  Belfast)","title":"Synthetic Light Curves and Spectra from a Self-Consistent 2D Simulation\n  of an Ultra-strippped Supernova","comments":"13 pages, 14 figures, submitted to MNRAS","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spectroscopy is an important tool for providing insights into the structure\nof core-collapse supernova explosions. We use the Monte Carlo radiative\ntransfer code ARTIS to compute synthetic spectra and light curves based on a\ntwo-dimensional explosion model of an ultra-stripped supernova. These\ncalculations are designed both to identify observable fingerprints of\nultra-stripped supernovae and as a proof-of-principle for using synthetic\nspectroscopy to constrain the nature of stripped-envelope supernovae more\nbroadly. We predict very characteristic spectral and photometric features for\nour ultra-stripped explosion model, but find that these do not match observed\nultra-stripped supernova candidates like SN 2005ek. With a peak bolometric\nluminosity of $6.8\\times10^{41}\\,\\mathrm{erg}\\,\\mathrm{s}^{-1}$, a peak\nmagnitude of $-15.9\\,\\mathrm{mag}$ in R-band, and $\\Delta\nm_{15,\\mathrm{R}}=3.50$, the model is even fainter and evolves even faster than\nSN 2005ek as the closest possible analogue in photometric properties. The\npredicted spectra are extremely unusual. The most prominent features are Mg II\nlines at 2,800 Angstrom and 4,500 Angstrom and the infrared Ca triplet at late\ntimes. The Mg lines are sensitive to the multi-dimensional structure of the\nmodel and are viewing-angle dependent. They disappear due to line blanketing by\nFe group elements in a spherically averaged model with additional microscopic\nmixing. In future studies, multi-D radiative transfer calculations need to be\napplied to a broader range of models to elucidate the nature of observed Type\nIb/c supernovae.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:40:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17442","submitter":"Dawei Zhu","authors":"Dawei Zhu, Xiaoyu Shen, Marius Mosbach, Andreas Stephan, Dietrich\n  Klakow","title":"Weaker Than You Think: A Critical Look atWeakly Supervised Learning","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Weakly supervised learning is a popular approach for training machine\nlearning models in low-resource settings. Instead of requesting high-quality\nyet costly human annotations, it allows training models with noisy annotations\nobtained from various weak sources. Recently, many sophisticated approaches\nhave been proposed for robust training under label noise, reporting impressive\nresults. In this paper, we revisit the setup of these approaches and find that\nthe benefits brought by these approaches are significantly overestimated.\nSpecifically, we find that the success of existing weakly supervised learning\napproaches heavily relies on the availability of clean validation samples\nwhich, as we show, can be leveraged much more efficiently by simply training on\nthem. After using these clean labels in training, the advantages of using these\nsophisticated approaches are mostly wiped out. This remains true even when\nreducing the size of the available clean data to just five samples per class,\nmaking these approaches impractical. To understand the true value of weakly\nsupervised learning, we thoroughly analyse diverse NLP datasets and tasks to\nascertain when and why weakly supervised approaches work, and provide\nrecommendations for future research.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:46:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17443","submitter":"Simone Baldi","authors":"Di Liu, Sebastian Mair, Kang Yang, Simone Baldi, Paolo Frasca,\n  Matthias Althoff","title":"Resilience in Platoons of Cooperative Heterogeneous Vehicles:\n  Self-organization Strategies and Provably-correct Design","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This work proposes provably-correct self-organizing strategies for platoons\nof heterogeneous vehicles. We refer to self-organization as the capability of a\nplatoon to autonomously homogenize to a common group behavior. We show that\nself-organization promotes resilience to acceleration limits and communication\nfailures, i.e., homogenizing to a common group behavior makes the platoon\nrecover from these causes of impairments. In the presence of acceleration\nlimits, resilience is achieved by self-organizing to a common constrained group\nbehavior that prevents the vehicles from hitting their acceleration limits. In\nthe presence of communication failures, resilience is achieved by\nself-organizing to a common group observer to estimate the missing information.\nStability of the self-organization mechanism is studied analytically, and\ncorrectness with respect to traffic actions (e.g. emergency braking, cut-in,\nmerging) is realized through a provably-correct safety layer. Numerical\nvalidations via the platooning toolbox OpenCDA in CARLA and via the CommonRoad\nplatform confirm improved performance through self-organization and the\nprovably-correct safety layer.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:00:07 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17444","submitter":"Deokjae Lee","authors":"Deokjae Lee, JunYeong Lee, Jung-Woo Ha, Jin-Hwa Kim, Sang-Woo Lee,\n  Hwaran Lee, Hyun Oh Song","title":"Query-Efficient Black-Box Red Teaming via Bayesian Optimization","comments":"ACL 2023 Long Paper - Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL cs.CR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The deployment of large-scale generative models is often restricted by their\npotential risk of causing harm to users in unpredictable ways. We focus on the\nproblem of black-box red teaming, where a red team generates test cases and\ninteracts with the victim model to discover a diverse set of failures with\nlimited query access. Existing red teaming methods construct test cases based\non human supervision or language model (LM) and query all test cases in a\nbrute-force manner without incorporating any information from past evaluations,\nresulting in a prohibitively large number of queries. To this end, we propose\nBayesian red teaming (BRT), novel query-efficient black-box red teaming methods\nbased on Bayesian optimization, which iteratively identify diverse positive\ntest cases leading to model failures by utilizing the pre-defined user input\npool and the past evaluations. Experimental results on various user input pools\ndemonstrate that our method consistently finds a significantly larger number of\ndiverse positive test cases under the limited query budget than the baseline\nmethods. The source code is available at\nhttps://github.com/snu-mllab/Bayesian-Red-Teaming.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:00:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17445","submitter":"Chun Yong Chong","authors":"Julia Kaiwen Lau, Kelvin Kai Wen Kong, Julian Hao Yong, Per Hoong Tan,\n  Zhou Yang, Zi Qian Yong, Joshua Chern Wey Low, Chun Yong Chong, Mei Kuan Lim,\n  and David Lo","title":"Synthesizing Speech Test Cases with Text-to-Speech? An Empirical Study\n  on the False Alarms in Automated Speech Recognition Testing","comments":"12 pages, Accepted at ISSTA2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent studies have proposed the use of Text-To-Speech (TTS) systems to\nautomatically synthesise speech test cases on a scale and uncover a large\nnumber of failures in ASR systems. However, the failures uncovered by synthetic\ntest cases may not reflect the actual performance of an ASR system when it\ntranscribes human audio, which we refer to as false alarms. Given a failed test\ncase synthesised from TTS systems, which consists of TTS-generated audio and\nthe corresponding ground truth text, we feed the human audio stating the same\ntext to an ASR system. If human audio can be correctly transcribed, an instance\nof a false alarm is detected. In this study, we investigate false alarm\noccurrences in five popular ASR systems using synthetic audio generated from\nfour TTS systems and human audio obtained from two commonly used datasets. Our\nresults show that the least number of false alarms is identified when testing\nDeepspeech, and the number of false alarms is the highest when testing\nWav2vec2. On average, false alarm rates range from 21% to 34% in all five ASR\nsystems. Among the TTS systems used, Google TTS produces the least number of\nfalse alarms (17%), and Espeak TTS produces the highest number of false alarms\n(32%) among the four TTS systems. Additionally, we build a false alarm\nestimator that flags potential false alarms, which achieves promising results:\na precision of 98.3%, a recall of 96.4%, an accuracy of 98.5%, and an F1 score\nof 97.3%. Our study provides insight into the appropriate selection of TTS\nsystems to generate high-quality speech to test ASR systems. Additionally, a\nfalse alarm estimator can be a way to minimise the impact of false alarms and\nhelp developers choose suitable test inputs when evaluating ASR systems. The\nsource code used in this paper is publicly available on GitHub at\nhttps://github.com/julianyonghao/FAinASRtest.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:07:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17446","submitter":"Zhong Zhang","authors":"Zhong Zhang, Bang Liu, Junming Shao","title":"Fine-tuning Happens in Tiny Subspaces: Exploring Intrinsic Task-specific\n  Subspaces of Pre-trained Language Models","comments":"ACL 2023 (main conference, long paper)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained language models (PLMs) are known to be overly parameterized and\nhave significant redundancy, indicating a small degree of freedom of the PLMs.\nMotivated by the observation, in this paper, we study the problem of\nre-parameterizing and fine-tuning PLMs from a new perspective: Discovery of\nintrinsic task-specific subspace. Specifically, by exploiting the dynamics of\nthe fine-tuning process for a given task, the parameter optimization trajectory\nis learned to uncover its intrinsic task-specific subspace. A key finding is\nthat PLMs can be effectively fine-tuned in the subspace with a small number of\nfree parameters. Beyond, we observe some outlier dimensions emerging during\nfine-tuning in the subspace. Disabling these dimensions degrades the model\nperformance significantly. This suggests that these dimensions are crucial to\ninduce task-specific knowledge to downstream tasks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:16:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17447","submitter":"Nicola Zamponi","authors":"Jingwei Hu, Ansgar J\\\"ungel, Nicola Zamponi","title":"Global weak solutions for a nonlocal multispecies Fokker-Planck-Landau\n  system","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The global-in-time existence of weak solutions to a spatially homogeneous\nmultispecies Fokker-Planck-Landau system for plasmas in the three-dimensional\nwhole space is shown. The Fokker-Planck-Landau system is a simplification of\nthe Landau equations assuming a linearized, velocity-independent, and isotropic\nkernel. The resulting equations depend nonlocally and nonlinearly on the\nmoments of the distribution functions via the multispecies local Maxwellians.\nThe existence proof is based on a three-level approximation scheme, energy and\nentropy estimates, as well as compactness results, and it holds for both soft\nand hard potentials.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:16:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17448","submitter":"Ting Xu","authors":"Ting Xu, Huiyun Yang, Zhen Wu, Jiaze Chen, Fei Zhao, Xinyu Dai","title":"Measuring Your ASTE Models in The Wild: A Diversified Multi-domain\n  Dataset For Aspect Sentiment Triplet Extraction","comments":"15pages, 5 figures, ACL2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Aspect Sentiment Triplet Extraction (ASTE) is widely used in various\napplications. However, existing ASTE datasets are limited in their ability to\nrepresent real-world scenarios, hindering the advancement of research in this\narea. In this paper, we introduce a new dataset, named DMASTE, which is\nmanually annotated to better fit real-world scenarios by providing more diverse\nand realistic reviews for the task. The dataset includes various lengths,\ndiverse expressions, more aspect types, and more domains than existing\ndatasets. We conduct extensive experiments on DMASTE in multiple settings to\nevaluate previous ASTE approaches. Empirical results demonstrate that DMASTE is\na more challenging ASTE dataset. Further analyses of in-domain and cross-domain\nsettings provide promising directions for future research. Our code and dataset\nare available at https://github.com/NJUNLP/DMASTE.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:21:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17449","submitter":"Munkhjargal Gochoo","authors":"Munkhjargal Gochoo, Munkh-Erdene Otgonbold, Erkhembayar Ganbold,\n  Jun-Wei Hsieh, Ming-Ching Chang, Ping-Yang Chen, Byambaa Dorj, Hamad Al\n  Jassmi, Ganzorig Batnasan, Fady Alnajjar, Mohammed Abduljabbar, Fang-Pang Lin","title":"FishEye8K: A Benchmark and Dataset for Fisheye Camera Object Detection","comments":"CVPR Workshops 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With the advance of AI, road object detection has been a prominent topic in\ncomputer vision, mostly using perspective cameras. Fisheye lens provides\nomnidirectional wide coverage for using fewer cameras to monitor road\nintersections, however with view distortions. To our knowledge, there is no\nexisting open dataset prepared for traffic surveillance on fisheye cameras.\nThis paper introduces an open FishEye8K benchmark dataset for road object\ndetection tasks, which comprises 157K bounding boxes across five classes\n(Pedestrian, Bike, Car, Bus, and Truck). In addition, we present benchmark\nresults of State-of-The-Art (SoTA) models, including variations of YOLOv5,\nYOLOR, YOLO7, and YOLOv8. The dataset comprises 8,000 images recorded in 22\nvideos using 18 fisheye cameras for traffic monitoring in Hsinchu, Taiwan, at\nresolutions of 1080$\\times$1080 and 1280$\\times$1280. The data annotation and\nvalidation process were arduous and time-consuming, due to the ultra-wide\npanoramic and hemispherical fisheye camera images with large distortion and\nnumerous road participants, particularly people riding scooters. To avoid bias,\nframes from a particular camera were assigned to either the training or test\nsets, maintaining a ratio of about 70:30 for both the number of images and\nbounding boxes in each class. Experimental results show that YOLOv8 and YOLOR\noutperform on input sizes 640$\\times$640 and 1280$\\times$1280, respectively.\nThe dataset will be available on GitHub with PASCAL VOC, MS COCO, and YOLO\nannotation formats. The FishEye8K benchmark will provide significant\ncontributions to the fisheye video analytics and smart city applications.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:26:25 GMT"},{"version":"v2","created":"Tue, 6 Jun 2023 07:02:32 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.17450","submitter":"Alexander Kruchkov","authors":"Alexander Kruchkov","title":"Anomalous conductivity of $\\mathcal{PT}$-symmetric Fermi liquids","comments":"5 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el cond-mat.other","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a non-Hermitian yet $\\mathcal{PT}$-symmetric Fermi liquid\n($\\mathcal{PT}$-FL) in external electric fields. Due to\n$\\mathcal{PT}$-symmetry, the system exhibits real spectrum, Fermi surface and\nelectric conductivity are well-defined through propagators. We find that, in\ncontrast to the conventional Fermi liquids (FL), the $\\mathcal{PT}$-FL can\nexhibit a zero resistance state in the longitudinal ($xx$) channel. Moreover,\nthe temperature dependence of the resistivity anomaly violates the conventional\nFL scaling (it is not limited by $T^2$). These findings open route to further\nexploration of transport anomalies beyond the conventional paradigm.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:26:47 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17451","submitter":"Lina Achaji","authors":"Lina Achaji, Julien Moreau, Fran\\c{c}ois Aioun, Fran\\c{c}ois\n  Charpillet","title":"Analysis over vision-based models for pedestrian action anticipation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Anticipating human actions in front of autonomous vehicles is a challenging\ntask. Several papers have recently proposed model architectures to address this\nproblem by combining multiple input features to predict pedestrian crossing\nactions. This paper focuses specifically on using images of the pedestrian's\ncontext as an input feature. We present several spatio-temporal model\narchitectures that utilize standard CNN and Transformer modules to serve as a\nbackbone for pedestrian anticipation. However, the objective of this paper is\nnot to surpass state-of-the-art benchmarks but rather to analyze the positive\nand negative predictions of these models. Therefore, we provide insights on the\nexplainability of vision-based Transformer models in the context of pedestrian\naction prediction. We will highlight cases where the model can achieve correct\nquantitative results but falls short in providing human-like explanations\nqualitatively, emphasizing the importance of investing in explainability for\npedestrian action anticipation problems.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:30:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17452","submitter":"Shubham Mishra","authors":"Shubham Mishra, Sourav Pal, Aditya Srivastav, Anurag Tripathi","title":"Multiparton Cwebs at five loops","comments":"46 pages, 29 figures, 27 tables and 1 ancillary file","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Scattering amplitudes involving multiple partons are plagued with infrared\nsingularities. The soft singularities of the amplitude are captured by the soft\nfunction which is defined as the vacuum expectation value of Wilson line\ncorrelators. Renormalization properties of soft function allows us to write it\nas an exponential of the finite soft anomalous dimension. An efficient way to\nstudy the soft function is through a set of Feynman diagrams known as Cwebs\n(webs). We obtain the mixing matrices and exponentiated colour factors for all\nthe Cwebs at five loops that connect six massless Wilson lines. Our results are\nthe first key ingredient for the calculation of the soft anomalous dimension at\nfive loops.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:40:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17454","submitter":"Sahil Mishra","authors":"Sahil Mishra, Sanjaya Kumar Panda","title":"Cloud Computing: Applications, Challenges and Open Issues","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cloud computing is one of the innovative computing, which deals with storing\nand accessing data and programs over the Internet [1]. It is the delivery of\ncomputing resources and services, such as storing of data on servers and\ndatabases, providing networking facilities and software development platforms\nover the Internet. It provides the flexibility of resources for everyone. These\nservices are provided via data centers, which are located in various parts of\nthe world [2, 3]. Cloud computing makes access to these resources to everyone\non a global scale at a very minimal cost and significantly higher speed. These\nservers provide services to the users, which would have cost a lot of\ncomputational power to them if they had to buy them. The first mention of cloud\ncomputing was referenced in a Compaq internal document released in 1996 [4].\nCloud computing was then commercialized in 2006 when Amazon released elastic\ncompute cloud (EC2). Furthermore, Google released Google app engine in 2008 and\nMicrosoft Azure services were launched in October 2008, which increased the\ncompetition in the area of cloud computing. Since then these companies have\ndone a lot of development in cloud computing.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:52:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17455","submitter":"Dachuan Shi","authors":"Dachuan Shi, Chaofan Tao, Anyi Rao, Zhendong Yang, Chun Yuan, Jiaqi\n  Wang","title":"CrossGET: Cross-Guided Ensemble of Tokens for Accelerating\n  Vision-Language Transformers","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vision-language models have achieved tremendous progress far beyond what we\never expected. However, their computational costs and latency are also\ndramatically growing with rapid development, making model acceleration\nexceedingly critical for researchers with limited resources and consumers with\nlow-end devices. Although extensively studied for unimodal models, the\nacceleration for multimodal models, especially the vision-language\nTransformers, is still relatively under-explored. Accordingly, this paper\nproposes \\textbf{Cross}-\\textbf{G}uided \\textbf{E}nsemble of \\textbf{T}okens\n(\\textbf{\\emph{CrossGET}}) as a universal vison-language Transformer\nacceleration framework, which adaptively reduces token numbers during inference\nvia cross-modal guidance on-the-fly, leading to significant model acceleration\nwhile keeping high performance. Specifically, the proposed \\textit{CrossGET}\nhas two key designs:1) \\textit{Cross-Guided Matching and Ensemble}.\n\\textit{CrossGET} incorporates cross-modal guided token matching and ensemble\nto merge tokens effectively, only introducing cross-modal tokens with\nnegligible extra parameters. 2) \\textit{Complete-Graph Soft Matching}. In\ncontrast to the previous bipartite soft matching approach, \\textit{CrossGET}\nintroduces an efficient and effective complete-graph soft matching policy to\nachieve more reliable token-matching results. Extensive experiments on various\nvision-language tasks, datasets, and model architectures demonstrate the\neffectiveness and versatility of the proposed \\textit{CrossGET} framework. The\ncode will be at https://github.com/sdc17/CrossGET.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:07:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17456","submitter":"Lucas Fidon","authors":"Lucas Fidon","title":"Trustworthy Deep Learning for Medical Image Segmentation","comments":"PhD thesis successfully defended on 1st July 2022. Examiners: Prof\n  Sotirios Tsaftaris and Dr Wenjia Bai","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite the recent success of deep learning methods at achieving new\nstate-of-the-art accuracy for medical image segmentation, some major\nlimitations are still restricting their deployment into clinics. One major\nlimitation of deep learning-based segmentation methods is their lack of\nrobustness to variability in the image acquisition protocol and in the imaged\nanatomy that were not represented or were underrepresented in the training\ndataset. This suggests adding new manually segmented images to the training\ndataset to better cover the image variability. However, in most cases, the\nmanual segmentation of medical images requires highly skilled raters and is\ntime-consuming, making this solution prohibitively expensive. Even when\nmanually segmented images from different sources are available, they are rarely\nannotated for exactly the same regions of interest. This poses an additional\nchallenge for current state-of-the-art deep learning segmentation methods that\nrely on supervised learning and therefore require all the regions of interest\nto be segmented for all the images to be used for training. This thesis\nintroduces new mathematical and optimization methods to mitigate those\nlimitations.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:12:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17457","submitter":"Elias Zavitsanos","authors":"Elias Zavitsanos, Dimitris Mavroeidis, Konstantinos Bougiatiotis,\n  Eirini Spyropoulou, Lefteris Loukas, Georgios Paliouras","title":"Financial misstatement detection: a realistic evaluation","comments":"9 pages, ICAIF2021","journal-ref":"Proceedings of the Second ACM International Conference on AI in\n  Finance, no 34, 2021","doi":"10.1145/3490354.3494453","report-no":null,"categories":"cs.CL cs.LG q-fin.CP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we examine the evaluation process for the task of detecting\nfinancial reports with a high risk of containing a misstatement. This task is\noften referred to, in the literature, as ``misstatement detection in financial\nreports''. We provide an extensive review of the related literature. We propose\na new, realistic evaluation framework for the task which, unlike a large part\nof the previous work: (a) focuses on the misstatement class and its rarity, (b)\nconsiders the dimension of time when splitting data into training and test and\n(c) considers the fact that misstatements can take a long time to detect. Most\nimportantly, we show that the evaluation process significantly affects system\nperformance, and we analyze the performance of different models and feature\ntypes in the new realistic framework.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:19:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17458","submitter":"Fangqi Zhu","authors":"Fangqi Zhu, Lin Zhang, Jun Gao, Bing Qin, Ruifeng Xu, Haiqin Yang","title":"A Diffusion Model for Event Skeleton Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Event skeleton generation, aiming to induce an event schema skeleton graph\nwith abstracted event nodes and their temporal relations from a set of event\ninstance graphs, is a critical step in the temporal complex event schema\ninduction task. Existing methods effectively address this task from a graph\ngeneration perspective but suffer from noise-sensitive and error accumulation,\ne.g., the inability to correct errors while generating schema. We, therefore,\npropose a novel Diffusion Event Graph Model~(DEGM) to address these issues. Our\nDEGM is the first workable diffusion model for event skeleton generation, where\nthe embedding and rounding techniques with a custom edge-based loss are\nintroduced to transform a discrete event graph into learnable latent\nrepresentation. Furthermore, we propose a denoising training process to\nmaintain the model's robustness. Consequently, DEGM derives the final schema,\nwhere error correction is guaranteed by iteratively refining the latent\nrepresentation during the schema generation process. Experimental results on\nthree IED bombing datasets demonstrate that our DEGM achieves better results\nthan other state-of-the-art baselines. Our code and data are available at\nhttps://github.com/zhufq00/EventSkeletonGeneration.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:19:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17459","submitter":"Lena Patterer Ms.","authors":"Lena Patterer, Sabrina Kollmann, Teresa de los Arcos, Leonie Jende,\n  Soheil Karimi Aghda, Damian M. Holzapfel, Sameer Aman Salman, Stanislav\n  Mr\\'az, Guido Grundmeier, Jochen M. Schneider","title":"Large-area deposition of protective (Ti,Al)N coatings onto polycarbonate","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Polycarbonate (PC) and protective (Ti,Al)N coatings exhibit extremely\ndifferent material properties, specifically crystal structure, thermal\nstability, elastic and plastic behavior as well as thermal expansion\ncoefficients. These differences present formidable challenges for the\ndeposition process development as low-temperature synthesis routes have to be\nexplored to avoid a thermal overload of the polymer substrate. Here, a\nlarge-area sputtering process is developed to address the challenges by\nsystematically adjusting target peak power density and duty cycle. Adhering\n(Ti,Al)N coatings with a critical residual tensile stress of 2.2 +/- 0.2 GPa\nare obtained in the pulsed direct current magnetron sputtering range, whereas\ndepositions at higher target peak power densities, realized by high power\npulsed magnetron sputtering, lead to stress-induced adhesive and/or cohesive\nfailure. The stress-optimized (Ti,Al)N coatings deposited onto PC with a target\npeak power density of 0.036 kW cm-2 and a duty cycle of 5.3% were investigated\nby cross-cut test confirming adhesion. By investigating the bond formation at\nthe PC | (Ti,Al)N interface, mostly interfacial CNx bonds and a small fraction\nof (C-O)-(Ti,Al) bonds are identified by X-ray photoelectron spectroscopy,\nindicating reactions at the hydrocarbon and the carbonate groups during\ndeposition. Nanoindentation reveals an elastic modulus of 296 +/- 18 GPa for\nthe (Ti,Al)N coating, while a Ti-Al-O layer is formed during electrochemical\nimpedance spectroscopy in a borate buffer solution, indicating protective\npassivation. This work demonstrates that the challenge posed by the extremely\ndifferent material properties at the interface of soft polymer substrates and\nhard coatings can be addressed by systematical variation of the pulsing\nparameters to reduce the residual film stress.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:23:55 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17460","submitter":"Xiyan Peng","authors":"Xiyan Peng, Zhaoxiang Qi, Tianmeng Zhang, Zhenyu Wu, Zhimin Zhou,\n  Jundan Nie, Hu Zou, Xiaohui Fan, Linhua Jiang, Ian McGreer, Jinyi Yang, Arjun\n  Dey, Jun Ma, Jiali Wang, David Schlegel, and Xu Zhou","title":"Astrometric Calibration of the Beijing$-$Arizona Sky Survey","comments":"The article has been published on AJ, 11 pages, 12 figures","journal-ref":null,"doi":"10.3847/1538-3881/acbc78","report-no":null,"categories":"astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present the astrometric calibration of the Beijing-Arizona Sky Survey\n(BASS). The BASS astrometry was tied to the International Celestial Reference\nFrame via the \\emph{Gaia} Data Release 2 reference catalog. For effects that\nwere stable throughout the BASS observations, including differential chromatic\nrefraction and the low charge transfer efficiency of the CCD, we corrected for\nthese effects at the raw image coordinates. Fourth-order polynomial\nintermediate longitudinal and latitudinal corrections were used to remove\noptical distortions. The comparison with the \\emph{Gaia} catalog shows that the\nsystematic errors, depending on color or magnitude, are less than 2\nmilliarcseconds (mas). The position systematic error is estimated to be about\n$-0.01\\pm0.7$ mas in the region between 30 and 60 degrees of declination and up\nto $-0.07 \\pm 0.9$ mas in the region north of declination 60 degrees.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:34:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17461","submitter":"Shu-Min Wu","authors":"Rui-Di Wang, Shu-Min Wu, Xiao-Li Huang","title":"Nonlocal coherence harvesting from quantum vacuum","comments":"18 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It is well known that nonlocal coherence reflects nonclassical correlations\nbetter than quantum entan-glement. Here, we analyze nonlocal coherence\nharvesting from the quantum vacuum to particle detectors adiabatically\ninteracting with a quantum scalar field in Minkowski spacetime. We find that\nthe harvesting-achievable separation range of nonlocal coherence is larger than\nthat of quantum entanglement. As the energy gap grows sufficiently large, the\ndetectors harvest less quantum coherence, while the detectors could extract\nmore quantum entanglement from the vacuum state. Compared with the linear\nconfiguration and the scalene configuration, the equilateral triangle\nconfiguration is the best model to harvest tripartite coherence. Finally, we\nfind a monogamous relationship, which means that tripartite l1-norm of\ncoherence is essentially bipartite types.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:39:10 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17462","submitter":"Subhradip Ghosh","authors":"Mandira Das, Himanshu Murari, Subhradip Ghosh, Biplab Sanyal","title":"Effects of Chemical and magnetic disorder on the electrochemical\n  properties of V$_{2-x}$Mn$_{x}$CO$_{2}$} MXene electrodes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Investigation of structure-property relations in chemically and magnetically\ndisordered materials can give rise to interesting physical phenomena. The\npotential of two-dimensional MXenes as electrodes in supercapacitor\napplications have been studied extensively. However, the role of chemical and\nmagnetic disorder on their electrochemical parameters like the capacitance have\nnot been explored yet. In this work, we have systematically addressed this for\nV$_{2-x}$Mn$_{x}$CO$_{2}$ MXene solid solutions with an analysis based upon\nresults from first-principles electronic structure calculations. We find that\nthe variations in the total capacitance over a voltage window depends upon the\ndegree of chemical and magnetic disorder. In course of our investigation, we\nalso found out that the magnetic structure on the surface can substantially\ninfluence the redox charge transfer, an yet unexplored phenomenon. A\nsignificantly large charge transfer and thus a large capacitance can be\nobtained by manipulating the chemical composition and the magnetic order of the\nsurfaces.These findings can be useful in designing operational supercapacitor\nelectrodes with magnetic constituents.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:40:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17463","submitter":"YuehCheng Huang","authors":"Yueh-Cheng Huang, Chen-Tao Hsu, and Jen-Hui Chuang","title":"Pentagon-Match (PMatch): Identification of View-Invariant Planar Feature\n  for Local Feature Matching-Based Homography Estimation","comments":"arXiv admin note: text overlap with arXiv:2211.03007","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In computer vision, finding correct point correspondence among images plays\nan important role in many applications, such as image stitching, image\nretrieval, visual localization, etc. Most of the research works focus on the\nmatching of local feature before a sampling method is employed, such as RANSAC,\nto verify initial matching results via repeated fitting of certain global\ntransformation among the images. However, incorrect matches may still exist.\nThus, a novel sampling scheme, Pentagon-Match (PMatch), is proposed in this\nwork to verify the correctness of initially matched keypoints using pentagons\nrandomly sampled from them. By ensuring shape and location of these pentagons\nare view-invariant with various evaluations of cross-ratio (CR), incorrect\nmatches of keypoint can be identified easily with homography estimated from\ncorrectly matched pentagons. Experimental results show that highly accurate\nestimation of homography can be obtained efficiently for planar scenes of the\nHPatches dataset, based on keypoint matching results provided by LoFTR.\nBesides, accurate outlier identification for the above matching results and\npossible extension of the approach for multi-plane situation are also\ndemonstrated.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:41:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17464","submitter":"Sergio Moreschini","authors":"Sergio Moreschini, Elham Younesian, David H\\\"astbacka, Michele Albano,\n  Ji\\v{r}\\'i Ho\\v{s}ek and Davide Taibi","title":"Edge to Cloud Tools: A Multivocal Literature Review","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Edge-to-cloud computing is an emerging paradigm for distributing\ncomputational tasks between edge devices and cloud resources. Different\napproaches for orchestration, offloading, and many more purposes have been\nintroduced in research. However, it is still not clear what has been\nimplemented in the industry. This work aims to merge this gap by mapping the\nexisting knowledge on edge-to-cloud tools by providing an overview of the\ncurrent state of research in this area and identifying research gaps and\nchallenges. For this purpose, we conducted a Multivocal Literature Review (MLR)\nby analyzing 40 tools from 1073 primary studies (220 PS from the white\nliterature and 853 PS from the gray literature). We categorized the tools based\non their characteristics and targeted environments. Overall, this systematic\nmapping study provides a comprehensive overview of edge-to-cloud tools and\nhighlights several opportunities for researchers and practitioners for future\nresearch in this area.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:42:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17465","submitter":"Benjamin Laufer","authors":"Benjamin Laufer, Thomas Krendl Gilbert, Helen Nissenbaum","title":"Optimization's Neglected Normative Commitments","comments":"14 pages, 1 figure, presentation at FAccT23","journal-ref":null,"doi":"10.1145/3593013.3593976","report-no":null,"categories":"cs.AI cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Optimization is offered as an objective approach to resolving complex,\nreal-world decisions involving uncertainty and conflicting interests. It drives\nbusiness strategies as well as public policies and, increasingly, lies at the\nheart of sophisticated machine learning systems. A paradigm used to approach\npotentially high-stakes decisions, optimization relies on abstracting the real\nworld to a set of decision(s), objective(s) and constraint(s). Drawing from the\nmodeling process and a range of actual cases, this paper describes the\nnormative choices and assumptions that are necessarily part of using\noptimization. It then identifies six emergent problems that may be neglected:\n1) Misspecified values can yield optimizations that omit certain imperatives\naltogether or incorporate them incorrectly as a constraint or as part of the\nobjective, 2) Problematic decision boundaries can lead to faulty modularity\nassumptions and feedback loops, 3) Failing to account for multiple agents'\ndivergent goals and decisions can lead to policies that serve only certain\nnarrow interests, 4) Mislabeling and mismeasurement can introduce bias and\nimprecision, 5) Faulty use of relaxation and approximation methods,\nunaccompanied by formal characterizations and guarantees, can severely impede\napplicability, and 6) Treating optimization as a justification for action,\nwithout specifying the necessary contextual information, can lead to ethically\ndubious or faulty decisions. Suggestions are given to further understand and\ncurb the harms that can arise when optimization is used wrongfully.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:43:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17466","submitter":"Vyacheslav Shaprynskii","authors":"Vyacheslav Yu. Shaprynski\\v{i}","title":"Semiring identities in the semigroup $B_0$","comments":"13 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The semigroup $B_0$ is the only, up to isomorphism, 4-element subsemigroup of\nthe 5-element Brandt semigroup $B_2$. Being an inverse semigroup, the semigroup\n$B_2$ can naturally be considered an additively idempotent semiring and $B_0$\nis its subsemiring. We show that the semiring $B_0$ has a finite basis of\nidentities.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:46:17 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17467","submitter":"Linan Zhang","authors":"Xiaofan Lu, Linan Zhang and Hongjin He","title":"Structured model selection via $\\ell_1-\\ell_2$ optimization","comments":"Wanted to revise","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.IT cs.LG math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automated model selection is an important application in science and\nengineering. In this work, we develop a learning approach for identifying\nstructured dynamical systems from undersampled and noisy spatiotemporal data.\nThe learning is performed by a sparse least-squares fitting over a large set of\ncandidate functions via a nonconvex $\\ell_1-\\ell_2$ sparse optimization solved\nby the alternating direction method of multipliers. Using a Bernstein-like\ninequality with a coherence condition, we show that if the set of candidate\nfunctions forms a structured random sampling matrix of a bounded orthogonal\nsystem, the recovery is stable and the error is bounded. The learning approach\nis validated on synthetic data generated by the viscous Burgers' equation and\ntwo reaction-diffusion equations. The computational results demonstrate the\ntheoretical guarantees of success and the efficiency with respect to the\nambient dimension and the number of candidate functions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:51:26 GMT"},{"version":"v2","created":"Tue, 30 May 2023 00:54:10 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17468","submitter":"Michael Roysdon","authors":"Juli\\'an Haddad, Dylan Langharst, Eli Putterman, Michael Roysdon, and\n  Deping Ye","title":"General Higher Order $L^p$ Isoperimetric and Sobolev Inequalities","comments":"33 pgs","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.DG math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Building off of the a previous work of the current authors, we give a unified\ntreatment of general higher order $L^p$ isoperimetric inequalities, among which\nare the higher order $L^p$ Petty projection inequality, higher order $L^p$\nBusemann-Petty centroid inequality, higher order $L^p$ Santal\\'o inequalities,\nand $L^p$ affine Sobolev inequalities. In this general framework, we give a\nfamily of inequalities that include the general affine isoperimetric and\nSobolev inequalities due to Harbel and Schuster and Lutwak, Yang and Zhang.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:53:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17469","submitter":"Myoungsoo Jung","authors":"Junhyeok Jang, Miryeong Kwon, Donghyun Gouk, Hanyeoreum Bae and\n  Myoungsoo Jung","title":"GraphTensor: Comprehensive GNN-Acceleration Framework for Efficient\n  Parallel Processing of Massive Datasets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present GraphTensor, a comprehensive open-source framework that supports\nefficient parallel neural network processing on large graphs. GraphTensor\noffers a set of easy-to-use programming primitives that appreciate both graph\nand neural network execution behaviors from the beginning (graph sampling) to\nthe end (dense data processing). Our framework runs diverse graph neural\nnetwork (GNN) models in a destination-centric, feature-wise manner, which can\nsignificantly shorten training execution times in a GPU. In addition,\nGraphTensor rearranges multiple GNN kernels based on their system\nhyperparameters in a self-governing manner, thereby reducing the processing\ndimensionality and the latencies further. From the end-to-end execution\nviewpoint, GraphTensor significantly shortens the service-level GNN latency by\napplying pipeline parallelism for efficient graph dataset preprocessing. Our\nevaluation shows that GraphTensor exhibits 1.4x better training performance\nthan emerging GNN frameworks under the execution of large-scale, real-world\ngraph workloads. For the end-to-end services, GraphTensor reduces training\nlatencies of an advanced version of the GNN frameworks (optimized for\nmulti-threaded graph sampling) by 2.4x, on average.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:04:24 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17470","submitter":"Dipam Das","authors":"Debasish Bhattacharjee, Dipam Das, Santanu Acharjee, Tarini Kumar\n  Dutta","title":"Two predators one prey model that integrates the effect of supplementary\n  food resources due to one predator's kleptoparasitism under the possibility\n  of retribution by the other predator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.PE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In ecology, foraging requires animals to expend energy in order to obtain\nresources. The cost of foraging can be reduced through kleptoparasitism, the\ntheft of a resource that another individual has expended effort to acquire.\nThus, kleptoparasitism is one of the most significant feeding techniques in\necology. In this study, we investigate a two predator one prey paradigm in\nwhich one predator acts as a kleptoparasite and the other as a host. This\nresearch considers the post-kleptoparasitism scenario, which has received\nlittle attention in the literature. Parametric requirements for the existence\nas well as local and global stability of biologically viable equilibria have\nbeen proposed. The occurrences of various one parametric bifurcations, such as\nsaddle-node bifurcation, transcritical bifurcation, and Hopf bifurcation, as\nwell as two parametric bifurcations, such as Bautin bifurcation, are explored\nin depth. Relatively low growth rate of first predator induces a subcritical\nHopf bifurcation although a supercritical Hopf bifurcation occurs at relatively\nhigh growth rate of first predator making coexistence of all three species\npossible. Some numerical simulations have been provided for the purpose of\nverifying our theoretical conclusions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:05:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17471","submitter":"Yiqiu Ma","authors":"Hao Yan, Haixing Miao, Shun Wang, Yiqiu Ma, and Zebing Zhou","title":"On the noise effect of test mass surface roughness in spaceborne\n  gravitational wave detectors","comments":"8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det astro-ph.IM gr-qc physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Spaceborne gravitational wave detection mission has a demanding requirement\nfor the precision of displacement sensing, which is conducted by the\ninteraction between the laser field and test mass. However, due to the\nroughness of the reflecting surface of the test mass, the displacement\nmeasurement along the sensitive axis suffers a coupling error caused by the\nresidue motion of other degrees of freedom. In this article, we model the\ncoupling of the test mass residue random motion to the displacement sensing\nalong the sensitive axis and derived an analytical formula of the required\nprecision of the surface error for the spaceborne gravitational wave detectors.\nOur result shows that this coupling error will not contaminate the picometer\ndisplacement sensing for the test masses in the LISA pathfinder.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:08:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17472","submitter":"Sajal Dhara","authors":"Devarshi Chakrabarty, Avijit Dhara, Pritam Das, Kritika Ghosh, Ayan\n  Roy Chaudhuri, Sajal Dhara","title":"Anisotropic exciton polariton pairs as a platform for PT-symmetric\n  non-Hermitian physics","comments":"18 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.optics quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Non-Hermitian systems with parity-time (PT) symmetry have been realized using\noptical constructs in the classical domain, leading to a plethora of\nnon-intuitive phenomena. However, PT-symmetry in purely quantum non-Hermitian\nsystems like microcavity exciton-polaritons has not been realized so far. Here\nwe show how a pair of nearly orthogonal sets of anisotropic exciton-polaritons\ncan offer a versatile platform for realizing multiple spectral degeneracies\ncalled Exceptional Points (EPs) and propose a roadmap to achieve a PT-symmetric\nsystem. Polarization-tunable coupling strength creates one class of EPs, while\nVoigt EPs are observed for specific orientations where splitting of polariton\nmodes due to birefringence is compensated by Transverse Electric (TE)\n-Transverse Magnetic (TM) mode splitting. Thus, paired sets of polarized\nanisotropic microcavity exciton-polaritons can offer a promising platform not\nonly for fundamental research in non-Hermitian quantum physics and topological\npolaritons, but also, we propose that it will be critical for realizing zero\nthreshold lasers.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:09:57 GMT"},{"version":"v2","created":"Wed, 31 May 2023 07:32:54 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17473","submitter":"Farhad Morteza Pour Shiri","authors":"Farhad Mortezapour Shiri, Thinagaran Perumal, Norwati Mustapha,\n  Raihani Mohamed","title":"A Comprehensive Overview and Comparative Analysis on Deep Learning\n  Models: CNN, RNN, LSTM, GRU","comments":"16 pages, 29 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Deep learning (DL) has emerged as a powerful subset of machine learning (ML)\nand artificial intelligence (AI), outperforming traditional ML methods,\nespecially in handling unstructured and large datasets. Its impact spans across\nvarious domains, including speech recognition, healthcare, autonomous vehicles,\ncybersecurity, predictive analytics, and more. However, the complexity and\ndynamic nature of real-world problems present challenges in designing effective\ndeep learning models. Consequently, several deep learning models have been\ndeveloped to address different problems and applications. In this article, we\nconduct a comprehensive survey of various deep learning models, including\nConvolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs),\nGenerative Models, Deep Reinforcement Learning (DRL), and Deep Transfer\nLearning. We examine the structure, applications, benefits, and limitations of\neach model. Furthermore, we perform an analysis using three publicly available\ndatasets: IMDB, ARAS, and Fruit-360. We compare the performance of six renowned\ndeep learning models: CNN, Simple RNN, Long Short-Term Memory (LSTM),\nBidirectional LSTM, Gated Recurrent Unit (GRU), and Bidirectional GRU.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:23:21 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 16:53:28 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17474","submitter":"Goran Petrevski","authors":"Goran Petrevski","title":"Macroeconomic Effects of Inflation Targeting: A Survey of the Empirical\n  Literature","comments":"109 pages, a survey of the empirical literature on macroeconomic\n  effects of inflation targeting","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper surveys the empirical literature of inflation targeting. The main\nfindings from our review are the following: there is robust empirical evidence\nthat larger and more developed countries are more likely to adopt the IT\nregime; the introduction of this regime is conditional on previous\ndisinflation, greater exchange rate flexibility, central bank independence, and\nhigher level of financial development; the empirical evidence has failed to\nprovide convincing evidence that IT itself may serve as an effective tool for\nstabilizing inflation expectations and for reducing inflation persistence; the\nempirical research focused on advanced economies has failed to provide\nconvincing evidence on the beneficial effects of IT on inflation performance,\nwhile there is some evidence that the gains from the IT regime may have been\nmore prevalent in the emerging market economies; there is not convincing\nevidence that IT is associated with either higher output growth or lower output\nvariability; the empirical research suggests that IT may have differential\neffects on exchange-rate volatility in advanced economies versus EMEs; although\nthe empirical evidence on the impact of IT on fiscal policy is quite limited,\nit supports the idea that IT indeed improves fiscal discipline; the empirical\nsupport to the proposition that IT is associated with lower disinflation costs\nseems to be rather weak. Therefore, the accumulated empirical literature\nimplies that IT does not produce superior macroeconomic benefits in comparison\nwith the alternative monetary strategies or, at most, they are quite modest.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:26:15 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17475","submitter":"Sajal Dhara","authors":"Avijit Dhara, Devarshi Chakrabarty, Pritam Das, Kritika Ghosh, Ayan\n  Roy Chaudhuri, Sajal Dhara","title":"A Zero-Threshold Polariton-Raman Laser","comments":"Total 25 pages, 4 main figures, 9 supplementary figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.optics quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Raman lasers are known for their low power operation and wavelength\ntunability unattainable by conventional lasers. Recently ultralow-threshold\nRaman lasers had been realized in semiconductors with various geometries.\nZero-threshold lasers were realized previously only in single atom emitter\nstrongly coupled in a single mode cavity with spontaneous emission coupling\nfactor of unity. However, this was not feasible in microcavities hosting\nisotropic Raman active materials with degenerate bare cavity modes. Here we\nshow that a zero threshold Raman laser can be achieved when Stoke shifted\npolariton Raman modes are tuned within one of the anisotropic exciton-polariton\nbands in an optical microcavity. In addition, we demonstrate that Raman active\nanisotropic exciton-polaritons in a single mode microcavity offers a platform\nto realize a PT-symmetric non-Hermitian quantum system of two nearly orthogonal\npolariton modes that constitute a non-trivial band dispersion containing\nexceptional points. We found that the PT-symmetric phase responsible for the\nzero-threshold lasing can be switched to a finite threshold in PT-symmetry\nbroken phase via cavity detuning by the variation of bath temperature, as well\nas by the variation of pump polarization and energy. Our discovery of zero\nthreshold polariton Raman laser, would not only open up several new paradigms\nof applications in the areas of quantum optics and on-chip photonics but also\noffer a platform for research in quantum physics of PT-symmetric non-Hermitian\nsystem.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:28:16 GMT"},{"version":"v2","created":"Wed, 31 May 2023 07:15:17 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17476","submitter":"Chenyu Zheng","authors":"Chenyu Zheng, Guoqiang Wu, Chongxuan Li","title":"Toward Understanding Generative Data Augmentation","comments":"39 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generative data augmentation, which scales datasets by obtaining fake labeled\nexamples from a trained conditional generative model, boosts classification\nperformance in various learning tasks including (semi-)supervised learning,\nfew-shot learning, and adversarially robust learning. However, little work has\ntheoretically investigated the effect of generative data augmentation. To fill\nthis gap, we establish a general stability bound in this not independently and\nidentically distributed (non-i.i.d.) setting, where the learned distribution is\ndependent on the original train set and generally not the same as the true\ndistribution. Our theoretical result includes the divergence between the\nlearned distribution and the true distribution. It shows that generative data\naugmentation can enjoy a faster learning rate when the order of divergence term\nis $o(\\max\\left( \\log(m)\\beta_m, 1 / \\sqrt{m})\\right)$, where $m$ is the train\nset size and $\\beta_m$ is the corresponding stability constant. We further\nspecify the learning setup to the Gaussian mixture model and generative\nadversarial nets. We prove that in both cases, though generative data\naugmentation does not enjoy a faster learning rate, it can improve the learning\nguarantees at a constant level when the train set is small, which is\nsignificant when the awful overfitting occurs. Simulation results on the\nGaussian mixture model and empirical results on generative adversarial nets\nsupport our theoretical conclusions. Our code is available at\nhttps://github.com/ML-GSAI/Understanding-GDA.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:46:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17477","submitter":"Nikita Alutis","authors":"Nikita Alutis, Egor Chistov, Mikhail Dremin, Dmitriy Vatolin","title":"BASED: Benchmarking, Analysis, and Structural Estimation of Deblurring","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper discusses the challenges of evaluating deblurring-methods quality\nand proposes a reduced-reference metric based on machine learning. Traditional\nquality-assessment metrics such as PSNR and SSIM are common for this task, but\nnot only do they correlate poorly with subjective assessments, they also\nrequire ground-truth (GT) frames, which can be difficult to obtain in the case\nof deblurring. To develop and evaluate our metric, we created a new motion-blur\ndataset using a beam splitter. The setup captured various motion types using a\nstatic camera, as most scenes in existing datasets include blur due to camera\nmotion. We also conducted two large subjective comparisons to aid in metric\ndevelopment. Our resulting metric requires no GT frames, and it correlates well\nwith subjective human perception of blur.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:47:25 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17478","submitter":"Guilherme Pombo","authors":"Guilherme Pombo, Robert Gray, Amy P.K. Nelson, Chris Foulon, John\n  Ashburner, Parashkev Nachev","title":"Deep Variational Lesion-Deficit Mapping","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV stat.AP stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Causal mapping of the functional organisation of the human brain requires\nevidence of \\textit{necessity} available at adequate scale only from\npathological lesions of natural origin. This demands inferential models with\nsufficient flexibility to capture both the observable distribution of\npathological damage and the unobserved distribution of the neural substrate.\nCurrent model frameworks -- both mass-univariate and multivariate -- either\nignore distributed lesion-deficit relations or do not model them explicitly,\nrelying on featurization incidental to a predictive task. Here we initiate the\napplication of deep generative neural network architectures to the task of\nlesion-deficit inference, formulating it as the estimation of an expressive\nhierarchical model of the joint lesion and deficit distributions conditioned on\na latent neural substrate. We implement such deep lesion deficit inference with\nvariational convolutional volumetric auto-encoders. We introduce a\ncomprehensive framework for lesion-deficit model comparison, incorporating\ndiverse candidate substrates, forms of substrate interactions, sample sizes,\nnoise corruption, and population heterogeneity. Drawing on 5500 volume images\nof ischaemic stroke, we show that our model outperforms established methods by\na substantial margin across all simulation scenarios, including comparatively\nsmall-scale and noisy data regimes. Our analysis justifies the widespread\nadoption of this approach, for which we provide an open source implementation:\nhttps://github.com/guilherme-pombo/vae_lesion_deficit\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:49:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17479","submitter":"Shishir Adhikari","authors":"Shishir Adhikari, Elena Zheleva","title":"Inferring Causal Effects Under Heterogeneous Peer Influence","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Causal inference in networks should account for interference, which occurs\nwhen a unit's outcome is influenced by treatments or outcomes of peers. There\ncan be heterogeneous peer influence between units when a unit's outcome is\nsubjected to variable influence from different peers based on their attributes\nand relationships, or when each unit has a different susceptibility to peer\ninfluence. Existing solutions to causal inference under interference consider\neither homogeneous influence from peers or specific heterogeneous influence\nmechanisms (e.g., based on local neighborhood structure). This paper presents a\nmethodology for estimating individual causal effects in the presence of\nheterogeneous peer influence due to arbitrary mechanisms. We propose a\nstructural causal model for networks that can capture arbitrary assumptions\nabout network structure, interference conditions, and causal dependence. We\nidentify potential heterogeneous contexts using the causal model and propose a\nnovel graph neural network-based estimator to estimate individual causal\neffects. We show that existing state-of-the-art methods for individual causal\neffect estimation produce biased results in the presence of heterogeneous peer\ninfluence, and that our proposed estimator is robust.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:57:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17480","submitter":"Abisek Rajakumar Kalarani","authors":"Naveen Badathala, Abisek Rajakumar Kalarani, Tejpalsingh Siledar,\n  Pushpak Bhattacharyya","title":"A Match Made in Heaven: A Multi-task Framework for Hyperbole and\n  Metaphor Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Hyperbole and metaphor are common in day-to-day communication (e.g., \"I am in\ndeep trouble\": how does trouble have depth?), which makes their detection\nimportant, especially in a conversational AI setting. Existing approaches to\nautomatically detect metaphor and hyperbole have studied these language\nphenomena independently, but their relationship has hardly, if ever, been\nexplored computationally. In this paper, we propose a multi-task deep learning\nframework to detect hyperbole and metaphor simultaneously. We hypothesize that\nmetaphors help in hyperbole detection, and vice-versa. To test this hypothesis,\nwe annotate two hyperbole datasets- HYPO and HYPO-L- with metaphor labels.\nSimultaneously, we annotate two metaphor datasets- TroFi and LCC- with\nhyperbole labels. Experiments using these datasets give an improvement of the\nstate of the art of hyperbole detection by 12%. Additionally, our multi-task\nlearning (MTL) approach shows an improvement of up to 17% over single-task\nlearning (STL) for both hyperbole and metaphor detection, supporting our\nhypothesis. To the best of our knowledge, ours is the first demonstration of\ncomputational leveraging of linguistic intimacy between metaphor and hyperbole,\nleading to showing the superiority of MTL over STL for hyperbole and metaphor\ndetection.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:17:59 GMT"},{"version":"v2","created":"Tue, 30 May 2023 13:35:35 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.17481","submitter":"Tomoya Naito","authors":"Hiroyuki Sagawa, Tomoya Naito, Xavier Roca-Maza, and Tetsuo Hatsuda","title":"QCD-Based Charge Symmetry Breaking Interaction and\n  Okamoto-Nolen-Schiffer Anomaly","comments":"5 pages, 2 figures, 6 tables in the main text; 5 pages, 2 figures, 2\n  tables in the supplemental material","journal-ref":null,"doi":null,"report-no":"RIKEN-iTHEMS-Report-23","categories":"nucl-th hep-lat hep-ph nucl-ex","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A novel approach is proposed to link the charge symmetry breaking (CSB)\nnuclear interaction and the low-energy constants in quantum chromodynamics\n(QCD) for the first time by matching the CSB effect in nuclear matter.\nResulting CSB interaction is applied to study the Okamoto-Nolen-Schiffer\nanomaly on the energy differences of mirror nuclei by taking $ {}^{17}\n\\mathrm{F} $-$ {}^{17} \\mathrm{O} $, $ {}^{15} \\mathrm{O} $-$ {}^{15}\n\\mathrm{N} $, $ {}^{41} \\mathrm{Sc} $-$ {}^{41} \\mathrm{Ca} $, and $ {}^{39}\n\\mathrm{Ca} $-$ {}^{39} \\mathrm{K} $ as typical examples. The magnitude and\nsign of the QCD-based CSB interactions are found to resolve the anomaly\nsuccessfully within theoretical uncertainties.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:18:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17482","submitter":"Junze Yin","authors":"Song Bian, Zhao Song, Junze Yin","title":"Federated Empirical Risk Minimization via Second-Order Method","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.DC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Many convex optimization problems with important applications in machine\nlearning are formulated as empirical risk minimization (ERM). There are several\nexamples: linear and logistic regression, LASSO, kernel regression, quantile\nregression, $p$-norm regression, support vector machines (SVM), and mean-field\nvariational inference. To improve data privacy, federated learning is proposed\nin machine learning as a framework for training deep learning models on the\nnetwork edge without sharing data between participating nodes. In this work, we\npresent an interior point method (IPM) to solve a general ERM problem under the\nfederated learning setting. We show that the communication complexity of each\niteration of our IPM is $\\tilde{O}(d^{3/2})$, where $d$ is the dimension (i.e.,\nnumber of features) of the dataset.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:23:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17483","submitter":"\\'Ad\\'am Gali","authors":"Meysam Mohseni, P\\'eter Udvarhelyi, Gerg\\H{o} Thiering, and Adam Gali","title":"The positively charged carbon vacancy defect as a near-infrared emitter\n  in 4H-SiC","comments":"8 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Certain intrinsic point defects in silicon carbide are promising quantum\nsystems with efficient spin-photon interface. Despite carbon vacancy in silicon\ncarbide is an elementary and relatively abundant intrinsic defect, no optical\nsignal has been reported associated with it. Here, we revisit the positively\ncharged carbon vacancy defects in the 4H polytype of silicon carbide (4H-SiC)\nby means of \\textit{ab initio} calculations. We find that the excited state is\noptically active for the so-called h-site configuration of carbon vacancy in\n4H-SiC, with zero-phonon line at $0.65~\\mathrm{eV}$. We propose this defect as\nan exotic paramagnetic near-infrared emitter in the IR-B region.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:27:03 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17484","submitter":"Adam Heins","authors":"Adam Heins and Angela P. Schoellig","title":"Keep it Upright: Model Predictive Control for Nonprehensile Object\n  Transportation with Obstacle Avoidance on a Mobile Manipulator","comments":"8 pages, 14 figures; submitted to Robotics and Automation Letters\n  (RA-L)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a nonprehensile manipulation task in which a mobile manipulator\nmust balance objects on its end effector without grasping them -- known as the\nwaiter's problem -- and move to a desired location while avoiding static and\ndynamic obstacles. In constrast to existing approaches, our focus is on fast\nonline planning in response to new and changing environments. Our main\ncontribution is a whole-body constrained model predictive controller (MPC) for\na mobile manipulator that balances objects and avoids collisions. Furthermore,\nwe propose planning using the minimum statically-feasible friction\ncoefficients, which provides robustness to frictional uncertainty and other\nforce disturbances while also substantially reducing the compute time required\nto update the MPC policy. Simulations and hardware experiments on a\nvelocity-controlled mobile manipulator with up to seven balanced objects,\nstacked objects, and various obstacles show that our approach can handle a\nvariety of conditions that have not been previously demonstrated, with end\neffector speeds and accelerations up to 2.0 m/s and 7.9 m/s$^2$, respectively.\nNotably, we demonstrate a projectile avoidance task in which the robot avoids a\nthrown ball while balancing a tall bottle.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:36:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17485","submitter":"Zachary Hansen","authors":"Jorge Fandinno, Zachary Hansen, Yuliya Lierler, Vladimir Lifschitz,\n  Nathan Temple","title":"External Behavior of a Logic Program and Verification of Refactoring","comments":"Accepted to Theory and Practice of Logic Programming (ICLP 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Refactoring is modifying a program without changing its external behavior. In\nthis paper, we make the concept of external behavior precise for a simple\nanswer set programming language. Then we describe a proof assistant for the\ntask of verifying that refactoring a program in that language is performed\ncorrectly.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:39:39 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17486","submitter":"Robert Stencel","authors":"Charles R. Cowley and Robert E. Stencel","title":"A revised comparison of distant and nearby solar twins","comments":"Revised and updated version of 2023 RNAAS 7, 88","journal-ref":"2023 RNAAS 7, issue 5, 88","doi":"10.3847/2515-5172/acd1ea","report-no":null,"categories":"astro-ph.SR astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Properties of solar twins reported by Lehmann et al. (2023) at kiloparsec\ndistances from the local standard of rest (LSR) are compared to solar twins\nwithin 100 pc of the Sun. These have velocity distributions closely similar to\nthose of the nearby twins in addition to closely matching $T_{\\rm eff}$,\n$\\log{(g)}$ and $[Fe/H]$. The new twins are at slightly higher galactic\nlatitudes, and are somewhat closer to the Galactic center. Additionally, they\nmay be significantly older than nearby solar twins.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:41:23 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17487","submitter":"Yu Shi","authors":"Dawei Wu, Shan-Chang Tang, Yu Shi","title":"Accelerating Unruh-DeWitt detectors coupled with a spinor field","comments":"30 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The behavior of accelerating Unruh-DeWitt detectors coupled with a spinor\nfield in (3+1)-dimensional spacetime is investigated. For a single point-like\ndetector with Gaussian switching function, the transition probability increases\nwith the acceleration and thus the antiUnruh effect effect cannot occur. Due to\nthe spinor structure of the Dirac field, UV divergences are encountered in the\ncalculation of the entanglement between the detectors. After introducing some\nUV cutoff $\\Lambda$, the logarithmic negativity of detectors is shown to behave\nnonmonotonically with respect to the acceleration. Besides, the logarithmic\nnegativity increases with the cutoff $\\Lambda$ and decreases with the distance\nbetween the detectors. The mutual information between the two detectors is also\ndiscussed.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:42:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17488","submitter":"Shan-Shan Ding","authors":"Shan-Shan Ding, Guang-Yu Ding, Kai Leong Chong, Wen-Tao Wu, Ke-Qing\n  Xia, Jin-Qiang Zhong","title":"Vortex Dynamics in Rotating Rayleigh-B\\'enard Convection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the spatial distribution and dynamics of the vortices in\nrotating Rayleigh-B\\'enard convection in a reduced Rayleigh-number range\n$1.3{\\le}Ra/Ra_{c}{\\le}166$. Under slow rotations ($Ra{\\gtrsim}10Ra_{c}$), the\nvortices are randomly distributed. The size-distribution of the Voronoi cells\nof the vortex centers is well described by the standard $\\Gamma$ distribution.\nIn this flow regime the vortices exhibit Brownian-type horizontal motion. The\nprobability density functions of the vortex displacements are, however,\nnon-Gaussian at short time scales. At modest rotating rates\n($4Ra_{c}{\\le}Ra{\\lesssim}10Ra_{c}$) the centrifugal force leads to radial\nvortex motions, i.e., warm cyclones (cold anticyclones) moving towards (outward\nfrom) the rotation axis. The mean-square-displacements of the vortices increase\nfaster than linearly at large time. This super-diffusive behavior can be\nsatisfactorily explained by a Langevin model incorporating the centrifugal\nforce. In the rapidly rotating regime ($1.6Ra_{c}{\\le}Ra{\\le}4Ra_{c}$) the\nvortices are densely distributed, with the size-distribution of their Voronoi\ncells differing significantly from the standard $\\Gamma$ distribution. The\nhydrodynamic interaction of neighboring vortices results in formation of vortex\nclusters. Inside clusters the correlation of the vortex velocity fluctuations\nis scale free, with the correlation length being approximately $30\\%$ of the\ncluster length. We examine the influence of cluster forming on the dynamics of\nindividual vortex. Within clusters, cyclones exhibit inverse-centrifugal motion\nas they submit to the motion of strong anticyclones, while the velocity for\noutward motion of the anticyclones is increased. Our analysis show that the\nmobility of isolated vortices, scaled by their vorticity strength, is a simple\npower function of the Froude number.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:46:35 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17489","submitter":"Zhongping Zhang","authors":"Zhongping Zhang, Jian Zheng, Jacob Zhiyuan Fang, Bryan A. Plummer","title":"Text-to-image Editing by Image Information Removal","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diffusion models have demonstrated impressive performance in text-guided\nimage generation. To leverage the knowledge of text-guided image generation\nmodels in image editing, current approaches either fine-tune the pretrained\nmodels using the input image (e.g., Imagic) or incorporate structure\ninformation as additional constraints into the pretrained models (e.g.,\nControlNet). However, fine-tuning large-scale diffusion models on a single\nimage can lead to severe overfitting issues and lengthy inference time. The\ninformation leakage from pretrained models makes it challenging to preserve the\ntext-irrelevant content of the input image while generating new features guided\nby language descriptions. On the other hand, methods that incorporate\nstructural guidance (e.g., edge maps, semantic maps, keypoints) as additional\nconstraints face limitations in preserving other attributes of the original\nimage, such as colors or textures. A straightforward way to incorporate the\noriginal image is to directly use it as an additional control. However, since\nimage editing methods are typically trained on the image reconstruction task,\nthe incorporation can lead to the identical mapping issue, where the model\nlearns to output an image identical to the input, resulting in limited editing\ncapabilities. To address these challenges, we propose a text-to-image editing\nmodel with Image Information Removal module (IIR) to selectively erase\ncolor-related and texture-related information from the original image, allowing\nus to better preserve the text-irrelevant content and avoid the identical\nmapping issue. We evaluate our model on three benchmark datasets: CUB, Outdoor\nScenes, and COCO. Our approach achieves the best editability-fidelity\ntrade-off, and our edited images are approximately 35% more preferred by\nannotators than the prior-arts on COCO.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:48:05 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17490","submitter":"Lei Wu","authors":"Lei Wu, Weijie J. Su","title":"The Implicit Regularization of Dynamical Stability in Stochastic\n  Gradient Descent","comments":"ICML 2023 camera ready","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  In this paper, we study the implicit regularization of stochastic gradient\ndescent (SGD) through the lens of {\\em dynamical stability} (Wu et al., 2018).\nWe start by revising existing stability analyses of SGD, showing how the\nFrobenius norm and trace of Hessian relate to different notions of stability.\nNotably, if a global minimum is linearly stable for SGD, then the trace of\nHessian must be less than or equal to $2/\\eta$, where $\\eta$ denotes the\nlearning rate. By contrast, for gradient descent (GD), the stability imposes a\nsimilar constraint but only on the largest eigenvalue of Hessian. We then turn\nto analyze the generalization properties of these stable minima, focusing\nspecifically on two-layer ReLU networks and diagonal linear networks. Notably,\nwe establish the {\\em equivalence} between these metrics of sharpness and\ncertain parameter norms for the two models, which allows us to show that the\nstable minima of SGD provably generalize well. By contrast, the\nstability-induced regularization of GD is provably too weak to ensure\nsatisfactory generalization. This discrepancy provides an explanation of why\nSGD often generalizes better than GD. Note that the learning rate (LR) plays a\npivotal role in the strength of stability-induced regularization. As the LR\nincreases, the regularization effect becomes more pronounced, elucidating why\nSGD with a larger LR consistently demonstrates superior generalization\ncapabilities. Additionally, numerical experiments are provided to support our\ntheoretical findings.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:54:21 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 07:54:48 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17491","submitter":"Jasivan Alex Sivakumar","authors":"Jasivan Alex Sivakumar and Nafise Sadat Moosavi","title":"FERMAT: An Alternative to Accuracy for Numerical Reasoning","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  While pre-trained language models achieve impressive performance on various\nNLP benchmarks, they still struggle with tasks that require numerical\nreasoning. Recent advances in improving numerical reasoning are mostly achieved\nusing very large language models that contain billions of parameters and are\nnot accessible to everyone. In addition, numerical reasoning is measured using\na single score on existing datasets. As a result, we do not have a clear\nunderstanding of the strengths and shortcomings of existing models on different\nnumerical reasoning aspects and therefore, potential ways to improve them apart\nfrom scaling them up. Inspired by CheckList (Ribeiro et al., 2020), we\nintroduce a multi-view evaluation set for numerical reasoning in English,\ncalled FERMAT. Instead of reporting a single score on a whole dataset, FERMAT\nevaluates models on various key numerical reasoning aspects such as number\nunderstanding, mathematical operations, and training dependency. Apart from\nproviding a comprehensive evaluation of models on different numerical reasoning\naspects, FERMAT enables a systematic and automated generation of an arbitrarily\nlarge training or evaluation set for each aspect.The datasets and codes are\npublicly available to generate further multi-view data for ulterior tasks and\nlanguages.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:00:45 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17492","submitter":"Soumyabrata Dey","authors":"Animesh Mitra, Saswata Sahoo, Soumyabrata Dey","title":"Dynamic User Segmentation and Usage Profiling","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Usage data of a group of users distributed across a number of categories,\nsuch as songs, movies, webpages, links, regular household products, mobile\napps, games, etc. can be ultra-high dimensional and massive in size. More often\nthis kind of data is categorical and sparse in nature making it even more\ndifficult to interpret any underlying hidden patterns such as clusters of\nusers. However, if this information can be estimated accurately, it will have\nhuge impacts in different business areas such as user recommendations for apps,\nsongs, movies, and other similar products, health analytics using electronic\nhealth record (EHR) data, and driver profiling for insurance premium estimation\nor fleet management.\n  In this work, we propose a clustering strategy of such categorical big data,\nutilizing the hidden sparsity of the dataset. Most traditional clustering\nmethods fail to give proper clusters for such data and end up giving one big\ncluster with small clusters around it irrespective of the true structure of the\ndata clusters. We propose a feature transformation, which maps the\nbinary-valued usage vector to a lower dimensional continuous feature space in\nterms of groups of usage categories, termed as covariate classes. The lower\ndimensional feature representations in terms of covariate classes can be used\nfor clustering. We implemented the proposed strategy and applied it to a large\nsized very high-dimensional song playlist dataset for the performance\nvalidation. The results are impressive as we achieved similar-sized user\nclusters with minimal between-cluster overlap in the feature space (8%) on\naverage). As the proposed strategy has a very generic framework, it can be\nutilized as the analytic engine of many of the above-mentioned business use\ncases allowing an intelligent and dynamic personal recommendation system or a\nsupport system for smart business decision-making.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:09:56 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17493","submitter":"Ilia Shumailov","authors":"Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas\n  Papernot, Ross Anderson","title":"The Curse of Recursion: Training on Generated Data Makes Models Forget","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.CR cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Stable Diffusion revolutionised image creation from descriptive text. GPT-2,\nGPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of\nlanguage tasks. ChatGPT introduced such language models to the general public.\nIt is now clear that large language models (LLMs) are here to stay, and will\nbring about drastic change in the whole ecosystem of online text and images. In\nthis paper we consider what the future might hold. What will happen to GPT-{n}\nonce LLMs contribute much of the language found online? We find that use of\nmodel-generated content in training causes irreversible defects in the\nresulting models, where tails of the original content distribution disappear.\nWe refer to this effect as Model Collapse and show that it can occur in\nVariational Autoencoders, Gaussian Mixture Models and LLMs. We build\ntheoretical intuition behind the phenomenon and portray its ubiquity amongst\nall learned generative models. We demonstrate that it has to be taken seriously\nif we are to sustain the benefits of training from large-scale data scraped\nfrom the web. Indeed, the value of data collected about genuine human\ninteractions with systems will be increasingly valuable in the presence of\ncontent generated by LLMs in data crawled from the Internet.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:10:41 GMT"},{"version":"v2","created":"Wed, 31 May 2023 10:39:26 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17494","submitter":"Sven Sandfeldt","authors":"Sven Sandfeldt","title":"Centralizer classification and rigidity for some partially hyperbolic\n  toral automorphisms","comments":"48 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper we consider local centralizer classification and rigidity of\nsome toral automorphisms. In low dimensions we classify up to finite index\npossible centralizers for volume preserving diffeomorphisms $f$ $C^{1}-$close\nto an ergodic irreducible toral automorphism $L$. Moreover, we show a rigidity\nresult in the case that the centralizer of $f$ is large: If the smooth\ncentralizer $Z^{\\infty}(f)$ is virtually isomorphic to that of $L$ then $f$ is\n$C^{\\infty}-$conjugate to $L$. In higher dimensions we show a similar rigidity\nresult for certain irreducible toral automorphisms. We also classify up to\nfinite index all possible centralizers for symplectic diffeomorphisms\n$C^{5}-$close to a class of irreducible symplectic automorphisms on tori of any\ndimension.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:14:41 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17495","submitter":"Shangyun Wang","authors":"Shangyun Wang, Songbai Chen, Jiliang Jing, Jieci Wang, Heng Fan","title":"Quantum collapse and exponential growth of out-of-time-ordered\n  correlator in anisotropic quantum Rabi model","comments":"6 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum chaos is an intriguing topic and has attracting a great deal of\ninterests in quantum mechanics and black hole physics. Recently, the\nexponential growth of out-of-time-ordered correlator (OTOC) has been proposed\nto diagnose quantum chaos and verify the correspondence principle. Here, we\ndemonstrate that the exponential growth of the OTOC at early times for the\ninitial states centered both in the chaotic and stable regions of the\nanisotropic quantum Rabi model. We attribute the exponential growth of the OTOC\nto quantum collapse which provides a novel mechanism of yielding exponential\ngrowth of the OTOC in quantum systems. Moreover, the quantum collapse effect is\nmore obvious for the initial states centered in the chaotic one. Our results\nshow that compared with the OTOC, the linear entanglement entropy and Loschmidt\necho seem to be more effective to diagnose the signals of quantum chaos in the\nanisotropic quantum Rabi model.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:23:37 GMT"},{"version":"v2","created":"Wed, 31 May 2023 04:42:14 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.17496","submitter":"Weifeng Sun","authors":"Rubing Huang, Chenhui Cui, Junlong Lian, Dave Towey, Weifeng Sun,\n  Haibo Chen","title":"Toward Cost-effective Adaptive Random Testing: An Approximate Nearest\n  Neighbor Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Adaptive Random Testing (ART) enhances the testing effectiveness (including\nfault-detection capability) of Random Testing (RT) by increasing the diversity\nof the random test cases throughout the input domain. Many ART algorithms have\nbeen investigated according to different criteria, such as\nFixed-Size-Candidate-Set ART (FSCS) and Restricted Random Testing (RRT), and\nhave been widely used in many practical applications. Despite its popularity,\nART suffers from the problem of high computational costs during test case\ngeneration, especially as the number of test cases increases. Although a number\nof strategies have been proposed to enhance the ART testing efficiency, such as\nthe forgetting strategy and the k-dimensional tree strategy, these algorithms\nstill face some challenges, including: (1) Although these algorithms can reduce\nthe computation time, their execution costs are still very high, especially\nwhen the number of test cases is large; and (2) To achieve low computational\ncosts, they may sacrifice some fault-detection capability. In this paper, we\npropose an approach based on Approximate Nearest Neighbors (ANNs), called\nLocality Sensitive Hashing ART (LSH-ART). When calculating distances among\ndifferent test inputs, LSH-ART identifies the approximate (not necessarily\nexact) nearest neighbors for candidates in an efficient way. LSH-ART attempts\nto balance ART testing effectiveness and efficiency.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:37:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17497","submitter":"Zhuang Li","authors":"Zhuang Li, Yuyang Chai, Terry Yue Zhuo, Lizhen Qu, Gholamreza Haffari,\n  Fei Li, Donghong Ji, Quan Hung Tran","title":"FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph\n  Parsing","comments":"9 pages, ACL 2023 (findings)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Textual scene graph parsing has become increasingly important in various\nvision-language applications, including image caption evaluation and image\nretrieval. However, existing scene graph parsers that convert image captions\ninto scene graphs often suffer from two types of errors. First, the generated\nscene graphs fail to capture the true semantics of the captions or the\ncorresponding images, resulting in a lack of faithfulness. Second, the\ngenerated scene graphs have high inconsistency, with the same semantics\nrepresented by different annotations.\n  To address these challenges, we propose a novel dataset, which involves\nre-annotating the captions in Visual Genome (VG) using a new intermediate\nrepresentation called FACTUAL-MR. FACTUAL-MR can be directly converted into\nfaithful and consistent scene graph annotations. Our experimental results\nclearly demonstrate that the parser trained on our dataset outperforms existing\napproaches in terms of faithfulness and consistency. This improvement leads to\na significant performance boost in both image caption evaluation and zero-shot\nimage retrieval tasks. Furthermore, we introduce a novel metric for measuring\nscene graph similarity, which, when combined with the improved scene graph\nparser, achieves state-of-the-art (SOTA) results on multiple benchmark datasets\nfor the aforementioned tasks. The code and dataset are available at\nhttps://github.com/zhuang-li/FACTUAL .\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:38:31 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 04:56:26 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.17498","submitter":"Si Yi Meng","authors":"Si Yi Meng, Robert M. Gower","title":"A Model-Based Method for Minimizing CVaR and Beyond","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We develop a variant of the stochastic prox-linear method for minimizing the\nConditional Value-at-Risk (CVaR) objective. CVaR is a risk measure focused on\nminimizing worst-case performance, defined as the average of the top quantile\nof the losses. In machine learning, such a risk measure is useful to train more\nrobust models. Although the stochastic subgradient method (SGM) is a natural\nchoice for minimizing the CVaR objective, we show that our stochastic\nprox-linear (SPL+) algorithm can better exploit the structure of the objective,\nwhile still providing a convenient closed form update. Our SPL+ method also\nadapts to the scaling of the loss function, which allows for easier tuning. We\nthen specialize a general convergence theorem for SPL+ to our setting, and show\nthat it allows for a wider selection of step sizes compared to SGM. We support\nthis theoretical finding experimentally.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:38:53 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17499","submitter":"Linhao Dong","authors":"Linhao Dong, Zhecheng An, Peihao Wu, Jun Zhang, Lu Lu, Zejun Ma","title":"CIF-PT: Bridging Speech and Text Representations for Spoken Language\n  Understanding via Continuous Integrate-and-Fire Pre-Training","comments":"Accepted by ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.MM eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech or text representation generated by pre-trained models contains\nmodal-specific information that could be combined for benefiting spoken\nlanguage understanding (SLU) tasks. In this work, we propose a novel\npre-training paradigm termed Continuous Integrate-and-Fire Pre-Training\n(CIF-PT). It relies on a simple but effective frame-to-token alignment:\ncontinuous integrate-and-fire (CIF) to bridge the representations between\nspeech and text. It jointly performs speech-to-text training and language model\ndistillation through CIF as the pre-training (PT). Evaluated on SLU benchmark\nSLURP dataset, CIF-PT outperforms the state-of-the-art model by 1.94% of\naccuracy and 2.71% of SLU-F1 on the tasks of intent classification and slot\nfilling, respectively. We also observe the cross-modal representation extracted\nby CIF-PT obtains better performance than other neural interfaces for the tasks\nof SLU, including the dominant speech representation learned from\nself-supervised pre-training.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:39:13 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17500","submitter":"Fernando Rold\\'an","authors":"Fernando Rold\\'an","title":"Forward-Reflected-Backward and Shadow-Douglas--Rachford with partial\n  inverse for Solving Monotone Inclusions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we study two methods for solving monotone inclusions in real\nHilbert spaces involving the sum of a maximally monotone operator, a\nmonotone-Lipschitzian operator, a cocoercive operator, and a normal cone to a\nvector subspace. Our algorithms split and exploits the intrinsic properties of\neach operator involved in the inclusion. We derive our methods by combining\npartial inverse techniques with the forward-reflected-backward algorithm and\nwith the shadow-Douglas--Rachford algorithm, respectively. Our methods inherit\nthe advantages of those methods, requiring only one activation of the\nLipschitzian operator, one activation of the cocoercive operator, two\nprojections onto the closed vector subspace, and one calculation of the\nresolvent of the maximally monotone operator. Furthermore, we develop methods\nfor solving primal-dual inclusions involving a mixtureof sums, linear\ncompositions, parallel sums, Lipschitzian operators, cocoercive operators, and\nnormal cones. We apply our methods to constrained composite convex optimization\nproblems as a specific example. Finally, in order to compare our methods with\nexisting methods in the literature, we provide numerical experiments on\nconstrained total variation least-squares optimization problems. We obtain\npromising numerical results.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:44:39 GMT"},{"version":"v2","created":"Tue, 6 Jun 2023 12:19:09 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.17501","submitter":"Jean Cortissoz","authors":"Jhon E. Bravo and Jean C. Cortissoz","title":"On March's criterion for transience on rotationally symmetric manifolds","comments":"Comments and criticisms are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this short paper we show that March's criterion for the existence of a\nbounded non constant harmonic function on a weak model is also a necessary and\nsufficient condition for the solvability of the Dirichlet problem at infinity\non a slight generalisation of a weak model (rotationally symmetric) metric on\n$\\mathbb{R}^n$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:50:08 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17502","submitter":"Nirmal Wickramasinghe Mr.","authors":"Nirmal D. Wickramasinghe, Indrakshi Dey","title":"Transmit Power Optimization of IoT Devices over Incomplete Channel\n  Information","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Efficient resource allocation (RA) strategies within massive and dense\nInternet of Things (IoT) networks is one of the major challenges in the\ndeployment of IoT-network based smart ecosystems involving heterogeneous\npower-constrained IoT devices operating in varied radio and environmental\nconditions. In this paper, we focus on the transmit power minimization problem\nfor IoT devices while maintaining a threshold channel throughput. The\nestablished optimization literature is not robust against the fast-fading\nchannel and the interaction among different transmit signals in each instance.\nBesides, realistically, each IoT node possesses incomplete channel state\ninformation (CSI) on its neighbors, such as the channel gain being private\ninformation for the node itself. In this work, we resort to Bayesian game\ntheoretic strategies for solving the transmit power optimization problem\nexploiting incomplete CSIs within massive IoT networks. We provide a steady\ndiscussion on the rationale for selecting the game theory, particularly the\nBayesian scheme, with a graphical visualization of our formulated problem. We\ntake advantage of the property of the existence and uniqueness of the Bayesian\nNash equilibrium (BNE), which exhibits reduced computational complexity while\noptimizing transmit power and maintaining target throughput within networks\ncomprised of heterogeneous devices.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:53:36 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17503","submitter":"Laya Ghodrati","authors":"Laya Ghodrati, Victor M. Panaretos","title":"Transportation of Measure Regression in Higher Dimensions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present an optimal transport framework for performing regression when both\ncovariate and response are probability distributions on a compact Euclidean\nsubset $\\Omega\\subset\\mathbb{R}^d$, $d>1$.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:58:42 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17504","submitter":"Sarah Loeb","authors":"Sally Cockburn, Sarah Loeb","title":"Symmetry Parameters of Two-Generator Circulant Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The derived graph of a voltage graph consisting of a single vertex and two\nloops of different voltages is a circulant graph with two generators. We\ncharacterize the automorphism groups of connected, two-generator circulant\ngraphs, and give their determining and distinguishing number, and when\nrelevant, their cost of 2-distinguishing. We do the same for the subdivisions\nof connected, two-generator circulant graphs obtained by replacing one loop in\nthe voltage graph with a directed cycle.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:59:11 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.17505","submitter":"Zhipeng Liang","authors":"Zhengzhong Yi, Zhipeng Liang, Kaixin Zhong, Yulin Wu, Zhou Fang, Xuan\n  Wang","title":"Improved belief propagation decoding algorithm based on decoupling\n  representation of Pauli operators for quantum LDPC codes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose a new method called decoupling representation to represent Pauli\noperators as vectors over GF(2), based on which we propose partially decoupled\nbelief propagation and fully decoupled belief propagation decoding algorithm\nfor quantum low density parity-check codes. Under the assumption that there is\nno measurement error, compared with traditional belief propagation algorithm in\nsymplectic representation over GF(2), within the same number of iterations, the\ndecoding accuracy of partially decoupled belief propagation and fully decoupled\nbelief propagation algorithm is significantly improved in pure Y noise channel\nand depolarizing noise channel, which supports that decoding algorithms of\nquantum error correcting codes might have better performance in decoupling\nrepresentation than in symplectic representation. The impressive performance of\nfully decoupled belief propagation algorithm might promote the realization of\nquantum error correcting codes in engineering.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:59:42 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 07:27:17 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.18228","submitter":"Rui Sun","authors":"Rui Sun, Andi Zhang, Haiming Zhang, Yao Zhu, Ruimao Zhang, Zhen Li","title":"SR-OOD: Out-of-Distribution Detection via Sample Repairing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It is widely reported that deep generative models can classify\nout-of-distribution (OOD) samples as in-distribution with high confidence. In\nthis work, we propose a hypothesis that this phenomenon is due to the\nreconstruction task, which can cause the generative model to focus too much on\nlow-level features and not enough on semantic information. To address this\nissue, we introduce SR-OOD, an OOD detection framework that utilizes sample\nrepairing to encourage the generative model to learn more than just an identity\nmap. By focusing on semantics, our framework improves OOD detection performance\nwithout external data and label information. Our experimental results\ndemonstrate the competitiveness of our approach in detecting OOD samples.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:35:20 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18231","submitter":"Lucas Theis","authors":"Emiel Hoogeboom, Eirikur Agustsson, Fabian Mentzer, Luca Versari,\n  George Toderici, Lucas Theis","title":"High-Fidelity Image Compression with Score-based Generative Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite the tremendous success of diffusion generative models in\ntext-to-image generation, replicating this success in the domain of image\ncompression has proven difficult. In this paper, we demonstrate that diffusion\ncan significantly improve perceptual quality at a given bit-rate, outperforming\nstate-of-the-art approaches PO-ELIC and HiFiC as measured by FID score. This is\nachieved using a simple but theoretically motivated two-stage approach\ncombining an autoencoder targeting MSE followed by a further score-based\ndecoder. However, as we will show, implementation details matter and the\noptimal design decisions can differ greatly from typical text-to-image models.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:16:16 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18354","submitter":"Yudong Xu","authors":"Yudong Xu, Wenhao Li, Pashootan Vaezipoor, Scott Sanner, Elias B.\n  Khalil","title":"LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and\n  the Importance of Object-based Representations","comments":"17 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Can a Large Language Model (LLM) solve simple abstract reasoning problems? We\nexplore this broad question through a systematic analysis of GPT on the\nAbstraction and Reasoning Corpus (ARC), a representative benchmark of abstract\nreasoning ability from limited examples in which solutions require some \"core\nknowledge\" of concepts such as objects, goal states, counting, and basic\ngeometry. GPT-4 solves only 13/50 of the most straightforward ARC tasks when\nusing textual encodings for their two-dimensional input-output grids. Our\nfailure analysis reveals that GPT-4's capacity to identify objects and reason\nabout them is significantly influenced by the sequential nature of the text\nthat represents an object within a text encoding of a task. To test this\nhypothesis, we design a new benchmark, the 1D-ARC, which consists of\none-dimensional (array-like) tasks that are more conducive to GPT-based\nreasoning, and where it indeed performs better than on the (2D) ARC. To\nalleviate this issue, we propose an object-based representation that is\nobtained through an external tool, resulting in nearly doubling the performance\non solved ARC tasks and near-perfect scores on the easier 1D-ARC. Although the\nstate-of-the-art GPT-4 is unable to \"reason\" perfectly within non-language\ndomains such as the 1D-ARC or a simple ARC subset, our study reveals that the\nuse of object-based representations can significantly improve its reasoning\nability. Visualizations, GPT logs, and data are available at\nhttps://khalil-research.github.io/LLM4ARC.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:32:17 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18355","submitter":"Fei Kong","authors":"Fei Kong, Jinhao Duan, RuiPeng Ma, Hengtao Shen, Xiaofeng Zhu,\n  Xiaoshuang Shi, Kaidi Xu","title":"An Efficient Membership Inference Attack for the Diffusion Model by\n  Proximal Initialization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.AI cs.LG eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently, diffusion models have achieved remarkable success in generating\ntasks, including image and audio generation. However, like other generative\nmodels, diffusion models are prone to privacy issues. In this paper, we propose\nan efficient query-based membership inference attack (MIA), namely Proximal\nInitialization Attack (PIA), which utilizes groundtruth trajectory obtained by\n$\\epsilon$ initialized in $t=0$ and predicted point to infer memberships.\nExperimental results indicate that the proposed method can achieve competitive\nperformance with only two queries on both discrete-time and continuous-time\ndiffusion models. Moreover, previous works on the privacy of diffusion models\nhave focused on vision tasks without considering audio tasks. Therefore, we\nalso explore the robustness of diffusion models to MIA in the text-to-speech\n(TTS) task, which is an audio generation task. To the best of our knowledge,\nthis work is the first to study the robustness of diffusion models to MIA in\nthe TTS task. Experimental results indicate that models with mel-spectrogram\n(image-like) output are vulnerable to MIA, while models with audio output are\nrelatively robust to MIA. {Code is available at\n\\url{https://github.com/kong13661/PIA}}.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 16:38:48 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18356","submitter":"Vani Nagarajan","authors":"Vani Nagarajan, Durga Mandarapu, Milind Kulkarni","title":"RT-kNNS Unbound: Using RT Cores to Accelerate Unrestricted Neighbor\n  Search","comments":"This paper has been accepted at the International Conference on\n  Supercomputing 2023 (ICS'23)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CG cs.PF","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The problem of identifying the k-Nearest Neighbors (kNNS) of a point has\nproven to be very useful both as a standalone application and as a subroutine\nin larger applications. Given its far-reaching applicability in areas such as\nmachine learning and point clouds, extensive research has gone into leveraging\nGPU acceleration to solve this problem. Recent work has shown that using Ray\nTracing cores in recent GPUs to accelerate kNNS is much more efficient compared\nto traditional acceleration using shader cores. However, the existing\ntranslation of kNNS to a ray tracing problem imposes a constraint on the search\nspace for neighbors. Due to this, we can only use RT cores to accelerate\nfixed-radius kNNS, which requires the user to set a search radius a priori and\nhence can miss neighbors. In this work, we propose TrueKNN, the first unbounded\nRT-accelerated neighbor search. TrueKNN adopts an iterative approach where we\nincrementally grow the search space until all points have found their k\nneighbors. We show that our approach is orders of magnitude faster than\nexisting approaches and can even be used to accelerate fixed-radius neighbor\nsearches.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:40:25 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18357","submitter":"Yali Bian","authors":"Yali Bian, Chris North","title":"DeepSI: Interactive Deep Learning for Semantic Interaction","comments":null,"journal-ref":"IUI '21: 26th International Conference on Intelligent User\n  Interfaces, College Station, TX, USA, April 2021","doi":"10.1145/3397481.3450670","report-no":null,"categories":"cs.LG cs.AI cs.CL cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we design novel interactive deep learning methods to improve\nsemantic interactions in visual analytics applications. The ability of semantic\ninteraction to infer analysts' precise intents during sensemaking is dependent\non the quality of the underlying data representation. We propose the\n$\\text{DeepSI}_{\\text{finetune}}$ framework that integrates deep learning into\nthe human-in-the-loop interactive sensemaking pipeline, with two important\nproperties. First, deep learning extracts meaningful representations from raw\ndata, which improves semantic interaction inference. Second, semantic\ninteractions are exploited to fine-tune the deep learning representations,\nwhich then further improves semantic interaction inference. This feedback loop\nbetween human interaction and deep learning enables efficient learning of user-\nand task-specific representations. To evaluate the advantage of embedding the\ndeep learning within the semantic interaction loop, we compare\n$\\text{DeepSI}_{\\text{finetune}}$ against a state-of-the-art but more basic use\nof deep learning as only a feature extractor pre-processed outside of the\ninteractive loop. Results of two complementary studies, a human-centered\nqualitative case study and an algorithm-centered simulation-based quantitative\nexperiment, show that $\\text{DeepSI}_{\\text{finetune}}$ more accurately\ncaptures users' complex mental models with fewer interactions.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:05:57 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18358","submitter":"Lizhou Fan","authors":"Lizhou Fan, Sara Lafia, Lingyao Li, Fangyuan Yang, Libby Hemphill","title":"DataChat: Prototyping a Conversational Agent for Dataset Search and\n  Visualization","comments":"6 pages, 2 figures, and 1 table. Accepted to the 86th Annual Meeting\n  of the Association for Information Science & Technology","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data users need relevant context and research expertise to effectively search\nfor and identify relevant datasets. Leading data providers, such as the\nInter-university Consortium for Political and Social Research (ICPSR), offer\nstandardized metadata and search tools to support data search. Metadata\nstandards emphasize the machine-readability of data and its documentation.\nThere are opportunities to enhance dataset search by improving users' ability\nto learn about, and make sense of, information about data. Prior research has\nshown that context and expertise are two main barriers users face in\neffectively searching for, evaluating, and deciding whether to reuse data. In\nthis paper, we propose a novel chatbot-based search system, DataChat, that\nleverages a graph database and a large language model to provide novel ways for\nusers to interact with and search for research data. DataChat complements data\narchives' and institutional repositories' ongoing efforts to curate, preserve,\nand share research data for reuse by making it easier for users to explore and\nlearn about available research data.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:21:12 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18359","submitter":"Paulo Roberto Bueno Professor","authors":"Paulo Roberto Bueno","title":"Quantum Rate Theory and Electron-Transfer Dynamics: A Theoretical and\n  Experimental Approach for Quantum Electrochemistry","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.gen-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum rate theory is based on a first-principle quantum mechanical rate\nconcept that comprises with the Planck-Einstein relationship $E = h\\nu$, where\n$\\nu = e^2/hC_q$ is a frequency associated with the quantum capacitance $C_q$\nand $E = e^2/C_q$ is the energy associated with $\\nu$. For a single state mode\nof transmittance, $e^2/C_q$ corresponds to the chemical potential differences\n$\\Delta \\mu$ between donor and acceptor state levels comprising an\nelectrochemical reaction. The latter assumption implies quantum electrodynamics\nwithin a particular quantum transport mode intrinsically coupled to the\nelectron-transfer rate of electrochemical reactions that have not been\nconsidered thus far. Here it is demonstrated that the consideration of this\ninherent quantum transport is key to obtaining an in-depth understanding of the\nelectron transfer phenomenon. Finally, the theory is validated through its\ndescription of electron transfer, quantum conductance, and capacitance in\ndifferent electro-active molecular films.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:23:00 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18360","submitter":"Youngeun Kim","authors":"Youngeun Kim, Yuhang Li, Abhishek Moitra, Ruokai Yin, Priyadarshini\n  Panda","title":"Sharing Leaky-Integrate-and-Fire Neurons for Memory-Efficient Spiking\n  Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Spiking Neural Networks (SNNs) have gained increasing attention as\nenergy-efficient neural networks owing to their binary and asynchronous\ncomputation. However, their non-linear activation, that is\nLeaky-Integrate-and-Fire (LIF) neuron, requires additional memory to store a\nmembrane voltage to capture the temporal dynamics of spikes. Although the\nrequired memory cost for LIF neurons significantly increases as the input\ndimension goes larger, a technique to reduce memory for LIF neurons has not\nbeen explored so far. To address this, we propose a simple and effective\nsolution, EfficientLIF-Net, which shares the LIF neurons across different\nlayers and channels. Our EfficientLIF-Net achieves comparable accuracy with the\nstandard SNNs while bringing up to ~4.3X forward memory efficiency and ~21.9X\nbackward memory efficiency for LIF neurons. We conduct experiments on various\ndatasets including CIFAR10, CIFAR100, TinyImageNet, ImageNet-100, and\nN-Caltech101. Furthermore, we show that our approach also offers advantages on\nHuman Activity Recognition (HAR) datasets, which heavily rely on temporal\ninformation.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 22:55:26 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18361","submitter":"Yiqian Wang","authors":"Yiqian Wang, Alexandra Warter, Melina Cavichini, Varsha Alex, Dirk-Uwe\n  G. Bartsch, William R. Freeman, Truong Q. Nguyen, Cheolhong An","title":"Deep learning network to correct axial and coronal eye motion in 3D OCT\n  retinal imaging","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Optical Coherence Tomography (OCT) is one of the most important retinal\nimaging technique. However, involuntary motion artifacts still pose a major\nchallenge in OCT imaging that compromises the quality of downstream analysis,\nsuch as retinal layer segmentation and OCT Angiography. We propose deep\nlearning based neural networks to correct axial and coronal motion artifacts in\nOCT based on a single volumetric scan. The proposed method consists of two\nfully-convolutional neural networks that predict Z and X dimensional\ndisplacement maps sequentially in two stages. The experimental result shows\nthat the proposed method can effectively correct motion artifacts and achieve\nsmaller error than other methods. Specifically, the method can recover the\noverall curvature of the retina, and can be generalized well to various\ndiseases and resolutions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 03:55:19 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18362","submitter":"Kaiwen Xu","authors":"Kaiwen Xu, Kazuto Fukuchi, Youhei Akimoto and Jun Sakuma","title":"Statistically Significant Concept-based Explanation of Image Classifiers\n  via Model Knockoffs","comments":"Accepted to IJCAI'23","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A concept-based classifier can explain the decision process of a deep\nlearning model by human-understandable concepts in image classification\nproblems. However, sometimes concept-based explanations may cause false\npositives, which misregards unrelated concepts as important for the prediction\ntask. Our goal is to find the statistically significant concept for\nclassification to prevent misinterpretation. In this study, we propose a method\nusing a deep learning model to learn the image concept and then using the\nKnockoff samples to select the important concepts for prediction by controlling\nthe False Discovery Rate (FDR) under a certain value. We evaluate the proposed\nmethod in our synthetic and real data experiments. Also, it shows that our\nmethod can control the FDR properly while selecting highly interpretable\nconcepts to improve the trustworthiness of the model.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:40:05 GMT"},{"version":"v2","created":"Wed, 31 May 2023 03:20:18 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.18363","submitter":"Shuyu Guo","authors":"Shuyu Guo, Shuo Zhang, Weiwei Sun, Pengjie Ren, Zhumin Chen, Zhaochun\n  Ren","title":"Towards Explainable Conversational Recommender Systems","comments":null,"journal-ref":null,"doi":"10.1145/3539618.3591884","report-no":null,"categories":"cs.IR cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Explanations in conventional recommender systems have demonstrated benefits\nin helping the user understand the rationality of the recommendations and\nimproving the system's efficiency, transparency, and trustworthiness. In the\nconversational environment, multiple contextualized explanations need to be\ngenerated, which poses further challenges for explanations. To better measure\nexplainability in conversational recommender systems (CRS), we propose ten\nevaluation perspectives based on concepts from conventional recommender systems\ntogether with the characteristics of CRS. We assess five existing CRS benchmark\ndatasets using these metrics and observe the necessity of improving the\nexplanation quality of CRS. To achieve this, we conduct manual and automatic\napproaches to extend these dialogues and construct a new CRS dataset, namely\nExplainable Recommendation Dialogues (E-ReDial). It includes 756 dialogues with\nover 2,000 high-quality rewritten explanations. We compare two baseline\napproaches to perform explanation generation based on E-ReDial. Experimental\nresults suggest that models trained on E-ReDial can significantly improve\nexplainability while introducing knowledge into the models can further improve\nthe performance. GPT-3 in the in-context learning setting can generate more\nrealistic and diverse movie descriptions. In contrast, T5 training on E-ReDial\ncan better generate clear reasons for recommendations based on user\npreferences. E-ReDial is available at https://github.com/Superbooming/E-ReDial.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:36:08 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18364","submitter":"Xikun Li","authors":"Xikun Li, B{\\l}a\\.zej Jaworowski, Masudul Haque, Anne E. B. Nielsen","title":"Dynamics of quasiholes and quasiparticles at the edges of small lattices","comments":"13 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.quant-gas quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study quench dynamics of bosonic fractional quantum Hall systems in small\nlattices with cylindrical boundary conditions and low particle density. The\nstates studied have quasiholes or quasiparticles relative to the bosonic\nLaughlin state at half filling. Pinning potentials are placed at edge sites (or\nsites close to the edges) and are then turned off. Because the edges of\nfractional quantum Hall systems host chiral edge modes, we expect chiral\ndynamics, with motion in one direction for positive potentials pinning\nquasiholes, and motion in the other direction for negative potentials pinning\nquasiparticles. We numerically show that chiral motion of the density\ndistribution is observed and robust for the case with positive potentials\n(quasiholes), but that there is no noticeable chiral motion for negative\npotentials (quasiparticles). The comparison of the numerical ground states with\nmodel lattice Laughlin wavefunctions suggests that both positive and negative\npotentials do create and pin anyons that are not necessarily well-separated on\nsmall lattices. Initializing the dynamics with the model state also shows the\nlack of chiral dynamics of quasiparticles. Our results suggest that, in small\nlattices with low particle density, quasiparticles are strongly adversely\naffected in dynamical processes, whereas quasiholes are dynamically robust.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:36:58 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18365","submitter":"Taicheng Guo","authors":"Taicheng Guo, Kehan Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo,\n  Nitesh V. Chawla, Olaf Wiest, Xiangliang Zhang","title":"What indeed can GPT models do in chemistry? A comprehensive benchmark on\n  eight tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large Language Models (LLMs) with strong abilities in natural language\nprocessing tasks have emerged and have been rapidly applied in various kinds of\nareas such as science, finance and software engineering. However, the\ncapability of LLMs to advance the field of chemistry remains unclear. In this\npaper,we establish a comprehensive benchmark containing 8 practical chemistry\ntasks, including 1) name prediction, 2) property prediction, 3) yield\nprediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants\nfrom products), 6)text-based molecule design, 7) molecule captioning, and 8)\nreagent selection. Our analysis draws on widely recognized datasets including\nBBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the\ncapacities of LLMs within the context of practical chemistry. Three GPT models\n(GPT-4, GPT-3.5,and Davinci-003) are evaluated for each chemistry task in\nzero-shot and few-shot in-context learning settings with carefully selected\ndemonstration examples and specially crafted prompts. The key results of our\ninvestigation are 1) GPT-4 outperforms the other two models among the three\nevaluated; 2) GPT models exhibit less competitive performance in tasks\ndemanding precise understanding of molecular SMILES representation, such as\nreaction prediction and retrosynthesis;3) GPT models demonstrate strong\ncapabilities in text-related explanation tasks such as molecule captioning; and\n4) GPT models exhibit comparable or better performance to classical machine\nlearning models when applied to chemical problems that can be transformed into\nclassification or ranking tasks, such as property prediction, and yield\nprediction.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:17:33 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.18548","submitter":"Minjia Chen","authors":"Minjia Chen, Chunhui Yao, Adrian Wonfor, Qixiang Cheng, Richard Penty","title":"Generic photonic integrated linear operator processor","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.ET physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Photonic integration platforms have been explored extensively for optical\ncomputing with the aim of breaking the speed and power efficiency limitations\nof traditional digital electronic computers. Current technologies typically\nfocus on implementing a single computation iteration optically while leaving\nthe intermediate processing in the electronic domain, which are still limited\nby the electronic bottlenecks. Few explorations have been made of all-optical\nrecursive architectures for computations on integrated photonic platforms. Here\nwe propose a generic photonic integrated linear operator processor based on an\nall-optical recursive system that supports linear operations ranging from\nmatrix computations to solving equations. We demonstrate the first all-optical\non-chip matrix inversion system and use this to solve integral and differential\nequations. The absence of electronic processing during multiple iterations\nindicates the potential for an orders-of-magnitudes speed enhancement of this\nall-optical computing approach compared to electronic computers. We realize\nmatrix inversions, Fredholm integral equations of the second kind, 2^{nd} order\nordinary differential equations, and Poisson equations using the generic\nphotonic integrated linear operator processor.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 17:07:50 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.19280","submitter":"Yingjie Feng","authors":"Yingjie Feng, Jun Wang, Xianfeng Gu, Xiaoyin Xu, and Min Zhang","title":"Large language models improve Alzheimer's disease diagnosis using\n  multi-modality data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In diagnosing challenging conditions such as Alzheimer's disease (AD),\nimaging is an important reference. Non-imaging patient data such as patient\ninformation, genetic data, medication information, cognitive and memory tests\nalso play a very important role in diagnosis. Effect. However, limited by the\nability of artificial intelligence models to mine such information, most of the\nexisting models only use multi-modal image data, and cannot make full use of\nnon-image data. We use a currently very popular pre-trained large language\nmodel (LLM) to enhance the model's ability to utilize non-image data, and\nachieved SOTA results on the ADNI dataset.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 18:42:19 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.19281","submitter":"Zhaolin Li","authors":"Dihua Jiang, Zhaolin Li, and Guodong Xi","title":"The Uniqueness of the Ginzburg-Rallis Model: the Non-Archimedean Case","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.RT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove the uniqueness of the Ginzburg-Rallis models over $p$-adic local\nfields of characteristic zero, which completes the local uniqueness problem for\nthe Ginzburg-Rallis models starting from the work of C.-F. Nien in\n\\cite{MR2709083} that proves the non-split case, and the work of D. Jiang, B.\nSun and C. Zhu in \\cite{MR2763736} that proves the general case over\nArchimedean local fields. Our proof extends the strategy of \\cite{MR2763736} to\nthe $p$-adic case with the help of the refined structure of the wavefront sets\nof $\\mathfrak {z}$-finite distributions as developed by A. Aizenbud, D.\nGourevitch and E. Sayag in \\cite{MR3406530}.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 00:44:48 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.19282","submitter":"Roshanak Ghods","authors":"Vahid Reza Nafisi, Roshanak Ghods","title":"A Telecare System for Use in Traditional Persian Medicine","comments":null,"journal-ref":null,"doi":"10.2174/1874120702115010105","report-no":null,"categories":"cs.HC cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Persian Medicine (PM) uses wrist temperature/humidity and pulse to determine\na person's health status and temperament. However, the diagnosis may depend on\nthe physician's interpretation, hindering the combination of PM with modern\nmedical methods. This study proposes a system for measuring pulse signals and\ntemperament detection based on PM. The system uses recorded thermal\ndistribution, a temperament questionnaire, and a customized pulse measurement\ndevice. The collected data can be sent to a physician via a telecare system for\ninterpretation and prescription of medications. The system was clinically\nimplemented for patient care, assessed the temperaments of 34 participants, and\nrecorded thermal images of the wrist, back of the hand, and entire face. The\nstudy suggests that a customized device for measuring pulse waves and other\ncriteria based on PM can be incorporated into a telemedicine system, reducing\nthe dependency on PM specialists for diagnosis.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 05:20:01 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.19379","submitter":"Mohammad Asif","authors":"Mohammad Asif, Diya Srivastava, Aditya Gupta, Uma Shanker Tiwary","title":"Inter Subject Emotion Recognition Using Spatio-Temporal Features From\n  EEG Signal","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Inter-subject or subject-independent emotion recognition has been a\nchallenging task in affective computing. This work is about an\neasy-to-implement emotion recognition model that classifies emotions from EEG\nsignals subject independently. It is based on the famous EEGNet architecture,\nwhich is used in EEG-related BCIs. We used the Dataset on Emotion using\nNaturalistic Stimuli (DENS) dataset. The dataset contains the Emotional Events\n-- the precise information of the emotion timings that participants felt. The\nmodel is a combination of regular, depthwise and separable convolution layers\nof CNN to classify the emotions. The model has the capacity to learn the\nspatial features of the EEG channels and the temporal features of the EEG\nsignals variability with time. The model is evaluated for the valence space\nratings. The model achieved an accuracy of 73.04%.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 07:43:19 GMT"}],"update_date":"2023-06-01"}
{"id":"2306.00739","submitter":"Ruoxi Sun","authors":"Ruoxi Sun, Sercan O. Arik, Hootan Nakhost, Hanjun Dai, Rajarishi\n  Sinha, Pengcheng Yin, Tomas Pfister","title":"SQL-PaLM: Improved Large Language Model Adaptation for Text-to-SQL","comments":"16 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.DB","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  One impressive emergent capability of large language models (LLMs) is\ngeneration of code, including Structured Query Language (SQL) for databases.\nFor the task of converting natural language text to SQL queries, Text-to-SQL,\nadaptation of LLMs is of paramount importance, both in in-context learning and\nfine-tuning settings, depending on the amount of adaptation data used. In this\npaper, we propose an LLM-based Text-to-SQL model SQL-PaLM, leveraging on\nPaLM-2, that pushes the state-of-the-art in both settings. Few-shot SQL-PaLM is\nbased on an execution-based self-consistency prompting approach designed for\nText-to-SQL, and achieves 77.3% in test-suite accuracy on Spider, which to our\nbest knowledge is the first to outperform previous state-of-the-art with\nfine-tuning by a significant margin, 4%. Furthermore, we demonstrate that the\nfine-tuned SQL-PALM outperforms it further by another 1%. Towards applying\nSQL-PaLM to real-world scenarios we further evaluate its robustness on other\nchallenging variants of Spider and demonstrate the superior generalization\ncapability of SQL-PaLM. In addition, via extensive case studies, we demonstrate\nthe impressive intelligent capabilities and various success enablers of\nLLM-based Text-to-SQL.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:39:05 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 07:23:56 GMT"}],"update_date":"2023-06-08"}
{"id":"2306.00995","submitter":"Jean-Louis Krivine","authors":"Jean-Louis Krivine","title":"A note about Grothendieck's constant","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A remark on the proof that the Grothendieck constant satisfies $K_G <\n\\pi/(2\\ln(1+\\sqrt{2}))$.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 20:50:29 GMT"}],"update_date":"2023-06-05"}
{"id":"2306.01762","submitter":"Yujian Li","authors":"Kai Wu, Yujian Betterest Li, Xiaoyu Zhang, Handing Wang, Jing Liu","title":"Pre-trained transformer for adversarial purification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With more and more deep neural networks being deployed as various daily\nservices, their reliability is essential. It's frightening that deep neural\nnetworks are vulnerable and sensitive to adversarial attacks, the most common\none of which for the services is evasion-based. Recent works usually strengthen\nthe robustness by adversarial training or leveraging the knowledge of an amount\nof clean data. However, in practical terms, retraining and redeploying the\nmodel need a large computational budget, leading to heavy losses to the online\nservice. In addition, when adversarial examples of a certain attack are\ndetected, only limited adversarial examples are available for the service\nprovider, while much clean data may not be accessible. Given the mentioned\nproblems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is\nto rapidly defend against a certain attack for the frozen original service\nmodel with limitations of few clean and adversarial examples. Motivated by the\ngeneralization and the universal computation ability of pre-trained transformer\nmodels, we come up with a new defender method, CeTaD, which stands for\nConsidering Pre-trained Transformers as Defenders. In particular, we evaluate\nthe effectiveness and the transferability of CeTaD in the case of one-shot\nadversarial examples and explore the impact of different parts of CeTaD as well\nas training data conditions. CeTaD is flexible, able to be embedded into an\narbitrary differentiable model, and suitable for various types of attacks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 06:00:51 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01763","submitter":"Sumit Kumar","authors":"Bhawani Sandeep, Surjeet Singh, Sumit Kumar","title":"Optimization for truss design using Bayesian optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, geometry optimization of mechanical truss using computer-aided\nfinite element analysis is presented. The shape of the truss is a dominant\nfactor in determining the capacity of load it can bear. At a given parameter\nspace, our goal is to find the parameters of a hull that maximize the\nload-bearing capacity and also don't yield to the induced stress. We rely on\nfinite element analysis, which is a computationally costly design analysis tool\nfor design evaluation. For such expensive to-evaluate functions, we chose\nBayesian optimization as our optimization framework which has empirically\nproven sample efficient than other simulation-based optimization methods.\n  By utilizing Bayesian optimization algorithms, the truss design involves\niteratively evaluating a set of candidate truss designs and updating a\nprobabilistic model of the design space based on the results. The model is used\nto predict the performance of each candidate design, and the next candidate\ndesign is selected based on the prediction and an acquisition function that\nbalances exploration and exploitation of the design space. Our result can be\nused as a baseline for future study on AI-based optimization in expensive\nengineering domains especially in finite element Analysis.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 10:28:27 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01764","submitter":"Satoshi Takahashi","authors":"Satoshi Takahashi, Atushi Yoshikawa","title":"Data Science in an Agent-Based Simulation World","comments":"9 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In data science education, the importance of learning to solve real-world\nproblems has been argued. However, there are two issues with this approach: (1)\nit is very costly to prepare multiple real-world problems (using real data)\naccording to the learning objectives, and (2) the learner must suddenly tackle\ncomplex real-world problems immediately after learning from a textbook using\nideal data. To solve these issues, this paper proposes data science teaching\nmaterial that uses agent-based simulation (ABS). The proposed teaching material\nconsists of an ABS model and an ABS story. To solve issue 1, the scenario of\nthe problem can be changed according to the learning objectives by setting the\nappropriate parameters of the ABS model. To solve issue 2, the difficulty level\nof the tasks can be adjusted by changing the description in the ABS story. We\nshow that, by using this teaching material, the learner can simulate the\ntypical tasks performed by a data scientist in a step-by-step manner (causal\ninference, data understanding, hypothesis building, data collection, data\nwrangling, data analysis, and hypothesis testing). The teaching material\ndescribed in this paper focuses on causal inference as the learning objectives\nand infectious diseases as the model theme for ABS, but ABS is used as a model\nto reproduce many types of social phenomena, and its range of expression is\nextremely wide. Therefore, we expect that the proposed teaching material will\ninspire the construction of teaching material for various objectives in data\nscience education.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:16:03 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01765","submitter":"Jonathan Jiang","authors":"Jonathan H. Jiang, Anamaria Berea, Heather Bowden, Prithwis Das,\n  Kristen A. Fahy, Robert Jew, Xiaoming Jiang, Arik Kershenbaum, David Kipping,\n  Graham Lau, Karen Lewis, C. Isabel Nunez Lendo, Philip E. Rosen, Nick Searra,\n  Stuart F. Taylor, John Traphagan","title":"Message in a Bottle -- An Update to the Golden Record","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY physics.ed-ph physics.soc-ph","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Communication is an essential asset enabling humankind to forge an advanced\ncivilization. Using approximately 31,000 languages from the Stone Age to our\npresent digital information society, humans have connected and collaborated to\naccomplish remarkable feats. As the newly dawned Space Age progresses, we are\nattempting to communicate with intelligent species beyond our world, on distant\nplanets and in Earth's far future. Absent mutually understood signs, symbols,\nand semiotic conventions, this study, the \"Message in a Bottle\", uses\nscientific methods to assess and design a means of communication encapsulating\nthe story of humanity, conveying our thoughts, emotions, ingenuity, and\naspirations. The message will be structured to provide a universal yet\ncontextual understanding of modern human society, evolution of life on Earth,\nand challenges for the future. In assembling this space and time capsule, we\naim to energize and unite current generations to celebrate and preserve\nhumanity.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 12:20:33 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.01766","submitter":"Michail Chatzimanolakis","authors":"Konstantinos Vogiatzoglou, Costas Papadimitriou, Konstantinos\n  Ampountolas, Michail Chatzimanolakis, Petros Koumoutsakos, Vasilis\n  Bontozoglou","title":"An interpretable wildfire spreading model for real-time predictions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Forest fires pose a natural threat with devastating social, environmental,\nand economic implications. The rapid and highly uncertain rate of spread of\nwildfires necessitates a trustworthy digital tool capable of providing\nreal-time estimates of fire evolution and human interventions, while receiving\ncontinuous input from remote sensing. The current work aims at developing an\ninterpretable, physics-based model that will serve as the core of such a tool.\nThis model is constructed using easily understandable equations, incorporating\na limited set of parameters that capture essential quantities and heat\ntransport mechanisms. The simplicity of the model allows for effective\nutilization of data from sensory input, enabling optimal estimation of these\nparameters. In particular, simplified versions of combustion kinetics and\nmass/energy balances lead to a computationally inexpensive system of\ndifferential equations that provide the spatio-temporal evolution of\ntemperature and flammables over a two-dimensional region. The model is\nvalidated by comparing its predictions and the effect of parameters such as\nflammable bulk density, moisture content, and wind speed, with benchmark\nresults. Additionally, the model successfully captures the evolution of the\nfirefront shape and its rate of spread in multiple directions.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 15:19:43 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.03044","submitter":"Basudev Nag Chowdhury","authors":"Ankita Sengupta, Basudev Nag Chowdhury, Bodhishatwa Roy, Biswarup\n  Satpati, Satyaban Bhunia, Sanatan Chattopadhyay","title":"Light-activated memristor by Au-nanoparticle embedded\n  HfO$_2$-bilayer/p-Si MOS device","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The current work proposes a novel scheme for developing a light-activated\nnon-filamentary memristor device by fabricating an Au-nanoparticle embedded\nHfO$_2$-bilayer/p-Si MOS structure. Under illumination, the electrons in such\nembedded Au-nanoparticles are excited from d-level to quantized s-p level and\nare swept out on application of an appropriate gate bias, leaving behind the\nholes without recombination. Such photogenerated holes are confined within the\nnanoparticles and thus screen the external field to lead to a memristive effect\nin the device. The phenomenon is experimentally observed in the fabricated\nPt/HfO$_2$-(layer-II)/Au-NPs/HfO$_2$-(layer-I)/p-Si devices, where such\nmemristive effect is activated/deactivated by light pulses. The memory window\nand high-to-low resistance ratio of the device are obtained to be ~1 V and ~10,\nrespectively, which suggest the performance of a standard state-of-the-art\nmemristor. Further, the present device offers a voltage-sweep-endurance up to\nat least 150 cycles and the memory retention up to ~10,000 s. Such a device\nconcept can be extended for a combination of different nanoparticles with\nvarious dimensions and dielectric layers to optimize their memristive effect\nfor achieving CMOS-compatible memory devices with superior reliability.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 08:07:16 GMT"}],"update_date":"2023-06-06"}
{"id":"2306.03093","submitter":"Kaiyang Gao","authors":"Kaiyang Gao, Jiyu Shen, Zeyi Lu, Jiajun Mo, Guoqing Liu, Zhongjin Wu,\n  Chenying Gong, Dong Xie, Yanfang Xia and Min Liu","title":"The Effect of Ionic Spin on Multiferroic of Orthorhombic Perovskite","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To investigate the influence of ion spin on the coupling between\nferromagnetism and ferroelectricity in type II multiferroic perovskite, we\nprepared the multiferroic perovskite Er0.9La0.1Cr0.8Fe0.2O3 (ELCFO) using the\nsol-gel method, and explored the macroscopic magnetic properties of ELCFO\nthrough M\\\"ossbauer spectrum and magnetic testing. The thermal magnetic curve\nwas analyzed to examine the state and change of each ionic spin in the ELCFO\nsystem at different temperature ranges, and the role of ionic spin in the\ncoupling between ferromagnetism and ferroelectricity was investigated. This\nstudy provides a theoretical basis for further research on multiferroic\nperovskites and has practical implications.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:32:26 GMT"}],"update_date":"2023-06-07"}
{"id":"2306.03094","submitter":"Kaiyang Gao","authors":"Kaiyang Gao, Kexuan Zhou, Jiyu Shen, Zeyi Lu, Chenying Gong, Zhongjin\n  Wu, Ke Shi, Jing Guo, Zhaoyi Wang, Min Liu","title":"Calculation of Special Spin Behavior of Dy3+ in DyFe1-xCrxO3 System by\n  Molecular Field Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this study, the sol-gel method synthesized the magnetic measurement and\nanalysis of single-phase polycrystalline perovskite DyFe1-xCrxO3 (DFCO). The\nexperimental data were fitted and calculated by a four-sublattice molecular\nfield model. Unlike previous studies, we found that in DyFe1-xCrxO3, the spin\nof the A-site rare earth ion Dy3+ also changed simultaneously with the spin\nreorientation of the Fe3+/Cr3+ ions. The effective spin is defined as the\nprojection of the A site's total spin on the B site's spin plane, and the curve\nof temperature changes is obtained after fitting. With this theory, a very\naccurate thermomagnetic curve is obtained by fitting. This is convincing and,\nat the same time, provides a reference for the development of spintronic\ndevices in the future.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 11:46:00 GMT"}],"update_date":"2023-06-07"}
{"id":"2306.03777","submitter":"Enia Xhakaj","authors":"Enia Xhakaj, Alexie Leauthaud, Johannes Lange, Elisabeth Krause,\n  Andrew Hearin, Song Huang, Risa H. Wechsler, Sven Heydenreich","title":"Cluster Cosmology Without Cluster Finding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose that observations of super-massive galaxies contain cosmological\nconstraining power similar to conventional cluster cosmology, and we provide\npromising indications that the associated systematic errors are comparably\neasier to control. We consider a fiducial spectroscopic and stellar mass\ncomplete sample of galaxies drawn from the Dark Energy Spectroscopic Survey\n(DESI) and forecast how constraints on Omega_m-sigma_8 from this sample will\ncompare with those from number counts of clusters based on richness. At fixed\nnumber density, we find that massive galaxies offer similar constraints to\ngalaxy clusters. However, a mass-complete galaxy sample from DESI has the\npotential to probe lower halo masses than standard optical cluster samples\n(which are typically limited to richness above 20 and halo mass above 10^13.5);\nadditionally, it is straightforward to cleanly measure projected galaxy\nclustering for such a DESI sample, which we show can substantially improve the\nconstraining power on Omega_m. We also compare the constraining power of\nstellar mass-limited samples to those from larger but mass-incomplete samples\n(e.g., the DESI Bright Galaxy Survey, BGS, Sample); relative to a lower number\ndensity stellar mass-limited samples, we find that a BGS-like sample improves\nstatistical constraints by 60% for Omega_m and 40% for sigma_8, but this uses\nsmall scale information which will be harder to model for BGS. Our initial\nassessment of the systematics associated with supermassive galaxy cosmology\nyields promising results. The proposed samples have a 10% satellite fraction,\nbut we show that cosmological constraints may be robust to the impact of\nsatellites. These findings motivate future work to realize the potential of\nsuper-massive galaxies to probe lower halo masses than richness-based clusters\nand to avoid persistent systematics associated with optical cluster finding.\n","versions":[{"version":"v1","created":"Fri, 26 May 2023 21:44:09 GMT"}],"update_date":"2023-06-07"}
{"id":"2306.03781","submitter":"Xiaochen Wang","authors":"Xiaochen Wang, Lei Zhou, Alex McAvoy, Aming Li","title":"Imitation dynamics on networks with incomplete social information","comments":"14pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Imitation is an important social learning heuristic in animal and human\nsocieties that drives the evolution of collective behaviors. Previous\nexplorations find that the fate of cooperators has a sensitive dependence on\nthe protocol of imitation, including the number of social peers used for\ncomparison and whether one's own performance is considered. This leads to a\npuzzle about how to quantify the impact of different styles of imitation on the\nevolution of cooperation. Here, we take a novel perspective on the personal and\nsocial information required by imitation. We develop a general model of\nimitation dynamics with incomplete social information, which unifies classical\nimitation processes including death-birth and pairwise-comparison update rules.\nIn pairwise social dilemmas, we find that cooperation is most easily promoted\nif individuals neglect personal information when imitating. If personal\ninformation is considered, cooperators evolve more readily with more social\ninformation. Intriguingly, when interactions take place in larger groups on\nnetworks with low degrees of clustering, using more personal and less social\ninformation better facilitates cooperation. We offer a unifying perspective\nuncovering intuition behind these phenomena by examining the rate and range of\ncompetition induced by different social dilemmas.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 13:00:25 GMT"}],"update_date":"2023-06-07"}
{"id":"2306.04644","submitter":"Yuguang Yang","authors":"Yuguang Yang, Runtang Guo, Sheng Wu, Yimi Wang, Juan Zhang, Xuan Gong,\n  Baochang Zhang","title":"Decom--CAM: Tell Me What You See, In Details! Feature-Level\n  Interpretation via Decomposition Class Activation Map","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Interpretation of deep learning remains a very challenging problem. Although\nthe Class Activation Map (CAM) is widely used to interpret deep model\npredictions by highlighting object location, it fails to provide insight into\nthe salient features used by the model to make decisions. Furthermore, existing\nevaluation protocols often overlook the correlation between interpretability\nperformance and the model's decision quality, which presents a more fundamental\nissue. This paper proposes a new two-stage interpretability method called the\nDecomposition Class Activation Map (Decom-CAM), which offers a feature-level\ninterpretation of the model's prediction. Decom-CAM decomposes intermediate\nactivation maps into orthogonal features using singular value decomposition and\ngenerates saliency maps by integrating them. The orthogonality of features\nenables CAM to capture local features and can be used to pinpoint semantic\ncomponents such as eyes, noses, and faces in the input image, making it more\nbeneficial for deep model interpretation. To ensure a comprehensive comparison,\nwe introduce a new evaluation protocol by dividing the dataset into subsets\nbased on classification accuracy results and evaluating the interpretability\nperformance on each subset separately. Our experiments demonstrate that the\nproposed Decom-CAM outperforms current state-of-the-art methods significantly\nby generating more precise saliency maps across all levels of classification\naccuracy. Combined with our feature-level interpretability approach, this paper\ncould pave the way for a new direction for understanding the decision-making\nprocess of deep neural networks.\n","versions":[{"version":"v1","created":"Sat, 27 May 2023 14:33:01 GMT"}],"update_date":"2023-06-09"}
