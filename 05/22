{"id":"2305.12492","submitter":"Roberto Maiolino","authors":"Roberto Maiolino, Jan Scholtz, Joris Witstok, Stefano Carniani,\n  Francesco D'Eugenio, Anna de Graaff, Hannah Uebler, Sandro Tacchella, Emma\n  Curtis-Lake, Santiago Arribas, Andrew Bunker, St\\'ephane Charlot, Jacopo\n  Chevallard, Mirko Curti, Tobias J. Looser, Michael V. Maseda, Tim Rawle,\n  Bruno Rodriguez Del Pino, Chris J. Willott, Eiichi Egami, Daniel Eisenstein,\n  Kevin Hainline, Brant Robertson, Christina C. Williams, Christopher N. A.\n  Willmer, William M. Baker, Kristan Boyett, Christa DeCoursey, Andrew C.\n  Fabian, Jakob M. Helton, Zhiyuan Ji, Gareth C. Jones, Nimisha Kumari, Nicolas\n  Laporte, Erica Nelson, Michele Perna, Lester Sandles, Irene Shivaei and\n  Fengwu Sun","title":"A small and vigorous black hole in the early Universe","comments":"8 figures, submitted","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.CO astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Black holes with masses in excess of several billion solar masses have been\nfound at redshifts 6-7.5, when the universe was less than 1 Gyr old. The\nexistence of such supermassive black holes already in place at such early\nepochs has been challenging for theoretical models and distinguishing between\ndifferent scenarios has prompted the search for their progenitors at earlier\nepochs. Here we present an extensive analysis of the JWST-NIRSpec spectrum\n(from the JADES survey) of GN-z11, an exceptionally luminous galaxy at z=10.6,\nrevealing the detection of the high ionization [NeIV]$\\lambda$2423 transition\nand semi-forbidden nebular lines tracing gas densities higher than $\\rm\n10^{10}~cm^{-3}$, typical of the Broad Line Region of Active Galactic Nuclei\n(AGN). These spectral features indicate that, in addition to star formation,\nGN-z11 also hosts an accreting black hole. We do not exclude a contribution\nfrom extreme stellar populations, however Wolf Rayet stars alone cannot account\nfor many of the spectral properties. The spectrum also reveals a deep and\nblueshifted CIV$\\lambda$1549 absorption trough, tracing an outflow with a\nvelocity of $\\sim 800-1000$ km/s, higher than typically observed in starburst\ngalaxies, hence likely driven by the AGN. Assuming local virial scaling\nrelations, we derive a black hole mass of $\\rm \\log{(M_{BH}/M_{\\odot})}=6.2\\pm\n0.3$, accreting at about 5 times the Eddington rate. While super-Eddington\naccretion is probably episodic, if it has been occurring for the previous $\\sim\n100$ Myr, then the black hole could have potentially originated even from a\nstellar mass seed at z$\\sim$12-15. We finally discuss that our finding\nnaturally explains the high luminosity of GN-z11 and can also provide an\nexplanation for its exceptionally high nitrogen abundance.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:01:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12493","submitter":"Kaixun Huang","authors":"Kaixun Huang, Ao Zhang, Zhanheng Yang, Pengcheng Guo, Bingshen Mu,\n  Tianyi Xu, Lei Xie","title":"Contextualized End-to-End Speech Recognition with Contextual Phrase\n  Prediction Network","comments":"Accepted by interspeech2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Contextual information plays a crucial role in speech recognition\ntechnologies and incorporating it into the end-to-end speech recognition models\nhas drawn immense interest recently. However, previous deep bias methods lacked\nexplicit supervision for bias tasks. In this study, we introduce a contextual\nphrase prediction network for an attention-based deep bias method. This network\npredicts context phrases in utterances using contextual embeddings and\ncalculates bias loss to assist in the training of the contextualized model. Our\nmethod achieved a significant word error rate (WER) reduction across various\nend-to-end speech recognition models. Experiments on the LibriSpeech corpus\nshow that our proposed model obtains a 12.1% relative WER improvement over the\nbaseline model, and the WER of the context phrases decreases relatively by\n40.5%. Moreover, by applying a context phrase filtering strategy, we also\neffectively eliminate the WER degradation when using a larger biasing list.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:08:04 GMT"},{"version":"v2","created":"Mon, 29 May 2023 04:21:48 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12494","submitter":"Alexander Mang","authors":"Alexander Mang","title":"First cohomology with trivial coefficients of all unitary easy quantum\n  group duals","comments":"43 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.QA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The first quantum group cohomology with trivial coefficients of the discrete\ndual of any unitary easy quantum group is computed. That includes those\npotential quantum groups whose associated categories of two-colored partitions\nhave not yet been found.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:12:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12495","submitter":"Gaurav Maheshwari","authors":"Gaurav Maheshwari, Aur\\'elien Bellet, Pascal Denis, Mikaela Keller","title":"How to Capture Intersectional Fairness","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we tackle the problem of intersectional group fairness in the\nclassification setting, where the objective is to learn discrimination-free\nmodels in the presence of several intersecting sensitive groups. First, we\nillustrate various shortcomings of existing fairness measures commonly used to\ncapture intersectional fairness. Then, we propose a new framework called the\n$\\alpha$ Intersectional Fairness framework, which combines the absolute and the\nrelative performances between sensitive groups. Finally, we provide various\nanalyses of our proposed framework, including the min-max and efficiency\nanalysis. Our experiments using the proposed framework show that several\nin-processing fairness approaches show no improvement over a simple\nunconstrained approach. Moreover, we show that these approaches minimize\nexisting fairness measures by degrading the performance of the best of the\ngroup instead of improving the worst.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:15:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12496","submitter":"Pranava Chaitanya Jayanti","authors":"Juhi Jang, Pranava Chaitanya Jayanti, Igor Kukavica","title":"Small-data global existence of solutions for the Pitaevskii model of\n  superfluidity","comments":"34 pages. arXiv admin note: text overlap with arXiv:2106.04659","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP cond-mat.other physics.flu-dyn quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We investigate a micro-scale model of superfluidity derived by Pitaevskii in\n1959 to describe the interacting dynamics between the superfluid and normal\nfluid phases of Helium-4. The model involves the nonlinear Schr\\\"odinger\nequation (NLS) and the Navier-Stokes equations (NSE), coupled to each other via\na bidirectional nonlinear relaxation mechanism. Depending on the nature of the\nnonlinearity in the NLS, we prove global/almost global existence of solutions\nto this system in $\\mathbb{T}^2$ -- strong in wavefunction and velocity, and\nweak in density.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:19:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12497","submitter":"Chuan Fang","authors":"Yuan Dong, Chuan Fang, Liefeng Bo, Zilong Dong, Ping Tan","title":"PanoContext-Former: Panoramic Total Scene Understanding with a\n  Transformer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Panoramic image enables deeper understanding and more holistic perception of\n$360^\\circ$ surrounding environment, which can naturally encode enriched scene\ncontext information compared to standard perspective image. Previous work has\nmade lots of effort to solve the scene understanding task in a bottom-up form,\nthus each sub-task is processed separately and few correlations are explored in\nthis procedure. In this paper, we propose a novel method using depth prior for\nholistic indoor scene understanding which recovers the objects' shapes,\noriented bounding boxes and the 3D room layout simultaneously from a single\npanorama. In order to fully utilize the rich context information, we design a\ntransformer-based context module to predict the representation and relationship\namong each component of the scene. In addition, we introduce a real-world\ndataset for scene understanding, including photo-realistic panoramas,\nhigh-fidelity depth images, accurately annotated room layouts, and oriented\nobject bounding boxes and shapes. Experiments on the synthetic and real-world\ndatasets demonstrate that our method outperforms previous panoramic scene\nunderstanding methods in terms of both layout estimation and 3D object\ndetection.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:20:57 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 04:43:41 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12498","submitter":"Yassir Fathullah","authors":"Yassir Fathullah, Chunyang Wu, Yuan Shangguan, Junteng Jia, Wenhan\n  Xiong, Jay Mahadeokar, Chunxi Liu, Yangyang Shi, Ozlem Kalinli, Mike Seltzer,\n  Mark J. F. Gales","title":"Multi-Head State Space Model for Speech Recognition","comments":"Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.CL cs.LG cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  State space models (SSMs) have recently shown promising results on\nsmall-scale sequence and language modelling tasks, rivalling and outperforming\nmany attention-based approaches. In this paper, we propose a multi-head state\nspace (MH-SSM) architecture equipped with special gating mechanisms, where\nparallel heads are taught to learn local and global temporal dynamics on\nsequence data. As a drop-in replacement for multi-head attention in transformer\nencoders, this new model significantly outperforms the transformer transducer\non the LibriSpeech speech recognition corpus. Furthermore, we augment the\ntransformer block with MH-SSMs layers, referred to as the Stateformer,\nachieving state-of-the-art performance on the LibriSpeech task, with word error\nrates of 1.76\\%/4.37\\% on the development and 1.91\\%/4.36\\% on the test sets\nwithout using an external language model.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:28:57 GMT"},{"version":"v2","created":"Thu, 25 May 2023 21:55:58 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12499","submitter":"Abdul Khaliq Mr","authors":"Abdul Khaliq, Sabina Lewinska, Roman Minikaev, Monika Arciszewska,\n  Andrei Avdonin, Beata Brodowska, Vasily E. Slynko, Anna Slawska Waniewska,\n  and Lukasz Kilanski","title":"Magnetic phase diagram of Ge1-x-ySnxMnyTe multiferroic semiconductors;\n  coexistence of ferromagnetic and cluster glass ordering","comments":"This preprint has 18 pages, 8 main figures, 2 tables and 7 supporting\n  figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report the structural and magnetic results of polar {\\alpha}-GeTe doped\nwith Sn and Mn from x = 0.185 to 0.841 and y = 0.02 to 0.086, respectively. The\nmagnetic results of Ge1-x-y(SnxMny)Te (GSMT) crystals identify Mn-clustering\neffect with scaling parameter, R = 0.033 for x ~ 0.2 and y = 0.06. The\nexcessive Sn ions are assumed to drive the inception of short range\nferromagnetic clusters. For the crystals revealing glassy magnetic behavior,\nthe irreversibility temperature, Tirr shifts at high dc magnetic field which is\nwell described by de Almeida-Thouless equation, {\\delta}Tirr ~ H{\\Phi}/2\nyielding {\\Phi} values of 1.55 and 1.7 that validates the formation of Mn\nclusters. The spin relaxation time, {\\tau}0 ~ 10-9 s, activation energy, Ea/kB\n~ 5 TF where TF is freeing temperature and Vogel-Fulcher temperature, T0 ~ TF\nalso signify intracluster interactions. Also, the Mn-hole magnetic exchange\nconstant, Jpd drops from 0.24 eV for the samples with smaller Sn content of x ~\n0.2 to 0.16 eV for Sn rich alloy with x ~ 0.8. Consequently, we present a\nmagnetic phase diagram for GSMT bulk crystals as a function of Mn(y) ions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:29:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12500","submitter":"Molla Ahamed","authors":"Sanju Mandal, Partha Pratim Roy, and Molla Basir Ahamed","title":"Sharp bounds for second Hankel determinant of logarithmic coefficients\n  for certain classes of univalent functions","comments":"10 pages, 0 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Hankel determinant $H_{2,2}(F_{f}/2)$ is defined as: \\begin{align*}\n  H_{2,2}(F_{f}/2):= \\begin{vmatrix}\n  \\gamma_2 & \\gamma_3\n  \\gamma_3 & \\gamma_4\n  \\end{vmatrix}, \\end{align*} where $\\gamma_2, \\gamma_3,$ and $\\gamma_4$ are\nthe second, third, and fourth logarithmic coefficients of functions belonging\nto the class $\\mathcal{S}$ of normalized univalent functions. In this article,\nwe establish sharp inequalities $|H_{2,2}(F_{f}/2)|\\leq (1272 +\n113\\sqrt{678})/32856$ and $|H_{2,2}(F_{f}/2)| \\leq 13/1080$ for the logarithmic\ncoefficients of starlike and convex functions with respect to symmetric points.\nMoreover, we provide examples that demonstrate the strict inequality holds.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:32:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12501","submitter":"Jingyi Chen","authors":"Jingyi Chen and Micha Elsner","title":"Exploring How Generative Adversarial Networks Learn Phonological\n  Representations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper explores how Generative Adversarial Networks (GANs) learn\nrepresentations of phonological phenomena. We analyze how GANs encode\ncontrastive and non-contrastive nasality in French and English vowels by\napplying the ciwGAN architecture (Begus 2021a). Begus claims that ciwGAN\nencodes linguistically meaningful representations with categorical variables in\nits latent space and manipulating the latent variables shows an almost one to\none corresponding control of the phonological features in ciwGAN's generated\noutputs. However, our results show an interactive effect of latent variables on\nthe features in the generated outputs, which suggests the learned\nrepresentations in neural networks are different from the phonological\nrepresentations proposed by linguists. On the other hand, ciwGAN is able to\ndistinguish contrastive and noncontrastive features in English and French by\nencoding them differently. Comparing the performance of GANs learning from\ndifferent languages results in a better understanding of what language specific\nfeatures contribute to developing language specific phonological\nrepresentations. We also discuss the role of training data frequencies in\nphonological feature learning.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:37:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12502","submitter":"Yugeng Liu","authors":"Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang","title":"Watermarking Diffusion Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The availability and accessibility of diffusion models (DMs) have\nsignificantly increased in recent years, making them a popular tool for\nanalyzing and predicting the spread of information, behaviors, or phenomena\nthrough a population. Particularly, text-to-image diffusion models (e.g., DALLE\n2 and Latent Diffusion Models (LDMs) have gained significant attention in\nrecent years for their ability to generate high-quality images and perform\nvarious image synthesis tasks. Despite their widespread adoption in many\nfields, DMs are often susceptible to various intellectual property violations.\nThese can include not only copyright infringement but also more subtle forms of\nmisappropriation, such as unauthorized use or modification of the model.\nTherefore, DM owners must be aware of these potential risks and take\nappropriate steps to protect their models. In this work, we are the first to\nprotect the intellectual property of DMs. We propose a simple but effective\nwatermarking scheme that injects the watermark into the DMs and can be verified\nby the pre-defined prompts. In particular, we propose two different\nwatermarking methods, namely NAIVEWM and FIXEDWM. The NAIVEWM method injects\nthe watermark into the LDMs and activates it using a prompt containing the\nwatermark. On the other hand, the FIXEDWM is considered more advanced and\nstealthy compared to the NAIVEWM, as it can only activate the watermark when\nusing a prompt containing a trigger in a fixed position. We conducted a\nrigorous evaluation of both approaches, demonstrating their effectiveness in\nwatermark injection and verification with minimal impact on the LDM's\nfunctionality.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:37:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12503","submitter":"Amit Joshi Dr","authors":"Riyaz Ahmad, Amit M. Joshi, Dharmendra Boolchandani","title":"Programmable Transimpedance Amplifier with Integrated Bandgap Reference\n  for Glucose Concentration Measurement","comments":"17 Pages, 14 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For glucose electrochemical sensors, a comprehensive electronics interface is\ndesigned and constructed in 0.18 um, CMOS process technology, and 1.5 V supply\nvoltage. This interface includes a programmable readout amplifier and bandgap\nreference voltage potentiostat circuit. The programmable transimpedance\namplifier (PTIA), the proposed readout circuit, provides a large dynamic range\nand low noise. The overall transimpedance increase for the PTIA is 17.3-50.5\nkohm. For an input current range of 4.2-180 uA, the PTIA response has a linear\noutput voltage range of 0.55-1.44 V. The output rms noise value is calculated\nto be 5.101 Vrms, and the overall power consumption of the design is 2.33 mW.\nThe THD percentage spans from 7.6 to 10.2 in the current range mentioned above.\nAll bandgap reference voltage potentiostat measurements are made using the\nreference potential of 0.6 V. The working electrode was a glassy carbon\nelectrode (GCE) loaded with a CuO/Cu0:76CO2:25O4 (copper cobaltite) coating. An\nelectrochemical glucose sensing setup has been used to measure glucose\nconcentrations between 1 and 10 mM, and an emulated circuit has been used to\nverify the viability of the proposed glucose sensing design. The suggested\nglucose sensor architecture has a total size of 0.0684 mm2.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:42:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12504","submitter":"Raffaella Schneider","authors":"Raffaella Schneider, Rosa Valiante, Alessandro Trinca, Luca Graziani,\n  and Marta Volonteri","title":"Are we surprised to find SMBHs with JWST at z > 9?","comments":"11 pages, 5 figures, submitted to MNRAS","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent discovery of new Active Galactic Nuclei (AGN) at z > 4 with JWST\nis revolutionising the black hole (BH) landscape at cosmic dawn, unveiling for\nthe first time accreting BHs with masses of 10^6 - 10^7 Msun. To date, the most\ndistant reside in CEERS-1019 at z=8.7 and GNz11 at z=10.6. Given the high rate\nof newly discovered high-z AGNs, more than 10 at z > 4, we wonder: are we\nreally surprised to find them in the nuclei of z = 5 - 11 galaxies? Can we use\nthe estimated properties to trace their origin? In this work, we predict the\nproperties of 4 < z < 11 BHs and their host galaxies considering an\nEddington-limited (EL) and a super-Eddington (SE) BH accretion scenario, using\nthe Cosmic Archaeology Tool (CAT), a semi-analytical model for the formation\nand evolution of z > 4 AGNs and galaxies. We then calculate the transmitted\nspectral energy distribution of CAT synthetic candidates, representative of the\nestimated BH properties in CEERS-1019 and GNz11. We find that the estimated\nluminosity of high-z JWST detected AGNs are better reproduced by the SE model,\nwhere BHs descend from efficiently growing light and heavy seeds. Conversely,\nthe host galaxy stellar masses are better matched in the EL model, in which all\nthe systems detectable with JWST surveys JADES and CEERS appear to be\ndescendants of heavy BH seeds. Our study suggests an evolutionary connection\nbetween systems similar to GNz11 at z=10.6 and CEERS-1019 at z=8.7 and supports\nthe interpretation that the central point source of GNz11 could be powered by a\nsuper-Eddington (lambda_Edd = 2 - 3) accreting BH with mass 1.5 10^6 Msun,\nwhile CEERS-1019 harbours a more massive BH, with M_{BH} = 10^7 Msun, accreting\nsub-Eddington (lambda_Edd = 0.45 - 1), with a dominant emission from the host\ngalaxy.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:47:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12505","submitter":"Luca Nanni","authors":"Luca Nanni","title":"Electromagnetic Field Theory in Superluminal Spacetime","comments":"34 pages, 1 figure","journal-ref":"Indian Journal of Physics (2023)","doi":"10.1007/s12648-023-02747-3","report-no":null,"categories":"physics.gen-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, a number of experimental observations on the superluminal group\nvelocities of pulses propagating in dispersive media have led to reconsidering\nelectromagnetism theory in an unconventional framework. To consider\nfaster-than-light phenomena, it is not necessary to replace the current\nrelativistic theory, but it is sufficient to extend it to superluminal motions\nin a way that preserves the principle of causality. In the present paper, a new\napproach to study superluminal motions is proposed, which avoids introducing\nunphysical complex quantities and allows for the formulation of equations that\nare covariant according to a hyperbolic metric. In the framework of this\nformalism, Maxwell equations and the single-photon wave equation are obtained\nthrough superluminal transformations of ordinary equations. It is shown that\nthe covariant and contravariant components of the superluminal electromagnetic\nfield determine its magnitude and direction, respectively. Furthermore, the\nsolutions of the transformed Maxwell equations are X-shaped ways propagating in\nthe superluminal spacetime region that is delimited by the infinite light cone\nand the two-sheet hyperboloid perpendicular to it. Instead, in quantum\nmechanics, the covariant and contravariant components of the electromagnetic\nfield are proportional to the right- and left-handed helicities of the single\nphoton, respectively.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:50:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12506","submitter":"Xiaoguang Li","authors":"Xiaoguang Li","title":"CNN-based Dendrite Core Detection from Microscopic Images of\n  Directionally Solidified Ni-base Alloys","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Dendrite core is the center point of the dendrite. The information of\ndendrite core is very helpful for material scientists to analyze the properties\nof materials. Therefore, detecting the dendrite core is a very important task\nin the material science field. Meanwhile, because of some special properties of\nthe dendrites, this task is also very challenging. Different from the typical\ndetection problems in the computer vision field, detecting the dendrite core\naims to detect a single point location instead of the bounding-box. As a\nresult, the existing regressing bounding-box based detection methods can not\nwork well on this task because the calculated center point location based on\nthe upper-left and lower-right corners of the bounding-box is usually not\nprecise. In this work, we formulate the dendrite core detection problem as a\nsegmentation task and proposed a novel detection method to detect the dendrite\ncore directly. Our whole pipeline contains three steps: Easy Sample Detection\n(ESD), Hard Sample Detection(HSD), and Hard Sample Refinement (HSR).\nSpecifically, ESD and HSD focus on the easy samples and hard samples of\ndendrite cores respectively. Both of them employ the same Central Point\nDetection Network (CPDN) but do not share parameters. To make HSD only focus on\nthe feature of hard samples of dendrite cores, we destroy the structure of the\neasy samples of dendrites which are detected by ESD and force HSD to learn the\nfeature of hard samples. HSR is a binary classifier which is used to filter out\nthe false positive prediction of HSD. We evaluate our method on the dendrite\ndataset. Our method outperforms the state-of-the-art baselines on three\nmetrics, i.e., Recall, Precision, and F-score.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:51:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12507","submitter":"Siqi Zhao","authors":"Siqi Zhao, Huirong Yan, Terry Z. Liu, Ka Ho Yuen, Mijie Shi","title":"Compressible Magnetohydrodynamic Turbulence Modulated by Collisionless\n  Damping in Earth's Magnetosheath: Observation Matches Theory","comments":"Main text: 5 pages, 4 figures. Submitted to PRL on May 11, 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.EP astro-ph.GA physics.plasm-ph physics.space-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this letter, we provide the first observational evidence of substantial\ncollisionless damping (CD) modulation in the magnetohydrodynamic (MHD)\nturbulence cascade in Earth's magnetosheath using four Cluster spacecraft.\nPlasma turbulence is primarily shaped by the forcing on large scales and\ndamping on small scales. Based on an improved compressible MHD decomposition\nalgorithm, our observations demonstrate that CD enhances the anisotropy of\ncompressible MHD modes due to their strong pitch angle dependence. The\nwavenumber distributions of slow modes are more stretched perpendicular to the\nbackground magnetic field ($\\mathbf{B_0}$) under CD modulation compared to\nAlfv\\'en modes. In contrast, fast modes are subject to a more significant CD\nmodulation. Fast modes exhibit a scale-independent, slight anisotropy above the\nCD truncation scales, and their anisotropy increases as the wavenumbers fall\nbelow the CD truncation scales. As a result, CD affects the relative energy\nfractions in total compressible modes. Our findings take a significant step\nforward in comprehending the functions of CD in truncating the compressible MHD\nturbulence cascade and the consequential energy anisotropy in the wavevector\nspace.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:54:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12508","submitter":"Leonid Levitov","authors":"Zhiyu Dong, Olumakinde Ogunnaike, and Leonid Levitov","title":"Collective excitations in chiral Stoner magnets","comments":"8pgs, 2fgs","journal-ref":"Phys. Rev. Lett. 130, 206701 (2023)","doi":"10.1103/PhysRevLett.130.206701","report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We argue that spin and valley-polarized metallic phases recently observed in\ngraphene bilayers and trilayers support chiral edge modes that allow spin waves\nto propagate ballistically along system boundaries without backscattering. The\nchiral edge behavior originates from the interplay between the momentum-space\nBerry curvature in Dirac bands and the geometric phase of a spin texture in\nposition space. The edge modes are weakly confined to the edge, featuring\ndispersion which is robust and insensitive to the detailed profile of\nmagnetization at the edge. This unique character of edge modes reduces their\noverlap with edge disorder and enhances the mode lifetime. The mode propagation\ndirection reverses upon reversing valley polarization, an effect that provides\na clear testable signature of geometric interactions in isospin-polarized Dirac\nbands.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:55:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12509","submitter":"Kyle Gannon","authors":"Kyle Gannon","title":"Concerning Keisler Measures over ultraproducts","comments":"15 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As consequence of the VC theorem, any pseudo-finite measure over an NIP\nultraproduct is generically stable. We demonstrate a converse of this theorem\nand prove that any finitely approximable measure over an ultraproduct is itself\npseudo-finite (even without the NIP assumption). We also analyze the connection\nbetween the Morley product and the pseudo-finite product. In particular, we\nshow that if $\\mu$ is definable and both $\\mu$ and $\\nu$ are pseudo-finite,\nthen the Morley product of $\\mu$ and $\\nu$ agrees with the pseudo-finite\nproduct of $\\mu$ and $\\nu$. Using this observation, we construct generically\nstable idempotent measures on pseudo-finite NIP groups.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:58:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12510","submitter":"Oren Tsur","authors":"Yoav Tulpan, Oren Tsur","title":"A Deeper (Autoregressive) Approach to Non-Convergent Discourse Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Online social platforms provide a bustling arena for information-sharing and\nfor multi-party discussions. Various frameworks for dialogic discourse parsing\nwere developed and used for the processing of discussions and for predicting\nthe productivity of a dialogue. However, most of these frameworks are not\nsuitable for the analysis of contentious discussions that are commonplace in\nmany online platforms. A novel multi-label scheme for contentious dialog\nparsing was recently introduced by Zakharov et al. (2021). While the schema is\nwell developed, the computational approach they provide is both naive and\ninefficient, as a different model (architecture) using a different\nrepresentation of the input, is trained for each of the 31 tags in the\nannotation scheme. Moreover, all their models assume full knowledge of label\ncollocations and context, which is unlikely in any realistic setting. In this\nwork, we present a unified model for Non-Convergent Discourse Parsing that does\nnot require any additional input other than the previous dialog utterances. We\nfine-tuned a RoBERTa backbone, combining embeddings of the utterance, the\ncontext and the labels through GRN layers and an asymmetric loss function.\nOverall, our model achieves results comparable with SOTA, without using label\ncollocation and without training a unique architecture/model for each label.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:04:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12511","submitter":"Hang Lou","authors":"Hang Lou, Siran Li, Hao Ni","title":"PCF-GAN: generating sequential data via the characteristic function of\n  measures on the path space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generating high-fidelity time series data using generative adversarial\nnetworks (GANs) remains a challenging task, as it is difficult to capture the\ntemporal dependence of joint probability distributions induced by time-series\ndata. Towards this goal, a key step is the development of an effective\ndiscriminator to distinguish between time series distributions. We propose the\nso-called PCF-GAN, a novel GAN that incorporates the path characteristic\nfunction (PCF) as the principled representation of time series distribution\ninto the discriminator to enhance its generative performance. On the one hand,\nwe establish theoretical foundations of the PCF distance by proving its\ncharacteristicity, boundedness, differentiability with respect to generator\nparameters, and weak continuity, which ensure the stability and feasibility of\ntraining the PCF-GAN. On the other hand, we design efficient initialisation and\noptimisation schemes for PCFs to strengthen the discriminative power and\naccelerate training efficiency. To further boost the capabilities of complex\ntime series generation, we integrate the auto-encoder structure via sequential\nembedding into the PCF-GAN, which provides additional reconstruction\nfunctionality. Extensive numerical experiments on various datasets demonstrate\nthe consistently superior performance of PCF-GAN over state-of-the-art\nbaselines, in both generation and reconstruction quality. Code is available at\nhttps://github.com/DeepIntoStreams/PCF-GAN.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:05:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12512","submitter":"Subhajit Goswami","authors":"Sabyasachi Chatterjee, Partha S. Dey and Subhajit Goswami","title":"Central Limit Theorem for Gram-Schmidt Random Walk Design","comments":"35 pages. Some typo's fixed in the arxiv abstract to fit arxiv's\n  abstract requirements","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST math.PR stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We prove a central limit theorem for the Horvitz-Thompson estimator based on\nthe Gram-Schmidt Walk (GSW) design, recently developed in Harshaw et al.(2022).\nIn particular, we consider the version of the GSW design which uses randomized\npivot order, thereby answering an open question raised in the same article. We\ndeduce this under minimal and global assumptions involving only the problem\nparameters such as the (sum) potential outcome vector and the covariate matrix.\nAs an interesting consequence of our analysis we also obtain the precise\nlimiting variance of the estimator in terms of these parameters which is\nsmaller than the previously known upper bound. The main ingredients are a\nsimplified skeletal process approximating the GSW design and concentration\nphenomena for random matrices obtained from random sampling using the Stein's\nmethod for exchangeable pairs.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:06:55 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 05:28:43 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12513","submitter":"Luca-Maxim Meinhardt","authors":"Luca-Maxim Meinhardt, Jan-Henry Belz, Michael Rietzler, Enrico Rukzio","title":"Balancing the Digital and the Physical: Discussing Push and Pull Factors\n  for Digital Well-being","comments":"8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This position paper discusses the negative effects of excessive smartphone\nusage on mental health and well-being. Despite efforts to limit smartphone\nusage, users become desensitized to reminders and limitations. The paper\nproposes the use of Push & Pull Factors to contextualize intervention\nstrategies promoting digital well-being. Further, alternative metrics to\nmeasure the effectiveness of intervention strategies will be discussed.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:07:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12514","submitter":"Nicholas Cummins Dr","authors":"Judith Dineley, Ewan Carr, Faith Matcham, Johnny Downs, Richard\n  Dobson, Thomas F Quatieri, Nicholas Cummins","title":"Towards robust paralinguistic assessment for real-world mobile health\n  (mHealth) monitoring: an initial study of reverberation effects on speech","comments":"Accepted for publication at Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Speech is promising as an objective, convenient tool to monitor health\nremotely over time using mobile devices. Numerous paralinguistic features have\nbeen demonstrated to contain salient information related to an individual's\nhealth. However, mobile device specification and acoustic environments vary\nwidely, risking the reliability of the extracted features. In an initial step\ntowards quantifying these effects, we report the variability of 13 exemplar\nparalinguistic features commonly reported in the speech-health literature and\nextracted from the speech of 42 healthy volunteers recorded consecutively in\nrooms with low and high reverberation with one budget and two higher-end\nsmartphones and a condenser microphone. Our results show reverberation has a\nclear effect on several features, in particular voice quality markers. They\npoint to new research directions investigating how best to record and process\nin-the-wild speech for reliable longitudinal health state assessment.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:07:30 GMT"},{"version":"v2","created":"Wed, 31 May 2023 16:21:53 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.12515","submitter":"Louis Theran","authors":"Robert Connelly and Steven J. Gortler and Louis Theran","title":"General position stresses","comments":"24 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $G$ be a graph with $n$ vertices, and $d$ be a target dimension. In this\npaper we study the set of rank $n-d-1$ matrices that are equilibrium stress\nmatrices for at least one (unspecified) $d$-dimensional framework of $G$ in\ngeneral position. In particular, we show that this set is algebraically\nirreducible. Likewise, we show that the set of frameworks with such equilibrium\nstress matrices is irreducible. As an application, this leads to a new and\ndirect proof that every generically globally rigid graph has a generic\nframework that is universally rigid.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:09:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12516","submitter":"Yu-Xiao Liu","authors":"Yu-Qi Dong, Yu-Qiang Liu, Yu-Xiao Liu","title":"Polarization modes of gravitational waves in generalized Proca theory","comments":"26 pages, 1 figure, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we study polarization modes of gravitational waves in\ngeneralized Proca theory in the homogeneous and isotropic Minkowski background.\nThe results show that the polarizations of gravitational waves depend on the\nparameter space of this gravity theory and can be divided into quite rich cases\nby parameters. In some parameter space, it only allows two tensor modes, i.e.,\nthe $+$ and $\\times$ modes. In some parameter space, besides tensor modes, it\nalso allows one scalar mode, or two vector (vector-$x$ and vector-$y$) modes,\nor both one scalar mode and two vector modes. The scalar mode is a mixture mode\nof a breathing mode and a longitudinal mode, or just a pure breathing mode.\nInterestingly, it is found that the amplitude of the vector modes is related to\nthe speed of the tensor modes. This allows us to give the upper bound of the\namplitude of the vector modes by detecting the speed of the tensor modes.\nSpecifically, if the speed of tensor modes is strictly equal to the speed of\nlight, then the amplitude of vector modes is zero.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:10:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12517","submitter":"Shauli Ravfogel","authors":"Shauli Ravfogel, Valentina Pyatkin, Amir DN Cohen, Avshalom Manevich,\n  Yoav Goldberg","title":"Retrieving Texts based on Abstract Descriptions","comments":"A preprint; demo available at\n  https://github.com/shauli-ravfogel/AbstractSim","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we aim to connect two research areas: instruction models and\nretrieval-based models. While instruction-tuned Large Language Models (LLMs)\nexcel at extracting information from text, they are not suitable for semantic\nretrieval. Similarity search over embedding vectors allows to index and query\nvectors, but the similarity reflected in the embedding is sub-optimal for many\nuse cases. We identify the task of retrieving sentences based on abstract\ndescriptions of their content. We demonstrate the inadequacy of current text\nembeddings and propose an alternative model that significantly improves when\nused in standard nearest neighbor search. The model is trained using positive\nand negative pairs sourced through prompting an a large language model (LLM).\nWhile it is easy to source the training material from an LLM, the retrieval\ntask cannot be performed by the LLM directly. This demonstrates that data from\nLLMs can be used not only for distilling more efficient specialized models than\nthe original LLM, but also for creating new capabilities not immediately\npossible using the original model.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:14:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12518","submitter":"Shivam Mhaskar","authors":"Shivam Mhaskar, Vineet Bhat, Akshay Batheja, Sourabh Deoghare,\n  Paramveer Choudhary, Pushpak Bhattacharyya","title":"VAKTA-SETU: A Speech-to-Speech Machine Translation Service in Select\n  Indic Languages","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In this work, we present our deployment-ready Speech-to-Speech Machine\nTranslation (SSMT) system for English-Hindi, English-Marathi, and Hindi-Marathi\nlanguage pairs. We develop the SSMT system by cascading Automatic Speech\nRecognition (ASR), Disfluency Correction (DC), Machine Translation (MT), and\nText-to-Speech Synthesis (TTS) models. We discuss the challenges faced during\nthe research and development stage and the scalable deployment of the SSMT\nsystem as a publicly accessible web service. On the MT part of the pipeline\ntoo, we create a Text-to-Text Machine Translation (TTMT) service in all six\ntranslation directions involving English, Hindi, and Marathi. To mitigate data\nscarcity, we develop a LaBSE-based corpus filtering tool to select high-quality\nparallel sentences from a noisy pseudo-parallel corpus for training the TTMT\nsystem. All the data used for training the SSMT and TTMT systems and the best\nmodels are being made publicly available. Users of our system are (a) Govt. of\nIndia in the context of its new education policy (NEP), (b) tourists who\ncriss-cross the multilingual landscape of India, (c) Indian Judiciary where a\nleading cause of the pendency of cases (to the order of 10 million as on date)\nis the translation of case papers, (d) farmers who need weather and price\ninformation and so on. We also share the feedback received from various\nstakeholders when our SSMT and TTMT systems were demonstrated in large public\nevents.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:23:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12519","submitter":"Yuang Qi","authors":"Xiao Yu, Yuang Qi, Kejiang Chen, Guoqiang Chen, Xi Yang, Pengyuan Zhu,\n  Weiming Zhang and Nenghai Yu","title":"GPT Paternity Test: GPT Generated Text Detection with GPT Genetic\n  Inheritance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large Language Models (LLMs) can generate texts that carry the risk of\nvarious misuses, including plagiarism, planting fake reviews on e-commerce\nplatforms, or creating fake social media postings that can sway election\nresults. Detecting whether a text is machine-generated has thus become\nincreasingly important. While machine-learning-based detection strategies\nexhibit superior performance, they often lack generalizability, limiting their\npracticality. In this work, we introduce GPT Paternity Test (GPT-Pat), which\nreliably detects machine-generated text across varied datasets. Given a text\nunder scrutiny, we leverage ChatGPT to generate a corresponding question and\nprovide a re-answer to the question. By comparing the similarity between the\noriginal text and the generated re-answered text, it can be determined whether\nthe text is machine-generated. GPT-Pat consists of a Siamese network to compute\nthe similarity between the original text and the generated re-answered text and\na binary classifier. Our method achieved an average accuracy of 94.57% on four\ngeneralization test sets, surpassing the state-of-the-art RoBERTa-based method\nby 12.34%. The accuracy drop of our method is only about half of that of the\nRoBERTa-based method when it is attacked by re-translation and polishing.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:26:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12520","submitter":"Jordi Armengol-Estap\\'e","authors":"Jordi Armengol-Estap\\'e, Jackson Woodruff, Chris Cummins, Michael F.P.\n  O'Boyle","title":"SLaDe: A Portable Small Language Model Decompiler for Optimized\n  Assembler","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Decompilation is a well-studied area with numerous high-quality tools\navailable. These are frequently used for security tasks and to port legacy\ncode. However, they regularly generate difficult-to-read programs and require a\nlarge amount of engineering effort to support new programming languages and\nISAs. Recent interest in neural approaches has produced portable tools that\ngenerate readable code. However, to-date such techniques are usually restricted\nto synthetic programs without optimization, and no models have evaluated their\nportability. Furthermore, while the code generated may be more readable, it is\nusually incorrect. This paper presents SLaDe, a Small Language model Decompiler\nbased on a sequence-to-sequence transformer trained over real-world code. We\ndevelop a novel tokenizer and exploit no-dropout training to produce\nhigh-quality code. We utilize type-inference to generate programs that are more\nreadable and accurate than standard analytic and recent neural approaches.\nUnlike standard approaches, SLaDe can infer out-of-context types and unlike\nneural approaches, it generates correct code. We evaluate SLaDe on over 4,000\nfunctions from AnghaBench on two ISAs and at two optimizations levels. SLaDe is\nup to 6 times more accurate than Ghidra, a state-of-the-art,\nindustrial-strength decompiler and up to 4 times more accurate than the large\nlanguage model ChatGPT and generates significantly more readable code than\nboth.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:31:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12521","submitter":"Matthias Ludewig","authors":"Matthias Ludewig","title":"The spinor bundle on loop space","comments":"86 pages; Some minor corrections; added 2 figures; divested material\n  on super bundle gerbes to Appendix C","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG math.AT math.OA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give a construction of the spinor bundle of the loop space of a string\nmanifold together with its fusion product, inspired by ideas from Stolz and\nTeichner. The spinor bundle is a super bimodule bundle for a bundle of Clifford\nvon Neumann algebras over the free path space, and the fusion product is\ndefined using Connes fusion of such bimodules. As the main result, we prove\nthat a spinor bundle with fusion product on a manifold X exists if and only X\nis string.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:39:12 GMT"},{"version":"v2","created":"Wed, 31 May 2023 21:27:05 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.12522","submitter":"Lucas David","authors":"Lucas David, Helio Pedrini, and Zanoni Dias","title":"P-NOC: Adversarial CAM Generation for Weakly Supervised Semantic\n  Segmentation","comments":"18 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  To mitigate the necessity for large amounts of supervised segmentation\nannotation sets, multiple Weakly Supervised Semantic Segmentation (WSSS)\nstrategies have been devised. These will often rely on advanced data and model\nregularization strategies to instigate the development of useful properties\n(e.g., prediction completeness and fidelity to semantic boundaries) in\nsegmentation priors, notwithstanding the lack of annotated information. In this\nwork, we first create a strong baseline by analyzing complementary WSSS\ntechniques and regularizing strategies, considering their strengths and\nlimitations. We then propose a new Class-specific Adversarial Erasing strategy,\ncomprising two adversarial CAM generating networks being gradually refined to\nproduce robust semantic segmentation proposals. Empirical results suggest that\nour approach induces substantial improvement in the effectiveness of the\nbaseline, resulting in a noticeable improvement over both Pascal VOC 2012 and\nMS COCO 2014 datasets.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:46:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12523","submitter":"Zinat Behdad","authors":"Zinat Behdad, \\\"Ozlem Tu\\u{g}fe Demir, Ki Won Sung, Emil Bj\\\"ornson,\n  and Cicek Cavdar","title":"Multi-Static Target Detection and Power Allocation for Integrated\n  Sensing and Communication in Cell-Free Massive MIMO","comments":"30 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies an integrated sensing and communication (ISAC) system for\nsingle-target detection in a cloud radio access network architecture. The\nsystem considers downlink communication and multi-static sensing approach,\nwhere ISAC transmit access points (APs) jointly serve the user equipments (UEs)\nand optionally steer a beam toward the target. A centralized operation of\ncell-free massive MIMO (multiple-input multiple-output) is considered for\ncommunication and sensing purposes. A maximum a posteriori ratio test detector\nis developed to detect the target in the presence of clutter, so-called\ntarget-free signals. Moreover, a power allocation algorithm is proposed to\nmaximize the sensing signal-to-interference-plus-noise ratio (SINR) while\nensuring a minimum communication SINR value for each UE and meeting per-AP\npower constraints. Two ISAC setups are studied: i) using only existing\ncommunication beams for sensing and ii) using additional sensing beams. The\nproposed algorithm's efficiency is investigated in both realistic and\nidealistic scenarios, corresponding to the presence and absence of the\ntarget-free channels, respectively. Although detection probability degrades in\nthe presence of target-free channels that act as interference, the proposed\nalgorithm significantly outperforms the interference-unaware benchmark by\nexploiting the statistics of the clutter. It has also been shown that the\nproposed algorithm outperforms the fully communication-centric algorithm, both\nin the presence and absence of clutter. Moreover, using an additional sensing\nbeam improves the detection performance for a target with lower radar\ncross-section variances compared to the case without sensing beams.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:50:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12524","submitter":"Wenhu Chen","authors":"Wenhu Chen, Ming Yin, Max Ku, Pan Lu, Yixin Wan, Xueguang Ma, Jianyu\n  Xu, Xinyi Wang, Tony Xia","title":"TheoremQA: A Theorem-driven Question Answering dataset","comments":"Work in Progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent LLMs like GPT-4 and PaLM-2 have made tremendous progress in\nsolving fundamental math problems like GSM8K by achieving over 90% accuracy.\nHowever, their capabilities to solve more challenging math problems which\nrequire domain-specific knowledge (i.e. theorem) have yet to be investigated.\nIn this paper, we introduce TheoremQA, the first theorem-driven\nquestion-answering dataset designed to evaluate AI models' capabilities to\napply theorems to solve challenging science problems. TheoremQA is curated by\ndomain experts containing 800 high-quality questions covering 350 theorems\n(e.g. Taylor's theorem, Lagrange's theorem, Huffman coding, Quantum Theorem,\nElasticity Theorem, etc) from Math, Physics, EE&CS, and Finance. We evaluate a\nwide spectrum of 16 large language and code models with different prompting\nstrategies like Chain-of-Thoughts and Program-of-Thoughts. We found that\nGPT-4's capabilities to solve these problems are unparalleled, achieving an\naccuracy of 51% with Program-of-Thoughts Prompting. All the existing\nopen-sourced models are below 15%, barely surpassing the random-guess baseline.\nGiven the diversity and broad coverage of TheoremQA, we believe it can be used\nas a better benchmark to evaluate LLMs' capabilities to solve challenging\nscience problems. The data and code are released in\nhttps://github.com/wenhuchen/TheoremQA.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:51:35 GMT"},{"version":"v2","created":"Tue, 23 May 2023 22:35:20 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12525","submitter":"Xiaolong Yang","authors":"Xiaolong Yang, Su Yao, Luigi C. Gallo, Jun Yang, Luis C. Ho, Minfeng\n  Gu, Willem A. Baan, Jiri Svoboda, Ran Wang, Xiang Liu, Xiaoyu Hong, Xue-Bing\n  Wu, Wei Zhao","title":"Unveiling the small-scale jets in the rapidly growing supermassive black\n  hole IZw1","comments":"19 pages, 8 figures and 4 tables, submitted to ApJ. 2nd round referee\n  report received. comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accretion of black holes at near-Eddington or super-Eddington rates is the\nmost powerful episode that drives black hole growth, and it may work in several\ntypes of objects. However, the physics of accretion and jet-disc coupling in\nsuch a state remains unclear, mainly because the associated jets are not easily\ndetectable due to the extremely weak emission or possibly episodic nature of\nthe jets. Only a few near/super-Eddington systems have demonstrated radio\nactivity, and it remains unclear whether there is a jet and what are their\nproperties, in super-Eddington active galactic nuclei (AGNs) (and ultraluminous\nX-ray sources). The deficit is mainly due to the complex radio mixing between\nthe origins of jets and others, such as star formation activity, photo-ionized\ngas, accretion disk wind, and coronal activity. In this work, we conducted\nhigh-resolution very long baseline interferometry (VLBI) observations to\nexplore the jets in the highly accreting narrow-line Seyfert I system IZw1. Our\nobservations successfully revealed small-scale jets (with a linear size of\n$\\sim45$ parsec) at both 1.5 and 5 GHz, based on the high radio brightness\ntemperature, radio morphology, and spectral index distribution. Interestingly,\nthe lack of a flat-spectrum radio core and knotty jet structures imply episodic\nejections in IZw1, which resemble the ejection process in Galactic X-ray\nbinaries that are in the canonical very high state. The high accretion rates\nand jet properties in the AGN IZw1 may support the AGN/XRB analogy in the\nextreme state.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:52:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12526","submitter":"Xiaolong Yang","authors":"Xiaolong Yang, Ziwei Ou","title":"The core starbursts of the galaxy NGC 3628: Radio very long baseline\n  interferometry and X-ray studies","comments":"15 pages, 4 Tables and 6 Figures, accepted for publication in ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.HE astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present radio very long baseline interferometry (VLBI) and X-ray studies\nof the starburst galaxy NGC 3628. The VLBI observation at 1.5 GHz reveals seven\ncompact (0.7$-$7 parsec) radio sources in the central $\\sim$250 parsec region\nof NGC 3628. Based on their morphology, high radio brightness temperatures\n($10^5-10^7$ K), and steep radio spectra, none of these seven sources can be\nassociated with active galactic nuclei (AGNs); instead, they can be identified\nas supernova remnants (SNRs), with three of them appearing consistent with\npartial shells. Notably, one of them (W2) is likely a nascent radio supernova\nand appears to be consistent with the star formation rate of NGC 3628 when\nassuming a canonical initial mass function. The VLBI observation provides the\nfirst precise measurement of the diameter of the radio sources in NGC 3628,\nwhich allow us to fit a well-constrained radio surface brightness - diameter\n($\\Sigma-D$) correlation by including the detected SNRs. Furthermore, future\nVLBI observations can be conducted to measure the expansion velocity of the\ndetected SNRs. In addition to our radio VLBI study, we analyze Chandra and\nXMM-Newton spectra of NGC 3628. The spectral fitting indicates that the SNR\nactivities could well account for the observed X-ray emissions. Along with the\nChandra X-ray image, it further reveals that the X-ray emission is likely\nmaintained by the galactic-scale outflow triggered by SN activities. These\nresults provide strong evidence that SN-triggered activities play a critical\nrole in generating both radio and X-ray emissions in NGC 3628 and further\nsuggest that the galaxy NGC 3628 is in an early stage of starbursts.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:52:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12527","submitter":"Xiaolong Yang","authors":"Xiaolong Yang, Jun Yang","title":"Intermediate-Mass Black Holes: The Essential Population to Explore the\n  Unified Model for Accretion and Ejection Processes","comments":"16 pages, 3 figures and 1 Table, accepted for publication in Galaxies","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study radio and X-ray emissions from IMBHs and explore the unified model\nfor accretion and ejection processes. The radio band survey of IMBH (candidate)\nhosted galaxies indicates that only a small fraction ($\\sim$0.6\\%) of them are\nradio-band active. In addition, very long baseline interferometry observations\nreveal parsec-scale radio emission of IMBHs, further resulting in a lower\nfraction of actively ejecting objects (radio emission is produced by IMBHs\nother than hosts), which is consistent with a long quiescent state in the\nevolution cycle of IMBHs. Most (75\\%, i.e., 3 out of 4 samples according to a\nrecent mini-survey) of the radio-emitting IMBHs are associated with radio\nrelics and there is also evidence of dual radio blobs from episodic ejecting\nphases. Taking the radio emission and the corresponding core X-ray emission of\nIMBH, we confirm a universal fundamental plane relation (FMP) of black hole\nactivity. Furthermore, state transitions can be inferred by comparing a few\ncases in XRBs and IMBHs in FMP, i.e., both radio luminosity and emission\nregions evolve along these state transitions. These signatures and evidence\nsuggest an analogy among all kinds of accretion systems which span from stellar\nmass to supermassive black holes, hinting at unified accretion and ejection\nphysics. To validate the unified model, we explore the correlation between the\nscale of outflows (corresponding to ejection powers) and the masses of central\nengines; it shows that the largest scale of outflows $\\hat{LS}_\\mathrm{out}$\nfollows a power-law correlation with the masses of accretors $M_\\mathrm{core}$,\ni.e., $\\log{\\hat{LS}_\\mathrm{out}} = (0.73\\pm0.01)\\log{M_\\mathrm{core}} -\n(3.34\\pm0.10)$. In conclusion, this work provides evidence to support the claim\nthat the ejection (and accretion) process behaves as scale-invariant and their\npower is regulated by the masses of accretors.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:52:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12528","submitter":"Moksh Shukla","authors":"Moksh Shukla, Nitik Jain, Shubham Gupta","title":"IR Models and the COVID-19 Pandemic: A Comparative Study of Performance\n  and Challenges","comments":"7 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This research study investigates the efficiency of different information\nretrieval (IR) systems in accessing relevant information from the scientific\nliterature during the COVID-19 pandemic. The study applies the TREC framework\nto the COVID-19 Open Research Dataset (CORD-19) and evaluates BM25, Contriever,\nand Bag of Embeddings IR frameworks. The objective is to build a test\ncollection for search engines that tackle the complex information landscape\nduring a pandemic. The study uses the CORD-19 dataset to train and evaluate the\nIR models and compares the results to those manually labeled in the TREC-COVID\nIR Challenge. The results indicate that advanced IR models like BERT and\nContriever better retrieve relevant information during a pandemic. However, the\nstudy also highlights the challenges in processing large datasets and the need\nfor strategies to focus on abstracts or summaries. Overall, the research\nhighlights the importance of effectively tailored IR systems in dealing with\ninformation overload during crises like COVID-19 and can guide future research\nand development in this field.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:58:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12529","submitter":"Yukun Huang","authors":"Yukun Huang, Jianan Wang, Ailing Zeng, He Cao, Xianbiao Qi, Yukai Shi,\n  Zheng-Jun Zha, Lei Zhang","title":"DreamWaltz: Make a Scene with Complex 3D Animatable Avatars","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present DreamWaltz, a novel framework for generating and animating complex\navatars given text guidance and parametric human body prior. While recent\nmethods have shown encouraging results in the text-to-3D generation of common\nobjects, creating high-quality and animatable 3D avatars remains challenging.\nTo create high-quality 3D avatars, DreamWaltz proposes 3D-consistent\nocclusion-aware Score Distillation Sampling (SDS) to optimize implicit neural\nrepresentations with canonical poses. It provides view-aligned supervision via\n3D-aware skeleton conditioning and enables complex avatar generation without\nartifacts and multiple faces. For animation, our method learns an animatable\nand generalizable avatar representation which could map arbitrary poses to the\ncanonical pose representation. Extensive evaluations demonstrate that\nDreamWaltz is an effective and robust approach for creating 3D avatars that can\ntake on complex shapes and appearances as well as novel poses for animation.\nThe proposed framework further enables the creation of complex scenes with\ndiverse compositions, including avatar-avatar, avatar-object and avatar-scene\ninteractions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 17:59:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12530","submitter":"Jialu Li","authors":"Jialu Li, Mark Hasegawa-Johnson, Nancy L. McElwain","title":"Towards Robust Family-Infant Audio Analysis Based on Unsupervised\n  Pretraining of Wav2vec 2.0 on Large-Scale Unlabeled Family Audio","comments":"Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  To perform automatic family audio analysis, past studies have collected\nrecordings using phone, video, or audio-only recording devices like LENA,\ninvestigated supervised learning methods, and used or fine-tuned\ngeneral-purpose embeddings learned from large pretrained models. In this study,\nwe advance the audio component of a new infant wearable multi-modal device\ncalled LittleBeats (LB) by learning family audio representation via wav2vec 2.0\n(W2V2) pertaining. We show given a limited number of labeled LB home\nrecordings, W2V2 pretrained using 1k-hour of unlabeled home recordings\noutperforms oracle W2V2 pretrained on 52k-hour unlabeled audio in terms of\nparent/infant speaker diarization (SD) and vocalization classifications (VC) at\nhome. Extra relevant external unlabeled and labeled data further benefit W2V2\npretraining and fine-tuning. With SpecAug and environmental speech corruptions,\nwe obtain 12% relative gain on SD and moderate boost on VC. Code and model\nweights are available.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:00:16 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 01:39:24 GMT"}],"update_date":"2023-06-02"}
{"id":"2305.12531","submitter":"Deepak Pachattu","authors":"Deepak Pachattu","title":"Singlet cross section and the tensor interaction in\n  $\\overline{\\mathrm{p}} \\mathrm{p} \\rightarrow \\bar{\\Lambda} \\Lambda$","comments":"2 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th hep-ex nucl-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this short paper, we demonstrate using irreducible tensorial techniques\nand in a model-independent way, why tensor interactions and also\norbital-angular momentum-changing vector interactions are absent in the singlet\nunpolarized differential cross section for the reaction $\\overline{\\mathrm{p}}\n\\mathrm{p} \\rightarrow \\bar{\\Lambda} \\Lambda$.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:05:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12532","submitter":"Sebastian Joseph","authors":"Sebastian Joseph, Kathryn Kazanas, Keziah Reina, Vishnesh J.\n  Ramanathan, Wei Xu, Byron C. Wallace, and Junyi Jessy Li","title":"Multilingual Simplification of Medical Texts","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automated text simplification aims to produce simple versions of complex\ntexts. This task is especially useful in the medical domain, where the latest\nmedical findings are typically communicated via complex and technical articles.\nThis creates barriers for laypeople seeking access to up-to-date medical\nfindings, consequently impeding progress on health literacy. Most existing work\non medical text simplification has focused on monolingual settings, with the\nresult that such evidence would be available only in just one language (most\noften, English). This work addresses this limitation via multilingual\nsimplification, i.e., directly simplifying complex texts into simplified texts\nin multiple languages. We introduce MultiCochrane, the first sentence-aligned\nmultilingual text simplification dataset for the medical domain in four\nlanguages: English, Spanish, French, and Farsi. We evaluate fine-tuned and\nzero-shot models across these languages, with extensive human assessments and\nanalyses. Although models can now generate viable simplified texts, we identify\noutstanding challenges that this dataset might be used to address.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:25:07 GMT"},{"version":"v2","created":"Tue, 23 May 2023 03:57:41 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12533","submitter":"Ranjan Kumar Das","authors":"Ranjan Kumar Das and Harish K. Pillai","title":"Unified framework for Fiedler-like strong linearizations of polynomial\n  and rational matrices","comments":"arXiv admin note: text overlap with arXiv:2008.00427","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Linearization is a widely used method for solving polynomial eigenvalue\nproblems (PEPs) and rational eigenvalue problem (REPs) in which the PEP/REP is\ntransformed to a generalized eigenproblem and then solve this generalized\neigenproblem with algorithms available in the literature. Fiedler-like pencils\n(Fiedler pencils (FPs), generalized Fiedler pencils (GFPs), Fiedler pencils\nwith repetition (FPRs) and generalized Fiedler pencils with repetition (GFPRs))\nare well known classes of strong linearizations. GFPs are an intriguing family\nof linearizations, and GF pencils are the fundamental building blocks of FPRs\nand GFPRs. As a result, FPRs and GFPRs have distinctive features and they\nprovide structure-preserving linearizations for structured matrix polynomials.\nBut GFPRs do not use the full potential of GF pencils. Indeed, not all the GFPs\nare FPRs or GFPRs, and vice versa. The main aim of this paper is two-fold.\nFirst, to build a unified framework for all the Fiedler-like pencils FPs, GFPs,\nFPRs and GFPRs. To that end, we construct a new family of strong linearizations\n(named as EGFPs) of a matrix polynomial $P(\\lam)$ that subsumes all the\nFiedler-like linearizations. A salient feature of the EGFPs family is that it\nallows the construction of structured preserving banded linearizations with low\nbandwidth for structured (symmetric, Hermitian, palindromic) matrix polynomial.\nLow bandwidth structured linearizations may be useful for numerical\ncomputations. Second, to utilize EGFPs directly to form a family of Rosenbrock\nstrong linearizations of an $n \\times n$ rational matrix $G(\\lam)$ associated\nwith a realization. We describe the formulas for the construction of low\nbandwidth linearizations for $P(\\lam)$ and $G(\\lam)$. We show that the\neigenvectors, minimal bases/indices of $P(\\lam)$ and $G(\\lam)$ can be easily\nrecovered from those of the linearizations of $P(\\lam)$ and $G(\\lam)$.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:26:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12534","submitter":"Piyush Jha","authors":"Piyush Jha, Joseph Scott, Jaya Sriram Ganeshna, Mudit Singh, Vijay\n  Ganesh","title":"BertRLFuzzer: A BERT and Reinforcement Learning based Fuzzer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.CR cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a novel tool BertRLFuzzer, a BERT and Reinforcement Learning (RL)\nbased fuzzer aimed at finding security vulnerabilities. BertRLFuzzer works as\nfollows: given a list of seed inputs, the fuzzer performs grammar-adhering and\nattack-provoking mutation operations on them to generate candidate attack\nvectors. The key insight of BertRLFuzzer is the combined use of two machine\nlearning concepts. The first one is the use of semi-supervised learning with\nlanguage models (e.g., BERT) that enables BertRLFuzzer to learn (relevant\nfragments of) the grammar of a victim application as well as attack patterns,\nwithout requiring the user to specify it explicitly. The second one is the use\nof RL with BERT model as an agent to guide the fuzzer to efficiently learn\ngrammar-adhering and attack-provoking mutation operators. The RL-guided\nfeedback loop enables BertRLFuzzer to automatically search the space of attack\nvectors to exploit the weaknesses of the given victim application without the\nneed to create labeled training data. Furthermore, these two features together\nenable BertRLFuzzer to be extensible, i.e., the user can extend BertRLFuzzer to\na variety of victim applications and attack vectors automatically (i.e.,\nwithout explicitly modifying the fuzzer or providing a grammar).\n  In order to establish the efficacy of BertRLFuzzer we compare it against a\ntotal of 13 black box and white box fuzzers over a benchmark of 9 victim\nwebsites. We observed a significant improvement in terms of time to first\nattack (54% less than the nearest competing tool), time to find all\nvulnerabilities (40-60% less than the nearest competing tool), and attack rate\n(4.4% more attack vectors generated than the nearest competing tool). Our\nexperiments show that the combination of the BERT model and RL-based learning\nmakes BertRLFuzzer an effective, adaptive, easy-to-use, automatic, and\nextensible fuzzer.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:26:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12535","submitter":"Javier Ferrando","authors":"Javier Ferrando, Gerard I. G\\'allego, Ioannis Tsiamas, Marta R.\n  Costa-juss\\`a","title":"Explaining How Transformers Use Context to Build Predictions","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Language Generation Models produce words based on the previous context.\nAlthough existing methods offer input attributions as explanations for a\nmodel's prediction, it is still unclear how prior words affect the model's\ndecision throughout the layers. In this work, we leverage recent advances in\nexplainability of the Transformer and present a procedure to analyze models for\nlanguage generation. Using contrastive examples, we compare the alignment of\nour explanations with evidence of the linguistic phenomena, and show that our\nmethod consistently aligns better than gradient-based and perturbation-based\nbaselines. Then, we investigate the role of MLPs inside the Transformer and\nshow that they learn features that help the model predict words that are\ngrammatically acceptable. Lastly, we apply our method to Neural Machine\nTranslation models, and demonstrate that they generate human-like source-target\nalignments for building predictions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:29:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12536","submitter":"Wayne de Paula","authors":"A. Castro, W. de Paula, E. Ydrefors, T. Frederico, G. Salme","title":"Exploring the $0^-$ bound state with dressed quarks in Minkowski space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-th nucl-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Bethe-Salpeter equation for a pseudoscalar bound-system, with i) a ladder\nkernel with massive gluons, ii) dynamically-dressed quark mass function and\niii) an extended quark-gluon vertex, is solved in Minkowski space by using the\nNakanishi integral representation of the Bethe-Salpeter amplitude. The quark\ndressing is implemented through a phenomenological ansatz, which was tuned by\nlattice QCD calculations of the quark running mass. The latter were also used\nfor assigning the range of the gluon mass and the parameter featuring the\nextended color density. This framework allows to investigate the gluon dynamics\nthat manifest itself in the quark dressing, quark-gluon vertex and the binding,\ndirectly in the physical space. We present the first results for low-density\npseudoscalar systems in order to elucidate the onset of the interplay between\nthe above mentioned gluonic phenomena, and we discuss both static and dynamical\nquantities, like valence longitudinal and transverse distributions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:38:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12537","submitter":"Larry Liebovitch","authors":"Larry S. Liebovitch (1 and 2), William Powers (1), Lin Shi (1),\n  Allegra Chen-Carrel (3), Philippe Loustaunau (4), Peter T. Coleman (2) ((1)\n  Queens College City University of New York, (2) Columbia University, (3)\n  University of San Francisco, (4) Vista Consulting)","title":"Word differences in news media of lower and higher peace countries\n  revealed by natural language processing and machine learning","comments":"21 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Language is both a cause and a consequence of the social processes that lead\nto conflict or peace. Hate speech can mobilize violence and destruction. What\nare the characteristics of peace speech that reflect and support the social\nprocesses that maintain peace? This study used existing peace indices, machine\nlearning, and on-line, news media sources to identify the words most associated\nwith lower-peace versus higher-peace countries. As each peace index measures\ndifferent social properties, there is little consensus on the numerical values\nof these indices. There is however greater consensus with these indices for the\ncountries that are at the extremes of lower-peace and higher-peace. Therefore,\na data driven approach was used to find the words most important in\ndistinguishing lower-peace and higher-peace countries. Rather than assuming a\ntheoretical framework that predicts which words are more likely in lower-peace\nand higher-peace countries, and then searching for those words in news media,\nin this study, natural language processing and machine learning were used to\nidentify the words that most accurately classified a country as lower-peace or\nhigher-peace. Once the machine learning model was trained on the word\nfrequencies from the extreme lower-peace and higher-peace countries, that model\nwas also used to compute a quantitative peace index for these and other\nintermediate-peace countries. The model successfully yielded a quantitative\npeace index for intermediate-peace countries that was in between that of the\nlower-peace and higher-peace, even though they were not in the training set.\nThis study demonstrates how natural language processing and machine learning\ncan help to generate new quantitative measures of social systems, which in this\nstudy, were linguistic differences resulting in a quantitative index of peace\nfor countries at different levels of peacefulness.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:43:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12538","submitter":"Volkan Bak{\\i}\\c{s} PhD.","authors":"Zeki Eker, Volkan Bakis","title":"Testing Multiband (G, GBP, GRP, B, V and TESS) Standard Bolometric\n  Corrections by Recovering Luminosity and Radii of 341 Host Stars","comments":"11 pages, 9 figures, a total of 6 tables, 5 online only tables","journal-ref":null,"doi":"10.1093/mnras/stad1563","report-no":null,"categories":"astro-ph.SR astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Main-sequence bolometric corrections (BC) and a standard BC-Teff relation are\nproduced for TESS wavelengths using published physical parameters and light\nratios from SED models of 209 detached double-lined eclipsing binaries. This\nand previous five-band (Johnson B, V, Gaia G, GBP, GRP) standard BC-Teff\nrelations are tested by recovering luminosity (L) of the most accurate 341\nsingle host stars (281 MS, 40 subgiants, 19 giants and one PMS). The recovered\nL of photometry is compared to L from published R and Teff. A very high\ncorrelation ($R^2$ = 0.9983) is achieved for this mixed sample. Error\nhistograms of recovered and calculated L show peaks at 2 and 4 per cent\nrespectively. The recovered L and the published Teff} were then used in $L = 4\n\\pi R^2 \\sigma Teff^4$ to predict the standard R of the host stars. Comparison\nbetween the predicted and published R of all luminosity classes are found\nsuccessful with a negligible offset associated with the giants and subgiants.\nThe peak of the predicted R errors is found at 2 per cent, which is equivalent\nto the peak of the published R errors. Thus, a main-sequence BC-Teff relation\ncould be used in predicting both L and R of a single star at any luminosity\nclass, but this does not mean BC-Teff relations of all luminosity classes are\nthe same because luminosity information could be more constrained by star's\napparent magnitude $\\xi$ than its BC since $m_{Bol} = \\xi + BC_\\xi$.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:45:48 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.12539","submitter":"Peyman Alipour","authors":"Peyman Alipour, Ali Foroush Bastani","title":"Value-at-Risk-Based Portfolio Insurance: Performance Evaluation and\n  Benchmarking Against CPPI in a Markov-Modulated Regime-Switching Market","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.CP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Designing dynamic portfolio insurance strategies under market conditions\nswitching between two or more regimes is a challenging task in financial\neconomics. Recently, a promising approach employing the value-at-risk (VaR)\nmeasure to assign weights to risky and riskless assets has been proposed in\n[Jiang C., Ma Y. and An Y. \"The effectiveness of the VaR-based portfolio\ninsurance strategy: An empirical analysis\" , International Review of Financial\nAnalysis 18(4) (2009): 185-197]. In their study, the risky asset follows a\ngeometric Brownian motion with constant drift and diffusion coefficients. In\nthis paper, we first extend their idea to a regime-switching framework in which\nthe expected return of the risky asset and its volatility depend on an\nunobservable Markovian term which describes the cyclical nature of asset\nreturns in modern financial markets. We then analyze and compare the resulting\nVaR-based portfolio insurance (VBPI) strategy with the well-known constant\nproportion portfolio insurance (CPPI) strategy. In this respect, we employ a\nvariety of performance evaluation criteria such as Sharpe, Omega and Kappa\nratios to compare the two methods. Our results indicate that the CPPI strategy\nhas a better risk-return tradeoff in most of the scenarios analyzed and\nmaintains a relatively stable return profile for the resulting portfolio at the\nmaturity.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:48:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12540","submitter":"Subrahmanya Pavankumar Dubagunta","authors":"Lokesh Bansal, S. Pavankumar Dubagunta, Malolan Chetlur, Pushpak\n  Jagtap, Aravind Ganapathiraju","title":"On the Efficacy and Noise-Robustness of Jointly Learned Speech Emotion\n  and Automatic Speech Recognition","comments":"accepted to be part of INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  New-age conversational agent systems perform both speech emotion recognition\n(SER) and automatic speech recognition (ASR) using two separate and often\nindependent approaches for real-world application in noisy environments. In\nthis paper, we investigate a joint ASR-SER multitask learning approach in a\nlow-resource setting and show that improvements are observed not only in SER,\nbut also in ASR. We also investigate the robustness of such jointly trained\nmodels to the presence of background noise, babble, and music. Experimental\nresults on the IEMOCAP dataset show that joint learning can improve ASR word\nerror rate (WER) and SER classification accuracy by 10.7% and 2.3% respectively\nin clean scenarios. In noisy scenarios, results on data augmented with MUSAN\nshow that the joint approach outperforms the independent ASR and SER approaches\nacross many noisy conditions. Overall, the joint ASR-SER approach yielded more\nnoise-resistant models than the independent ASR and SER approaches.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:52:21 GMT"},{"version":"v2","created":"Thu, 25 May 2023 19:33:54 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12541","submitter":"Robert Black","authors":"Erfan Fatehi, Manish Thadani, Gabriel Birsan, Robert W Black","title":"A Critical Evaluation of a Self-Driving Laboratory for the Optimization\n  of Electrodeposited Earth-Abundant Mixed-Metal Oxide Catalysts for the Oxygen\n  Evolution Reaction (OER)","comments":"46 pages, 8 main body figures, 11 supporting information figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.app-ph cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This work highlights the potential of earth-abundant mixed-metal oxide\ncatalysts for the acid-based oxygen evolution reaction. These catalysts offer\nnumerous combinations of metal-centre compositions, which can enhance catalytic\nactivity and stability compared to precious-metal-based catalysts commonly used\ntoday. Despite substantial research in this field, there is a need for new\nmethods and approaches to accelerate the exploration of these materials. In\nthis study, we present a comprehensive approach to designing, developing, and\nimplementing a self-driving laboratory to optimize the electrodeposition\nsynthesis of amorphous mixed-metal oxide catalysts for the acidic oxygen\nevolution reaction. We particularly emphasize the development of methodologies\nto address experimental variability. We investigate crucial parameters and\nconsiderations when transitioning from manual bench-top synthesis and\nevaluation to automation and machine learning guided optimization. We address\nboth experimental and optimization algorithm considerations in the presence of\nexperimental variability. To illustrate our approach, we demonstrate the\noptimization of CoFeMnPbOx electrodeposited catalyst materials through multiple\ncampaigns. Our results highlight considerations for optimizing overpotential\nand stability based on the outcomes of our experiments.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:52:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12542","submitter":"Zachary Yang","authors":"Zachary Yang, Yasmine Maricar, MohammadReza Davari, Nicolas\n  Grenon-Godbout, Reihaneh Rabbany","title":"ToxBuster: In-game Chat Toxicity Buster with BERT","comments":"11 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.CY","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Detecting toxicity in online spaces is challenging and an ever more pressing\nproblem given the increase in social media and gaming consumption. We introduce\nToxBuster, a simple and scalable model trained on a relatively large dataset of\n194k lines of game chat from Rainbow Six Siege and For Honor, carefully\nannotated for different kinds of toxicity. Compared to the existing\nstate-of-the-art, ToxBuster achieves 82.95% (+7) in precision and 83.56% (+57)\nin recall. This improvement is obtained by leveraging past chat history and\nmetadata. We also study the implication towards real-time and post-game\nmoderation as well as the model transferability from one game to another.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:53:26 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12543","submitter":"Ibrahim Ahmed","authors":"Ibrahim Ahmed and Marcos Quinones-Grueiro and Gautam Biswas","title":"A Reinforcement Learning Approach for Robust Supervisory Control of UAVs\n  Under Disturbances","comments":"In review (2023-05-16)","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.LG cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work, we present an approach to supervisory reinforcement learning\ncontrol for unmanned aerial vehicles (UAVs). UAVs are dynamic systems where\ncontrol decisions in response to disturbances in the environment have to be\nmade in the order of milliseconds. We formulate a supervisory control\narchitecture that interleaves with extant embedded control and demonstrates\nrobustness to environmental disturbances in the form of adverse wind\nconditions. We run case studies with a Tarot T-18 Octorotor to demonstrate the\neffectiveness of our approach and compare it against a classic cascade control\narchitecture used in most vehicles. While the results show the performance\ndifference is marginal for nominal operations, substantial performance\nimprovement is obtained with the supervisory RL approach under unseen wind\nconditions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:00:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12544","submitter":"Rada Mihalcea","authors":"Oana Ignat, Zhijing Jin, Artem Abzaliev, Laura Biester, Santiago\n  Castro, Naihao Deng, Xinyi Gao, Aylin Gunal, Jacky He, Ashkan Kazemi,\n  Muhammad Khalifa, Namho Koh, Andrew Lee, Siyang Liu, Do June Min, Shinka\n  Mori, Joan Nwatu, Veronica Perez-Rosas, Siqi Shen, Zekun Wang, Winston Wu,\n  Rada Mihalcea","title":"A PhD Student's Perspective on Research in NLP in the Era of Very Large\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent progress in large language models has enabled the deployment of many\ngenerative NLP applications. At the same time, it has also led to a misleading\npublic discourse that ``it's all been solved.'' Not surprisingly, this has in\nturn made many NLP researchers -- especially those at the beginning of their\ncareer -- wonder about what NLP research area they should focus on. This\ndocument is a compilation of NLP research directions that are rich for\nexploration, reflecting the views of a diverse group of PhD students in an\nacademic research lab. While we identify many research areas, many others\nexist; we do not cover those areas that are currently addressed by LLMs but\nwhere LLMs lag behind in performance, or those focused on LLM development. We\nwelcome suggestions for other research directions to include:\nhttps://bit.ly/nlp-era-llm\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:06:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12545","submitter":"Saeed Noori Gashti","authors":"Jafar Sadeghi, Saeed Noori Gashti, Mohammad Reza Alipour and Mohammad\n  Ali S. Afshar","title":"Can black holes cause cosmic expansion?","comments":"12 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently, it was shown in [1] that black holes are the source of dark energy.\nIn [2-5], the truth or falsity of this concept has been discussed. We briefly\nstate the arguments raised in each of these papers, but our main goal is not to\naccept or reject these debates. Rather, in this note, we show that black holes\nin specific structures, such as the Reissner-Nordstrom (R-N) black hole in the\npresence of quintessence, string cloud, and perfect fluid, can produce a\nrepulsive force with respect to the weak gravity conjecture mechanism that\novercomes the gravitational force.\\textit{ We discuss these repulsions forces\nin a population of black holes of the same family can be considered as an\nauxiliary factor (albeit a weak factor) for the expansion of the universe}.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:09:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12546","submitter":"Erdogan Aydin","authors":"Bulent Sagir, Erdogan Aydin, Haci Ilhan","title":"Deep-Learning Based Reconfigurable Intelligent Surfaces for\n  Intervehicular Communication","comments":"12 pages, 3 figures, 1 Table","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This letter proposes a novel deep neural network (DNN) assisted cooperative\nreconfigurable intelligent surface (RIS) scheme and a DNN-based symbol\ndetection model for intervehicular communication over cascaded Nakagami-m\nfading channels. In the considered realistic channel model, the channel links\nbetween moving nodes are modeled as cascaded Nakagami-m channels, and the links\ninvolving any stationary node are modeled as Nakagami-m fading channels, where\nall nodes between source and destination are realized with RIS-based relays.\nThe performances of the proposed models are evaluated and compared with the\nconventional methods in terms of bit error rates (BER). It is exhibited that\nthe DNN-based systems show near-identical performance with low system\ncomplexity.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:11:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12547","submitter":"Calin Iuliu Lazaroiu","authors":"Calin Iuliu Lazaroiu","title":"Natural coordinates and horizontal approximations in two-field\n  cosmological models","comments":"50 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We construct natural local coordinate systems on the phase space of two-field\ncosmological models with orientable target space, which allow for a description\nof cosmological flows through quantities of direct physical interest. Such\ncoordinates are induced by the fundamental observables of the model, which we\nformulate geometrically using the tautological bundle of the tangent bundle of\nthe scalar manifold. We also describe a large class of geometric dynamical\napproximations induced by the choice of an Ehresmann connection in the tangent\nbundle of the scalar manifold. Such approximations take a conceptually simple\nform in natural coordinates and we illustrate one of them as an application.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:17:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12548","submitter":"Daniel Minahan","authors":"Daniel Minahan","title":"The acyclicity of the complex of homologous curves","comments":"38 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show that the complex of homologous curves of a surface of genus g is\n(g-3)--acyclic.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:19:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12549","submitter":"Marco Piva","authors":"Marco Piva","title":"Higher-Derivative Quantum Gravity with Purely Virtual Particles:\n  Renormalizability and Unitarity","comments":"article prepared for EPJ Plus, Focus Point on Higher Derivatives in\n  Quantum Gravity: Theory, Tests, Phenomenology","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We review the formulation of quantum field theories with purely virtual\nparticles, a new type of degrees of freedom that can mediate interactions\nwithout ever appear as external on-shell states. This property allows to solve\nthe problem of ghosts in higher-derivative quantum gravity, leading to a\nrenormalizable and unitary theory. The main steps for the BRST quantization of\ngravity are recalled and renormalizability is discussed. Then, we introduce\npurely virtual particles in a general quantum field theory and show the\nderivation of the so-called spectral identities, which are a key ingredient to\nprove unitarity. Finally, phenomenological consequences and predictions in\ninflationary cosmology are presented.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:21:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12550","submitter":"Gaosheng Liu","authors":"Gaosheng Liu, Lin Wang","title":"Routing for Intermittently-Powered Sensing Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, intermittent computing (IC) has received tremendous attention due\nto its high potential in perpetual sensing for Internet-of-Things (IoT). By\nharvesting ambient energy, battery-free devices can perform sensing\nintermittently without maintenance, thus significantly improving IoT\nsustainability. To build a practical intermittently-powered sensing system,\nefficient routing across battery-free devices for data delivery is essential.\nHowever, the intermittency of these devices brings new challenges, rendering\nexisting routing protocols inapplicable.\n  In this paper, we propose RICS, the first-of-its-kind routing scheme tailored\nfor intermittently-powered sensing systems. RICS features two major designs,\nwith the goal of achieving low-latency data delivery on a network built with\nbattery-free devices. First, RICS incorporates a fast topology construction\nprotocol for each IC node to establish a path towards the sink node with the\nleast hop count. Second, RICS employs a low-latency message forwarding\nprotocol, which incorporates an efficient synchronization mechanism and a novel\ntechnique called pendulum-sync to avoid the time-consuming repeated node\nsynchronization. Our evaluation based on an implementation in OMNeT++ and\ncomprehensive experiments with varying system settings show that RICS can\nachieve orders of magnitude latency reduction in data delivery compared with\nthe baselines.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:22:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12551","submitter":"Xiaoda Qu","authors":"Xiaoda Qu, Xiran Fan, Baba C. Vemuri","title":"Kernel Stein Discrepancy on Lie Groups: Theory and Applications","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST math.PR stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Distributional approximation is a fundamental problem in machine learning\nwith numerous applications across all fields of science and engineering and\nbeyond. The key challenge in most approximation methods is the need to tackle\nthe intractable normalization constant pertaining to the parametrized\ndistributions used to model the data. In this paper, we present a novel Stein\noperator on Lie groups leading to a kernel Stein discrepancy (KSD) which is a\nnormalization-free loss function. We present several theoretical results\ncharacterizing the properties of this new KSD on Lie groups and its minimizers\nnamely, the minimum KSD estimator (MKSDE). Proof of several properties of MKSDE\nare presented, including strong consistency, CLT and a closed form of the MKSDE\nfor the von Mises-Fisher distribution on SO(N). Finally, we present\nexperimental evidence depicting advantages of minimizing KSD over maximum\nlikelihood estimation.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:22:45 GMT"},{"version":"v2","created":"Wed, 24 May 2023 18:08:44 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12552","submitter":"Huadai Liu","authors":"Huadai Liu, Rongjie Huang, Jinzheng He, Gang Sun, Ran Shen, Xize\n  Cheng, Zhou Zhao","title":"Wav2SQL: Direct Generalizable Speech-To-SQL Parsing","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech-to-SQL (S2SQL) aims to convert spoken questions into SQL queries given\nrelational databases, which has been traditionally implemented in a cascaded\nmanner while facing the following challenges: 1) model training is faced with\nthe major issue of data scarcity, where limited parallel data is available; and\n2) the systems should be robust enough to handle diverse out-of-domain speech\nsamples that differ from the source data. In this work, we propose the first\ndirect speech-to-SQL parsing model Wav2SQL which avoids error compounding\nacross cascaded systems. Specifically, 1) to accelerate speech-driven SQL\nparsing research in the community, we release a large-scale and multi-speaker\ndataset MASpider; 2) leveraging the recent progress in the large-scale\npre-training, we show that it alleviates the data scarcity issue and allow for\ndirect speech-to-SQL parsing; and 3) we include the speech re-programming and\ngradient reversal classifier techniques to reduce acoustic variance and learned\nstyle-agnostic representation, improving generalization to unseen out-of-domain\ncustom data. Experimental results demonstrate that Wav2SQL avoids error\ncompounding and achieves state-of-the-art results by up to 2.5\\% accuracy\nimprovement over the baseline.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:26:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12553","submitter":"Chinmay Maheshwari","authors":"Xin Guo and Xinyu Li and Chinmay Maheshwari and Shankar Sastry and\n  Manxi Wu","title":"Markov $\\alpha$-Potential Games: Equilibrium Approximation and Regret\n  Analysis","comments":"26 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT cs.AI cs.MA cs.SY eess.SY math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a new framework to study multi-agent interaction in\nMarkov games: Markov $\\alpha$-potential games. Markov potential games are\nspecial cases of Markov $\\alpha$-potential games, so are two important and\npractically significant classes of games: Markov congestion games and perturbed\nMarkov team games. In this paper, {$\\alpha$-potential} functions for both games\nare provided and the gap $\\alpha$ is characterized with respect to game\nparameters. Two algorithms -- the projected gradient-ascent algorithm and the\nsequential maximum improvement smoothed best response dynamics -- are\nintroduced for approximating the stationary Nash equilibrium in Markov\n$\\alpha$-potential games. The Nash-regret for each algorithm is shown to scale\nsub-linearly in time horizon. Our analysis and numerical experiments\ndemonstrates that simple algorithms are capable of finding approximate\nequilibrium in Markov $\\alpha$-potential games.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:27:31 GMT"},{"version":"v2","created":"Wed, 24 May 2023 18:01:12 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12554","submitter":"Jiarui Sun","authors":"Jiarui Sun, Girish Chowdhary","title":"Towards Globally Consistent Stochastic Human Motion Prediction via\n  Motion Diffusion","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Stochastic human motion prediction aims to predict multiple possible upcoming\npose sequences based on past human motion trajectories. Prior works focused\nheavily on generating diverse motion samples, leading to inconsistent, abnormal\npredictions from the immediate past observations. To address this issue, in\nthis work, we propose DiffMotion, a diffusion-based stochastic human motion\nprediction framework that considers both the kinematic structure of the human\nbody and the globally temporally consistent nature of motion. Specifically,\nDiffMotion consists of two modules: 1) a transformer-based network for\ngenerating an initial motion reconstruction from corrupted motion, and 2) a\nmulti-stage graph convolutional network to iteratively refine the generated\nmotion based on past observations. Facilitated by the proposed direct target\nprediction objective and the variance scheduler, our method is capable of\npredicting accurate, realistic and consistent motion with an appropriate level\nof diversity. Our results on benchmark datasets demonstrate that DiffMotion\noutperforms previous methods by large margins in terms of accuracy and fidelity\nwhile demonstrating superior robustness.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:31:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12555","submitter":"Pablo Portilla Cuadrado","authors":"Pablo Portilla Cuadrado and Baldur Sigur{\\dh}sson","title":"The total spine of the Milnor fibration of a plane curve singularity","comments":"96 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the separatrices at the origin of the vector field $-\\nabla \\log\n|f|$ where $f$ is any plane curve singularity. Under some genericity conditions\non the metric we produce a natural partition of the set of separatrices $S$\ninto segments and disks. As a byproduct of this theory we construct a smooth\nfibration equivalent to the Milnor fibration that lives on a quotient of the\nMilnor fibration at radius $0$, and, furthermore we see how the strict\ntransform of $S$ in this space induces a spine for each Milnor fiber of this\nfibration.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:55:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12556","submitter":"Vicente Rodriguez-Gomez","authors":"S. Michael Fall and Vicente Rodriguez-Gomez","title":"Negligible Effects of Baryons on the Angular Momentum Scaling Relations\n  of Galactic Dark Matter Halos","comments":"8 pages, 3 figures, 1 table. Accepted for publication in ApJL","journal-ref":"2023, ApJ, 949, L14","doi":"10.3847/2041-8213/acd4c3","report-no":null,"categories":"astro-ph.GA astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In cosmological simulations without baryons, the relation between the\nspecific angular momentum $j_{\\rm h}$ and mass $M_{\\rm h}$ of galactic dark\nmatter halos has the well-established form $j_{\\rm h} \\propto M_{\\rm h}^{2/3}$.\nThis is invariably adopted as the starting point in efforts to understand the\nanalogous relation between the specific angular momentum $j_{\\ast}$ and mass\n$M_{\\ast}$ of the stellar parts of galaxies, which are often re-expressed\nrelative to the corresponding halo properties through the retention fractions\n$f_j = j_{\\ast} / j_{\\rm h}$ and $f_M = M_{\\ast} / M_{\\rm h}$. An important\ncaveat here is that the adopted $j_{\\rm h} \\propto M_{\\rm h}^{2/3}$ relation\ncould, in principle, be modified by the gravitational back-reaction of baryons\non dark matter (DM). We have tested for this possibility by comparing the\n$j_{\\rm h}$-$M_{\\rm h}$ relations in the IllustrisTNG100 and TNG50 simulations\nthat include baryons (full-physics runs) with their counterparts that do not\n(DM-only runs). In all cases, we find scaling relations of the form $j_{\\rm h}\n\\propto M_{\\rm h}^{\\alpha}$, with $\\alpha \\approx 2/3$ over the ranges of mass\nand redshift studied here: $M_{\\rm h} \\geq 10^{10} \\, M_{\\odot}$ and $0 \\leq z\n\\leq 2$. The values of $\\alpha$ are virtually identical in the full-physics and\nDM-only runs at the same redshift. The only detectable effect of baryons on the\n$j_{\\rm h}$-$M_{\\rm h}$ relation is a slightly higher normalization, by 12%-15%\nat $z=0$ and by 5% at $z=2$. This implies that existing estimates of $f_j$\nbased on DM-only simulations should be adjusted downward by similar amounts.\nFinally, we discuss briefly some implications of this work for studies of\ngalaxy formation.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:12:10 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12557","submitter":"Junyi Zhu","authors":"Junyi Zhu, Xingchen Ma, Matthew B. Blaschko","title":"Confidence-aware Personalized Federated Learning via Variational\n  Expectation Maximization","comments":"Accepted at CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Federated Learning (FL) is a distributed learning scheme to train a shared\nmodel across clients. One common and fundamental challenge in FL is that the\nsets of data across clients could be non-identically distributed and have\ndifferent sizes. Personalized Federated Learning (PFL) attempts to solve this\nchallenge via locally adapted models. In this work, we present a novel\nframework for PFL based on hierarchical Bayesian modeling and variational\ninference. A global model is introduced as a latent variable to augment the\njoint distribution of clients' parameters and capture the common trends of\ndifferent clients, optimization is derived based on the principle of maximizing\nthe marginal likelihood and conducted using variational expectation\nmaximization. Our algorithm gives rise to a closed-form estimation of a\nconfidence value which comprises the uncertainty of clients' parameters and\nlocal model deviations from the global model. The confidence value is used to\nweigh clients' parameters in the aggregation stage and adjust the\nregularization effect of the global model. We evaluate our method through\nextensive empirical studies on multiple datasets. Experimental results show\nthat our approach obtains competitive results under mild heterogeneous\ncircumstances while significantly outperforming state-of-the-art PFL frameworks\nin highly heterogeneous settings. Our code is available at\nhttps://github.com/JunyiZhu-AI/confidence_aware_PFL.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:12:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12558","submitter":"Ada Stelzer","authors":"Ada Stelzer, Alexander Yong","title":"Schubert determinantal ideals are Hilbertian","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC math.AG math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Abhyankar defined an ideal to be Hilbertian if its Hilbert polynomial\ncoincides with its Hilbert function for all nonnegative integers. In 1984, he\nproved that the ideal of (r+1)-order minors of a generic p x q matrix is\nHilbertian. We give a different proof and a generalization to the Schubert\ndeterminantal ideals introduced by Fulton in 1994. Our proof reduces to a\nsimple upper bound for the Castelnuovo-Mumford regularity of these ideals.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:13:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12559","submitter":"Zsolt Pocze","authors":"Zsolt Pocze","title":"Multi-scale information content measurement method based on Shannon\n  information","comments":"12 pages, 5 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we present a new multi-scale information content calculation\nmethod based on Shannon information (and Shannon entropy). The original method\ndescribed by Claude E. Shannon and based on the logarithm of the probability of\nelements gives an upper limit to the information content of discrete patterns,\nbut in many cases (for example, in the case of repeating patterns) it is\ninaccurate and does not approximate the true information content of the pattern\nwell enough. The new mathematical method presented here provides a more\naccurate estimate of the (internal) information content of any discrete pattern\nbased on Shannon's original function. The method is tested on different data\nsets and the results are compared with the results of other methods like\ncompression algorithms.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:14:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12560","submitter":"Romain M. Yvinec","authors":"Juan Calvo, Erwan Hingant, Romain Yvinec","title":"Long-time asymptotic of the Lifshitz-Slyozov equation with nucleation","comments":null,"journal-ref":null,"doi":null,"report-no":"hal-04098262","categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the Lifshitz-Slyozov model with inflow boundary conditions of\nnucleation type. We show that for a collection of representative rate functions\nthe size distributions approach degenerate states concentrated at zero size for\nsufficiently large times. The proof relies on monotonicity properties of some\nquantities associated to an entropy functional. Moreover, we give numerical\nevidence on the fact that the convergence rate to the goal state is algebraic\nin time. Besides their mathematical interest, these results can be relevant for\nthe interpretation of experimental data.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:22:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12561","submitter":"Roberto Daza","authors":"\\'Alvaro Becerra, Roberto Daza, Ruth Cobos, Aythami Morales, Mutlu\n  Cukurova, Julian Fierrez","title":"M2LADS: A System for Generating MultiModal Learning Analytics Dashboards\n  in Open Education","comments":"Accepted in \"Workshop on Open Education Resources (OER) of COMPSAC\n  2023\"","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we present a Web-based System called M2LADS, which supports\nthe integration and visualization of multimodal data recorded in learning\nsessions in a MOOC in the form of Web-based Dashboards. Based on the edBB\nplatform, the multimodal data gathered contains biometric and behavioral\nsignals including electroencephalogram data to measure learners' cognitive\nattention, heart rate for affective measures, visual attention from the video\nrecordings. Additionally, learners' static background data and their learning\nperformance measures are tracked using LOGCE and MOOC tracking logs\nrespectively, and both are included in the Web-based System. M2LADS provides\nopportunities to capture learners' holistic experience during their\ninteractions with the MOOC, which can in turn be used to improve their learning\noutcomes through feedback visualizations and interventions, as well as to\nenhance learning analytics models and improve the open content of the MOOC.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:22:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12562","submitter":"Romain M. Yvinec","authors":"Claire Alamichel, Juan Calvo, Erwan Hingant, Saoussen Latrach, Nathan\n  Quiblier, Romain Yvinec","title":"Modeling compartmentalization within intracellular signaling pathway","comments":null,"journal-ref":null,"doi":null,"report-no":"hal-04098543","categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a new modeling approach for G protein coupled receptors signaling\nsystems, that take into account the compartmentalization of receptors and their\neffectors, both at plasma membrane and in dynamic intra-cellular vesicles\ncalled endosomes. The first building block of the model is about compartment\ndynamics. It takes into account creation of de-novo endosomes, i.e.\nendocytosis, recycling of endosomes back to plasma membrane, degradation\nthrough transfer into lysosomes as well as endosomes fusion through coagulation\ndynamics. The second building block is biochemical reactions into each\ncompartments and the transfer of molecules between the dynamical compartments.\nIn this work, we prove sufficient conditions to obtain exponentially ergodicity\nfor the size distribution of intracellular compartments. We futher design a\nfinite volume scheme to simulate our model and show two application cases for\nreceptor trafficking and spatially biased second effector signaling.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:23:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12563","submitter":"Jordan Meadows","authors":"Jordan Meadows, Marco Valentino, Damien Teney, Andre Freitas","title":"A Symbolic Framework for Systematic Evaluation of Mathematical Reasoning\n  with Transformers","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Whether Transformers can learn to apply symbolic rules and generalise to\nout-of-distribution examples is an open research question. In this paper, we\ndevise a data generation method for producing intricate mathematical\nderivations, and systematically perturb them with respect to syntax, structure,\nand semantics. Our task-agnostic approach generates equations, annotations, and\ninter-equation dependencies, employing symbolic algebra for scalable data\nproduction and augmentation. We then instantiate a general experimental\nframework on next-equation prediction, assessing systematic mathematical\nreasoning and generalisation of Transformer encoders on a total of 200K\nexamples. The experiments reveal that perturbations heavily affect performance\nand can reduce F1 scores of $97\\%$ to below $17\\%$, suggesting that inference\nis dominated by surface-level patterns unrelated to a deeper understanding of\nmathematical operators. These findings underscore the importance of rigorous,\nlarge-scale evaluation frameworks for revealing fundamental limitations of\nexisting models.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:40:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12564","submitter":"Jin Kim","authors":"Jared Wong and Jin Kim","title":"ChatGPT Is More Likely to Be Perceived as Male Than Female","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.AI cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We investigate how people perceive ChatGPT, and, in particular, how they\nassign human-like attributes such as gender to the chatbot. Across five\npre-registered studies (N = 1,552), we find that people are more likely to\nperceive ChatGPT to be male than female. Specifically, people perceive male\ngender identity (1) following demonstrations of ChatGPT's core abilities (e.g.,\nproviding information or summarizing text), (2) in the absence of such\ndemonstrations, and (3) across different methods of eliciting perceived gender\n(using various scales and asking to name ChatGPT). Moreover, we find that this\nseemingly default perception of ChatGPT as male can reverse when ChatGPT's\nfeminine-coded abilities are highlighted (e.g., providing emotional support for\na user).\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 20:57:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12565","submitter":"Ziqi Wang","authors":"Ziqi Wang, Chi Han, Wenxuan Bao, Heng Ji","title":"Understanding the Effect of Data Augmentation on Knowledge Distillation","comments":"14 pages, 8 tables, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Knowledge distillation (KD) requires sufficient data to transfer knowledge\nfrom large-scale teacher models to small-scale student models. Therefore, data\naugmentation has been widely used to mitigate the shortage of data under\nspecific scenarios. Classic data augmentation techniques, such as synonym\nreplacement and k-nearest-neighbors, are initially designed for fine-tuning. To\navoid severe semantic shifts and preserve task-specific labels, those methods\nprefer to change only a small proportion of tokens (e.g., changing 10% tokens\nis generally the best option for fine-tuning). However, such data augmentation\nmethods are sub-optimal for knowledge distillation since the teacher model\ncould provide label distributions and is more tolerant to semantic shifts. We\nfirst observe that KD prefers as much data as possible, which is different from\nfine-tuning that too much data will not gain more performance. Since changing\nmore tokens leads to more semantic shifts, we use the proportion of changed\ntokens to reflect semantic shift degrees. Then we find that KD prefers\naugmented data with a larger semantic shift degree (e.g., changing 30% tokens\nis generally the best option for KD) than fine-tuning (changing 10% tokens).\nBesides, our findings show that smaller datasets prefer larger degrees until\nthe out-of-distribution problem occurs (e.g., datasets with less than 10k\ninputs may prefer the 50% degree, and datasets with more than 100k inputs may\nprefer the 10% degree). Our work sheds light on the preference difference in\ndata augmentation between fine-tuning and knowledge distillation and encourages\nthe community to explore KD-specific data augmentation methods.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:02:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12566","submitter":"Bartosz Fornal","authors":"Bartosz Fornal, Kassandra Garcia, Erika Pierre","title":"Testing Unification and Dark Matter with Gravitational Waves","comments":"10 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose to search for a new type of gravitational wave signature relevant\nfor particle physics models with symmetries broken at vastly different energy\nscales. The spectrum contains a characteristic double-peak structure consisting\nof a sharp peak from domain walls and a smooth bump from a first order phase\ntransition in the early Universe. We demonstrate how such a gravitational wave\nsignal arises in a new theory unifying baryon number and color into an SU(4)\ngauge group broken at the multi-TeV scale, and with lepton number promoted to\nan SU(2) gauge symmetry broken at the multi-EeV scale. The model contains two\ntypes of dark matter particles, explains the observed domination of matter over\nantimatter in the Universe, and accommodates nonzero neutrino masses. We\ndiscuss how future gravitational wave experiments, such as LISA, Big Bang\nObserver, DECIGO, Einstein Telescope, and Cosmic Explorer, can be utilized to\nlook for this novel signature.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:03:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12567","submitter":"Linyuan Gong","authors":"Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie,\n  Alvin Cheung, Jianfeng Gao, Xia Song","title":"Model-Generated Pretraining Signals Improves Zero-Shot Generalization of\n  Text-to-Text Transformers","comments":"Published as a conference paper at ACL 2023. 9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper explores the effectiveness of model-generated signals in improving\nzero-shot generalization of text-to-text Transformers such as T5. We study\nvarious designs to pretrain T5 using an auxiliary model to construct more\nchallenging token replacements for the main model to denoise. Key aspects under\nstudy include the decoding target, the location of the RTD head, and the\nmasking pattern. Based on these studies, we develop a new model, METRO-T0,\nwhich is pretrained using the redesigned ELECTRA-Style pretraining strategies\nand then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all\nsimilar-sized baselines on prompted NLP benchmarks, such as T0 Eval and MMLU,\nand rivals the state-of-the-art T0-11B model with only 8% of its parameters.\nOur analysis on model's neural activation and parameter sensitivity reveals\nthat the effectiveness of METRO-T0 stems from more balanced contribution of\nparameters and better utilization of their capacity. The code and model\ncheckpoints are available at https://github.com/gonglinyuan/metro_t0.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:06:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12568","submitter":"Avetik Karagulyan","authors":"Hanmin Li, Avetik Karagulyan, Peter Richt\\'arik","title":"Det-CGD: Compressed Gradient Descent with Matrix Stepsizes for\n  Non-Convex Optimization","comments":"9 pages, 39 figures, Under review","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper introduces a new method for minimizing matrix-smooth non-convex\nobjectives through the use of novel Compressed Gradient Descent (CGD)\nalgorithms enhanced with a matrix-valued stepsize. The proposed algorithms are\ntheoretically analyzed first in the single-node and subsequently in the\ndistributed settings. Our theoretical results reveal that the matrix stepsize\nin CGD can capture the objective's structure and lead to faster convergence\ncompared to a scalar stepsize. As a byproduct of our general results, we\nemphasize the importance of selecting the compression mechanism and the matrix\nstepsize in a layer-wise manner, taking advantage of model structure. Moreover,\nwe provide theoretical guarantees for free compression, by designing specific\nlayer-wise compressors for the non-convex matrix smooth objectives. Our\nfindings are supported with empirical evidence.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:09:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12569","submitter":"Zheng Dong","authors":"Zheng Dong, Zekai Fan, Shixiang Zhu","title":"Conditional Generative Modeling is All You Need for Marked Temporal\n  Point Processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent advancements in generative modeling have made it possible to generate\nhigh-quality content from context information, but a key question remains: how\nto teach models to know when to generate content? To answer this question, this\nstudy proposes a novel event generative model that draws its statistical\nintuition from marked temporal point processes, and offers a clean, flexible,\nand computationally efficient solution for a wide range of applications\ninvolving multi-dimensional marks. We aim to capture the distribution of the\npoint process without explicitly specifying the conditional intensity or\nprobability density. Instead, we use a conditional generator that takes the\nhistory of events as input and generates the high-quality subsequent event that\nis likely to occur given the prior observations. The proposed framework offers\na host of benefits, including exceptional efficiency in learning the model and\ngenerating samples, as well as considerable representational power to capture\nintricate dynamics in multi- or even high-dimensional event space. Our\nnumerical results demonstrate superior performance compared to other\nstate-of-the-art baselines.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:13:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12570","submitter":"Luuk Jacobs","authors":"Luuk Jacobs, Stefano Mandija, Hongyan Liu, Cornelis A.T. van den Berg,\n  Alessandro Sbrizzi, Matteo Maspero","title":"Generalizable synthetic MRI with physics-informed convolutional networks","comments":"23 pages, 7 figures, 1 table. Presented at ISMRM 2022. Will be\n  submitted to NMR in biomedicine","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we develop a physics-informed deep learning-based method to\nsynthesize multiple brain magnetic resonance imaging (MRI) contrasts from a\nsingle five-minute acquisition and investigate its ability to generalize to\narbitrary contrasts to accelerate neuroimaging protocols. A dataset of\nfifty-five subjects acquired with a standard MRI protocol and a five-minute\ntransient-state sequence was used to develop a physics-informed deep\nlearning-based method. The model, based on a generative adversarial network,\nmaps data acquired from the five-minute scan to \"effective\" quantitative\nparameter maps, here named q*-maps, by using its generated PD, T1, and T2\nvalues in a signal model to synthesize four standard contrasts (proton\ndensity-weighted, T1-weighted, T2-weighted, and T2-weighted fluid-attenuated\ninversion recovery), from which losses are computed. The q*-maps are compared\nto literature values and the synthetic contrasts are compared to an end-to-end\ndeep learning-based method proposed by literature. The generalizability of the\nproposed method is investigated for five volunteers by synthesizing three\nnon-standard contrasts unseen during training and comparing these to respective\nground truth acquisitions via contrast-to-noise ratio and quantitative\nassessment. The physics-informed method was able to match the high-quality\nsynthMRI of the end-to-end method for the four standard contrasts, with mean\n\\pm standard deviation structural similarity metrics above 0.75 \\pm 0.08 and\npeak signal-to-noise ratios above 22.4 \\pm 1.9 and 22.6 \\pm 2.1. Additionally,\nthe physics-informed method provided retrospective contrast adjustment, with\nvisually similar signal contrast and comparable contrast-to-noise ratios to the\nground truth acquisitions for three sequences unused for model training,\ndemonstrating its generalizability and potential application to accelerate\nneuroimaging protocols.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:16:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12571","submitter":"Iordanis Fostiropoulos","authors":"Iordanis Fostiropoulos, Bowman Brown, Laurent Itti","title":"Reproducibility Requires Consolidated Artifacts","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.SE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Machine learning is facing a 'reproducibility crisis' where a significant\nnumber of works report failures when attempting to reproduce previously\npublished results. We evaluate the sources of reproducibility failures using a\nmeta-analysis of 142 replication studies from ReScience C and 204 code\nrepositories. We find that missing experiment details such as hyperparameters\nare potential causes of unreproducibility. We experimentally show the bias of\ndifferent hyperparameter selection strategies and conclude that consolidated\nartifacts with a unified framework can help support reproducibility.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:21:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12572","submitter":"Manu Prakash","authors":"Xingting Gong, Manu Prakash","title":"Active dislocations and topological traps govern dynamics of spiraling\n  filamentous cyanobacteria","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft physics.bio-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Activity can organize matter in unique configurations inaccessible to\nequilibrium systems, including a sundry of spiraling shapes seen in nature that\nrange from galaxies to living tissues to fossilized stromatolites. How these\ndynamic yet stable patterns form in motile active systems that span a range of\nlength and time scales remains an open question. Here we study the collective\ngliding dynamics of ultra-long filamentous cyanobacteria confined in two\ndimensions and present the discovery of an emergent pattern we call ``active\nspirals\". Individual filaments in the spiral bulk remain confluent due to\nadhesion forces and exhibit reversible gliding motility. Thus individual\nfilaments undergo bidirectional movement and the spiral object as a whole has\nno fixed vorticity. Using single filament tracking, we discover that spirals\npermit the radial flux of material as filaments shear past one another. We\ndemonstrate that these rearrangements can be entirely described by topological\nrules of interaction between filaments tips. We thus reduce the dynamics of a\nspiral to a set of active dislocations (corresponding to the filament tips) on\na polar coordinate lattice and show that we can reproduce and predict the\nmaterial flux in the system. Finally, we present a discovery of a novel\ntopological trap present in these spirals, and is induced purely by the\ngeometric chirality of long winding filaments with winding number greater than\nzero. A topological trap creates boundaries in the spiral across which material\ncannot flow, leading to persistent structures that are topologically locked for\nthe lifetime of the system. The emergent mechanics of active spirals presented\nhere sheds light on the critical role of adhesion forces, activity and geometry\nin the formation of long-term, stable, yet dynamic active patterns.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:27:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12573","submitter":"Jian-Wen Zhou","authors":"J. W. Zhou, F. Wyrowski, S. Neupane, J. S. Urquhart, N. J. Evans II,\n  E. V\\'azquez-Semadeni, K. M. Menten, Y. Gong and T. Liu","title":"High-resolution APEX/LAsMA $^{12}$CO and $^{13}$CO (3-2) observation of\n  the G333 giant molecular cloud complex : I. Evidence for gravitational\n  acceleration in hub-filament systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Hub-filament systems are suggested to be the birth cradles of high-mass stars\nand clusters. We apply the FILFINDER algorithm to the integrated intensity maps\nof the 13CO (3-2) line to identify filaments in the G333 complex, and extract\nthe velocity and intensity along the filament skeleton from moment maps. Clear\nvelocity and density fluctuations are seen along the filaments, allowing us to\nfit velocity gradients around the intensity peaks. The velocity gradients\nfitted to the LAsMA data and ALMA data agree with each other over the scales\ncovered by ALMA observations in the ATOMS survey. Changes of velocity gradient\nwith scale indicate a ''funnel'' structure of the velocity field in PPV space,\nindicative of a smooth, continuously increasing velocity gradient from large to\nsmall scales, and thus consistent with gravitational acceleration. The typical\nvelocity gradient corresponding to a 1 pc scale is ~1.6km/s/pc. Assuming\nfree-fall, we estimate a kinematic mass within 1 pc of ~1190 M$_\\odot$, which\nis consistent with typical masses of clumps in the ATLASGAL survey. We find\ndirect evidence for gravitational acceleration from comparison of the observed\naccelerations to those predicted by free-fall onto dense hubs. On large scales,\nwe find that the inflow may be driven by the larger scale structure, consistent\nwith hierarchical structure in the molecular cloud and gas inflow from large to\nsmall scales. The hub-filament structures at different scales may be organized\ninto a hierarchical system extending up to the largest scales probed, through\nthe coupling of gravitational centers at different scales. We argue that the\n''funnel'' structure in PPV space can be an effective probe for the\ngravitational collapse motions in molecular clouds. The large scale gas inflow\nis driven by gravity, implying that the molecular clouds in G333 complex may be\nin the state of global gravitational collapse.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:35:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12574","submitter":"Subham Sahoo","authors":"Subham Sahoo, Arpan Malkhandi and Kristian Skafte Jensen","title":"Atomic Anatomy of Low-Inertia Power Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we determine a fundamental anatomical modeling parallelism\nbetween low-inertia power systems and Bohr's atomic model. The proposed atomic\narchitecture will serve as a microscopic building block, where we validate the\nstructural analogy of low-inertia power systems using semi-classical quantum\napproximations in IEEE 9-bus & 39-bus systems. As a future scope of work,\ndetailed modeling & system stability will be investigated by using\npre-quantization and geometric quantization methods.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:37:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12575","submitter":"Scott Hansen","authors":"Scott K. Hansen, Yichen Tao, Satish Karra","title":"Impacts of permeability heterogeneity and background flow on\n  supercritical CO2 dissolution in the deep subsurface","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Motivated by CO2 capture and sequestration (CCS) design considerations, we\nconsider the coupled effects of permeability heterogeneity and background flow\non the dissolution of a supercritical CO2 lens into an underlying deep,\nconfined aquifer. We present the results of a large-scale Monte Carlo\nsimulation study examining the interaction of background flow rate and three\nparameters describing multi-Gaussian log-permeability fields: mean, variance,\nand correlation length. Hundreds of high-resolution simulations were performed\nusing the PFLOTRAN finite volume software to model CO2 dissolution in a\nkilometer-scale aquifer over 1000 y. Predictive dimensionless scaling\nrelationships relating CO2 dissolution rate to heterogeneity statistics,\nRayleigh (Ra) and Peclet (Pe) numbers were developed for both gravitationally\ndominated free convection to background flow-dominated forced convection\nregimes. An empirical criterion, $\\rm Pe\\ = Ra^{3/4}$, was discovered for\nregime transition. All simulations converged quickly to a quasi-steady,\napproximately linear dissolution rate. However, this rate displayed profound\nvariability between permeability field realizations sharing the same\nheterogeneity statistics, even under mild permeability heterogeneity. In\ngeneral, increased heterogeneity was associated with a lower mean and higher\nvariance of dissolution rate, undesirable from a CCS design perspective. The\nrelationship between dissolution rate and background flow was found to be\ncomplex and nonlinear. Dimensionless scaling relationships were uncovered for a\nnumber of special cases. Results call into question the validity of the\nBoussinesq approximation in the context of modest-to-high background flow rates\nand the general applicability of numerical simulations without background flow.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:49:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12576","submitter":"Rami Aly","authors":"Rami Aly, Xingjian Shi, Kaixiang Lin, Aston Zhang, Andrew Gordon\n  Wilson","title":"Automated Few-shot Classification with Instruction-Finetuned Language\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  A particularly successful class of approaches for few-shot learning combines\nlanguage models with prompts -- hand-crafted task descriptions that complement\ndata samples. However, designing prompts by hand for each task commonly\nrequires domain knowledge and substantial guesswork. We observe, in the context\nof classification tasks, that instruction finetuned language models exhibit\nremarkable prompt robustness, and we subsequently propose a simple method to\neliminate the need for handcrafted prompts, named AuT-Few. This approach\nconsists of (i) a prompt retrieval module that selects suitable task\ninstructions from the instruction-tuning knowledge base, and (ii) the\ngeneration of two distinct, semantically meaningful, class descriptions and a\nselection mechanism via cross-validation. Over $12$ datasets, spanning $8$\nclassification tasks, we show that AuT-Few outperforms current state-of-the-art\nfew-shot learning methods. Moreover, AuT-Few is the best ranking method across\ndatasets on the RAFT few-shot benchmark. Notably, these results are achieved\nwithout task-specific handcrafted prompts on unseen tasks.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:50:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12577","submitter":"Korrawe Karunratanakul","authors":"Korrawe Karunratanakul, Konpat Preechakul, Supasorn Suwajanakorn, Siyu\n  Tang","title":"GMD: Controllable Human Motion Synthesis via Guided Diffusion Models","comments":"Project page: https://korrawe.github.io/gmd-project/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Denoising diffusion models have shown great promise in human motion synthesis\nconditioned on natural language descriptions. However, it remains a challenge\nto integrate spatial constraints, such as pre-defined motion trajectories and\nobstacles, which is essential for bridging the gap between isolated human\nmotion and its surrounding environment. To address this issue, we propose\nGuided Motion Diffusion (GMD), a method that incorporates spatial constraints\ninto the motion generation process. Specifically, we propose an effective\nfeature projection scheme that largely enhances the coherency between spatial\ninformation and local poses. Together with a new imputation formulation, the\ngenerated motion can reliably conform to spatial constraints such as global\nmotion trajectories. Furthermore, given sparse spatial constraints (e.g. sparse\nkeyframes), we introduce a new dense guidance approach that utilizes the\ndenoiser of diffusion models to turn a sparse signal into denser signals,\neffectively guiding the generation motion to the given constraints. The\nextensive experiments justify the development of GMD, which achieves a\nsignificant improvement over state-of-the-art methods in text-based motion\ngeneration while being able to control the synthesized motions with spatial\nconstraints.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:54:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12578","submitter":"Huaisheng Zhu","authors":"Huaisheng Zhu, Dongsheng Luo, Xianfeng Tang, Junjie Xu, Hui Liu,\n  Suhang Wang","title":"Self-Explainable Graph Neural Networks for Link Prediction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph Neural Networks (GNNs) have achieved state-of-the-art performance for\nlink prediction. However, GNNs suffer from poor interpretability, which limits\ntheir adoptions in critical scenarios that require knowing why certain links\nare predicted. Despite various methods proposed for the explainability of GNNs,\nmost of them are post-hoc explainers developed for explaining node\nclassification. Directly adopting existing post-hoc explainers for explaining\nlink prediction is sub-optimal because: (i) post-hoc explainers usually adopt\nanother strategy or model to explain a target model, which could misinterpret\nthe target model; and (ii) GNN explainers for node classification identify\ncrucial subgraphs around each node for the explanation; while for link\nprediction, one needs to explain the prediction for each pair of nodes based on\ngraph structure and node attributes. Therefore, in this paper, we study a novel\nproblem of self-explainable GNNs for link prediction, which can simultaneously\ngive accurate predictions and explanations. Concretely, we propose a new\nframework and it can find various $K$ important neighbors of one node to learn\npair-specific representations for links from this node to other nodes. These\n$K$ different neighbors represent important characteristics of the node and\nmodel various factors for links from it. Thus, $K$ neighbors can provide\nexplanations for the existence of links. Experiments on both synthetic and\nreal-world datasets verify the effectiveness of the proposed framework for link\nprediction and explanation.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 21:57:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12579","submitter":"Karel Bene\\v{s}","authors":"Karel Bene\\v{s}, Martin Kocour, Luk\\'a\\v{s} Burget","title":"Hystoc: Obtaining word confidences for fusion of end-to-end ASR systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  End-to-end (e2e) systems have recently gained wide popularity in automatic\nspeech recognition. However, these systems do generally not provide\nwell-calibrated word-level confidences. In this paper, we propose Hystoc, a\nsimple method for obtaining word-level confidences from hypothesis-level\nscores. Hystoc is an iterative alignment procedure which turns hypotheses from\nan n-best output of the ASR system into a confusion network. Eventually,\nword-level confidences are obtained as posterior probabilities in the\nindividual bins of the confusion network. We show that Hystoc provides\nconfidences that correlate well with the accuracy of the ASR hypothesis.\nFurthermore, we show that utilizing Hystoc in fusion of multiple e2e ASR\nsystems increases the gains from the fusion by up to 1\\,\\% WER absolute on\nSpanish RTVE2020 dataset. Finally, we experiment with using Hystoc for direct\nfusion of n-best outputs from multiple systems, but we only achieve minor gains\nwhen fusing very similar systems.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:06:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12580","submitter":"Marc Canby","authors":"Marc E. Canby and Julia Hockenmaier","title":"A Framework for Bidirectional Decoding: Case Study in Morphological\n  Inflection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transformer-based encoder-decoder models that generate outputs in a\nleft-to-right fashion have become standard for sequence-to-sequence tasks. In\nthis paper, we propose a framework for decoding that produces sequences from\nthe \"outside-in\": at each step, the model chooses to generate a token on the\nleft, on the right, or join the left and right sequences. We argue that this is\nmore principled than prior bidirectional decoders. Our proposal supports a\nvariety of model architectures and includes several training methods, such as a\ndynamic programming algorithm that marginalizes out the latent ordering\nvariable. Our model improves considerably over a simple baseline based on\nunidirectional transformers on the SIGMORPHON 2023 inflection task and sets\nSOTA on the 2022 shared task. The model performs particularly well on long\nsequences, can learn the split point of words composed of stem and affix\n(without supervision), and performs better relative to the baseline on datasets\nthat have fewer unique lemmas (but more examples per lemma).\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:08:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12581","submitter":"Erik Drysdale","authors":"Erik Drysdale","title":"A parametric distribution for exact post-selection inference with data\n  carving","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Post-selection inference (PoSI) is a statistical technique for obtaining\nvalid confidence intervals and p-values when hypothesis generation and testing\nuse the same source of data. PoSI can be used on a range of popular algorithms\nincluding the Lasso. Data carving is a variant of PoSI in which a portion of\nheld out data is combined with the hypothesis generating data at inference\ntime. While data carving has attractive theoretical and empirical properties,\nexisting approaches rely on computationally expensive MCMC methods to carry out\ninference. This paper's key contribution is to show that pivotal quantities can\nbe constructed for the data carving procedure based on a known parametric\ndistribution. Specifically, when the selection event is characterized by a set\nof polyhedral constraints on a Gaussian response, data carving will follow the\nsum of a normal and a truncated normal (SNTN), which is a variant of the\ntruncated bivariate normal distribution. The main impact of this insight is\nthat obtaining exact inference for data carving can be made computationally\ntrivial, since the CDF of the SNTN distribution can be found using the CDF of a\nstandard bivariate normal. A python package sntn has been released to further\nfacilitate the adoption of data carving with PoSI.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:29:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12582","submitter":"Mikhail Ostrovskii","authors":"Stephen J. Dilworth, Denka Kutzarova, Mikhail I. Ostrovskii","title":"Cycle spaces: invariant projections and applications to transportation\n  cost","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.CO math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The paper starts with discussion of applications of cycle spaces to\ntransportation cost. After a short survey of the known results on cycle spaces,\nwe turn to the study of minimal projections onto cycle spaces in the\ncorresponding $\\ell_1$-spaces. This study is naturally related to the study of\ninvariant projections on the cycle space, which, in turn, are determined by the\nproperties of representations of the automorphism group of the corresponding\ngraph. The main focus is on discrete tori and Hamming graphs.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:32:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12583","submitter":"Muhammad Mahboob Ur Rahman","authors":"Ahsan Mehmood, Asma Sarauji, M. Mahboob Ur Rahman, Tareq Y.\n  Al-Naffouri","title":"Your smartphone could act as a pulse-oximeter and as a single-lead ECG","comments":"14 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the post-covid19 era, every new wave of the pandemic causes an increased\nconcern among the masses to learn more about their state of well-being.\nTherefore, it is the need of the hour to come up with ubiquitous, low-cost,\nnon-invasive tools for rapid and continuous monitoring of body vitals that\nreflect the status of one's overall health. In this backdrop, this work\nproposes a deep learning approach to turn a smartphone-the popular hand-held\npersonal gadget-into a diagnostic tool to measure/monitor the three most\nimportant body vitals, i.e., pulse rate (PR), blood oxygen saturation level\n(aka SpO2), and respiratory rate (RR). Furthermore, we propose another method\nthat could extract a single-lead electrocardiograph (ECG) of the subject. The\nproposed methods include the following core steps: subject records a small\nvideo of his/her fingertip by placing his/her finger on the rear camera of the\nsmartphone, and the recorded video is pre-processed to extract the filtered\nand/or detrended video-photoplethysmography (vPPG) signal, which is then fed to\ncustom-built convolutional neural networks (CNN), which eventually spit-out the\nvitals (PR, SpO2, and RR) as well as a single-lead ECG of the subject. To be\nprecise, the contribution of this paper is two-fold: 1) estimation of the three\nbody vitals (PR, SpO2, RR) from the vPPG data using custom-built CNNs, vision\ntransformer, and most importantly by CLIP model; 2) a novel discrete cosine\ntransform+feedforward neural network-based method that translates the recorded\nvideo- PPG signal to a single-lead ECG signal. The proposed method is\nanticipated to find its application in several use-case scenarios, e.g., remote\nhealthcare, mobile health, fitness, sports, etc.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:34:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12584","submitter":"Mingsong Yan","authors":"Rui Wang, Yuesheng Xu, Mingsong Yan","title":"Sparse Representer Theorems for Learning in Reproducing Kernel Banach\n  Spaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Sparsity of a learning solution is a desirable feature in machine learning.\nCertain reproducing kernel Banach spaces (RKBSs) are appropriate hypothesis\nspaces for sparse learning methods. The goal of this paper is to understand\nwhat kind of RKBSs can promote sparsity for learning solutions. We consider two\ntypical learning models in an RKBS: the minimum norm interpolation (MNI)\nproblem and the regularization problem. We first establish an explicit\nrepresenter theorem for solutions of these problems, which represents the\nextreme points of the solution set by a linear combination of the extreme\npoints of the subdifferential set, of the norm function, which is\ndata-dependent. We then propose sufficient conditions on the RKBS that can\ntransform the explicit representation of the solutions to a sparse kernel\nrepresentation having fewer terms than the number of the observed data. Under\nthe proposed sufficient conditions, we investigate the role of the\nregularization parameter on sparsity of the regularized solutions. We further\nshow that two specific RKBSs: the sequence space $\\ell_1(\\mathbb{N})$ and the\nmeasure space can have sparse representer theorems for both MNI and\nregularization models.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:36:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12585","submitter":"Wilson Gregory","authors":"Wilson Gregory, David W. Hogg, Ben Blum-Smith, Maria Teresa Arias,\n  Kaze W. K. Wong, Soledad Villar","title":"GeometricImageNet: Extending convolutional neural networks to vector and\n  tensor images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Convolutional neural networks and their ilk have been very successful for\nmany learning tasks involving images. These methods assume that the input is a\nscalar image representing the intensity in each pixel, possibly in multiple\nchannels for color images. In natural-science domains however, image-like data\nsets might have vectors (velocity, say), tensors (polarization, say),\npseudovectors (magnetic field, say), or other geometric objects in each pixel.\nTreating the components of these objects as independent channels in a CNN\nneglects their structure entirely. Our formulation -- the GeometricImageNet --\ncombines a geometric generalization of convolution with outer products, tensor\nindex contractions, and tensor index permutations to construct geometric-image\nfunctions of geometric images that use and benefit from the tensor structure.\nThe framework permits, with a very simple adjustment, restriction to function\nspaces that are exactly equivariant to translations, discrete rotations, and\nreflections. We use representation theory to quantify the dimension of the\nspace of equivariant polynomial functions on 2-dimensional vector images. We\ngive partial results on the expressivity of GeometricImageNet on small images.\nIn numerical experiments, we find that GeometricImageNet has good\ngeneralization for a small simulated physics system, even when trained with a\nsmall training set. We expect this tool will be valuable for scientific and\nengineering machine learning, for example in cosmology or ocean dynamics.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:44:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12586","submitter":"Linyong Nan","authors":"Linyong Nan, Yilun Zhao, Weijin Zou, Narutatsu Ri, Jaesung Tae, Ellen\n  Zhang, Arman Cohan, Dragomir Radev","title":"Enhancing Few-shot Text-to-SQL Capabilities of Large Language Models: A\n  Study on Prompt Design Strategies","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  In-context learning (ICL) has emerged as a new approach to various natural\nlanguage processing tasks, utilizing large language models (LLMs) to make\npredictions based on context that has been supplemented with a few examples or\ntask-specific instructions. In this paper, we aim to extend this method to\nquestion answering tasks that utilize structured knowledge sources, and improve\nText-to-SQL systems by exploring various prompt design strategies for employing\nLLMs. We conduct a systematic investigation into different demonstration\nselection methods and optimal instruction formats for prompting LLMs in the\nText-to-SQL task. Our approach involves leveraging the syntactic structure of\nan example's SQL query to retrieve demonstrations, and we demonstrate that\npursuing both diversity and similarity in demonstration selection leads to\nenhanced performance. Furthermore, we show that LLMs benefit from\ndatabase-related knowledge augmentations. Our most effective strategy\noutperforms the state-of-the-art system by 2.5 points (Execution Accuracy) and\nthe best fine-tuned system by 5.1 points on the Spider dataset. These results\nhighlight the effectiveness of our approach in adapting LLMs to the Text-to-SQL\ntask, and we present an analysis of the factors contributing to the success of\nour strategy.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:44:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12587","submitter":"Ravi Shankar","authors":"Ravi Shankar and Yu Yuan","title":"Hessian estimates for the sigma-2 equation in dimension four","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive a priori interior Hessian estimates and interior regularity for the\n$\\sigma_2$ equation in dimension four. Our method provides respectively a new\nproof for the corresponding three dimensional results and a Hessian estimate\nfor smooth solutions satisfying a dynamic semi-convexity condition in higher\n$n\\ge 5$ dimensions.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:51:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12588","submitter":"D.V. Skryabin","authors":"Juanjuan Lu, Danila N. Puzyrev, Vladislav V. Pankratov, Dmitry V.\n  Skryabin, Fengyan Yang, Zheng Gong, Joshua B. Surya, and Hong X. Tang","title":"Two-colour dissipative solitons and breathers in microresonator\n  second-harmonic generation","comments":"6 figures","journal-ref":"Nature Communications 14, 2798 (2023)","doi":"10.1038/s41467-023-38412-w","report-no":null,"categories":"physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Frequency conversion of dissipative solitons associated with the generation\nof broadband optical frequency combs having a tooth spacing of hundreds of\ngiga-hertz is a topical challenge holding the key to practical applications in\nprecision spectroscopy and data processing. The work in this direction is\nunderpinned by fundamental problems in nonlinear and quantum optics. Here, we\npresent the dissipative two-colour bright-bright and dark-dark solitons in a\nquasi-phase-matched microresonator pumped for the second-harmonic generation in\nthe near-infrared spectral range. We also found the breather states associated\nwith the pulse front motion and collisions. The soliton regime is found to be\ntypical in slightly phase-mismatched resonators, while the phase-matched ones\nreveal broader but incoherent spectra and higher-order harmonic generation.\nSoliton and breather effects reported here exist for the negative tilt of the\nresonance line, which is possible only via the dominant contribution of\nsecond-order nonlinearity.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:52:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12589","submitter":"Antoine Detaille","authors":"Antoine Detaille","title":"A complete answer to the strong density problem in Sobolev spaces with\n  values into compact manifolds","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of strong density of smooth maps in the Sobolev space\n$ W^{s,p}(Q^{m};\\mathcal{N}) $, where $ 0 < s < +\\infty $, $ 1 \\leq p < +\\infty\n$, $ Q^{m} $ is the unit cube in $ \\mathbb{R}^{m} $, and $ \\mathcal{N} $ is a\nsmooth compact connected Riemannian manifold without boundary. Our main result\nfully answers the strong density problem in the whole range $ 0 < s < +\\infty\n$: the space $ \\mathcal{C}^{\\infty}(\\overline{Q}^{m};\\mathcal{N}) $ is dense in\n$ W^{s,p}(Q^{m};\\mathcal{N}) $ if and only if $ \\pi_{[sp]}(\\mathcal{N}) = \\{0\\}\n$. This completes the results of Bethuel ($ s=1 $), Brezis and Mironescu ($ 0 <\ns < 1 $), and Bousquet, Ponce, and Van Schaftingen ($ s = 2 $, $ 3 $, ...). We\nalso consider the case of more general domains $ \\Omega $, in the setting\nstudied by Hang and Lin when $ s = 1 $.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:53:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12590","submitter":"Muhammad Abdullah Hanif","authors":"Muhammad Abdullah Hanif, Muhammad Shafique","title":"FAQ: Mitigating the Impact of Faults in the Weight Memory of DNN\n  Accelerators through Fault-Aware Quantization","comments":"8 pages, 15 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Permanent faults induced due to imperfections in the manufacturing process of\nDeep Neural Network (DNN) accelerators are a major concern, as they negatively\nimpact the manufacturing yield of the chip fabrication process. Fault-aware\ntraining is the state-of-the-art approach for mitigating such faults. However,\nit incurs huge retraining overheads, specifically when used for large DNNs\ntrained on complex datasets. To address this issue, we propose a novel\nFault-Aware Quantization (FAQ) technique for mitigating the effects of stuck-at\npermanent faults in the on-chip weight memory of DNN accelerators at a\nnegligible overhead cost compared to fault-aware retraining while offering\ncomparable accuracy results. We propose a lookup table-based algorithm to\nachieve ultra-low model conversion time. We present extensive evaluation of the\nproposed approach using five different DNNs, i.e., ResNet-18, VGG11, VGG16,\nAlexNet and MobileNetV2, and three different datasets, i.e., CIFAR-10,\nCIFAR-100 and ImageNet. The results demonstrate that FAQ helps in maintaining\nthe baseline accuracy of the DNNs at low and moderate fault rates without\ninvolving costly fault-aware training. For example, for ResNet-18 trained on\nthe CIFAR-10 dataset, at 0.04 fault rate FAQ offers (on average) an increase of\n76.38% in accuracy. Similarly, for VGG11 trained on the CIFAR-10 dataset, at\n0.04 fault rate FAQ offers (on average) an increase of 70.47% in accuracy. The\nresults also show that FAQ incurs negligible overheads, i.e., less than 5% of\nthe time required to run 1 epoch of retraining. We additionally demonstrate the\nefficacy of our technique when used in conjunction with fault-aware retraining\nand show that the use of FAQ inside fault-aware retraining enables fast\naccuracy recovery.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:01:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12591","submitter":"Valeri Frolov P","authors":"Noah P. Baker and Valeri P. Frolov","title":"Charged Particle Motion Near a Magnetized Black Hole: A Near-Horizon\n  Approximation","comments":"14 pages, 5 figures. Typos are corrected","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.HE hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, the orbits of a charged particle near the event horizon of a\nmagnetized black hole are investigated. For a static black hole of mass $M$\nimmersed in a homogeneous magnetic field $B$, the dimensionless parameter\n$b=eBGM/ (mc^4)$ controls the radius of the circular orbits and determines the\nposition of the innermost stable circular orbit (ISCO), where $m$ and $e$ are\nthe mass and charge of the particle. For large values of the parameter $b$, the\nISCO radius can be very close to the gravitational radius. We demonstrate that\nthe properties of such orbits can be effectively and easily found by using a\nproperly constructed ``near-horizon approximation''. In particular, we show\nthat the effective potential (which determines the position of the orbit) can\nbe written in a form which is invariant under rescaling of the magnetic field,\nand as a result is universal in this sense. We also demonstrate that in the\nnear-horizon approximation, the particle orbits are stationary worldlines in\nMinkowski spacetime. We use this property to solve the equation describing slow\nchanges in the distance of the particle orbit from the horizon, which arise as\na result of the electromagnetic field radiated by the particle itself. This\nallows us to evaluate the life-time of the particle before it reaches the ISCO\nand ultimately falls into the black hole.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:01:19 GMT"},{"version":"v2","created":"Fri, 26 May 2023 19:05:33 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12592","submitter":"Ramachandran Ganesh","authors":"Eric Tan, R. Ganesh","title":"Scattering off a junction","comments":"10 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas cond-mat.mes-hall quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Scattering off a potential is a fundamental problem in quantum physics. It\nhas been studied extensively with amplitudes derived for various potentials. In\nthis article, we explore a setting with no potentials, where scattering occurs\noff a junction where many wires meet. We study this problem using a\ntight-binding discretization of a star graph geometry -- one incoming wire and\n$M$ outgoing wires intersecting at a point. When an incoming wave scatters, one\npart is reflected along the same wire while the rest is transmitted along the\nothers. Remarkably, the reflectance increases monotonically with $M$, i.e., the\ngreater the number of outgoing channels, the more the particle bounces back. In\nthe $M \\rightarrow \\infty$ limit, the wave is entirely reflected back along the\nincoming wire. We rationalize this observation by establishing a quantitative\nmapping between a junction and an on-site potential. To each junction, we\nassign an equivalent potential that produces the same reflectance. As the\nnumber of wires ($M$) increases, the equivalent potential also increases. A\nrecent article by one of us has drawn an equivalence between junctions and\npotentials from the point of view of bound state formation. Our results here\nshow that the same equivalence also holds for scattering amplitudes. We verify\nour analytic results by simulating wavepacket motion through a junction. We\nextend the wavepacket approach to two dimensions where analytic solutions\ncannot be found. An incoming wave travels on a sheet and scatters off a point\nwhere many sheets intersect. Unlike in 1D, the equivalent potential is\nmomentum-dependent. Nevertheless, for any given momentum, the equivalent\npotential grows monotonically with the number of intersecting sheets. Our\nfindings can be tested in ultracold atom setups and semiconductor structures.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:03:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12593","submitter":"Djordje Minic","authors":"Djordje Minic","title":"The Vacuum Energy Problem in Quantum Gravity and the Masses of\n  Elementary Particles","comments":"10 pages. To appear in the conference proceedings of BASIC 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This talk summarizes a new understanding of the cosmological constant\nproblem, which essentially relies on a phase-space-like computation of the\nvacuum energy, both in the realm of quantum field theory coupled to gravity,\nand in the realm of a consistent formulation of a quantum theory of gravity and\nmatter, such as string theory, combined with central properties of\ngravitational entropy as captured by the Bekenstein bound. This new\nunderstanding of the vacuum in a quantum theory of gravity and matter sheds\nlight on the Higgs mass as well as the masses of quarks and leptons.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:03:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12594","submitter":"Fanghua Ye","authors":"Fanghua Ye, Zhiyuan Hu, Emine Yilmaz","title":"Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process","comments":"To appear at ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Dialogue systems have received increasing attention while automatically\nevaluating their performance remains challenging. User satisfaction estimation\n(USE) has been proposed as an alternative. It assumes that the performance of a\ndialogue system can be measured by user satisfaction and uses an estimator to\nsimulate users. The effectiveness of USE depends heavily on the estimator.\nExisting estimators independently predict user satisfaction at each turn and\nignore satisfaction dynamics across turns within a dialogue. In order to fully\nsimulate users, it is crucial to take satisfaction dynamics into account. To\nfill this gap, we propose a new estimator ASAP (sAtisfaction eStimation via\nHAwkes Process) that treats user satisfaction across turns as an event sequence\nand employs a Hawkes process to effectively model the dynamics in this\nsequence. Experimental results on four benchmark dialogue datasets demonstrate\nthat ASAP can substantially outperform state-of-the-art baseline estimators.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:04:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12595","submitter":"Muhammad Abdullah Hanif","authors":"Muhammad Abdullah Hanif, Muhammad Shafique","title":"Reduce: A Framework for Reducing the Overheads of Fault-Aware Retraining","comments":"2 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:2304.12949","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Fault-aware retraining has emerged as a prominent technique for mitigating\npermanent faults in Deep Neural Network (DNN) hardware accelerators. However,\nretraining leads to huge overheads, specifically when used for fine-tuning\nlarge DNNs designed for solving complex problems. Moreover, as each fabricated\nchip can have a distinct fault pattern, fault-aware retraining is required to\nbe performed for each chip individually considering its unique fault map, which\nfurther aggravates the problem. To reduce the overall retraining cost, in this\nwork, we introduce the concept of resilience-driven retraining amount\nselection. To realize this concept, we propose a novel framework, Reduce, that,\nat first, computes the resilience of the given DNN to faults at different fault\nrates and with different amounts of retraining. Then, based on the resilience,\nit computes the amount of retraining required for each chip considering its\nunique fault map. We demonstrate the effectiveness of our methodology for a\nsystolic array-based DNN accelerator experiencing permanent faults in the\ncomputational array.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:09:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12596","submitter":"Shivangi Yadav","authors":"Shivangi Yadav and Arun Ross","title":"iWarpGAN: Disentangling Identity and Style to Generate Synthetic Iris\n  Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generative Adversarial Networks (GANs) have shown success in approximating\ncomplex distributions for synthetic image generation and for editing specific\nportions of an input image, particularly in faces. However, current GAN-based\nmethods for generating biometric images, such as iris, have limitations in\ncontrolling the identity of the generated images, i.e., the synthetically\ngenerated images often closely resemble images in the training dataset.\nFurther, the generated images often lack diversity in terms of the number of\nunique identities represented in them. To overcome these issues, we propose\niWarpGAN that disentangles identity and style in the context of the iris\nmodality by using two transformation pathways: Identity Transformation Pathway\nto generate unique identities from the training set, and Style Transformation\nPathway to extract the style code from a reference image and output an iris\nimage using this style. By concatenating the transformed identity code and\nreference style code, iWarpGAN generates iris images with both inter and\nintra-class variations. The efficacy of the proposed method in generating Iris\nDeepFakes is evaluated both qualitatively and quantitatively using ISO/IEC\n29794-6 Standard Quality Metrics and the VeriEye iris matcher. Finally, the\nutility of the synthetically generated images is demonstrated by improving the\nperformance of multiple deep learning based iris matchers that augment\nsynthetic data with real data during the training process.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:10:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12597","submitter":"Jinglei Cheng","authors":"Jinglei Cheng, Zhiding Liang, Rui Yang, Hang Ren, Yiyu Shi, Tongyang\n  Li, Xuehai Qian","title":"Fidelity estimator, randomized benchmarking and ZNE for quantum pulses","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Most previous research focused on designing pulse programs without\nconsidering the performance of individual elements or the final fidelity. To\nevaluate the performance of quantum pulses, it is required to know the\nnoiseless results of the pulses. However, quantum pulses can implement unitary\nmatrices that are not analytically known to the user, and pulse simulator\nusually comes with significant computational overhead. Consequently,\ndetermining fidelity of a pulse program is challenging without the knowledge of\nthe ideal results. In this paper, we propose to use reversed pulses to evaluate\nthe performance of quantum pulses, which can provide guidance to design pulse\nprograms. By employing reversed pulses, we can ensure that, in the noiseless\nsituation, the final quantum states are the same as the initial states. This\nmethod enables us to evaluate the fidelity of pulse programs by measuring the\ndifference between the final states and the initial states. Such fidelity\nestimator can tell whether the results are meaningful for quantum pulses on\nreal quantum machines. There are various quantum error correction (QEC) methods\navailable for gate circuits; however, few studies have demonstrated QEC on\npulse-level programs. In this paper, we use reversed pulses to implement zero\nnoise extrapolation (ZNE) on pulse programs and demonstrate results for\nvariational quantum eigensolver (VQE) tasks. The deviation from the idea energy\nvalue is reduced by an average of 54.1\\% with our techniques.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:12:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12598","submitter":"Takahiro Ueda","authors":"Takahiro Ueda, Satoshi Okuzumi, Akimasa Kataoka and Mario Flock","title":"Probing the Temperature Structure of the Inner Region of a\n  Protoplanetary Disk","comments":"19 pages, 25 figures, accepted for publication in A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.EP astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Midplane heating induced by disk accretion plays a key role in determining\nthe disk temperature particularly at the inner disk midplane where planets\nform. However, the efficiency of accretion heating has been not well\nconstrained by observations. We construct two-dimensional models of the Class\nII disk around CW Tau, taking into account the midplane heating. The models are\ncompared with the ALMA dust continuum observations at Bands 4, 6, 7 and 8, with\nan angular resolution of 0.1 arcsec. The observed brightness temperatures are\nalmost wavelength-indenpendent at $\\lesssim$10 au. We find that if the maximum\ndust size $a_{\\rm max}$ is $\\lesssim100~{\\rm \\mu m}$, the brightness\ntemperatures predicted by the model exceed the observed values, regardless of\nthe efficiency of accretion heating. The low observed brightness temperatures\ncan be explained if millimeter scattering reduces the intensity. If the disk is\npassive, $a_{\\rm max}$ needs to be either $\\sim150~{\\rm \\mu m}$ or $\\gtrsim$\nfew ${\\rm cm}$. The accretion heating significantly increases the brightness\ntemperature particularly when $a_{\\rm max}\\lesssim300~{\\rm \\mu m}$, and hence\n$a_{\\rm max}$ needs to be either $\\sim300~{\\rm \\mu m}$ or $\\gtrsim$ few ${\\rm\ncm}$. The midplane temperature is expected to be $\\sim$1.5-3 times higher than\nthe observed brightness temperatures, depending on the models. The dust\nsettling effectively increases the temperature of the dust responsible for the\nmillimeter emission in the active disk, which makes the model with $300~{\\rm\n\\mu m}$-sized dust overpredicts the brightness temperatures when strong\nturbulence is absent. Porous dust (porosity of 0.9) makes the accretion heating\nmore efficient so that some sort of reduction in accretion heating is required.\nFuture longer wavelength and higher angular resolution observations will help\nus constrain the heating mechanisms of the inner protoplanetary disks.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:13:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12599","submitter":"Qiming Bao","authors":"Qiming Bao, Alex Yuxuan Peng, Zhenyun Deng, Wanjun Zhong, Neset Tan,\n  Nathan Young, Yang Chen, Yonghua Zhu, Michael Witbrock, Jiamou Liu","title":"Contrastive Learning with Logic-driven Data Augmentation for Logical\n  Reasoning over Text","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Pre-trained large language model (LLM) is under exploration to perform NLP\ntasks that may require logical reasoning. Logic-driven data augmentation for\nrepresentation learning has been shown to improve the performance of tasks\nrequiring logical reasoning, but most of these data rely on designed templates\nand therefore lack generalization. In this regard, we propose an AMR-based\nlogical equivalence-driven data augmentation method (AMR-LE) for generating\nlogically equivalent data. Specifically, we first parse a text into the form of\nan AMR graph, next apply four logical equivalence laws (contraposition, double\nnegation, commutative and implication laws) on the AMR graph to construct a\nlogically equivalent/inequivalent AMR graph, and then convert it into a\nlogically equivalent/inequivalent sentence. To help the model to better learn\nthese logical equivalence laws, we propose a logical equivalence-driven\ncontrastive learning training paradigm, which aims to distinguish the\ndifference between logical equivalence and inequivalence. Our AMR-LE (Ensemble)\nachieves #2 on the ReClor leaderboard\nhttps://eval.ai/web/challenges/challenge-page/503/leaderboard/1347 . Our model\nshows better performance on seven downstream tasks, including ReClor, LogiQA,\nMNLI, MRPC, RTE, QNLI, and QQP. The source code and dataset are public at\nhttps://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning .\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:16:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12600","submitter":"Qian Huang","authors":"Qian Huang, Hongyu Ren, Peng Chen, Gregor Kr\\v{z}manc, Daniel Zeng,\n  Percy Liang, Jure Leskovec","title":"PRODIGY: Enabling In-context Learning Over Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In-context learning is the ability of a pretrained model to adapt to novel\nand diverse downstream tasks by conditioning on prompt examples, without\noptimizing any parameters. While large language models have demonstrated this\nability, how in-context learning could be performed over graphs is unexplored.\nIn this paper, we develop \\textbf{Pr}etraining \\textbf{O}ver \\textbf{D}iverse\n\\textbf{I}n-Context \\textbf{G}raph S\\textbf{y}stems (PRODIGY), the first\npretraining framework that enables in-context learning over graphs. The key\nidea of our framework is to formulate in-context learning over graphs with a\nnovel \\emph{prompt graph} representation, which connects prompt examples and\nqueries. We then propose a graph neural network architecture over the prompt\ngraph and a corresponding family of in-context pretraining objectives. With\nPRODIGY, the pretrained model can directly perform novel downstream\nclassification tasks on unseen graphs via in-context learning. We provide\nempirical evidence of the effectiveness of our framework by showcasing its\nstrong in-context learning performance on tasks involving citation networks and\nknowledge graphs. Our approach outperforms the in-context learning accuracy of\ncontrastive pretraining baselines with hard-coded adaptation by 18\\% on average\nacross all setups. Moreover, it also outperforms standard finetuning with\nlimited data by 33\\% on average with in-context learning.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:16:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12601","submitter":"L\\^e Th\\`anh D\\~ung (Tito) Nguy\\^en","authors":"L\\^e Th\\`anh D\\~ung Nguy\\^en","title":"Simply typed convertibility is TOWER-complete even for safe lambda-terms","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.PL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the following decision problem: given two simply typed\n$\\lambda$-terms, are they $\\beta$-convertible? Equivalently, do they have the\nsame normal form? It is famously non-elementary, but the precise complexity -\nnamely TOWER-complete - is lesser known. One goal of this short paper is to\npopularize this fact.\n  Our original contribution is to show that the problem stays TOWER-complete\nwhen the two input terms belong to Blum and Ong's safe $\\lambda$-calculus, a\nfragment of the simply typed $\\lambda$-calculus arising from the study of\nhigher-order recursion schemes. Previously, the best known lower bound for this\nsafe $\\beta$-convertibility problem was PSPACE-hardness. Our proof proceeds by\nreduction from the star-free expression equivalence problem, taking inspiration\nfrom the author's work with Pradic on \"implicit automata in typed\n$\\lambda$-calculi\".\n  These results also hold for $\\beta\\eta$-convertibility.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:24:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12602","submitter":"Santiago Schnell","authors":"Justin Eilertsen, Santiago Schnell, Sebastian Walcher","title":"Rigorous estimates for the quasi-steady state approximation of the\n  Michaelis-Menten reaction mechanism at low enzyme concentrations","comments":"32 pages; 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS physics.chem-ph q-bio.MN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  There is a vast amount of literature concerning the appropriateness of\nvarious perturbation parameters for the standard quasi-steady state\napproximation in the Michaelis-Menten reaction mechanism, and also concerning\nthe relevance of these parameters for the accuracy of the approximation by the\nfamiliar Michaelis-Menten equation. Typically, the arguments in the literature\nare based on (heuristic) timescale estimates, from which one cannot obtain\nreliable quantitative estimates for the error of the quasi-steady state\napproximation. We take a different approach. By combining phase plane analysis\nwith differential inequalities, we derive sharp explicit upper and lower\nestimates for the duration of the initial transient and substrate depletion\nduring this transitory phase. In addition, we obtain rigorous bounds on the\naccuracy of the standard quasi-steady state approximation in the slow dynamics\nregime. Notably, under the assumption that the quasi-steady state approximation\nis valid over the entire time course of the reaction, our error estimate is of\norder one in the Segel-Slemrod parameter.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:34:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12603","submitter":"Paul Grigas","authors":"Meng Li, Paul Grigas, Alper Atamturk","title":"On the Softplus Penalty for Constrained Convex Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study a new penalty reformulation of constrained convex optimization based\non the softplus penalty function. We develop novel and tight upper bounds on\nthe objective value gap and the violation of constraints for the solutions to\nthe penalty reformulations by analyzing the solution path of the reformulation\nwith respect to the smoothness parameter. We use these upper bounds to analyze\nthe complexity of applying gradient methods, which are advantageous when the\nnumber of constraints is large, to the reformulation.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:37:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12604","submitter":"Takashi Ishizuka","authors":"Takashi Ishizuka","title":"Graphical One-Sided Markets with Exchange Costs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper proposes a new one-sided matching market model in which every\nagent has a cost function that is allowed to take a negative value. Our model\naims to capture the situation where some agents can profit by exchanging their\nobtained goods with other agents. We formulate such a model based on a\ngraphical one-sided matching market, introduced by Massand and Simon [Massand\nand Simon, IJCAI 2019]. We examine the existence of stable outcomes for such a\nmarket. We prove that there is an instance that has no core-stable allocation.\nOn the other hand, we guarantee the existence of two-stable allocations even\nwhere exchange costs exist. However, it is PLS-hard to find a two-stable\nallocation for a market with exchange costs even if the maximum degree of the\ngraph is five.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:39:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12605","submitter":"Daniel Fernandes Gomes","authors":"Daniel Fernandes Gomes and Paolo Paoletti and Shan Luo","title":"Beyond Flat GelSight Sensors: Simulation of Optical Tactile Sensors of\n  Complex Morphologies for Sim2Real Learning","comments":null,"journal-ref":"Robotics: Science and Systems 2023","doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, several morphologies, each with its advantages, have been proposed\nfor the \\textit{GelSight} high-resolution tactile sensors. However, existing\nsimulation methods are limited to flat-surface sensors, which prevents their\nusage with the newer sensors of non-flat morphologies in Sim2Real experiments.\nIn this paper, we extend a previously proposed GelSight simulation method\ndeveloped for flat-surface sensors and propose a novel method for curved\nsensors. In particular, we address the simulation of light rays travelling\nthrough a curved tactile membrane in the form of geodesic paths. The method is\nvalidated by simulating the finger-shaped GelTip sensor and comparing the\ngenerated synthetic tactile images against the corresponding real images. Our\nextensive experiments show that combining the illumination generated from the\ngeodesic paths, with a background image from the real sensor, produces the best\nresults when compared to the lighting generated by direct linear paths in the\nsame conditions. As the method is parameterised by the sensor mesh, it can be\napplied in principle to simulate a tactile sensor of any morphology. The\nproposed method not only unlocks simulating existing optical tactile sensors of\ncomplex morphologies but also enables experimenting with sensors of novel\nmorphologies, before the fabrication of the real sensor. Project website:\nhttps://danfergo.github.io/geltip-sim\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:51:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12606","submitter":"Andrew Rouditchenko","authors":"Andrew Rouditchenko, Sameer Khurana, Samuel Thomas, Rogerio Feris,\n  Leonid Karlinsky, Hilde Kuehne, David Harwath, Brian Kingsbury, James Glass","title":"Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech\n  Pre-Training for Adaptation to Unseen Languages","comments":"Accepted at Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent models such as XLS-R and Whisper have made multilingual speech\ntechnologies more accessible by pre-training on audio from around 100 spoken\nlanguages each. However, there are thousands of spoken languages worldwide, and\nadapting to new languages is an important problem. In this work, we aim to\nunderstand which model adapts better to languages unseen during pre-training.\nWe fine-tune both models on 13 unseen languages and 18 seen languages. Our\nresults show that the number of hours seen per language and language family\nduring pre-training is predictive of how the models compare, despite the\nsignificant differences in the pre-training methods.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:53:12 GMT"},{"version":"v2","created":"Wed, 31 May 2023 01:27:41 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.12607","submitter":"Drew Geller","authors":"Drew A. Geller and Johanna L. Mathieu","title":"Tunable Experimental Testbed for Evaluating Load Coordination Methods","comments":"20 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Driven by the need to offset the variability of wind and solar generation on\nthe electrical grid, development of load controls is a highly active field in\nthe engineering literature. However, practical use of residential loads for\ngrid balancing and ancillary services remains rare, in part due to the relative\ncost of communicating with hordes of small loads and also due to the limited\nexperimentation done so far to demonstrate reliable operation. To establish a\nbasis for the safe and reliable use of fleets of small compressor loads as\ndistributed energy resources (DERs), we have constructed an experimental\ntestbed in a laboratory, so that load coordination schemes can be tested at\nextreme conditions within a laboratory environment. This experiment can be used\nto tune a simulation testbed to which it can then be linked, thereby augmenting\nthe effective size of the ensemble of loads. Control algorithms can simply be\nplugged in for testing. Modeling of the system was done both to demonstrate the\nexperimental testbed's behavior and also to understand how to tune the behavior\nof each participating model house in the system. Implementing this testbed has\nbeen useful for the rapid turnaround of experiments on various control types,\nand it enables testing year-round without the constraints and limitations\narising in seasonal field tests with real human participants.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 23:58:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12608","submitter":"Jasper van de Kreeke","authors":"Raf Bocklandt, Jasper van de Kreeke","title":"Deformed Mirror Symmetry for Punctured Surfaces","comments":"123 pages, multiple illustrations","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.RT","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Mirror symmetry originally envisions a correspondence between deformations of\nthe A-side and deformations of the B-side. In this paper, we achieve an\nexplicit correspondence in the case of punctured surfaces.\n  The starting point is the noncommutative mirror equivalence $\n\\operatorname{Gtl} Q \\cong \\operatorname{mf} (\\operatorname{Jac} \\check{Q},\n\\ell) $ for a punctured surface $ Q $. We pick a deformation $\n\\operatorname{Gtl}_q Q $ which captures a large part of the deformation theory\nand includes the relative Fukaya category. To find the corresponding\ndeformation of $ \\operatorname{mf} (\\operatorname{Jac} \\check{Q}, \\ell) $, we\ndeform work of Cho-Hong-Lau which interprets mirror symmetry as Koszul duality.\nAs result we explicitly obtain the corresponding deformation $\n\\operatorname{mf} (\\operatorname{Jac}_q \\check{Q}, \\ell_q) $ together with a\ndeformed mirror functor $ \\operatorname{Gtl}_q Q \\xrightarrow{\\sim}\n\\operatorname{mf} (\\operatorname{Jac}_q \\check{Q}, \\ell_q) $.\n  The bottleneck is to verify that the algebra $ \\operatorname{Jac}_q \\check{Q}\n$ is indeed a (flat) deformation of $ \\operatorname{Jac} \\check{Q} $. We\nachieve this by deploying a result of Berger-Ginzburg-Taillefer on deformations\nof CY3 algebras, which however requires the relations to be homogeneous. We\nshow how to replace this homogeneity requirement by a simple boundedness\ncondition and obtain flatness of $ \\operatorname{Jac}_q \\check{Q} $ for almost\nall $ Q $.\n  We finish the paper with examples, including a full treatment of the\n3-punctured sphere and 4-punctured torus. With the help of our computations in\narXiv:2305.09112, we describe $ \\operatorname{Jac}_q \\check{Q} $ explicitly. It\nturns out that the deformed potential $ \\ell_q $ is still central in $\n\\operatorname{Jac}_q \\check{Q} $, in contrast to the popular slogan that\ncentral elements do not survive under deformation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:04:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12609","submitter":"Sang Hyun Park","authors":"Sang Hyun Park, Michael Sammon, Eugene Mele, Tony Low","title":"Helical boundary modes from synthetic spin in a plasmonic lattice","comments":"14 pages, 5 figures, supplementary information included","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Artificial lattices have been used as a platform to extend the application of\ntopological physics beyond electronic systems. Here, using the two-dimensional\nLieb lattice as a prototypical example, we show that an array of disks which\neach support localized plasmon modes give rise to an analog of the quantum spin\nHall state enforced by a synthetic time reversal symmetry. We find that an\neffective next-nearest-neighbor coupling mechanism intrinsic to the plasmonic\ndisk array introduces a nontrivial $Z_2$ topological order and gaps out the\nBloch spectrum. A faithful mapping of the plasmonic system onto a tight-binding\nmodel is developed and shown to capture its essential topological signatures.\nFull wave numerical simulations of graphene disks arranged in a Lieb lattice\nconfirm the existence of propagating helical boundary modes in the nontrivial\nband gap.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:17:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12610","submitter":"Alexandre Vieira PhD","authors":"J. S. Porto and A. R. Vieira","title":"Scale anomaly in a Lorentz and CPT-violating Quantum Electrodynamics","comments":"9 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We compute the classical and the quantum breaking of the dilatation current\nin the minimal Lorentz and CPT-violating quantum electrodynamics. At the\nclassical level, scale symmetry is broken by the general mass term\n\\bar{\\psi}M\\psi and the Chern-Simons-like term. At the quantum level, it is\nbroken by all expected observable fermion operators in the massless limit.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:21:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12611","submitter":"Jun-Jin Peng","authors":"Jun-Jin Peng, Yao Wang, Wei-Jie Guo","title":"Conserved quantities for asymptotically AdS spacetimes in quadratic\n  curvature gravity in terms of a rank-4 tensor","comments":"40 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the conserved quantities associated to Killing isometries for\nasymptotically AdS spacetimes within the framework of quadratic-curvature\ngravity. By constructing a rank-4 tensor possessing the same index symmetries\nas the ones of the Riemann tensor, we propose a 2-form potential resembling the\nNoether one for quadratic-curvature gravity. Such a potential is compared with\nthe results via other methods existing in the literature to establish the\nequivalence. Then this potential is adopted to define conserved quantities of\nasymptotically AdS spacetimes. As applications, we explicitly compute the mass\nof static spherically-symmetric spacetimes, as well as the mass and the angular\nmomentum for rotating spacetimes, such as the four(higher)-dimensional Kerr-AdS\nblack holes and black strings embedded in quadratic-curvature gravities.\nParticularly, we emphasize the conserved charges of Einstein-Gauss-Bonnet, Weyl\nand critical gravities, together with the ones for the asymptotically AdS\nsolutions satisfying vacuum Einstein field equations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:32:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12612","submitter":"Luke Gessler","authors":"Luke Gessler","title":"PrOnto: Language Model Evaluations for 859 Languages","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Evaluation datasets are critical resources for measuring the quality of\npretrained language models. However, due to the high cost of dataset\nannotation, these resources are scarce for most languages other than English,\nmaking it difficult to assess the quality of language models. In this work, we\npresent a new method for evaluation dataset construction which enables any\nlanguage with a New Testament translation to receive a suite of evaluation\ndatasets suitable for pretrained language model evaluation. The method\ncritically involves aligning verses with those in the New Testament portion of\nEnglish OntoNotes, and then projecting annotations from English to the target\nlanguage, with no manual annotation required. We apply this method to 1051 New\nTestament translations in 859 and make them publicly available. Additionally,\nwe conduct experiments which demonstrate the efficacy of our method for\ncreating evaluation tasks which can assess language model quality.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:33:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12613","submitter":"Oliver Knill","authors":"Oliver Knill","title":"Cohomology of open sets","comments":"26 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DM math.CO math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  If G is a finite abstract simplicial complex and K is a subcomplex of G and\nU=G-K is the open complement of K in G, the Betti vectors of K and U and G\nsatisfy the inequality b(G) less or equal b(K)+b(U).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:41:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12614","submitter":"Yaohui Guo","authors":"Yaohui Guo, X. Jessie Yang, Cong Shi","title":"Enabling Team of Teams: A Trust Inference and Propagation (TIP) Model in\n  Multi-Human Multi-Robot Teams","comments":"In Proceedings of Robotics: Science and Systems, 2023, Daegu, Korea.\n  arXiv admin note: text overlap with arXiv:2301.10928","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Trust has been identified as a central factor for effective human-robot\nteaming. Existing literature on trust modeling predominantly focuses on dyadic\nhuman-autonomy teams where one human agent interacts with one robot. There is\nlittle, if not no, research on trust modeling in teams consisting of multiple\nhuman agents and multiple robotic agents.\n  To fill this research gap, we present the trust inference and propagation\n(TIP) model for trust modeling in multi-human multi-robot teams. In a\nmulti-human multi-robot team, we postulate that there exist two types of\nexperiences that a human agent has with a robot: direct and indirect\nexperiences. The TIP model presents a novel mathematical framework that\nexplicitly accounts for both types of experiences. To evaluate the model, we\nconducted a human-subject experiment with 15 pairs of participants (${N=30}$).\nEach pair performed a search and detection task with two drones. Results show\nthat our TIP model successfully captured the underlying trust dynamics and\nsignificantly outperformed a baseline model. To the best of our knowledge, the\nTIP model is the first mathematical framework for computational trust modeling\nin multi-human multi-robot teams.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:43:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12615","submitter":"Gui-Qiang G. Chen","authors":"Gui-Qiang G. Chen, Feimin Huang, Tianhong Li, Weiqiang Wang, Yong Wang","title":"Global Finite-Energy Solutions of the Compressible Euler-Poisson\n  Equations for General Pressure Laws with Spherical Symmetry","comments":"70 pages, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We are concerned with global finite-energy solutions of the three-dimensional\ncompressible Euler-Poisson equations with {\\it gravitational potential} and\n{\\it general pressure law}, especially including the constitutive equation of\n{\\it white dwarf stars}. In this paper, we construct global finite-energy\nsolutions with spherical symmetry of the Cauchy problem for the Euler-Poisson\nequations as the inviscid limit of the corresponding compressible\nNavier-Stokes-Poisson equations. The strong convergence of the vanishing\nviscosity solutions is achieved through entropy analysis, uniform estimates in\n$L^p$, and a more general compensated compactness framework via several new\nmain ingredients. A key estimate is first established for the integrability of\nthe density over unbounded domains independent of the vanishing viscosity\ncoefficient. Then a special entropy pair is carefully designed via solving a\nGoursat problem for the entropy equation such that a higher integrability of\nthe velocity is established, which is a crucial step. Moreover, the weak\nentropy kernel for the general pressure law and its fractional derivatives of\nthe required order near vacuum ($\\rho=0$) and far-field ($\\rho=\\infty$) are\ncarefully analyzed. Owing to the generality of the pressure law, only the\n$W^{-1,p}_{\\mathrm{loc}}$-compactness of weak entropy dissipation measures with\n$p\\in [1,2)$ can be obtained; this is rescued by the equi-integrability of weak\nentropy pairs which can be established by the estimates obtained above, so that\nthe div-curl lemma still applies. Finally, based on the above analysis of weak\nentropy pairs, the $L^p$ compensated compactness framework for the compressible\nEuler equations with general pressure law is established. This new compensated\ncompactness framework and the techniques developed in this paper should be\nuseful for solving further nonlinear problems with similar features.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:45:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12616","submitter":"Isaac Gibbs","authors":"Isaac Gibbs, John J. Cherian, Emmanuel J. Cand\\`es","title":"Conformal Prediction With Conditional Guarantees","comments":"54 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the problem of constructing distribution-free prediction sets\nwith finite-sample conditional guarantees. Prior work has shown that it is\nimpossible to provide exact conditional coverage universally in finite samples.\nThus, most popular methods only provide marginal coverage over the covariates.\nThis paper bridges this gap by defining a spectrum of problems that interpolate\nbetween marginal and conditional validity. We motivate these problems by\nreformulating conditional coverage as coverage over a class of covariate\nshifts. When the target class of shifts is finite dimensional, we show how to\nsimultaneously obtain exact finite sample coverage over all possible shifts.\nFor example, given a collection of protected subgroups, our algorithm outputs\nintervals with exact coverage over each group. For more flexible, infinite\ndimensional classes where exact coverage is impossible, we provide a simple\nprocedure for quantifying the gap between the coverage of our algorithm and the\ntarget level. Moreover, by tuning a single hyperparameter, we allow the\npractitioner to control the size of this gap across shifts of interest. Our\nmethods can be easily incorporated into existing split conformal inference\npipelines, and thus can be used to quantify the uncertainty of modern black-box\nalgorithms without distributional assumptions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:49:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12617","submitter":"Chunhe Li","authors":"Zihao Chen, Jia Lu, Xing-Ming Zhao, Haiyang Yu, Chunhe Li","title":"Energy landscape reveals the underlying mechanism of cancer-adipose\n  conversion with gene network models","comments":"35 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.MN q-bio.QM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Cancer is a systemic heterogeneous disease involving complex molecular\nnetworks. Tumor formation involves epithelial-mesenchymal transition (EMT),\nwhich promotes both metastasis and plasticity of cancer cells. Recent\nexperiments proposed that cancer cells can be transformed into adipocytes with\ncombination drugs. However, the underlying mechanisms for how these drugs work\nfrom molecular network perspective remain elusive. To reveal the mechanism of\ncancer-adipose conversion (CAC), we adopt a systems biology approach by combing\nmathematical modeling and molecular experiments based on the underlying\nmolecular regulatory network. We identified four types of attractors which\ncorrespond to epithelial (E), mesenchymal (M), adipose (A) and\npartial/intermediate EMT (P) cell states on the CAC landscape. Landscape and\ntransition path results illustrate that the intermediate states play critical\nroles in cancer to adipose transition. Through a landscape control strategy, we\nidentified two new therapeutic strategies for drug combinations to promote CAC.\nWe further verified these predictions by molecular experiments in different\ncell lines. Our combined computational and experimental approach provides a\npowerful tool to explore molecular mechanisms for cell fate transitions in\ncancer networks. Our results revealed the underlying mechanism for intermediate\ncell states governing the CAC, and identified new potential drug combinations\nto induce cancer adipogenesis.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:49:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12618","submitter":"Jiahao Chen","authors":"Jiahao Chen, Yurou Liu, Jiangmeng Li, Bing Su, Jirong Wen","title":"Atomic and Subgraph-aware Bilateral Aggregation for Molecular\n  Representation Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI q-bio.QM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Molecular representation learning is a crucial task in predicting molecular\nproperties. Molecules are often modeled as graphs where atoms and chemical\nbonds are represented as nodes and edges, respectively, and Graph Neural\nNetworks (GNNs) have been commonly utilized to predict atom-related properties,\nsuch as reactivity and solubility. However, functional groups (subgraphs) are\nclosely related to some chemical properties of molecules, such as efficacy, and\nmetabolic properties, which cannot be solely determined by individual atoms. In\nthis paper, we introduce a new model for molecular representation learning\ncalled the Atomic and Subgraph-aware Bilateral Aggregation (ASBA), which\naddresses the limitations of previous atom-wise and subgraph-wise models by\nincorporating both types of information. ASBA consists of two branches, one for\natom-wise information and the other for subgraph-wise information. Considering\nexisting atom-wise GNNs cannot properly extract invariant subgraph features, we\npropose a decomposition-polymerization GNN architecture for the subgraph-wise\nbranch. Furthermore, we propose cooperative node-level and graph-level\nself-supervised learning strategies for ASBA to improve its generalization. Our\nmethod offers a more comprehensive way to learn representations for molecular\nproperty prediction and has broad potential in drug and material discovery\napplications. Extensive experiments have demonstrated the effectiveness of our\nmethod.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 00:56:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12619","submitter":"Yaping Sun","authors":"Yaping Sun, Hao Chen, Xiaodong Xu, Ping Zhang, Shuguang Cui","title":"Zero-shot Multi-level Feature Transmission Policy Powered by Semantic\n  Knowledge Base","comments":"6 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Remote zero-shot object recognition, i.e., offloading zero-shot object\nrecognition task from one mobile device to remote mobile edge computing (MEC)\nserver or another mobile device, has become a common and important task to\nsolve for 6G. In order to tackle this problem, this paper first establishes a\nzero-shot multi-level feature extractor, which projects the image into visual,\nsemantic, as well as intermediate feature space in a lightweight way. Then,\nthis paper proposes a novel multi-level feature transmission framework powered\nby semantic knowledge base (SKB), and characterizes the semantic loss and\nrequired transmission latency at each level. Under this setup, this paper\nformulates the multi-level feature transmission optimization problem to\nminimize the semantic loss under the end-to-end latency constraint. The\noptimization problem, however, is a multi-choice knapsack problem, and thus\nvery difficult to be optimized. To resolve this issue, this paper proposes an\nefficient algorithm based on convex concave procedure to find a high-quality\nsolution. Numerical results show that the proposed design outperforms the\nbenchmarks, and illustrate the tradeoff between the transmission latency and\nzero-shot classification accuracy, as well as the effects of the SKBs at both\nthe transmitter and receiver on classification accuracy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:01:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12620","submitter":"Ioana Baldini","authors":"Ioana Baldini, Chhavi Yadav, Payel Das, Kush R. Varshney","title":"Keeping Up with the Language Models: Robustness-Bias Interplay in NLI\n  Data and Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Auditing unwanted social bias in language models (LMs) is inherently hard due\nto the multidisciplinary nature of the work. In addition, the rapid evolution\nof LMs can make benchmarks irrelevant in no time. Bias auditing is further\ncomplicated by LM brittleness: when a presumably biased outcome is observed, is\nit due to model bias or model brittleness? We propose enlisting the models\nthemselves to help construct bias auditing datasets that remain challenging,\nand introduce bias measures that distinguish between types of model errors.\nFirst, we extend an existing bias benchmark for NLI (BBNLI) using a combination\nof LM-generated lexical variations, adversarial filtering, and human\nvalidation. We demonstrate that the newly created dataset (BBNLInext) is more\nchallenging than BBNLI: on average, BBNLI-next reduces the accuracy of\nstate-of-the-art NLI models from 95.3%, as observed by BBNLI, to 58.6%. Second,\nwe employ BBNLI-next to showcase the interplay between robustness and bias, and\nthe subtlety in differentiating between the two. Third, we point out\nshortcomings in current bias scores used in the literature and propose bias\nmeasures that take into account pro-/anti-stereotype bias and model\nbrittleness. We will publicly release the BBNLI-next dataset to inspire\nresearch on rapidly expanding benchmarks to keep up with model evolution, along\nwith research on the robustness-bias interplay in bias auditing.\n  Note: This paper contains offensive text examples.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:02:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12621","submitter":"Ashish Sinha","authors":"Ashish Sinha, Jeremy Kawahara, Arezou Pakzad, Kumar Abhishek, Matthieu\n  Ruthven, Enjie Ghorbel, Anis Kacem, Djamila Aouada, Ghassan Hamarneh","title":"DermSynth3D: Synthesis of in-the-wild Annotated Dermatology Images","comments":"Preprint. 21 pages. Submitted to MedIA","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In recent years, deep learning (DL) has shown great potential in the field of\ndermatological image analysis. However, existing datasets in this domain have\nsignificant limitations, including a small number of image samples, limited\ndisease conditions, insufficient annotations, and non-standardized image\nacquisitions. To address these shortcomings, we propose a novel framework\ncalled DermSynth3D. DermSynth3D blends skin disease patterns onto 3D textured\nmeshes of human subjects using a differentiable renderer and generates 2D\nimages from various camera viewpoints under chosen lighting conditions in\ndiverse background scenes. Our method adheres to top-down rules that constrain\nthe blending and rendering process to create 2D images with skin conditions\nthat mimic in-the-wild acquisitions, ensuring more meaningful results. The\nframework generates photo-realistic 2D dermoscopy images and the corresponding\ndense annotations for semantic segmentation of the skin, skin conditions, body\nparts, bounding boxes around lesions, depth maps, and other 3D scene\nparameters, such as camera position and lighting conditions. DermSynth3D allows\nfor the creation of custom datasets for various dermatology tasks. We\ndemonstrate the effectiveness of data generated using DermSynth3D by training\nDL models on synthetic data and evaluating them on various dermatology tasks\nusing real 2D dermatological images. We make our code publicly available at\nhttps://github.com/sfu-mial/DermSynth3D.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:14:30 GMT"},{"version":"v2","created":"Thu, 25 May 2023 18:12:47 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12622","submitter":"Ming Ying Yang","authors":"Ming Ying Yang, Gloria Hyunjung Kwak, Tom Pollard, Leo Anthony Celi,\n  Marzyeh Ghassemi","title":"Evaluating the Impact of Social Determinants on Health Prediction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Social determinants of health (SDOH) -- the conditions in which people live,\ngrow, and age -- play a crucial role in a person's health and well-being. There\nis a large, compelling body of evidence in population health studies showing\nthat a wide range of SDOH is strongly correlated with health outcomes. Yet, a\nmajority of the risk prediction models based on electronic health records (EHR)\ndo not incorporate a comprehensive set of SDOH features as they are often noisy\nor simply unavailable. Our work links a publicly available EHR database,\nMIMIC-IV, to well-documented SDOH features. We investigate the impact of such\nfeatures on common EHR prediction tasks across different patient populations.\nWe find that community-level SDOH features do not improve model performance for\na general patient population, but can improve data-limited model fairness for\nspecific subpopulations. We also demonstrate that SDOH features are vital for\nconducting thorough audits of algorithmic biases beyond protective attributes.\nWe hope the new integrated EHR-SDOH database will enable studies on the\nrelationship between community health and individual outcomes and provide new\nbenchmarks to study algorithmic biases beyond race, gender, and age.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:27:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12623","submitter":"Archana Vadakattu","authors":"Archana Vadakattu, Michelle Blom, Adrian R. Pearce","title":"Strategy Extraction in Single-Agent Games","comments":"9 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ability to continuously learn and adapt to new situations is one where\nhumans are far superior compared to AI agents. We propose an approach to\nknowledge transfer using behavioural strategies as a form of transferable\nknowledge influenced by the human cognitive ability to develop strategies. A\nstrategy is defined as a partial sequence of events - where an event is both\nthe result of an agent's action and changes in state - to reach some predefined\nevent of interest. This information acts as guidance or a partial solution that\nan agent can generalise and use to make predictions about how to handle unknown\nobserved phenomena. As a first step toward this goal, we develop a method for\nextracting strategies from an agent's existing knowledge that can be applied in\nmultiple contexts. Our method combines observed event frequency information\nwith local sequence alignment techniques to find patterns of significance that\nform a strategy. We show that our method can identify plausible strategies in\nthree environments: Pacman, Bank Heist and a dungeon-crawling video game. Our\nevaluation serves as a promising first step toward extracting knowledge for\ngeneralisation and, ultimately, transfer learning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:28:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12624","submitter":"Yuanyuan Luan","authors":"Roger S. Zoh, Yuanyuan Luan, Erjia Cui, Xiaoxin Yu, Heyang Ji, Sneha\n  Jadhav, Carmen D. Tekwe","title":"Scalable regression calibration approaches to correcting measurement\n  error in multi-level generalized functional linear regression models with\n  heteroscedastic measurement errors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Wearable devices permit the continuous monitoring of biological processes,\nsuch as blood glucose metabolism, and behavior, such as sleep quality and\nphysical activity. The continuous monitoring often occurs in epochs of 60\nseconds over multiple days, resulting in high dimensional longitudinal curves\nthat are best described and analyzed as functional data. From this perspective,\nthe functional data are smooth, latent functions obtained at discrete time\nintervals and prone to homoscedastic white noise. However, the assumption of\nhomoscedastic errors might not be appropriate in this setting because the\ndevices collect the data serially. While researchers have previously addressed\nmeasurement error in scalar covariates prone to errors, less work has been done\non correcting measurement error in high dimensional longitudinal curves prone\nto heteroscedastic errors. We present two new methods for correcting\nmeasurement error in longitudinal functional curves prone to complex\nmeasurement error structures in multi-level generalized functional linear\nregression models. These methods are based on two-stage scalable regression\ncalibration. We assume that the distribution of the scalar responses and the\nsurrogate measures prone to heteroscedastic errors both belong in the\nexponential family and that the measurement errors follow Gaussian processes.\nIn simulations and sensitivity analyses, we established some finite sample\nproperties of these methods. In our simulations, both regression calibration\nmethods for correcting measurement error performed better than estimators based\non averaging the longitudinal functional data and using observations from a\nsingle day. We also applied the methods to assess the relationship between\nphysical activity and type 2 diabetes in community dwelling adults in the\nUnited States who participated in the National Health and Nutrition Examination\nSurvey.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:30:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12625","submitter":"Sai Ravela","authors":"Erina Yamaguchi and Sai Ravela","title":"Multirotor Ensemble Model Predictive Control I: Simulation Experiments","comments":"11 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.LG cs.RO cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Nonlinear receding horizon model predictive control is a powerful approach to\ncontrolling nonlinear dynamical systems. However, typical approaches that use\nthe Jacobian, adjoint, and forward-backward passes may lose fidelity and\nefficacy for highly nonlinear problems. Here, we develop an Ensemble Model\nPredictive Control (EMPC) approach wherein the forward model remains fully\nnonlinear, and an ensemble-represented Gaussian process performs the backward\ncalculations to determine optimal gains for the initial time. EMPC admits black\nbox, possible non-differentiable models, simulations are executable in parallel\nover long horizons, and control is uncertainty quantifying and applicable to\nstochastic settings. We construct the EMPC for terminal control and regulation\nproblems and apply it to the control of a quadrotor in a simulated,\nidentical-twin study. Results suggest that the easily implemented approach is\npromising and amenable to controlling autonomous robotic systems with added\nstate/parameter estimation and parallel computing.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:32:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12626","submitter":"Walter Goodwin","authors":"Walter Goodwin, Ioannis Havoutis, Ingmar Posner","title":"You Only Look at One: Category-Level Object Representations for Pose\n  Estimation From a Single Example","comments":"16 pages, 6 figures, CoRL 2022","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.CV","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  In order to meaningfully interact with the world, robot manipulators must be\nable to interpret objects they encounter. A critical aspect of this\ninterpretation is pose estimation: inferring quantities that describe the\nposition and orientation of an object in 3D space. Most existing approaches to\npose estimation make limiting assumptions, often working only for specific,\nknown object instances, or at best generalising to an object category using\nlarge pose-labelled datasets. In this work, we present a method for achieving\ncategory-level pose estimation by inspection of just a single object from a\ndesired category. We show that we can subsequently perform accurate pose\nestimation for unseen objects from an inspected category, and considerably\noutperform prior work by exploiting multi-view correspondences. We demonstrate\nthat our method runs in real-time, enabling a robot manipulator equipped with\nan RGBD sensor to perform online 6D pose estimation for novel objects. Finally,\nwe showcase our method in a continual learning setting, with a robot able to\ndetermine whether objects belong to known categories, and if not, use active\nperception to produce a one-shot category representation for subsequent pose\nestimation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:32:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12627","submitter":"Zhibin Gou","authors":"Zhibin Gou, Qingyan Guo, Yujiu Yang","title":"MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction","comments":"Accepted to ACL 2023 Main Conference","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Generative methods greatly promote aspect-based sentiment analysis via\ngenerating a sequence of sentiment elements in a specified format. However,\nexisting studies usually predict sentiment elements in a fixed order, which\nignores the effect of the interdependence of the elements in a sentiment tuple\nand the diversity of language expression on the results. In this work, we\npropose Multi-view Prompting (MvP) that aggregates sentiment elements generated\nin different orders, leveraging the intuition of human-like problem-solving\nprocesses from different views. Specifically, MvP introduces element order\nprompts to guide the language model to generate multiple sentiment tuples, each\nwith a different element order, and then selects the most reasonable tuples by\nvoting. MvP can naturally model multi-view and multi-task as permutations and\ncombinations of elements, respectively, outperforming previous task-specific\ndesigned methods on multiple ABSA tasks with a single model. Extensive\nexperiments show that MvP significantly advances the state-of-the-art\nperformance on 10 datasets of 4 benchmark tasks, and performs quite effectively\nin low-resource settings. Detailed evaluation verified the effectiveness,\nflexibility, and cross-task transferability of MvP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:32:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12628","submitter":"Xianchao Wu","authors":"Xianchao Wu","title":"Duplex Diffusion Models Improve Speech-to-Speech Translation","comments":"11 pages, 3 figures. Accepted by ACL 2023 findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG cs.SD eess.AS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Speech-to-speech translation is a typical sequence-to-sequence learning task\nthat naturally has two directions. How to effectively leverage bidirectional\nsupervision signals to produce high-fidelity audio for both directions?\nExisting approaches either train two separate models or a multitask-learned\nmodel with low efficiency and inferior performance. In this paper, we propose a\nduplex diffusion model that applies diffusion probabilistic models to both\nsides of a reversible duplex Conformer, so that either end can simultaneously\ninput and output a distinct language's speech. Our model enables reversible\nspeech translation by simply flipping the input and output ends. Experiments\nshow that our model achieves the first success of reversible speech translation\nwith significant improvements of ASR-BLEU scores compared with a list of\nstate-of-the-art baselines.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:39:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12629","submitter":"Sanghoon Lee","authors":"Sanghoon Lee","title":"On the Lebesgue Property of Dir-stationary $Q$-valued functions","comments":"All comments welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We prove that a stationary $Q$-valued function possesses the Lebesgue\nproperty at all points within its domain. We define a generalized\nCampanato-Morrey spaces tailored to our problem and find that if a stationary\nQ-valued function belongs to a specific generalized Campanato-Morrey space of a\nparticular order, it is continuous.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:40:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12630","submitter":"Yu Zhang","authors":"Xiangjun Wang, Yu Zhang","title":"A correspondence between higher Adams differentials and higher algebraic\n  Novikov differentials at odd primes","comments":"10 pages. Accepted version, to appear in Proc. Amer. Math. Soc","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the higher differentials of the classical Adams spectral\nsequence at odd primes. In particular, we follow the ``cofiber of $\\tau$\nphilosophy'' of Gheorghe, Isaksen, Wang, and Xu to show that higher Adams\ndifferentials agree with their corresponding higher algebraic Novikov\ndifferentials in a certain range.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:44:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12631","submitter":"Feng Wang","authors":"Feng Wang and Chuan-Fu Yang","title":"Incomplete inverse problem for Dirac operator with constant delay","comments":"arXiv admin note: substantial text overlap with arXiv:2305.10752","journal-ref":null,"doi":null,"report-no":null,"categories":"math.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we consider Dirac-type operators with a constant delay less\nthan two-fifths of the interval and not less than one-third of the interval.\nFor our considered Dirac-type operators, an incomplete inverse spectral problem\nis studied. Specifically, when two complex potentials are known a priori on a\ncertain subinterval, reconstruction of the two potentials on the entire\ninterval is studied from complete spectra of two boundary value problems with\none common boundary condition. The uniqueness of the solution of the inverse\nproblem is proved. A constructive method is developed for the solution of the\ninverse problem.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:49:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12632","submitter":"Masato Hisakado","authors":"Masato Hisakado and Takuya Kaneko","title":"Deformation of Marchenko-Pastur distribution for the correlated time\n  series","comments":"20 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech q-fin.ST","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We study the eigenvalue of the Wishart matrix which is created form the time\nseries with the temporal correlation. When there is no correlation, the\neigenvalue distribution of the Wishart matrix is known as the Marchenko-Pastur\ndistribution (MPD) in the double scaling limit. When there is the temporal\ncorrelation, the eigenvalue distribution converges to the deformed MPD which\nhas longer tail and higher peak than the MPD. We discuss the moments of the\ndistribution and the convergence to the deformed MPD. We show the second moment\nincreases as the temporal correlation increases. When the temporal correlation\nis the power decay, we can confirm the phase transition. When $\\gamma>1/2$\nwhich is the power index, the second moment of the distribution is finite and\nthe largest eigenvalue is finite. On the other hand, when $\\gamma\\leq 1/2$, the\nsecond moment is infinite and the maximum eigenvalue is infinite.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:54:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12633","submitter":"Jiayu Chen","authors":"Jiayu Chen, Dipesh Tamboli, Tian Lan, Vaneet Aggarwal","title":"Multi-task Hierarchical Adversarial Inverse Reinforcement Learning","comments":"This paper is accepted at ICML 2023. arXiv admin note: text overlap\n  with arXiv:2210.01969","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-task Imitation Learning (MIL) aims to train a policy capable of\nperforming a distribution of tasks based on multi-task expert demonstrations,\nwhich is essential for general-purpose robots. Existing MIL algorithms suffer\nfrom low data efficiency and poor performance on complex long-horizontal tasks.\nWe develop Multi-task Hierarchical Adversarial Inverse Reinforcement Learning\n(MH-AIRL) to learn hierarchically-structured multi-task policies, which is more\nbeneficial for compositional tasks with long horizons and has higher expert\ndata efficiency through identifying and transferring reusable basic skills\nacross tasks. To realize this, MH-AIRL effectively synthesizes context-based\nmulti-task learning, AIRL (an IL approach), and hierarchical policy learning.\nFurther, MH-AIRL can be adopted to demonstrations without the task or skill\nannotations (i.e., state-action pairs only) which are more accessible in\npractice. Theoretical justifications are provided for each module of MH-AIRL,\nand evaluations on challenging multi-task settings demonstrate superior\nperformance and transferability of the multi-task policies learned with MH-AIRL\nas compared to SOTA MIL baselines.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:58:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12634","submitter":"Zhisong Zhang","authors":"Zhisong Zhang, Emma Strubell, Eduard Hovy","title":"Data-efficient Active Learning for Structured Prediction with Partial\n  Annotation and Self-Training","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this work we propose a pragmatic method that reduces the annotation cost\nfor structured label spaces using active learning. Our approach leverages\npartial annotation, which reduces labeling costs for structured outputs by\nselecting only the most informative substructures for annotation. We also\nutilize selftraining to incorporate the current model's automatic predictions\nas pseudo-labels for unannotated sub-structures. A key challenge in effectively\ncombining partial annotation with self-training to reduce annotation cost is\ndetermining which sub-structures to select to label. To address this challenge\nwe adopt an error estimator to decide the partial selection ratio adaptively\naccording to the current model's capability. In evaluations spanning four\nstructured prediction tasks, we show that our combination of partial annotation\nand self-training using an adaptive selection ratio reduces annotation cost\nover strong full annotation baselines under a fair comparison scheme that takes\nreading time into consideration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:58:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12635","submitter":"Tianyou Chen","authors":"Tianyou Chen, Jin Xiao, Xiaoguang Hu, Guofeng Zhang, Shaojie Wang","title":"A bioinspired three-stage model for camouflaged object detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Camouflaged objects are typically assimilated into their backgrounds and\nexhibit fuzzy boundaries. The complex environmental conditions and the high\nintrinsic similarity between camouflaged targets and their surroundings pose\nsignificant challenges in accurately locating and segmenting these objects in\ntheir entirety. While existing methods have demonstrated remarkable performance\nin various real-world scenarios, they still face limitations when confronted\nwith difficult cases, such as small targets, thin structures, and indistinct\nboundaries. Drawing inspiration from human visual perception when observing\nimages containing camouflaged objects, we propose a three-stage model that\nenables coarse-to-fine segmentation in a single iteration. Specifically, our\nmodel employs three decoders to sequentially process subsampled features,\ncropped features, and high-resolution original features. This proposed approach\nnot only reduces computational overhead but also mitigates interference caused\nby background noise. Furthermore, considering the significance of multi-scale\ninformation, we have designed a multi-scale feature enhancement module that\nenlarges the receptive field while preserving detailed structural cues.\nAdditionally, a boundary enhancement module has been developed to enhance\nperformance by leveraging boundary information. Subsequently, a mask-guided\nfusion module is proposed to generate fine-grained results by integrating\ncoarse prediction maps with high-resolution feature maps. Our network surpasses\nstate-of-the-art CNN-based counterparts without unnecessary complexities. Upon\nacceptance of the paper, the source code will be made publicly available at\nhttps://github.com/clelouch/BTSNet.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:01:48 GMT"},{"version":"v2","created":"Tue, 6 Jun 2023 12:17:15 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.12636","submitter":"Arjun Singh","authors":"Arjun Singh, Vitaly Petrov, Hichem Guerboukha, Innem V.A.K. Reddy,\n  Edward W. Knightly, Daniel M. Mittleman, Josep M. Jornet","title":"Wavefront Engineering: Realizing Efficient Terahertz Band Communications\n  in 6G and Beyond","comments":"Accepted to IEEE Wireless Communications Magazine, 2023.\n  \\c{opyright}2023 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material, creating new works,\n  for resale or redistribution to servers or lists, or reuse of any copyrighted\n  component of this work in other works","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Terahertz (THz) band communications is envisioned as a key technology for\nfuture wireless standards. Substantial progress has been made in this field,\nwith advances in hardware design, channel models, and signal processing.\nHigh-rate backhaul links operating at sub-THz frequencies have been\nexperimentally demonstrated. However, there are inherent challenges in making\nthe next great leap for adopting the THz band in widespread communication\nsystems, such as cellular access and wireless local area networks. Primarily,\nsuch systems have to be both: (i) wideband, to maintain desired data rate and\nsensing resolution; and, more importantly, (ii) operate in the massive near\nfield of the high-gain devices required to overcome the propagation losses. In\nthis article, it is first explained why the state-of-the-art techniques from\nlower frequencies, including millimeter-wave, cannot be simply repurposed to\nrealize THz band communication systems. Then, a vision of wavefront engineering\nis presented to address these shortfalls. Further, it is illustrated how novel\nimplementations of specific wavefronts, such as Bessel beams and Airy beams,\noffer attractive advantages in creating THz links over state-of-the-art\nfar-field beamforming and near-field beamfocusing techniques. The paper ends by\ndiscussing novel problems and challenges in this new and exciting research\narea.\n  Index Terms - Terahertz Communications; 6G; Wavefront Engineering; Bessel\nbeams; Near field; Orbital Angular Momentum\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:09:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12637","submitter":"Dusan Sarenac","authors":"D. A. Pushin, C. Kapahi, A. E. Silva, D. G. Cory, M. Kulmaganbetov, M.\n  Mungalsingh, T. Singh, B. Thompson, D. Sarenac","title":"Psychophysical discrimination of radially varying polarization entoptic\n  phenomena","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The incorporation of structured light techniques into vision science has\nenabled more selective probes of polarization related entoptic phenomena.\nDiverse sets of stimuli have become accessible in which the spatially dependant\noptical properties can be rapidly controlled and manipulated. For example, past\nstudies with human perception of polarization have dealt with stimuli that\nappear to vary azimuthally. This is mainly due to the constraint that the\ntypically available degree of freedom to manipulate the phase shift of light\nrotates the perceived pattern around a person's point of fixation. Here we\ncreate a structured light stimulus that is perceived to vary purely along the\nradial direction and test discrimination sensitivity to inwards and outwards\nradial motion. This is accomplished by preparing a radial state coupled to an\norbital angular momentum state that matches the orientation of the dichroic\nelements in the macula. The presented methods offering a new dimension of\nexploration serve as a direct compliment to previous studies and may provide\nnew insights into characterizing macular pigment density profiles and assessing\nthe health of the macula.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:13:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12638","submitter":"Sharad Goel","authors":"Michael Zanger-Tishler, Julian Nyarko, and Sharad Goel","title":"Risk Scores, Label Bias, and Everything but the Kitchen Sink","comments":"19 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY stat.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In designing risk assessment algorithms, many scholars promote a \"kitchen\nsink\" approach, reasoning that more information yields more accurate\npredictions. We show, however, that this rationale often fails when algorithms\nare trained to predict a proxy of the true outcome, as is typically the case.\nWith such \"label bias\", one should exclude a feature if its correlation with\nthe proxy and its correlation with the true outcome have opposite signs,\nconditional on the other model features. This criterion is often satisfied when\na feature is weakly correlated with the true outcome, and, additionally, that\nfeature and the true outcome are both direct causes of the remaining features.\nFor example, due to patterns of police deployment, criminal behavior and\ngeography may be weakly correlated and direct causes of one's criminal record,\nsuggesting one should exclude geography in criminal risk assessments trained to\npredict arrest as a proxy for behavior.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:21:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12639","submitter":"Lili Chen","authors":"Lili Chen, Jingge Zhu, Jamie Evans","title":"Accelerating Graph Neural Networks via Edge Pruning for Power Allocation\n  in Wireless Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.LG cs.NI eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural Networks (GNNs) have recently emerged as a promising approach to\ntackling power allocation problems in wireless networks. Since unpaired\ntransmitters and receivers are often spatially distant, the distanced-based\nthreshold is proposed to reduce the computation time by excluding or including\nthe channel state information in GNNs. In this paper, we are the first to\nintroduce a neighbour-based threshold approach to GNNs to reduce the time\ncomplexity. Furthermore, we conduct a comprehensive analysis of both\ndistance-based and neighbour-based thresholds and provide recommendations for\nselecting the appropriate value in different communication channel scenarios.\nWe design the corresponding distance-based and neighbour-based Graph Neural\nNetworks with the aim of allocating transmit powers to maximise the network\nthroughput. Our results show that our proposed GNNs offer significant\nadvantages in terms of reducing time complexity while preserving strong\nperformance. Besides, we show that by choosing a suitable threshold, the time\ncomplexity is reduced from O(|V|^2) to O(|V|), where |V| is the total number of\ntransceiver pairs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:22:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12640","submitter":"Panayiotis Danassis","authors":"Panayiotis Danassis, Shresth Verma, Jackson A. Killian, Aparna Taneja,\n  Milind Tambe","title":"Limited Resource Allocation in a Non-Markovian World: The Case of\n  Maternal and Child Healthcare","comments":"Proceedings of the 32nd International Joint Conference on Artificial\n  Intelligence (IJCAI 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The success of many healthcare programs depends on participants' adherence.\nWe consider the problem of scheduling interventions in low resource settings\n(e.g., placing timely support calls from health workers) to increase adherence\nand/or engagement. Past works have successfully developed several classes of\nRestless Multi-armed Bandit (RMAB) based solutions for this problem.\nNevertheless, all past RMAB approaches assume that the participants' behaviour\nfollows the Markov property. We demonstrate significant deviations from the\nMarkov assumption on real-world data on a maternal health awareness program\nfrom our partner NGO, ARMMAN. Moreover, we extend RMABs to continuous state\nspaces, a previously understudied area. To tackle the generalised non-Markovian\nRMAB setting we (i) model each participant's trajectory as a time-series, (ii)\nleverage the power of time-series forecasting models to learn complex patterns\nand dynamics to predict future states, and (iii) propose the Time-series Arm\nRanking Index (TARI) policy, a novel algorithm that selects the RMAB arms that\nwill benefit the most from an intervention, given our future state predictions.\nWe evaluate our approach on both synthetic data, and a secondary analysis on\nreal data from ARMMAN, and demonstrate significant increase in engagement\ncompared to the SOTA, deployed Whittle index solution. This translates to 16.3\nhours of additional content listened, 90.8% more engagement drops prevented,\nand reaching more than twice as many high dropout-risk beneficiaries.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:26:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12641","submitter":"Abhinav Ramesh Kashyap","authors":"Abhinav Ramesh Kashyap, Thanh-Tung Nguyen, Viktor Schlegel, Stefan\n  Winkler, See-Kiong Ng, Soujanya Poria","title":"Beyond Words: A Comprehensive Survey of Sentence Representations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sentence representations have become a critical component in natural language\nprocessing applications, such as retrieval, question answering, and text\nclassification. They capture the semantics and meaning of a sentence, enabling\nmachines to understand and reason over human language. In recent years,\nsignificant progress has been made in developing methods for learning sentence\nrepresentations, including unsupervised, supervised, and transfer learning\napproaches. In this paper, we provide an overview of the different methods for\nsentence representation learning, including both traditional and deep\nlearning-based techniques. We provide a systematic organization of the\nliterature on sentence representation learning, highlighting the key\ncontributions and challenges in this area. Overall, our review highlights the\nprogress made in sentence representation learning, the importance of this area\nin natural language processing, and the challenges that remain. We conclude\nwith directions for future research, suggesting potential avenues for improving\nthe quality and efficiency of sentence representations in NLP applications.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:31:15 GMT"},{"version":"v2","created":"Tue, 23 May 2023 15:33:07 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12642","submitter":"Zhenduo Zhao","authors":"Zhenduo Zhao, Zhuo Li, Wenchao Wang, Pengyuan Zhang","title":"The HCCL system for VoxCeleb Speaker Recognition Challenge 2022","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This report describes our submission to track1 and track3 for VoxCeleb\nSpeaker Recognition Challenge 2022(VoxSRC2022). Our best system achieves minDCF\n0.1397 and EER 2.414 in track1, minDCF 0.388 and EER 7.030 in track3.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:32:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12643","submitter":"Xinyang Yu","authors":"Binyan Jiang, Chenlei Leng, Ting Yan, Qiwei Yao, Xinyang Yu","title":"A two-way heterogeneity model for dynamic networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Analysis of networks that evolve dynamically requires the joint modelling of\nindividual snapshots and time dynamics. This paper proposes a new flexible\ntwo-way heterogeneity model towards this goal. The new model equips each node\nof the network with two heterogeneity parameters, one to characterize the\npropensity to form ties with other nodes statically and the other to\ndifferentiate the tendency to retain existing ties over time. With $n$ observed\nnetworks each having $p$ nodes, we develop a new asymptotic theory for the\nmaximum likelihood estimation of $2p$ parameters when $np\\rightarrow \\infty$.\nWe overcome the global non-convexity of the negative log-likelihood function by\nthe virtue of its local convexity, and propose a novel method of moment\nestimator as the initial value for a simple algorithm that leads to the\nconsistent local maximum likelihood estimator (MLE). To establish the upper\nbounds for the estimation error of the MLE, we derive a new uniform deviation\nbound, which is of independent interest. The theory of the model and its\nusefulness are further supported by extensive simulation and a data analysis\nexamining social interactions of ants.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:37:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12644","submitter":"Hailiang Tang","authors":"Hailiang Tang, Xiaoji Niu, Tisheng Zhang, Liqiang Wang, Guan Wang, and\n  Jingnan Liu","title":"PO-VINS: An Efficient Pose-Only LiDAR-Enhanced Visual-Inertial State\n  Estimator","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The pose-only (PO) visual representation has been proven to be equivalent to\nthe classical multiple-view geometry, while significantly improving\ncomputational efficiency. However, its applicability for real-world navigation\nin large-scale complex environments has not yet been demonstrated. In this\nstudy, we present an efficient pose-only LiDAR-enhanced visual-inertial\nnavigation system (PO-VINS) to enhance the real-time performance of the state\nestimator. In the visual-inertial state estimator (VISE), we propose a\npose-only visual-reprojection measurement model that only contains the inertial\nmeasurement unit (IMU) pose and extrinsic-parameter states. We further\nintegrated the LiDAR-enhanced method to construct a pose-only LiDAR-depth\nmeasurement model. Real-world experiments were conducted in large-scale complex\nenvironments, demonstrating that the proposed PO-VISE and LiDAR-enhanced\nPO-VISE reduce computational complexity by more than 50% and over 20%,\nrespectively. Additionally, the PO-VINS yields the same accuracy as\nconventional methods. These results indicate that the pose-only solution is\nefficient and applicable for real-time visual-inertial state estimation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:38:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12645","submitter":"Sihem Mesnager","authors":"Kwang Ho Kim, Sihem Mesnager, Chung Hyok Kim","title":"Solving $X^{2^{2k}+2^{k}+1}+(X+1)^{2^{2k}+2^{k}+1}=b$ over $\\GF{2^{4k}}$","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $F(X)=X^{2^{2k}+2^k+1}$ be the power function over the finite field\n$\\GF{2^{4k}}$ which is known as the Bracken-Leander function. In\n\\cite{BCC10,BL10,CV20,Fu22,XY17}, it was proved that the number of solutions in\n$\\GF{q^4}$ to the equation $F(X)+F(X+1)=b$ is in $\\{0,2,4\\}$ for any $b\\in\n\\GF{q^4}$ and the number of the $b$ giving $i$ solutions have been determined\nfor every $i$. However, no paper provided a direct and complete method to solve\nsuch an equation, and\n  this problem remained open. This article presents a direct technique to\nderive an explicit solution to that equation. The main result\n  in \\cite{BCC10,BL10,Fu22,XY17}, determining differential spectrum of\n  $F(X)=X^{2^{2k}+2^k+1}$ over $\\GF{2^{4k}}$,\n  is re-derived simply from our results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:41:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12646","submitter":"Shuqiang Wang","authors":"Bowen Hu, Baiying Lei, Shuqiang Wang","title":"SG-GAN: Fine Stereoscopic-Aware Generation for 3D Brain Point Cloud\n  Up-sampling from a Single Image","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In minimally-invasive brain surgeries with indirect and narrow operating\nenvironments, 3D brain reconstruction is crucial. However, as requirements of\naccuracy for some new minimally-invasive surgeries (such as brain-computer\ninterface surgery) are higher and higher, the outputs of conventional 3D\nreconstruction, such as point cloud (PC), are facing the challenges that sample\npoints are too sparse and the precision is insufficient. On the other hand,\nthere is a scarcity of high-density point cloud datasets, which makes it\nchallenging to train models for direct reconstruction of high-density brain\npoint clouds. In this work, a novel model named stereoscopic-aware graph\ngenerative adversarial network (SG-GAN) with two stages is proposed to generate\nfine high-density PC conditioned on a single image. The Stage-I GAN sketches\nthe primitive shape and basic structure of the organ based on the given image,\nyielding Stage-I point clouds. The Stage-II GAN takes the results from Stage-I\nand generates high-density point clouds with detailed features. The Stage-II\nGAN is capable of correcting defects and restoring the detailed features of the\nregion of interest (ROI) through the up-sampling process. Furthermore, a\nparameter-free-attention-based free-transforming module is developed to learn\nthe efficient features of input, while upholding a promising performance.\nComparing with the existing methods, the SG-GAN model shows superior\nperformance in terms of visual quality, objective measurements, and performance\nin classification, as demonstrated by comprehensive results measured by several\nevaluation metrics including PC-to-PC error and Chamfer distance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:42:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12647","submitter":"Kevin Fischer","authors":"Kevin A. Fischer","title":"Reflective Linguistic Programming (RLP): A Stepping Stone in\n  Socially-Aware AGI (SocialAGI)","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.CL cs.HC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents Reflective Linguistic Programming (RLP), a unique\napproach to conversational AI that emphasizes self-awareness and strategic\nplanning. RLP encourages models to introspect on their own predefined\npersonality traits, emotional responses to incoming messages, and planned\nstrategies, enabling contextually rich, coherent, and engaging interactions. A\nstriking illustration of RLP's potential involves a toy example, an AI persona\nwith an adversarial orientation, a demon named `Bogus' inspired by the\nchildren's fairy tale Hansel & Gretel. Bogus exhibits sophisticated behaviors,\nsuch as strategic deception and sensitivity to user discomfort, that\nspontaneously arise from the model's introspection and strategic planning.\nThese behaviors are not pre-programmed or prompted, but emerge as a result of\nthe model's advanced cognitive modeling. The potential applications of RLP in\nsocially-aware AGI (Social AGI) are vast, from nuanced negotiations and mental\nhealth support systems to the creation of diverse and dynamic AI personas. Our\nexploration of deception serves as a stepping stone towards a new frontier in\nAGI, one filled with opportunities for advanced cognitive modeling and the\ncreation of truly human `digital souls'.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:43:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12648","submitter":"Sheng Chen","authors":"Sheng Chen, Ziyang Zhang","title":"Weak approximation of symmetric products and norm varieties","comments":"9 pages; improved theorem 1.3","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let k be a number field. For a variety X over k that satisfies weak\napproximation with Brauer-Manin obstruction, we study the same property for\nsmooth projective models of its symmetric products. Based on the same method,\nwe also explore the property of weak approximation with Brauer-Manin\nobstruction for norm varieties.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:45:58 GMT"},{"version":"v2","created":"Wed, 31 May 2023 12:24:21 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.12649","submitter":"Mingkui Tan","authors":"Hongbin Lin, Mingkui Tan, Yifan Zhang, Zhen Qiu, Shuaicheng Niu, Dong\n  Liu, Qing Du and Yanxia Liu","title":"Imbalance-Agnostic Source-Free Domain Adaptation via Avatar Prototype\n  Alignment","comments":"arXiv admin note: text overlap with arXiv:2106.15326","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Source-free Unsupervised Domain Adaptation (SF-UDA) aims to adapt a\nwell-trained source model to an unlabeled target domain without access to the\nsource data. One key challenge is the lack of source data during domain\nadaptation. To handle this, we propose to mine the hidden knowledge of the\nsource model and exploit it to generate source avatar prototypes. To this end,\nwe propose a Contrastive Prototype Generation and Adaptation (CPGA) method.\nCPGA consists of two stages: Prototype generation and Prototype adaptation.\nExtensive experiments on three UDA benchmark datasets demonstrate the\nsuperiority of CPGA. However, existing SF.UDA studies implicitly assume\nbalanced class distributions for both the source and target domains, which\nhinders their real applications. To address this issue, we study a more\npractical SF-UDA task, termed imbalance-agnostic SF-UDA, where the class\ndistributions of both the unseen source domain and unlabeled target domain are\nunknown and could be arbitrarily skewed. This task is much more challenging\nthan vanilla SF-UDA due to the co-occurrence of covariate shifts and\nunidentified class distribution shifts between the source and target domains.\nTo address this task, we extend CPGA and propose a new Target-aware Contrastive\nPrototype Generation and Adaptation (T-CPGA) method. Specifically, for better\nprototype adaptation in the imbalance-agnostic scenario, T-CPGA applies a new\npseudo label generation strategy to identify unknown target class distribution\nand generate accurate pseudo labels, by utilizing the collective intelligence\nof the source model and an additional contrastive language-image pre-trained\nmodel. Meanwhile, we further devise a target label-distribution-aware\nclassifier to adapt the model to the unknown target class distribution. We\nempirically show that T-CPGA significantly outperforms CPGA and other SF-UDA\nmethods in imbalance-agnostic SF-UDA.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:46:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12650","submitter":"Chunxu Zhang","authors":"Chunxu Zhang, Guodong Long, Tianyi Zhou, Xiangyu Zhao, Zijian Zhang\n  and Bo Yang","title":"IFedRec: Item-Guided Federated Aggregation for Cold-Start","comments":"10 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Federated recommendation system is a recently emerging architecture, which\nprovides recommendation services without exposing users' private data. Existing\nmethods are mainly designed to recommend items already existing in the system.\nIn practical scenarios, the system continuously introduces new items and\nrecommends them to users, i.e., cold-start recommendation. To recommend cold\nitems, existing federated recommendation models require collecting new\ninteractions from users and retraining the model, which is time-consuming and\nposes a privacy threat to users' sensitive information. This paper presents a\nnovel Item-guided Federated aggregation for cold-start Recommendation (IFedRec)\nframework. The IFedRec exchanges the item embedding to learn the common item\npreference semantic and preserves other model parameters locally to capture\nuser personalization. Besides, it deploys a meta attribute network on the\nserver to learn the item feature semantic, and a semantic alignment mechanism\nis presented to align both kinds of item semantic. When the new items arrive,\neach client can make recommendations with item feature semantic learned from\nthe meta attribute network by incorporating the locally personalized model\nwithout retraining. Experiments on four benchmark datasets demonstrate\nIFedRec's outstanding performance for cold-start recommendation. Besides,\nin-depth analysis verifies IFedRec's learning ability for cold items while\nprotecting user's privacy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:51:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12651","submitter":"Priyanga Dilini Talagala PhD","authors":"Puwasala Gamakumara and Edgar Santos-Fernandez and Priyanga Dilini\n  Talagala and Rob J. Hyndman and Kerrie Mengersen and Catherine Leigh","title":"Conditional normalization in time series analysis","comments":"36 pages, 26 Figures, Journal Article","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.AP stat.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Time series often reflect variation associated with other related variables.\nControlling for the effect of these variables is useful when modeling or\nanalysing the time series. We introduce a novel approach to normalize time\nseries data conditional on a set of covariates. We do this by modeling the\nconditional mean and the conditional variance of the time series with\ngeneralized additive models using a set of covariates. The conditional mean and\nvariance are then used to normalize the time series. We illustrate the use of\nconditionally normalized series using two applications involving river network\ndata. First, we show how these normalized time series can be used to impute\nmissing values in the data. Second, we show how the normalized series can be\nused to estimate the conditional autocorrelation function and conditional\ncross-correlation functions via additive models. Finally we use the conditional\ncross-correlations to estimate the time it takes water to flow between two\nlocations in a river network.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:51:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12652","submitter":"Yifeng Zheng","authors":"Yifeng Zheng, Shuangqing Xu, Songlei Wang, Yansong Gao, Zhongyun Hua","title":"Privet: A Privacy-Preserving Vertical Federated Learning Service for\n  Gradient Boosted Decision Tables","comments":"Accepted in IEEE Transactions on Services Computing (TSC)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Vertical federated learning (VFL) has recently emerged as an appealing\ndistributed paradigm empowering multi-party collaboration for training\nhigh-quality models over vertically partitioned datasets. Gradient boosting has\nbeen popularly adopted in VFL, which builds an ensemble of weak learners\n(typically decision trees) to achieve promising prediction performance.\nRecently there have been growing interests in using decision table as an\nintriguing alternative weak learner in gradient boosting, due to its simpler\nstructure, good interpretability, and promising performance. In the literature,\nthere have been works on privacy-preserving VFL for gradient boosted decision\ntrees, but no prior work has been devoted to the emerging case of decision\ntables. Training and inference on decision tables are different from that the\ncase of generic decision trees, not to mention gradient boosting with decision\ntables in VFL. In light of this, we design, implement, and evaluate Privet, the\nfirst system framework enabling privacy-preserving VFL service for gradient\nboosted decision tables. Privet delicately builds on lightweight cryptography\nand allows an arbitrary number of participants holding vertically partitioned\ndatasets to securely train gradient boosted decision tables. Extensive\nexperiments over several real-world datasets and synthetic datasets demonstrate\nthat Privet achieves promising performance, with utility comparable to\nplaintext centralized learning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:51:40 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 03:33:17 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12653","submitter":"He Chen","authors":"Crane He Chen","title":"Estimating Discrete Total Curvature with Per Triangle Normal Variation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GR cs.CG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a novel approach for measuring the total curvature at every\ntriangle of a discrete surface. This method takes advantage of the relationship\nbetween per triangle total curvature and the Dirichlet energy of the Gauss map.\nThis new tool can be used on both triangle meshes and point clouds and has\nnumerous applications. In this study, we demonstrate the effectiveness of our\ntechnique by using it for feature-aware mesh decimation, and show that it\noutperforms existing curvature-estimation methods from popular libraries such\nas Meshlab, Trimesh2, and Libigl. When estimating curvature on point clouds,\nour method outperforms popular libraries PCL and CGAL.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:52:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12654","submitter":"M. Ibrahim Mirza","authors":"Jyotsna Singh, M. Ibrahim Mirza","title":"Challenges in Neutrino Mass Measurements","comments":"15 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ex hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neutrino masses are yet unknown. We discuss the present state of absolute\nneutrino mass from $\\beta$ decay experiments; effective Majorana neutrino mass\nfrom neutrinoless double-beta decay experiments; neutrino mass squared\ndifferences from neutrino oscillation: solar, atmospheric, reactor and\naccelerator based experiments; sum of neutrino masses from cosmological\nobservations. Current experimental challenges in the determination of neutrino\nmasses are briefly discussed. The main focus is devoted to contemporary\nexperiments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:52:56 GMT"},{"version":"v2","created":"Sun, 28 May 2023 20:58:33 GMT"},{"version":"v3","created":"Wed, 7 Jun 2023 07:23:05 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.12655","submitter":"Sihem Mesnager","authors":"Kwang Ho Kim, Sihem Mesnager, Ye Bong Kim","title":"On the Boomerang Spectrum of Power Permutation\n  $X^{2^{3n}+2^{2n}+2^{n}-1}$ over $\\GF{2^{4n}}$ and Extraction of Optimal\n  Uniformity Boomerang Functions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A substitution box (S-box) in a symmetric primitive is a mapping $F$ that\ntakes $k$ binary inputs and whose image is a binary $m$-tuple for some positive\nintegers $k$ and $m$, which is usually the only nonlinear element of the most\nmodern block ciphers. Therefore, employing S-boxes with good cryptographic\nproperties to resist various attacks is significant. For power permutation $F$\nover finite field $\\GF{2^k}$, the multiset of\n  values $\\beta_F(1,b)=\\#\\{x\\in \\GF{2^k}\\mid\nF^{-1}(F(x)+b)+F^{-1}(F(x+1)+b)=1\\}$ for $b\\in \\GF{2^k}$ is called the\nboomerang spectrum of $F$. The maximum value in the boomerang spectrum is\ncalled boomerang uniformity. This paper determines the boomerang spectrum of\nthe power permutation $X^{2^{3n}+2^{2n}+2^{n}-1}$ over $\\GF{2^{4n}}$. The\nboomerang uniformity of that power permutation is $3(2^{2n}-2^n)$. However, on\na large subset $\\{b\\in \\GF{2^{4n}}\\mid \\mathbf{Tr}_n^{4n}(b)\\neq 0\\}$ of\n$\\GF{2^{4n}}$ of cardinality $2^{4n}-2^{3n}$ (where $ \\mathbf{Tr}_n^{4n}$ is\nthe (relative) trace function from $\\GF{2^{4n}}$ to $\\GF{2^{n}}$), we prove\nthat the studied function $F$ achieves the optimal boomerang uniformity $2$.\n  It is known that obtaining such functions is a challenging problem.\n  More importantly, the set of $b$'s giving this value is explicitly determined\nfor any value in the boomerang spectrum.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:53:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12656","submitter":"Hehu Xie","authors":"Yifan Wang and Hehi Xie","title":"Computing Multi-Eigenpairs of High-Dimensional Eigenvalue Problems Using\n  Tensor Neural Networks","comments":"25 pages, 64 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper, we propose a type of tensor-neural-network-based machine\nlearning method to compute multi-eigenpairs of high dimensional eigenvalue\nproblems without Monte-Carlo procedure. Solving multi-eigenvalues and their\ncorresponding eigenfunctions is one of the basic tasks in mathematical and\ncomputational physics. With the help of tensor neural network and deep Ritz\nmethod, the high dimensional integrations included in the loss functions of the\nmachine learning process can be computed with high accuracy. The high accuracy\nof high dimensional integrations can improve the accuracy of the machine\nlearning method for computing multi-eigenpairs of high dimensional eigenvalue\nproblems. Here, we introduce the tensor neural network and design the machine\nlearning method for computing multi-eigenpairs of the high dimensional\neigenvalue problems. The proposed numerical method is validated with plenty of\nnumerical examples.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:55:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12657","submitter":"Guy Martial Nkiet","authors":"Jean Roland Ebende Penda and St\\'ephane Bouka and Guy Martial Nkiet","title":"Variable selection in multivariate regression model for spatially\n  dependent data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper deals with variable selection in multivariate linear regression\nmodel when the data are observations on a spatial domain being a grid of sites\nin $\\mathbb{Z}^d$ with $d\\geqslant 2$. We use a criterion that allows to\ncharacterize the subset of relevant variables as depending on two parameters,\nand we propose estimators for these parameters based on spatially dependent\nobservations. We prove the consistency, under specified assumptions, of the\nmethod thus proposed. A simulation study made in order to assess the\nfinite-sample behaviour of the proposed method with comparison to existing ones\nis presented.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:57:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12658","submitter":"Amit Kumar Mr.","authors":"Amit Kumar and Vaibhav Shekhar","title":"Dual Drazin generalized inverse for dual matrices","comments":"Under certain necessary and sufficient conditions, we establish the\n  existence of the DDGI of a dual matrix of any index","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA cs.NA math.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This manuscript proposes a generalized inverse for a dual matrix called dual\nDrazin generalized inverse (DDGI) which generalizes the notion of the dual\ngroup generalized inverse (DGGI). Under certain necessary and sufficient\nconditions, we establish the existence of the DDGI of a dual matrix of any\nindex. Thereafter, we show that the DDGI is unique (whenever exists). The DDGI\nis then used to solve a linear dual system. We also establish reverse-order law\nand forward-order law for a particular form of the DGGI, dual Moore-Penrose\ngeneralized inverse (DMPGI), dual core generalized inverse (DCGI), and DDGI\nunder certain suitable conditions. Finally, the partial-orders based on DCGI\nand DGGI are proposed.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:03:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12659","submitter":"Zhenghao Zhang","authors":"Zhenghao Zhang and Zhichao Wei and Shengfan Zhang and Zuozhuo Dai and\n  Siyu Zhu","title":"UVOSAM: A Mask-free Paradigm for Unsupervised Video Object Segmentation\n  via Segment Anything Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Unsupervised video object segmentation has made significant progress in\nrecent years, but the manual annotation of video mask datasets is expensive and\nlimits the diversity of available datasets. The Segment Anything Model (SAM)\nhas introduced a new prompt-driven paradigm for image segmentation, unlocking a\nrange of previously unexplored capabilities. In this paper, we propose a novel\nparadigm called UVOSAM, which leverages SAM for unsupervised video object\nsegmentation without requiring video mask labels. To address SAM's limitations\nin instance discovery and identity association, we introduce a video salient\nobject tracking network that automatically generates trajectories for prominent\nforeground objects. These trajectories then serve as prompts for SAM to produce\nvideo masks on a frame-by-frame basis. Our experimental results demonstrate\nthat UVOSAM significantly outperforms current mask-supervised methods. These\nfindings suggest that UVOSAM has the potential to improve unsupervised video\nobject segmentation and reduce the cost of manual annotation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:03:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12660","submitter":"Siyu Yuan","authors":"Siyu Yuan, Jiangjie Chen, Xuyang Ge, Yanghua Xiao, Deqing Yang","title":"Beneath Surface Similarity: Large Language Models Make Reasonable\n  Scientific Analogies after Structure Abduction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Analogical reasoning is essential for human cognition, allowing us to\ncomprehend new concepts by relating them to familiar ones based on common\nrelational structures. Previous work mainly focuses on word analogies, which do\nnot fully represent the analogical reasoning ability of language models (LMs)\naligning with humans. This paper first examines analogy prompting for large\nlanguage models (LLMs) in scientific question-answering tasks. Then we discover\nthat LLMs tend to ignore relational structures when performing word analogies,\ncasting doubt on their utility for evaluating analogical reasoning. For better\nevaluation aligning with humans, we propose an analogical structure abduction\ntask based on cognitive psychology, which aims to abduct structures between two\nsystems to establish an analogy. Then we create a benchmark of scientific\nanalogical reasoning with structure abduction, SCAR, consisting of 400\nscientific analogies across 13 domains for this task. Empirical results reveal\nthat LLMs struggle with this task, but the Chain-of-Thought (CoT) method with\nbackground knowledge and explanations can improve their capability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:04:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12661","submitter":"Chuanxin Song","authors":"Chuanxin Song, Hanbo Wu, Xin Ma, Yibin Li","title":"Semantic-guided context modeling for indoor scene recognition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Exploring the semantic context in scene images is essential for indoor scene\nrecognition. However, due to the diverse intra-class spatial layouts and the\ncoexisting inter-class objects, modeling contextual relationships to adapt\nvarious image characteristics is a great challenge. Existing contextual\nmodeling methods for indoor scene recognition exhibit two limitations: 1)\nDuring training, space-independent information, such as color, may hinder\noptimizing the network's capacity to represent the spatial context. 2) These\nmethods often overlook the differences in coexisting objects across different\nscenes, suppressing the performance of scene recognition. To address these\nlimitations, we propose SpaCoNet, a novel approach that simultaneously models\nthe Spatial relation and Co-occurrence of objects based on semantic\nsegmentation. Firstly, the semantic spatial relation module (SSRM) is designed\nto explore the spatial relations among objects within a scene. With the help of\nsemantic segmentation, this module decouples the spatial information from the\nimage, effectively avoiding the influence of irrelevant features. Secondly,\nboth spatial context features from SSRM and deep features from RGB feature\nextractor are used to distinguish the coexisting object across different\nscenes. Finally, utilizing the discriminative features mentioned above, we\nemploy the self-attention mechanism to explore the long-range co-occurrence\nrelationships among objects, and further generate a semantic-guided feature\nrepresentation for indoor scene recognition. Experimental results on three\npublicly available datasets demonstrate the effectiveness and generality of the\nproposed method. The code will be made publicly available after the\nblind-review process is completed.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:04:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12662","submitter":"Hye-Young Kim","authors":"Hye-young Kim, Minjin Choi, Sunkyung Lee, Eunseong Choi, Young-In\n  Song, Jongwuk Lee","title":"ConQueR: Contextualized Query Reduction using Search Logs","comments":"In Proceedings of the 46th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR'23). 6 pages","journal-ref":null,"doi":"10.1145/3539618.3591966","report-no":null,"categories":"cs.IR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Query reformulation is a key mechanism to alleviate the linguistic chasm of\nquery in ad-hoc retrieval. Among various solutions, query reduction effectively\nremoves extraneous terms and specifies concise user intent from long queries.\nHowever, it is challenging to capture hidden and diverse user intent. This\npaper proposes Contextualized Query Reduction (ConQueR) using a pre-trained\nlanguage model (PLM). Specifically, it reduces verbose queries with two\ndifferent views: core term extraction and sub-query selection. One extracts\ncore terms from an original query at the term level, and the other determines\nwhether a sub-query is a suitable reduction for the original query at the\nsequence level. Since they operate at different levels of granularity and\ncomplement each other, they are finally aggregated in an ensemble manner. We\nevaluate the reduction quality of ConQueR on real-world search logs collected\nfrom a commercial web search engine. It achieves up to 8.45% gains in exact\nmatch scores over the best competing model.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:06:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12663","submitter":"Yecheng Jason Ma","authors":"Yecheng Jason Ma, Kausik Sivakumar, Jason Yan, Osbert Bastani, Dinesh\n  Jayaraman","title":"TOM: Learning Policy-Aware Models for Model-Based Reinforcement Learning\n  via Transition Occupancy Matching","comments":"L4DC 2023; Project website: https://penn-pal-lab.github.io/TOM/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Standard model-based reinforcement learning (MBRL) approaches fit a\ntransition model of the environment to all past experience, but this wastes\nmodel capacity on data that is irrelevant for policy improvement. We instead\npropose a new \"transition occupancy matching\" (TOM) objective for MBRL model\nlearning: a model is good to the extent that the current policy experiences the\nsame distribution of transitions inside the model as in the real environment.\nWe derive TOM directly from a novel lower bound on the standard reinforcement\nlearning objective. To optimize TOM, we show how to reduce it to a form of\nimportance weighted maximum-likelihood estimation, where the automatically\ncomputed importance weights identify policy-relevant past experiences from a\nreplay buffer, enabling stable optimization. TOM thus offers a plug-and-play\nmodel learning sub-routine that is compatible with any backbone MBRL algorithm.\nOn various Mujoco continuous robotic control tasks, we show that TOM\nsuccessfully focuses model learning on policy-relevant experience and drives\npolicies faster to higher task rewards than alternative model learning\napproaches.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:06:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12664","submitter":"Ali Rad","authors":"Ali Rad","title":"Deep Quantum Neural Networks are Gaussian Process","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The overparameterization of variational quantum circuits, as a model of\nQuantum Neural Networks (QNN), not only improves their trainability but also\nserves as a method for evaluating the property of a given ansatz by\ninvestigating their kernel behavior in this regime. In this study, we shift our\nperspective from the traditional viewpoint of training in parameter space into\nfunction space by employing the Bayesian inference in the Reproducing Kernel\nHilbert Space (RKHS). We observe the influence of initializing parameters using\nrandom Haar distribution results in the QNN behaving similarly to a Gaussian\nProcess (QNN-GP) at wide width or, empirically, at a deep depth. This outcome\naligns with the behaviors observed in classical neural networks under similar\ncircumstances with Gaussian initialization. Moreover, we present a framework to\nexamine the impact of finite width in the closed-form relationship using a $\n1/d$ expansion, where $d$ represents the dimension of the circuit's Hilbert\nspace. The deviation from Gaussian output can be monitored by introducing new\nquantum meta-kernels. Furthermore, we elucidate the relationship between GP and\nits parameter space equivalent, characterized by the Quantum Neural Tangent\nKernels (QNTK). This study offers a systematic way to study QNN behavior in\nover- and under-parameterized scenarios, based on the perturbation method, and\naddresses the limitations of tracking the gradient descent methods for\nhigher-order corrections like dQNTK and ddQNTK. Additionally, this\nprobabilistic viewpoint lends itself naturally to accommodating noise within\nour model.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:07:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12665","submitter":"Qasim Ajao","authors":"Qasim Ajao, and Olukotun Oludamilare","title":"Safety Challenges and Analysis of Autonomous Electric Vehicle\n  Development: Insights from On-Road Testing and Accident Reports","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Autonomous electric vehicles (AEVs) hold great promise for the future of\nautomotive engineering, but safety remains a significant challenge in their\ndevelopment and commercialization. Therefore, conducting a comprehensive\nanalysis of AEV development and reported accidents is crucial. This paper\nreviews the levels of automation in AEVs, their disengagement frequencies, and\non-road accident reports. According to the report, numerous manufacturers\nthoroughly tested AEVs across a distance of more than 3.9 million miles between\n2014 and 2022. Disengagement frequencies vary among manufacturers, and\napproximately 65% of accidents during this period occurred while AEVs were\noperating in autonomous mode. Notably, the majority of accidents (90%) were\ncaused by other road users, with only a small fraction (approximately 8%)\ndirectly attributed to AEVs. Enhancing AEVs' ability to detect and mitigate\nsafety risks from external sources has the potential to significantly improve\ntheir safety. This paper provides valuable insights into AEV safety by\nemphasizing the importance of comprehensively understanding AEV development and\nreported accidents. Through the analysis of disengagement and accident reports,\nthe study highlights the prevalence of passive accidents caused by other road\nusers. Future research should concentrate on enabling AEVs to effectively\ndetect and respond to safety risks originating from external sources to enhance\nAEV safety. Overall, this analysis contributes to the ongoing efforts in AEV\ndevelopment and provides guidance for strategies aimed at improving their\nsafety features.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:11:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12666","submitter":"Ryo Ikehata","authors":"Xiaoyan Li and Ryo Ikehata","title":"Fast energy decay for wave equation with a monotone potential and an\n  effective damping","comments":"13 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the total energy decay of the Cauchy problem for wave equations\nwith a potential and an effective damping. We treat it in the whole\none-dimensional Euclidean space. Fast energy decay is established with the help\nof potential. The proofs of main results rely on a multiplier method and\nmodified techniques adopted in [8].\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:12:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12667","submitter":"Margherita De Marzio","authors":"Margherita De Marzio, Amit Das, Jeffrey J. Fredberg and Dapeng Bi","title":"Epithelial layer fluidization by curvature-induced unjamming","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The transition of an epithelial layer from a stationary, quiescent state to a\nhighly migratory, dynamic state is required for wound healing, development, and\nregeneration. This transition, known as the unjamming transition (UJT), is\nresponsible for epithelial fluidization and collective migration. Previous\ntheoretical models have primarily focused on the UJT in flat epithelial layers,\nneglecting the effects of strong surface curvature that is characteristic of\nepithelial tissues in vivo. In this study, we investigate the role of surface\ncurvature on tissue plasticity and cellular migration using a vertex model\nembedded on a spherical surface. Our findings reveal that increasing curvature\npromotes epithelial unjamming by reducing the energy barriers to cellular\nrearrangements. Higher curvature favors cell intercalation, mobility, and\nself-diffusivity, resulting in epithelial structures that are malleable and\nmigratory when small, but become more rigid and stationary as they grow. As\nsuch, curvature-induced unjamming emerges as a novel mechanism for epithelial\nlayer fluidization. Our quantitative model proposes the existence of a new,\nextended, phase diagram wherein local cell shape, cell propulsion, and tissue\ngeometry combine to determine the epithelial migratory phenotype.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:12:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12668","submitter":"Wu-Long Xu","authors":"Wenyu Wang, Wu-Long Xu, Jin Min Yang and Rui Zhu","title":"Direct detection of cosmic ray-boosted puffy dark matter","comments":"14 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph astro-ph.CO hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For the light relativistic dark matter (DM) boosted by high energy cosmic\nray, its scattering cross section with the nucleon is sensitively dependent on\nthe momentum-transfer and such an dependence is caused by the mediator in the\nscattering. For puffy DM particle with a size, the momentum-transfer dependence\ncan also arise from the DM radius effect. All these momentum-transfer\ndependences should be considered. In this note we study the direct detection\nlimits on the cosmic ray-boosted puffy DM for a simplified model with a light\nmediator. For comparison, we first re-derive the direct detection limits on the\ncosmic ray-boosted point-like DM. We display the limits on various planes of\nparameters and find that the limits for the cosmic ray-boosted puffy DM are\nstronger than for the point-like DM.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:14:46 GMT"},{"version":"v2","created":"Tue, 30 May 2023 02:18:03 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.12669","submitter":"Jie Yang","authors":"Jie Yang, Chao-Kai Wen, Jing Xu, Hang Que, Haikun Wei, Shi Jin","title":"Angle-based SLAM on 5G mmWave Systems: Design, Implementation, and\n  Measurement","comments":"Accepted by the IEEE Internet of Things Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Simultaneous localization and mapping (SLAM) is a key technology that\nprovides user equipment (UE) tracking and environment mapping services,\nenabling the deep integration of sensing and communication. The millimeter-wave\n(mmWave) communication, with its larger bandwidths and antenna arrays,\ninherently facilitates more accurate delay and angle measurements than sub-6\nGHz communication, thereby providing opportunities for SLAM. However, none of\nthe existing works have realized the SLAM function under the 5G New Radio (NR)\nstandard due to specification and hardware constraints. In this study, we\ninvestigate how 5G mmWave communication systems can achieve situational\nawareness without changing the transceiver architecture and 5G NR standard. We\nimplement 28 GHz mmWave transceivers that deploy OFDM-based 5G NR waveform with\n160 MHz channel bandwidth, and we realize beam management following the 5G NR.\nFurthermore, we develop an efficient successive cancellation-based angle\nextraction approach to obtain angles of arrival and departure from the\nreference signal received power measurements. On the basis of angle\nmeasurements, we propose an angle-only SLAM algorithm to track UE and map\nfeatures in the radio environment. Thorough experiments and ray tracing-based\ncomputer simulations verify that the proposed angle-based SLAM can achieve\nsub-meter level localization and mapping accuracy with a single base station\nand without the requirement of strict time synchronization. Our experiments\nalso reveal many propagation properties critical to the success of SLAM in 5G\nmmWave communication systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:17:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12670","submitter":"Peixin Zhu","authors":"Peixin Zhu, Lisa J. Kewley, and Ralph S. Sutherland","title":"A New Photoionization Model of the Narrow Line Region in Active Galactic\n  Nuclei","comments":"23 pages, 11 figures, Accepted for publication in ApJ","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The photoionization model of narrow-line regions (NLRs) in active galactic\nnuclei (AGNs) has been investigated for decades. Many published models are\nrestricted to simple linear scaling abundance relations, dust-free assumption,\nuniform AGN radiation field, and using one specific photoionization code, which\nrestricts them from providing a satisfactory prediction on a broad range of AGN\nobservations. Through a comprehensive investigation, here we present how the\nchoice of abundance scaling relations, dust inclusion, AGN radiation fields,\nand different photoionization codes CLOUDY and MAPPINGS affect the predictions\non the strength of strong UV, optical, and infrared emission lines. We find the\ndust-depleted radiation pressure-dominated AGN model built with the latest\nnon-linear abundance sets and photoionization code MAPPINGS V are consistent\nwith AGN observations across a broad range of wavelengths. We also assess new\npotential HII-AGN separation diagrams in the optical and UV wavelengths.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:18:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12671","submitter":"Carlos A. Aguirre","authors":"Carlos Aguirre and Mark Dredze","title":"Generalizing Fairness using Multi-Task Learning without Demographic\n  Information","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  To ensure the fairness of machine learning systems, we can include a fairness\nloss during training based on demographic information associated with the\ntraining data. However, we cannot train debiased classifiers for most tasks\nsince the relevant datasets lack demographic annotations. Can we utilize\ndemographic data for a related task to improve the fairness of our target task?\nWe demonstrate that demographic fairness objectives transfer to new tasks\ntrained within a multi-task framework. We adapt a single-task fairness loss to\na multi-task setting to exploit demographic labels from a related task in\ndebiasing a target task. We explore different settings with missing demographic\ndata and show how our loss can improve fairness even without in-task\ndemographics, across various domains and tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:22:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12672","submitter":"Weijie Gan","authors":"Weijie Gan, Shirin Shoushtari, Yuyang Hu, Jiaming Liu, Hongyu An,\n  Ulugbek S. Kamilov","title":"Block Coordinate Plug-and-Play Methods for Blind Inverse Problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Plug-and-play (PnP) prior is a well-known class of methods for solving\nimaging inverse problems by computing fixed-points of operators combining\nphysical measurement models and learned image denoisers. While PnP methods have\nbeen extensively used for image recovery with known measurement operators,\nthere is little work on PnP for solving blind inverse problems. We address this\ngap by presenting a new block-coordinate PnP (BC-PnP) method that efficiently\nsolves this joint estimation problem by introducing learned denoisers as priors\non both the unknown image and the unknown measurement operator. We present a\nnew convergence theory for BC-PnP compatible with blind inverse problems by\nconsidering nonconvex data-fidelity terms and expansive denoisers. Our theory\nanalyzes the convergence of BC-PnP to a stationary point of an implicit\nfunction associated with an approximate minimum mean-squared error (MMSE)\ndenoiser. We numerically validate our method on two blind inverse problems:\nautomatic coil sensitivity estimation in magnetic resonance imaging (MRI) and\nblind image deblurring. Our results show that BC-PnP provides an efficient and\nprincipled framework for using denoisers as PnP priors for jointly estimating\nmeasurement operators and images.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:27:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12673","submitter":"Lingfeng He","authors":"De cheng, Lingfeng He, Nannan Wang, Shizhou Zhang, Zhen Wang and Xinbo\n  Gao","title":"Efficient Bilateral Cross-Modality Cluster Matching for Unsupervised\n  Visible-Infrared Person ReID","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Unsupervised visible-infrared person re-identification (USL-VI-ReID) aims to\nmatch pedestrian images of the same identity from different modalities without\nannotations. Existing works mainly focus on alleviating the modality gap by\naligning instance-level features of the unlabeled samples. However, the\nrelationships between cross-modality clusters are not well explored. To this\nend, we propose a novel bilateral cluster matching-based learning framework to\nreduce the modality gap by matching cross-modality clusters. Specifically, we\ndesign a Many-to-many Bilateral Cross-Modality Cluster Matching (MBCCM)\nalgorithm through optimizing the maximum matching problem in a bipartite graph.\nThen, the matched pairwise clusters utilize shared visible and infrared\npseudo-labels during the model training. Under such a supervisory signal, a\nModality-Specific and Modality-Agnostic (MSMA) contrastive learning framework\nis proposed to align features jointly at a cluster-level. Meanwhile, the\ncross-modality Consistency Constraint (CC) is proposed to explicitly reduce the\nlarge modality discrepancy. Extensive experiments on the public SYSU-MM01 and\nRegDB datasets demonstrate the effectiveness of the proposed method, surpassing\nstate-of-the-art approaches by a large margin of 8.76% mAP on average.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:27:46 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 03:34:00 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12674","submitter":"Kazumi Okuyama","authors":"Kazumi Okuyama","title":"End of the world brane in double scaled SYK","comments":"20 pages; v2: minor corrections","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the end of the world (EOW) brane in double scaled SYK (DSSYK) model.\nWe find that the boundary state of EOW brane is a coherent state of the\n$q$-deformed oscillators and the associated orthogonal polynomial is the\ncontinuous big $q$-Hermite polynomial. In a certain scaling limit, the big\n$q$-Hermite polynomial reduces to the Whittaker function, which reproduces the\nwavefunction of JT gravity with an EOW brane. We also compute the half-wormhole\namplitude in DSSYK and show that the amplitude is decomposed into the trumpet\nand the factor coming from the EOW brane.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:28:46 GMT"},{"version":"v2","created":"Thu, 25 May 2023 06:13:05 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12675","submitter":"Haoran Yang","authors":"Haoran Yang, Deng Cai, Huayang Li, Wei Bi, Wai Lam, Shuming Shi","title":"A Frustratingly Simple Decoding Method for Neural Text Generation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a frustratingly simple, super efficient and surprisingly\neffective decoding method, which we call Frustratingly Simple Decoding (FSD),\nfor neural text generation. The idea behind FSD is straightforward: we build an\nanti-LM based on previously generated text and use this anti-LM to penalize\nfuture generation of what has been generated. The anti-LM can be implemented as\nsimple as an n-gram language model or a vectorized variant. In this way, FSD\nintroduces no extra model parameters and negligible computational overhead (FSD\ncan be as fast as greedy search). Despite the simplicity, FSD is surprisingly\neffective; Experiments show that FSD can outperform the canonical methods to\ndate (i.e., nucleus sampling) as well as several strong baselines that were\nproposed recently.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:28:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12676","submitter":"Hong Liu","authors":"Hong Liu, Zhaobiao Lv, Zhijian Ou, Wenbo Zhao, Qing Xiao","title":"Exploring Energy-based Language Models with Different Architectures and\n  Training Methods for Speech Recognition","comments":"Accepted into INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Energy-based language models (ELMs) parameterize an unnormalized distribution\nfor natural sentences and are radically different from popular autoregressive\nlanguage models (ALMs). As an important application, ELMs have been\nsuccessfully used as a means for calculating sentence scores in speech\nrecognition, but they all use less-modern CNN or LSTM networks. The recent\nprogress in Transformer networks and large pretrained models such as BERT and\nGPT2 opens new possibility to further advancing ELMs. In this paper, we explore\ndifferent architectures of energy functions and different training methods to\ninvestigate the capabilities of ELMs in rescoring for speech recognition, all\nusing large pretrained models as backbones.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:28:48 GMT"},{"version":"v2","created":"Fri, 26 May 2023 05:55:34 GMT"},{"version":"v3","created":"Mon, 29 May 2023 06:38:21 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12677","submitter":"Jinsong Chen","authors":"Jinsong Chen, Chang Liu, Kaiyuan Gao, Gaichao Li, Kun He","title":"Tokenized Graph Transformer with Neighborhood Augmentation for Node\n  Classification in Large Graphs","comments":"14pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:2206.04910","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph Transformers, emerging as a new architecture for graph representation\nlearning, suffer from the quadratic complexity on the number of nodes when\nhandling large graphs. To this end, we propose a Neighborhood Aggregation Graph\nTransformer (NAGphormer) that treats each node as a sequence containing a\nseries of tokens constructed by our proposed Hop2Token module. For each node,\nHop2Token aggregates the neighborhood features from different hops into\ndifferent representations, producing a sequence of token vectors as one input.\nIn this way, NAGphormer could be trained in a mini-batch manner and thus could\nscale to large graphs. Moreover, we mathematically show that compared to a\ncategory of advanced Graph Neural Networks (GNNs), called decoupled Graph\nConvolutional Networks, NAGphormer could learn more informative node\nrepresentations from multi-hop neighborhoods. In addition, we propose a new\ndata augmentation method called Neighborhood Augmentation (NrAug) based on the\noutput of Hop2Token that augments simultaneously the features of neighborhoods\nfrom global as well as local views to strengthen the training effect of\nNAGphormer. Extensive experiments on benchmark datasets from small to large\ndemonstrate the superiority of NAGphormer against existing graph Transformers\nand mainstream GNNs, and the effectiveness of NrAug for further boosting\nNAGphormer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:29:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12678","submitter":"Thong Nguyen","authors":"Thong Nguyen, Xiaobao Wu, Xinshuai Dong, Anh Tuan Luu, Cong-Duy\n  Nguyen, Zhen Hai, Lidong Bing","title":"Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal\n  Review Helpfulness Prediction","comments":"Published in ACL 2023 (Findings)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews\nbased on predicted helpfulness scores and has been widely applied in e-commerce\nvia presenting customers with useful reviews. Previous studies commonly employ\nfully-connected neural networks (FCNNs) as the final score predictor and\npairwise loss as the training objective. However, FCNNs have been shown to\nperform inefficient splitting for review features, making the model difficult\nto clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise\nobjective, which works on review pairs, may not completely capture the MRHP\ngoal to produce the ranking for the entire review list, and possibly induces\nlow generalization during testing. To address these issues, we propose a\nlistwise attention network that clearly captures the MRHP ranking context and a\nlistwise optimization objective that enhances model generalization. We further\npropose gradient-boosted decision tree as the score predictor to efficaciously\npartition product reviews' representations. Extensive experiments demonstrate\nthat our method achieves state-of-the-art results and polished generalization\nperformance on two large-scale MRHP benchmark datasets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:31:00 GMT"},{"version":"v2","created":"Thu, 25 May 2023 04:51:43 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12679","submitter":"Chenjie Mao","authors":"Chenjie Mao","title":"Offline Reinforcement Learning with Additional Covering Distributions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study learning optimal policies from a logged dataset, i.e., offline RL,\nwith function approximation. Despite the efforts devoted, existing algorithms\nwith theoretic finite-sample guarantees typically assume exploratory data\ncoverage or strong realizable function classes, which is hard to be satisfied\nin reality. While there are recent works that successfully tackle these strong\nassumptions, they either require the gap assumptions that only could be\nsatisfied by part of MDPs or use the behavior regularization that makes the\noptimality of learned policy even intractable. To solve this challenge, we\nprovide finite-sample guarantees for a simple algorithm based on marginalized\nimportance sampling (MIS), showing that sample-efficient offline RL for general\nMDPs is possible with only a partial coverage dataset and weak realizable\nfunction classes given additional side information of a covering distribution.\nFurthermore, we demonstrate that the covering distribution trades off prior\nknowledge of the optimal trajectories against the coverage requirement of the\ndataset, revealing the effect of this inductive bias in the learning processes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:31:03 GMT"},{"version":"v2","created":"Wed, 24 May 2023 13:25:31 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12680","submitter":"Haolan Zhan","authors":"Haolan Zhan and Xuanli He and Qiongkai Xu and Yuxiang Wu and Pontus\n  Stenetorp","title":"G3Detector: General GPT-Generated Text Detector","comments":"Work in Progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:35:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12681","submitter":"Yuta Mimura","authors":"Yuta Mimura","title":"Phased data augmentation for training PixelCNNs with VQ-VAE-2 and\n  limited data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With development of deep learning, researchers have developed generative\nmodels in generating realistic images. One of such generative models, a\nPixelCNNs model with Vector Quantized Variational AutoEncoder 2 (VQ-VAE-2), can\ngenerate more various images than other models. However, a PixelCNNs model with\nVQ-VAE-2, I call it PC-VQ2, requires sufficiently much training data like other\ndeep learning models. Its practical applications are often limited in domains\nwhere collecting sufficient data is not difficult. To solve the problem,\nresearchers have recently proposed more data-efficient methods for training\ngenerative models with limited unlabeled data from scratch. However, no such\nmethods in PC-VQ2s have been researched. This study provides the first step in\nthis direction, considering generation of images using PC-VQ2s and limited\nunlabeled data. In this study, I propose a training strategy for training a\nPC-VQ2 with limited data from scratch, phased data augmentation. In the\nstrategy, ranges of parameters of data augmentation is narrowed in phases\nthrough learning. Quantitative evaluation shows that the phased data\naugmentation enables the model with limited data to generate images competitive\nwith the one with sufficient data in diversity and outperforming it in\nfidelity. The evaluation suggests that the proposed method should be useful for\ntraining a PC-VQ2 with limited data efficiently to generate various and natural\nimages.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:38:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12682","submitter":"Mahdi Chehimi","authors":"Mahdi Chehimi, Bernd Simon, Walid Saad, Anja Klein, Don Towsley,\n  M\\'erouane Debbah","title":"Matching Game for Optimized Association in Quantum Communication\n  Networks","comments":"6 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Enabling quantum switches (QSs) to serve requests submitted by quantum end\nnodes in quantum communication networks (QCNs) is a challenging problem due to\nthe heterogeneous fidelity requirements of the submitted requests and the\nlimited resources of the QCN. Effectively determining which requests are served\nby a given QS is fundamental to foster developments in practical QCN\napplications, like quantum data centers. However, the state-of-the-art on QS\noperation has overlooked this association problem, and it mainly focused on\nQCNs with a single QS. In this paper, the request-QS association problem in\nQCNs is formulated as a matching game that captures the limited QCN resources,\nheterogeneous application-specific fidelity requirements, and scheduling of the\ndifferent QS operations. To solve this game, a swap-stable request-QS\nassociation (RQSA) algorithm is proposed while considering partial QCN\ninformation availability. Extensive simulations are conducted to validate the\neffectiveness of the proposed RQSA algorithm. Simulation results show that the\nproposed RQSA algorithm achieves a near-optimal (within 5%) performance in\nterms of the percentage of served requests and overall achieved fidelity, while\noutperforming benchmark greedy solutions by over 13%. Moreover, the proposed\nRQSA algorithm is shown to be scalable and maintain its near-optimal\nperformance even when the size of the QCN increases.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:39:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12683","submitter":"Chumeng Liang","authors":"Chumeng Liang, Xiaoyu Wu","title":"Mist: Towards Improved Adversarial Examples for Diffusion Models","comments":"Working paper","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Diffusion Models (DMs) have empowered great success in\nartificial-intelligence-generated content, especially in artwork creation, yet\nraising new concerns in intellectual properties and copyright. For example,\ninfringers can make profits by imitating non-authorized human-created paintings\nwith DMs. Recent researches suggest that various adversarial examples for\ndiffusion models can be effective tools against these copyright infringements.\nHowever, current adversarial examples show weakness in transferability over\ndifferent painting-imitating methods and robustness under straightforward\nadversarial defense, for example, noise purification. We surprisingly find that\nthe transferability of adversarial examples can be significantly enhanced by\nexploiting a fused and modified adversarial loss term under consistent\nparameters. In this work, we comprehensively evaluate the cross-method\ntransferability of adversarial examples. The experimental observation shows\nthat our method generates more transferable adversarial examples with even\nstronger robustness against the simple adversarial defense.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:43:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12684","submitter":"Brian Shin","authors":"Brian Shin","title":"Norms and Transfers in Motivic Homotopy Theory","comments":"49 pages, comments welcome!","journal-ref":null,"doi":null,"report-no":null,"categories":"math.KT math.AG math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study norm functors in the sense of Bachmann--Hoyois for various\n$\\infty$-categories of correspondences occurring in motivic homotopy theory. We\nshow in particular that the symmetric monoidal structure on the\n$\\infty$-category of framed correspondence can be refined to a norm monoidal\nstructure, and that the resulting norm monoidal structure on the\n$\\infty$-category of motivic spectra with framed transfers is compatible with\nthe Reconstruction Theorem of Elmanto--Hoyois--Khan--Sosnilo--Yakerson. This\nyields a recognition principle for normed motivic spectra. We show similar\nresults for various other flavors of transfer, e.g. finite syntomic and\noriented finite Gorenstein.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:44:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12685","submitter":"Tianle Wang","authors":"Tianle Wang, Lianghao Xia, Chao Huang","title":"Denoised Self-Augmented Learning for Social Recommendation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Social recommendation is gaining increasing attention in various online\napplications, including e-commerce and online streaming, where social\ninformation is leveraged to improve user-item interaction modeling. Recently,\nSelf-Supervised Learning (SSL) has proven to be remarkably effective in\naddressing data sparsity through augmented learning tasks. Inspired by this,\nresearchers have attempted to incorporate SSL into social recommendation by\nsupplementing the primary supervised task with social-aware self-supervised\nsignals. However, social information can be unavoidably noisy in characterizing\nuser preferences due to the ubiquitous presence of interest-irrelevant social\nconnections, such as colleagues or classmates who do not share many common\ninterests. To address this challenge, we propose a novel social recommender\ncalled the Denoised Self-Augmented Learning paradigm (DSL). Our model not only\npreserves helpful social relations to enhance user-item interaction modeling\nbut also enables personalized cross-view knowledge transfer through adaptive\nsemantic alignment in embedding space. Our experimental results on various\nrecommendation benchmarks confirm the superiority of our DSL over\nstate-of-the-art methods. We release our model implementation at:\nhttps://github.com/HKUDS/DSL.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:48:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12686","submitter":"Wenlu Tang","authors":"Wenlu Tang, Zicheng Liu","title":"Conformal Inference for Invariant Risk Minimization","comments":"arXiv admin note: text overlap with arXiv:2209.11355","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ML cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The application of machine learning models can be significantly impeded by\nthe occurrence of distributional shifts, as the assumption of homogeneity\nbetween the population of training and testing samples in machine learning and\nstatistics may not be feasible in practical situations. One way to tackle this\nproblem is to use invariant learning, such as invariant risk minimization\n(IRM), to acquire an invariant representation that aids in generalization with\ndistributional shifts. This paper develops methods for obtaining\ndistribution-free prediction regions to describe uncertainty estimates for\ninvariant representations, accounting for the distribution shifts of data from\ndifferent environments. Our approach involves a weighted conformity score that\nadapts to the specific environment in which the test sample is situated. We\nconstruct an adaptive conformal interval using the weighted conformity score\nand prove its conditional average under certain conditions. To demonstrate the\neffectiveness of our approach, we conduct several numerical experiments,\nincluding simulation studies and a practical example using real-world data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:48:38 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12687","submitter":"Zhipeng Wang","authors":"Z.P. Wang and R.J. Lin, Z.Y. Zhao, P.M. Guo, N. Yang, D.X. Fan","title":"Learn to Flap: Foil Non-parametric Path Planning via Deep Reinforcement\n  Learning","comments":"submitted to Journal of Fluid Mechanics rapids","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To optimize flapping foil performance, the application of deep reinforcement\nlearning (DRL) on controlling foil non-parametric motion is conducted in the\npresent study. Traditional control techniques and simplified motions cannot\nfully model nonlinear, unsteady and high-dimensional foil-vortex interactions.\nA DRL-training framework based on Proximal Policy Optimization and Transformer\narchitecture is proposed. The policy is initialized from the sinusoidal expert\ndisplay. We first demonstrate the effectiveness of the proposed DRL-training\nframework which can optimize foil motion while enhancing foil generated thrust.\nBy adjusting reward setting and action threshold, the DRL-optimized foil\ntrajectories can gain further enhancement compared to sinusoidal motion. Via\nflow analysis of wake morphology and instantaneous pressure distributions, it\nis found that the DRL-optimized foil can adaptively adjust the phases between\nmotion and shedding vortices to improve hydrodynamic performance. Our results\ngive a hint for solving complex fluid manipulation problems through DRL method.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:50:16 GMT"},{"version":"v2","created":"Thu, 25 May 2023 07:17:36 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12688","submitter":"Rui Xue","authors":"Rui Xue","title":"Testing Isomorphism of Graphs in Polynomial Time","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.CC cs.DM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given a graph $G$, the graph $[G]$ obtained by adding, for each pair of\nvertices of $G$, a unique vertex adjacent to both vertices is called the\nbinding graph of $G$. In this work, we show that the class of binding graphs is\ngraph-isomorphism complete and that the stable partitions of binding graphs by\nthe Weisfeiler-Lehman (WL) algorithm produce automorphism partitions. To test\nthe isomorphism of two graphs $G$ and $H$, one computes the stable graph of the\nbinding graph $[G\\uplus H]$ for the disjoint union graph $G\\uplus H$. The\nautomorphism partition reveals the isomorphism of $G$ and $H$. Because the WL\nalgorithm is a polynomial-time procedure, the claim can be made that the\ngraph-isomorphism problem is in complexity class $\\mathtt{P}$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:53:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12689","submitter":"Ting Chen","authors":"Ting Chen and Lala Li","title":"FIT: Far-reaching Interleaved Transformers","comments":"preliminary work (code at https://github.com/google-research/pix2seq)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present FIT: a transformer-based architecture with efficient\nself-attention and adaptive computation. Unlike original transformers, which\noperate on a single sequence of data tokens, we divide the data tokens into\ngroups, with each group being a shorter sequence of tokens. We employ two types\nof transformer layers: local layers operate on data tokens within each group,\nwhile global layers operate on a smaller set of introduced latent tokens. These\nlayers, comprising the same set of self-attention and feed-forward layers as\nstandard transformers, are interleaved, and cross-attention is used to\nfacilitate information exchange between data and latent tokens within the same\ngroup. The attention complexity is $O(n^2)$ locally within each group of size\n$n$, but can reach $O(L^{{4}/{3}})$ globally for sequence length of $L$. The\nefficiency can be further enhanced by relying more on global layers that\nperform adaptive computation using a smaller set of latent tokens. FIT is a\nversatile architecture and can function as an encoder, diffusion decoder, or\nautoregressive decoder. We provide initial evidence demonstrating its\neffectiveness in high-resolution image understanding and generation tasks.\nNotably, FIT exhibits potential in performing end-to-end training on\ngigabit-scale data, such as 6400$\\times$6400 images, or 160K tokens (after\npatch tokenization), within a memory capacity of 16GB, without requiring\nspecific optimizations or model parallelism.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:56:44 GMT"},{"version":"v2","created":"Thu, 25 May 2023 16:27:30 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12690","submitter":"Saleh Naqib","authors":"Mst. Bina Aktar, F. Parvin, A. K. M. Azharul Islam, S. H. Naqib","title":"Structural, elastic, electronic, bonding, thermo-mechanical and optical\n  properties of predicted NbAlB MAB phase in comparison to MoAlB: DFT based\n  ab-initio insights","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we have used density functional theory (DFT) based\nfirst-principles investigation of the physical properties of prospective NbAlB\ncompound for the first time. From the analysis of the cohesive energy and\nenthalpy of formation, it was found that NbAlB is chemically stable. The\nphysical properties of NbAlB have been compared and contrasted with those\nobtained for MoAlB. Both these MAB phases are elastically anisotropic,\nmechanically stable, machinable and brittle materials. Structural and elastic\nfeatures reflect the layered features. The estimated hardness of NbAlB is 19.0\nGPa comparable to that of MoAlB (20.8 GPa) suggesting that predicted NbAlB is a\nhard compound and is suitable for heavy duty industrial applications. NbAlB is\nmore machinable than MoAlB. Electronic band structure calculations reveal\nconventional metallic behavior with the electronic density of states at the\nFermi level arising mainly due to the Nb 4d orbitals in NbAlB. The electronic\ndensity of states at the Fermi level is significantly higher in NbAlB in\ncomparison to MoAlB, indicating that NbAlB is expected to exhibit higher level\nof electrical conductivity. Electronic dispersion is highly anisotropic for\nboth MoAlB and NbAlB with substantially large electronic effective masses in\nthe out-of-plane directions. The bonding features have been elucidated via the\nanalysis of the band structure and charge density distribution. Both the\ncompounds have mixed covalent, ionic and metallic bonding characteristics. The\nFermi surfaces of MoAlB and NbAlB consists of electron and hole like sheets.\nThe Debye temperatures of MoAlB and NbAlB are comparable. The estimated melting\ntemperature of NbAlB is somewhat lower than that of MoAlB. NbAlB shows\nexcellent reflection characteristics suitable to be used as an efficient solar\nreflector. NbAlB is also expected to absorb ultraviolet radiation very\neffectively.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:58:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12691","submitter":"Yuxia Chen","authors":"Yuxia Chen, Pengcheng Fang, Jianhui Yu, Xiaoling Zhong, Xiaoming\n  Zhang, Tianrui Li","title":"Hi-ResNet: A High-Resolution Remote Sensing Network for Semantic\n  Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  High-resolution remote sensing (HRS) semantic segmentation extracts key\nobjects from high-resolution coverage areas. However, objects of the same\ncategory within HRS images generally show significant differences in scale and\nshape across diverse geographical environments, making it difficult to fit the\ndata distribution. Additionally, a complex background environment causes\nsimilar appearances of objects of different categories, which precipitates a\nsubstantial number of objects into misclassification as background. These\nissues make existing learning algorithms sub-optimal. In this work, we solve\nthe above-mentioned problems by proposing a High-resolution remote sensing\nnetwork (Hi-ResNet) with efficient network structure designs, which consists of\na funnel module, a multi-branch module with stacks of information aggregation\n(IA) blocks, and a feature refinement module, sequentially, and Class-agnostic\nEdge Aware (CEA) loss. Specifically, we propose a funnel module to downsample,\nwhich reduces the computational cost, and extract high-resolution semantic\ninformation from the initial input image. Secondly, we downsample the processed\nfeature images into multi-resolution branches incrementally to capture image\nfeatures at different scales and apply IA blocks, which capture key latent\ninformation by leveraging attention mechanisms, for effective feature\naggregation, distinguishing image features of the same class with variant\nscales and shapes. Finally, our feature refinement module integrate the CEA\nloss function, which disambiguates inter-class objects with similar shapes and\nincreases the data distribution distance for correct predictions. With\neffective pre-training strategies, we demonstrated the superiority of Hi-ResNet\nover state-of-the-art methods on three HRS segmentation benchmarks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:58:25 GMT"},{"version":"v2","created":"Tue, 23 May 2023 04:32:46 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12692","submitter":"Zhenrui Yue","authors":"Zhenrui Yue, Huimin Zeng, Yang Zhang, Lanyu Shang, Dong Wang","title":"MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta\n  Learning","comments":"Accepted to ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  With emerging topics (e.g., COVID-19) on social media as a source for the\nspreading misinformation, overcoming the distributional shifts between the\noriginal training domain (i.e., source domain) and such target domains remains\na non-trivial task for misinformation detection. This presents an elusive\nchallenge for early-stage misinformation detection, where a good amount of data\nand annotations from the target domain is not available for training. To\naddress the data scarcity issue, we propose MetaAdapt, a meta learning based\napproach for domain adaptive few-shot misinformation detection. MetaAdapt\nleverages limited target examples to provide feedback and guide the knowledge\ntransfer from the source to the target domain (i.e., learn to adapt). In\nparticular, we train the initial model with multiple source tasks and compute\ntheir similarity scores to the meta task. Based on the similarity scores, we\nrescale the meta gradients to adaptively learn from the source tasks. As such,\nMetaAdapt can learn how to adapt the misinformation detection model and exploit\nthe source data for improved performance in the target domain. To demonstrate\nthe efficiency and effectiveness of our method, we perform extensive\nexperiments to compare MetaAdapt with state-of-the-art baselines and large\nlanguage models (LLMs) such as LLaMA, where MetaAdapt achieves better\nperformance in domain adaptive few-shot misinformation detection with\nsubstantially reduced parameters on real-world datasets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:00:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12693","submitter":"Ke Yang","authors":"Yi Zhong, Ke Yang","title":"Localization of matter fields on a chameleon brane","comments":"17 pages, 21 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th gr-qc","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  In this work, we address the localization problem of vector field in the\nchameleon braneworld and investigate the localization of various matter fields.\nThe conditions for localizing the matter fields are determined. It is found\nthat the zero modes of scalar, vector, and fermion fields can be successfully\nlocalized, yet the zero mode of Kalb-Ramond field cannot be localized, which\nimplies that the recovery of standard model fields on the brane. Furthermore,\nthe characteristics of quasi-localized modes of the $q$-form fields are\nanalyzed, and the parameter constraints of the model are estimated.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:01:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12694","submitter":"Thierno Ibrahima Ciss\\'e","authors":"Thierno Ibrahima Ciss\\'e and Fatiha Sadat","title":"Automatic Spell Checker and Correction for Under-represented Spoken\n  Languages: Case Study on Wolof","comments":"10 pages, 1 figure, 7 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents a spell checker and correction tool specifically designed\nfor Wolof, an under-represented spoken language in Africa. The proposed spell\nchecker leverages a combination of a trie data structure, dynamic programming,\nand the weighted Levenshtein distance to generate suggestions for misspelled\nwords. We created novel linguistic resources for Wolof, such as a lexicon and a\ncorpus of misspelled words, using a semi-automatic approach that combines\nmanual and automatic annotation methods. Despite the limited data available for\nthe Wolof language, the spell checker's performance showed a predictive\naccuracy of 98.31% and a suggestion accuracy of 93.33%. Our primary focus\nremains the revitalization and preservation of Wolof as an Indigenous and\nspoken language in Africa, providing our efforts to develop novel linguistic\nresources. This work represents a valuable contribution to the growth of\ncomputational tools and resources for the Wolof language and provides a strong\nfoundation for future studies in the automatic spell checking and correction\nfield.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:03:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12695","submitter":"Ali Kazemi Arani","authors":"Ali Kazemi Arani, Triet Huynh Minh Le, Mansooreh Zahedi and Muhammad\n  Ali Babar","title":"Systematic Literature Review on Application of Machine Learning in\n  Continuous Integration","comments":"37 pages, 20 Tables, 8 Figures, submitted to Journal of Systems and\n  Software","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This research conducted a systematic review of the literature on machine\nlearning (ML)-based methods in the context of Continuous Integration (CI) over\nthe past 22 years. The study aimed to identify and describe the techniques used\nin ML-based solutions for CI and analyzed various aspects such as data\nengineering, feature engineering, hyper-parameter tuning, ML models, evaluation\nmethods, and metrics. In this paper, we have depicted the phases of CI testing,\nthe connection between them, and the employed techniques in training the ML\nmethod phases. We presented nine types of data sources and four taken steps in\nthe selected studies for preparing the data. Also, we identified four feature\ntypes and nine subsets of data features through thematic analysis of the\nselected studies. Besides, five methods for selecting and tuning the\nhyper-parameters are shown. In addition, we summarised the evaluation methods\nused in the literature and identified fifteen different metrics. The most\ncommonly used evaluation methods were found to be precision, recall, and\nF1-score, and we have also identified five methods for evaluating the\nperformance of trained ML models. Finally, we have presented the relationship\nbetween ML model types, performance measurements, and CI phases. The study\nprovides valuable insights for researchers and practitioners interested in\nML-based methods in CI and emphasizes the need for further research in this\narea.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:07:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12696","submitter":"Ajay Patel","authors":"Ajay Patel, Delip Rao, Chris Callison-Burch","title":"Learning Interpretable Style Embeddings via Prompting LLMs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Style representation learning builds content-independent representations of\nauthor style in text. Stylometry, the analysis of style in text, is often\nperformed by expert forensic linguists and no large dataset of stylometric\nannotations exists for training. Current style representation learning uses\nneural methods to disentangle style from content to create style vectors,\nhowever, these approaches result in uninterpretable representations,\ncomplicating their usage in downstream applications like authorship attribution\nwhere auditing and explainability is critical. In this work, we use prompting\nto perform stylometry on a large number of texts to create a synthetic dataset\nand train human-interpretable style representations we call LISA embeddings. We\nrelease our synthetic stylometry dataset and our interpretable style models as\nresources.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:07:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12697","submitter":"Ayan Khan","authors":"Argha Debnath, Ayan Khan, Prasanta K Panigrahi","title":"Dynamics of Bright Soliton Under Cubic-Quartic Interactions in Quasi\n  One-Dimensional Geometry","comments":"11 pages, 27 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent inspection of liquid-like state in ultracold atomic gases due to the\nstabilization mechanism through the delicate balance between effective\nmean-field and beyond mean-field (BMF) interactions, has motivated us to study\nthe modified/extended Gross-Pitaevskii (eGP) equation which includes the BMF\ncontribution. In this article, we focus on variational analysis of solitonic\nregime with eGP equation while the soliton is subjected to an obstacle. This\nreveals different scattering scenarios of the soliton with explicit dependence\nof the BMF interaction. The results show the existence of tunneling, partial\nand complete trappings, in different parameter domains. These observations are\nfurther corroborated by the fast-Fourier transform method. In the later part we\nalso extend our analysis to trapped systems. The controlled trapping in defect\npotential and its release can be potentially useful for quantum information\nstorage.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:09:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12698","submitter":"Ananya Parashar","authors":"Dwaipayan Saha and Ananya Parashar","title":"Prophet Inequalities for Subadditive Combinatorial Auctions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we survey literature on prophet inequalities for subadditive\ncombinatorial auctions. We give an overview of the previous best $O(\\log \\log\nm)$ prophet inequality as well as the preceding $O(\\log m)$ prophet inequality.\nThen, we provide the constructive posted price mechanisms used in order to\nprove the two bounds. We mainly focus on the most recent literature that\nresolves a central open problem in this area of discovering a constant factor\nprophet inequality for subadditive valuations. We detail the approach of this\nnew paper, which is $\\textit{non-constructive}$ and therefore cannot be\nimplemented using prices, as done in previous literature.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:11:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12699","submitter":"Ramy E. Ali","authors":"Ramy E. Ali","title":"Comments on CausalEC: A Causally Consistent Data Storage Algorithm Based\n  on Cross-Object Erasure Coding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT cs.DC math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cadambe and Lyu 2021 presents an erasure coding based algorithm called\nCausalEC that ensures causal consistency based on cross-object erasure coding.\nThis note shows that the algorithm presented in Cadambe and Lyu 2021 and the\nmain ideas behind it are in essence the same as the algorithm developed in Lyu,\nCadambe, Ali and Urgaonkar 2018.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:12:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12700","submitter":"Tomoya Asaba","authors":"Tomoya Asaba, Lang Peng, Takahiro Ono, Satoru Akutagawa, Ibuki Tanaka,\n  Hinako Murayama, Shota Suetsugu, Aleksandar Razpopov, Yuichi Kasahara,\n  Takahito Terashima, Yuhki Kohsaka, Takasada Shibauchi, Masatoshi Ichikawa,\n  Roser Valent\\'i, Shin-ichi Sasa, Yuji Matsuda","title":"Growth of self-integrated atomic quantum wires and junctions of a Mott\n  semiconductor","comments":null,"journal-ref":"Sci. Adv.9,eabq5561(2023)","doi":"10.1126/sciadv.abq5561","report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el nlin.AO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Continued advances in quantum technologies rely on producing nanometer-scale\nwires. Although several state-of-the-art nanolithographic technologies and\nbottom-up synthesis processes have been used to engineer such wires, critical\nchallenges remain in growing uniform atomic-scale crystalline wires and\nconstructing their network structures. Here we discover a simple method to\nfabricate atomic-scale wires with various arrangements, including stripes, X-,\nY-junctions, and nanorings. Single-crystalline atomic-scale wires of a Mott\ninsulator, whose band gap is comparable to those of wide-gap semiconductors,\nare spontaneously grown on graphite substrates \\DEL{and epitaxial monolayer\ngraphene on SiC }by pulsed-laser deposition. These wires are\none-unit-cell-thick and have an exact width of two- and four-unit-cells (1.4\nand 2.8\\,nm) and lengths up to a few $\\mu m$. We show that the non-equilibrium\nreaction-diffusion processes may play an essential role in atomic pattern\nformation. Our findings offer a new perspective on the non-equilibrium\nself-organization phenomena on an atomic scale, paving a unique way for the\nquantum architecture of nano-network.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:13:53 GMT"},{"version":"v2","created":"Tue, 23 May 2023 02:38:17 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12701","submitter":"Shipei Liu","authors":"Shipei Liu, Xiaoya Fan, Guowei Wu","title":"More Perspectives Mean Better: Underwater Target Recognition and\n  Localization with Multimodal Data via Symbiotic Transformer and Multiview\n  Regression","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.MM eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Underwater acoustic target recognition (UATR) and localization (UATL) play\nimportant roles in marine exploration. The highly noisy acoustic signal and\ntime-frequency interference among various sources pose big challenges to this\ntask. To tackle these issues, we propose a multimodal approach to extract and\nfuse audio-visual-textual information to recognize and localize underwater\ntargets through the designed Symbiotic Transformer (Symb-Trans) and Multi-View\nRegression (MVR) method. The multimodal data were first preprocessed by a\ncustom-designed HetNorm module to normalize the multi-source data in a common\nfeature space. The Symb-Trans module embeds audiovisual features by co-training\nthe preprocessed multimodal features through parallel branches and a content\nencoder with cross-attention. The audiovisual features are then used for\nunderwater target recognition. Meanwhile, the text embedding combined with the\naudiovisual features is fed to an MVR module to predict the localization of the\nunderwater targets through multi-view clustering and multiple regression. Since\nno off-the-shell multimodal dataset is available for UATR and UATL, we combined\nmultiple public datasets, consisting of acoustic, and/or visual, and/or\ntextural data, to obtain audio-visual-textual triplets for model training and\nvalidation. Experiments show that our model outperforms comparative methods in\n91.7% (11 out of 12 metrics) and 100% (4 metrics) of the quantitative metrics\nfor the recognition and localization tasks, respectively. In a case study, we\ndemonstrate the advantages of multi-view models in establishing sample\ndiscriminability through visualization methods. For UATL, the proposed MVR\nmethod produces the relation graphs, which allow predictions based on records\nof underwater targets with similar conditions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:16:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12702","submitter":"Eduardo Vitral","authors":"Eduardo Vitral, Mattia Libralato, Kyle Kremer, Gary A. Mamon, Andrea\n  Bellini, Luigi R. Bedin, Jay Anderson","title":"An elusive dark central mass in the globular cluster M4","comments":"19 page, 15 figures, 3 tables. Accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1068","report-no":null,"categories":"astro-ph.GA astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent studies of nearby globular clusters have discovered excess dark mass\nin their cores, apparently in an extended distribution, and simulations\nindicate that this mass is composed mostly of white dwarfs (respectively\nstellar-mass black holes) in clusters that are core-collapsed (respectively\nwith a flatter core). We perform mass-anisotropy modelling of the closest\nglobular cluster, M4, with intermediate slope for the inner stellar density. We\nuse proper-motion data from Gaia EDR3 and from observations by the Hubble Space\nTelescope. We extract the mass profile employing Bayesian Jeans modelling, and\ncheck our fits with realistic mock data. Our analyses return isotropic motions\nin the cluster core and tangential motions ($\\beta\\approx -0.4$$\\pm$$0.1$) in\nthe outskirts. We also robustly measure a dark central mass of roughly\n$800\\pm300 \\,$M$_{\\odot}$, but it is not possible to distinguish between a\npoint-like source, such as an intermediate-mass black hole (IMBH), or a dark\npopulation of stellar remnants of extent $\\approx 0.016\\,\\rm pc \\simeq\n3300\\,AU$. However, when removing a high-velocity star from the cluster centre,\nthe same mass excess is found, but more extended ($\\sim 0.034\\, \\rm{pc} \\approx\n7000\\,\\rm AU$). We use Monte Carlo $N$-body models of M4 to interpret the\nsecond outcome, and find that our excess mass is not sufficiently extended to\nbe confidently associated with a dark population of remnants. Finally, we\ndiscuss the feasibility of these two scenarios (i.e., IMBH vs. remnants), and\npropose new observations that could help to better grasp the complex dynamics\nin M4's core.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:25:17 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.12703","submitter":"Zhuo Li","authors":"Zhuo Li, Jingze Lu, Zhenduo Zhao, Wenchao Wang, Pengyuan Zhang","title":"Progressive Sub-Graph Clustering Algorithm for Semi-Supervised Domain\n  Adaptation Speaker Verification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Utilizing the large-scale unlabeled data from the target domain via\npseudo-label clustering algorithms is an important approach for addressing\ndomain adaptation problems in speaker verification tasks. In this paper, we\npropose a novel progressive subgraph clustering algorithm based on multi-model\nvoting and double-Gaussian based assessment (PGMVG clustering). To fully\nexploit the relationships among utterances and the complementarity among\nmultiple models, our method constructs multiple k-nearest neighbors graphs\nbased on diverse models and generates high-confidence edges using a voting\nmechanism. Further, to maximize the intra-class diversity, the connected\nsubgraph is utilized to obtain the initial pseudo-labels. Finally, to prevent\ndisastrous clustering results, we adopt an iterative approach that\nprogressively increases k and employs a double-Gaussian based assessment\nalgorithm to decide whether merging sub-classes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:26:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12704","submitter":"Jiawei Qin","authors":"Yoichiro Hisadome, Tianyi Wu, Jiawei Qin, Yusuke Sugano","title":"Rotation-Constrained Cross-View Feature Fusion for Multi-View\n  Appearance-based Gaze Estimation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Appearance-based gaze estimation has been actively studied in recent years.\nHowever, its generalization performance for unseen head poses is still a\nsignificant limitation for existing methods. This work proposes a generalizable\nmulti-view gaze estimation task and a cross-view feature fusion method to\naddress this issue. In addition to paired images, our method takes the relative\nrotation matrix between two cameras as additional input. The proposed network\nlearns to extract rotatable feature representation by using relative rotation\nas a constraint and adaptively fuses the rotatable features via stacked fusion\nmodules. This simple yet efficient approach significantly improves\ngeneralization performance under unseen head poses without significantly\nincreasing computational cost. The model can be trained with random\ncombinations of cameras without fixing the positioning and can generalize to\nunseen camera pairs during inference. Through experiments using multiple\ndatasets, we demonstrate the advantage of the proposed method over baseline\nmethods, including state-of-the-art domain generalization approaches.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:29:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12705","submitter":"Fabio Ruetz","authors":"Fabio Ruetz, Nicholas Lawrance, Emili Hern\\'andez, Paulo Borges,\n  Thierry Peynot","title":"ForestTrav: Accurate, Efficient and Deployable Forest Traversability\n  Estimation for Autonomous Ground Vehicles","comments":"Videolink: https://youtu.be/Kw8easF89Zg","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Autonomous navigation in unstructured vegetated environments remains an open\nchallenge. To successfully operate in these settings, ground vehicles must\nassess the traversability of the environment and determine which vegetation is\npliable enough to push through. In this work, we propose a novel method that\ncombines a high-fidelity and feature-rich 3D voxel representation while\nleveraging the structural context and sparseness of \\acfp{SCNN} to assess\n\\ac{TE} in densely vegetated environments. The proposed method is thoroughly\nevaluated on an accurately-labeled real-world data set that we provide to the\ncommunity. It is shown to outperform state-of-the-art methods by a significant\nmargin (0.59 vs. 0.39 MCC score at 0.1m voxel resolution) in challenging scenes\nand to generalize to unseen environments. In addition, the method is economical\nin the amount of training data and training time required: a model is trained\nin minutes on a desktop computer. We show that by exploiting the context of the\nenvironment, our method can use different feature combinations with only\nlimited performance variations. For example, our approach can be used with\nlidar-only features, whilst still assessing complex vegetated environments\naccurately, which was not demonstrated previously in the literature in such\nenvironments. In addition, we propose an approach to assess a traversability\nestimator's sensitivity to information quality and show our method's\nsensitivity is low.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:29:57 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12706","submitter":"Raghunathan Ramakrishnan Dr.","authors":"Saurabh Chandra Kandpal, Kgalaletso P. Otukile, Shweta Jindal, Salini\n  Senthil, Cameron Matthews, Sabyasachi Chakraborty, Lyudmila V. Moskaleva,\n  Raghunathan Ramakrishnan","title":"Leveraging Stereo-Electronic Factors for ab initio Design of Long-lived\n  Hydroperoxyalkyl Radicals","comments":"Version 1","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this study, we investigate the stability of hydroperoxyalkyl radicals,\n.QOOH, in terms of various stereo-electronic effects stemming from molecular\nstructural features. These radicals are known to play a significant role in\ncombustion and tropospheric processes, yet their direct spectroscopic detection\nremains challenging. While the thermodynamic stability of .QOOH depends on its\nrelative energy with respect to its precursor, (alkylperoxyl radical, ROO.),\nand the dissociation products (cyclic ethers + .OH), its kinetic stability is\ndecided by favorable energy barriers along the formation/depletion paths. We\nutilize quantitatively precise ab initio methods to determine net energies and\nbarriers for the reaction channels: ROO. <=> .QOOH, ROO. <=> alkene {+} OOH,\n.QOOH <=> alkene {+} OOH, and .QOOH <=> cyclic ether {+} .OH. We focus on free\nradical reactive intermediates derived from the oxidation of acyclic\nhydrocarbon radicals: ethyl, isopropyl, isobutyl, tertiarybutyl, neopentyl, and\ntheir alicyclic counterparts: cyclohexyl, cyclohexenyl, and cyclohexadienyl. We\nascertain the individual contributions from inductive, resonance, and steric\neffects towards the overall stability of $\\cdot$QOOH and rationally design more\nstable species with potentially long lifetimes suitable for their spectroscopic\ndetection.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:30:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12707","submitter":"Jie Huang","authors":"Hanyin Shao, Jie Huang, Shen Zheng, Kevin Chen-Chuan Chang","title":"Quantifying Association Capabilities of Large Language Models and Its\n  Implications on Privacy Leakage","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The advancement of large language models (LLMs) brings notable improvements\nacross various applications, while simultaneously raising concerns about\npotential private data exposure. One notable capability of LLMs is their\nability to form associations between different pieces of information, but this\nraises concerns when it comes to personally identifiable information (PII).\nThis paper delves into the association capabilities of language models, aiming\nto uncover the factors that influence their proficiency in associating\ninformation. Our study reveals that as models scale up, their capacity to\nassociate entities/information intensifies, particularly when target pairs\ndemonstrate shorter co-occurrence distances or higher co-occurrence\nfrequencies. However, there is a distinct performance gap when associating\ncommonsense knowledge versus PII, with the latter showing lower accuracy.\nDespite the proportion of accurately predicted PII being relatively small, LLMs\nstill demonstrate the capability to predict specific instances of email\naddresses and phone numbers when provided with appropriate prompts. These\nfindings underscore the potential risk to PII confidentiality posed by the\nevolving capabilities of LLMs, especially as they continue to expand in scale\nand power.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:30:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12708","submitter":"Huadai Liu","authors":"Huadai Liu, Rongjie Huang, Xuan Lin, Wenqiang Xu, Maozong Zheng, Hong\n  Chen, Jinzheng He, Zhou Zhao","title":"ViT-TTS: Visual Text-to-Speech with Scalable Diffusion Transformer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Text-to-speech(TTS) has undergone remarkable improvements in performance,\nparticularly with the advent of Denoising Diffusion Probabilistic Models\n(DDPMs). However, the perceived quality of audio depends not solely on its\ncontent, pitch, rhythm, and energy, but also on the physical environment. In\nthis work, we propose ViT-TTS, the first visual TTS model with scalable\ndiffusion transformers. ViT-TTS complement the phoneme sequence with the visual\ninformation to generate high-perceived audio, opening up new avenues for\npractical applications of AR and VR to allow a more immersive and realistic\naudio experience. To mitigate the data scarcity in learning visual acoustic\ninformation, we 1) introduce a self-supervised learning framework to enhance\nboth the visual-text encoder and denoiser decoder; 2) leverage the diffusion\ntransformer scalable in terms of parameters and capacity to learn visual scene\ninformation. Experimental results demonstrate that ViT-TTS achieves new\nstate-of-the-art results, outperforming cascaded systems and other baselines\nregardless of the visibility of the scene. With low-resource data (1h, 2h, 5h),\nViT-TTS achieves comparative results with rich-resource\nbaselines.~\\footnote{Audio samples are available at\n\\url{https://ViT-TTS.github.io/.}}\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:37:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12709","submitter":"Seraphina Goldfarb-Tarrant","authors":"Seraphina Goldfarb-Tarrant, Bj\\\"orn Ross, Adam Lopez","title":"Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis","comments":"8 pages, preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Sentiment analysis (SA) systems are widely deployed in many of the world's\nlanguages, and there is well-documented evidence of demographic bias in these\nsystems. In languages beyond English, scarcer training data is often\nsupplemented with transfer learning using pre-trained models, including\nmultilingual models trained on other languages. In some cases, even supervision\ndata comes from other languages. Does cross-lingual transfer also import new\nbiases? To answer this question, we use counterfactual evaluation to test\nwhether gender or racial biases are imported when using cross-lingual transfer,\ncompared to a monolingual transfer setting. Across five languages, we find that\nsystems using cross-lingual transfer usually become more biased than their\nmonolingual counterparts. We also find racial biases to be much more prevalent\nthan gender biases. To spur further research on this topic, we release the\nsentiment models we used for this study, and the intermediate checkpoints\nthroughout training, yielding 1,525 distinct models; we also release our\nevaluation code.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:37:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12710","submitter":"Bingsheng Yao","authors":"Bingsheng Yao, Ishan Jindal, Lucian Popa, Yannis Katsis, Sayan Ghosh,\n  Lihong He, Yuxuan Lu, Shashank Srivastava, James Hendler, and Dakuo Wang","title":"Beyond Labels: Empowering Human with Natural Language Explanations\n  through a Novel Active-Learning Architecture","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Data annotation is a costly task; thus, researchers have proposed\nlow-scenario learning techniques like Active-Learning (AL) to support human\nannotators; Yet, existing AL works focus only on the label, but overlook the\nnatural language explanation of a data point, despite that real-world humans\n(e.g., doctors) often need both the labels and the corresponding explanations\nat the same time. This work proposes a novel AL architecture to support and\nreduce human annotations of both labels and explanations in low-resource\nscenarios. Our AL architecture incorporates an explanation-generation model\nthat can explicitly generate natural language explanations for the prediction\nmodel and for assisting humans' decision-making in real-world. For our AL\nframework, we design a data diversity-based AL data selection strategy that\nleverages the explanation annotations. The automated AL simulation evaluations\ndemonstrate that our data selection strategy consistently outperforms\ntraditional data diversity-based strategy; furthermore, human evaluation\ndemonstrates that humans prefer our generated explanations to the SOTA\nexplanation-generation system.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:38:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12711","submitter":"Lingfeng He","authors":"De Cheng, Xiaojian Huang, Nannan Wang, Lingfeng He, Zhihui Li and\n  Xinbo Gao","title":"Unsupervised Visible-Infrared Person ReID by Collaborative Learning with\n  Neighbor-Guided Label Refinement","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Unsupervised learning visible-infrared person re-identification (USL-VI-ReID)\naims at learning modality-invariant features from unlabeled cross-modality\ndataset, which is crucial for practical applications in video surveillance\nsystems. The key to essentially address the USL-VI-ReID task is to solve the\ncross-modality data association problem for further heterogeneous joint\nlearning. To address this issue, we propose a Dual Optimal Transport Label\nAssignment (DOTLA) framework to simultaneously assign the generated labels from\none modality to its counterpart modality. The proposed DOTLA mechanism\nformulates a mutual reinforcement and efficient solution to cross-modality data\nassociation, which could effectively reduce the side-effects of some\ninsufficient and noisy label associations. Besides, we further propose a\ncross-modality neighbor consistency guided label refinement and regularization\nmodule, to eliminate the negative effects brought by the inaccurate supervised\nsignals, under the assumption that the prediction or label distribution of each\nexample should be similar to its nearest neighbors. Extensive experimental\nresults on the public SYSU-MM01 and RegDB datasets demonstrate the\neffectiveness of the proposed method, surpassing existing state-of-the-art\napproach by a large margin of 7.76% mAP on average, which even surpasses some\nsupervised VI-ReID methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:40:30 GMT"},{"version":"v2","created":"Sat, 3 Jun 2023 03:30:46 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12712","submitter":"Shwetank Choudhary","authors":"Shwetank Choudhary, CR Karthik, Punuru Sri Lakshmi and Sumit Kumar","title":"LEAN: Light and Efficient Audio Classification Network","comments":"Accepted at INDICON 2022","journal-ref":null,"doi":"10.1109/INDICON56171.2022.10039921","report-no":null,"categories":"cs.SD cs.AI eess.AS","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Over the past few years, audio classification task on large-scale dataset\nsuch as AudioSet has been an important research area. Several deeper\nConvolution-based Neural networks have shown compelling performance notably\nVggish, YAMNet, and Pretrained Audio Neural Network (PANN). These models are\navailable as pretrained architecture for transfer learning as well as specific\naudio task adoption. In this paper, we propose a lightweight on-device deep\nlearning-based model for audio classification, LEAN. LEAN consists of a raw\nwaveform-based temporal feature extractor called as Wave Encoder and\nlogmel-based Pretrained YAMNet. We show that using a combination of trainable\nwave encoder, Pretrained YAMNet along with cross attention-based temporal\nrealignment, results in competitive performance on downstream audio\nclassification tasks with lesser memory footprints and hence making it suitable\nfor resource constraints devices such as mobile, edge devices, etc . Our\nproposed system achieves on-device mean average precision(mAP) of .445 with a\nmemory footprint of a mere 4.5MB on the FSD50K dataset which is an improvement\nof 22% over baseline on-device mAP on same dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:45:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12713","submitter":"Mridweeka Singh","authors":"Mridweeka Singh, Devendra. K. Sahu, Raya Dastidar, Barnabas Barna,\n  Kuntal Misra, Anjasha Gangopadhyay, D. Andrew Howell, Saurabh W. Jha, Hyobin\n  Im, Kirsty Taggart, Jennifer Andrews, Daichi Hiramatsu, Rishabh Singh Teja,\n  Craig Pellegrino, Ryan J. Foley, Arti Joshi, G. C. Anupama, K. Azalee\n  Bostroem, Jamison Burke, Yssavo Camacho-Neves, Anirban Dutta, Lindsey A.\n  Kwok, Curtis McCully, Yen-Chen Pan, Matt Siebert, Shubham Srivastav, Tamas\n  Szalai, Jonathan J. Swift, Grace Yang, Henry Zhou, Nico DiLullo, and Jackson\n  Scheer","title":"Observational properties of a bright type Iax SN 2018cni and a faint\n  type Iax SN 2020kyg","comments":"18 pages, 18 figures, Accepted for Publication in The Astrophysical\n  Journal","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present the optical photometric and spectroscopic analysis of two type Iax\nSNe 2018cni and 2020kyg. SN 2018cni is a bright type Iax SN (M$_{V,peak}$ =\n$-$17.81$\\pm$0.21 mag) whereas SN 2020kyg (M$_{V,peak}$ = $-$14.52$\\pm$0.21\nmag) is a faint one. We derive $^{56}$Ni mass of 0.07 and 0.002 M${_\\odot}$,\nejecta mass of 0.48 and 0.14 M${_\\odot}$ for SNe 2018cni and 2020kyg,\nrespectively. A combined study of the bright and faint type Iax SNe in $R/r$-\nband reveals that the brighter objects tend to have a longer rise time.\nHowever, the correlation between the peak luminosity and decline rate shows\nthat bright and faint type Iax SNe exhibit distinct behaviour. Comparison with\nstandard deflagration models suggests that SN 2018cni is consistent with the\ndeflagration of a CO white dwarf whereas the properties of SN 2020kyg can be\nbetter explained by the deflagration of a hybrid CONe white dwarf. The spectral\nfeatures of both the SNe point to the presence of similar chemical species but\nwith different mass fractions. Our spectral modelling indicates stratification\nat the outer layers and mixed inner ejecta for both the SNe.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:45:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12714","submitter":"June-Young Kim","authors":"June-Young Kim","title":"Quark distribution functions and spin-flavor structures in $N \\to\n  \\Delta$ transitions","comments":"15 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-lat","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Transition generalized parton distributions have emerged as a novel tool for\nstudying the quantum chromodynamics (QCD) structure of resonances. They provide\nan integrated picture of the transition form factors and the transition parton\ndistribution functions. In this study, we delve into the angular momentum (AM)\nproperties for the $N\\to \\Delta$ transition and its decomposition into the\norbital angular momentum and the intrinsic spin in the context of the quark\ndistribution functions. First, we explore the spin-flavor structures within the\nframework of both the overlap representations of the three-quark light-cone\nwave functions and the large $N_c$ limit of QCD. We then estimate the AM quark\ndistribution functions for the $N\\to \\Delta$ transition. Our analysis reveals a\nsubstantial flavor asymmetry present in both the orbital angular momentum and\nintrinsic spin components.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:48:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12715","submitter":"Hao Chen","authors":"Hao Chen, Ankit Shah, Jindong Wang, Ran Tao, Yidong Wang, Xing Xie,\n  Masashi Sugiyama, Rita Singh, Bhiksha Raj","title":"Imprecise Label Learning: A Unified Framework for Learning with Various\n  Imprecise Label Configurations","comments":"Preprint","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we introduce the imprecise label learning (ILL) framework, a\nunified approach to handle various imprecise label configurations, which are\ncommonplace challenges in machine learning tasks. ILL leverages an\nexpectation-maximization (EM) algorithm for the maximum likelihood estimation\n(MLE) of the imprecise label information, treating the precise labels as latent\nvariables. Compared to previous versatile methods attempting to infer correct\nlabels from the imprecise label information, our ILL framework considers all\npossible labeling imposed by the imprecise label information, allowing a\nunified solution to deal with any imprecise labels. With comprehensive\nexperimental results, we demonstrate that ILL can seamlessly adapt to various\nsituations, including partial label learning, semi-supervised learning, noisy\nlabel learning, and a mixture of these settings. Notably, our simple method\nsurpasses the existing techniques for handling imprecise labels, marking the\nfirst unified framework with robust and effective performance across various\nimprecise labels. We believe that our approach has the potential to\nsignificantly enhance the performance of machine learning models on tasks where\nobtaining precise labels is expensive and complicated. We hope our work will\ninspire further research on this topic with an open-source codebase release.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:50:28 GMT"},{"version":"v2","created":"Tue, 23 May 2023 03:44:58 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12716","submitter":"Yuxuan Ding","authors":"Yuxuan Ding, Chunna Tian, Haoxuan Ding, Lingqiao Liu","title":"The CLIP Model is Secretly an Image-to-Prompt Converter","comments":"19 pages, 24 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Stable Diffusion model is a prominent text-to-image generation model that\nrelies on a text prompt as its input, which is encoded using the Contrastive\nLanguage-Image Pre-Training (CLIP). However, text prompts have limitations when\nit comes to incorporating implicit information from reference images. Existing\nmethods have attempted to address this limitation by employing expensive\ntraining procedures involving millions of training samples for image-to-image\ngeneration. In contrast, this paper demonstrates that the CLIP model, as\nutilized in Stable Diffusion, inherently possesses the ability to\ninstantaneously convert images into text prompts. Such an image-to-prompt\nconversion can be achieved by utilizing a linear projection matrix that is\ncalculated in a closed form. Moreover, the paper showcases that this capability\ncan be further enhanced by either utilizing a small amount of similar-domain\ntraining data (approximately 100 images) or incorporating several online\ntraining steps (around 30 iterations) on the reference images. By leveraging\nthese approaches, the proposed method offers a simple and flexible solution to\nbridge the gap between images and text prompts. This methodology can be applied\nto various tasks such as image variation and image editing, facilitating more\neffective and seamless interaction between images and textual prompts.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:52:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12717","submitter":"Chia-Chien Hung","authors":"Chia-Chien Hung, Lukas Lange, Jannik Str\\\"otgen","title":"TADA: Efficient Task-Agnostic Domain Adaptation for Transformers","comments":"ACL-Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Intermediate training of pre-trained transformer-based language models on\ndomain-specific data leads to substantial gains for downstream tasks. To\nincrease efficiency and prevent catastrophic forgetting alleviated from full\ndomain-adaptive pre-training, approaches such as adapters have been developed.\nHowever, these require additional parameters for each layer, and are criticized\nfor their limited expressiveness. In this work, we introduce TADA, a novel\ntask-agnostic domain adaptation method which is modular, parameter-efficient,\nand thus, data-efficient. Within TADA, we retrain the embeddings to learn\ndomain-aware input representations and tokenizers for the transformer encoder,\nwhile freezing all other parameters of the model. Then, task-specific\nfine-tuning is performed. We further conduct experiments with meta-embeddings\nand newly introduced meta-tokenizers, resulting in one model per task in\nmulti-domain use cases. Our broad evaluation in 4 downstream tasks for 14\ndomains across single- and multi-domain setups and high- and low-resource\nscenarios reveals that TADA is an effective and efficient alternative to full\ndomain-adaptive pre-training and adapters for domain adaptation, while not\nintroducing additional parameters or complex training steps.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:53:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12718","submitter":"Yannan Wu","authors":"Yannan Nellie Wu, Po-An Tsai, Saurav Muralidharan, Angshuman Parashar,\n  Vivienne Sze, Joel S. Emer","title":"HighLight: Efficient and Flexible DNN Acceleration with Hierarchical\n  Structured Sparsity","comments":"12 pages, 17 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Due to complex interactions among various deep neural network (DNN)\noptimization techniques, modern DNNs can have weights and activations that are\ndense or sparse with diverse sparsity degrees. To offer a good trade-off\nbetween accuracy and hardware performance, an ideal DNN accelerator should have\nhigh flexibility to efficiently translate DNN sparsity into reductions in\nenergy and/or latency without incurring significant complexity overhead.\n  This paper introduces hierarchical structured sparsity (HSS), with the key\ninsight that we can systematically represent diverse sparsity degrees by having\nthem hierarchically composed from multiple simple sparsity patterns. As a\nresult, HSS simplifies the underlying hardware since it only needs to support\nsimple sparsity patterns; this significantly reduces the sparsity acceleration\noverhead, which improves efficiency. Motivated by such opportunities, we\npropose a simultaneously efficient and flexible accelerator, named HighLight,\nto accelerate DNNs that have diverse sparsity degrees (including dense). Due to\nthe flexibility of HSS, different HSS patterns can be introduced to DNNs to\nmeet different applications' accuracy requirements. Compared to existing works,\nHighLight achieves a geomean of up to 6.4x better energy-delay product (EDP)\nacross workloads with diverse sparsity degrees, and always sits on the\nEDP-accuracy Pareto frontier for representative DNNs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:54:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12719","submitter":"Zhiliang Yuan","authors":"Bang Wu, Xu-Jie Wang, Li Liu, Guoqi Huang, Wenyan Wang, Hanqing Liu,\n  Haiqiao Ni, Zhichuan Niu and Zhiliang Yuan","title":"The Mollow triplets under few-photon excitation","comments":"8 Figures and 9 Pages. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Resonant excitation is an essential tool in the development of semiconductor\nquantum dots (QDs) for quantum information processing. One central challenge is\nto enable a transparent access to the QD signal without post-selection\ninformation loss. A viable path is through cavity enhancement, which has\nsuccessfully lifted the resonantly scattered field strength over the laser\nbackground under \\emph{weak} excitation. Here, we extend this success to the\n\\emph{saturation} regime using a QD-micropillar device with a Purcell factor of\n10.9 and an ultra-low background cavity reflectivity of just 0.0089. We achieve\na signal to background ratio of 50 and an overall system responsivity of 3~\\%,\ni.e., we detect on average 0.03 resonantly scattered single photons for every\nincident laser photon. Raising the excitation to the few-photon level, the QD\nresponse is brought into saturation where we observe the Mollow triplets as\nwell as the associated cascade single photon emissions, without resort to any\nlaser background rejection technique. Our work offers a new perspective toward\nQD cavity interface that is not restricted by the laser background.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:56:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12720","submitter":"Masanori Hirano","authors":"Masanori Hirano, Masahiro Suzuki, Hiroki Sakaji","title":"llm-japanese-dataset v0: Construction of Japanese Chat Dataset for Large\n  Language Models and its Methodology","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study constructed a Japanese chat dataset for tuning large language\nmodels (LLMs), which consist of about 8.4 million records. Recently, LLMs have\nbeen developed and gaining popularity. However, high-performing LLMs are\nusually mainly for English. There are two ways to support languages other than\nEnglish by those LLMs: constructing LLMs from scratch or tuning existing\nmodels. However, in both ways, datasets are necessary parts. In this study, we\nfocused on supporting Japanese in those LLMs and making a dataset for training\nor tuning LLMs in Japanese. The dataset we constructed consisted of various\ntasks, such as translation and knowledge tasks. In our experiment, we tuned an\nexisting LLM using our dataset and evaluated the performance qualitatively. The\nresults suggest that our dataset is possibly beneficial for LLMs. However, we\nalso revealed some difficulties in constructing LLMs in languages other than\nEnglish.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 04:59:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12721","submitter":"Sitaram Ramakrishnan Site","authors":"Sitaram Ramakrishnan, Tatsuya Yamakawa, Ryohei Oishi, Yasuyuki\n  Shimura, Takahiro Onimaru, Arumugam Thamizhavel, Srinivasan Ramakrishnan and\n  Minoru Nohara","title":"Enhancement of density of states and suppression of superconductivity in\n  site-disordered topological metal LaPtSi","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Single crystals of non-centrosymmetric $s$-wave superconductor\nLaPt$_{0.88}$Si$_{1.12}$ have been grown by the Czochralski (Cz) technique,\nwhose crystal structure is described by the space group $I4{_1}md$ at ambient\nconditions. The inter-site mixing between platinum and silicon is confirmed by\nboth single-crystal x-ray diffraction (SXRD) and electron probe micro-analyzer\n(EPMA). The disordered material exhibits a lower superconducting (SC)\ntransition temperature $T_c$ at 2.02 K as opposed to the highest value of 3.9 K\nreported in polycrystalline LaPtSi without inter-site mixing. From specific\nheat, the Sommerfeld coefficient ($\\gamma$) is estimated to be 7.85 mJ/mol\nK$^2$, which is much larger than the values reported for the samples exhibiting\nhigher $T_c$. This is unprecedented as $T_c$ seems to decrease with increase in\nthe electron density of states (DOS) at the Fermi energy and thus $\\gamma$. The\npresent work reports on the anomalous behaviour of SC and normal state\nproperties of LaPt$_{x}$Si$_{2-x}$, presumably caused due to the existence of\nnon-trivial topological bands.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:09:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12722","submitter":"Gustav Nilsson","authors":"Gustav Nilsson and Alejandro D. Owen Aquino and Samuel Coogan and\n  Daniel K. Molzahn","title":"GreenEVT: Greensboro Electric Vehicle Testbed","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The ongoing electrification of the transportation fleet will increase the\nload on the electric power grid. Since both the transportation network and the\npower grid already experience periods of significant stress, joint analyses of\nboth infrastructures will most likely be necessary to ensure acceptable\noperation in the future. To enable such analyses, this paper presents an\nopen-source testbed that jointly simulates high-fidelity models of both the\nelectric distribution system and the transportation network. The testbed\nutilizes two open-source simulators, OpenDSS to simulate the electric\ndistribution system and the microscopic traffic simulator SUMO to simulate the\ntraffic dynamics. Electric vehicle charging links the electric distribution\nsystem and the transportation network models at vehicle locations determined\nusing publicly available parcel data. Leveraging high-fidelity synthetic\nelectric distribution system data from the SMART-DS project and transportation\nsystem data from OpenStreetMap, this testbed models the city of Greensboro, NC\ndown to the household level. Moreover, the methodology and the supporting\nscripts released with the testbed allow adaption to other areas where\nhigh-fidelity geolocated OpenDSS datasets are available. After describing the\ncomponents and usage of the testbed, we exemplify applications enabled by the\ntestbed via two scenarios modeling the extreme stresses encountered during\nevacuations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:12:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12723","submitter":"Xinlu Zhang","authors":"Xinlu Zhang, Shiyang Li, Xianjun Yang, Chenxin Tian, Yao Qin, Linda\n  Ruth Petzold","title":"Enhancing Small Medical Learners with Privacy-preserving Contextual\n  Prompting","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) demonstrate remarkable medical expertise, but\ndata privacy concerns impede their direct use in healthcare environments.\nAlthough offering improved data privacy protection, domain-specific small\nlanguage models (SLMs) often underperform LLMs, emphasizing the need for\nmethods that reduce this performance gap while alleviating privacy concerns. In\nthis paper, we present a simple yet effective method that harnesses LLMs'\nmedical proficiency to boost SLM performance in medical tasks under\nprivacy-restricted scenarios. Specifically, we mitigate patient privacy issues\nby extracting keywords from medical data and prompting the LLM to generate a\nmedical knowledge-intensive context by simulating clinicians' thought\nprocesses. This context serves as additional input for SLMs, augmenting their\ndecision-making capabilities. Our method significantly enhances performance in\nboth few-shot and full training settings across three medical\nknowledge-intensive tasks, achieving up to a 22.57% increase in absolute\naccuracy compared to SLM fine-tuning without context, and sets new\nstate-of-the-art results in two medical tasks within privacy-restricted\nscenarios. Further out-of-domain testing and experiments in two general domain\ndatasets showcase its generalizability and broad applicability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:14:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12724","submitter":"Weixin Luo","authors":"Feng Yan, Weixin Luo, Yujie Zhong, Yiyang Gan, Lin Ma","title":"Bridging the Gap Between End-to-end and Non-End-to-end Multi-Object\n  Tracking","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Existing end-to-end Multi-Object Tracking (e2e-MOT) methods have not\nsurpassed non-end-to-end tracking-by-detection methods. One potential reason is\nits label assignment strategy during training that consistently binds the\ntracked objects with tracking queries and then assigns the few newborns to\ndetection queries. With one-to-one bipartite matching, such an assignment will\nyield unbalanced training, i.e., scarce positive samples for detection queries,\nespecially for an enclosed scene, as the majority of the newborns come on stage\nat the beginning of videos. Thus, e2e-MOT will be easier to yield a tracking\nterminal without renewal or re-initialization, compared to other\ntracking-by-detection methods. To alleviate this problem, we present Co-MOT, a\nsimple and effective method to facilitate e2e-MOT by a novel coopetition label\nassignment with a shadow concept. Specifically, we add tracked objects to the\nmatching targets for detection queries when performing the label assignment for\ntraining the intermediate decoders. For query initialization, we expand each\nquery by a set of shadow counterparts with limited disturbance to itself. With\nextensive ablations, Co-MOT achieves superior performance without extra costs,\ne.g., 69.4% HOTA on DanceTrack and 52.8% TETA on BDD100K. Impressively, Co-MOT\nonly requires 38\\% FLOPs of MOTRv2 to attain a similar performance, resulting\nin the 1.4$\\times$ faster inference speed.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:18:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12725","submitter":"Engin Arslan","authors":"Tasdiqul Islam and Engin Arslan","title":"Quantum Key Distribution with Minimal Qubit Transmission Based on\n  MultiQubit Greenberger Horne Zeilinger State","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Conventional Quantum Key Distribution (QKD) requires the transmission of\nmultiple qubits equivalent to the length of the key. As quantum networks are\nstill in their infancy thus, they are expected to have a limited capacity,\nnecessitating too many qubit transmissions for QKD might limit the effective\nuse of limited network bandwidth of quantum networks. To address this challenge\nand enhance the practicality of QKD, we propose a Multi-Qubit Greenberger Horne\nZeilinger (GHZ) State-based QKD scheme that requires a small number of qubit\ntransmissions. The proposed method transmits one qubit between endpoints and\nreuses it for the transmission of multiple classical bits with the help of\nQuantum nondemolition (QND) measurements. We show that one can transfer L-1\nclassical bits by generating an L-qubit GHZ state and transferring one to the\nremote party. We further show that the proposed QKD algorithm can be extended\nto enable multi-party QKD. It can also support QKD between parties with minimal\nquantum resources. As a result, the proposed scheme offers a quantum\nnetwork-efficient alternative QKD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:19:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12726","submitter":"Haoning Wu Mr","authors":"Haoning Wu, Erli Zhang, Liang Liao, Chaofeng Chen, Jingwen Hou, Annan\n  Wang, Wenxiu Sun, Qiong Yan, Weisi Lin","title":"Towards Explainable In-the-Wild Video Quality Assessment: a Database and\n  a Language-Prompted Approach","comments":"12 pages (with appendix). Under review, non-finalised version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL cs.MM","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The proliferation of in-the-wild videos has greatly expanded the Video\nQuality Assessment (VQA) problem. Unlike early definitions that usually focus\non limited distortion types, VQA on in-the-wild videos is especially\nchallenging as it could be affected by complicated factors, including various\ndistortions and diverse contents. Though subjective studies have collected\noverall quality scores for these videos, how the abstract quality scores relate\nwith specific factors is still obscure, hindering VQA methods from more\nconcrete quality evaluations (e.g. sharpness of a video). To solve this\nproblem, we collect over two million opinions on 4,543 in-the-wild videos on 13\ndimensions of quality-related factors, including in-capture authentic\ndistortions (e.g. motion blur, noise, flicker), errors introduced by\ncompression and transmission, and higher-level experiences on semantic contents\nand aesthetic issues (e.g. composition, camera trajectory), to establish the\nmulti-dimensional Maxwell database. Specifically, we ask the subjects to label\namong a positive, a negative, and a neural choice for each dimension. These\nexplanation-level opinions allow us to measure the relationships between\nspecific quality factors and abstract subjective quality ratings, and to\nbenchmark different categories of VQA algorithms on each dimension, so as to\nmore comprehensively analyze their strengths and weaknesses. Furthermore, we\npropose the MaxVQA, a language-prompted VQA approach that modifies\nvision-language foundation model CLIP to better capture important quality\nissues as observed in our analyses. The MaxVQA can jointly evaluate various\nspecific quality factors and final quality scores with state-of-the-art\naccuracy on all dimensions, and superb generalization ability on existing\ndatasets. Code and data available at\n\\url{https://github.com/VQAssessment/MaxVQA}.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:20:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12727","submitter":"Kyria Wawryk","authors":"Janosch Rieger, Kyria Wawryk","title":"Towards optimal space-time discretizations for reachable sets of\n  nonlinear systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reachable sets of nonlinear control systems can in general only be\napproximated numerically, and these approximations are typically very expensive\nto compute. In this paper, we explore strategies for choosing the temporal and\nspatial discretizations of Euler's method for reachable set computation in a\nnon-uniform way to improve the performance of the method.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:30:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12728","submitter":"Didar Zowghi","authors":"Didar Zowghi and Francesca da Rimini","title":"Diversity and Inclusion in Artificial Intelligence","comments":"27 pages, 1 figure","journal-ref":null,"doi":null,"report-no":"Book Title - Responsible AI: Best Practices for Creating Trustworthy\n  AI Systems To be published by Pearson Addison Wesley in 2023","categories":"cs.AI cs.SE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To date, there has been little concrete practical advice about how to ensure\nthat diversity and inclusion considerations should be embedded within both\nspecific Artificial Intelligence (AI) systems and the larger global AI\necosystem. In this chapter, we present a clear definition of diversity and\ninclusion in AI, one which positions this concept within an evolving and\nholistic ecosystem. We use this definition and conceptual framing to present a\nset of practical guidelines primarily aimed at AI technologists, data\nscientists and project leaders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:33:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12729","submitter":"Ekrem O\\u{g}uzhan Ang\\\"uner","authors":"E.O. Ang\\\"uner","title":"Exploring the high energy frontiers of the Milky Way with ground-based\n  gamma-ray astronomy: PeVatrons and the quest for the origin of Galactic\n  cosmic-rays","comments":"This review article is accepted for publication in Turkish Journal of\n  Physics (57 pages, 24 figures)","journal-ref":"Turkish Journal of Physics: Vol. 47: No. 2, Article 2 (2023)","doi":"10.55730/1300-0101.2738","report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cosmic rays (CRs) are charged particles that arrive at Earth isotropically\nfrom all directions and interact with the atmosphere. The presence of a\nspectral knee feature seen in the CR spectrum at $\\sim$3 PeV energies is an\nevidence that astrophysical objects within our Galaxy, which are known as\n'Galactic PeVatrons', are capable of accelerating particles to PeV energies.\nScientists have been trying to identify the origin of Galactic CRs and have\nbeen looking for signatures of Galactic PeVatrons through neutral messengers.\nRecent advancements in ground-based $\\gamma$-ray astronomy have led to the\ndiscovery of 12 Galactic sources emitting above 100 TeV energies, and even the\nfirst time detection of PeV photons from the direction of the Crab Nebula and\nthe Cygnus region. These groundbreaking discoveries have opened up the field of\nultra-high energy (UHE, E$>$100 TeV) $\\gamma$-ray astronomy, which can help us\nexplore the high energy frontiers of our Galaxy, hunt for PeVatron sources, and\nshed light on the century-old problem of the origin of CRs. This review article\nprovides an overview of the current state of the art and potential future\ndirections for the search for Galactic PeVatrons using ground-based\n$\\gamma$-ray observations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:34:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12730","submitter":"Siyu Chen","authors":"Siyu Chen, Jing Na and Yingbo Huang","title":"Parameter Estimation Based on Newton Method under Different Excitations","comments":"12 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Persistent excitation is often recognized as a sufficient condition to\nexponentially converge in the field of parameter estimation. But in fact, this\ncondition is strict even impractical where each stage is required to hold.\nTherefore, recent attention has shifted towards achieving exponential\nconvergence under finite excitation. This paper presents a novel estimator that\ncombines filtering and a second-order Newton algorithm to achieve Q-superlinear\nconvergence, which is able to maintain exponential convergence even in the\npresence of finite excitation. Moreover, a time-varying forgetting factor is\nintroduced to ensure the estimator remains bounded. The proposed estimator is\nanalyzed for convergence properties under different excitation conditions and\ndemonstrated through numerical simulations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:37:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12731","submitter":"Zhujun Zhang","authors":"Zhujun Zhang","title":"Perfect Information Hearthstone is PSPACE-hard","comments":"18 pages, 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider the computational complexity of Hearthstone which is a popular\nonline CCG (collectible card game). We reduce a PSPACE-complete problem, the\npartition game, to perfect information Hearthstone in which there is no hidden\ninformation or random elements. In the reduction, each turn in Hearthstone is\nused to simulate one choice in the partition game. It is proved that\ndetermining whether the player has a forced win in perfect information\nHearthstone is PSPACE-hard.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:39:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12732","submitter":"Kento Sugiura","authors":"Kento Sugiura (1) and Yoshiharu Ishikawa (1) ((1) Graduate School of\n  Informatics, Nagoya University)","title":"Z-ordered Range Refinement for Multi-dimensional Range Queries","comments":"16 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DB","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The z-order curve is a space-filling curve and is now attracting the interest\nof developers because of its simple and useful features. In the case of\nkey-value stores, because the z-order curve achieves multi-dimensional range\nqueries in one-dimensional z-ordered space, its use has been proposed for both\nacademic and industrial purposes. However, z-ordered range queries suffer from\nwasteful query regions due to the properties of the z-order curve. Although\nprevious studies have proposed refining z-ordered ranges, doing so is\ncomputationally expensive. In this paper, we propose z-ordered range refinement\nbased on jump-in/out algorithms, and then we approximate z-ordered query\nregions to achieve efficient range refinement. Because the proposed method is\nlightweight and pluggable, it can be applied to various databases. We\nimplemented our approach using PL/pgSQL in PostgreSQL and evaluated the\nperformance of range refinement and multi-dimensional range queries. The\nexperimental results demonstrate the effectiveness and efficiency of the\nproposed method.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:48:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12733","submitter":"Jia-Chen Gu","authors":"Jia-Chen Gu, Chao-Hong Tan, Caiyuan Chu, Zhen-Hua Ling, Chongyang Tao,\n  Quan Liu, Cong Liu, Guoping Hu","title":"MADNet: Maximizing Addressee Deduction Expectation for Multi-Party\n  Conversation Generation","comments":"Work in Progress. arXiv admin note: text overlap with\n  arXiv:2203.08500","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modeling multi-party conversations (MPCs) with graph neural networks has been\nproven effective at capturing complicated and graphical information flows.\nHowever, existing methods rely heavily on the necessary addressee labels and\ncan only be applied to an ideal setting where each utterance must be tagged\nwith an addressee label. To study the scarcity of addressee labels which is a\ncommon issue in MPCs, we propose MADNet that maximizes addressee deduction\nexpectation in heterogeneous graph neural networks for MPC generation. Given an\nMPC with a few addressee labels missing, existing methods fail to build a\nconsecutively connected conversation graph, but only a few separate\nconversation fragments instead. To ensure message passing between these\nconversation fragments, four additional types of latent edges are designed to\ncomplete a fully-connected graph. Besides, to optimize the edge-type-dependent\nmessage passing for those utterances without addressee labels, an\nExpectation-Maximization-based method that iteratively generates silver\naddressee labels (E step), and optimizes the quality of generated responses (M\nstep), is designed. Experimental results on two Ubuntu IRC channel benchmarks\nshow that MADNet outperforms various baseline models on the task of MPC\ngeneration, especially under the more common and challenging setting where part\nof addressee labels are missing.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:50:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12734","submitter":"Renshuai Liu","authors":"Renshuai Liu, Chengyang Li, Haitao Cao, Yinglin Zheng, Ming Zeng, Xuan\n  Cheng","title":"EMEF: Ensemble Multi-Exposure Image Fusion","comments":"Preprint, Accepted by AAAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Although remarkable progress has been made in recent years, current\nmulti-exposure image fusion (MEF) research is still bounded by the lack of real\nground truth, objective evaluation function, and robust fusion strategy. In\nthis paper, we study the MEF problem from a new perspective. We don't utilize\nany synthesized ground truth, design any loss function, or develop any fusion\nstrategy. Our proposed method EMEF takes advantage of the wisdom of multiple\nimperfect MEF contributors including both conventional and deep learning-based\nmethods. Specifically, EMEF consists of two main stages: pre-train an imitator\nnetwork and tune the imitator in the runtime. In the first stage, we make a\nunified network imitate different MEF targets in a style modulation way. In the\nsecond stage, we tune the imitator network by optimizing the style code, in\norder to find an optimal fusion result for each input pair. In the experiment,\nwe construct EMEF from four state-of-the-art MEF methods and then make\ncomparisons with the individuals and several other competitive methods on the\nlatest released MEF benchmark dataset. The promising experimental results\ndemonstrate that our ensemble framework can \"get the best of all worlds\". The\ncode is available at https://github.com/medalwill/EMEF.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:50:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12735","submitter":"Nemanja Stefan Perovic","authors":"Nemanja Stefan Perovi\\'c, Le-Nam Tran, Marco Di Renzo, Mark F.\n  Flanagan","title":"Optimization of RIS-aided SISO Systems Based on a Mutually Coupled\n  Loaded Wire Dipole Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The electromagnetic (EM) features of reconfigurable intelligent surfaces\n(RISs) fundamentally determine their operating principles and performance.\nMotivated by these considerations, we study a single-input single-output (SISO)\nsystem in the presence of an RIS, which is characterized by a circuit-based\nEM-compliant model. Specifically, we model the RIS as a collection of thin wire\ndipoles controlled by tunable load impedances, and we propose a gradient-based\nalgorithm for calculating the optimal impedances of the scattering elements of\nthe RIS in the presence of mutual coupling. Furthermore, we prove the\nconvergence of the proposed algorithm and derive its computational complexity\nin terms of number of complex multiplications. Numerical results show that the\nproposed algorithm provides better performance than a benchmark algorithm and\nthat it converges in a shorter amount of time.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:53:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12736","submitter":"Ali Kazemi Arani","authors":"Ali Kazemi Arani, Triet Huynh Minh Le, Mansooreh Zahedi and Muhammad\n  Ali Babar","title":"Mitigating ML Model Decay in Continuous Integration with Data Drift\n  Detection: An Empirical Study","comments":"12 pages, 5 figures, 4 tables, submitted to Empirical Software\n  Engineering and Measurement (ESEM) 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Background: Machine Learning (ML) methods are being increasingly used for\nautomating different activities, e.g., Test Case Prioritization (TCP), of\nContinuous Integration (CI). However, ML models need frequent retraining as a\nresult of changes in the CI environment, more commonly known as data drift.\nAlso, continuously retraining ML models consume a lot of time and effort.\nHence, there is an urgent need of identifying and evaluating suitable\napproaches that can help in reducing the retraining efforts and time for ML\nmodels used for TCP in CI environments. Aims: This study aims to investigate\nthe performance of using data drift detection techniques for automatically\ndetecting the retraining points for ML models for TCP in CI environments\nwithout requiring detailed knowledge of the software projects. Method: We\nemployed the Hellinger distance to identify changes in both the values and\ndistribution of input data and leveraged these changes as retraining points for\nthe ML model. We evaluated the efficacy of this method on multiple datasets and\ncompared the APFDc and NAPFD evaluation metrics against models that were\nregularly retrained, with careful consideration of the statistical methods.\nResults: Our experimental evaluation of the Hellinger distance-based method\ndemonstrated its efficacy and efficiency in detecting retraining points and\nreducing the associated costs. However, the performance of this method may vary\ndepending on the dataset. Conclusions: Our findings suggest that data drift\ndetection methods can assist in identifying retraining points for ML models in\nCI environments, while significantly reducing the required retraining time.\nThese methods can be helpful for practitioners who lack specialized knowledge\nof software projects, enabling them to maintain ML model accuracy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:55:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12737","submitter":"Zhuang Li","authors":"Zhuang Li, Lizhen Qu, Philip R. Cohen, Raj V. Tumuluri, Gholamreza\n  Haffari","title":"The Best of Both Worlds: Combining Human and Machine Translations for\n  Multilingual Semantic Parsing with Active Learning","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Multilingual semantic parsing aims to leverage the knowledge from the\nhigh-resource languages to improve low-resource semantic parsing, yet commonly\nsuffers from the data imbalance problem. Prior works propose to utilize the\ntranslations by either humans or machines to alleviate such issues. However,\nhuman translations are expensive, while machine translations are cheap but\nprone to error and bias. In this work, we propose an active learning approach\nthat exploits the strengths of both human and machine translations by\niteratively adding small batches of human translations into the\nmachine-translated training set. Besides, we propose novel aggregated\nacquisition criteria that help our active learning method select utterances to\nbe manually translated. Our experiments demonstrate that an ideal utterance\nselection can significantly reduce the error and bias in the translated data,\nresulting in higher parser accuracies than the parsers merely trained on the\nmachine-translated data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:57:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12738","submitter":"Chi Han","authors":"Chi Han, Qizheng He, Charles Yu, Xinya Du, Hanghang Tong, Heng Ji","title":"Logical Entity Representation in Knowledge-Graphs for Differentiable\n  Rule Learning","comments":"9 pages, 5 figures; accepted by 11th International Conference on\n  Learning Representations (ICLR 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Probabilistic logical rule learning has shown great strength in logical rule\nmining and knowledge graph completion. It learns logical rules to predict\nmissing edges by reasoning on existing edges in the knowledge graph. However,\nprevious efforts have largely been limited to only modeling chain-like Horn\nclauses such as $R_1(x,z)\\land R_2(z,y)\\Rightarrow H(x,y)$. This formulation\noverlooks additional contextual information from neighboring sub-graphs of\nentity variables $x$, $y$ and $z$. Intuitively, there is a large gap here, as\nlocal sub-graphs have been found to provide important information for knowledge\ngraph completion. Inspired by these observations, we propose Logical Entity\nRePresentation (LERP) to encode contextual information of entities in the\nknowledge graph. A LERP is designed as a vector of probabilistic logical\nfunctions on the entity's neighboring sub-graph. It is an interpretable\nrepresentation while allowing for differentiable optimization. We can then\nincorporate LERP into probabilistic logical rule learning to learn more\nexpressive rules. Empirical results demonstrate that with LERP, our model\noutperforms other rule learning methods in knowledge graph completion and is\ncomparable or even superior to state-of-the-art black-box methods. Moreover, we\nfind that our model can discover a more expressive family of logical rules.\nLERP can also be further combined with embedding learning methods like TransE\nto make it more interpretable.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:59:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12739","submitter":"Aman Saggu","authors":"Aman Saggu, Lennart Ante","title":"The Influence of ChatGPT on Artificial Intelligence Related Crypto\n  Assets: Evidence from a Synthetic Control Analysis","comments":"26 pages, 4 tables, 1 figure, 2 appendix figures","journal-ref":"Finance Research Letters, 103993 (2023)","doi":"10.1016/j.frl.2023.103993","report-no":null,"categories":"q-fin.GN q-fin.PR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  The introduction of OpenAI's large language model, ChatGPT, catalyzed\ninvestor attention towards artificial intelligence (AI) technologies, including\nAI-related crypto assets not directly related to ChatGPT. Utilizing the\nsynthetic difference-in-difference methodology, we identify significant\n'ChatGPT effects' with returns of AI-related crypto assets experiencing average\nreturns ranging between 10.7% and 15.6% (35.5% to 41.3%) in the one-month\n(two-month) period after the ChatGPT launch. Furthermore, Google search\nvolumes, a proxy for attention to AI, emerged as critical pricing indicators\nfor AI-related crypto post-launch. We conclude that investors perceived\nAI-assets as possessing heightened potential or value after the launch,\nresulting in higher market valuations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:59:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12740","submitter":"Ce Zheng","authors":"Ce Zheng, Lei Li, Qingxiu Dong, Yuxuan Fan, Zhiyong Wu, Jingjing Xu\n  and Baobao Chang","title":"Can We Edit Factual Knowledge by In-Context Learning?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Previous studies have shown that large language models (LLMs) like GPTs store\nmassive factual knowledge in their parameters. However, the stored knowledge\ncould be false or out-dated. Traditional knowledge editing methods refine LLMs\nvia fine-tuning on texts containing specific knowledge. However, with the\nincreasing scales of LLMs, these gradient-based approaches bring large\ncomputation costs. The trend of model-as-a-service also makes it impossible to\nmodify knowledge in black-box LMs. Inspired by in-context learning (ICL), a new\nparadigm based on demonstration contexts without parameter updating, we explore\nwhether ICL can edit factual knowledge. To answer this question, we give a\ncomprehensive empirical study of ICL strategies. Experiments show that\nin-context knowledge editing (IKE), without any gradient and parameter\nupdating, achieves a competitive success rate compared to gradient-based\nmethods on GPT-J (6B) but with much fewer side effects, including less\nover-editing on similar but unrelated facts and less knowledge forgetting on\npreviously stored knowledge. We also apply the method to larger LMs with tens\nor hundreds of parameters like OPT-175B, which shows the scalability of our\nmethod. The code is available at https://github.com/Zce1112zslx/IKE.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:07:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12741","submitter":"Debarpan Bhattacharya","authors":"Debarpan Bhattacharya, Neeraj Kumar Sharma, Debottam Dutta, Srikanth\n  Raj Chetupalli, Pravin Mote, Sriram Ganapathy, Chandrakiran C, Sahiti Nori,\n  Suhail K K, Sadhana Gonuguntla, Murali Alagesan","title":"Coswara: A respiratory sounds and symptoms dataset for remote screening\n  of SARS-CoV-2 infection","comments":"Accepted for publiation in Nature Scientific Data","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.LG cs.SD q-bio.QM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper presents the Coswara dataset, a dataset containing diverse set of\nrespiratory sounds and rich meta-data, recorded between April-2020 and\nFebruary-2022 from 2635 individuals (1819 SARS-CoV-2 negative, 674 positive,\nand 142 recovered subjects). The respiratory sounds contained nine sound\ncategories associated with variants of breathing, cough and speech. The rich\nmetadata contained demographic information associated with age, gender and\ngeographic location, as well as the health information relating to the\nsymptoms, pre-existing respiratory ailments, comorbidity and SARS-CoV-2 test\nstatus. Our study is the first of its kind to manually annotate the audio\nquality of the entire dataset (amounting to 65~hours) through manual listening.\nThe paper summarizes the data collection procedure, demographic, symptoms and\naudio data information. A COVID-19 classifier based on bi-directional long\nshort-term (BLSTM) architecture, is trained and evaluated on the different\npopulation sub-groups contained in the dataset to understand the bias/fairness\nof the model. This enabled the analysis of the impact of gender, geographic\nlocation, date of recording, and language proficiency on the COVID-19 detection\nperformance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:09:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12742","submitter":"Kamal Diki","authors":"Daniel Alpay, Antonino De Martino, Kamal Diki, Mihaela Vajiac","title":"The Bicomplex Tensor Product, a Bicomplex Choi Theorem and Applications","comments":"arXiv admin note: text overlap with arXiv:2202.02354","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper we extend the concept of tensor product to the bicomplex case\nand use it to prove the bicomplex counterpart of the classical Choi theorem in\nthe theory of complex matrices and operators. The concept of hyperbolic tensor\nproduct is also discussed, and we link these results to the theory of quantum\nchannels in the bicomplex and hyperbolic case, as well as applications to\nbicomplex digital signal processing.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:09:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12743","submitter":"Pengxin Zeng","authors":"Pengxin Zeng, Mouxing Yang, Yiding Lu, Changqing Zhang, Peng Hu, Xi\n  Peng","title":"Semantic Invariant Multi-view Clustering with Fully Incomplete\n  Information","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Robust multi-view learning with incomplete information has received\nsignificant attention due to issues such as incomplete correspondences and\nincomplete instances that commonly affect real-world multi-view applications.\nExisting approaches heavily rely on paired samples to realign or impute\ndefective ones, but such preconditions cannot always be satisfied in practice\ndue to the complexity of data collection and transmission. To address this\nproblem, we present a novel framework called SeMantic Invariance LEarning\n(SMILE) for multi-view clustering with incomplete information that does not\nrequire any paired samples. To be specific, we discover the existence of\ninvariant semantic distribution across different views, which enables SMILE to\nalleviate the cross-view discrepancy to learn consensus semantics without\nrequiring any paired samples. The resulting consensus semantics remains\nunaffected by cross-view distribution shifts, making them useful for\nrealigning/imputing defective instances and forming clusters. We demonstrate\nthe effectiveness of SMILE through extensive comparison experiments with 13\nstate-of-the-art baselines on five benchmarks. Our approach improves the\nclustering accuracy of NoisyMNIST from 19.3\\%/23.2\\% to 82.7\\%/69.0\\% when the\ncorrespondences/instances are fully incomplete. We will release the code after\nacceptance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:11:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12744","submitter":"Liangming Pan","authors":"Liangming Pan, Xiaobao Wu, Xinyuan Lu, Anh Tuan Luu, William Yang\n  Wang, Min-Yen Kan, Preslav Nakov","title":"Fact-Checking Complex Claims with Program-Guided Reasoning","comments":"ACL 2023 (main conference, long paper)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Fact-checking real-world claims often requires collecting multiple pieces of\nevidence and applying complex multi-step reasoning. In this paper, we present\nProgram-Guided Fact-Checking (ProgramFC), a novel fact-checking model that\ndecomposes complex claims into simpler sub-tasks that can be solved using a\nshared library of specialized functions. We first leverage the in-context\nlearning ability of large language models to generate reasoning programs to\nguide the verification process. Afterward, we execute the program by delegating\neach sub-task to the corresponding sub-task handler. This process makes our\nmodel both explanatory and data-efficient, providing clear explanations of its\nreasoning process and requiring minimal training data. We evaluate ProgramFC on\ntwo challenging fact-checking datasets and show that it outperforms seven\nfact-checking baselines across different settings of evidence availability,\nwith explicit output programs that benefit human debugging. Our codes and data\nare publicly available at https://github.com/mbzuai-nlp/ProgramFC.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:11:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12745","submitter":"Yan Li Zhou","authors":"Yan-Li Zhou, Xiao-Die Yu, Chun-Wang Wu, Xie-Qian Li, Jie Zhang, Weibin\n  Li, Ping-Xing Chen","title":"Accelerating relaxation through Liouvillian exceptional point","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate speeding up of relaxation of Markovian open quantum systems\nwith the Liouvillian exceptional point (LEP), where the slowest decay mode\ndegenerate with a faster decay mode. The degeneracy significantly increases the\ngap of the Liouvillian operator, which determines the timescale of such systems\nin converging to stationarity, and hence accelerates the relaxation process. We\nexplore an experimentally relevant three level atomic system, whose\neigenmatrices and eigenspectra are obtained completely analytically. This\nallows us to gain insights in the LEP and examine respective dynamics with\ndetails. We illustrate that the gap can be further widened through Floquet\nengineering, which further accelerates the relaxation process. Finally, we\nextend this approach to analyze laser cooling of trapped ions, where vibrations\n(phonons) couple to the electronic states. An optimal cooling condition is\nobtained analytically, which agrees with both existing experiments and\nnumerical simulations. Our study provides analytical insights in understanding\nLEP, as well as in controlling and optimizing dissipative dynamics of atoms and\ntrapped ions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:12:00 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 05:39:20 GMT"},{"version":"v3","created":"Tue, 6 Jun 2023 10:27:45 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.12746","submitter":"Xiaofan Wang","authors":"Xiaofan Wang, Li Zeng, Weiqing Zhang, Xueming Yang","title":"Ultra-high harmonic conversion of a seeded free-electron laser via\n  harmonic optical klystron","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.acc-ph physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  External seeded free-electron lasers (FELs) have proven to be compelling\ntools for generating fully coherent EUV and soft X-ray radiations. Echo-enabled\nharmonic generation (EEHG), as the most typical representative of external\nseeded FELs, has unparalleled harmonic conversion efficiency. However, due to\nthe limitations of various collective effects, the harmonic conversion of a\nhigh-gain EEHG that has been proved in experiments does not exceed 50 times.\nThis paper proposes a new EEHG technology with the help of harmonic optical\nklystron technology, which can effectively increase the number of harmonic\nconversion to about 100 times. Theoretical analysis and numerical simulations\nshow that intense and almost fully coherent FEL pulses with a radiation\nwavelength of 3 nm can be generated. At the same time, the seed laser intensity\nrequired by this scheme is lower, compared to nominal EEHG, thus facilitating\nthe generation of high repetition rate seeded FELs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:12:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12747","submitter":"Wanlun Ma","authors":"Wanlun Ma, Yiliao Song, Minhui Xue, Sheng Wen, Yang Xiang","title":"The \"code'' of Ethics:A Holistic Audit of AI Code Generators","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  AI-powered programming language generation (PLG) models have gained\nincreasing attention due to their ability to generate source code of programs\nin a few seconds with a plain program description. Despite their remarkable\nperformance, many concerns are raised over the potential risks of their\ndevelopment and deployment, such as legal issues of copyright infringement\ninduced by training usage of licensed code, and malicious consequences due to\nthe unregulated use of these models. In this paper, we present the\nfirst-of-its-kind study to systematically investigate the accountability of PLG\nmodels from the perspectives of both model development and deployment. In\nparticular, we develop a holistic framework not only to audit the training data\nusage of PLG models, but also to identify neural code generated by PLG models\nas well as determine its attribution to a source model. To this end, we propose\nusing membership inference to audit whether a code snippet used is in the PLG\nmodel's training data. In addition, we propose a learning-based method to\ndistinguish between human-written code and neural code. In neural code\nattribution, through both empirical and theoretical analysis, we show that it\nis impossible to reliably attribute the generation of one code snippet to one\nmodel. We then propose two feasible alternative methods: one is to attribute\none neural code snippet to one of the candidate PLG models, and the other is to\nverify whether a set of neural code snippets can be attributed to a given PLG\nmodel. The proposed framework thoroughly examines the accountability of PLG\nmodels which are verified by extensive experiments. The implementations of our\nproposed framework are also encapsulated into a new artifact, named\nCodeForensic, to foster further research.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:14:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12748","submitter":"Pavel Exner","authors":"Pavel Exner","title":"Geometry effects in quantum dot families","comments":"16 pages, two figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.SP cond-mat.mes-hall math-ph math.MP quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider Schr\\\"odinger operators in $L^2(\\mathrm{R}^\\nu),\\, \\nu=2,3$, with\nthe interaction in the form on an array of potential wells, each on them having\nrotational symmetry, arranged along a curve $\\Gamma$. We prove that if $\\Gamma$\nis a bend or deformation of a line, being straight outside a compact, and the\nwells have the same arcwise distances, such an operator has a nonempty discrete\nspectrum. It is also shown that if $\\Gamma$ is a circle, the principal\neigenvalue is maximized by the arrangement in which the wells have the same\nangular distances. Some conjectures and open problems are also mentioned.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:17:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12749","submitter":"Zihan Wang","authors":"Zihan Wang, Tianle Wang, Dheeraj Mekala, Jingbo Shang","title":"A Benchmark on Extremely Weakly Supervised Text Classification:\n  Reconcile Seed Matching and Prompting Approaches","comments":"ACL 2023 Findings","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Etremely Weakly Supervised Text Classification (XWS-TC) refers to text\nclassification based on minimal high-level human guidance, such as a few\nlabel-indicative seed words or classification instructions. There are two\nmainstream approaches for XWS-TC, however, never being rigorously compared: (1)\ntraining classifiers based on pseudo-labels generated by (softly) matching seed\nwords (SEED) and (2) prompting (and calibrating) language models using\nclassification instruction (and raw texts) to decode label words (PROMPT). This\npaper presents the first XWS-TC benchmark to compare the two approaches on fair\ngrounds, where the datasets, supervisions, and hyperparameter choices are\nstandardized across methods. Our benchmarking results suggest that (1) Both\nSEED and PROMPT approaches are competitive and there is no clear winner; (2)\nSEED is empirically more tolerant than PROMPT to human guidance (e.g., seed\nwords, classification instructions, and label words) changes; (3) SEED is\nempirically more selective than PROMPT to the pre-trained language models; (4)\nRecent SEED and PROMPT methods have close connections and a clustering\npost-processing step based on raw in-domain texts is a strong performance\nbooster to both. We hope this benchmark serves as a guideline in selecting\nXWS-TC methods in different scenarios and stimulate interest in developing\nguidance- and model-robust XWS-TC methods. We release the repo at\nhttps://github.com/ZihanWangKi/x-TC.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:18:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12750","submitter":"Ajay Dev","authors":"Ajay Dev, Simon P. Driver, Martin Meyer, Sambit Roychowdhury, Jonghwan\n  Rhee, Adam R. H. Stevens, Claudia del P. Lagos, Joss Bland-Hawthorn, Barbara\n  Catinella, A. M. Hopkins, Jonathan Loveday, Danail Obreschkow, Steven\n  Phillipps, Aaron S. G. Robotham","title":"Galaxy And Mass Assembly (GAMA): The group HI mass as a function of halo\n  mass","comments":"Accepted in MNRAS; 18 pages, 12 figures","journal-ref":null,"doi":"10.1093/mnras/stad1575","report-no":null,"categories":"astro-ph.CO astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We determine the atomic hydrogen (HI) to halo mass relation (HIHM) using\nArecibo Legacy Fast ALFA survey HI data at the location of optically selected\ngroups from the Galaxy and Mass Assembly (GAMA) survey. We make direct HI\ndetections for 37 GAMA groups. Using HI group spectral stacking of 345 groups,\nwe study the group HI content as function of halo mass across a halo mass range\nof $10^{11} - 10^{14.7}\\text{ M}_\\odot$. We also correct our results for\nEddington bias. We find that the group HI mass generally rises as a function of\nhalo mass from $1.3\\%$ of the halo mass at $10^{11.6} \\text{M}_\\odot$ to\n$0.4\\%$ at $10^{13.7} \\text{M}_\\odot$ with some indication of flattening\ntowards the high-mass end. Despite the differences in optical survey limits,\ngroup catalogues, and halo mass estimation methods, our results are consistent\nwith previous group HI-stacking studies. Our results are also consistent with\nmock observations from SHARK and IllustrisTNG.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:21:32 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.12751","submitter":"Matteo Biagiola","authors":"Matteo Biagiola, Paolo Tonella","title":"Testing of Deep Reinforcement Learning Agents with Surrogate Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Deep Reinforcement Learning (DRL) has received a lot of attention from the\nresearch community in recent years. As the technology moves away from game\nplaying to practical contexts, such as autonomous vehicles and robotics, it is\ncrucial to evaluate the quality of DRL agents. In this paper, we propose a\nsearch-based approach to test such agents. Our approach, implemented in a tool\ncalled Indago, trains a classifier on failure and non-failure environment\nconfigurations resulting from the DRL training process. The classifier is used\nat testing time as a surrogate model for the DRL agent execution in the\nenvironment, predicting the extent to which a given environment configuration\ninduces a failure of the DRL agent under test. Indeed, the failure prediction\nacts as a fitness function, in order to guide the generation towards failure\nenvironment configurations, while saving computation time by deferring the\nexecution of the DRL agent in the environment to those configurations that are\nmore likely to expose failures. Experimental results show that our search-based\napproach finds 50% more failures of the DRL agent than state-of-the-art\ntechniques. Moreover, such failure environment configurations, as well as the\nbehaviours of the DRL agent induced by them, are significantly more diverse.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:21:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12752","submitter":"Shouyong Jiang","authors":"Shouyong Jiang, Yong Wang, Yaru Hu, Qingyang Zhang, Shengxiang Yang","title":"Vector Autoregressive Evolution for Dynamic Multi-Objective Optimisation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Dynamic multi-objective optimisation (DMO) handles optimisation problems with\nmultiple (often conflicting) objectives in varying environments. Such problems\npose various challenges to evolutionary algorithms, which have popularly been\nused to solve complex optimisation problems, due to their dynamic nature and\nresource restrictions in changing environments. This paper proposes vector\nautoregressive evolution (VARE) consisting of vector autoregression (VAR) and\nenvironment-aware hypermutation to address environmental changes in DMO. VARE\nbuilds a VAR model that considers mutual relationship between decision\nvariables to effectively predict the moving solutions in dynamic environments.\nAdditionally, VARE introduces EAH to address the blindness of existing\nhypermutation strategies in increasing population diversity in dynamic\nscenarios where predictive approaches are unsuitable. A seamless integration of\nVAR and EAH in an environment-adaptive manner makes VARE effective to handle a\nwide range of dynamic environments and competitive with several popular DMO\nalgorithms, as demonstrated in extensive experimental studies. Specially, the\nproposed algorithm is computationally 50 times faster than two widely-used\nalgorithms (i.e., TrDMOEA and MOEA/D-SVR) while producing significantly better\nresults.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:24:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12753","submitter":"Xingxian Liu","authors":"Xingxian Liu, Yajing Xu","title":"Learning to Rank Utterances for Query-Focused Meeting Summarization","comments":"Accepted by Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Query-focused meeting summarization(QFMS) aims to generate a specific summary\nfor the given query according to the meeting transcripts. Due to the conflict\nbetween long meetings and limited input size, previous works mainly adopt\nextract-then-summarize methods, which use extractors to simulate binary labels\nor ROUGE scores to extract utterances related to the query and then generate a\nsummary. However, the previous approach fails to fully use the comparison\nbetween utterances. To the extractor, comparison orders are more important than\nspecific scores. In this paper, we propose a Ranker-Generator framework. It\nlearns to rank the utterances by comparing them in pairs and learning from the\nglobal orders, then uses top utterances as the generator's input. We show that\nlearning to rank utterances helps to select utterances related to the query\neffectively, and the summarizer can benefit from it. Experimental results on\nQMSum show that the proposed model outperforms all existing multi-stage models\nwith fewer parameters.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:25:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12754","submitter":"Satoshi Tsuchimi","authors":"Satoshi Tsuchimi","title":"$q$-difference equation satisfied by the universal mock theta functions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we give fundamental solutions of some $q$-difference equations\nsatisfied by the universal mock theta functions and the higher level Appell\nfunctions. As an application, we provide an alternative proof of the\nrepresentation formulas of the universal mock theta functions and the higher\nlevel Appell functions using Zwegers' $\\mu$-function.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:25:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12755","submitter":"Junhua Li","authors":"J. Li, Z. Duan, S. Li, X. Yu, G. Yang","title":"GNCformer Enhanced Self-attention for Automatic Speech Recognition","comments":"5 pages,3 figures,","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CL eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper,an Enhanced Self-Attention (ESA) mechanism has been put forward\nfor robust feature extraction.The proposed ESA is integrated with the recursive\ngated convolution and self-attention mechanism.In particular, the former is\nused to capture multi-order feature interaction and the latter is for global\nfeature extraction.In addition, the location of interest that is suitable for\ninserting the ESA is also worth being explored.In this paper, the ESA is\nembedded into the encoder layer of the Transformer network for automatic speech\nrecognition (ASR) tasks, and this newly proposed model is named GNCformer. The\neffectiveness of the GNCformer has been validated using two datasets, that are\nAishell-1 and HKUST.Experimental results show that, compared with the\nTransformer network,0.8%CER,and 1.2%CER improvement for these two mentioned\ndatasets, respectively, can be achieved.It is worth mentioning that only 1.4M\nadditional parameters have been involved in our proposed GNCformer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:26:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12756","submitter":"Mishal Assif P K","authors":"Mishal Assif P K, William Kennedy, Iraj Saniee","title":"Fair Allocation in Crowd-Sourced Systems","comments":"21 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we address the problem of fair sharing of the total value of a\ncrowd-sourced network system between major participants (founders) and minor\nparticipants (crowd) using cooperative game theory. Shapley allocation is\nregarded as a fair way for computing the shares of all participants in a\ncooperative game when the values of all possible coalitions could be\nquantified. We define a class of value functions for crowd-sourced systems\nwhich capture the contributions of the founders and the crowd plausibly and\nderive closed-form expressions for Shapley allocations to both. These value\nfunctions are defined for different scenarios, such as presence of oligopolies\nor geographic spread of the crowd, taking network effects, including Metcalfe's\nlaw, into account. A key result we obtain is that under quite general\nconditions, the crowd participants are collectively owed a share between\n$\\frac{1}{2}$ to $\\frac{2}{3}$ of the total value of the crowd-sourced system.\nWe close with an empirical analysis demonstrating consistency of our results\nwith the compensation offered to the crowd participants in some public internet\ncontent sharing companies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:27:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12757","submitter":"Seraphina Goldfarb-Tarrant","authors":"Seraphina Goldfarb-Tarrant, Eddie Ungless, Esma Balkir, Su Lin\n  Blodgett","title":"This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language\n  Models","comments":"Accepted to ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bias research in NLP seeks to analyse models for social biases, thus helping\nNLP practitioners uncover, measure, and mitigate social harms. We analyse the\nbody of work that uses prompts and templates to assess bias in language models.\nWe draw on a measurement modelling framework to create a taxonomy of attributes\nthat capture what a bias test aims to measure and how that measurement is\ncarried out. By applying this taxonomy to 90 bias tests, we illustrate\nqualitatively and quantitatively that core aspects of bias test\nconceptualisations and operationalisations are frequently unstated or\nambiguous, carry implicit assumptions, or be mismatched. Our analysis\nilluminates the scope of possible bias types the field is able to measure, and\nreveals types that are as yet under-researched. We offer guidance to enable the\ncommunity to explore a wider section of the possible bias space, and to better\nclose the gap between desired outcomes and experimental design, both for bias\nand for evaluating language models more broadly.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:28:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12758","submitter":"Fritz Colonius","authors":"Fritz Colonius and Alexandre J. Santana","title":"Chain recurrence and Selgrade`s theorem for affine flows","comments":"40 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC math.DS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Affine flows on vector bundles with chain transitive base flow are lifted to\nlinear flows and the decomposition into exponentially separated subbundles\nprovided by Selgrade's theorem is determined. The results are illustrated by an\napplication to affine control systems with bounded control range.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:29:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12759","submitter":"Hao Wang","authors":"Hao Wang, Hirofumi Shimizu, Daisuke Kawahara","title":"Kanbun-LM: Reading and Translating Classical Chinese in Japanese Methods\n  by Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent studies in natural language processing (NLP) have focused on modern\nlanguages and achieved state-of-the-art results in many tasks. Meanwhile,\nlittle attention has been paid to ancient texts and related tasks. Classical\nChinese first came to Japan approximately 2,000 years ago. It was gradually\nadapted to a Japanese form called Kanbun-Kundoku (Kanbun) in Japanese reading\nand translating methods, which has significantly impacted Japanese literature.\nHowever, compared to the rich resources for ancient texts in mainland China,\nKanbun resources remain scarce in Japan. To solve this problem, we construct\nthe first Classical-Chinese-to-Kanbun dataset in the world. Furthermore, we\nintroduce two tasks, character reordering and machine translation, both of\nwhich play a significant role in Kanbun comprehension. We also test the current\nlanguage models on these tasks and discuss the best evaluation method by\ncomparing the results with human scores. We release our code and dataset on\nGitHub.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:30:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12760","submitter":"Nourhan Hesham Ms","authors":"Nourhan Hesham, Anas Chaaban, Hesham ElSawy, and Jahangir Hossain","title":"Finite Blocklength Regime Performance of Downlink Large Scale Networks","comments":"This paper is submitted in IEEE Transactions on Wireless\n  Communications (Status: Accepted). This is a 32-pages paper with 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Some emerging 5G and beyond use-cases impose stringent latency constraints,\nwhich necessitates a paradigm shift towards finite blocklength performance\nanalysis. In contrast to Shannon capacity-achieving codes, the codeword length\nin the finite blocklength regime (FBR) is a critical design parameter that\nimposes an intricate tradeoff between delay, reliability, and information\ncoding rate. In this context, this paper presents a novel mathematical analysis\nto characterize the performance of large-scale downlink networks using short\ncodewords. Theoretical achievable rates, outage probability, and reliability\nexpressions are derived using the finite blocklength coding theory in\nconjunction with stochastic geometry, and compared to the performance in the\nasymptotic regime (AR). Achievable rates under practical modulation schemes as\nwell as multilevel polar coded modulation (MLPCM) are investigated. Numerical\nresults provide theoretical performance benchmarks, highlight the potential of\nMLPCM in achieving close to optimal performance with short codewords, and\nconfirm the discrepancy between the performance in the FBR and that predicted\nby analysis in the AR. Finally, the meta distribution of the coding rate is\nderived, providing the percentiles of users that achieve a predefined target\nrate in a network.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:30:38 GMT"},{"version":"v2","created":"Thu, 25 May 2023 19:26:31 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12761","submitter":"Shu'ang Li","authors":"Shuang Li, Xuming Hu, Aiwei Liu, Yawen Yang, Fukun Ma, Philip S. Yu,\n  Lijie Wen","title":"Enhancing Cross-lingual Natural Language Inference by Soft Prompting\n  with Multilingual Verbalizer","comments":"Accept at ACL2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cross-lingual natural language inference is a fundamental problem in\ncross-lingual language understanding. Many recent works have used prompt\nlearning to address the lack of annotated parallel corpora in XNLI. However,\nthese methods adopt discrete prompting by simply translating the templates to\nthe target language and need external expert knowledge to design the templates.\nBesides, discrete prompts of human-designed template words are not trainable\nvectors and can not be migrated to target languages in the inference stage\nflexibly. In this paper, we propose a novel Soft prompt learning framework with\nthe Multilingual Verbalizer (SoftMV) for XNLI. SoftMV first constructs\ncloze-style question with soft prompts for the input sample. Then we leverage\nbilingual dictionaries to generate an augmented multilingual question for the\noriginal question. SoftMV adopts a multilingual verbalizer to align the\nrepresentations of original and augmented multilingual questions into the same\nsemantic space with consistency regularization. Experimental results on XNLI\ndemonstrate that SoftMV can achieve state-of-the-art performance and\nsignificantly outperform the previous methods under the few-shot and full-shot\ncross-lingual transfer settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:31:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12762","submitter":"Yongqing Cai","authors":"Xiangyue Cui, Hejin Yan, Xuefei Yan, Kun Zhou, Yongqing Cai","title":"Promoted Electronic Coupling of Acoustic Phonon Modes in Doped\n  Semimetallic MoTe2","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  As a prototype of the Weyl superconductor, layered molybdenum telluride\n(MoTe2) encompasses two semimetallic phases (1T_prime and Td) which\ndifferentiate from each other via a slight tilting of the out-of-plane lattice.\nBoth phases are subjected to serious phase mixing which complicates the\nanalysis of its origin of superconductivity. Herein, we explore the\nelectron-phonon coupling (EPC) of the monolayer semimetallic MoTe2, without\nphase ambiguity under this thickness limit. Apart from the hardening or\nsoftening of phonon modes, the strength of the EPC can be strongly modulated by\ndoping. Specifically, longitudinal and out-of-plane acoustic modes are\nsignificantly activated for electron doped MoTe2. This is ascribed to the\npresence of rich valley states and equispaced nesting bands which are\ndynamically populated under charge doping. Through comparing the monolayer and\nbilayer MoTe2, the strength of EPC is found to be less likely to depend on\nthickness for neutral samples but clearly promoted for thinner samples with\nelectron doping, while for hole doping, the strength alters more significantly\nwith the thickness than doping. Our work explains the puzzling issue of the\ndoping sensitivity of the superconductivity in semimetallic MoTe2 and\nestablishes the critical role of activating acoustic phonons in such\nlow-dimensional materials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:32:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12763","submitter":"You Shan","authors":"Yiting Chen, Tracy Xiao Liu, You Shan, and Songfa Zhong","title":"The Emergence of Economic Rationality of GPT","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As large language models (LLMs) like GPT become increasingly prevalent, it is\nessential that we assess their capabilities beyond language processing. This\npaper examines the economic rationality of GPT by instructing it to make\nbudgetary decisions in four domains: risk, time, social, and food preferences.\nWe measure economic rationality by assessing the consistency of GPT decisions\nwith utility maximization in classic revealed preference theory. We find that\nGPT decisions are largely rational in each domain and demonstrate higher\nrationality scores than those of humans reported in the literature. We also\nfind that the rationality scores are robust to the degree of randomness and\ndemographic settings such as age and gender, but are sensitive to contexts\nbased on the language frames of the choice situations. These results suggest\nthe potential of LLMs to make good decisions and the need to further understand\ntheir capabilities, limitations, and underlying mechanisms.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:32:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12764","submitter":"Qing-Hong Cao","authors":"Qing-Hong Cao, Kun Cheng, Changlong Xu","title":"Global Symmetries and Effective Potential of 2HDM in Orbit Space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We extend the framework of analyzing the 2HDM in its orbit space to study the\none-loop effective potential before and after electroweak symmetry breaking. In\nthis framework, we present a comprehensive analysis of global symmetries of the\none-loop thermal effective potential in the 2HDM, demonstrating when the global\nsymmetries of the tree-level 2HDM potential are broken by loop contributions.\nBy introducing light-cone coordinates and generalizing the bilinear notation\naround the vacuum, we present a geometric view of the scalar mass matrix and\non-shell renormalization conditions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:35:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12765","submitter":"Adam Bednorz","authors":"Adam Bednorz","title":"General quantum measurements in relativistic quantum field theory","comments":"15 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Single particle detection is described in a limited way by simple models of\nmeasurements in quantum field theory. We show that a general approach, using\nKraus operators in spacetime constructed from natural combinations of fields,\nleads to an efficient model of a single particle detector. The model is free\nfrom any auxiliary objects as it is defined solely within the existing quantum\nfield framework. It can be applied to a large family of setup where the time\nresolution of the measurement is relevant, such as Bell correlations or\nsequential measurement. We also discuss limitations and working regimes of the\nmodel.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:37:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12766","submitter":"Chi Han","authors":"Chi Han, Ziqi Wang, Han Zhao, Heng Ji","title":"In-Context Learning of Large Language Models Explained as Kernel\n  Regression","comments":"9 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models (LLMs) have initiated a paradigm shift in transfer\nlearning. In contrast to the classic pretraining-then-finetuning procedure, in\norder to use LLMs for downstream prediction tasks, one only needs to provide a\nfew demonstrations, known as in-context examples, without adding more or\nupdating existing model parameters. This in-context learning (ICL) capabilities\nof LLMs is intriguing, and it is not yet fully understood how pretrained LLMs\nacquire such capabilities. In this paper, we investigate the reason why a\ntransformer-based language model can accomplish in-context learning after\npre-training on a general language corpus by proposing one hypothesis that LLMs\ncan simulate kernel regression algorithms when faced with in-context examples.\nMore concretely, we first prove that Bayesian inference on in-context prompts\ncan be asymptotically understood as kernel regression $\\hat y = \\frac{\\sum_i\ny_i K(x, x_i)}{\\sum_i K(x, x_i)}$ as the number of in-context demonstrations\ngrows. Then, we empirically investigate the in-context behaviors of language\nmodels. We find that during ICL, the attentions and hidden features in LLMs\nmatch the behaviors of a kernel regression. Finally, our theory provides\ninsights on multiple phenomena observed in ICL field: why retrieving\ndemonstrative samples similar to test sample can help, why ICL performance is\nsensitive to the output formats, and why ICL accuracy benefits from selecting\nin-distribution and representative samples. We will make our code available to\nthe research community following publication.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:45:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12767","submitter":"Yunlong Liang","authors":"Yunlong Liang, Fandong Meng, Jiaan Wang, Jinan Xu, Yufeng Chen, Jie\n  Zhou","title":"D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling\n  for Many-to-Many Multimodal Summarization","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many-to-many multimodal summarization (M$^3$S) task aims to generate\nsummaries in any language with document inputs in any language and the\ncorresponding image sequence, which essentially comprises multimodal\nmonolingual summarization (MMS) and multimodal cross-lingual summarization\n(MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has\nobtained increasing attention in recent years, little research pays attention\nto the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS\nto enhance MXLS via knowledge distillation without considering the performance\nof MMS or 2) improving MMS models by filtering summary-unrelated visual\nfeatures with implicit learning or explicitly complex training objectives. In\nthis paper, we first introduce a general and practical task, i.e., M$^3$S.\nFurther, we propose a dual knowledge distillation and target-oriented vision\nmodeling framework for the M$^3$S task. Specifically, the dual knowledge\ndistillation method guarantees that the knowledge of MMS and MXLS can be\ntransferred to each other and thus mutually prompt both of them. To offer\ntarget-oriented visual features, a simple yet effective target-oriented\ncontrastive objective is designed and responsible for discarding needless\nvisual information. Extensive experiments on the many-to-many setting show the\neffectiveness of the proposed approach. Additionally, we will contribute a\nmany-to-many multimodal summarization (M$^3$Sum) dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:47:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12768","submitter":"Jae-woong Lee","authors":"Jae-woong Lee, Seongmin Park, Mincheol Yoon, and Jongwuk Lee","title":"uCTRL: Unbiased Contrastive Representation Learning via Alignment and\n  Uniformity for Collaborative Filtering","comments":"SIGIR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Because implicit user feedback for the collaborative filtering (CF) models is\nbiased toward popular items, CF models tend to yield recommendation lists with\npopularity bias. Previous studies have utilized inverse propensity weighting\n(IPW) or causal inference to mitigate this problem. However, they solely employ\npointwise or pairwise loss functions and neglect to adopt a contrastive loss\nfunction for learning meaningful user and item representations. In this paper,\nwe propose Unbiased ConTrastive Representation Learning (uCTRL), optimizing\nalignment and uniformity functions derived from the InfoNCE loss function for\nCF models. Specifically, we formulate an unbiased alignment function used in\nuCTRL. We also devise a novel IPW estimation method that removes the bias of\nboth users and items. Despite its simplicity, uCTRL equipped with existing CF\nmodels consistently outperforms state-of-the-art unbiased recommender models,\nup to 12.22% for Recall@20 and 16.33% for NDCG@20 gains, on four benchmark\ndatasets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:55:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12769","submitter":"Lingfei Jin","authors":"Keqin Feng, Lingfei Jin, Chaoping Xing and Chen Yuan","title":"Constructions of $k$-uniform states in heterogeneous systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A pure quantum state of $n$ parties associated with the Hilbert space\n$\\CC^{d_1}\\otimes \\CC^{d_2}\\otimes\\cdots\\otimes \\CC^{d_n}$ is called\n$k$-uniform if all the reductions to $k$-parties are maximally mixed. The $n$\npartite system is called homogenous if the local dimension\n$d_1=d_2=\\cdots=d_n$, while it is called heterogeneous if the local dimension\nare not all equal. $k$-uniform sates play an important role in quantum\ninformation theory. There are many progress in characterizing and constructing\n$k$-uniform states in homogeneous systems. However, the study of entanglement\nfor heterogeneous systems is much more challenging than that for the\nhomogeneous case. There are very few results known for the $k$-uniform states\nin heterogeneous systems for $k>3$. We present two general methods to construct\n$k$-uniform states in the heterogeneous systems for general $k$. The first\nconstruction is derived from the error correcting codes by establishing a\nconnection between irredundant mixed orthogonal arrays and error correcting\ncodes. We can produce many new $k$-uniform states such that the local dimension\nof each subsystem can be a prime power. The second construction is derived from\na matrix $H$ meeting the condition that $H_{A\\times \\bar{A}}+H^T_{\\bar{A}\\times\nA}$ has full rank for any row index set $A$ of size $k$. These matrix\nconstruction can provide more flexible choices for the local dimensions, i.e.,\nthe local dimensions can be any integer (not necessarily prime power) subject\nto some constraints. Our constructions imply that for any positive integer $k$,\none can construct $k$-uniform states of a heterogeneous system in many\ndifferent Hilbert spaces.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:58:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12770","submitter":"Kun Li","authors":"Kun Li and Fan Zhang and Wei Guo","title":"FGAM:Fast Adversarial Malware Generation Method Based on Gradient Sign","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Malware detection models based on deep learning have been widely used, but\nrecent research shows that deep learning models are vulnerable to adversarial\nattacks. Adversarial attacks are to deceive the deep learning model by\ngenerating adversarial samples. When adversarial attacks are performed on the\nmalware detection model, the attacker will generate adversarial malware with\nthe same malicious functions as the malware, and make the detection model\nclassify it as benign software. Studying adversarial malware generation can\nhelp model designers improve the robustness of malware detection models. At\npresent, in the work on adversarial malware generation for byte-to-image\nmalware detection models, there are mainly problems such as large amount of\ninjection perturbation and low generation efficiency. Therefore, this paper\nproposes FGAM (Fast Generate Adversarial Malware), a method for fast generating\nadversarial malware, which iterates perturbed bytes according to the gradient\nsign to enhance adversarial capability of the perturbed bytes until the\nadversarial malware is successfully generated. It is experimentally verified\nthat the success rate of the adversarial malware deception model generated by\nFGAM is increased by about 84\\% compared with existing methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 06:58:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12771","submitter":"Uwe R. Fischer","authors":"Sang-Shin Baak, Satadal Datta, Uwe R. Fischer","title":"Petrov classification of analogue spacetimes","comments":"10 pages, 2 figures; further clarification and added references","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In an effort to invariantly characterize the conformal curvature structure of\nanalogue spacetimes built from a nonrelativistic fluid background, we determine\nthe Petrov type of a variety of lab geometries. Starting from the simplest\nexamples, we increase the complexity of the background, and thereby determine\nhow the lab fluid symmetry affects the corresponding Petrov type in the\nanalogue spacetime realm of the sound waves. We find that for more complex\nflows isolated hypersurfaces develop, which are of a Petrov type differing from\nthat of the surrounding fluid.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:01:13 GMT"},{"version":"v2","created":"Wed, 31 May 2023 04:55:16 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.12772","submitter":"Klas Markstr\\\"om","authors":"Victor Falgas-Ravry, Klas Markstr\\\"om, and Eero R\\\"aty","title":"Minimum degree conditions for rainbow triangles","comments":"This paper was earlier part of a longer version of arXiv:2212.07180","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO cs.DM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let $\\mathbf{G}:=(G_1, G_2, G_3)$ be a triple of graphs on a common vertex\nset $V$ of size $n$. A rainbow triangle in $\\mathbf{G}$ is a triple of edges\n$(e_1, e_2, e_3)$ with $e_i\\in G_i$ for each $i$ and $\\{e_1, e_2, e_3\\}$\nforming a triangle in $V$. In this paper we consider the following question:\nwhat triples of minimum degree conditions $(\\delta(G_1), \\delta(G_2),\n\\delta(G_3))$ guarantee the existence of a rainbow triangle? This may be seen\nas a minimum degree version of a problem of Aharoni, DeVos, de la Maza,\nMontejanos and \\v{S}\\'amal on density conditions for rainbow triangles, which\nwas recently resolved by the authors. We establish that the extremal behaviour\nin the minimum degree setting differs strikingly from that seen in the density\nsetting, with discrete jumps as opposed to continuous transitions. Our work\nleaves a number of natural questions open, which we discuss.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:01:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12773","submitter":"Maciej Malinowski","authors":"M. Malinowski, D. T. C. Allcock, C. J. Ballance","title":"How to wire a 1000-qubit trapped ion quantum computer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  One of the most formidable challenges of scaling up quantum computers is that\nof control signal delivery. Today's small-scale quantum computers typically\nconnect each qubit to one or more separate external signal sources. This\napproach is not scalable due to the I/O limitations of the qubit chip,\nnecessitating the integration of control electronics. However, it is no small\nfeat to shrink control electronics into a small package that is compatible with\nqubit chip fabrication and operation constraints without sacrificing\nperformance. This so-called \"wiring challenge\" is likely to impact the\ndevelopment of more powerful quantum computers even in the near term. In this\npaper, we address the wiring challenge of trapped-ion quantum computers. We\ndescribe a control architecture called WISE (Wiring using Integrated Switching\nElectronics), which significantly reduces the I/O requirements of ion trap\nquantum computing chips without compromising performance. Our method relies on\njudiciously integrating simple switching electronics into the ion trap chip -\nin a way that is compatible with its fabrication and operation constraints -\nwhile complex electronics remain external. To demonstrate its power, we\ndescribe how the WISE architecture can be used to operate a fully connected\n1000-qubit trapped ion quantum computer using ~ 200 signal sources at a speed\nof ~ 40 - 2600 quantum gate layers per second.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:01:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12774","submitter":"Shoutao Guo","authors":"Shoutao Guo, Shaolei Zhang, Yang Feng","title":"Learning Optimal Policy for Simultaneous Machine Translation via Binary\n  Search","comments":"Accepted to ACL 2023. 14 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Simultaneous machine translation (SiMT) starts to output translation while\nreading the source sentence and needs a precise policy to decide when to output\nthe generated translation. Therefore, the policy determines the number of\nsource tokens read during the translation of each target token. However, it is\ndifficult to learn a precise translation policy to achieve good latency-quality\ntrade-offs, because there is no golden policy corresponding to parallel\nsentences as explicit supervision. In this paper, we present a new method for\nconstructing the optimal policy online via binary search. By employing explicit\nsupervision, our approach enables the SiMT model to learn the optimal policy,\nwhich can guide the model in completing the translation during inference.\nExperiments on four translation tasks show that our method can exceed strong\nbaselines across all latency scenarios.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:03:06 GMT"},{"version":"v2","created":"Thu, 25 May 2023 13:55:22 GMT"},{"version":"v3","created":"Sat, 27 May 2023 15:27:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12775","submitter":"Marco Braun","authors":"Marco Braun, Alessandro Cennamo, Markus Schoeler, Kevin Kollek, Anton\n  Kummert","title":"Semantic Segmentation of Radar Detections using Convolutions on Point\n  Clouds","comments":"5th International Conference on Artificial Intelligence, Automation\n  and Control Technologies (AIACT 2021), 26-28 March 2021, Shanghai, China","journal-ref":"Journal of Physics: Conference Series, Volume 1924","doi":"10.1088/1742-6596/1924/1/012003","report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For autonomous driving, radar sensors provide superior reliability regardless\nof weather conditions as well as a significantly high detection range.\nState-of-the-art algorithms for environment perception based on radar scans\nbuild up on deep neural network architectures that can be costly in terms of\nmemory and computation. By processing radar scans as point clouds, however, an\nincrease in efficiency can be achieved in this respect. While Convolutional\nNeural Networks show superior performance on pattern recognition of regular\ndata formats like images, the concept of convolutions is not yet fully\nestablished in the domain of radar detections represented as point clouds. The\nmain challenge in convolving point clouds lies in their irregular and unordered\ndata format and the associated permutation variance. Therefore, we apply a\ndeep-learning based method introduced by PointCNN that weights and permutes\ngrouped radar detections allowing the resulting permutation invariant cluster\nto be convolved. In addition, we further adapt this algorithm to radar-specific\nproperties through distance-dependent clustering and pre-processing of input\npoint clouds. Finally, we show that our network outperforms state-of-the-art\napproaches that are based on PointNet++ on the task of semantic segmentation of\nradar point clouds.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:09:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12776","submitter":"Xiang Li","authors":"Xiang Li, Jia-Cheng Huang, Guang-Ze Zhang, Changsu Cao, Han-Shi Hu","title":"Non-stochastic Optimization Algorithm for Neural-network Quantum States","comments":"21 pages, 5 figures, and 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Neural-network quantum states (NQS), which use an artificial neural network\nto encode variational many-body wave functions in second quantization, have\nbeen successfully applied to the electronic problem for several molecules\nrecently. Though already competes with many traditional quantum chemistry\nmethods, describing electronic wave function of molecules using NQS is just in\nits early stages. Here we introduce a general non-stochastic optimization\nalgorithm for NQS in chemical systems, which deterministically generates a\nselected set of important configurations simultaneously with energy evaluation\nof NQS and sidesteps Markov-chain Monte Carlo that is required in the typical\nvariational Monte Carlo (VMC) framework, making the whole optimization smoother\nand faster. This newly developed non-stochastic optimization algorithm for NQS\ncan recover the potential energy curves with a level of accuracy competitive\nwith CCSD(T) in carbon dimer with cc-pVDZ basis after perturbative correction\nwith ~$1.4\\times 10^{11}$ configurations in the full variational space, and to\nan accuracy of better than 0.2 mHa in strongly correlated equidistant hydrogen\nchain H10 with STO-6G basis. These successful applications of NQS to molecules\nthat have large variational spaces or strong electron correlations manifest the\nstrength of our non-stochastic optimization algorithm, provide further\nunderstanding about the performance of NQS in chemical systems and suggest\nroutes for future improvements.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:13:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12777","submitter":"Polina Tsvilodub","authors":"Polina Tsvilodub, Michael Franke","title":"Evaluating Pragmatic Abilities of Image Captioners on A3DS","comments":"5 pages, 2 figures, to appear in the 61st Proceedings of the\n  Association for Computational Linguistics (ACL 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Evaluating grounded neural language model performance with respect to\npragmatic qualities like the trade off between truthfulness, contrastivity and\noverinformativity of generated utterances remains a challenge in absence of\ndata collected from humans. To enable such evaluation, we present a novel open\nsource image-text dataset \"Annotated 3D Shapes\" (A3DS) comprising over nine\nmillion exhaustive natural language annotations and over 12 million\nvariable-granularity captions for the 480,000 images provided by Burges & Kim\n(2018). We showcase the evaluation of pragmatic abilities developed by a\ntask-neutral image captioner fine-tuned in a multi-agent communication setting\nto produce contrastive captions. The evaluation is enabled by the dataset\nbecause the exhaustive annotations allow to quantify the presence of\ncontrastive features in the model's generations. We show that the model\ndevelops human-like patterns (informativity, brevity, over-informativity for\nspecific features (e.g., shape, color biases)).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:15:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12778","submitter":"Baihua Shi","authors":"Baihua Shi, Yang Wang, Danqi Li, Wenlong Cai, Jinyong Lin, Shuo Zhang,\n  Weiping Shi, Shihao Yan, and Feng Shu","title":"STAR-RIS-UAV Aided Coordinated Multipoint Cellular System for Multi-user\n  Networks","comments":"10 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Different with conventional reconfigurable intelligent surface (RIS),\nsimultaneous transmitting and reflecting RIS (STAR-RIS) can reflect and\ntransmit the signals to the receiver. In this paper, to serve more ground users\nand increase the deployment flexibility, we investigate an unmanned aerial\nvehicle equipped with a STAR-RIS (STAR-RIS-UAV) aided wireless communications\nfor multi-user networks. Energy splitting (ES) and mode switching (MS)\nprotocols are considered to control the reflection and transmission\ncoefficients of STAR-RIS elements. To maximize the sum rate of the STAR-RIS-UAV\naided coordinated multipoint cellular system for multi-user networks, the\ncorresponding beamforming vectors as well as transmitted and reflected\ncoefficients matrices are optimized. Specifically, instead of adopting the\nalternating optimization, we design an iteration method to optimize all\nvariables for both ES and MS protocols at the same time. Simulation results\nreveal that STAR-RIS-UAV aided wireless communication system has a much higher\nsum rate than the system with conventional RIS or without RIS. Furthermore, the\nproposed structure is more flexible than a fixed STAR-RIS and could greatly\npromote the sum rate.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:19:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12779","submitter":"Gregor Rauw","authors":"Gregor Rauw (1), Ya\\\"el Naz\\'e (1,2), Eric Gosset (1,2) ((1) Liege\n  University, Belgium, (2) FNRS, Belgium)","title":"Revisiting the orbital motion of WR 138","comments":"accepted for publication by New Astronomy","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The optical spectrum of WR 138 exhibits emission lines typical of a WN6o star\nand absorption lines from a rapidly-rotating OB star. Using a large set of\nspectroscopic data, we establish a new orbital solution of the WN6o star based\non the radial velocities of highly-ionized nitrogen lines. We show that the\nWN6o star moves on a 4.3 yr orbit with a comparatively low eccentricity of\n0.16. The radial velocities of the OB star display considerable scatter. Our\nbest estimates of the velocities of He I absorption lines result in a\nmass-ratio of $m_{\\rm WN6o}/m_{\\rm OB} = 0.53 \\pm 0.09$. We disentangle the\nspectra of the two stars and derive a projected rotational velocity of\n$v\\,\\sin{i} = 350 \\pm 10$ km s$^{-1}$ for the OB star. Our best orbital\nparameters, combined with the Gaia parallax of WR 138, are at odds with a\nprevious interferometric detection of the companion, suggesting that there is\neither a bias in this detection or that WR 138 is actually a triple system.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:19:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12780","submitter":"Tejas Kalelkar","authors":"Tejas Kalelkar and Ramya Nair","title":"Essential surfaces in Seifert fiber spaces with singular surfaces","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Two-sided incompressible surfaces in Seifert fiber spaces with isolated\nsingular fibers are well-understood. Frohman and Rannard have shown that\none-sided incompressible surfaces in Seifert fiber spaces which have isolated\nsingular fibers are either pseudo-horizontal or psuedo-vertical. We extend\ntheir result to characterise essential surfaces in Seifert fiber spaces which\nmay have singular surfaces, i.e., in $S^1$-foliated $3$-manifolds which have\nfibered model neighbourhoods that are isomorphic to either a fibered solid\ntorus or a fibered solid Klein bottle.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:20:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12781","submitter":"Chokri Ogabi","authors":"David Maltese and Chokri Ogabi","title":"Uniform estimations for conforming Galerkin method for anisotropic\n  singularly perturbed elliptic problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this article, we study some anisotropic singular perturbations for a class\nof linear elliptic problems. A uniform estimations for conforming $Q_1$ finite\nelement method are derived, and some other results of convergence and\nregularity for the continuous problem are proved.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:22:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12782","submitter":"Liang Chen","authors":"Liang Chen, Hongru Wang, Yang Deng, Wai-Chung Kwan, Zezhong Wang and\n  Kam-Fai Wong","title":"Towards Robust Personalized Dialogue Generation via Order-Insensitive\n  Representation Regularization","comments":"ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Generating persona consistent dialogue response is important for developing\nan intelligent conversational agent. Recent works typically fine-tune\nlarge-scale pre-trained models on this task by concatenating persona texts and\ndialogue history as a single input sequence to generate the target response.\nWhile simple and effective, our analysis shows that this popular practice is\nseriously affected by order sensitivity where different input orders of persona\nsentences significantly impact the quality and consistency of generated\nresponse, resulting in severe performance fluctuations (i.e., 29.4% on GPT2 and\n83.2% on BART). To mitigate the order sensitivity problem, we propose a\nmodel-agnostic framework, ORder Insensitive Generation (ORIG), which enables\ndialogue models to learn robust representation under different persona orders\nand improve the consistency of response generation. Experiments on the\nPersona-Chat dataset justify the effectiveness and superiority of our method\nwith two dominant pre-trained models (GPT2 and BART).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:24:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12783","submitter":"Kamakhya Mishra Mr","authors":"Dr. Prabhat Santi, Kamakhya Mishra, Sibabrata Mohanty","title":"Quantum Text Classifier -- A Synchronistic Approach Towards Classical\n  and Quantum Machine Learning","comments":"7 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Although it will be a while before a practical quantum computer is available,\nthere is no need to hold off. Methods and algorithms are being developed to\ndemonstrate the feasibility of running machine learning (ML) pipelines in QC\n(Quantum Computing). There is a lot of ongoing work on general QML (Quantum\nMachine Learning) algorithms and applications. However, a working model or\npipeline for a text classifier using quantum algorithms isn't available. This\npaper introduces quantum machine learning w.r.t text classification to readers\nof classical machine learning. It begins with a brief description of quantum\ncomputing and basic quantum algorithms, with an emphasis on building text\nclassification pipelines. A new approach is introduced to implement an\nend-to-end text classification framework (Quantum Text Classifier - QTC), where\npre- and post-processing of data is performed on a classical computer, and text\nclassification is performed using the QML algorithm. This paper also presents\nan implementation of the QTC framework and available quantum ML algorithms for\ntext classification using the IBM Qiskit library and IBM backends.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:27:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12784","submitter":"Jason Kim","authors":"Hritvik Taneja, Jason Kim, Jie Jeff Xu, Stephan van Schaik, Daniel\n  Genkin, Yuval Yarom","title":"Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and ARM\n  SoCs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The drive to create thinner, lighter, and more energy efficient devices has\nresulted in modern SoCs being forced to balance a delicate tradeoff between\npower consumption, heat dissipation, and execution speed (i.e., frequency).\nWhile beneficial, these DVFS mechanisms have also resulted in software-visible\nhybrid side-channels, which use software to probe analog properties of\ncomputing devices. Such hybrid attacks are an emerging threat that can bypass\ncountermeasures for traditional microarchitectural side-channel attacks.\n  Given the rise in popularity of both Arm SoCs and GPUs, in this paper we\ninvestigate the susceptibility of these devices to information leakage via\npower, temperature and frequency, as measured via internal sensors. We\ndemonstrate that the sensor data observed correlates with both instructions\nexecuted and data processed, allowing us to mount software-visible hybrid\nside-channel attacks on these devices.\n  To demonstrate the real-world impact of this issue, we present\nJavaScript-based pixel stealing and history sniffing attacks on Chrome and\nSafari, with all side channel countermeasures enabled. Finally, we also show\nwebsite fingerprinting attacks, without any elevated privileges.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:29:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12785","submitter":"Hanxing Ding","authors":"Hanxing Ding, Liang Pang, Zihao Wei, Huawei Shen, Xueqi Cheng,\n  Tat-Seng Chua","title":"MacLaSa: Multi-Aspect Controllable Text Generation via Efficient\n  Sampling from Compact Latent Space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-aspect controllable text generation aims to generate fluent sentences\nthat possess multiple desired attributes simultaneously. Traditional methods\neither combine many operators in the decoding stage, often with costly\niteration or search in the discrete text space, or train separate controllers\nfor each aspect, resulting in a degeneration of text quality due to the\ndiscrepancy between different aspects. To address these limitations, we\nintroduce a novel approach for multi-aspect control, namely MacLaSa, that\nestimates compact latent space for multiple aspects and performs efficient\nsampling with a robust sampler based on ordinary differential equations (ODEs).\nTo eliminate the domain gaps between different aspects, we utilize a\nVariational Autoencoder (VAE) network to map text sequences from varying data\nsources into close latent representations. The estimated latent space enables\nthe formulation of joint energy-based models (EBMs) and the plugging in of\narbitrary attribute discriminators to achieve multi-aspect control. Afterwards,\nwe draw latent vector samples with an ODE-based sampler and feed sampled\nexamples to the VAE decoder to produce target text sequences. Experimental\nresults demonstrate that MacLaSa outperforms several strong baselines on\nattribute relevance and textual quality while maintaining a high inference\nspeed.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:30:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12786","submitter":"Wen Lai","authors":"Wen Lai, Alexandra Chronopoulou, Alexander Fraser","title":"Mitigating Data Imbalance and Representation Degeneration in\n  Multilingual Machine Translation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite advances in multilingual neural machine translation (MNMT), we argue\nthat there are still two major challenges in this area: data imbalance and\nrepresentation degeneration. The data imbalance problem refers to the imbalance\nin the amount of parallel corpora for all language pairs, especially for\nlong-tail languages (i.e., very low-resource languages). The representation\ndegeneration problem refers to the problem of encoded tokens tending to appear\nonly in a small subspace of the full space available to the MNMT model. To\nsolve these two issues, we propose Bi-ACL, a framework that uses only\ntarget-side monolingual data and a bilingual dictionary to improve the\nperformance of the MNMT model. We define two modules, named bidirectional\nautoencoder and bidirectional contrastive learning, which we combine with an\nonline constrained beam search and a curriculum learning sampling strategy.\nExtensive experiments show that our proposed method is more effective both in\nlong-tail languages and in high-resource languages. We also demonstrate that\nour approach is capable of transferring knowledge between domains and languages\nin zero-shot scenarios.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:31:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12787","submitter":"Sohei Horibe","authors":"Sohei Horibe, Hiroki Shimizu, Koujiro Hoshi, Takahiko Makiuchi,\n  Tomosato Hioki and Eiji Saitoh","title":"Switching of magnon parametric oscillation by magnetic field direction","comments":"5 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Parametric oscillation occurs when a parameter of an oscillator is\nperiodically modulated. Owing to time-reversal symmetry breaking in magnets,\nnonreciprocal magnons can be parametrically excited when spatial-inversion\nsymmetry breaking is provided. This means that magnons with opposite\npropagation directions have different amplitudes. Here we demonstrate switching\non and off the magnon parametric oscillation by reversing the external field\ndirection applied to a Y$_3$Fe$_5$O$_{12}$ micro-structured film. The result\noriginates from the nonreciprocity of surface mode magnons, leading to\nfield-direction dependence of the magnon accumulation under a nonuniform\nmicrowave pumping. Our numerical calculation well reproduces the experimental\nresult.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:31:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12788","submitter":"Pengcheng Jiang","authors":"Pengcheng Jiang, Cao Xiao, Adam Cross, Jimeng Sun","title":"GraphCare: Enhancing Healthcare Predictions with Open-World Personalized\n  Knowledge Graphs","comments":"22 pages, 8 figures, 7 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Clinical predictive models often rely on patients electronic health records\n(EHR), but integrating medical knowledge to enhance predictions and\ndecision-making is challenging. This is because personalized predictions\nrequire personalized knowledge graphs (KGs), which are difficult to generate\nfrom patient EHR data. To address this, we propose GraphCare, an open-world\nframework that leverages external KGs to improve EHR-based predictions. Our\nmethod extracts knowledge from large language models (LLMs) and external\nbiomedical KGs to generate patient-specific KGs, which are then used to train\nour proposed Bi-attention AugmenTed BAT graph neural network GNN for healthcare\npredictions. We evaluate GraphCare on two public datasets: MIMIC-III and\nMIMIC-IV. Our method outperforms baseline models in four vital healthcare\nprediction tasks: mortality, readmission, length-of-stay, and drug\nrecommendation, improving AUROC on MIMIC-III by average margins of 10.4%, 3.8%,\n2.0%, and 1.5%, respectively. Notably, GraphCare demonstrates a substantial\nedge in scenarios with limited data availability. Our findings highlight the\npotential of using external KGs in healthcare prediction tasks and demonstrate\nthe promise of GraphCare in generating personalized KGs for promoting\npersonalized medicine.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:35:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12789","submitter":"Yuqian Zhang","authors":"Yuqian Zhang, Abhishek Chakrabortty and Jelena Bradic","title":"Semi-Supervised Causal Inference: Generalizable and Double Robust\n  Inference for Average Treatment Effects under Selection Bias with Decaying\n  Overlap","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME math.ST stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Average treatment effect (ATE) estimation is an essential problem in the\ncausal inference literature, which has received significant recent attention,\nespecially with the presence of high-dimensional confounders. We consider the\nATE estimation problem in high dimensions when the observed outcome (or label)\nitself is possibly missing. The labeling indicator's conditional propensity\nscore is allowed to depend on the covariates, and also decay uniformly with\nsample size - thus allowing for the unlabeled data size to grow faster than the\nlabeled data size. Such a setting fills in an important gap in both the\nsemi-supervised (SS) and missing data literatures. We consider a missing at\nrandom (MAR) mechanism that allows selection bias - this is typically forbidden\nin the standard SS literature, and without a positivity condition - this is\ntypically required in the missing data literature. We first propose a general\ndoubly robust 'decaying' MAR (DR-DMAR) SS estimator for the ATE, which is\nconstructed based on flexible (possibly non-parametric) nuisance estimators.\nThe general DR-DMAR SS estimator is shown to be doubly robust, as well as\nasymptotically normal (and efficient) when all the nuisance models are\ncorrectly specified. Additionally, we propose a bias-reduced DR-DMAR SS\nestimator based on (parametric) targeted bias-reducing nuisance estimators\nalong with a special asymmetric cross-fitting strategy. We demonstrate that the\nbias-reduced ATE estimator is asymptotically normal as long as either the\noutcome regression or the propensity score model is correctly specified.\nMoreover, the required sparsity conditions are weaker than all the existing\ndoubly robust causal inference literature even under the regular supervised\nsetting - this is a special degenerate case of our setting. Lastly, this work\nalso contributes to the growing literature on generalizability in causal\ninference.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:37:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12790","submitter":"Mykhailo Osypchuk","authors":"Mykhailo Osypchuk","title":"Bilateral estimates of some pseudo-derivatives of the transition\n  probability density of an isotropic $\\alpha$-stable stochastic process","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the paper, the transition probability density of isotropic $\\alpha$-stable\nstochastic process in a finite dimensional Euclidean space is considered. The\nresults of applying pseudo differential operators with respect spatial\nvariables to this function are estimated from the both side: above and below.\nOperators in the consideration are defined by the symbols $|\\lambda|^\\varkappa$\nand $\\lambda|\\lambda|^{\\varkappa-1}$, where $\\varkappa$ is some constant. The\nfirst operator with negative sign is fractional Laplacian and the second one\nmultiplied by imaginary unit is fractional gradient.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:38:07 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12791","submitter":"Yutaro Ono","authors":"Yutaro Ono, Ryohei Tsuruta, Tomohiro Nobeyama, Kazuki Matsui, Masahiro\n  Sasaki, Makoto Tadokoro, Yasuo Nakayama, and Yoichi Yamada","title":"Partial Hydrogenation of N-heteropentacene: Impact on molecular packing\n  and electronic structure","comments":"27 pages, including supplementary material, 4 figures in the main\n  text, 2 supplementary figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Four-nitrogen-containing 5,6,13,14-Tetraazapentacene (BTANC) has attracted\nattention as a new n-type organic semiconductor with a rigid crystalline phase\ndue to intermolecular CH-N hydrogen bonding. However, in the thin film\ntransistor of BTANC, poor carrier transport properties and low stability in the\nambient condition have been reported so far; thus further refining and\nunderstanding of the thin film of BTANC will be required. Here, by means of\ncarefully-controlled vacuum deposition of BTANC in the narrow window of\ntemperature avoiding impurity sublimation and thermal degradation of molecules,\nwe produced a well-defined monolayer on Cu(111) for molecular-level\ninvestigations. Synchrotron photoemission of the monolayer revealed a\nnoticeable alteration of the chemical state of N atoms, which is unexpected for\nthe pure BTANC molecule. In addition, molecular imaging of the monolayer by\nscanning tunneling microscope (STM) revealed that the molecular packing\nstructure in the monolayer significantly differed from that in the single\ncrystal of BTANC. These observations can be interpreted as a result of the\npartial hydrogenation of N atoms in BTANC and the emergence of the NH-N type\nintermolecular hydrogen bonding in the monolayer. These findings will provide a\ngeneral remark and strategy to control the molecular packing structure and\nelectronic property in the molecular films of the nitrogen-containing acenes,\nby means of controlled hydrogenation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:38:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12792","submitter":"Zhilei Hu","authors":"Zhilei Hu, Zixuan Li, Xiaolong Jin, Long Bai, Saiping Guan, Jiafeng\n  Guo, Xueqi Cheng","title":"Semantic Structure Enhanced Event Causality Identification","comments":"Accepted at ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Event Causality Identification (ECI) aims to identify causal relations\nbetween events in unstructured texts. This is a very challenging task, because\ncausal relations are usually expressed by implicit associations between events.\nExisting methods usually capture such associations by directly modeling the\ntexts with pre-trained language models, which underestimate two kinds of\nsemantic structures vital to the ECI task, namely, event-centric structure and\nevent-associated structure. The former includes important semantic elements\nrelated to the events to describe them more precisely, while the latter\ncontains semantic paths between two events to provide possible supports for\nECI. In this paper, we study the implicit associations between events by\nmodeling the above explicit semantic structures, and propose a Semantic\nStructure Integration model (SemSIn). It utilizes a GNN-based event aggregator\nto integrate the event-centric structure information, and employs an LSTM-based\npath aggregator to capture the event-associated structure information between\ntwo events. Experimental results on three widely used datasets show that SemSIn\nachieves significant improvements over baseline methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:42:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12793","submitter":"Jianfeng He","authors":"Jianfeng He, Julian Salazar, Kaisheng Yao, Haoqi Li, Jinglun Cai","title":"Zero-Shot End-to-End Spoken Language Understanding via Cross-Modal\n  Selective Self-Training","comments":"15 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.MM cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  End-to-end (E2E) spoken language understanding (SLU) is constrained by the\ncost of collecting speech-semantics pairs, especially when label domains\nchange. Hence, we explore \\textit{zero-shot} E2E SLU, which learns E2E SLU\nwithout speech-semantics pairs, instead using only speech-text and\ntext-semantics pairs. Previous work achieved zero-shot by pseudolabeling all\nspeech-text transcripts with a natural language understanding (NLU) model\nlearned on text-semantics corpora. However, this method requires the domains of\nspeech-text and text-semantics to match, which often mismatch due to separate\ncollections. Furthermore, using the entire speech-text corpus from any domains\nleads to \\textit{imbalance} and \\textit{noise} issues. To address these, we\npropose \\textit{cross-modal selective self-training} (CMSST). CMSST tackles\nimbalance by clustering in a joint space of the three modalities (speech, text,\nand semantics) and handles label noise with a selection network. We also\nintroduce two benchmarks for zero-shot E2E SLU, covering matched and found\nspeech (mismatched) settings. Experiments show that CMSST improves performance\nin both two settings, with significantly reduced sample sizes and training\ntime.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:42:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12794","submitter":"Hadi Ghasemi","authors":"Hadi Ghasemi and Tayebe Lal Shateri","title":"On perturbation of continuous frames in Hilbert C*-modules","comments":"arXiv admin note: text overlap with arXiv:2302.13554,\n  arXiv:2208.06799","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In the present paper, we examine the perturbation of continuous frames and\nRiesz-type frames in Hilbert $C^*$-modules. We extend the Casazza-Christensen\ngeneral perturbation theorem for Hilbert space frames to continuous frames in\nHilbert $C^*$-modules. We obtain a necessary condition under which the\nperturbation of a Riesz-type frame of Hilbert $C^*$-modules remains to be a\nRiesz-type frame. Also, we examine the effect of duality on the perturbation of\ncontinuous frames in Hilbert $C^*$-modules, and we prove if the operator frame\nof a continuous frame $F$ is near to the combination of the synthesis operator\nof a continuous Bessel mapping $G$ and the analysis operator of $F$, then $G$\nis a continuous frame.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:44:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12795","submitter":"Zirui Xu","authors":"Zirui Xu, Xiaofeng Lin, Vasileios Tzoumas","title":"Bandit Submodular Maximization for Multi-Robot Coordination in\n  Unpredictable and Partially Observable Environments","comments":"Accepted to RSS 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.AI cs.MA cs.RO cs.SY math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the problem of multi-agent coordination in unpredictable and\npartially observable environments, that is, environments whose future evolution\nis unknown a priori and that can only be partially observed. We are motivated\nby the future of autonomy that involves multiple robots coordinating actions in\ndynamic, unstructured, and partially observable environments to complete\ncomplex tasks such as target tracking, environmental mapping, and area\nmonitoring. Such tasks are often modeled as submodular maximization\ncoordination problems due to the information overlap among the robots. We\nintroduce the first submodular coordination algorithm with bandit feedback and\nbounded tracking regret -- bandit feedback is the robots' ability to compute in\nhindsight only the effect of their chosen actions, instead of all the\nalternative actions that they could have chosen instead, due to the partial\nobservability; and tracking regret is the algorithm's suboptimality with\nrespect to the optimal time-varying actions that fully know the future a\npriori. The bound gracefully degrades with the environments' capacity to change\nadversarially, quantifying how often the robots should re-select actions to\nlearn to coordinate as if they fully knew the future a priori. The algorithm\ngeneralizes the seminal Sequential Greedy algorithm by Fisher et al. to the\nbandit setting, by leveraging submodularity and algorithms for the problem of\ntracking the best action. We validate our algorithm in simulated scenarios of\nmulti-target tracking.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:44:54 GMT"},{"version":"v2","created":"Fri, 26 May 2023 09:22:54 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12796","submitter":"Nan Li","authors":"Nan Li, Mehdi Bennis, Alexandros Iosifidis and Qi Zhang","title":"Spatiotemporal Attention-based Semantic Compression for Real-time Video\n  Recognition","comments":"Submitted to IEEE Globecom 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.NI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the computational offloading of video action recognition\nin edge computing. To achieve effective semantic information extraction and\ncompression, following semantic communication we propose a novel spatiotemporal\nattention-based autoencoder (STAE) architecture, including a frame attention\nmodule and a spatial attention module, to evaluate the importance of frames and\npixels in each frame. Additionally, we use entropy encoding to remove\nstatistical redundancy in the compressed data to further reduce communication\noverhead. At the receiver, we develop a lightweight decoder that leverages a\n3D-2D CNN combined architecture to reconstruct missing information by\nsimultaneously learning temporal and spatial information from the received data\nto improve accuracy. To fasten convergence, we use a step-by-step approach to\ntrain the resulting STAE-based vision transformer (ViT_STAE) models.\nExperimental results show that ViT_STAE can compress the video dataset HMDB51\nby 104x with only 5% accuracy loss, outperforming the state-of-the-art baseline\nDeepISC. The proposed ViT_STAE achieves faster inference and higher accuracy\nthan the DeepISC-based ViT model under time-varying wireless channel, which\nhighlights the effectiveness of STAE in guaranteeing higher accuracy under time\nconstraints.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:47:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12797","submitter":"Seyed Reza Seyednejad","authors":"Seyed Reza Seyednejad, Saeedeh Shoarinejad, Mohammad Reza Mozaffari,\n  Faezeh Amini Joneghani","title":"Thin Pyramidal Cones in Nematic Liquid Crystal","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The present study investigates the arrangement of hollow pyramidal cone\nshells and their interactions with degenerate planar anchoring on the inner and\nouter surfaces of particles within the nematic host. The shell thickness is in\norder of the nematic coherence length. The numerical behavior of colloids is\ndetermined by minimizing the Landau-de Gennes free energy in the presence of\nthe Fournier surface energy and using the finite element method. Colloidal\npyramidal cones can orient parallel and perpendicular with the far director\norientation. In the parallel alignment, we found the splay director distortion\ninto the pyramid with two boojum defects at the inner and outer tips. The\ndirector shows bending distortion without defect patterns when the pyramid is\naligned perpendicularly. They induce long-range dipolar interaction and can\nform nested structures in close contact.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:51:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12798","submitter":"Chi Han","authors":"Chi Han, Jialiang Xu, Manling Li, Yi Fung, Chenkai Sun, Nan Jiang,\n  Tarek Abdelzaher, Heng Ji","title":"LM-Switch: Lightweight Language Model Conditioning in Word Embedding\n  Space","comments":"9 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In recent years, large language models (LMs) have achieved remarkable\nprogress across various natural language processing tasks. As pre-training and\nfine-tuning are costly and might negatively impact model performance, it is\ndesired to efficiently adapt an existing model to different conditions such as\nstyles, sentiments or narratives, when facing different audiences or scenarios.\nHowever, efficient adaptation of a language model to diverse conditions remains\nan open challenge. This work is inspired by the observation that text\nconditions are often associated with selection of certain words in a context.\nTherefore we introduce LM-Switch, a theoretically grounded, lightweight and\nsimple method for generative language model conditioning. We begin by\ninvestigating the effect of conditions in Hidden Markov Models (HMMs), and\nestablish a theoretical connection with language model. Our finding suggests\nthat condition shifts in HMMs are associated with linear transformations in\nword embeddings. LM-Switch is then designed to deploy a learnable linear factor\nin the word embedding space for language model conditioning. We show that\nLM-Switch can model diverse tasks, and achieves comparable or better\nperformance compared with state-of-the-art baselines in LM detoxification and\ngeneration control, despite requiring no more than 1% of parameters compared\nwith baselines and little extra time overhead compared with base LMs. It is\nalso able to learn from as few as a few sentences or one document. Moreover, a\nlearned LM-Switch can be transferred to other LMs of different sizes, achieving\na detoxification performance similar to the best baseline. We will make our\ncode available to the research community following publication.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:52:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12799","submitter":"Qifan Yu","authors":"Qifan Yu, Juncheng Li, Wentao Ye, Siliang Tang, Yueting Zhuang","title":"Interactive Data Synthesis for Systematic Vision Adaptation via\n  LLMs-AIGCs Collaboration","comments":"11 pages, 6 figures, technical report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent text-to-image generation models have shown promising results in\ngenerating high-fidelity photo-realistic images. In parallel, the problem of\ndata scarcity has brought a growing interest in employing AIGC technology for\nhigh-quality data expansion. However, this paradigm requires well-designed\nprompt engineering that cost-less data expansion and labeling remain\nunder-explored. Inspired by LLM's powerful capability in task guidance, we\npropose a new paradigm of annotated data expansion named as ChatGenImage. The\ncore idea behind it is to leverage the complementary strengths of diverse\nmodels to establish a highly effective and user-friendly pipeline for\ninteractive data augmentation. In this work, we extensively study how LLMs\ncommunicate with AIGC model to achieve more controllable image generation and\nmake the first attempt to collaborate them for automatic data augmentation for\na variety of downstream tasks. Finally, we present fascinating results obtained\nfrom our ChatGenImage framework and demonstrate the powerful potential of our\nsynthetic data for systematic vision adaptation. Our codes are available at\nhttps://github.com/Yuqifan1117/Labal-Anything-Pipeline.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:53:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12800","submitter":"Yachun Li","authors":"Yachun Li, Jingjing Wang, Yuhui Chen, Di Xie, Shiliang Pu","title":"Single Domain Dynamic Generalization for Iris Presentation Attack\n  Detection","comments":"ICASSP 2023 Camera Ready","journal-ref":null,"doi":"10.1109/ICASSP49357.2023.10095424","report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Iris presentation attack detection (PAD) has achieved great success under\nintra-domain settings but easily degrades on unseen domains. Conventional\ndomain generalization methods mitigate the gap by learning domain-invariant\nfeatures. However, they ignore the discriminative information in the\ndomain-specific features. Moreover, we usually face a more realistic scenario\nwith only one single domain available for training. To tackle the above issues,\nwe propose a Single Domain Dynamic Generalization (SDDG) framework, which\nsimultaneously exploits domain-invariant and domain-specific features on a\nper-sample basis and learns to generalize to various unseen domains with\nnumerous natural images. Specifically, a dynamic block is designed to\nadaptively adjust the network with a dynamic adaptor. And an information\nmaximization loss is further combined to increase diversity. The whole network\nis integrated into the meta-learning paradigm. We generate amplitude perturbed\nimages and cover diverse domains with natural images. Therefore, the network\ncan learn to generalize to the perturbed domains in the meta-test phase.\nExtensive experiments show the proposed method is effective and outperforms the\nstate-of-the-art on LivDet-Iris 2017 dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:54:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12801","submitter":"Oliver Lorscheid","authors":"Oliver Lorscheid and Samarpita Ray","title":"The topological shadow of F1-geometry: congruence spaces","comments":"52 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we introduce congruence spaces, which are topological spaces\nthat are canonically attached to monoid schemes and that reflect closed\ntopological properties. This leads to satisfactory topological\ncharacterizations of closed morphisms and closed immersions as well as\nseparated and proper morphisms. We study congruence spaces thoroughly and\nextend standard results from usual scheme theory to monoid schemes: a closed\nimmersion is the same as an affine morphism for which the pullback of sections\nis surjective; a morphism is separated if and only if the image of the diagonal\nis a closed subset of the congruence space; a valuative criterion for separated\nand proper morphisms.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:57:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12802","submitter":"Zied Bouraoui","authors":"Na Li, Zied Bouraoui, Steven Schockaert","title":"Ultra-Fine Entity Typing with Prior Knowledge about Labels: A Simple\n  Clustering Based Strategy","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Ultra-fine entity typing (UFET) is the task of inferring the semantic types,\nfrom a large set of fine-grained candidates, that apply to a given entity\nmention. This task is especially challenging because we only have a small\nnumber of training examples for many of the types, even with distant\nsupervision strategies. State-of-the-art models, therefore, have to rely on\nprior knowledge about the type labels in some way. In this paper, we show that\nthe performance of existing methods can be improved using a simple technique:\nwe use pre-trained label embeddings to cluster the labels into semantic domains\nand then treat these domains as additional types. We show that this strategy\nconsistently leads to improved results, as long as high-quality label\nembeddings are used. We furthermore use the label clusters as part of a simple\npost-processing technique, which results in further performance gains. Both\nstrategies treat the UFET model as a black box and can thus straightforwardly\nbe used to improve a wide range of existing models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:00:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12803","submitter":"Attila Jo\\'o","authors":"Attila Jo\\'o","title":"Finite matchability under the matroidal Hall's condition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Aharoni and Ziv conjectured that if $ M $ and $ N $ are finitary matroids on\n$ E $, then a certain ``Hall-like'' condition is sufficient to guarantee the\nexistence of an $ M $-independent spanning set of $ N $. We show that their\ncondition ensures that every finite subset of $ E $ is $ N $-spanned by an $ M\n$-independent set.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:01:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12804","submitter":"Lingwei Meng","authors":"Haibin Wu, Jiawen Kang, Lingwei Meng, Helen Meng and Hung-yi Lee","title":"The defender's perspective on automatic speaker verification: An\n  overview","comments":"Submitted to IJCAI 2023 Workshop","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automatic speaker verification (ASV) plays a critical role in\nsecurity-sensitive environments. Regrettably, the reliability of ASV has been\nundermined by the emergence of spoofing attacks, such as replay and synthetic\nspeech, as well as adversarial attacks and the relatively new partially fake\nspeech. While there are several review papers that cover replay and synthetic\nspeech, and adversarial attacks, there is a notable gap in a comprehensive\nreview that addresses defense against adversarial attacks and the recently\nemerged partially fake speech. Thus, the aim of this paper is to provide a\nthorough and systematic overview of the defense methods used against these\ntypes of attacks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:01:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12805","submitter":"Xiaotong Zhao","authors":"Xiaotong Zhao, Mian Li, Bo Wang, Enbin Song, Tsung-Hui Chang, and\n  Qingjiang Shi","title":"Decentralized Equalization for Massive MIMO Systems With Colored Noise\n  Samples","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, the decentralized baseband processing (DBP) paradigm and relevant\ndetection methods have been proposed to enable extremely large-scale massive\nmultiple-input multiple-output technology. Under the DBP architecture, base\nstation antennas are divided into several independent clusters, each connected\nto a local computing fabric. However, current detection methods tailored to DBP\nonly consider ideal white Gaussian noise scenarios, while in practice, the\nnoise is often colored due to interference from neighboring cells. Moreover, in\nthe DBP architecture, linear minimum mean-square error (LMMSE) detection\nmethods rely on the estimation of the noise covariance matrix through averaging\ndistributedly stored noise samples. This presents a significant challenge for\ndecentralized LMMSE-based equalizer design. To address this issue, this paper\nproposes decentralized LMMSE equalization methods under colored noise scenarios\nfor both star and daisy chain DBP architectures. Specifically, we first propose\ntwo decentralized equalizers for the star DBP architecture based on\ndimensionality reduction techniques. Then, we derive an optimal decentralized\nequalizer using the block coordinate descent (BCD) method for the daisy chain\nDBP architecture with a bandwidth reduction enhancement scheme based on\ndecentralized low-rank decomposition. Finally, simulation results demonstrate\nthat our proposed methods can achieve excellent detection performance while\nrequiring much less communication bandwidth.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:03:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12806","submitter":"Long-Ke Li","authors":"Belle Collaboration: L. K. Li, A. J. Schwartz, E. Won, K. Kinoshita,\n  I. Adachi, H. Aihara, S. Al Said, D. M. Asner, V. Aulchenko, T. Aushev, V.\n  Babu, Sw. Banerjee, P. Behera, K. Belous, J. Bennett, M. Bessner, T. Bilka,\n  D. Biswas, A. Bobrov, D. Bodrov, G. Bonvicini, J. Borah, M. Bra\\v{c}ko, P.\n  Branchini, A. Budano, D. \\v{C}ervenkov, M.-C. Chang, B. G. Cheon, H. E. Cho,\n  K. Cho, S.-K. Choi, Y. Choi, S. Choudhury, D. Cinabro, J. Cochran, S. Das, G.\n  De Nardo, G. De Pietro, R. Dhamija, F. Di Capua, J. Dingfelder, Z.\n  Dole\\v{z}al, T. V. Dong, S. Dubey, D. Epifanov, A. Frey, B. G. Fulsom, V.\n  Gaur, A. Giri, P. Goldenzweig, G. Gong, E. Graziani, D. Greenwald, T. Gu, Y.\n  Guan, K. Gudkova, C. Hadjivasiliou, T. Hara, K. Hayasaka, H. Hayashii, D.\n  Herrmann, W.-S. Hou, C.-L. Hsu, N. Ipsita, A. Ishikawa, R. Itoh, M. Iwasaki,\n  W. W. Jacobs, E.-J. Jang, Q. P. Ji, S. Jia, Y. Jin, K. K. Joo, J. Kahn, A. B.\n  Kaliyar, C. Kiesling, C. H. Kim, D. Y. Kim, K.-H. Kim, Y. J. Kim, Y.-K. Kim,\n  H. Kindo, P. Kody\\v{s}, A. Korobov, S. Korpar, E. Kovalenko, P. Kri\\v{z}an,\n  P. Krokovny, M. Kumar, R. Kumar, K. Kumara, Y.-J. Kwon, Y. T. Lai, T. Lam, S.\n  C. Lee, Y. Li, J. Libby, K. Lieret, Y.-R. Lin, D. Liventsev, Y. Ma, M.\n  Masuda, T. Matsuda, D. Matvienko, S. K. Maurya, F. Meier, M. Merola, F.\n  Metzner, R. Mizuk, G. B. Mohanty, M. Nakao, D. Narwal, Z. Natkaniec, A.\n  Natochii, L. Nayak, N. K. Nisar, S. Nishida, S. Ogawa, H. Ono, P. Oskin, G.\n  Pakhlova, S. Pardi, H. Park, J. Park, S.-H. Park, A. Passeri, S. Patra, S.\n  Paul, R. Pestotnik, L. E. Piilonen, T. Podobnik, E. Prencipe, M. T. Prim, G.\n  Russo, S. Sandilya, A. Sangal, L. Santelj, V. Savinov, G. Schnell, C.\n  Schwanda, Y. Seino, M. E. Sevior, W. Shan, M. Shapkin, C. Sharma, J.-G. Shiu,\n  B. Shwartz, E. Solovieva, M. Stari\\v{c}, Z. S. Stottler, M. Sumihama, M.\n  Takizawa, K. Tanida, F. Tenchini, M. Uchida, T. Uglov, Y. Unno, K. Uno, S.\n  Uno, G. Varner, K. E. Varvell, A. Vinokurova, D. Wang, E. Wang, X. L. Wang,\n  S. Watanuki, O. Werbycka, X. Xu, B. D. Yabsley, W. Yan, S. B. Yang, J. H.\n  Yin, Y. Yook, Z. P. Zhang, V. Zhilich, V. Zhukova","title":"Search for $C\\!P$ violation using $T$-odd correlations in\n  $D_{(s)}^{+}\\to K^{+} K^{-}\\pi^{+}\\pi^{0}$, $D_{(s)}^{+}\\to K^{+}\n  \\pi^{-}\\pi^{+}\\pi^{0}$, and $D^{+}\\to K^{-}\\pi^{+}\\pi^{+}\\pi^{0}$ decays","comments":"10 pages, 5 figures","journal-ref":null,"doi":null,"report-no":"Belle Preprint 2023-07, KEK Preprint 2023-3, UCHEP-23-02","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We search for $C\\!P$ violation using $T$-odd correlations in five\n$D_{(s)}^{+}$ and $D_{(s)}^{-}$ four-body decays. Our analysis is based on 980\n$\\rm fb^{-1}$ of data collected by the Belle detector at the KEKB\nenergy-asymmetric $e^+e^-$ collider. Our results for the $T$-odd\n$C\\!P$-violating parameter $a^{T\\text{-odd}}_{C\\!P}$ are:\n$a^{T\\text{-odd}}_{C\\!P}({D^{+}\\to K^{-}K^{+}\\pi^{+}\\pi^{0}}) = (+2.6\\pm 6.6\\pm\n1.3 )\\times10^{-3}$, $a^{T\\text{-odd}}_{C\\!P}({D^{+}\\to\nK^{+}\\pi^{-}\\pi^{+}\\pi^{0}}) = (-1.3\\pm 4.2\\pm 0.1 )\\times10^{-2}$,\n$a^{T\\text{-odd}}_{C\\!P}({D^{+}\\to K^{-}\\pi^{+}\\pi^{+}\\pi^{0}}) = (+0.2\\pm\n1.5\\pm 0.8 )\\times10^{-3}$, $a^{T\\text{-odd}}_{C\\!P}({D_s^{+}\\to\nK^{+}\\pi^{-}\\pi^{+}\\pi^{0}}) = (-1.1\\pm 2.2\\pm 0.1 )\\times10^{-2}$, and\n$a^{T\\text{-odd}}_{C\\!P}({D_s^{+}\\to K^{-}K^{+}\\pi^{+}\\pi^{0}}) = (+2.2\\pm\n3.3\\pm 4.3 )\\times10^{-3}$, where the uncertainties are statistical and\nsystematic, respectively. These results are the first such measurements and are\nall consistent with zero. They include the first measurement for a $D^+_s$\nsingly Cabibbo-suppressed decay, and the first measurement for a $D$ meson\ndoubly Cabibbo-suppressed decay. We also measure $a^{T\\text{-odd}}_{C\\!P}$ in\ndifferent subregions of phase space, where the decays are dominated by\ndifferent intermediate resonance states such as $D^+\\to\\phi\\rho^+$,\n$\\bar{K}^{*0}K^{*+}$, and $\\bar{K}^{*0}\\rho^+$; and $D_s^+\\to K^{*+}\\rho^{0}$,\n$K^{*0}\\rho^{+}$, $\\phi\\rho^+$, and $\\bar{K}^{*0}K^{*+}$. No evidence for\n$C\\!P$ violation is found.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:08:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12807","submitter":"Bo Liu","authors":"Peng Li and Bo Liu","title":"Multi-task Combinatorial Optimization: Adaptive Multi-modality Knowledge\n  Transfer by an Explicit Inter-task Distance","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Scheduling problems are often tackled independently, and rarely solved by\nleveraging the commonalities across problems. Lack of awareness of this\ninter-task similarity could impede the search efficacy. A quantifiable\nrelationship between scheduling problems is to-date rather unclear, how to\nleverage it in combinatorial optimization remains largely unknown, and its\neffects on search are also undeterminable. This paper addresses these hard\nquestions by delving into quantifiable useful inter-task relationships and,\nthrough leveraging the explicit relationship, presenting a speed-up algorithm.\nAfter deriving an analytical inter-task distance metric to quantitatively\nreveal latent similarity across scheduling problems, an adaptive transfer of\nmulti-modality knowledge is devised to promptly adjust the transfer in forms of\nexplicit and implicit knowledge in response to heterogeneity in the inter-task\ndiscrepancy. For faintly related problems with disappearing dependences, a\nproblem transformation function is suggested with a matching-feature-based\ngreedy policy, and the function projects faintly related problems into a latent\nspace where these problems gain similarity in a way that creates search\nspeed-ups. Finally, a multi-task scatter search combinatorial algorithm is\nformed and a large-scale multi-task benchmark is generated serving the purposes\nof validation. That the algorithm exhibits dramatic speed-ups of 2~3 orders of\nmagnitude, as compared to direct problem solving in strongly related problems\nand 3 times faster in weakly related ones, suggests leveraging commonality\nacross problems could be successful.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:08:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12808","submitter":"Christoph Krieger","authors":"E. Garutti and H. Janssen and D. Kreikemeyer-Lorenzo and C. Krieger\n  and A. Lindner and B. Majorovits and J. Schaffran and B. van Bree","title":"Qualification of piezo-electric actuators for the MADMAX booster system\n  at cryogenic temperatures and high magnetic fields","comments":"13 pages, 9 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report on the qualification of a piezo-based linear stage for the\nmanipulation of positions of dielectric discs in the booster of the MADMAX\naxion dark matter search experiment. A first demonstrator of the piezo drives,\nspecifically developed for MADMAX, was tested at room temperature as well as at\ncryogenic temperatures down to 4.5 K and inside strong magnetic fields up to\n5.3 T. These qualification measurements prove that the piezo-based linear stage\nis suited for MADMAX and fulfills the requirements.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:10:10 GMT"},{"version":"v2","created":"Tue, 23 May 2023 07:49:51 GMT"},{"version":"v3","created":"Tue, 30 May 2023 07:54:15 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.12809","submitter":"Jinghan Yang","authors":"Jinghan Yang, Lequan Yu","title":"Relabel Minimal Training Subset to Flip a Prediction","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Yang et al. (2023) discovered that removing a mere 1% of training points can\noften lead to the flipping of a prediction. Given the prevalence of noisy data\nin machine learning models, we pose the question: can we also result in the\nflipping of a test prediction by relabeling a small subset of the training data\nbefore the model is trained? In this paper, utilizing the extended influence\nfunction, we propose an efficient procedure for identifying and relabeling such\na subset, demonstrating consistent success. This mechanism serves multiple\npurposes: (1) providing a complementary approach to challenge model predictions\nby recovering potentially mislabeled training points; (2) evaluating model\nresilience, as our research uncovers a significant relationship between the\nsubset's size and the ratio of noisy data in the training set; and (3) offering\ninsights into bias within the training set. To the best of our knowledge, this\nwork represents the first investigation into the problem of identifying and\nrelabeling the minimal training subset required to flip a given prediction.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:10:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12810","submitter":"Benoit Coasne Dr.","authors":"Wanda Kellouai, Jean-Louis Barrat, Patrick Judeinstein, Marie\n  Plazanet, Benoit Coasne","title":"On De Gennes Narrowing of Fluids Confined at the Molecular Scale in\n  Nanoporous Materials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Beyond well-documented confinement and surface effects arising from the large\ninternal surface and severely confining porosity of nanoporous hosts, the\ntransport of nanoconfined fluids remains puzzling by many aspects. With\nstriking examples such as memory, \\textit{i.e.} non-viscous, effects,\nintermittent dynamics and surface barriers, the dynamics of fluids in\nnanoconfinement challenges classical formalisms (\\textit{e.g.} random walk,\nviscous/advective transport) -- especially for molecular pore sizes. In this\ncontext, while molecular frameworks such as intermittent brownian motion, free\nvolume theory and surface diffusion are available to describe the\nself-diffusion of a molecularly confined fluid, a microscopic theory for the\ncollective diffusion (\\textit{i.e.} permeability) -- which characterizes the\nflow induced by a thermodynamic gradient -- is lacking. Here, to fill this\nknowledge gap, we invoke the concept of `De Gennes narrowing' which relates the\nwavevector-dependent collective diffusivity $D_0(q)$ to the fluid structure\nfactor $S(q)$. First, using molecular simulation for a simple yet\nrepresentative fluid confined in a prototypical solid (zeolite), we unravel an\nessential coupling between the wavevector-dependent collective diffusivity and\nthe structural ordering imposed on the fluid by the crystalline nanoporous\nhost. Second, despite this complex interplay with marked Bragg peaks in the\nfluid structure, the fluid collective dynamics is shown to be accurately\ndescribed through De Gennes narrowing. Moreover, in contrast to the bulk fluid,\ndeparture from De Gennes narrowing for the confined fluid in the macroscopic\nlimit remains small as the fluid/solid interactions in severe confinement\nscreen collective effects and, hence, weaken the wavevector dependence of\ncollective transport.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:11:56 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 19:59:41 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.12811","submitter":"Lars Schmarje","authors":"Lars Schmarje, Vasco Grossmann, Tim Michels, Jakob Nazarenus, Monty\n  Santarossa, Claudius Zelenka, Reinhard Koch","title":"Label Smarter, Not Harder: CleverLabel for Faster Annotation of\n  Ambiguous Image Classification with Higher Quality","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  High-quality data is crucial for the success of machine learning, but\nlabeling large datasets is often a time-consuming and costly process. While\nsemi-supervised learning can help mitigate the need for labeled data, label\nquality remains an open issue due to ambiguity and disagreement among\nannotators. Thus, we use proposal-guided annotations as one option which leads\nto more consistency between annotators. However, proposing a label increases\nthe probability of the annotators deciding in favor of this specific label.\nThis introduces a bias which we can simulate and remove. We propose a new\nmethod CleverLabel for Cost-effective LabEling using Validated proposal-guidEd\nannotations and Repaired LABELs. CleverLabel can reduce labeling costs by up to\n30.0%, while achieving a relative improvement in Kullback-Leibler divergence of\nup to 29.8% compared to the previous state-of-the-art on a multi-domain\nreal-world image classification benchmark. CleverLabel offers a novel solution\nto the challenge of efficiently labeling large datasets while also improving\nthe label quality.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:12:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12812","submitter":"Koya Murakami","authors":"Koya Murakami, Indira Ocampo, Savvas Nesseris, Atsushi J. Nishizawa,\n  Sachiko Kuroyanagi","title":"Non-Linearity-Free prediction of the growth-rate $f\\sigma_8$ using\n  Convolutional Neural Networks","comments":"25 pages, 8 figures","journal-ref":null,"doi":null,"report-no":"IFT-UAM/CSIC-23-57","categories":"astro-ph.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The growth-rate $f\\sigma_8(z)$ of the large-scale structure of the Universe\nis an important dynamic probe of gravity that can be used to test for\ndeviations from General Relativity. However, in order for galaxy surveys to\nextract this key quantity from cosmological observations, two important\nassumptions have to be made: i) a fiducial cosmological model, typically taken\nto be the cosmological constant and cold dark matter ($\\Lambda$CDM) model and\nii) the modeling of the observed power spectrum from H$\\alpha$ emitters,\nespecially at non-linear scales, which is particularly dangerous as most models\nused in the literature are phenomenological at best. In this work, we propose a\nnovel approach involving convolutional neural networks (CNNs), trained on the\nQuijote N-body simulations, to predict $f\\sigma_8(z)$ directly and without\nassuming a model for the non-linear part of the power spectrum, thus avoiding\nthe second of the aforementioned assumptions. We find that the predictions for\nthe value of $f\\sigma_8$ from the CNN are in excellent agreement with the\nfiducial values, while the errors are within a factor of order unity from those\nof the traditionally optimistic Fisher matrix approach, assuming an ideal\nfiducial survey matching the specifications of the Quijote simulations. Thus,\nwe find the CNN reconstructions provide a viable alternative in order to avoid\nthe theoretical modeling of the non-linearities at small scales when extracting\nthe growth-rate.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:13:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12813","submitter":"Matteo Tacchi","authors":"Yingzhao Lian, Matteo Tacchi, Colin Jones","title":"Robust data-driven Lyapunov analysis with fixed data","comments":"32 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this era of digitalization, data has widely been used in control\nengineering. While stability analysis is a mainstay for control science, most\nstability analysis tools still require explicit knowledge of the model or a\nhigh-fidelity simulator. In this work, a new data-driven Lyapunov analysis\nframework is proposed. Without using the model or its simulator, the proposed\napproach can learn a piece-wise affine Lyapunov function with a finite and\nfixed off-line dataset. The learnt Lyapunov function is robust to any dynamics\nthat are consistent with the off-line dataset. Along the development of\nproposed scheme, the Lyapunov stability criterion is generalized. This\ngeneralization enables an iterative algorithm to augment the region of\nattraction.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:13:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12814","submitter":"Juergen Reuter","authors":"J\\\"urgen Reuter","title":"Precision test of the muon-Higgs coupling at a high-energy muon collider","comments":"Contribution to Corfu Summer Institute 2022 \"School and Workshops on\n  Elementary Particle Physics and Gravity\"","journal-ref":null,"doi":null,"report-no":"DESY-23-058","categories":"hep-ph","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Muon colliders offer the possibility to go to very high energies with\nrelatively small circular colliders, energies up to 10 or 14 TeV are\nenvisioned. Due to their very clean collider environment they provide a\nfantastic tool to search for new physics in the electroweak sector, especially\nthrough the production of multiple EW vector and Higgs bosons, and they allow\nto measure the Higgs-muon coupling very precisely. I will elucidate the physics\ncapabilities from these processes and also discuss issues on precision\npredictions for SM backgrounds at high-energy lepton colliders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:16:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12815","submitter":"Ashish Sharma","authors":"Ashish Sharma, Sudha Rao, Chris Brockett, Akanksha Malhotra, Nebojsa\n  Jojic, Bill Dolan","title":"Towards Dialogue Systems with Agency in Human-AI Collaboration Tasks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Agency, the capacity to proactively shape events, is crucial to how humans\ninteract and collaborate with other humans. In this paper, we investigate\nAgency as a potentially desirable function of dialogue agents, and how it can\nbe measured and controlled. We build upon the social-cognitive theory of\nBandura (2001) to develop a framework of features through which Agency is\nexpressed in dialogue -- indicating what you intend to do (Intentionality),\nmotivating your intentions (Motivation), having self-belief in intentions\n(Self-Efficacy), and being able to self-adjust (Self-Regulation). We collect\nand release a new dataset of 83 human-human collaborative interior design\nconversations containing 908 conversational snippets annotated for Agency\nfeatures. Using this dataset, we explore methods for measuring and controlling\nAgency in dialogue systems. Automatic and human evaluation show that although a\nbaseline GPT-3 model can express Intentionality, models that explicitly\nmanifest features associated with high Motivation, Self-Efficacy, and\nSelf-Regulation are better perceived as being highly agentive. This work has\nimplications for the development of dialogue systems with varying degrees of\nAgency in collaborative tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:17:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12816","submitter":"Xiao Wang","authors":"Xiao Wang, Weikang Zhou, Qi Zhang, Jie Zhou, Songyang Gao, Junzhe\n  Wang, Menghan Zhang, Xiang Gao, Yunwen Chen, Tao Gui","title":"Farewell to Aimless Large-scale Pretraining: Influential Subset\n  Selection for Language Model","comments":"Accepted by ACL2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pretrained language models have achieved remarkable success in various\nnatural language processing tasks. However, pretraining has recently shifted\ntoward larger models and larger data, and this has resulted in significant\ncomputational and energy costs. In this paper, we propose Influence Subset\nSelection (ISS) for language model, which explicitly utilizes end-task\nknowledge to select a tiny subset of the pretraining corpus. Specifically, the\nISS selects the samples that will provide the most positive influence on the\nperformance of the end-task. Furthermore, we design a gradient matching based\ninfluence estimation method, which can drastically reduce the computation time\nof influence. With only 0.45% of the data and a three-orders-of-magnitude lower\ncomputational cost, ISS outperformed pretrained models (e.g., RoBERTa) on eight\ndatasets covering four domains.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:18:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12817","submitter":"Yu-Shuo Chen","authors":"Reyna Quita, Yu-Shuo Chen, Hsin-Yi Lee Alex C. Hu, John M. Hong","title":"Conservative Physics-Informed Neural Networks for Non-Conservative\n  Hyperbolic Conservation Laws Near Critical States","comments":"23 pages, 26 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, a modified version of conservative Physics-informed Neural\nNetworks (cPINN for short) is provided to construct the weak solutions of\nRiemann problem for the hyperbolic scalar conservation laws in non-conservative\nform. To demonstrate the results, we use the model of generalized\nBuckley-Leverett equation (GBL equation for short) with discontinuous porosity\nin porous media. By inventing a new unknown, the GBL equation is transformed\ninto a two-by-two resonant hyperbolic conservation laws in conservative form.\nThe modified method of cPINN is invented to overcome the difficulties due to\nthe discontinuity of the porosity and the appearance of the critical states\n(near vacuum) in the Riemann data. We experiment with our idea by using a deep\nlearning algorithm to solve the GBL equation in both conservative and\nnon-conservative forms, as well as the cases of critical and non-critical\nstates. This method provides a combination of two different neural networks and\ncorresponding loss functions, one is for the two-by-two resonant hyperbolic\nsystem, and the other is for the scalar conservation law with a discontinuous\nperturbation term in the non-convex flux. The technique of re-scaling to the\nunknowns is adopted to avoid the oscillation of the Riemann solutions in the\ncases of critical Riemann data. The solutions constructed by the modified cPINN\nmatch the exact solutions constructed by the theoretical analysis for\nhyperbolic conservation laws. In addition, the solutions are identical in both\nconservative and non-conservative cases. Finally, we compare the performance of\nthe modified cPINN with numerical method called WENO5. Whereas WENO5 struggles\nwith the highly oscillation of approximate solutions for the Riemann problems\nof GBL equation in non-conservative form, cPINN works admirably.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:19:00 GMT"},{"version":"v2","created":"Tue, 23 May 2023 00:50:15 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12818","submitter":"Yihong Liu","authors":"Yihong Liu, Haotian Ye, Leonie Weissweiler, Hinrich Sch\\\"utze","title":"Crosslingual Transfer Learning for Low-Resource Languages Based on\n  Multilingual Colexification Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Colexification in comparative linguistics refers to the phenomenon of a\nlexical form conveying two or more distinct meanings. In this paper, we propose\nsimple and effective methods to build multilingual graphs from colexification\npatterns: ColexNet and ColexNet+. ColexNet's nodes are concepts and its edges\nare colexifications. In ColexNet+, concept nodes are in addition linked through\nintermediate nodes, each representing an ngram in one of 1,334 languages. We\nuse ColexNet+ to train high-quality multilingual embeddings\n$\\overrightarrow{\\mbox{ColexNet+}}$ that are well-suited for transfer learning\nscenarios. Existing work on colexification patterns relies on annotated word\nlists. This limits scalability and usefulness in NLP. In contrast, we identify\ncolexification patterns of more than 2,000 concepts across 1,335 languages\ndirectly from an unannotated parallel corpus. In our experiments, we first show\nthat ColexNet has a high recall on CLICS, a dataset of crosslingual\ncolexifications. We then evaluate $\\overrightarrow{\\mbox{ColexNet+}}$ on\nroundtrip translation, verse retrieval and verse classification and show that\nour embeddings surpass several baselines in a transfer learning setting. This\ndemonstrates the benefits of colexification for multilingual NLP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:20:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12819","submitter":"Leandros Perivolaropoulos","authors":"Leandros Perivolaropoulos","title":"On the isotropy of SnIa absolute magnitudes in the Pantheon+ and SH0ES\n  samples","comments":"11 pages, 9 Figures, 2 Tables. The Mathematica v13 files used for the\n  construction of the figures of the analysis may be downloaded from\n  https://github.com/leandros11/anisotropy","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We use the hemisphere comparison method to test the isotropy of the SnIa\nabsolute magnitudes of the Pantheon+ and SH0ES samples in various\nredshift/distance bins. We compare the identified levels of anisotropy in each\nbin with Monte-Carlo simulations of corresponding isotropised data to estimate\nthe frequency of such levels of anisotropy in the context of an underlying\nisotropic cosmological. We find that the identified levels of anisotropy in all\nbins are consistent with the Monte-Carlo isotropic simulated samples. However,\nin the real samples for both the Pantheon+ and the SH0ES cases we find sharp\nchanges of the level of anisotropy occuring at distances less than $40Mpc$. For\nthe Pantheon+ sample we find that the redshift bin $[0.005,0.01]$ is\nsignificantly more anisotropic than the other 5 redshift bins considered. For\nthe SH0ES sample we find a sharp drop of the anisotropy level at distances\nlarger than about $30Mpc$. These anisotropy transitions are relatively rare in\nthe Monte-Carlo isotropic simulated data and occur in $2\\%$ of the SH0ES\nsimulated data and at about $7\\%$ of the Pantheon+ isotropic simulated samples.\nThis effect is consistent with the experience of an off center observer in a\n$30Mpc$ bubble of distinct physics or systematics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:24:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12820","submitter":"Vaishali Pal","authors":"Vaishali Pal, Andrew Yates, Evangelos Kanoulas, Maarten de Rijke","title":"MultiTabQA: Generating Tabular Answers for Multi-Table Question\n  Answering","comments":"Accepted at ACL-2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Recent advances in tabular question answering (QA) with large language models\nare constrained in their coverage and only answer questions over a single\ntable. However, real-world queries are complex in nature, often over multiple\ntables in a relational database or web page. Single table questions do not\ninvolve common table operations such as set operations, Cartesian products\n(joins), or nested queries. Furthermore, multi-table operations often result in\na tabular output, which necessitates table generation capabilities of tabular\nQA models. To fill this gap, we propose a new task of answering questions over\nmultiple tables. Our model, MultiTabQA, not only answers questions over\nmultiple tables, but also generalizes to generate tabular answers. To enable\neffective training, we build a pre-training dataset comprising of 132,645 SQL\nqueries and tabular answers. Further, we evaluate the generated tables by\nintroducing table-specific metrics of varying strictness assessing various\nlevels of granularity of the table structure. MultiTabQA outperforms\nstate-of-the-art single table QA models adapted to a multi-table QA setting by\nfinetuning on three datasets: Spider, Atis and GeoQuery.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:25:15 GMT"},{"version":"v2","created":"Wed, 24 May 2023 17:13:47 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12821","submitter":"Youngwoon Lee","authors":"Minho Heo and Youngwoon Lee and Doohyun Lee and Joseph J. Lim","title":"FurnitureBench: Reproducible Real-World Benchmark for Long-Horizon\n  Complex Manipulation","comments":"Robotics: Science and Systems (RSS) 2023. Website:\n  https://clvrai.com/furniture-bench","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Reinforcement learning (RL), imitation learning (IL), and task and motion\nplanning (TAMP) have demonstrated impressive performance across various robotic\nmanipulation tasks. However, these approaches have been limited to learning\nsimple behaviors in current real-world manipulation benchmarks, such as pushing\nor pick-and-place. To enable more complex, long-horizon behaviors of an\nautonomous robot, we propose to focus on real-world furniture assembly, a\ncomplex, long-horizon robot manipulation task that requires addressing many\ncurrent robotic manipulation challenges to solve. We present FurnitureBench, a\nreproducible real-world furniture assembly benchmark aimed at providing a low\nbarrier for entry and being easily reproducible, so that researchers across the\nworld can reliably test their algorithms and compare them against prior work.\nFor ease of use, we provide 200+ hours of pre-collected data (5000+\ndemonstrations), 3D printable furniture models, a robotic environment setup\nguide, and systematic task initialization. Furthermore, we provide\nFurnitureSim, a fast and realistic simulator of FurnitureBench. We benchmark\nthe performance of offline RL and IL algorithms on our assembly tasks and\ndemonstrate the need to improve such algorithms to be able to solve our tasks\nin the real world, providing ample opportunities for future research.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:29:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12822","submitter":"Vladyslav Andriiashen","authors":"Vladyslav Andriiashen, Robert van Liere, Tristan van Leeuwen, K. Joost\n  Batenburg","title":"Quantifying the effect of X-ray scattering for data generation in\n  real-time defect detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  X-ray imaging is widely used for non-destructive detection of defects in\nindustrial products on a conveyor belt. Real-time detection requires highly\naccurate, robust, and fast algorithms to analyze X-ray images. Deep\nconvolutional neural networks (DCNNs) satisfy these requirements if a large\namount of labeled data is available. To overcome the challenge of collecting\nthese data, different methods of X-ray image generation can be considered.\nDepending on the desired level of similarity to real data, various physical\neffects either should be simulated or can be ignored. X-ray scattering is known\nto be computationally expensive to simulate, and this effect can heavily\ninfluence the accuracy of a generated X-ray image. We propose a methodology for\nquantitative evaluation of the effect of scattering on defect detection. This\nmethodology compares the accuracy of DCNNs trained on different versions of the\nsame data that include and exclude the scattering signal. We use the\nProbability of Detection (POD) curves to find the size of the smallest defect\nthat can be detected with a DCNN and evaluate how this size is affected by the\nchoice of training data. We apply the proposed methodology to a model problem\nof defect detection in cylinders. Our results show that the exclusion of the\nscattering signal from the training data has the largest effect on the smallest\ndetectable defects. Furthermore, we demonstrate that accurate inspection is\nmore reliant on high-quality training data for images with a high quantity of\nscattering. We discuss how the presented methodology can be used for other\ntasks and objects.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:29:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12823","submitter":"Stephane Vujasinovic","authors":"St\\'ephane Vujasinovi\\'c, Sebastian Bullinger, Stefan Becker, Norbert\n  Scherer-Negenborn, Michael Arens and Rainer Stiefelhagen","title":"READMem: Robust Embedding Association for a Diverse Memory in\n  Unconstrained Video Object Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present READMem (Robust Embedding Association for a Diverse Memory), a\nmodular framework for semi-automatic video object segmentation (sVOS) methods\ndesigned to handle unconstrained videos. Contemporary sVOS works typically\naggregate video frames in an ever-expanding memory, demanding high hardware\nresources for long-term applications. To mitigate memory requirements and\nprevent near object duplicates (caused by information of adjacent frames),\nprevious methods introduce a hyper-parameter that controls the frequency of\nframes eligible to be stored. This parameter has to be adjusted according to\nconcrete video properties (such as rapidity of appearance changes and video\nlength) and does not generalize well. Instead, we integrate the embedding of a\nnew frame into the memory only if it increases the diversity of the memory\ncontent. Furthermore, we propose a robust association of the embeddings stored\nin the memory with query embeddings during the update process. Our approach\navoids the accumulation of redundant data, allowing us in return, to restrict\nthe memory size and prevent extreme memory demands in long videos. We extend\npopular sVOS baselines with READMem, which previously showed limited\nperformance on long videos. Our approach achieves competitive results on the\nLong-time Video dataset (LV1) while not hindering performance on short\nsequences. Our code is publicly available.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:31:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12824","submitter":"Mengxi Liu","authors":"Mengxi Liu, Bo Zhou, Zimin Zhao, Hyeonseok Hong, Hyun Kim, Sungho Suh,\n  Vitor Fortes Rey and Paul Lukowicz","title":"FieldHAR: A Fully Integrated End-to-end RTL Framework for Human Activity\n  Recognition with Neural Networks from Heterogeneous Sensors","comments":"This work has been accepted by 2023 ASAP conference. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.AR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we propose an open-source scalable end-to-end RTL framework\nFieldHAR, for complex human activity recognition (HAR) from heterogeneous\nsensors using artificial neural networks (ANN) optimized for FPGA or ASIC\nintegration. FieldHAR aims to address the lack of apparatus to transform\ncomplex HAR methodologies often limited to offline evaluation to efficient\nrun-time edge applications. The framework uses parallel sensor interfaces and\ninteger-based multi-branch convolutional neural networks (CNNs) to support\nflexible modality extensions with synchronous sampling at the maximum rate of\neach sensor. To validate the framework, we used a sensor-rich kitchen scenario\nHAR application which was demonstrated in a previous offline study. Through\nresource-aware optimizations, with FieldHAR the entire RTL solution was created\nfrom data acquisition to ANN inference taking as low as 25\\% logic elements and\n2\\% memory bits of a low-end Cyclone IV FPGA and less than 1\\% accuracy loss\nfrom the original FP32 precision offline study. The RTL implementation also\nshows advantages over MCU-based solutions, including superior data acquisition\nperformance and virtually eliminating ANN inference bottleneck.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:34:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12825","submitter":"Kira Maag","authors":"Kira Maag and Asja Fischer","title":"Uncertainty-based Detection of Adversarial Attacks in Semantic\n  Segmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  State-of-the-art deep neural networks have proven to be highly powerful in a\nbroad range of tasks, including semantic image segmentation. However, these\nnetworks are vulnerable against adversarial attacks, i.e., non-perceptible\nperturbations added to the input image causing incorrect predictions, which is\nhazardous in safety-critical applications like automated driving. Adversarial\nexamples and defense strategies are well studied for the image classification\ntask, while there has been limited research in the context of semantic\nsegmentation. First works however show that the segmentation outcome can be\nseverely distorted by adversarial attacks. In this work, we introduce an\nuncertainty-based method for the detection of adversarial attacks in semantic\nsegmentation. We observe that uncertainty as for example captured by the\nentropy of the output distribution behaves differently on clean and perturbed\nimages using this property to distinguish between the two cases. Our method\nworks in a light-weight and post-processing manner, i.e., we do not modify the\nmodel or need knowledge of the process used for generating adversarial\nexamples. In a thorough empirical analysis, we demonstrate the ability of our\napproach to detect perturbed images across multiple types of adversarial\nattacks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:36:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12826","submitter":"Abdulnasser Hatemi-J","authors":"Abdulnasser Hatemi-J and Alan Mustafa","title":"A Simulation Package in VBA to Support Finance Students for Constructing\n  Optimal Portfolios","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.PM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper introduces a software component created in Visual Basic for\nApplications (VBA) that can be applied for creating an optimal portfolio using\ntwo different methods. The first method is the seminal approach of Markowitz\nthat is based on finding budget shares via the minimization of the variance of\nthe underlying portfolio. The second method is developed by El-Khatib and\nHatemi-J, which combines risk and return directly in the optimization problem\nand yields budget shares that lead to maximizing the risk adjusted return of\nthe portfolio. This approach is consistent with the expectation of rational\ninvestors since these investors consider both risk and return as the\nfundamental basis for selection of the investment assets. Our package offers\nanother advantage that is usually neglected in the literature, which is the\nnumber of assets that should be included in the portfolio. The common practice\nis to assume that the number of assets is given exogenously when the portfolio\nis constructed. However, the current software component constructs all possible\ncombinations and thus the investor can figure out empirically which portfolio\nis the best one among all portfolios considered. The software is consumer\nfriendly via a graphical user interface. An application is also provided to\ndemonstrate how the software can be used using real-time series data for\nseveral assets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:38:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12827","submitter":"Alessandro Favero","authors":"Guillermo Ortiz-Jimenez, Alessandro Favero, Pascal Frossard","title":"Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained\n  Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Task arithmetic has recently emerged as a cost-effective and scalable\napproach to edit pre-trained models directly in weight space: By adding the\nfine-tuned weights of different tasks, the model's performance can be improved\non these tasks, while negating them leads to task forgetting. Yet, our\nunderstanding of the effectiveness of task arithmetic and its underlying\nprinciples remains limited. We present a comprehensive study of task arithmetic\nin vision-language models and show that weight disentanglement is the crucial\nfactor that makes it effective. This property arises during pre-training and\nmanifests when distinct directions in weight space govern separate, localized\nregions in function space associated with the tasks. Notably, we show that\nfine-tuning models in their tangent space by linearizing them amplifies weight\ndisentanglement. This leads to substantial performance improvements across\nmultiple task arithmetic benchmarks and diverse models. Building on these\nfindings, we provide theoretical and empirical analyses of the neural tangent\nkernel (NTK) of these models and establish a compelling link between task\narithmetic and the spatial localization of the NTK eigenfunctions. Overall, our\nwork uncovers novel insights into the fundamental mechanisms of task arithmetic\nand offers a more reliable and effective approach to edit pre-trained models\nthrough the NTK linearization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:39:25 GMT"},{"version":"v2","created":"Tue, 30 May 2023 15:05:07 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.12828","submitter":"Xiang Li Lxws","authors":"Huan Liang, Xiang Li, Dunyan Yan","title":"Sharp bounds for the multilinear integral operators on Heisenberg group\n  BMO space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CA math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we study m-linear n-demensional Hardy-Littlewood-P\\'{o}lya\noperator and m-linear n-demensional Hilbert operator on Heisenberg group BMO\nspace. We obtain that the above two $m$-linear n-demensional operators is\nbounded in the BMO space of the Heisenberg group.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:40:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12829","submitter":"Fatma Elsafoury","authors":"Fatma Elsafoury, Stamos Katsigiannis, Naeem Ramzan","title":"On Bias and Fairness in NLP: How to have a fairer text classification?","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we provide a holistic analysis of the different sources of\nbias, Upstream, Sample and Overampflication biases, in NLP models. We\ninvestigate how they impact the fairness of the task of text classification. We\nalso investigate the impact of removing these biases using different debiasing\ntechniques on the fairness of text classification. We found that\noveramplification bias is the most impactful bias on the fairness of text\nclassification. And that removing overamplification bias by fine-tuning the LM\nmodels on a dataset with balanced representations of the different identity\ngroups leads to fairer text classification models. Finally, we build on our\nfindings and introduce practical guidelines on how to have a fairer text\nclassification model.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:44:00 GMT"},{"version":"v2","created":"Wed, 31 May 2023 10:13:26 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.12830","submitter":"Sourav Pal","authors":"Sourav Pal, Rickmoy Samanta, Supratik Pal","title":"Revisiting coupled CDM-massive neutrino perturbations in diverse\n  cosmological backgrounds","comments":"16 pages, 2 figures, 2 sets of figure","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO gr-qc hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Massive neutrinos are well-known to cause a characteristic suppression in the\ngrowth of structures at scales below the neutrino free-streaming length. A\ndetailed understanding of this suppression is essential in the era of precision\ncosmology we are entering into, enabling us to better constrain the total\nneutrino mass and possibly probe (beyond)-$\\Lambda$CDM cosmological model(s).\nInstead of the usual N-body simulation or Boltzmann solver, in this article we\nconsider a two-fluid framework at the linear scales, where the neutrino fluid\nperturbations are coupled to the CDM (+ baryon) fluid via gravity at redshifts\nof interest. Treating the neutrino mass fraction $f_\\nu$ as a perturbative\nparameter, we find a fully analytic solution to the system with\nredshift-dependent neutrino free-streaming length in $\\Lambda$CDM background.\nThe perturbative scale-dependent solution is shown to be in excellent agreement\nwith numerical solution of the two-fluid equations valid to all orders in\n$f_{\\nu}$, and also agrees with results from {\\texttt{CLASS}} to a good\naccuracy. We further generalize the framework to incorporate different evolving\ndark energy backgrounds and found sub-percent level differences in the\nsuppression, all of which lie within the observational uncertainty of BOSS-like\nsurveys. We also present a brief discussion on the prospects of the current\nanalysis in the context of upcoming missions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:50:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12831","submitter":"Yidi Jiang","authors":"Yidi Jiang, Ruijie Tao, Zexu Pan, Haizhou Li","title":"Target Active Speaker Detection with Audio-visual Cues","comments":"Accepted to INTERSPEECH2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In active speaker detection (ASD), we would like to detect whether an\non-screen person is speaking based on audio-visual cues. Previous studies have\nprimarily focused on modeling audio-visual synchronization cue, which depends\non the video quality of the lip region of a speaker. In real-world\napplications, it is possible that we can also have the reference speech of the\non-screen speaker. To benefit from both facial cue and reference speech, we\npropose the Target Speaker TalkNet (TS-TalkNet), which leverages a pre-enrolled\nspeaker embedding to complement the audio-visual synchronization cue in\ndetecting whether the target speaker is speaking. Our framework outperforms the\npopular model, TalkNet on two datasets, achieving absolute improvements of\n1.6\\% in mAP on the AVA-ActiveSpeaker validation set, and 0.8\\%, 0.4\\%, and\n0.8\\% in terms of AP, AUC and EER on the ASW test set, respectively. Code is\navailable at\n\\href{https://github.com/Jiang-Yidi/TS-TalkNet/}{\\color{red}{https://github.com/Jiang-Yidi/TS-TalkNet/}}.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:52:42 GMT"},{"version":"v2","created":"Fri, 26 May 2023 08:54:48 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12832","submitter":"Bolys Sabitbek","authors":"Claudia Garetto, Bolys Sabitbek","title":"Hyperbolic systems with non-diagonalisable principal part and variable\n  multiplicities, III: singular coefficients","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we continue the analysis of non-diagonalisable hyperbolic\nsystems initiated in \\cite{GarJRuz, GarJRuz2}. Here we assume that the system\nhas discontinuous coefficients or more in general distributional coefficients.\nWell-posedness is proven in the very weak sense for systems with singularities\nwith respect to the space variable or the time variable. Consistency with the\nclassical theory is proven in the case of smooth coefficients.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:53:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12833","submitter":"Na Dong","authors":"Na Dong and Yongqiang Zhang and Mingli Ding and Gim Hee Lee","title":"Boosting Long-tailed Object Detection via Step-wise Learning on\n  Smooth-tail Data","comments":"10 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Real-world data tends to follow a long-tailed distribution, where the class\nimbalance results in dominance of the head classes during training. In this\npaper, we propose a frustratingly simple but effective step-wise learning\nframework to gradually enhance the capability of the model in detecting all\ncategories of long-tailed datasets. Specifically, we build smooth-tail data\nwhere the long-tailed distribution of categories decays smoothly to correct the\nbias towards head classes. We pre-train a model on the whole long-tailed data\nto preserve discriminability between all categories. We then fine-tune the\nclass-agnostic modules of the pre-trained model on the head class dominant\nreplay data to get a head class expert model with improved decision boundaries\nfrom all categories. Finally, we train a unified model on the tail class\ndominant replay data while transferring knowledge from the head class expert\nmodel to ensure accurate detection of all categories. Extensive experiments on\nlong-tailed datasets LVIS v0.5 and LVIS v1.0 demonstrate the superior\nperformance of our method, where we can improve the AP with ResNet-50 backbone\nfrom 27.0% to 30.3% AP, and especially for the rare categories from 15.5% to\n24.9% AP. Our best model using ResNet-101 backbone can achieve 30.7% AP, which\nsuppresses all existing detectors using the same backbone.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:53:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12834","submitter":"Stefan Schnabel","authors":"Stefan Schnabel and Wolfhard Janke","title":"Surveying an Energy Landscape","comments":"9 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech physics.comp-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We derive a formula that expresses the density of states of a system with\ncontinuous degrees of freedom as a function of microcanonical averages of\nsquared gradient and Laplacian of the Hamiltonian. This result is then used to\npropose a novel flat-histogram Monte Carlo algorithm, which is tested on a\nsystem of interacting Lennard-Jones particles and the O(n) vector spin model.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:55:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12835","submitter":"Siyi Liu","authors":"Siyi Liu, Hongming Zhang, Hongwei Wang, Kaiqiang Song, Dan Roth, Dong\n  Yu","title":"Open-Domain Event Graph Induction for Mitigating Framing Bias","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Researchers have proposed various information extraction (IE) techniques to\nconvert news articles into structured knowledge for news understanding.\nHowever, none of the existing methods have explicitly addressed the issue of\nframing bias that is inherent in news articles. We argue that studying and\nidentifying framing bias is a crucial step towards trustworthy event\nunderstanding. We propose a novel task, neutral event graph induction, to\naddress this problem. An event graph is a network of events and their temporal\nrelations. Our task aims to induce such structural knowledge with minimal\nframing bias in an open domain. We propose a three-step framework to induce a\nneutral event graph from multiple input sources. The process starts by inducing\nan event graph from each input source, then merging them into one merged event\ngraph, and lastly using a Graph Convolutional Network to remove event nodes\nwith biased connotations. We demonstrate the effectiveness of our framework\nthrough the use of graph prediction metrics and bias-focused metrics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:57:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12836","submitter":"Michael Crabb","authors":"M. C. Crabb","title":"Fibrewise topological complexity of sphere and projective bundles","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We establish a stable homotopy-theoretic version of a recent result of Farber\nand Weinberger on the fibrewise topological complexity of sphere bundles and\nprove, by closely parallel methods, a similar result for real, complex and\nquaternionic projective bundles. The symmetrized invariant introduced by Farber\nand Grant is also considered.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:59:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12837","submitter":"Zhangming Chan","authors":"Zhangming Chan, Yu Zhang, Shuguang Han, Yong Bai, Xiang-Rong Sheng,\n  Siyuan Lou, Jiacen Hu, Baolin Liu, Yuning Jiang, Jian Xu, Bo Zheng","title":"Capturing Conversion Rate Fluctuation during Sales Promotions: A Novel\n  Historical Data Reuse Approach","comments":"Accepted at KDD 2023. This work has already been deployed on the\n  display advertising system in Alibaba, bringing substantial economic gains","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Conversion rate (CVR) prediction is one of the core components in online\nrecommender systems, and various approaches have been proposed to obtain\naccurate and well-calibrated CVR estimation. However, we observe that a\nwell-trained CVR prediction model often performs sub-optimally during sales\npromotions. This can be largely ascribed to the problem of the data\ndistribution shift, in which the conventional methods no longer work. To this\nend, we seek to develop alternative modeling techniques for CVR prediction.\nObserving similar purchase patterns across different promotions, we propose\nreusing the historical promotion data to capture the promotional conversion\npatterns. Herein, we propose a novel \\textbf{H}istorical \\textbf{D}ata\n\\textbf{R}euse (\\textbf{HDR}) approach that first retrieves historically\nsimilar promotion data and then fine-tunes the CVR prediction model with the\nacquired data for better adaptation to the promotion mode. HDR consists of\nthree components: an automated data retrieval module that seeks similar data\nfrom historical promotions, a distribution shift correction module that\nre-weights the retrieved data for better aligning with the target promotion,\nand a TransBlock module that quickly fine-tunes the original model for better\nadaptation to the promotion mode. Experiments conducted with real-world data\ndemonstrate the effectiveness of HDR, as it improves both ranking and\ncalibration metrics to a large extent. HDR has also been deployed on the\ndisplay advertising system in Alibaba, bringing a lift of $9\\%$ RPM and $16\\%$\nCVR during Double 11 Sales in 2022.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:00:34 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 12:38:20 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.12838","submitter":"Yafeng Chen","authors":"Yafeng Chen, Siqi Zheng, Hui Wang, Luyao Cheng, Qian Chen, Jiajun Qi","title":"An Enhanced Res2Net with Local and Global Feature Fusion for Speaker\n  Verification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.SD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Effective fusion of multi-scale features is crucial for improving speaker\nverification performance. While most existing methods aggregate multi-scale\nfeatures in a layer-wise manner via simple operations, such as summation or\nconcatenation. This paper proposes a novel architecture called Enhanced Res2Net\n(ERes2Net), which incorporates both local and global feature fusion techniques\nto improve the performance. The local feature fusion (LFF) fuses the features\nwithin one single residual block to extract the local signal. The global\nfeature fusion (GFF) takes acoustic features of different scales as input to\naggregate global signal. To facilitate effective feature fusion in both LFF and\nGFF, an attentional feature fusion module is employed in the ERes2Net\narchitecture, replacing summation or concatenation operations. A range of\nexperiments conducted on the VoxCeleb datasets demonstrate the superiority of\nthe ERes2Net in speaker verification.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:01:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12839","submitter":"Shilin Zhou","authors":"Shilin Zhou, Zhenghua Li, Yu Hong, Min Zhang, Zhefeng Wang, Baoxing\n  Huai","title":"CopyNE: Better Contextual ASR by Copying Named Entities","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent years have seen remarkable progress in automatic speech recognition\n(ASR). However, traditional token-level ASR models have struggled with\naccurately transcribing entities due to the problem of homophonic and\nnear-homophonic tokens. This paper introduces a novel approach called CopyNE,\nwhich uses a span-level copying mechanism to improve ASR in transcribing\nentities. CopyNE can copy all tokens of an entity at once, effectively avoiding\nerrors caused by homophonic or near-homophonic tokens that occur when\npredicting multiple tokens separately. Experiments on Aishell and ST-cmds\ndatasets demonstrate that CopyNE achieves significant reductions in character\nerror rate (CER) and named entity CER (NE-CER), especially in entity-rich\nscenarios. Furthermore, even when compared to the strong Whisper baseline,\nCopyNE still achieves notable reductions in CER and NE-CER. Qualitative\ncomparisons with previous approaches demonstrate that CopyNE can better handle\nentities, effectively improving the accuracy of ASR.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:03:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12840","submitter":"Barbara Dietz","authors":"Xiaodong Zhang, Weihua Zhang, Jiongning Che, and Barbara Dietz","title":"Experimental test of the Rosenzweig-Porter model for the transition from\n  Poisson to Gaussian unitary ensemble statistics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph nlin.CD","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report on an experimental investigation of the transition of a quantum\nsystem with integrable classical dynamics to one with violated time-reversal (T\n) invariance and chaotic classical counterpart. High-precision experiments are\nperformed with a flat superconducting microwave resonator with circular shape\nin which T invariance and a chaotic dynamics are induced by magnetizing a\nferrite disk placed at its center. We determine a complete sequence of ' 1000\neigenfrequencies and verify analytical predictions for the spectral properties\nof the Rosenzweig-Porter (RP) model which, currently, is under intensive study\nin the context of many-body quantum chaos as it exhibits ergodic, fractal and\nlocalized phases. Furthermore, we introduce based on this RP model and the\nHeidelberg approach a random-matrix model for the scattering (S) matrix of the\ncorresponding open quantum system and show that it perfectly reproduces the\nfluctuation properties of the measured S matrix of the microwave resonator.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:04:20 GMT"},{"version":"v2","created":"Sun, 28 May 2023 09:49:46 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12841","submitter":"Kazuo Iwama","authors":"Kazuo Iwama, Shuichi Miyazaki","title":"Marriage and Roommate","comments":"accepted to IJFCS","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CC cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper has two objectives. One is to give a linear time algorithm that\nsolves the stable roommates problem (i.e., obtains one stable matching) using\nthe stable marriage problem. The idea is that a stable matching of a roommate\ninstance $I$ is a stable matching (that however must satisfy a certain\ncondition) of some marriage instance $I'$. $I'$ is obtained just by making two\ncopies of $I$, one for the men's table and the other for the women's table. The\nsecond objective is to investigate the possibility of reducing the roommate\nproblem to the marriage problem (with a one-to-one correspondence between their\nstable matchings) in polynomial time. For a given $I$, we construct the\nrotation POSET $P$ of $I'$ and then we ``halve'' it to obtain $P'$, by which we\ncan forget the above condition and can use all the closed subsets of $P'$ for\nall the stable matchings of $I$. Unfortunately, this approach works (runs in\npolynomial time) only for restricted instances.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:05:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12842","submitter":"Zhiqiang Wei","authors":"Zhiqiang Wei, Fan Liu, Chang Liu, Zai Yang, Derrick Wing Kwan Ng,\n  Robert Schober","title":"Integrated Sensing, Navigation, and Communication for Secure UAV\n  Networks with a Mobile Eavesdropper","comments":"30 pages, 20 figures, submitted to an IEEE journal for possible\n  publication","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper proposes an integrated sensing, navigation, and communication\n(ISNC) framework for safeguarding unmanned aerial vehicle (UAV)-enabled\nwireless networks against a mobile eavesdropping UAV (E-UAV). To cope with the\nmobility of the E-UAV, the proposed framework advocates the dual use of\nartificial noise transmitted by the information UAV (I-UAV) for simultaneous\njamming and sensing to facilitate navigation and secure communication. In\nparticular, the I-UAV communicates with legitimate downlink ground users, while\navoiding potential information leakage by emitting jamming signals, and\nestimates the state of the E-UAV with an extended Kalman filter based on the\nbackscattered jamming signals. Exploiting the estimated state of the E-UAV in\nthe previous time slot, the I-UAV determines its flight planning strategy,\npredicts the wiretap channel, and designs its communication resource allocation\npolicy for the next time slot. To circumvent the severe coupling between these\nthree tasks, a divide-and-conquer approach is adopted. The online navigation\ndesign has the objective to minimize the distance between the I-UAV and a\npre-defined destination point considering kinematic and geometric constraints.\nSubsequently, given the predicted wiretap channel, the robust resource\nallocation design is formulated as an optimization problem to achieve the\noptimal trade-off between sensing and communication in the next time slot,\nwhile taking into account the wiretap channel prediction error and the\nquality-of-service (QoS) requirements of secure communication. Simulation\nresults demonstrate the superior performance of the proposed design compared\nwith baseline schemes and validate the benefits of integrating sensing and\nnavigation into secure UAV communication systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:07:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12843","submitter":"Han Jiang","authors":"Han Jiang, Ruoxuan Li, Haosen Sun, Yu-Wing Tai, Chi-Keung Tang","title":"Registering Neural Radiance Fields as 3D Density Images","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  No significant work has been done to directly merge two partially overlapping\nscenes using NeRF representations. Given pre-trained NeRF models of a 3D scene\nwith partial overlapping, this paper aligns them with a rigid transform, by\ngeneralizing the traditional registration pipeline, that is, key point\ndetection and point set registration, to operate on 3D density fields. To\ndescribe corner points as key points in 3D, we propose to use universal\npre-trained descriptor-generating neural networks that can be trained and\ntested on different scenes. We perform experiments to demonstrate that the\ndescriptor networks can be conveniently trained using a contrastive learning\nstrategy. We demonstrate that our method, as a global approach, can effectively\nregister NeRF models, thus making possible future large-scale NeRF construction\nby registering its smaller and overlapping NeRFs captured individually.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:08:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12844","submitter":"Md. Alamin Talukder","authors":"Md. Alamin Talukder, Md. Manowarul Islam, Md Ashraf Uddin, Arnisha\n  Akhter, Md. Alamgir Jalil Pramanik, Sunil Aryal, Muhammad Ali Abdulllah\n  Almoyad, Khondokar Fida Hasan, Mohammad Ali Moni","title":"An efficient deep learning model to categorize brain tumor using\n  reconstruction and fine-tuning","comments":"Accepted in the Expert Systems with Applications (Scopus, Web of\n  Science, Science Citation Index Expanded, Quartile: Q1, Site Score: 12.20,\n  Impact Factor: 8.665) on 19 May 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Brain tumors are among the most fatal and devastating diseases, often\nresulting in significantly reduced life expectancy. An accurate diagnosis of\nbrain tumors is crucial to devise treatment plans that can extend the lives of\naffected individuals. Manually identifying and analyzing large volumes of MRI\ndata is both challenging and time-consuming. Consequently, there is a pressing\nneed for a reliable deep learning (DL) model to accurately diagnose brain\ntumors. In this study, we propose a novel DL approach based on transfer\nlearning to effectively classify brain tumors. Our novel method incorporates\nextensive pre-processing, transfer learning architecture reconstruction, and\nfine-tuning. We employ several transfer learning algorithms, including\nXception, ResNet50V2, InceptionResNetV2, and DenseNet201. Our experiments used\nthe Figshare MRI brain tumor dataset, comprising 3,064 images, and achieved\naccuracy scores of 99.40%, 99.68%, 99.36%, and 98.72% for Xception, ResNet50V2,\nInceptionResNetV2, and DenseNet201, respectively. Our findings reveal that\nResNet50V2 achieves the highest accuracy rate of 99.68% on the Figshare MRI\nbrain tumor dataset, outperforming existing models. Therefore, our proposed\nmodel's ability to accurately classify brain tumors in a short timeframe can\naid neurologists and clinicians in making prompt and precise diagnostic\ndecisions for brain tumor patients.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:08:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12845","submitter":"Chenhang Cui","authors":"Chenhang Cui, Jinyu Xie, Yechenhao Yang","title":"Bright Channel Prior Attention for Multispectral Pedestrian Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multispectral methods have gained considerable attention due to their\npromising performance across various fields. However, most existing methods\ncannot effectively utilize information from two modalities while optimizing\ntime efficiency. These methods often prioritize accuracy or time efficiency,\nleaving room for improvement in their performance. To this end, we propose a\nnew method bright channel prior attention for enhancing pedestrian detection in\nlow-light conditions by integrating image enhancement and detection within a\nunified framework. The method uses the V-channel of the HSV image of the\nthermal image as an attention map to trigger the unsupervised auto-encoder for\nvisible light images, which gradually emphasizes pedestrian features across\nlayers. Moreover, we utilize unsupervised bright channel prior algorithms to\naddress light compensation in low light images. The proposed method includes a\nself-attention enhancement module and a detection module, which work together\nto improve object detection. An initial illumination map is estimated using the\nBCP, guiding the learning of the self-attention map from the enhancement\nnetwork to obtain more informative representation focused on pedestrians. The\nextensive experiments show effectiveness of the proposed method is demonstrated\nthrough.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:10:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12846","submitter":"Paul Manns","authors":"Felix Bestehorn, Christoph Hansknecht, Christian Kirches, Paul Manns","title":"Non-uniform Grid Refinement for the Combinatorial Integral Approximation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The combinatorial integral approximation (CIA) is a solution technique for\ninteger optimal control problems. In order to regularize the solutions produced\nby CIA, one can minimize switching costs in one of its algorithmic steps. This\nleads to combinatorial optimization problems, which are called switching cost\naware rounding problems (SCARP). They can be solved efficiently on\none-dimensional domains but no efficient solution algorithms have been found so\nfar for multi-dimensional domains.\n  The CIA problem formulation depends on a discretization grid. We propose to\nreduce the number of variables and thus improve the computational tractability\nof SCARP by means of a non-uniform grid refinement strategy. We prove that the\ngrid refinement preserves the approximation properties of the combinatorial\nintegral approximation. Computational results are offered to show that the\nproposed approach is able to achieve, within a prescribed time limit, smaller\nduality gaps that does the uniform approach. For several large instances, a\ndual bound could only be obtained through adaptivity.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:12:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12847","submitter":"Xuemei Li","authors":"Xuemei Li, Dongsheng Li","title":"pointwise boundary $\\bm{{C}^{1,\\alpha}}$ Estimates for some degenerate\n  fully nonlinear elliptic equations on $\\bm{C^{1,\\alpha}}$ Domains","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this paper, we establish pointwise boundary ${{C}^{1,\\alpha}}$ estimates\nfor viscosity solutions of some degenerate fully nonlinear elliptic equations\non ${C^{1,\\alpha}}$ domains. Instead of straightening out the boundary, we\nutilize the perturbation and compactness techniques.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:13:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12848","submitter":"Vladimir Enaldiev","authors":"M.A. Kaliteevsky, V.V. Enaldiev, V.I. Fal'ko","title":"Twirling and spontaneous symmetry breaking of domain wall networks in\n  lattice-reconstructed heterostructures of 2D materials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.mtrl-sci","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Lattice relaxation in twistronic bilayers with close lattice parameters and\nalmost perfect crystallographic alignment of the layers results in the\ntransformation of moir\\'e pattern into a sequence of preferential stacking\ndomains and domain wall networks. Here, we show that reconstructed moir\\'e\nsuperlattices of the perfectly aligned heterobilayers of same-chalcogen\ntransition metal dichalcogenides have broken-symmetry structures featuring\ntwisted nodes ('twirls') of domain wall networks. Analysing\ntwist-angle-dependences of strain characteristics for the broken-symmetry\nstructures we show that the formation of twirl reduces amount of hydrostatic\nstrain around the nodes, potentially, reducing their infuence on the band edge\nenergies of electrons and holes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:15:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12849","submitter":"Alexandr Valyuzhenich","authors":"Alexandr Valyuzhenich","title":"On reduction for eigenfunctions of graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work, we prove a general version of the reduction lemmas for\neigenfunctions of graphs admitting involutive automorphisms of a special type.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:16:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12850","submitter":"Jin Won Kim","authors":"Jin Won Kim and Prashant G. Mehta","title":"Variance Decay Property for Filter Stability","comments":"13 pages, under peer reviewing","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is concerned with the problem of nonlinear (stochastic) filter\nstability of a hidden Markov model (HMM) with white noise observations. The\nmain contribution is the variance decay property which is used to conclude\nfilter stability. The property is closely inspired by the Poincar\\'e inequality\n(PI) in the study of stochastic stability of Markov processes. In this paper,\nthe property is related to both the ergodicity of the Markov process as well as\nthe observability of the HMM. The proofs are based upon a recently discovered\nminimum variance duality which is used to transform the nonlinear filtering\nproblem into a stochastic optimal control problem for a backward stochastic\ndifferential equation (BSDE).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:19:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12851","submitter":"Renlong Jie","authors":"Renlong Jie, Xiaojun Meng, Lifeng Shang, Xin Jiang, Qun Liu","title":"Enhancing Coherence of Extractive Summarization with Multitask Learning","comments":"11 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study proposes a multitask learning architecture for extractive\nsummarization with coherence boosting. The architecture contains an extractive\nsummarizer and coherent discriminator module. The coherent discriminator is\ntrained online on the sentence vectors of the augmented textual input, thus\nimproving its general ability of judging whether the input sentences are\ncoherent. Meanwhile, we maximize the coherent scores from the coherent\ndiscriminator by updating the parameters of the summarizer. To make the\nextractive sentences trainable in a differentiable manner, we introduce two\nstrategies, including pre-trained converting model (model-based) and converting\nmatrix (MAT-based) that merge sentence representations. Experiments show that\nour proposed method significantly improves the proportion of consecutive\nsentences in the extracted summaries based on their positions in the original\narticle (i.e., automatic sentence-level coherence metric), while the goodness\nin terms of other automatic metrics (i.e., Rouge scores and BertScores) are\npreserved. Human evaluation also evidences the improvement of coherence and\nconsistency of the extracted summaries given by our method.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:20:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12852","submitter":"Aydogan Ozcan","authors":"Luzhe Huang, Jianing Li, Xiaofu Ding, Yijie Zhang, Hanlong Chen,\n  Aydogan Ozcan","title":"Cycle Consistency-based Uncertainty Quantification of Neural Networks in\n  Inverse Imaging Problems","comments":"28 Pages, 4 Figures, 1 Table","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG eess.IV physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Uncertainty estimation is critical for numerous applications of deep neural\nnetworks and draws growing attention from researchers. Here, we demonstrate an\nuncertainty quantification approach for deep neural networks used in inverse\nproblems based on cycle consistency. We build forward-backward cycles using the\nphysical forward model available and a trained deep neural network solving the\ninverse problem at hand, and accordingly derive uncertainty estimators through\nregression analysis on the consistency of these forward-backward cycles. We\ntheoretically analyze cycle consistency metrics and derive their relationship\nwith respect to uncertainty, bias, and robustness of the neural network\ninference. To demonstrate the effectiveness of these cycle consistency-based\nuncertainty estimators, we classified corrupted and out-of-distribution input\nimage data using some of the widely used image deblurring and super-resolution\nneural networks as testbeds. The blind testing of our method outperformed other\nmodels in identifying unseen input data corruption and distribution shifts.\nThis work provides a simple-to-implement and rapid uncertainty quantification\nmethod that can be universally applied to various neural networks used for\nsolving inverse problems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:23:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12853","submitter":"Jinglin Zhan","authors":"Jinglin Zhan, Tiejun Liu, Rengang Li, Jingwei Zhang, Zhaoxiang Zhang,\n  Yuntao Chen","title":"Real-Aug: Realistic Scene Synthesis for LiDAR Augmentation in 3D Object\n  Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Data and model are the undoubtable two supporting pillars for LiDAR object\ndetection. However, data-centric works have fallen far behind compared with the\never-growing list of fancy new models. In this work, we systematically study\nthe synthesis-based LiDAR data augmentation approach (so-called GT-Aug) which\noffers maxium controllability over generated data samples. We pinpoint the main\nshortcoming of existing works is introducing unrealistic LiDAR scan patterns\nduring GT-Aug. In light of this finding, we propose Real-Aug, a synthesis-based\naugmentation method which prioritizes on generating realistic LiDAR scans. Our\nmethod consists a reality-conforming scene composition module which handles the\ndetails of the composition and a real-synthesis mixing up training strategy\nwhich gradually adapts the data distribution from synthetic data to the real\none. To verify the effectiveness of our methods, we conduct extensive ablation\nstudies and validate the proposed Real-Aug on a wide combination of detectors\nand datasets. We achieve a state-of-the-art 0.744 NDS and 0.702 mAP on nuScenes\ntest set. The code shall be released soon.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:24:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12854","submitter":"Sven Dummer","authors":"Sven Dummer, Nicola Strisciuglio, Christoph Brune","title":"RSA-INR: Riemannian Shape Autoencoding via 4D Implicit Neural\n  Representations","comments":"26 pages, 20 figures (including subfigures)","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.GR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Shape encoding and shape analysis are valuable tools for comparing shapes and\nfor dimensionality reduction. A specific framework for shape analysis is the\nLarge Deformation Diffeomorphic Metric Mapping (LDDMM) framework, which is\ncapable of shape matching and dimensionality reduction. Researchers have\nrecently introduced neural networks into this framework. However, these works\ncan not match more than two objects simultaneously or have suboptimal\nperformance in shape variability modeling. The latter limitation occurs as the\nworks do not use state-of-the-art shape encoding methods. Moreover, the\nliterature does not discuss the connection between the LDDMM Riemannian\ndistance and the Riemannian geometry for deep learning literature. Our work\naims to bridge this gap by demonstrating how LDDMM can integrate Riemannian\ngeometry into deep learning. Furthermore, we discuss how deep learning solves\nand generalizes shape matching and dimensionality reduction formulations of\nLDDMM. We achieve both goals by designing a novel implicit encoder for shapes.\nThis model extends a neural network-based algorithm for LDDMM-based pairwise\nregistration, results in a nonlinear manifold PCA, and adds a Riemannian\ngeometry aspect to deep learning models for shape variability modeling.\nAdditionally, we demonstrate that the Riemannian geometry component improves\nthe reconstruction procedure of the implicit encoder in terms of reconstruction\nquality and stability to noise. We hope our discussion paves the way to more\nresearch into how Riemannian geometry, shape/image analysis, and deep learning\ncan be combined.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:27:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12855","submitter":"Ram Prasad","authors":"Ram Prasad","title":"Microcontroller Based AVR Hazardous Gas Detection System using IoT","comments":"7 Pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  MQ-6 Semiconductor Sensor for Combustible Gas detection is a Sensitive Gas\nsensor. The sensitive material of this MQ-6 gas sensor is SnO2, which works\nwith lower conductivity in clean air. When the target combustible gas exist,\nthe sensors conductivity is higher along with the gas concentration rising. As\nthe conductivity increases the current in the circuit of the sensor increases\nwhich results in lower sensor resistance. This change is used to correspond,\nthe output signal of gas concentration. MQ-6 gas sensor has high sensitivity to\nMethane, Propane and Butane and could be used to detect both Methane and\nPropane. The sensor could be used to detect different combustible gas\nespecially Methane, it is with low cost and suitable for different application.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:29:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12856","submitter":"Xiaokai Hou","authors":"Xiaokai Hou, Qingyu Li, Man-Hong Yung, Xusheng Xu, Zizhu Wang, Chu Guo\n  and Xiaoting Wang","title":"A sequentially generated variational quantum circuit with polynomial\n  complexity","comments":"21 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Variational quantum algorithms have been a promising candidate to utilize\nnear-term quantum devices to solve real-world problems. The powerfulness of\nvariational quantum algorithms is ultimately determined by the expressiveness\nof the underlying quantum circuit ansatz for a given problem. In this work, we\npropose a sequentially generated circuit ansatz, which naturally adapts to 1D,\n2D, 3D quantum many-body problems. Specifically, in 1D our ansatz can\nefficiently generate any matrix product states with a fixed bond dimension,\nwhile in 2D our ansatz generates the string-bond states. As applications, we\ndemonstrate that our ansatz can be used to accurately reconstruct unknown pure\nand mixed quantum states which can be represented as matrix product states, and\nthat our ansatz is more efficient compared to several alternatives in finding\nthe ground states of some prototypical quantum many-body systems as well as\nquantum chemistry systems, in terms of the number of quantum gate operations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:30:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12857","submitter":"Stefania Miricola","authors":"Stefania Miricola, Armando Rungi, Gianluca Santoni","title":"Ownership Chains in Multinational Enterprises","comments":"35 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  In this contribution, we investigate the role of ownership chains developed\nby multinational enterprises across different national borders. First, we\ndocument that parent companies control a majority (58%) of foreign subsidiaries\nthrough indirect control relationships involving at least two countries along\nan ownership chain. Therefore, we hypothesize that locations along ownership\nchains are driven by the existence of communication costs to transmit\nmanagement decisions. In line with motivating evidence, we develop a\ntheoretical model for competition on corporate control that considers the\npossibility that parent companies in the origin countries can delegate their\nmonitoring activities in final subsidiaries to middlemen subsidiaries that are\nlocated in intermediate jurisdictions. Our model returns us a two-step\nempirical strategy with two gravity equations: i) a triangular gravity for\nestablishing a middleman by the parent, conditional on final investments'\nlocations; ii) a classical gravity for the location of final investments. First\nestimates confirm the predictions that ease of communication at the country\nlevel shapes the heterogeneous locations of subsidiaries along global ownership\nchains.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:31:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12858","submitter":"Valeriy Kondratiev","authors":"Valeriy I. Kondratyev, Dmitry V. Permyakov, Tatyana V. Ivanova, Ivan\n  V. Iorsh, Dmitry N. Krizhanovskii, Maurice S. Skolnick, Vasily Kravtsov, and\n  Anton K. Samusev","title":"Probing and control of guided exciton-polaritons in a 2D\n  semiconductor-integrated slab waveguide","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Guided 2D exciton-polaritons, resulting from the strong coupling of excitons\nin semiconductors with non-radiating waveguide modes, provide an attractive\napproach towards developing novel on-chip optical devices. These quasiparticles\nare characterized by long propagation distances and efficient nonlinear\ninteraction. However, as guided exciton-polaritons are uncoupled from the free\nspace, it is challenging to investigate them using conventional far-field\nspectroscopy techniques. Here we demonstrate a powerful approach for probing\nand manipulating guided polaritons in a Ta$_2$O$_5$ slab integrated with a\nWS$_2$ monolayer using evanescent coupling through a high-index solid immersion\nlens. Tuning the nanoscale gap between the lens and the sample, we demonstrate\nin-situ control over radiative losses and Rabi splitting of guided polaritons\nat ambient conditions. This extra degree of freedom allows for extracting all\nthe intrinsic parameters of the strongly coupled system under study. Our\nresults enable the future development of integrated optics employing\nroom-temperature exciton-polaritons in 2D semiconductor-based structures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:32:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12859","submitter":"Pia Hanfeld","authors":"Pia Hanfeld and Marina M.-C. H\\\"ohne and Michael Bussmann and Wolfgang\n  H\\\"onig","title":"Flying Adversarial Patches: Manipulating the Behavior of Deep\n  Learning-based Autonomous Multirotors","comments":"6 pages, 5 figures, Workshop on Multi-Robot Learning, International\n  Conference on Robotics and Automation (ICRA)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.CR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Autonomous flying robots, e.g. multirotors, often rely on a neural network\nthat makes predictions based on a camera image. These deep learning (DL) models\ncan compute surprising results if applied to input images outside the training\ndomain. Adversarial attacks exploit this fault, for example, by computing small\nimages, so-called adversarial patches, that can be placed in the environment to\nmanipulate the neural network's prediction. We introduce flying adversarial\npatches, where an image is mounted on another flying robot and therefore can be\nplaced anywhere in the field of view of a victim multirotor. For an effective\nattack, we compare three methods that simultaneously optimize the adversarial\npatch and its position in the input image. We perform an empirical validation\non a publicly available DL model and dataset for autonomous multirotors.\nUltimately, our attacking multirotor would be able to gain full control over\nthe motions of the victim multirotor.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:35:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12860","submitter":"Meng Guo","authors":"Zili Tang, Junfeng Chen and Meng Guo","title":"Combinatorial-hybrid Optimization for Multi-agent Systems under\n  Collaborative Tasks","comments":"8 pages, 7 figures, 1 table","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Multi-agent systems can be extremely efficient when working concurrently and\ncollaboratively, e.g., for transportation, maintenance, search and rescue.\nCoordination of such teams often involves two aspects: (i) selecting\nappropriate sub-teams for different tasks; (ii) designing collaborative control\nstrategies to execute these tasks. The former aspect can be combinatorial\nw.r.t. the team size, while the latter requires optimization over joint\nstate-spaces under geometric and dynamic constraints. Existing work often\ntackles one aspect by assuming the other is given, while ignoring their close\ndependency. This work formulates such problems as combinatorial-hybrid\noptimizations (CHO), where both the discrete modes of collaboration and the\ncontinuous control parameters are optimized simultaneously and iteratively. The\nproposed framework consists of two interleaved layers: the dynamic formation of\ntask coalitions and the hybrid optimization of collaborative behaviors. Overall\nfeasibility and costs of different coalitions performing various tasks are\napproximated at different granularities to improve the computational\nefficiency. At last, a Nash-stable strategy for both task assignment and\nexecution is derived with provable guarantee on the feasibility and quality.\nTwo non-trivial applications of collaborative transportation and dynamic\ncapture are studied against several baselines.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:37:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12861","submitter":"Fran\\c{c}ois Rondeau","authors":"Victor Franken, Herv\\'e Partouche, Fran\\c{c}ois Rondeau, Nicolaos\n  Toumbas","title":"Bridging the static patches: de Sitter holography and entanglement","comments":"82 pages, 11 figures","journal-ref":null,"doi":null,"report-no":"CPHT-RR018.042023","categories":"hep-th gr-qc","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the context of de Sitter static-patch holography, two prescriptions have\nbeen put forward for holographic entanglement entropy computations, the\nmonolayer and bilayer proposals. In this paper, we reformulate both\nprescriptions in a covariant way and extend them to include quantum\ncorrections. We argue that the bilayer proposal is self-consistent, while the\nmonolayer proposal exhibits contradictory behavior. In fact, the bilayer\nproposal leads to a stronger holographic description, in which the full\nspacetime is encoded on two screens at the cosmological horizons. At the\nclassical level, we find large degeneracies of minimal extremal homologous\nsurfaces, localized at the horizons, which can be lifted by quantum\ncorrections. The entanglement wedges of subregions of the screens exhibit\nnon-trivial behaviors, hinting at the existence of interesting phase\ntransitions and non-locality in the holographic theory. In particular, while\neach screen encodes its corresponding static patch, we show that the\nentanglement wedge of the screen with the larger quantum area extends and\ncovers the causal diamond between the screens, with a phase transition\noccurring when the quantum areas of the screens become equal. We argue that the\ncapacity of the screens to encode the region between them is lost, when these\nare pushed further in the static patches of the observers and placed on\nstretched horizons.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:38:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12862","submitter":"Shuqin Gao","authors":"Shuqin Gao, Costas A. Courcoubetis and Lingjie Duan","title":"Average-Case Analysis of Greedy Matching for Large-Scale D2D Resource\n  Sharing","comments":"Accepted by IEEE Transactions on Mobile Computing. arXiv admin note:\n  substantial text overlap with arXiv:2107.12581","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given the proximity of many wireless users and their diversity in consuming\nlocal resources (e.g., data-plans, computation and energy resources),\ndevice-to-device (D2D) resource sharing is a promising approach towards\nrealizing a sharing economy. This paper adopts an easy-to-implement greedy\nmatching algorithm with distributed fashion and only sub-linear O(log n)\nparallel complexity (in user number n) for large-scale D2D sharing. Practical\ncases indicate that the greedy matching's average performance is far better\nthan the worst-case approximation ratio 50% as compared to the optimum.\nHowever, there is no rigorous average-case analysis in the literature to back\nup such encouraging findings and this paper is the first to present such\nanalysis for multiple representative classes of graphs. For 1D linear networks,\nwe prove that our greedy algorithm performs better than 86.5% of the optimum.\nFor 2D grids, though dynamic programming cannot be directly applied, we still\nprove this average performance ratio to be above 76%. For the more challenging\nErdos-Renyi random graphs, we equivalently reduce to the asymptotic analysis of\nrandom trees and successfully prove a ratio up to 79%. Finally, we conduct\nexperiments using real data to simulate realistic D2D networks, and show that\nour analytical performance measure approximates well practical cases.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:39:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12863","submitter":"Simin Li","authors":"Simin Li, Shuing Zhang, Gujun Chen, Dong Wang, Pu Feng, Jiakai Wang,\n  Aishan Liu, Xin Yi, Xianglong Liu","title":"Towards Benchmarking and Assessing Visual Naturalness of Physical World\n  Adversarial Attacks","comments":null,"journal-ref":"CVPR 2023","doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Physical world adversarial attack is a highly practical and threatening\nattack, which fools real world deep learning systems by generating conspicuous\nand maliciously crafted real world artifacts. In physical world attacks,\nevaluating naturalness is highly emphasized since human can easily detect and\nremove unnatural attacks. However, current studies evaluate naturalness in a\ncase-by-case fashion, which suffers from errors, bias and inconsistencies. In\nthis paper, we take the first step to benchmark and assess visual naturalness\nof physical world attacks, taking autonomous driving scenario as the first\nattempt. First, to benchmark attack naturalness, we contribute the first\nPhysical Attack Naturalness (PAN) dataset with human rating and gaze. PAN\nverifies several insights for the first time: naturalness is (disparately)\naffected by contextual features (i.e., environmental and semantic variations)\nand correlates with behavioral feature (i.e., gaze signal). Second, to\nautomatically assess attack naturalness that aligns with human ratings, we\nfurther introduce Dual Prior Alignment (DPA) network, which aims to embed human\nknowledge into model reasoning process. Specifically, DPA imitates human\nreasoning in naturalness assessment by rating prior alignment and mimics human\ngaze behavior by attentive prior alignment. We hope our work fosters researches\nto improve and automatically assess naturalness of physical world attacks. Our\ncode and dataset can be found at https://github.com/zhangsn-19/PAN.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:40:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12864","submitter":"Nirbhay Patil","authors":"Nirbhay Patil, Jean-Pierre Nadal, Jean-Philippe Bouchaud","title":"Income Inequalities Increase with City Size: Evidence from French Data","comments":"11 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyse the income distributions of cities in France and the scaling of\nthe income of different deciles as a function of the population. We find a\nsignificant difference in the scaling exponents for the richer and poorer parts\nof the population, implying an unequivocal rise in inequalities in larger\ncities, made worse by living costs that are disproportionately higher for the\npoor. We find that the distribution of revenues of cities in France has a\nuniversal, Gumbel-like form, with mean and variance growing with the logarithm\nof population. We show how this result directly implies different income\nscaling exponents as a function of decile. We also study the spatial\ncorrelations of income and population, which decay exponentially with distance.\nWe find that large cities are not more income-segregated than small cities.\nFinally, we search for couplings between social and economic factors, like age\nand income, and propose a toy model that reproduces some of our observations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:43:17 GMT"},{"version":"v2","created":"Thu, 1 Jun 2023 14:54:40 GMT"},{"version":"v3","created":"Sun, 4 Jun 2023 20:28:22 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.12865","submitter":"Weisong Sun","authors":"Weisong Sun, Chunrong Fang, Yudu You, Yun Miao, Yi Liu, Yuekang Li,\n  Gelei Deng, Shenghan Huang, Yuchen Chen, Quanjun Zhang, Hanwei Qian, Yang\n  Liu, Zhenyu Chen","title":"Automatic Code Summarization via ChatGPT: How Far Are We?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SE cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To support software developers in understanding and maintaining programs,\nvarious automatic code summarization techniques have been proposed to generate\na concise natural language comment for a given code snippet. Recently, the\nemergence of large language models (LLMs) has led to a great boost in the\nperformance of natural language processing tasks. Among them, ChatGPT is the\nmost popular one which has attracted wide attention from the software\nengineering community. However, it still remains unclear how ChatGPT performs\nin (automatic) code summarization. Therefore, in this paper, we focus on\nevaluating ChatGPT on a widely-used Python dataset called CSN-Python and\ncomparing it with several state-of-the-art (SOTA) code summarization models.\nSpecifically, we first explore an appropriate prompt to guide ChatGPT to\ngenerate in-distribution comments. Then, we use such a prompt to ask ChatGPT to\ngenerate comments for all code snippets in the CSN-Python test set. We adopt\nthree widely-used metrics (including BLEU, METEOR, and ROUGE-L) to measure the\nquality of the comments generated by ChatGPT and SOTA models (including NCS,\nCodeBERT, and CodeT5). The experimental results show that in terms of BLEU and\nROUGE-L, ChatGPT's code summarization performance is significantly worse than\nall three SOTA models. We also present some cases and discuss the advantages\nand disadvantages of ChatGPT in code summarization. Based on the findings, we\noutline several open challenges and opportunities in ChatGPT-based code\nsummarization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:43:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12866","submitter":"Robert Woodward","authors":"Andrew Lord, Robert Woodward, Shinya Murai, Hideaki Sato, James Dynes,\n  Paul Wright, Catherine White, Russell Davey, Mark Wilkinson, Piers\n  Clinton-Tarestad, Ian Hawkins, Kristopher Farrington, Andrew Shields","title":"London quantum-secured metro network","comments":"https://opg.optica.org/abstract.cfm?uri=OFC-2023-W4K.4","journal-ref":"Optical Fiber Communication Conference (OFC) 2023, Technical\n  Digest Series (Optica Publishing Group, 2023), paper W4K.4","doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We describe a London Quantum-Secured Metro Network using Quantum Key\nDistribution between three London nodes together with customer access tails.\nThe commercially- eady solution is fully integrated into the BT network and\non-boarded its first customer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:44:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12867","submitter":"David K\\\"onen","authors":"David K\\\"onen and Michael Stiglmayr","title":"An output-polynomial time algorithm to determine all supported efficient\n  solutions for multi-objective integer network flow problems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper addresses the problem of enumerating all supported efficient\nsolutions for a linear multi-objective integer minimum cost flow problem\n(MOIMCF).\n  First, we highlight an inconsistency in various definitions of supported\nnondominated vectors for multi-objective integer linear programs (MOILP).\nSeveral characterizations for supported nondominated vectors/efficient\nsolutions are used in the literature, which are equivalent in the non-integer\ncase. However, they may lead to different sets of supported nondominated\nvectors/efficient solutions for MOILPs. This motivates us to summarize\nequivalent definitions and characterizations for supported efficient solutions\nand to distinguish between supported and weakly supported efficient solutions.\n  In this paper we derive an output-polynomial time algorithm to determine all\nsupported efficient solutions for MOIMCF problems.\n  This is the first approach that solves this general problem in\noutput-polynomial time.\n  Moreover, we prove that the existence of an output-polynomial time algorithm\nto determine all weakly supported nondominated vectors (or all weakly supported\nefficient solutions) for a MOIMCF problem with a fixed number of d>3 objectives\ncan be excluded, unless P = NP.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:45:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12868","submitter":"Wei Xue","authors":"Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, Yike Guo","title":"NAS-FM: Neural Architecture Search for Tunable and Interpretable Sound\n  Synthesis based on Frequency Modulation","comments":null,"journal-ref":"IJCAI 2023","doi":null,"report-no":null,"categories":"cs.SD cs.AI cs.CL cs.LG cs.MM eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Developing digital sound synthesizers is crucial to the music industry as it\nprovides a low-cost way to produce high-quality sounds with rich timbres.\nExisting traditional synthesizers often require substantial expertise to\ndetermine the overall framework of a synthesizer and the parameters of\nsubmodules. Since expert knowledge is hard to acquire, it hinders the\nflexibility to quickly design and tune digital synthesizers for diverse sounds.\nIn this paper, we propose ``NAS-FM'', which adopts neural architecture search\n(NAS) to build a differentiable frequency modulation (FM) synthesizer. Tunable\nsynthesizers with interpretable controls can be developed automatically from\nsounds without any prior expert knowledge and manual operating costs. In\ndetail, we train a supernet with a specifically designed search space,\nincluding predicting the envelopes of carriers and modulators with different\nfrequency ratios. An evolutionary search algorithm with adaptive oscillator\nsize is then developed to find the optimal relationship between oscillators and\nthe frequency ratio of FM. Extensive experiments on recordings of different\ninstrument sounds show that our algorithm can build a synthesizer fully\nautomatically, achieving better results than handcrafted synthesizers. Audio\nsamples are available at https://nas-fm.github.io/.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:46:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12869","submitter":"Bauyrzhan Sartayev","authors":"B.K. Sartayev","title":"Some generalizations of the variety of transposed Poisson algebras","comments":"7 p, changed the title","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is shown that the variety of transposed Poisson algebras coincides with\nthe variety of Gelfand-Dorfman algebras in which the Novikov multiplication is\ncommutative. The Grobner-Shirshov basis for the transposed Poisson operad is\ncalculated up to degree 4. Furthermore, we demonstrate that transposed Poisson\nalgebras are F-manifolds. We verify that the special identities of the variety\nof GD-algebras hold in transposed Poisson algebras. Finally, we propose a\nconjecture stating that transposed Poisson algebras are special, i.e., can be\nembedded into a differential Poisson algebra.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:48:58 GMT"},{"version":"v2","created":"Mon, 29 May 2023 14:16:59 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12870","submitter":"Yuxin Jiang","authors":"Yuxin Jiang, Chunkit Chan, Mingyang Chen, Wei Wang","title":"Lion: Adversarial Distillation of Closed-Source Large Language Model","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The practice of transferring knowledge from a sophisticated, closed-source\nlarge language model (LLM) to a compact, open-source LLM has garnered\nconsiderable attention. Previous works have focused on a unidirectional\nknowledge distillation way by aligning the responses of the student model with\nthose of the teacher model to a set of instructions. Nevertheless, they\noverlooked the possibility of incorporating any reciprocal\n\"feedback\"--identifying challenging instructions where the student model's\nperformance falls short--to boost the student model's proficiency iteratively.\nTo this end, we propose a novel adversarial distillation framework for a more\nefficient knowledge transfer. Leveraging the versatile role adaptability of\nLLMs, we prompt the closed-source model to identify \"hard\" instructions and\ngenerate new \"hard\" instructions for the student model, creating a three-stage\nadversarial loop of imitation, discrimination, and generation. By applying this\nadversarial framework, we successfully transfer knowledge from ChatGPT to a 7B\nstudent model (named Lion), achieving nearly 95% capability approximation using\na mere 70k training data. We aspire that this proposed model may serve as the\nbaseline to reflect the performance of ChatGPT, especially the open-source\ninstruction-following language model baseline for our community.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:49:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12871","submitter":"Fabien Casenave","authors":"Fabien Casenave, Brian Staber and Xavier Roynard","title":"MMGP: a Mesh Morphing Gaussian Process-based machine learning method for\n  regression of physical problems under non-parameterized geometrical\n  variability","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  When learning simulations for modeling physical phenomena in industrial\ndesigns, geometrical variabilities are of prime interest. For parameterized\ngeometries, classical regression techniques can be successfully employed.\nHowever, in practice, the shape parametrization is generally not available in\nthe inference stage and we only have access to a mesh discretization. Learning\nmesh-based simulations is challenging and most of the recent advances have been\nrelying on deep graph neural networks in order to overcome the limitations of\nstandard machine learning approaches. While graph neural networks have shown\npromising performances, they still suffer from a few shortcomings, such as the\nneed of large datasets or their inability to provide predictive uncertainties\nout of the shelf. In this work, we propose a machine learning method that do\nnot rely on graph neural networks. Complex geometrical shapes and variations\nwith fixed topology are dealt with using well-known mesh morphing onto a common\nsupport, combined with classical dimensionality reduction techniques and\nGaussian processes. The proposed methodology can easily deal with large meshes,\nwithout knowing any parametrization describing the shape, and provide\npredictive uncertainties, which are of primary importance for decision-making.\nIn the considered numerical experiments, the proposed method is competitive\nwith respect to our implementation of graph neural networks, regarding either\nefficiency of the training and accuracy of the predictions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:50:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12872","submitter":"Simin Li","authors":"Simin Li, Jun Guo, Jingqiao Xiu, Xini Yu, Jiakai Wang, Aishan Liu,\n  Yaodong Yang, Xianglong Liu","title":"Byzantine Robust Cooperative Multi-Agent Reinforcement Learning as a\n  Bayesian Game","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this study, we explore the robustness of cooperative multi-agent\nreinforcement learning (c-MARL) against Byzantine failures, where any agent can\nenact arbitrary, worst-case actions due to malfunction or adversarial attack.\nTo address the uncertainty that any agent can be adversarial, we propose a\nBayesian Adversarial Robust Dec-POMDP (BARDec-POMDP) framework, which views\nByzantine adversaries as nature-dictated types, represented by a separate\ntransition. This allows agents to learn policies grounded on their posterior\nbeliefs about the type of other agents, fostering collaboration with identified\nallies and minimizing vulnerability to adversarial manipulation. We define the\noptimal solution to the BARDec-POMDP as an ex post robust Bayesian Markov\nperfect equilibrium, which we proof to exist and weakly dominates the\nequilibrium of previous robust MARL approaches. To realize this equilibrium, we\nput forward a two-timescale actor-critic algorithm with almost sure convergence\nunder specific conditions. Experimentation on matrix games, level-based\nforaging and StarCraft II indicate that, even under worst-case perturbations,\nour method successfully acquires intricate micromanagement skills and\nadaptively aligns with allies, demonstrating resilience against non-oblivious\nadversaries, random allies, observation-based attacks, and transfer-based\nattacks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:50:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12873","submitter":"Joaquim Martin","authors":"Joaquim Mart\\'in and Walter A. Ortiz","title":"A note on rearrangement Poincar\\'e inequalities and the doubling\n  condition","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce Poincar\\'e type inequalities based on rearrangement invariant\nspaces in the setting of metric measure spaces and analyze when they imply the\ndoubling condition on the underline measure.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:52:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12874","submitter":"Ricky Hutchins","authors":"Ricky Hutchins, Olga Maleva","title":"On the structural decomposition of planar Lipschitz quotient mappings","comments":null,"journal-ref":"Pure and Applied Functional Analysis 2023","doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that for each fixed non-constant complex polynomial $P$ of the plane\nthere exists a homeomorphism $h$ such that $P\\circ h$ is a Lipschitz quotient\nmapping. This corrects errors in the construction given earlier by Johnson et.\nal. [Michigan Math. J. $\\textbf{47}$ (2000), 15-31]. Further we introduce a\nstronger notion of pointwise co-Lipschitzness and characterise its equivalence\nto the standard pointwise definition whilst also highlighting its relevance to\na long-standing conjecture concerning Lipschitz quotient mappings\n$\\mathbb{R}^n\\to\\mathbb{R}^n, n\\geq 3$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:54:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12875","submitter":"Damien Querlioz","authors":"Fadi Jebali, Atreya Majumdar, Cl\\'ement Turck, Kamel-Eddine Harabi,\n  Mathieu-Coumba Faye, Eloi Muhr, Jean-Pierre Walder, Oleksandr Bilousov,\n  Amadeo Michaud, Elisa Vianello, Tifenn Hirtzlin, Fran\\c{c}ois Andrieu, Marc\n  Bocquet, St\\'ephane Collin, Damien Querlioz, Jean-Michel Portal","title":"Powering AI at the Edge: A Robust, Memristor-based Binarized Neural\n  Network with Near-Memory Computing and Miniaturized Solar Cell","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.ET","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Memristor-based neural networks provide an exceptional energy-efficient\nplatform for artificial intelligence (AI), presenting the possibility of\nself-powered operation when paired with energy harvesters. However, most\nmemristor-based networks rely on analog in-memory computing, necessitating a\nstable and precise power supply, which is incompatible with the inherently\nunstable and unreliable energy harvesters. In this work, we fabricated a robust\nbinarized neural network comprising 32,768 memristors, powered by a miniature\nwide-bandgap solar cell optimized for edge applications. Our circuit employs a\nresilient digital near-memory computing approach, featuring complementarily\nprogrammed memristors and logic-in-sense-amplifier. This design eliminates the\nneed for compensation or calibration, operating effectively under diverse\nconditions. Under high illumination, the circuit achieves inference performance\ncomparable to that of a lab bench power supply. In low illumination scenarios,\nit remains functional with slightly reduced accuracy, seamlessly transitioning\nto an approximate computing mode. Through image classification neural network\nsimulations, we demonstrate that misclassified images under low illumination\nare primarily difficult-to-classify cases. Our approach lays the groundwork for\nself-powered AI and the creation of intelligent sensors for various\napplications in health, safety, and environment monitoring.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:56:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12876","submitter":"Kezhou Lin","authors":"Kezhou Lin, Xiaohan Wang, Linchao Zhu, Ke Sun, Bang Zhang, Yi Yang","title":"Gloss-Free End-to-End Sign Language Translation","comments":"ACL 2023 Main Conference (Oral)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we tackle the problem of sign language translation (SLT)\nwithout gloss annotations. Although intermediate representation like gloss has\nbeen proven effective, gloss annotations are hard to acquire, especially in\nlarge quantities. This limits the domain coverage of translation datasets, thus\nhandicapping real-world applications. To mitigate this problem, we design the\nGloss-Free End-to-end sign language translation framework (GloFE). Our method\nimproves the performance of SLT in the gloss-free setting by exploiting the\nshared underlying semantics of signs and the corresponding spoken translation.\nCommon concepts are extracted from the text and used as a weak form of\nintermediate representation. The global embedding of these concepts is used as\na query for cross-attention to find the corresponding information within the\nlearned visual features. In a contrastive manner, we encourage the similarity\nof query results between samples containing such concepts and decrease those\nthat do not. We obtained state-of-the-art results on large-scale datasets,\nincluding OpenASL and How2Sign. The code and model will be available at\nhttps://github.com/HenryLittle/GloFE.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:57:43 GMT"},{"version":"v2","created":"Sat, 27 May 2023 16:43:18 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12877","submitter":"Piotr Kokocki","authors":"Aleksander \\'Cwiszewski, Piotr Kokocki","title":"Standing Waves for Schr\\\"{o}dinger Equations with Kato-Rellich\n  potentials","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show the existence of standing waves for the nonlinear Schr\\\"{o}dinger\nequation with Kato-Rellich type potential. We consider both resonant with the\nnonlinearity satisfying one of Landesman-Lazer type or sign conditions and\nnon-resonant case where the linearization at infinity has zero kernel. The\napproach relies on the geometric and topological analysis of the parabolic\nsemiflow associated to the involved elliptic problem. Tail estimates techniques\nand spectral theory of unbounded linear operators are used to exploit subtle\ncompactness properties necessary for use of the Conley index theory due to\nRybakowski.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:58:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12878","submitter":"Guangsheng Bao","authors":"Guangsheng Bao, Zhiyang Teng, Yue Zhang","title":"Non-Autoregressive Document-Level Machine Translation (NA-DMT):\n  Exploring Effective Approaches, Challenges, and Opportunities","comments":"6 pages, 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Non-autoregressive translation (NAT) models have been extensively\ninvestigated within the context of sentence-level machine translation (MT)\ntasks, demonstrating comparable quality and superior translation speed when\ncontrasted with autoregressive translation (AT) models. However, the challenges\nassociated with multi-modality and alignment issues within NAT models become\nmore prominent when increasing input and output length, leading to unexpected\ncomplications in document-level MT. In this paper, we conduct a comprehensive\nexamination of typical NAT models in the context of document-level MT tasks.\nExperiments reveal that, although NAT models significantly accelerate text\ngeneration on documents, they do not perform as effectively as on sentences. To\nbridge this performance gap, we introduce a novel design that underscores the\nimportance of sentence-level alignment for non-autoregressive document-level\nmachine translation (NA-DMT). This innovation substantially reduces the\nperformance discrepancy. However, it is worth noting that NA-DMT models are\nstill far from perfect and may necessitate additional research to fully\noptimize their performance. We delve into the related opportunities and\nchallenges and provide our code at https://github.com/baoguangsheng/nat-on-doc\nto stimulate further research in this field.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:59:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12879","submitter":"Andrei Agrachev","authors":"Andrei Agrachev","title":"\"Good Lie Brackets\" for Control Affine Systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We consider a smooth system of the form $\\dot q=f_0(q)+\\sum\\limits_{i=1}^k\nu_i f_i(q)$, $q\\in M,\\ u_i\\in\\mathbb R,$ and study controllability issues on\nthe group of diffeomorphisms of $M$. It is well-known that the system can\narbitrarily well approximate the movement in the direction of any Lie bracket\npolynomial of $f_1,\\ldots,f_k$. Any Lie bracket polynomial of $f_1,\\ldots,f_k$\nis good in this sense. Moreover, some combinations of Lie brackets which\ninvolve the drift term $f_0$ are also good but surely not all of them. In this\npaper we try to characterize good ones and, in particular, all universal good\ncombinations, which are good for any nilpotent truncation of any system.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:00:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12880","submitter":"Philipp Sadler","authors":"Philipp Sadler, Sherzod Hakimov and David Schlangen","title":"Yes, this Way! Learning to Ground Referring Expressions into Actions\n  with Intra-episodic Feedback from Supportive Teachers","comments":"5 pages, Accepted at Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ability to pick up on language signals in an ongoing interaction is\ncrucial for future machine learning models to collaborate and interact with\nhumans naturally. In this paper, we present an initial study that evaluates\nintra-episodic feedback given in a collaborative setting. We use a referential\nlanguage game as a controllable example of a task-oriented collaborative joint\nactivity. A teacher utters a referring expression generated by a well-known\nsymbolic algorithm (the \"Incremental Algorithm\") as an initial instruction and\nthen monitors the follower's actions to possibly intervene with intra-episodic\nfeedback (which does not explicitly have to be requested). We frame this task\nas a reinforcement learning problem with sparse rewards and learn a follower\npolicy for a heuristic teacher. Our results show that intra-episodic feedback\nallows the follower to generalize on aspects of scene complexity and performs\nbetter than providing only the initial statement.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:01:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12881","submitter":"Jiazhi Guan","authors":"Jiazhi Guan, Tianshu Hu, Hang Zhou, Zhizhi Guo, Lirui Deng, Chengbin\n  Quan, Errui Ding, Youjian Zhao","title":"Building an Invisible Shield for Your Portrait against Deepfakes","comments":"under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The issue of detecting deepfakes has garnered significant attention in the\nresearch community, with the goal of identifying facial manipulations for abuse\nprevention. Although recent studies have focused on developing generalized\nmodels that can detect various types of deepfakes, their performance is not\nalways be reliable and stable, which poses limitations in real-world\napplications. Instead of learning a forgery detector, in this paper, we propose\na novel framework - Integrity Encryptor, aiming to protect portraits in a\nproactive strategy. Our methodology involves covertly encoding messages that\nare closely associated with key facial attributes into authentic images prior\nto their public release. Unlike authentic images, where the hidden messages can\nbe extracted with precision, manipulating the facial attributes through\ndeepfake techniques can disrupt the decoding process. Consequently, the\nmodified facial attributes serve as a mean of detecting manipulated images\nthrough a comparison of the decoded messages. Our encryption approach is\ncharacterized by its brevity and efficiency, and the resulting method exhibits\na good robustness against typical image processing traces, such as image\ndegradation and noise. When compared to baselines that struggle to detect\ndeepfakes in a black-box setting, our method utilizing conditional encryption\nshowcases superior performance when presented with a range of different types\nof forgeries. In experiments conducted on our protected data, our approach\noutperforms existing state-of-the-art methods by a significant margin.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:01:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12882","submitter":"Dmitry Kobyakov","authors":"Dmitry Kobyakov","title":"On the screening condition in the core of neutron stars","comments":"4 pages, 4 figures. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"nucl-th astro-ph.HE astro-ph.SR cond-mat.supr-con","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The screening condition in neutron star core has been formulated as equality\nof velocities of superconducting protons and the electrons\n$\\mathbf{v}_p=\\mathbf{u}_e$ at wavenumbers $q\\ll\\lambda^{-1}$ ($\\lambda$ is the\nLondon depth) and has been used to derive the force between the electronic flow\npast the flux tube, which has astrophysical applications. By calculating the\ncurrent-current response, I find that $\\mathbf{v}_p\\neq\\mathbf{u}_e$ for\n$l^{-1}<q\\ll\\lambda^{-1}$ ($l$ is the electron mean free path) at typical\nrealistic parameters. Therefore, the momentum exchange between the electrons\nand the flux tubes in the core of neutron stars remains an open question.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:03:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12883","submitter":"Sokbae Lee","authors":"Sungyoon Lee, Sokbae Lee","title":"The Mean Squared Error of the Ridgeless Least Squares Estimator under\n  General Assumptions on Regression Errors","comments":"18 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST cs.LG econ.EM stat.ML stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In recent years, there has been a significant growth in research focusing on\nminimum $\\ell_2$ norm (ridgeless) interpolation least squares estimators.\nHowever, the majority of these analyses have been limited to a simple\nregression error structure, assuming independent and identically distributed\nerrors with zero mean and common variance, independent of the feature vectors.\nAdditionally, the main focus of these theoretical analyses has been on the\nout-of-sample prediction risk. This paper breaks away from the existing\nliterature by examining the mean squared error of the ridgeless interpolation\nleast squares estimator, allowing for more general assumptions about the\nregression errors. Specifically, we investigate the potential benefits of\noverparameterization by characterizing the mean squared error in a finite\nsample. Our findings reveal that including a large number of unimportant\nparameters relative to the sample size can effectively reduce the mean squared\nerror of the estimator. Notably, we establish that the estimation difficulties\nassociated with the variance term can be summarized through the trace of the\nvariance-covariance matrix of the regression errors.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:04:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12884","submitter":"Monalisa Chatterjee","authors":"Monalisa Chatterjee, Manoranjan Kumar, and Zolt\\'an G. Soos","title":"Singlet quantum phases and magnetization of the frustrated spin-1/2\n  ladder with ferromagnetic (F) exchange in legs and alternating F-AF exchange\n  in rungs","comments":"6 pages, 4 figues","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The magnetization $M(h)$ is used to identify three singlet quantum phases of\nthe ladder with isotropic exchange interactions. The Dimer phase with\nfrustrated F exchanges in rungs and legs has a first-order $M(h)$ transition at\n$0$ K from singlet to ferromagnetic at the saturation field $h_s$. The\nHaldane-DAF phase with strong F exchange in rungs and net AF exchange between\nrungs has continuous $M(h)$ and is adiabatically connected to the $S = 1$\nHeisenberg AF chain. The AF phase with strong F exchange in legs and net AF\nexchange between legs has continuous $M(h)$ and is adiabatically connected to\nthe spin-1/2 $J_1-J_2$ model with $J_1 > 0$ and $J_2 < 0$. All three singlet\nphases have finite gaps to the lowest triplet state.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:08:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12885","submitter":"Raphael Bennett-Tennenhaus","authors":"Raphael Bennett-Tennenhaus","title":"String algebras over local rings: admissibility and biseriality","comments":"28 pages, comments welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA math.RT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  For a path algebra over a (noetherian) local ground ring the notion of an\nadmissible ideal was defined by Raggi-C\\'ardenas and Salmer\\'on. We provide\nsufficient conditions for admissibility and use them to study semiperfect\nmodule-finite algebras over local rings whose quotient by the radical is a\nproduct of copies of the residue field. We define string algebras over local\nground rings and recover the notion introduced by Butler and Ringel when the\nground ring is a field. We prove they are biserial in a sense of Kiri\\v{c}enko\nand Kostyukevich. We describe the syzygies of uniserial summands of the\nradical. We give examples string algebras which arise as B\\\"{a}ckstr\\\"{o}m\norders over discrete valuation rings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:09:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12886","submitter":"Konstantinos Chatzilygeroudis","authors":"Dionis Totsila, Konstantinos Chatzilygeroudis, Denis Hadjivelichkov,\n  Valerio Modugno, Ioannis Hatzilygeroudis, Dimitrios Kanoulas","title":"End-to-End Stable Imitation Learning via Autonomous Neural Dynamic\n  Policies","comments":"6 pages, 7 figures, Accepted at the Life-Long Learning with Human\n  Help(L3H2) ICRA 2023 Workshop","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.AI cs.LG math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  State-of-the-art sensorimotor learning algorithms offer policies that can\noften produce unstable behaviors, damaging the robot and/or the environment.\nTraditional robot learning, on the contrary, relies on dynamical system-based\npolicies that can be analyzed for stability/safety. Such policies, however, are\nneither flexible nor generic and usually work only with proprioceptive sensor\nstates. In this work, we bridge the gap between generic neural network policies\nand dynamical system-based policies, and we introduce Autonomous Neural Dynamic\nPolicies (ANDPs) that: (a) are based on autonomous dynamical systems, (b)\nalways produce asymptotically stable behaviors, and (c) are more flexible than\ntraditional stable dynamical system-based policies. ANDPs are fully\ndifferentiable, flexible generic-policies that can be used in imitation\nlearning setups while ensuring asymptotic stability. In this paper, we explore\nthe flexibility and capacity of ANDPs in several imitation learning tasks\nincluding experiments with image observations. The results show that ANDPs\ncombine the benefits of both neural network-based and dynamical system-based\nmethods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:10:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12887","submitter":"Mireille Fares","authors":"Mireille Fares, Catherine Pelachaud, Nicolas Obin","title":"ZS-MSTM: Zero-Shot Style Transfer for Gesture Animation driven by Text\n  and Speech using Adversarial Disentanglement of Multimodal Style Encoding","comments":"arXiv admin note: substantial text overlap with arXiv:2208.01917","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.AI cs.LG cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this study, we address the importance of modeling behavior style in\nvirtual agents for personalized human-agent interaction. We propose a machine\nlearning approach to synthesize gestures, driven by prosodic features and text,\nin the style of different speakers, even those unseen during training. Our\nmodel incorporates zero-shot multimodal style transfer using multimodal data\nfrom the PATS database, which contains videos of diverse speakers. We recognize\nstyle as a pervasive element during speech, influencing the expressivity of\ncommunicative behaviors, while content is conveyed through multimodal signals\nand text. By disentangling content and style, we directly infer the style\nembedding, even for speakers not included in the training phase, without the\nneed for additional training or fine-tuning. Objective and subjective\nevaluations are conducted to validate our approach and compare it against two\nbaseline methods.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:10:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12888","submitter":"Werner Hofmann","authors":"Werner Hofmann and Roberta Zanin","title":"The Cherenkov Telescope Array","comments":"To appear in \"Handbook of X-ray and Gamma-ray Astrophysics\" by\n  Springer (Eds. C. Bambi and A. Santangelo)","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM astro-ph.HE","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The Cherenkov Telescope Array Observatory (CTAO) is a next-generation\nfacility for ground-based very high energy gamma ray astronomy. CTAO will be\noperated as an open observatory. With two sites, in the northern and southern\nhemispheres, the Cherenkov Telescope Array CTA will provide full-sky coverage,\nimproving sensitivity by an order of magnitude over current instruments, with a\nwide gamma ray energy coverage from 20 GeV to 300 TeV. CTA will use telescope\narrays composed of three types of telescopes, optimized to cover different\nenergy ranges. The large telescopes covering the lowest energies provide rapid\nslewing capability, for follow-up of transients. Key Science Projects (KSPs)\nare developed to form a significant part of the CTAO observing program during\nthe first decade of operation, providing legacy data sets such as surveys or\ndeep observations of key targets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:12:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12889","submitter":"Andrea Merlo","authors":"Andrea Merlo, Andrea Pavone, Daniel B\\\"ockenhoff, Ekkehard Pasch, Golo\n  Fuchert, Kai Jakob Brunner, Kian Rahbarnia, Jonathan Schilling, Udo H\\\"ofel,\n  Sehyun Kwak, Jakob Svensson, Thomas Sunn Pedersen, and the W7-X team","title":"Accelerated Bayesian inference of plasma profiles with self-consistent\n  MHD equilibria at W7-X via neural networks","comments":"18 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.plasm-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  High-$\\langle \\beta \\rangle$ operations require a fast and robust inference\nof plasma parameters with a self-consistent MHD equilibrium. Precalculated MHD\nequilibria are usually employed at W7-X due to the high computational cost. To\naddress this, we couple a physics-regularized NN model that approximates the\nideal-MHD equilibrium with the Bayesian modeling framework Minerva. We show the\nfast and robust inference of plasma profiles (electron temperature and density)\nwith a self-consistent MHD equilibrium approximated by the NN model. We\ninvestigate the robustness of the inference across diverse synthetic W7-X\nplasma scenarios. The inferred plasma parameters and their uncertainties are\ncompatible with the parameters inferred using the VMEC, and the inference time\nis reduced by more than two orders of magnitude. This work suggests that MHD\nself-consistent inferences of plasma parameters can be performed between shots.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:15:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12890","submitter":"Marko Stari\\v{c}","authors":"Marko Staric","title":"The TOP counter and determination of bunch-crossing time at Belle II","comments":"4 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ex physics.ins-det","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  At the Belle II experiment a Time-of-Propagation (TOP) counter is used for\nparticle identification in the barrel region. This novel type of particle\nidentification device combines the Cherenkov ring imaging technique with the\ntime-of-flight and therefore it relies on a precise knowledge of the time of\ncollision in each triggered event. We discuss the performance of the counter\nand present a maximum likelihood based method for the determination of event\ncollision time from the measured data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:16:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12891","submitter":"Jun Peng","authors":"Jun Peng and Xing-Hui Feng","title":"Blandford-Znajek Process in Einsteinian Cubic Gravity","comments":"v2: 13 pages, references added","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.HE hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we investigate the Blandford-Znajek (BZ) process within the\nframework of Einsteinian cubic gravity (ECG). To analytically study the BZ\nprocess using the split monopole configuration, we construct a slowly rotating\nblack hole in ECG up to cubic order in small spin, considering the leading\norder in small coupling constant of higher curvature terms. By deriving the\nmagnetosphere solution around the black hole, we determine the BZ power up to\nthe second relative order in spin. The BZ power is modified by the coupling\nconstant compared to Kerr black hole. Although the general nature of the BZ\nprocess in ECG remains unchanged at the leading order in spin, the coupling\nconstant introduces modification at the second relative order in spin.\nTherefore, we anticipate that it is feasible to discern general relativity from\nhigher derivative gravities by examining the BZ power in rapidly rotating black\nholes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:20:22 GMT"},{"version":"v2","created":"Sun, 28 May 2023 14:57:37 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12892","submitter":"Daniel Casanueva-Morato","authors":"Daniel Casanueva-Morato, Alvaro Ayuso-Martinez, Juan P.\n  Dominguez-Morales, Angel Jimenez-Fernandez, Gabriel Jimenez-Moreno, Fernando\n  Perez-Pena","title":"Bio-inspired spike-based Hippocampus and Posterior Parietal Cortex\n  models for robot navigation and environment pseudo-mapping","comments":"24 pages, 10 figures, journal, Neural Networks","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.LG cs.NE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The brain has a great capacity for computation and efficient resolution of\ncomplex problems, far surpassing modern computers. Neuromorphic engineering\nseeks to mimic the basic principles of the brain to develop systems capable of\nachieving such capabilities. In the neuromorphic field, navigation systems are\nof great interest due to their potential applicability to robotics, although\nthese systems are still a challenge to be solved. This work proposes a\nspike-based robotic navigation and environment pseudomapping system formed by a\nbio-inspired hippocampal memory model connected to a Posterior Parietal Cortex\nmodel. The hippocampus is in charge of maintaining a representation of an\nenvironment state map, and the PPC is in charge of local decision-making. This\nsystem was implemented on the SpiNNaker hardware platform using Spiking Neural\nNetworks. A set of real-time experiments was applied to demonstrate the correct\nfunctioning of the system in virtual and physical environments on a robotic\nplatform. The system is able to navigate through the environment to reach a\ngoal position starting from an initial position, avoiding obstacles and mapping\nthe environment. To the best of the authors knowledge, this is the first\nimplementation of an environment pseudo-mapping system with dynamic learning\nbased on a bio-inspired hippocampal memory.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:20:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12893","submitter":"Robert Woodward","authors":"R. S. Tessinari, R. I. Woodward, A. J. Shields","title":"Software-defined quantum network using a QKD-secured SDN controller and\n  encrypted messages","comments":"https://opg.optica.org/abstract.cfm?uri=OFC-2023-W2A.38","journal-ref":"Optical Fiber Communication Conference (OFC) 2023, Technical\n  Digest Series (Optica Publishing Group, 2023), paper W2A.38","doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose and implement a software-defined network architecture that\nintegrates the QKD SDN Controller within the QKD node, enabling it to use\nquantum keys to secure its communication with SDN agents while optimizing\nQKD-keys consumption.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:21:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12894","submitter":"Owen Henkel","authors":"Owen Henkel Libby Hills","title":"Leveraging Human Feedback to Scale Educational Datasets: Combining\n  Crowdworkers and Comparative Judgement","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Machine Learning models have many potentially beneficial applications in\neducation settings, but a key barrier to their development is securing enough\ndata to train these models. Labelling educational data has traditionally relied\non highly skilled raters using complex, multi-class rubrics, making the process\nexpensive and difficult to scale. An alternative, more scalable approach could\nbe to use non-expert crowdworkers to evaluate student work, however,\nmaintaining sufficiently high levels of accuracy and inter-rater reliability\nwhen using non-expert workers is challenging. This paper reports on two\nexperiments investigating using non-expert crowdworkers and comparative\njudgement to evaluate complex student data. Crowdworkers were hired to evaluate\nstudent responses to open-ended reading comprehension questions. Crowdworkers\nwere randomly assigned to one of two conditions: the control, where they were\nasked to decide whether answers were correct or incorrect (i.e., a categorical\njudgement), or the treatment, where they were shown the same question and\nanswers, but were instead asked to decide which of two candidate answers was\nmore correct (i.e., a comparative/preference-based judgement). We found that\nusing comparative judgement substantially improved inter-rater reliability on\nboth tasks. These results are in-line with well-established literature on the\nbenefits of comparative judgement in the field of educational assessment, as\nwell as with recent trends in artificial intelligence research, where\ncomparative judgement is becoming the preferred method for providing human\nfeedback on model outputs when working with non-expert crowdworkers. However,\nto our knowledge, these results are novel and important in demonstrating the\nbeneficial effects of using the combination of comparative judgement and\ncrowdworkers to evaluate educational data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:22:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12895","submitter":"Qizhang Feng","authors":"Qizhang Feng, Ninghao Liu, Fan Yang, Ruixiang Tang, Mengnan Du, Xia Hu","title":"DEGREE: Decomposition Based Explanation For Graph Neural Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Graph Neural Networks (GNNs) are gaining extensive attention for their\napplication in graph data. However, the black-box nature of GNNs prevents users\nfrom understanding and trusting the models, thus hampering their applicability.\nWhereas explaining GNNs remains a challenge, most existing methods fall into\napproximation based and perturbation based approaches with suffer from\nfaithfulness problems and unnatural artifacts, respectively. To tackle these\nproblems, we propose DEGREE \\degree to provide a faithful explanation for GNN\npredictions. By decomposing the information generation and aggregation\nmechanism of GNNs, DEGREE allows tracking the contributions of specific\ncomponents of the input graph to the final prediction. Based on this, we\nfurther design a subgraph level interpretation algorithm to reveal complex\ninteractions between graph nodes that are overlooked by previous methods. The\nefficiency of our algorithm can be further improved by utilizing GNN\ncharacteristics. Finally, we conduct quantitative and qualitative experiments\non synthetic and real-world datasets to demonstrate the effectiveness of DEGREE\non node classification and graph classification tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:29:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12896","submitter":"Reisel Millan Dr.","authors":"Reisel Millan, Estefania Bello-Jurado, Manual Moliner, Mercedes\n  Boronat, Rafael Gomez-Bombarelli","title":"Effect of framework composition and NH3 on the diffusion of Cu+ in\n  Cu-CHA catalysts predicted by machine-learning accelerated molecular dynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.chem-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cu-exchanged zeolites rely on mobile solvated Cu+ cations for their catalytic\nactivity, but the role of framework composition on transport is not fully\nunderstood. Ab initio molecular dynamics simulations can provide quantitative\natomistic insight but are too computationally expensive to explore large\nlength- and time-scales or diverse compositions. We report a machine-learning\ninteratomic potential that accurately reproduces ab initio results and\neffectively generalizes to allow multi-nanosecond simulations of large\nsupercells and diverse chemical compositions. Biased and unbiased simulations\nof [Cu(NH3)2]+ mobility show that aluminum pairing in eight-membered rings\naccelerates local hopping, and demonstrate that increased NH3 concentration\nenhances long-range diffusion. The probability of finding two [Cu(NH3)2]+\ncomplexes in the same cage - key for SCR-NOx reaction - increases with Cu\ncontent and Al content, but does not correlate with the long-range mobility of\nCu+. Supporting experimental evidence was obtained from reactivity tests of\nCu-CHA catalysts with controlled chemical composition.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:31:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12897","submitter":"Raphael Steck","authors":"Raphael Steck","title":"On the edge-Erd\\H{o}s-P\\'{o}sa property of walls","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  I show that walls of size at least $6 \\times 4$ do not have the\nedge-Erd\\H{o}s-P\\'{o}sa property.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:33:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12898","submitter":"Michael Stiglmayr","authors":"Konstantin Kraus and Kathrin Klamroth and Michael Stiglmayr","title":"On the online path extension problem -- Location and routing problems in\n  board games","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.DM","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We consider an online version of a longest path problem in an undirected and\nplanar graph that is motivated by a location and routing problem occurring in\nthe board game \"Turn & Taxis\". Path extensions have to be selected based on\nonly partial knowledge on the order in which nodes become available in later\niterations. Besides board games, online path extension problems have\napplications in disaster relief management when infrastructure has to be\nrebuilt after natural disasters. For example, flooding may affect large parts\nof a road network, and parts of the network may become available only\niteratively and decisions may have to be made without the possibility of\nplanning ahead.\n  We suggest and analyse selection criteria that identify promising nodes\n(locations) for path extensions. We introduce the concept of tentacles of paths\nas an indicator for the future extendability. Different initialization and\nextension heuristics are suggested on compared to an ideal solution that is\nobtained by an integer linear programming formulation assuming complete\nknowledge, i.e., assuming that the complete sequence in which nodes become\navailable is known beforehand. All algorithms are tested and evaluated on the\noriginal \"Turn & Taxis\" graph, and on an extended version of the \"Turn & Taxis\"\ngraph, with different parameter settings. The numerical results confirm that\nthe number of tentacles is a useful criterion when selecting path extensions,\nleading to near-optimal paths at relatively low computational costs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:34:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12899","submitter":"Luc\\'ia Olano-Vegas","authors":"L. Olano-Vegas, I. Pardo, S. Leardini, M. Morales, A. R. Carreira, R.\n  M. Corral, D. Gonz\\'alez-D\\'iaz, A. Tesi, L. Moleri, C. D. R. Azevedo, L.\n  Carramate, F. Guiti\\'an","title":"Development of Fe$_2$O$_3$/YSZ ceramic plates for cryogenic operation of\n  resistive-protected gaseous detectors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ins-det","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a ceramic material based on hematite (Fe$_2$O$_3$) and zirconia\nstabilized with yttria at 8% molar (YSZ), that exhibits stable electrical\nproperties with transported charge and that can be tuned to the resistivities\nnecessary to induce spark-quenching in gaseous detectors ($\\rho = 10^9-10^{12}$\n$\\Omega \\cdot$cm), from room temperature down to the liquid-vapor coexistence\npoint of nitrogen (77 K). It, thus, allows covering the operating temperatures\nof most immediate interest to gaseous instrumentation. The ceramics have been\nproduced in a region of mass concentrations far from what has been usually\nexplored in literature: optimal characteristics are achieved for Fe$_2$O$_3$\nconcentrations of 75%wt (LAr boiling temperature), 35%wt (LXe boiling\ntemperature), and 100%wt (room temperature). The nine order of magnitude\nenhancement observed for the electrical conductivity of the mixed phases\nrelative to that of pure Fe$_2$O$_3$ is startling, however it can be\nqualitatively understood based on existing literature. Plates of 4 cm x 4 cm\nhave been manufactured and, prior to this work, operated in-detector at the LXe\nboiling point (165 K), demonstrating spark-free operation. Preliminary results\nobtained for the first time on a spark-protected amplification structure\n(RP-WELL) at around the LAr boiling point (90 K) are now presented, too.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:34:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12900","submitter":"Jennifer D'Souza","authors":"Jennifer D'Souza, Moussab Hrou and S\\\"oren Auer","title":"Evaluating Prompt-based Question Answering for Object Prediction in the\n  Open Research Knowledge Graph","comments":"14 pages, 1 figure, accepted for publication as a short paper at DEXA\n  2023 (https://www.dexa.org/dexa2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.DL cs.IT math.IT","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  There have been many recent investigations into prompt-based training of\ntransformer language models for new text genres in low-resource settings. The\nprompt-based training approach has been found to be effective in generalizing\npre-trained or fine-tuned models for transfer to resource-scarce settings. This\nwork, for the first time, reports results on adopting prompt-based training of\ntransformers for \\textit{scholarly knowledge graph object prediction}. The work\nis unique in the following two main aspects. 1) It deviates from the other\nworks proposing entity and relation extraction pipelines for predicting objects\nof a scholarly knowledge graph. 2) While other works have tested the method on\ntext genera relatively close to the general knowledge domain, we test the\nmethod for a significantly different domain, i.e. scholarly knowledge, in turn\ntesting the linguistic, probabilistic, and factual generalizability of these\nlarge-scale transformer models. We find that (i) per expectations, transformer\nmodels when tested out-of-the-box underperform on a new domain of data, (ii)\nprompt-based training of the models achieve performance boosts of up to 40\\% in\na relaxed evaluation setting, and (iii) testing the models on a starkly\ndifferent domain even with a clever training objective in a low resource\nsetting makes evident the domain knowledge capture gap offering an\nempirically-verified incentive for investing more attention and resources to\nthe scholarly domain in the context of transformer models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:35:18 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12901","submitter":"Yu-Shan Tai","authors":"Yu-Shan Tai, Ming-Guang Lin, and An-Yeu (Andy) Wu","title":"TSPTQ-ViT: Two-scaled post-training quantization for vision transformer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Vision transformers (ViTs) have achieved remarkable performance in various\ncomputer vision tasks. However, intensive memory and computation requirements\nimpede ViTs from running on resource-constrained edge devices. Due to the\nnon-normally distributed values after Softmax and GeLU, post-training\nquantization on ViTs results in severe accuracy degradation. Moreover,\nconventional methods fail to address the high channel-wise variance in\nLayerNorm. To reduce the quantization loss and improve classification accuracy,\nwe propose a two-scaled post-training quantization scheme for vision\ntransformer (TSPTQ-ViT). We design the value-aware two-scaled scaling factors\n(V-2SF) specialized for post-Softmax and post-GeLU values, which leverage the\nbit sparsity in non-normal distribution to save bit-widths. In addition, the\noutlier-aware two-scaled scaling factors (O-2SF) are introduced to LayerNorm,\nalleviating the dominant impacts from outlier values. Our experimental results\nshow that the proposed methods reach near-lossless accuracy drops (<0.5%) on\nthe ImageNet classification task under 8-bit fully quantized ViTs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:35:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12902","submitter":"Chi-Yee Cheung","authors":"Chi-Yee Cheung","title":"Unconditionally secure quantum bit commitment using modified double-slit\n  and unstable particles","comments":"5 pages, no figure","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We note that the proof of the no-go theorem of unconditionally secure quantum\nbit commitment is based on a model which is not universal. For protocols not\ndescribed by the model, this theorem does not apply. Using unstable particles\nand a modified double-slit setup, we construct such a protocol and show that it\nis unconditionally secure. In this protocol, the committer transfers no quantum\nstates to the receiver.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:36:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12903","submitter":"Shentong Mo","authors":"Shentong Mo, Jing Shi, Yapeng Tian","title":"DiffAVA: Personalized Text-to-Audio Generation with Visual Alignment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Text-to-audio (TTA) generation is a recent popular problem that aims to\nsynthesize general audio given text descriptions. Previous methods utilized\nlatent diffusion models to learn audio embedding in a latent space with text\nembedding as the condition. However, they ignored the synchronization between\naudio and visual content in the video, and tended to generate audio mismatching\nfrom video frames. In this work, we propose a novel and personalized\ntext-to-sound generation approach with visual alignment based on latent\ndiffusion models, namely DiffAVA, that can simply fine-tune lightweight\nvisual-text alignment modules with frozen modality-specific encoders to update\nvisual-aligned text embeddings as the condition. Specifically, our DiffAVA\nleverages a multi-head attention transformer to aggregate temporal information\nfrom video features, and a dual multi-modal residual network to fuse temporal\nvisual representations with text embeddings. Then, a contrastive learning\nobjective is applied to match visual-aligned text embeddings with audio\nfeatures. Experimental results on the AudioCaps dataset demonstrate that the\nproposed DiffAVA can achieve competitive performance on visual-aligned\ntext-to-audio generation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:37:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12904","submitter":"Erkko Lehtonen","authors":"Erkko Lehtonen","title":"Near-unanimity-closed minions of Boolean functions","comments":"43 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.RA math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The near-unanimity-closed minions of Boolean functions, i.e., the clonoids\nwhose target algebra contains a near-unanimity function, are completely\ndescribed. The key concept towards this result is the minorant-minor partial\norder and its order ideals.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:37:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12905","submitter":"Christopher Schroeder","authors":"Christopher A. Schroeder","title":"Finite groups with many $p$-regular conjugacy classes","comments":"21 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $G$ be a finite group and let $p$ be a prime. In this paper, we study the\nstructure of finite groups with a large number of $p$-regular conjugacy classes\nor, equivalently, a large number of irreducible $p$-modular representations. We\nprove sharp lower bounds for this number in terms of $p$ and the $p'$-part of\nthe order of $G$ which ensure that $G$ is $p$-solvable. A bound for the\n$p$-length is obtained which is sharp for odd primes. We also prove a new best\npossible criterion for the existence of a normal Sylow $p$-subgroup in terms of\nthese quantities.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:38:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12906","submitter":"BoYang Zheng","authors":"BoYang Zheng","title":"Latent Magic: An Investigation into Adversarial Examples Crafted in the\n  Semantic Latent Space","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Adversarial attacks against Deep Neural Networks(DNN) have been a crutial\ntopic ever since \\cite{goodfellow} purposed the vulnerability of DNNs. However,\nmost prior works craft adversarial examples in the pixel space, following the\n$l_p$ norm constraint. In this paper, we give intuitional explain about why\ncrafting adversarial examples in the latent space is equally efficient and\nimportant. We purpose a framework for crafting adversarial examples in semantic\nlatent space based on an pre-trained Variational Auto Encoder from state-of-art\nStable Diffusion Model\\cite{SDM}. We also show that adversarial examples\ncrafted in the latent space can also achieve a high level of fool rate.\nHowever, examples crafted from latent space are often hard to evaluated, as\nthey doesn't follow a certain $l_p$ norm constraint, which is a big challenge\nfor existing researches. To efficiently and accurately evaluate the adversarial\nexamples crafted in the latent space, we purpose \\textbf{a novel evaluation\nmatric} based on SSIM\\cite{SSIM} loss and fool rate.Additionally, we explain\nwhy FID\\cite{FID} is not suitable for measuring such adversarial examples. To\nthe best of our knowledge, it's the first evaluation metrics that is\nspecifically designed to evaluate the quality of a adversarial attack. We also\ninvestigate the transferability of adversarial examples crafted in the latent\nspace and show that they have superiority over adversarial examples crafted in\nthe pixel space.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:39:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12907","submitter":"Julian Coda-Forno","authors":"Julian Coda-Forno, Marcel Binz, Zeynep Akata, Matthew Botvinick, Jane\n  X. Wang, Eric Schulz","title":"Meta-in-context learning in large language models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models have shown tremendous performance in a variety of\ntasks. In-context learning -- the ability to improve at a task after being\nprovided with a number of demonstrations -- is seen as one of the main\ncontributors to their success. In the present paper, we demonstrate that the\nin-context learning abilities of large language models can be recursively\nimproved via in-context learning itself. We coin this phenomenon\nmeta-in-context learning. Looking at two idealized domains, a one-dimensional\nregression task and a two-armed bandit task, we show that meta-in-context\nlearning adaptively reshapes a large language model's priors over expected\ntasks. Furthermore, we find that meta-in-context learning modifies the\nin-context learning strategies of such models. Finally, we extend our approach\nto a benchmark of real-world regression problems where we observe competitive\nperformance to traditional learning algorithms. Taken together, our work\nimproves our understanding of in-context learning and paves the way toward\nadapting large language models to the environment they are applied purely\nthrough meta-in-context learning rather than traditional finetuning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:40:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12908","submitter":"Miriam Ansch\\\"utz","authors":"Miriam Ansch\\\"utz, Joshua Oehms, Thomas Wimmer, Bart{\\l}omiej\n  Jezierski, Georg Groh","title":"Language Models for German Text Simplification: Overcoming Parallel Data\n  Scarcity through Style-specific Pre-training","comments":"Accepted to ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Automatic text simplification systems help to reduce textual information\nbarriers on the internet. However, for languages other than English, only few\nparallel data to train these systems exists. We propose a two-step approach to\novercome this data scarcity issue. First, we fine-tuned language models on a\ncorpus of German Easy Language, a specific style of German. Then, we used these\nmodels as decoders in a sequence-to-sequence simplification task. We show that\nthe language models adapt to the style characteristics of Easy Language and\noutput more accessible texts. Moreover, with the style-specific pre-training,\nwe reduced the number of trainable parameters in text simplification models.\nHence, less parallel data is sufficient for training. Our results indicate that\npre-training on unaligned data can reduce the required parallel data while\nimproving the performance on downstream tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:41:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12909","submitter":"Jintian Zhu","authors":"Jianchun Chu and Jintian Zhu","title":"A non-spin method to the positive weighted mass theorem for weighted\n  manifolds","comments":"27 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we investigate the weighted mass for weighted manifolds. By\nestablishing a version of density theorem and generalizing Geroch conjecture in\nthe setting of $P$-scalar curvature, we are able to prove the positive weighted\nmass theorem for weighted manifolds, which generalizes the result of\nBaldauf-Ozuch to non-spin manifolds.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:42:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12910","submitter":"Elena Rufeil Fiori","authors":"Elena Rufeil Fiori and Adolfo J. Banchio","title":"Simulation study of integral equation theory for dipolar density\n  interacting disks","comments":"9 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Integral equation theories (IETs) based on the Ornstein-Zernike (OZ) relation\ncan be used as an analytical tool to predict structural and thermodynamic\nproperties and phase behavior of fluids, with low numerical cost. However,\nthere are no studies of the IETs for the dipolar density interaction potential\nin 2D systems, a main inter-domain interaction in lipid monolayers with phase\ncoexistence. This work studies the performance of three closures of the OZ\nequation: Rogers-Young (RY), Modified Hypernetted Chain (MHNC), and Variational\nModified Hypernetted Chain (VMHNC). Two different approximations for the hard\ndisks reference system were considered for the last two closures, which\napproximate the bridge function by that of a reference system: one based on the\nPercus--Yevic approximation (PY), and the other based on an extension of the\nhard spheres Verlet-Weis-Henderson--Grundke parameterization (LB). The accuracy\nof the five approaches is evaluated via direct Monte Carlo simulations, and the\nresults show that there is no major difference in performance between MHNC and\nVMHNC. The reference system has a significant impact on the results. When the\npair correlation function serves as the measure, the LB--based closures\noutperform the PY ones qualitatively. However, the closures based on LB do not\nhave a solution for all studied interaction strength parameters, limiting their\napplicability. On the other hand, RY is satisfactory only for low interaction\nstrength regimes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:44:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12911","submitter":"Kwassi Anani","authors":"Anani Kwassi","title":"Analytical approximations in short times of exact operational solutions\n  to reaction diffusion problems on bounded intervals","comments":"19 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP cs.NA math.NA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper aims at obtaining, by means of integral transforms, analytical\napproximations in short times of solutions to boundary value problems for the\none-dimensional reaction-diffusion equation with constant coefficients. The\ngeneral form of the equation is considered on a bounded generic interval and\nthe three classical types of boundary conditions, i.e., Dirichlet as well as\nNeumann and mixed boundary conditions are considered in a unified way. The\nFourier and Laplace integral transforms are successively applied and an exact\nsolution is obtained in the Laplace domain. This operational solution is proven\nto be the accurate Laplace transform of the infinite series obtained by the\nFourier decomposition method and presented in the literature as solutions to\nthis type of problem. On the basis of this unified operational solution, four\ncases are distinguished where innovative formulas expressing consistent\nanalytical approximations in short time limits are derived with respect to the\nbehavior of the solution at the boundaries. Compared to the infinite series\nsolutions, the analytical approximations may open new perspectives and\napplications, among which can be noted the improvement of numerical efficiency\nin simulations of one-dimensional moving boundary problems, such as in Stefan\nmodels.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:44:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12912","submitter":"Wujian Peng","authors":"Wujian Peng, Zejia Weng, Hengduo Li and Zuxuan Wu","title":"BMB: Balanced Memory Bank for Imbalanced Semi-supervised Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Exploring a substantial amount of unlabeled data, semi-supervised learning\n(SSL) boosts the recognition performance when only a limited number of labels\nare provided. However, traditional methods assume that the data distribution is\nclass-balanced, which is difficult to achieve in reality due to the long-tailed\nnature of real-world data. While the data imbalance problem has been\nextensively studied in supervised learning (SL) paradigms, directly\ntransferring existing approaches to SSL is nontrivial, as prior knowledge about\ndata distribution remains unknown in SSL. In light of this, we propose Balanced\nMemory Bank (BMB), a semi-supervised framework for long-tailed recognition. The\ncore of BMB is an online-updated memory bank that caches historical features\nwith their corresponding pseudo labels, and the memory is also carefully\nmaintained to ensure the data therein are class-rebalanced. Additionally, an\nadaptive weighting module is introduced to work jointly with the memory bank so\nas to further re-calibrate the biased training process. We conduct experiments\non multiple datasets and demonstrate, among other things, that BMB surpasses\nstate-of-the-art approaches by clear margins, for example 8.2$\\%$ on the 1$\\%$\nlabeled subset of ImageNet127 (with a resolution of 64$\\times$64) and 4.3$\\%$\non the 50$\\%$ labeled subset of ImageNet-LT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:52:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12913","submitter":"Alexey Matveev Prof.","authors":"Valerii Chernov, Alexey Matveev","title":"Geometric Facts Underlying Algorithms of Robot Navigation for Tight\n  Circumnavigation of Group Objects through Singular Inter-Object Gaps","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  An underactuated nonholonomic Dubins-vehicle-like robot with a lower-limited\nturning radius travels with a constant speed in a plane, which hosts unknown\ncomplex objects. The robot has to approach and then circumnavigate all objects,\nwith maintaining a given distance to the currently nearest of them. So the\nideal targeted path is the equidistant curve of the entire set of objects. The\nfocus is on the case where this curve cannot be perfectly traced due to\nexcessive contortions and singularities. So the objective shapes into that of\nautomatically finding, approaching and repeatedly tracing an approximation of\nthe equidistant curve that is the best among those trackable by the robot. The\npaper presents some geometric facts that are in demand in research on reactive\ntight circumnavigation of group objects in the delineated situation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:52:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12914","submitter":"Omar Ghazal","authors":"Omar Ghazal, Simranjeet Singh, Tousif Rahman, Shengqi Yu, Yujin Zheng,\n  Domenico Balsamo, Sachin Patkar, Farhad Merchant, Fei Xia, Alex Yakovlev,\n  Rishad Shafik","title":"IMBUE: In-Memory Boolean-to-CUrrent Inference ArchitecturE for Tsetlin\n  Machines","comments":"Accepted at ACM/IEEE International Symposium on Low Power Electronics\n  and Design 2023 (ISLPED 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AR cs.AI cs.ET cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In-memory computing for Machine Learning (ML) applications remedies the von\nNeumann bottlenecks by organizing computation to exploit parallelism and\nlocality. Non-volatile memory devices such as Resistive RAM (ReRAM) offer\nintegrated switching and storage capabilities showing promising performance for\nML applications. However, ReRAM devices have design challenges, such as\nnon-linear digital-analog conversion and circuit overheads. This paper proposes\nan In-Memory Boolean-to-Current Inference Architecture (IMBUE) that uses\nReRAM-transistor cells to eliminate the need for such conversions. IMBUE\nprocesses Boolean feature inputs expressed as digital voltages and generates\nparallel current paths based on resistive memory states. The proportional\ncolumn current is then translated back to the Boolean domain for further\ndigital processing. The IMBUE architecture is inspired by the Tsetlin Machine\n(TM), an emerging ML algorithm based on intrinsically Boolean logic. The IMBUE\narchitecture demonstrates significant performance improvements over binarized\nconvolutional neural networks and digital TM in-memory implementations,\nachieving up to a 12.99x and 5.28x increase, respectively.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:55:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12915","submitter":"Tamoghna Das","authors":"Tamoghna Das","title":"What do the fast dynamics tell us about aggregation?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft cond-mat.stat-mech","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Two typical morphology of two-dimensional aggregates are considered: compact\ncrystalline clusters and string-like non-compact conformations. Simulated\ntrajectories of both types of aggregates are analysed with fine spatial\nresolution. While the long-time geometry of such trajectories appears to be\nstatistically identical for two conformations, the self-overlap statistics\nreveal two distinct short-time {\\em pre-caging} mechanisms. While the\ntime-scale is directly proportional with length-scale for particles in a\ncompact aggregates, an inverse relationship holds for non-compact clusters.\nThese short length-fast time relationship of particle localization might hold\nthe key to the structure-function relationship of aggregate forming systems and\nother non-equilibrium soft materials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:56:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12916","submitter":"Thi-Hoa Nguyen","authors":"Thi-Hoa Nguyen, Ren\\'e R. Hiemstra, Sascha Eisentr\\\"ager, Dominik\n  Schillinger","title":"Towards higher-order accurate mass lumping in explicit isogeometric\n  analysis for structural dynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We present a mass lumping approach based on an isogeometric Petrov-Galerkin\nmethod that preserves higher-order spatial accuracy in explicit dynamics\ncalculations irrespective of the polynomial degree of the spline approximation.\nTo discretize the test function space, our method uses an approximate dual\nbasis, whose functions are smooth, have local support and satisfy approximate\nbi-orthogonality with respect to a trial space of B-splines. The resulting mass\nmatrix is ``close'' to the identity matrix. Specifically, a lumped version of\nthis mass matrix preserves all relevant polynomials when utilized in a Galerkin\nprojection. Consequently, the mass matrix can be lumped (via row-sum lumping)\nwithout compromising spatial accuracy in explicit dynamics calculations. We\naddress the imposition of Dirichlet boundary conditions and the preservation of\napproximate bi-orthogonality under geometric mappings. In addition, we\nestablish a link between the exact dual and approximate dual basis functions\nvia an iterative algorithm that improves the approximate dual basis towards\nexact bi-orthogonality. We demonstrate the performance of our higher-order\naccurate mass lumping approach via convergence studies and spectral analyses of\ndiscretized beam, plate and shell models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:57:01 GMT"},{"version":"v2","created":"Fri, 26 May 2023 18:40:30 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.12917","submitter":"Jing-Ren Zhou","authors":"Tian Lan and Jing-Ren Zhou","title":"Quantum Current and Holographic Categorical Symmetry","comments":"75 pages, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.str-el hep-th math-ph math.MP quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We establish the formulation for quantum current. Given a symmetry group $G$,\nlet $\\mathcal{C}:=\\mathrm{Rep}\\, G$ be its representation category. Physically,\nsymmetry charges are objects of $\\mathcal{C}$ and symmetric operators are\nmorphisms in $\\mathcal{C}$. The addition of charges is given by the tensor\nproduct of representations. For any symmetric operator $O$ crossing two\nsubsystems, the exact symmetry charge transported by $O$ can be extracted. The\nquantum current is defined as symmetric operators that can transport symmetry\ncharges over an arbitrary long distance. A quantum current exactly corresponds\nto an object in the Drinfeld center $Z_1(\\mathcal{C})$. The condition for\nquantum currents to be condensed is also specified. To express the local\nconservation, the internal hom must be used to compute the charge difference,\nand the framework of enriched category is inevitable. To illustrate these\nideas, we develop a rigorous scheme of renormalization in one-dimensional\nlattice systems and analyse the fixed-point models. It is proved that in the\nfixed-point models, condensed quantum currents form a Lagrangian algebra in\n$Z_1(\\mathcal{C})$ and the boundary-bulk correspondence is verified in the\nenriched setting. Overall, the quantum current provides a natural physical\ninterpretation to the holographic categorical symmetry.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:00:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12918","submitter":"Claudio Paonessa","authors":"Claudio Paonessa and Dominik Frefel and Manfred Vogel","title":"Improving Metrics for Speech Translation","comments":"Preprint SwissText 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce Parallel Paraphrasing ($\\text{Para}_\\text{both}$), an\naugmentation method for translation metrics making use of automatic\nparaphrasing of both the reference and hypothesis. This method counteracts the\ntypically misleading results of speech translation metrics such as WER, CER,\nand BLEU if only a single reference is available. We introduce two new datasets\nexplicitly created to measure the quality of metrics intended to be applied to\nSwiss German speech-to-text systems. Based on these datasets, we show that we\nare able to significantly improve the correlation with human quality perception\nif our method is applied to commonly used metrics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:01:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12919","submitter":"Thomas Fernique","authors":"Thomas Fernique","title":"Packing unequal disks in the Euclidean plane","comments":"Survey","journal-ref":null,"doi":null,"report-no":null,"categories":"math.MG cs.CG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A packing of disks in the plane is a set of disks with disjoint interiors.\nThis paper is a survey of some open questions about such packings. It is\norganized into five themes: compacity, conjugacy, density, uniformity and\ncomputability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:03:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12920","submitter":"Aniket Pramanick","authors":"Aniket Pramanick, Yufang Hou, Iryna Gurevych","title":"A Diachronic Analysis of the NLP Research Paradigm Shift: When, How, and\n  Why?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Understanding the fundamental concepts and trends in a scientific field is\ncrucial for keeping abreast of its ongoing development. In this study, we\npropose a systematic framework for analyzing the evolution of research topics\nin a scientific field using causal discovery and inference techniques. By\nconducting extensive experiments on the ACL Anthology corpus, we demonstrate\nthat our framework effectively uncovers evolutionary trends and the underlying\ncauses for a wide range of natural language processing (NLP) research topics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:08:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12921","submitter":"Masamichi Ishihara","authors":"Masamichi Ishihara","title":"Relation between the escort average in microcanonical ensemble and the\n  escort average in canonical ensemble in the Tsallis statistics","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech hep-ph hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We studied the escort averages in microcanonical and canonical ensembles in\nthe Tsallis statistics of entropic parameter $q>1$. The quantity $(q-1)$ is the\nmeasure of the deviation from the Boltzmann-Gibbs statistics. We derived the\nrelation between the escort average in the microcanonical ensemble and the\nescort average in the canonical ensemble. Conditions arise by requiring that\nthe integrals appeared in the canonical ensemble do not diverge. A condition is\nthe relation between the heat capacity $C_V^{\\mathrm{CE}}$ at constant volume\nin the canonical ensemble and the entropic parameter $q$: $0 < (q-1)\nC_V^{\\mathrm{CE}} < 1$. This condition gives the known condition when\n$C_V^{\\mathrm{CE}}$ equals the number of ingredients $N$. With the derived\nrelation, we calculated the energy, the energy fluctuation, and the difference\nbetween the canonical ensemble and the microcanonical ensemble in the\nexpectation value of the square of Hamiltonian. The difference between the\nmicrocanonical ensemble and the canonical ensemble in energy is small because\nof the condition. The heat capacity $C_V^{\\mathrm{CE}}$ and the quantity\n$(q-1)$ are related to the energy fluctuation and the difference. It was shown\nthat the magnitude of the relative difference\n$|(S^{\\mathrm{CE}}_{\\mathrm{R}q}-S^{\\mathrm{ME}}_{\\mathrm{R}q})/S^{\\mathrm{ME}}_{\\mathrm{R}q}|$\nis small when the number of free particles is large, where\n$S^{\\mathrm{ME}}_{\\mathrm{R}q}$ is the R\\'enyi entropy in the microcanonical\nensemble and $S^{\\mathrm{CE}}_{\\mathrm{R}q}$ is the R\\'enyi entropy in the\ncanonical ensemble. The similar result was also obtained for the Tsallis\nentropy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:09:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12922","submitter":"Jaewan Moon","authors":"Jaewan Moon, Hye-young Kim, and Jongwuk Lee","title":"It's Enough: Relaxing Diagonal Constraints in Linear Autoencoders for\n  Recommendation","comments":"Accepted by SIGIR 2023","journal-ref":null,"doi":"10.1145/3539618.3591704","report-no":null,"categories":"cs.IR cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Linear autoencoder models learn an item-to-item weight matrix via convex\noptimization with L2 regularization and zero-diagonal constraints. Despite\ntheir simplicity, they have shown remarkable performance compared to\nsophisticated non-linear models. This paper aims to theoretically understand\nthe properties of two terms in linear autoencoders. Through the lens of\nsingular value decomposition (SVD) and principal component analysis (PCA), it\nis revealed that L2 regularization enhances the impact of high-ranked PCs.\nMeanwhile, zero-diagonal constraints reduce the impact of low-ranked PCs,\nleading to performance degradation for unpopular items. Inspired by this\nanalysis, we propose simple-yet-effective linear autoencoder models using\ndiagonal inequality constraints, called Relaxed Linear AutoEncoder (RLAE) and\nRelaxed Denoising Linear AutoEncoder (RDLAE). We prove that they generalize\nlinear autoencoders by adjusting the degree of diagonal constraints.\nExperimental results demonstrate that our models are comparable or superior to\nstate-of-the-art linear and non-linear models on six benchmark datasets; they\nsignificantly improve the accuracy of long-tail items. These results also\nsupport our theoretical insights on regularization and diagonal constraints in\nlinear autoencoders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:09:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12923","submitter":"Detlev Buchholz","authors":"Detlev Buchholz and Klaus Fredenhagen","title":"Algebraic quantum field theory: objectives, methods, and results","comments":"31 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph hep-th math.MP quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Algebraic quantum field theory is a general mathematical framework for\nrelativistic quantum physics, based on the theory of operator algebras. It\ncomprises all observable and operational aspects of a theory. In its framework\nthe entire state space of a theory is covered, starting from the vacuum over\narbitrary configurations of particles to thermal equilibrium and\nnon-equilibrium states. It provides a solid foundation for structural analysis,\nthe physical interpretation of the theory and the development of new\nconstructive schemes. This survey is commissioned by the Encyclopedia of\nMathematical Physics, edited by M. Bojowald and R.J. Szabo. It is to be\npublished by the Elsevier publishing house.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:11:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12924","submitter":"Frank Mtumbuka","authors":"Frank Mtumbuka and Steven Schockaert","title":"EnCore: Pre-Training Entity Encoders using Coreference Chains","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Entity typing is the task of assigning semantic types to the entities that\nare mentioned in a text. Since obtaining sufficient amounts of manual\nannotations is expensive, current state-of-the-art methods are typically\ntrained on automatically labelled datasets, e.g. by exploiting links between\nWikipedia pages. In this paper, we propose to use coreference chains as an\nadditional supervision signal. Specifically, we pre-train an entity encoder\nusing a contrastive loss, such that entity embeddings of coreferring entities\nare more similar to each other than to the embeddings of other entities. Since\nthis strategy is not tied to Wikipedia, we can pre-train our entity encoder on\nother genres than encyclopedic text and on larger amounts of data. Our\nexperimental results show that the proposed pre-training strategy allows us to\nimprove the state-of-the-art in fine-grained entity typing, provided that only\nhigh-quality coreference links are exploited.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:11:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12925","submitter":"Imtak Jeon","authors":"Alfredo Gonz\\'alez Lezcano, Imtak Jeon, Augniva Ray","title":"Supersymmetry and complexified spectrum on Euclidean AdS$_2$","comments":"6 pages, no figure","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We construct the supersymmetric Hilbert space for scalar and spinor fields on\nEuclidean global AdS$_2$ by complexifying the spectrum of the Dirac operator.\nThen its bosonic and fermionic basis functions are all paired by supersymmetry,\ndelta-function normalizable with an appropriate inner product and compatible\nwith the asymptotic boundary condition demanded by the variational principle.\nIn 1-loop computation, the local part using the heat kernel in this spectrum is\nthe same as the one in the real spectrum, while the global part can differ due\nto the potential zero modes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:12:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12926","submitter":"Christoph Weidenbach","authors":"Martin Bromberger and Chaahat Jain and Christoph Weidenbach","title":"SCL(FOL) Can Simulate Non-Redundant Superposition Clause Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO cs.AI cs.SC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that SCL(FOL) can simulate the derivation of non-redundant clauses by\nsuperposition for first-order logic without equality. Superposition-based\nreasoning is performed with respect to a fixed reduction ordering. The\ncompleteness proof of superposition relies on the grounding of the clause set.\nIt builds a ground partial model according to the fixed ordering, where minimal\nfalse ground instances of clauses then trigger non-redundant superposition\ninferences. We define a respective strategy for the SCL calculus such that\nclauses learned by SCL and superposition inferences coincide. From this\nperspective the SCL calculus can be viewed as a generalization of the\nsuperposition calculus.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:12:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12927","submitter":"Luyao Cheng","authors":"Luyao Cheng, Siqi Zheng, Zhang Qinglin, Hui Wang, Yafeng Chen, Qian\n  Chen","title":"Exploring Speaker-Related Information in Spoken Language Understanding\n  for Better Speaker Diarization","comments":"Accepted to Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Speaker diarization(SD) is a classic task in speech processing and is crucial\nin multi-party scenarios such as meetings and conversations. Current mainstream\nspeaker diarization approaches consider acoustic information only, which result\nin performance degradation when encountering adverse acoustic conditions. In\nthis paper, we propose methods to extract speaker-related information from\nsemantic content in multi-party meetings, which, as we will show, can further\nbenefit speaker diarization. We introduce two sub-tasks, Dialogue Detection and\nSpeaker-Turn Detection, in which we effectively extract speaker information\nfrom conversational semantics. We also propose a simple yet effective algorithm\nto jointly model acoustic and semantic information and obtain\nspeaker-identified texts. Experiments on both AISHELL-4 and AliMeeting datasets\nshow that our method achieves consistent improvements over acoustic-only\nspeaker diarization systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:14:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12928","submitter":"Dmitry Vasilyev Dr.","authors":"Dmitry Vasilyev","title":"Thermal expansion anisotropy of the Fe23Mo16 and Fe7Mo6 Mu-phases\n  predicted from first-principles calculations","comments":"28 pages, 13 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The intermetallic Mn-phase, which precipitates in steels and superalloys, can\nnoticeably soften the mechanical properties of their matrix. Despite the\nimportance of developing superalloys and steels, the thermodynamic properties\nand directions of thermal expansion of the Mu-phase are still poorly studied.\nIn this work, the thermal expansion paths, elastic, thermal and thermodynamic\nproperties of the Fe23Mo16 and Fe7Mo6 Mu-phases have been studied using\nfirst-principles based quasi-harmonic Debye-Gruneisen approach. A method\nallowing avoids differentiation in many variables is used. The free energies\nconsisting of the electronic, vibrational and magnetic energy contributions,\ncalculated along different paths of thermal expansions were compared between\nthemselves. A path with the least free energy was chosen as the trajectory of\nthermal expansion. Negative thermal expansion of the Fe7Mo6 compound was\npredicted, while the Fe23Mo16 has a conventional thermal expansion and negative\nTEC in the parameter c. The thermal expansions of both these compounds are not\nisotropic. The elastic constants, modulus, heat capacities, Curie and Debye\ntemperatures were predicted. The obtained results satisfactorily agree with the\navailable experimental data. Physical factors affecting the stability of\nFe23Mo16 and Fe7Mo6 have been studied. The paper presents an essential feature\nof thermal expansions of the Mu-phase of the Fe-Mo system, which can provide an\ninsight into future developments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:23:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12929","submitter":"Mohammad Farrokhi Derakhshandeh Ghouchan","authors":"Ali Azimi, R. B. Bapat, Mohammad Farrokhi Derakhshandeh Ghouchan","title":"Moore-Penrose inverse of incidence matrices","comments":"8 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present explicit formulas for Moore-Penrose inverses of some families of\nset inclusion matrices arising from sets, vector spaces, and designs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:23:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12930","submitter":"Timoteo Carletti","authors":"Marie Dorchain and Riccardo Muolo and Timoteo Carletti","title":"Pattern reconstruction through generalized eigenvectors on defective\n  networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech math-ph math.MP nlin.AO nlin.PS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Self-organization in natural and engineered systems causes the emergence of\nordered spatio-temporal motifs. In presence of diffusive species, Turing theory\nhas been widely used to understand the formation of such patterns obtained from\na diffusion-driven instability mechanism. The theory was later extended to\nnetworked systems, where the reaction processes occur locally (in the nodes),\nwhile diffusion takes place through the networks links. The condition for the\ninstability onset relies on the spectral property of the Laplace matrix, i.e.,\nthe diffusive operator, and in particular on the existence of an eigenbasis. In\nthis work we make one step forward and we prove the validity of Turing idea\nalso in the case of a defective Laplace matrix. Moreover, by using both\neigenvectors and generalized eigenvectors we show that we can reconstruct the\nasymptotic pattern with a relatively small discrepancy. Because a large\nmajority of empirical networks are non-normal and often defective, our results\npave the way for a thorough understanding of self-organization in real-world\nsystems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:24:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12931","submitter":"Tamoghna Das","authors":"Tamoghna Das","title":"Quantifying `local softness' in a simple liquid","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Mutual information between local stress and local non-affine deformation is\nproposed as a collective field variable quantifying the {\\em local softness} of\nsoft materials. The liquid-solid transition in a simple liquid is considered as\na generic example of mechanical transformation through varying correlation\nbetween stress and deformation at the microscopic level. Probing through this\nnew measure, a liquid appears as a spatially heterogeneous medium of\ninteracting interconnected regions of varying softness. In contrast, the soft\nregions shrink to isolated spots in the background of a negligible mean\nsoftness in the case of solids. In this view, the thermodynamic transition\nbecomes purely geometric while keeping the essential mechanical information\nintact. Besides offering a general framework for understanding the mechanics of\nmaterials, this new approach can complement recent machine learning efforts by\nassigning physical meaning to their findings. Further, this collective variable\ncan be used on the fly during material characterization as both of its\ningredient variables are experimentally accessible.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:24:25 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12932","submitter":"Vijaya Krishna Yalavarthi Mr","authors":"Vijaya Krishna Yalavarthi, Kiran Madusudanan, Randolf Sholz, Nourhan\n  Ahmed, Johannes Burchert, Shayan Javed, Stefan Born, Lars Schmidt-Thieme","title":"Forecasting Irregularly Sampled Time Series using Graphs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Forecasting irregularly sampled time series with missing values is a crucial\ntask for numerous real-world applications such as healthcare, astronomy, and\nclimate sciences. State-of-the-art approaches to this problem rely on Ordinary\nDifferential Equations (ODEs) but are known to be slow and to require\nadditional features to handle missing values. To address this issue, we propose\na novel model using Graphs for Forecasting Irregularly Sampled Time Series with\nmissing values which we call GraFITi. GraFITi first converts the time series to\na Sparsity Structure Graph which is a sparse bipartite graph, and then\nreformulates the forecasting problem as the edge weight prediction task in the\ngraph. It uses the power of Graph Neural Networks to learn the graph and\npredict the target edge weights. We show that GraFITi can be used not only for\nour Sparsity Structure Graph but also for alternative graph representations of\ntime series. GraFITi has been tested on 3 real-world and 1 synthetic\nirregularly sampled time series dataset with missing values and compared with\nvarious state-of-the-art models. The experimental results demonstrate that\nGraFITi improves the forecasting accuracy by up to 17% and reduces the run time\nup to 5 times compared to the state-of-the-art forecasting models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:25:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12933","submitter":"Ruixue Zhang","authors":"W.C. Shiu, G.C. Lau, and R.X. Zhang","title":"On bridge graphs with local antimagic chromatic number 3","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Let $G=(V, E)$ be a connected graph. A bijection $f: E\\to \\{1, \\ldots, |E|\\}$\nis called a local antimagic labeling if for any two adjacent vertices $x$ and\n$y$, $f^+(x)\\neq f^+(y)$, where $f^+(x)=\\sum_{e\\in E(x)}f(e)$ and $E(x)$ is the\nset of edges incident to $x$. Thus a local antimagic labeling induces a proper\nvertex coloring of $G$, where the vertex $x$ is assigned the color $f^+(x)$.\nThe local antimagic chromatic number $\\chi_{la}(G)$ is the minimum number of\ncolors taken over all colorings induced by local antimagic labelings of $G$. In\nthis paper, we present some families of bridge graphs with $\\chi_{la}(G)=3$ and\ngive several ways to construct bridge graphs with $\\chi_{la}(G)=3$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:26:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12934","submitter":"Atul Sharma","authors":"Atul Sharma and S. Janardhanan","title":"Position Control of Single Link Flexible Manipulator: A Functional\n  Observer Based Sliding Mode Approach","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper proposes a functional observer-based sliding mode control\ntechnique for position control of a single-link flexible manipulator. The\nproposed method considers the unmodelled system dynamics as uncertainty and\naims to achieve accurate position control. The functional observer is used to\ndirectly estimate the sliding mode control design components and a sliding mode\ncontroller to generate the control signal, which guarantees the system's\nrobustness and stability. The proposed control scheme is validated using\nnumerical simulations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:29:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12935","submitter":"Amani Abusafia","authors":"Yisheng Alison Zheng, Abdallah Lakhdari, Amani Abusafia, Shing Tai\n  Tony Lui, Athman Bouguettaya","title":"CrowdWeb: A Visualization Tool for Mobility Patterns in Smart Cities","comments":"4 pages, 8 figures. This is an accepted demo paper and it will appear\n  in the Proceedings of the International Conference on Distributed Computing\n  Systems (ICDCS)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI cs.DM cs.HC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Human mobility patterns refer to the regularities and trends in the way\npeople move, travel, or navigate through different geographical locations over\ntime. Detecting human mobility patterns is essential for a variety of\napplications, including smart cities, transportation management, and disaster\nresponse. The accuracy of current mobility prediction models is less than 25%.\nThe low accuracy is mainly due to the fluid nature of human movement.\nTypically, humans do not adhere to rigid patterns in their daily activities,\nmaking it difficult to identify hidden regularities in their data. To address\nthis issue, we proposed a web platform to visualize human mobility patterns by\nabstracting the locations into a set of places to detect more realistic\npatterns. However, the platform was initially designed to detect individual\nmobility patterns, making it unsuitable for representing the crowd in a smart\ncity scale. Therefore, we extend the platform to visualize the mobility of\nmultiple users from a city-scale perspective. Our platform allows users to\nvisualize a graph of visited places based on their historical records using a\nmodified PrefixSpan approach. Additionally, the platform synchronizes,\naggregates, and displays crowd mobility patterns across various time intervals\nwithin a smart city. We showcase our platform using a real dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:30:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12936","submitter":"Igor Vladimirov","authors":"Igor G. Vladimirov","title":"Entropy bounds for invariant measure perturbations in stochastic systems\n  with uncertain noise","comments":"14 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.SY eess.SY math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper is concerned with stochastic systems whose state is a diffusion\nprocess governed by an Ito stochastic differential equation (SDE). In the\nframework of a nominal white-noise model, the SDE is driven by a standard\nWiener process. For a scenario of statistical uncertainty, where the driving\nnoise acquires a state-dependent drift and thus deviates from its idealised\nmodel, we consider the perturbation of the invariant probability density\nfunction (PDF) as a steady-state solution of the Fokker-Planck-Kolmogorov\nequation. We discuss an upper bound on a logarithmic Dirichlet form for the\nratio of the invariant PDF to its nominal counterpart in terms of the\nKullback-Leibler relative entropy rate of the actual noise distribution with\nrespect the Wiener measure. This bound is shown to be achievable, provided the\nPDF ratio is preserved by the nominal steady-state probability flux. The\nlogarithmic Dirichlet form bound is used in order to obtain an upper bound on\nthe relative entropy of the perturbed invariant PDF in terms of\nquadratic-exponential moments of the noise drift in the uniform ellipticity\ncase. These results are illustrated for perturbations of Gaussian invariant\nmeasures in linear stochastic systems involving linear noise drifts.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:31:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12937","submitter":"J\\'er\\'emie Quarroz","authors":"Ming-Ming Long, Kirill Melnikov, J\\'er\\'emie Quarroz","title":"Non-factorizable virtual corrections to Higgs boson production in weak\n  boson fusion beyond the eikonal approximation","comments":"26 pages, 6 figures","journal-ref":null,"doi":null,"report-no":"TTP23-017, P3H-23-032","categories":"hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Non-factorizable virtual corrections to Higgs boson production in weak boson\nfusion at next-to-next-to-leading order in QCD were estimated in the eikonal\napproximation [1]. This approximation corresponds to the expansion of relevant\namplitudes around the forward limit. In this paper we compute the leading power\ncorrection to the eikonal limit and show that it is proportional to first power\nof the Higgs boson transverse momentum or the Higgs boson mass over partonic\ncenter-of-mass energy. Moreover, this correction can be significantly enhanced\nby the rapidity of the Higgs boson. For realistic weak boson fusion cuts, the\nnext-to-eikonal correction reduces the estimate of non-factorizable\ncontributions to fiducial cross section by O(30) percent.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:31:57 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12938","submitter":"The ATLAS Collaboration","authors":"ATLAS Collaboration","title":"Search for dark matter produced in association with a Higgs boson\n  decaying to tau leptons at $\\sqrt{s}=13$ TeV with the ATLAS detector","comments":"53 pages in total, author list starting page 36, 8 figures, 8 tables,\n  submitted to JHEP. All figures including auxiliary figures are available at:\n  https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/PAPERS/HDBS-2018-50/","journal-ref":null,"doi":null,"report-no":"CERN-EP-2023-072","categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A search for dark matter produced in association with a Higgs boson in final\nstates with two hadronically decaying $\\tau$-leptons and missing transverse\nmomentum is presented. The analysis uses $139$ fb$^{-1}$ of proton-proton\ncollision data at $\\sqrt{s}=13$ TeV collected by the ATLAS experiment at the\nLarge Hadron Collider between 2015 and 2018. No evidence for physics beyond the\nStandard Model is found. The results are interpreted in terms of a 2HDM+$a$\nmodel. Exclusion limits at 95% confidence level are derived. Model-independent\nlimits are also set on the visible cross section for processes beyond the\nStandard Model producing missing transverse momentum in association with a\nHiggs boson decaying to $\\tau$-leptons.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:34:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12939","submitter":"Xiaoyu Wang","authors":"Xiaoyu Wang, Mikael Johansson, and Tong Zhang","title":"Generalized Polyak Step Size for First Order Optimization with Momentum","comments":"28 pages, ICML2023","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In machine learning applications, it is well known that carefully designed\nlearning rate (step size) schedules can significantly improve the convergence\nof commonly used first-order optimization algorithms. Therefore how to set step\nsize adaptively becomes an important research question. A popular and effective\nmethod is the Polyak step size, which sets step size adaptively for gradient\ndescent or stochastic gradient descent without the need to estimate the\nsmoothness parameter of the objective function. However, there has not been a\nprincipled way to generalize the Polyak step size for algorithms with momentum\naccelerations. This paper presents a general framework to set the learning rate\nadaptively for first-order optimization methods with momentum, motivated by the\nderivation of Polyak step size. It is shown that the resulting methods are much\nless sensitive to the choice of momentum parameter and may avoid the\noscillation of the heavy-ball method on ill-conditioned problems. These\nadaptive step sizes are further extended to the stochastic settings, which are\nattractive choices for stochastic gradient descent with momentum. Our methods\nare demonstrated to be more effective for stochastic gradient methods than\nprior adaptive step size algorithms in large-scale machine learning tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:36:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12940","submitter":"Mihai Masala","authors":"Mihai Masala, Nicolae Cudlenco, Traian Rebedea, Marius Leordeanu","title":"GEST: the Graph of Events in Space and Time as a Common Representation\n  between Vision and Language","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One of the essential human skills is the ability to seamlessly build an inner\nrepresentation of the world. By exploiting this representation, humans are\ncapable of easily finding consensus between visual, auditory and linguistic\nperspectives. In this work, we set out to understand and emulate this ability\nthrough an explicit representation for both vision and language - Graphs of\nEvents in Space and Time (GEST). GEST alows us to measure the similarity\nbetween texts and videos in a semantic and fully explainable way, through graph\nmatching. It also allows us to generate text and videos from a common\nrepresentation that provides a well understood content. In this work we show\nthat the graph matching similarity metrics based on GEST outperform classical\ntext generation metrics and can also boost the performance of state of art,\nheavily trained metrics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:38:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12941","submitter":"Emily Cheng","authors":"Emily Cheng, Mathieu Rita, Thierry Poibeau","title":"On the Correspondence between Compositionality and Imitation in Emergent\n  Neural Communication","comments":"Findings of ACL 2023; 5 pages + 8 pages of supplementary materials","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.NE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Compositionality is a hallmark of human language that not only enables\nlinguistic generalization, but also potentially facilitates acquisition. When\nsimulating language emergence with neural networks, compositionality has been\nshown to improve communication performance; however, its impact on imitation\nlearning has yet to be investigated. Our work explores the link between\ncompositionality and imitation in a Lewis game played by deep neural agents.\nOur contributions are twofold: first, we show that the learning algorithm used\nto imitate is crucial: supervised learning tends to produce more average\nlanguages, while reinforcement learning introduces a selection pressure toward\nmore compositional languages. Second, our study reveals that compositional\nlanguages are easier to imitate, which may induce the pressure toward\ncompositional languages in RL imitation settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:41:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12942","submitter":"Brahim El Alaoui","authors":"Driss Bennis and Brahim El Alaoui","title":"Partitioning zero-divisor graphs of finite commutative rings into global\n  defensive alliances","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AC math.CO","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  For a commutative ring $R$ with identity, the zero-divisor graph of $R$,\ndenoted $\\Gamma(R)$, is the graph whose vertices are the non-zero zero divisors\nof $R$ with two distinct vertices $x$ and $y$ are adjacent if and only if\n$xy=0$. In this paper, we are interested in partitioning the vertex set of\n$\\Gamma(R)$ into global defensive alliances for a finite commutative ring $R$.\nThis problem has been well investigated in graph theory. Here we connected it\nwith the ring theoretical context. We characterize various commutative finite\nrings for which the zero divisor graph is partitionable into global defensive\nalliances. We also give several examples to illustrate the scopes and limits of\nour results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:43:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12943","submitter":"Munan Ning","authors":"Munan Ning, Yujia Xie, Dongdong Chen, Zeyin Song, Lu Yuan, Yonghong\n  Tian, Qixiang Ye, Li Yuan","title":"Album Storytelling with Iterative Story-aware Captioning and Large\n  Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This work studies how to transform an album to vivid and coherent stories, a\ntask we refer to as \"album storytelling\". While this task can help preserve\nmemories and facilitate experience sharing, it remains an underexplored area in\ncurrent literature. With recent advances in Large Language Models (LLMs), it is\nnow possible to generate lengthy, coherent text, opening up the opportunity to\ndevelop an AI assistant for album storytelling. One natural approach is to use\ncaption models to describe each photo in the album, and then use LLMs to\nsummarize and rewrite the generated captions into an engaging story. However,\nwe find this often results in stories containing hallucinated information that\ncontradicts the images, as each generated caption (\"story-agnostic\") is not\nalways about the description related to the whole story or miss some necessary\ninformation. To address these limitations, we propose a new iterative album\nstorytelling pipeline. Specifically, we start with an initial story and build a\nstory-aware caption model to refine the captions using the whole story as\nguidance. The polished captions are then fed into the LLMs to generate a new\nrefined story. This process is repeated iteratively until the story contains\nminimal factual errors while maintaining coherence. To evaluate our proposed\npipeline, we introduce a new dataset of image collections from vlogs and a set\nof systematic evaluation metrics. Our results demonstrate that our method\neffectively generates more accurate and engaging stories for albums, with\nenhanced coherence and vividness.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:45:10 GMT"},{"version":"v2","created":"Wed, 24 May 2023 02:58:03 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12944","submitter":"Germano Gabbianelli","authors":"Germano Gabbianelli, Gergely Neu, Nneka Okolo, Matteo Papini","title":"Offline Primal-Dual Reinforcement Learning for Linear MDPs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Offline Reinforcement Learning (RL) aims to learn a near-optimal policy from\na fixed dataset of transitions collected by another policy. This problem has\nattracted a lot of attention recently, but most existing methods with strong\ntheoretical guarantees are restricted to finite-horizon or tabular settings. In\nconstrast, few algorithms for infinite-horizon settings with function\napproximation and minimal assumptions on the dataset are both sample and\ncomputationally efficient. Another gap in the current literature is the lack of\ntheoretical analysis for the average-reward setting, which is more challenging\nthan the discounted setting. In this paper, we address both of these issues by\nproposing a primal-dual optimization method based on the linear programming\nformulation of RL. Our key contribution is a new reparametrization that allows\nus to derive low-variance gradient estimators that can be used in a stochastic\noptimization scheme using only samples from the behavior policy. Our method\nfinds an $\\varepsilon$-optimal policy with $O(\\varepsilon^{-4})$ samples,\nimproving on the previous $O(\\varepsilon^{-5})$, while being computationally\nefficient for infinite-horizon discounted and average-reward MDPs with\nrealizable linear function approximation and partial coverage. Moreover, to the\nbest of our knowledge, this is the first theoretical result for average-reward\noffline RL.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:45:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12945","submitter":"Dongfang Li","authors":"Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu and Min Zhang","title":"ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist\n  Examination","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  As ChatGPT and GPT-4 spearhead the development of Large Language Models\n(LLMs), more researchers are investigating their performance across various\ntasks. But more research needs to be done on the interpretability capabilities\nof LLMs, that is, the ability to generate reasons after an answer has been\ngiven. Existing explanation datasets are mostly English-language general\nknowledge questions, which leads to insufficient thematic and linguistic\ndiversity. To address the language bias and lack of medical resources in\ngenerating rationales QA datasets, we present ExplainCPE (over 7k instances), a\nchallenging medical benchmark in Simplified Chinese. We analyzed the errors of\nChatGPT and GPT-4, pointing out the limitations of current LLMs in\nunderstanding text and computational reasoning. During the experiment, we also\nfound that different LLMs have different preferences for in-context learning.\nExplainCPE presents a significant challenge, but its potential for further\ninvestigation is promising, and it can be used to evaluate the ability of a\nmodel to generate explanations. AI safety and trustworthiness need more\nattention, and this work makes the first step to explore the medical\ninterpretability of LLMs.The dataset is available at\nhttps://github.com/HITsz-TMG/ExplainCPE.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:45:42 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12946","submitter":"Jennifer Przybilla","authors":"Jennifer Przybilla, Igor Pontes Duff, Peter Benner","title":"Semi-active damping optimization of vibrational systems using the\n  reduced basis method","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we consider vibrational systems with semi-active damping\nthat are described by a second-order model. In order to minimize the influence\nof external inputs to the system response, we are optimizing some damping\nvalues. As minimization criterion, we evaluate the energy response, that is the\n$\\cH_2$-norm of the corresponding transfer function of the system. Computing\nthe energy response includes solving Lyapunov equations for different damping\nparameters. Hence, the minimization process leads to high computational costs\nif the system is of large dimension. We present two techniques that reduce the\noptimization problem by applying the reduced basis method to the corresponding\nparametric Lyapunov equations. In the first method, we determine a reduced\nsolution space on which the Lyapunov equations and hence the resulting energy\nresponse values are computed approximately in a reasonable time. The second\nmethod includes the reduced basis method in the minimization process. To\nevaluate the quality of the approximations, we introduce error estimators that\nevaluate the error in the controllability Gramians and the energy response.\nFinally, we illustrate the advantages of our methods by applying them to two\ndifferent examples.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:46:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12947","submitter":"J\\'an \\v{C}egi\\v{n}","authors":"Jan Cegin, Jakub Simko and Peter Brusilovsky","title":"ChatGPT to Replace Crowdsourcing of Paraphrases for Intent\n  Classification: Higher Diversity and Comparable Model Robustness","comments":"11 pages, 3 figures (one of them with 4 subfigures) report","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The emergence of generative large language models (LLMs) raises the question:\nwhat will be its impact on crowdsourcing. Traditionally, crowdsourcing has been\nused for acquiring solutions to a wide variety of human-intelligence tasks,\nincluding ones involving text generation, manipulation or evaluation. For some\nof these tasks, models like ChatGPT can potentially substitute human workers.\nIn this study, we investigate, whether this is the case for the task of\nparaphrase generation for intent classification. We quasi-replicated the data\ncollection methodology of an existing crowdsourcing study (similar scale,\nprompts and seed data) using ChatGPT. We show that ChatGPT-created paraphrases\nare more diverse and lead to more robust models.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:46:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12948","submitter":"Joshua Smailes","authors":"Joshua Smailes and Razvan David and Sebastian Kohler and Simon\n  Birnbach and Ivan Martinovic","title":"POSTER: spaceQUIC: Securing Communication in Computationally Constrained\n  Spacecraft","comments":"2 pages, 2 figures; the first two authors contributed equally to this\n  paper","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent years have seen a rapid increase in the number of CubeSats and other\nsmall satellites in orbit - these have highly constrained computational and\ncommunication resources, but still require robust secure communication to\noperate effectively.\n  The QUIC transport layer protocol is designed to provide efficient\ncommunication with cryptography guarantees built-in, with a particular focus on\nnetworks with high latency and packet loss.\n  In this work we provide spaceQUIC, a proof of concept implementation of QUIC\nfor NASA's \"core Flight System\" satellite operating system, and assess its\nperformance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:47:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12949","submitter":"Nikolay Kuznetsov G.","authors":"Nikolay Kuznetsov","title":"The fundamental eigenfrequency is simple in the two-dimensional sloshing\n  problem","comments":"6 pages, no figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The two-dimensional sloshing problem is considered; it describes the\ntransversal free oscillations of water in an open, infinitely long canal of\nuniform cross-section. It is proved that the fundamental eigenfrequency is\nsimple, whereas the corresponding velocity potential has only one nodal line\nconnecting the free surface and the bottom; its harmonic conjugate (stream\nfunction) does not change sign under the proper choice of the additive\nconstant.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:51:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12950","submitter":"Fucai Luo","authors":"Fucai Luo, Saif Al-Kuwari, Haiyan Wang, and Xingfu Yan","title":"FSSA: Efficient 3-Round Secure Aggregation for Privacy-Preserving\n  Federated Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Federated learning (FL) allows a large number of clients to collaboratively\ntrain machine learning (ML) models by sending only their local gradients to a\ncentral server for aggregation in each training iteration, without sending\ntheir raw training data. Unfortunately, recent attacks on FL demonstrate that\nlocal gradients may leak information about local training data. In response to\nsuch attacks, Bonawitz \\textit{et al.} (CCS 2017) proposed a secure aggregation\nprotocol that allows a server to compute the sum of clients' local gradients in\na secure manner. However, their secure aggregation protocol requires at least 4\nrounds of communication between each client and the server in each training\niteration. The number of communication rounds is closely related not only to\nthe total communication cost but also the ML model accuracy, as the number of\ncommunication rounds affects client dropouts.\n  In this paper, we propose FSSA, a 3-round secure aggregation protocol, that\nis efficient in terms of computation and communication, and resilient to client\ndropouts. We prove the security of FSSA in honest-but-curious setting and show\nthat the security can be maintained even if an arbitrarily chosen subset of\nclients drop out at any time. We evaluate the performance of FSSA and show that\nits computation and communication overhead remains low even on large datasets.\nFurthermore, we conduct an experimental comparison between FSSA and Bonawitz\n\\textit{et al.}'s protocol. The comparison results show that, in addition to\nreducing the number of communication rounds, FSSA achieves a significant\nimprovement in computational efficiency.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:53:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12951","submitter":"Pedro Henrique Luz de Araujo","authors":"Pedro Henrique Luz de Araujo and Benjamin Roth","title":"Cross-functional Analysis of Generalisation in Behavioural Learning","comments":"16 pages, 1 figure. To be published in the Transactions of the\n  Association for Computational Linguistics (TACL). This preprint is a pre-MIT\n  Press publication version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In behavioural testing, system functionalities underrepresented in the\nstandard evaluation setting (with a held-out test set) are validated through\ncontrolled input-output pairs. Optimising performance on the behavioural tests\nduring training (behavioural learning) would improve coverage of phenomena not\nsufficiently represented in the i.i.d. data and could lead to seemingly more\nrobust models. However, there is the risk that the model narrowly captures\nspurious correlations from the behavioural test suite, leading to\noverestimation and misrepresentation of model performance -- one of the\noriginal pitfalls of traditional evaluation. In this work, we introduce BeLUGA,\nan analysis method for evaluating behavioural learning considering\ngeneralisation across dimensions of different granularity levels. We optimise\nbehaviour-specific loss functions and evaluate models on several partitions of\nthe behavioural test suite controlled to leave out specific phenomena. An\naggregate score measures generalisation to unseen functionalities (or\noverfitting). We use BeLUGA to examine three representative NLP tasks\n(sentiment analysis, paraphrase identification and reading comprehension) and\ncompare the impact of a diverse set of regularisation and domain generalisation\nmethods on generalisation performance.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:54:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12952","submitter":"Donatella Darsena","authors":"Donatella Darsena, Francesco Verde","title":"On the capacity of TDMA downlink with a reconfigurable intelligent\n  surface","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We provide accurate approximations of the sum-rate capacity of a\ntime-division multiple access (TDMA) down-link, when a reconfigurable\nintelligent surface (RIS) assists the transmission from a single-antenna base\nstation (BS) to K single-antenna user equipments (UEs). We consider the fading\neffects of both the direct (i.e., BS-to-UEs) and reflection (i.e,\nBS-to-RIS-to-UEs) links, by developing two approximations: the former one is\nbased on hardening of the reflection channel for large values of the number Q\nof meta-atoms at the RIS; the latter one relies on the distribution of the sum\nof Nakagami variates and does not require channel hardening. Our derivations\nshow the dependence of the sum-rate capacity as a function of both K and Q, as\nwell as to establish a comparison with a TDMA downlink without an RIS.\nNumerical results corroborate the accuracy of the proposed approximations and\nthe validity of the mathematical analysis.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:55:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12953","submitter":"Sanket Thakur","authors":"Sanket Thakur, Cigdem Beyan, Pietro Morerio, Vittorio Murino, Alessio\n  Del Bue","title":"Enhancing Next Active Object-based Egocentric Action Anticipation with\n  Guided Attention","comments":"Submitted to IEEE ICIP 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Short-term action anticipation (STA) in first-person videos is a challenging\ntask that involves understanding the next active object interactions and\npredicting future actions. Existing action anticipation methods have primarily\nfocused on utilizing features extracted from video clips, but often overlooked\nthe importance of objects and their interactions. To this end, we propose a\nnovel approach that applies a guided attention mechanism between the objects,\nand the spatiotemporal features extracted from video clips, enhancing the\nmotion and contextual information, and further decoding the object-centric and\nmotion-centric information to address the problem of STA in egocentric videos.\nOur method, GANO (Guided Attention for Next active Objects) is a multi-modal,\nend-to-end, single transformer-based network. The experimental results\nperformed on the largest egocentric dataset demonstrate that GANO outperforms\nthe existing state-of-the-art methods for the prediction of the next active\nobject label, its bounding box location, the corresponding future action, and\nthe time to contact the object. The ablation study shows the positive\ncontribution of the guided attention mechanism compared to other fusion\nmethods. Moreover, it is possible to improve the next active object location\nand class label prediction results of GANO by just appending the learnable\nobject tokens with the region of interest embeddings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:56:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12954","submitter":"Zheng Li","authors":"Zheng Li, Yuxuan Li, Penghai Zhao, Renjie Song, Xiang Li, Jian Yang","title":"Is Synthetic Data From Diffusion Models Ready for Knowledge\n  Distillation?","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diffusion models have recently achieved astonishing performance in generating\nhigh-fidelity photo-realistic images. Given their huge success, it is still\nunclear whether synthetic images are applicable for knowledge distillation when\nreal images are unavailable. In this paper, we extensively study whether and\nhow synthetic images produced from state-of-the-art diffusion models can be\nused for knowledge distillation without access to real images, and obtain three\nkey conclusions: (1) synthetic data from diffusion models can easily lead to\nstate-of-the-art performance among existing synthesis-based distillation\nmethods, (2) low-fidelity synthetic images are better teaching materials, and\n(3) relatively weak classifiers are better teachers. Code is available at\nhttps://github.com/zhengli97/DM-KD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:02:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12955","submitter":"Stefanie Walz","authors":"Stefanie Walz and Mario Bijelic and Andrea Ramazzina and Amanpreet\n  Walia and Fahim Mannan and Felix Heide","title":"Gated Stereo: Joint Depth Estimation from Gated and Wide-Baseline Active\n  Stereo Cues","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose Gated Stereo, a high-resolution and long-range depth estimation\ntechnique that operates on active gated stereo images. Using active and high\ndynamic range passive captures, Gated Stereo exploits multi-view cues alongside\ntime-of-flight intensity cues from active gating. To this end, we propose a\ndepth estimation method with a monocular and stereo depth prediction branch\nwhich are combined in a final fusion stage. Each block is supervised through a\ncombination of supervised and gated self-supervision losses. To facilitate\ntraining and validation, we acquire a long-range synchronized gated stereo\ndataset for automotive scenarios. We find that the method achieves an\nimprovement of more than 50 % MAE compared to the next best RGB stereo method,\nand 74 % MAE to existing monocular gated methods for distances up to 160 m. Our\ncode,models and datasets are available here.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:03:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12956","submitter":"Alejandro C\\'ardenas-Avenda\\~no","authors":"Alejandro C\\'ardenas-Avenda\\~no, Alexandru Lupsasca","title":"Prediction for the interferometric shape of the first black hole photon\n  ring","comments":"16 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Black hole images are theoretically predicted (under mild astrophysical\nassumptions) to display a stack of lensed \"photon rings\" that carry information\nabout the underlying spacetime geometry. Despite vigorous efforts, no such ring\nhas been observationally resolved thus far. However, planning is now actively\nunder way for space missions targeting the first (and possibly the second)\nphoton rings of the supermassive black holes M87* and Sgr A*. In this work, we\nstudy interferometric photon ring signatures in time-averaged images of Kerr\nblack holes surrounded by different astrophysical profiles. We focus on the\nfirst, most easily accessible photon ring, which has a larger width-to-diameter\nratio than subsequent rings and whose image consequently lacks a sharply\ndefined diameter. Nonetheless, we show that it does admit a precise\nangle-dependent diameter in visibility space, for which the Kerr metric\npredicts a specific functional form that tracks the critical curve. We find\nthat a measurement of this interferometric ring diameter is possible for most\nastrophysical profiles, paving the way for precision tests of strong-field\ngeneral relativity via near-future observations of the first photon ring.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:04:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12957","submitter":"Wentao Zhang","authors":"Wentao Zhang, Yang Shi, Baoyong Zhang, Deming Yuan","title":"Improved Dynamic Regret of Distributed Online Multiple Frank-Wolfe\n  Convex Optimization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we consider a distributed online convex optimization problem\nover a time-varying multi-agent network. The goal of this network is to\nminimize a global loss function through local computation and communication\nwith neighbors. To effectively handle the optimization problem with a\nhigh-dimensional and complicated constraint set, we develop a distributed\nonline multiple Frank-Wolfe algorithm to avoid the expensive computational cost\nof projection operation. The dynamic regret bounds are established as\n$\\mathcal{O}(T^{1-\\gamma}+H_T)$ with the linear oracle number $\\mathcal{O}\n(T^{1+\\gamma})$, which depends on the horizon (total iteration number) $T$, the\nfunction variation $H_T$, and the tuning parameter $0<\\gamma<1$. In particular,\nwhen the stringent computation requirement is satisfied, the bound can be\nenhanced to $\\mathcal{O} (1+H_T)$. Moreover, we illustrate the significant\nadvantages of the multiple iteration technique and reveal a trade-off between\ncomputational cost and dynamic regret bound. Finally, the performance of our\nalgorithm is verified and compared through the distributed online ridge\nregression problems with two constraint sets.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:07:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12958","submitter":"Jonas Soenen","authors":"Jonas Soenen, Elia Van Wolputte, Vincent Vercruyssen, Wannes Meert,\n  and Hendrik Blockeel","title":"AD-MERCS: Modeling Normality and Abnormality in Unsupervised Anomaly\n  Detection","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Most anomaly detection systems try to model normal behavior and assume\nanomalies deviate from it in diverse manners. However, there may be patterns in\nthe anomalies as well. Ideally, an anomaly detection system can exploit\npatterns in both normal and anomalous behavior. In this paper, we present\nAD-MERCS, an unsupervised approach to anomaly detection that explicitly aims at\ndoing both. AD-MERCS identifies multiple subspaces of the instance space within\nwhich patterns exist, and identifies conditions (possibly in other subspaces)\nthat characterize instances that deviate from these patterns. Experiments show\nthat this modeling of both normality and abnormality makes the anomaly detector\nperformant on a wide range of types of anomalies. Moreover, by identifying\npatterns and conditions in (low-dimensional) subspaces, the anomaly detector\ncan provide simple explanations of why something is considered an anomaly.\nThese explanations can be both negative (deviation from some pattern) as\npositive (meeting some condition that is typical for anomalies).\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:09:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12959","submitter":"Xiaoxiao Sheng","authors":"Xiaoxiao Sheng, Zhiqiang Shen, Gang Xiao","title":"Contrastive Predictive Autoencoders for Dynamic Point Cloud\n  Self-Supervised Learning","comments":"Accepted by AAAI2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a new self-supervised paradigm on point cloud sequence\nunderstanding. Inspired by the discriminative and generative self-supervised\nmethods, we design two tasks, namely point cloud sequence based Contrastive\nPrediction and Reconstruction (CPR), to collaboratively learn more\ncomprehensive spatiotemporal representations. Specifically, dense point cloud\nsegments are first input into an encoder to extract embeddings. All but the\nlast ones are then aggregated by a context-aware autoregressor to make\npredictions for the last target segment. Towards the goal of modeling\nmulti-granularity structures, local and global contrastive learning are\nperformed between predictions and targets. To further improve the\ngeneralization of representations, the predictions are also utilized to\nreconstruct raw point cloud sequences by a decoder, where point cloud\ncolorization is employed to discriminate against different frames. By combining\nclassic contrast and reconstruction paradigms, it makes the learned\nrepresentations with both global discrimination and local perception. We\nconduct experiments on four point cloud sequence benchmarks, and report the\nresults on action recognition and gesture recognition under multiple\nexperimental settings. The performances are comparable with supervised methods\nand show powerful transferability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:09:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12960","submitter":"Desmond Y.M. Tang","authors":"Desmond Y.M. Tang","title":"The Integrated Forward-Forward Algorithm: Integrating Forward-Forward\n  and Shallow Backpropagation With Local Losses","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The backpropagation algorithm, despite its widespread use in neural network\nlearning, may not accurately emulate the human cortex's learning process.\nAlternative strategies, such as the Forward-Forward Algorithm (FFA), offer a\ncloser match to the human cortex's learning characteristics. However, the\noriginal FFA paper and related works on the Forward-Forward Algorithm only\nmentioned very limited types of neural network mechanisms and may limit its\napplication and effectiveness. In response to these challenges, we propose an\nintegrated method that combines the strengths of both FFA and shallow\nbackpropagation, yielding a biologically plausible neural network training\nalgorithm which can also be applied to various network structures. We applied\nthis integrated approach to the classification of the Modified National\nInstitute of Standards and Technology (MNIST) database, where it outperformed\nFFA and demonstrated superior resilience to noise compared to backpropagation.\nWe show that training neural networks with the Integrated Forward-Forward\nAlgorithm has the potential of generating neural networks with advantageous\nfeatures like robustness.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:10:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12961","submitter":"Mitchell Keren Taraday","authors":"Mitchell Keren Taraday, Chaim Baskin","title":"Enhanced Meta Label Correction for Coping with Label Corruption","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Traditional methods for learning with the presence of noisy labels have\nsuccessfully handled datasets with artificially injected noise but still fall\nshort of adequately handling real-world noise. With the increasing use of\nmeta-learning in the diverse fields of machine learning, researchers leveraged\nauxiliary small clean datasets to meta-correct the training labels.\nNonetheless, existing meta-label correction approaches are not fully exploiting\ntheir potential. In this study, we propose an Enhanced Meta Label Correction\napproach abbreviated as EMLC for the learning with noisy labels (LNL) problem.\nWe re-examine the meta-learning process and introduce faster and more accurate\nmeta-gradient derivations. We propose a novel teacher architecture tailored\nexplicitly to the LNL problem, equipped with novel training objectives. EMLC\noutperforms prior approaches and achieves state-of-the-art results in all\nstandard benchmarks. Notably, EMLC enhances the previous art on the noisy\nreal-world dataset Clothing1M by $1.52\\%$ while requiring $\\times 0.5$ the time\nper epoch and with much faster convergence of the meta-objective when compared\nto the baseline approach.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:11:07 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12962","submitter":"Jiazheng Li","authors":"Jiazheng Li, Lin Gui, Yuxiang Zhou, David West, Cesare Aloisi, Yulan\n  He","title":"Distilling ChatGPT for Explainable Automated Student Answer Assessment","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Assessing student answers and providing valuable feedback is crucial for\neffective learning, but it can be a time-consuming task. Traditional methods of\nautomating student answer assessment through text classification often suffer\nfrom issues such as lack of trustworthiness, transparency, and the ability to\nprovide a rationale for the automated assessment process. These limitations\nhinder their usefulness in practice. In this paper, we explore using ChatGPT, a\ncutting-edge large language model, for the concurrent tasks of student answer\nscoring and rationale generation under both the zero-shot and few-shot\nsettings. We introduce a critic module which automatically filters incorrect\noutputs from ChatGPT and utilizes the remaining ChtaGPT outputs as noisy\nlabelled data to fine-tune a smaller language model, enabling it to perform\nstudent answer scoring and rationale generation. Moreover, by drawing multiple\nsamples from ChatGPT outputs, we are able to compute predictive confidence\nscores, which in turn can be used to identify corrupted data and human label\nerrors in the training set. Our experimental results demonstrate that despite\nbeing a few orders of magnitude smaller than ChatGPT, the fine-tuned language\nmodel achieves better performance in student answer scoring. Furthermore, it\ngenerates more detailed and comprehensible assessments than traditional text\nclassification methods. Our approach provides a viable solution to achieve\nexplainable automated assessment in education.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:11:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12963","submitter":"Madison Russell","authors":"Madison Russell, Marie Saitou, Omer Gokcumen, Naoki Masuda","title":"Gene communities in co-expression networks across different tissues","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.MN","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With the recent availability of tissue-specific gene expression data, e.g.,\nprovided by the GTEx Consortium, there is interest in comparing gene\nco-expression patterns across tissues. One promising approach to this problem\nis to use a multilayer network analysis framework and perform multilayer\ncommunity detection. Communities in gene co-expression networks reveal\ncommunities of genes similarly expressed across individuals, potentially\ninvolved in related biological processes responding to specific environmental\nstimuli or sharing common regulatory variations. We construct a multilayer\nnetwork in which each layer is a tissue-specific gene co-expression network. We\ndevelop methods for multilayer community detection with correlation matrix\ninput and an appropriate null model. Our correlation matrix input method\nidentifies groups of genes that are similarly co-expressed in multiple tissues\n(a community that spans multiple layers, which we call a generalist community)\nand some groups of genes that are co-expressed in just one tissue (a community\nthat lies primarily within just one layer, which we call a specialist\ncommunity). We further found gene co-expression communities where the genes\nphysically cluster across the genome significantly more than expected by\nchance. This clustering hints at underlying regulatory elements determining\nsimilar expression patterns across individuals and cell types. The results\nindicate that our multilayer community detection method for correlation matrix\ninput extracts biologically interesting communities of genes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:11:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12964","submitter":"Yang Bai","authors":"Yang Bai, Jingyao Wang, Min Cao, Chen Chen, Ziqiang Cao, Liqiang Nie\n  and Min Zhang","title":"Text-based Person Search without Parallel Image-Text Data","comments":"11 pages, 5 figures, 5 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-based person search (TBPS) aims to retrieve the images of the target\nperson from a large image gallery based on a given natural language\ndescription. Existing methods are dominated by training models with parallel\nimage-text pairs, which are very costly to collect. In this paper, we make the\nfirst attempt to explore TBPS without parallel image-text data ($\\mu$-TBPS), in\nwhich only non-parallel images and texts, or even image-only data, can be\nadopted. Towards this end, we propose a two-stage framework,\ngeneration-then-retrieval (GTR), to first generate the corresponding pseudo\ntext for each image and then perform the retrieval in a supervised manner. In\nthe generation stage, we propose a fine-grained image captioning strategy to\nobtain an enriched description of the person image, which firstly utilizes a\nset of instruction prompts to activate the off-the-shelf pretrained\nvision-language model to capture and generate fine-grained person attributes,\nand then converts the extracted attributes into a textual description via the\nfinetuned large language model or the hand-crafted template. In the retrieval\nstage, considering the noise interference of the generated texts for training\nmodel, we develop a confidence score-based training scheme by enabling more\nreliable texts to contribute more during the training. Experimental results on\nmultiple TBPS benchmarks (i.e., CUHK-PEDES, ICFG-PEDES and RSTPReid) show that\nthe proposed GTR can achieve a promising performance without relying on\nparallel image-text data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:13:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12965","submitter":"Francesco Sannino","authors":"A. D'Alise, G. Fabiano, D. Frattulillo, S. Hohenegger, D. Iacobacci,\n  F. Pezzella, F. Sannino","title":"Positivity Conditions for Generalised Schwarzschild Space-Times","comments":"LaTeX, 40 pages, 9 figures","journal-ref":null,"doi":null,"report-no":"LYCEN 2023-01","categories":"gr-qc hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We analyse the impact of positivity conditions on static spherically\nsymmetric deformations of the Schwarzschild space-time. The metric is taken to\nsatisfy, at least asymptotically, the Einstein equation in the presence of a\nnon-trivial stress-energy tensor, on which we impose various physicality\nconditions. We systematically study and compare the impact of these conditions\non the space-time deformations. The universal nature of our findings applies to\nboth classical and quantum metric deformations with and without event horizons.\nWe further discuss minimal realisations of the asymptotic stress energy tensor\nin terms of physical fields. Finally, we illustrate our results by discussing\nconcrete models of quantum black holes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:14:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12966","submitter":"Zheng Chen","authors":"Zheng Chen, Yulun Zhang, Ding Liu, Bin Xia, Jinjin Gu, Linghe Kong,\n  Xin Yuan","title":"Hierarchical Integration Diffusion Model for Realistic Image Deblurring","comments":"Code is available at https://github.com/zhengchen1999/HI-Diff","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diffusion models (DMs) have recently been introduced in image deblurring and\nexhibited promising performance, particularly in terms of details\nreconstruction. However, the diffusion model requires a large number of\ninference iterations to recover the clean image from pure Gaussian noise, which\nconsumes massive computational resources. Moreover, the distribution\nsynthesized by the diffusion model is often misaligned with the target results,\nleading to restrictions in distortion-based metrics. To address the above\nissues, we propose the Hierarchical Integration Diffusion Model (HI-Diff), for\nrealistic image deblurring. Specifically, we perform the DM in a highly\ncompacted latent space to generate the prior feature for the deblurring\nprocess. The deblurring process is implemented by a regression-based method to\nobtain better distortion accuracy. Meanwhile, the highly compact latent space\nensures the efficiency of the DM. Furthermore, we design the hierarchical\nintegration module to fuse the prior into the regression-based model from\nmultiple scales, enabling better generalization in complex blurry scenarios.\nComprehensive experiments on synthetic and real-world blur datasets demonstrate\nthat our HI-Diff outperforms state-of-the-art methods. Code and trained models\nare available at https://github.com/zhengchen1999/HI-Diff.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:18:20 GMT"},{"version":"v2","created":"Wed, 24 May 2023 04:32:53 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.12967","submitter":"Soutrik Bandyopadhyay","authors":"Soutrik Bandyopadhyay and Shubhendu Bhasin","title":"HJB based online safe reinforcement learning for state-constrained\n  systems","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  This paper proposes a safe reinforcement learning(RL) algorithm that solves\nthe constrained optimal control problem for continuous-time nonlinear systems\nwith uncertain dynamics. We formulate the safe RL problem as minimizing a\nLagrangian involving the cost functional and a user-defined barrier Lyapunov\nfunction(BLF) encoding the state constraints. We show that the analytical\nsolution obtained by the corresponding Hamilton-Jacobi-Bellman(HJB) equations\ninvolves an expression for the Lagrange multiplier, which includes unknown\nterms arising from the system uncertainties. However, the naive estimation of\nthe aforementioned Lagrange multiplier may lead to safety constraint\nviolations. To obviate this challenge, we propose a novel\nActor-Critic-Identifier-Lagrangian(ACIL) algorithm that learns optimal control\npolicies from online data without compromising safety. The safety and\nboundedness guarantees are proved for the proposed algorithm. Subsequently, we\ncompare the performance of the proposed ACIL algorithm against existing\noffline/online RL methods in a simulation study.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:22:49 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12968","submitter":"Peng Yan","authors":"Deng-Shan Wang, Peng Yan","title":"Rigorous asymptotic analysis for the Riemann problem of the defocusing\n  nonlinear Schr\\\"odinger hydrodynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP math-ph math.MP nlin.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The rigorous asymptotic analysis for the Riemann problem of the defocusing\nnonlinear Schr\\\"{o}dinger hydrodynamics is a very interesting problem with many\nchallenges. So far, the full analysis of this problem remains open. In this\nwork, the long-time asymptotics for the defocusing nonlinear Schr\\\"{o}dinger\nequation with general step-like initial data is investigated by Whitham\nmodulation theory and Riemann-Hilbert formulation. The Whitham modulation\ntheory shows that there are six cases for the initial discontinuity problem\naccording to the orders of the Riemann invariants. The leading-order terms and\nthe corresponding error estimates for each region of the six cases are\nformulated by Deift-Zhou nonlinear steepest method for oscillatory\nRiemann-Hilbert problems. It is demonstrated that the long-time asymptotic\nsolutions match very well with the results from Whitham modulation theory and\nthe numerical simulations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:22:55 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.12969","submitter":"Marios Maroudas","authors":"Josep Maria Batllori, Yikun Gu, Dieter Horns, Marios Maroudas,\n  Johannes Ulrichs","title":"WISP Searches on a Fiber Interferometer under a Strong Magnetic Field","comments":"7 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  A novel table-top experiment is introduced to detect photon-axion conversion:\nWISP Searches on a Fiber Interferometer (WISPFI). The setup consists of a\nMach-Zehnder-type interferometer with a fiber placed inside an external\nmagnetic field (14 T), where mixing occurs and is detected by measuring changes\nin phase/amplitude. We will use hollow-core photonic crystal fibers (HC-PCF) to\nachieve resonant mixing that is tuneable by regulating the gas pressure in the\nfiber. An unexplored axion mass-range (50 meV - 100 meV) can be probed reaching\nthe two-photon coupling expected for the QCD axion.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:25:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12970","submitter":"Kiarn Laverick","authors":"Kiarn T. Laverick, Prahlad Warszawski, Areeya Chantasri and Howard M.\n  Wiseman","title":"Quantum state smoothing cannot be assumed classical even when the\n  filtering and retrofiltering are classical","comments":"20 Pages, 9 Figures. Comments are welcomed!","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  State smoothing is a technique to estimate a state at a particular time,\nconditioned on information obtained both before (past) and after (future) that\ntime. For a classical system, the smoothed state is a normalized product of the\n$\\textit{filtered state}$ (a state conditioned only on the past measurement\ninformation and the initial preparation) and the $\\textit{retrofiltered\neffect}$ (depending only on the future measurement information). For the\nquantum case, whilst there are well-established analogues of the filtered state\n($\\rho_{\\rm F}$) and retrofiltered effect ($\\hat E_{\\rm R}$), their product\ndoes not, in general, provide a valid quantum state for smoothing. However,\nthis procedure does seem to work when $\\rho_{\\rm F}$ and $\\hat E_{\\rm R}$ are\nmutually diagonalizable. This fact has been used to obtain smoothed quantum\nstates -- more pure than the filtered states -- in a number of experiments on\ncontinuously monitored quantum systems, in cavity QED and atomic systems. In\nthis paper we show that there is an implicit assumption underlying this\ntechnique: that if all the information were known to the observer, the true\nsystem state would be one of the diagonal basis states. This assumption does\nnot necessarily hold, as the missing information is quantum information. It\ncould be known to the observer only if it were turned into a classical\nmeasurement record, but then its nature depends on the choice of measurement.\nWe show by a simple model that, depending on that measurement choice, the\nsmoothed quantum state can: agree with that from the classical method; disagree\nwith it but still be co-diagonal with it; or not even be co-diagonal with it.\nThat is, just because filtering and retrofiltering appear classical does not\nmean classical smoothing theory is applicable in quantum experiments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:25:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12971","submitter":"James Stovold","authors":"James Stovold","title":"Neural Cellular Automata Can Respond to Signals","comments":"Accepted to main track at ALIFE 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.AI cs.DC cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neural Cellular Automata (NCAs) are a model of morphogenesis, capable of\ngrowing two-dimensional artificial organisms from a single seed cell. In this\npaper, we show that NCAs can be trained to respond to signals. Two types of\nsignal are used: internal (genomically-coded) signals, and external\n(environmental) signals. Signals are presented to a single pixel for a single\ntimestep.\n  Results show NCAs are able to grow into multiple distinct forms based on\ninternal signals, and are able to change colour based on external signals.\nOverall these contribute to the development of NCAs as a model of artificial\nmorphogenesis, and pave the way for future developments embedding dynamic\nbehaviour into the NCA model.\n  Code and target images are available through GitHub:\nhttps://github.com/jstovold/ALIFE2023\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:26:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12972","submitter":"Hanting Chen","authors":"Hanting Chen, Yunhe Wang, Jianyuan Guo, Dacheng Tao","title":"VanillaNet: the Power of Minimalism in Deep Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  At the heart of foundation models is the philosophy of \"more is different\",\nexemplified by the astonishing success in computer vision and natural language\nprocessing. However, the challenges of optimization and inherent complexity of\ntransformer models call for a paradigm shift towards simplicity. In this study,\nwe introduce VanillaNet, a neural network architecture that embraces elegance\nin design. By avoiding high depth, shortcuts, and intricate operations like\nself-attention, VanillaNet is refreshingly concise yet remarkably powerful.\nEach layer is carefully crafted to be compact and straightforward, with\nnonlinear activation functions pruned after training to restore the original\narchitecture. VanillaNet overcomes the challenges of inherent complexity,\nmaking it ideal for resource-constrained environments. Its easy-to-understand\nand highly simplified architecture opens new possibilities for efficient\ndeployment. Extensive experimentation demonstrates that VanillaNet delivers\nperformance on par with renowned deep neural networks and vision transformers,\nshowcasing the power of minimalism in deep learning. This visionary journey of\nVanillaNet has significant potential to redefine the landscape and challenge\nthe status quo of foundation model, setting a new path for elegant and\neffective model design. Pre-trained models and codes are available at\nhttps://github.com/huawei-noah/VanillaNet and\nhttps://gitee.com/mindspore/models/tree/master/research/cv/vanillanet.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:27:27 GMT"},{"version":"v2","created":"Tue, 23 May 2023 12:51:30 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12973","submitter":"Mikhail Masharin","authors":"M.A. Masharin, D. Khmelevskaia, V.I. Kondratiev, D.I. Markina, A.D.\n  Utyushev, D.M. Dolgintsev, A.D. Dmitriev, V.A. Shahnazaryan, A.P. Pushkarev,\n  F. Isik, I.V. Iorsh, I.A. Shelykh, H.V. Demir, A.K. Samusev, S.V. Makarov","title":"Polariton lasing in Mie-resonant perovskite nanocavity","comments":"29 pages, 19 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deeply subwavelength lasers (or nanolasers) are highly demanded for compact\non-chip bioimaging and sensing at the nanoscale. One of the main obstacles for\nthe development of single-particle nanolasers with all three dimensions shorter\nthan the emitting wavelength in the visible range is the high lasing thresholds\nand the resulting overheating. Here we exploit exciton-polariton condensation\nand mirror-image Mie modes in a cuboid CsPbBr$_3$ nanoparticle to achieve\ncoherent emission at the visible wavelength of around 0.53~$\\mu $m from its\nultra-small ($\\approx$0.007$\\mu$m$^3$ or $\\approx\\lambda^3$/20) semiconductor\nnanocavity. The polaritonic nature of the emission from the nanocavity\nlocalized in all three dimensions is proven by direct comparison with\ncorresponding one-dimensional and two-dimensional waveguiding systems with\nsimilar material parameters. Such a deeply subwavelength nanolaser is enabled\nnot only by the high values for exciton binding energy ($\\approx$35 meV),\nrefractive index ($>$2.5 at low temperature), and luminescence quantum yield of\nCsPbBr$_3$, but also by the optimization of polaritons condensation on the Mie\nresonances. Moreover, the key parameters for optimal lasing conditions are\nintermode free spectral range and phonons spectrum in CsPbBr$_3$, which govern\npolaritons condensation path. Such chemically synthesized colloidal CsPbBr$_3$\nnanolasers can be easily deposited on arbitrary surfaces, which makes them a\nversatile tool for integration with various on-chip systems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:28:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12974","submitter":"Wenxiong Li","authors":"Wenxiong Li, Iair Arcavi, Ehud Nakar, Alexei V. Filippenko, Thomas G.\n  Brink, WeiKang Zheng, Marco C. Lam, Ido Keinan, Se\\'an J. Brennan, Noi\n  Shitrit","title":"Rapidly Evolving Transients in Archival ZTF Public Alerts","comments":"16 pages, 7 figures, submitted to AAS Journals","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We search the archival Zwicky Transient Facility public survey for rapidly\nevolving transient (RET) candidates based on well-defined criteria between 2018\nMay and 2021 December. The search yielded 19 bona-fide RET candidates,\ncorresponding to a discovery rate of $\\sim 5.2$ events per year. Even with a\nGalactic latitude cut of $20^\\circ$, 8 of the 19 events ($\\sim 42$%) are\nGalactic, including one with a light-curve shape closely resembling that of the\nGW170817 kilonova (KN). An additional event is a nova in M31. Four out of the\n19 events ($\\sim 21$%) are confirmed extragalactic RETs (one confirmed here for\nthe first time) and the origin of 6 additional events cannot be determined. We\ndid not find any extragalactic events resembling the GW170817 KN, from which we\nobtain an upper limit on the volumetric rate of GW170817-like KNe of $R \\le$\n2400 Gpc$^{-3}$ yr$^{-1}$ (95% confidence). These results can be used for\nquantifying contaminants to RET searches in transient alert streams,\nspecifically when searching for kilonovae independently of gravitational-wave\nand gamma-ray-burst triggers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:29:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12975","submitter":"Matteo Acclavio","authors":"Matteo Acclavio","title":"Graphical Proof Theory I: Multiplicative Linear Logic Beyond Cographs","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Cographs are a class of (undirected) graphs, characterized by the absence of\ninduced subgraphs isomorphic to the four-vertices path, showing an intuitive\none-to-one correspondence with classical propositional formulas. In this paper\nwe study sequent calculi operating on graphs, as a generalization of sequent\ncalculi operating on formulas, therefore on cographs.\n  We mostly focus on sequent systems with multiplicative rules (in the sense of\nlinear logic, that is, linear and context-free rules) extending multiplicative\nlinear logic with connectives allowing us to represent modular decomposition of\ngraphs by formulas, therefore obtaining a representation of a graph with linear\nsize with respect to the number of its vertices. We show that these proof\nsystems satisfy basic proof theoretical properties such as initial coherence,\ncut-elimination and analyticity of proof search. We prove that the system\nconservatively extend multiplicative linear logic with and without mix, and\nthat the system extending the former derives the same graphs which are\nderivable in the deep inference system GS from the literature. We provide a\nsyntax for proof nets for our systems by extending the syntax of Retor\\'e's\nRB-structures to represent graphical connectives. A topological\ncharacterization of those structures encoding correct proofs is given, as well\nas a sequentialization procedure to construct a derivation from a correct\nstructure. We conclude the paper by discussing how to extend those linear\nsystems with the structural rules of weakening and contraction, providing a\nsequent system for an extension of classical propositional logic beyond\ncographs.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:29:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12976","submitter":"Ming-Hao Juan","authors":"Ming-Hao Juan, Pu-Jen Cheng, Hui-Neng Hsu and Pin-Hsin Hsiao","title":"Attentive Graph-based Text-aware Preference Modeling for Top-N\n  Recommendation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Textual data are commonly used as auxiliary information for modeling user\npreference nowadays. While many prior works utilize user reviews for rating\nprediction, few focus on top-N recommendation, and even few try to incorporate\nitem textual contents such as title and description. Though delivering\npromising performance for rating prediction, we empirically find that many\nreview-based models cannot perform comparably well on top-N recommendation.\nAlso, user reviews are not available in some recommendation scenarios, while\nitem textual contents are more prevalent. On the other hand, recent graph\nconvolutional network (GCN) based models demonstrate state-of-the-art\nperformance for top-N recommendation. Thus, in this work, we aim to further\nimprove top-N recommendation by effectively modeling both item textual content\nand high-order connectivity in user-item graph. We propose a new model named\nAttentive Graph-based Text-aware Recommendation Model (AGTM). Extensive\nexperiments are provided to justify the rationality and effectiveness of our\nmodel design.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:32:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12977","submitter":"Cheng-Chien Chen","authors":"Adam D. Smith, Sumner B. Harris, Renato P. Camata, Da Yan, and\n  Cheng-Chien Chen","title":"Machine Learning the Relationship between Debye and Superconducting\n  Transition Temperatures","comments":"9 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recently a relationship between the Debye temperature $\\Theta_D$ and the\nsuperconducting transition temperature $T_c$ of conventional superconductors\nhas been proposed [npj Quantum Materials $\\mathbf{3}$, 59 (2018)]. The\nrelationship indicates that $T_c \\le A \\Theta_D$ for phonon-mediated BCS\nsuperconductors, with $A$ being a material-specific pre-factor of order $\\sim\n0.1$. In order to verify this bound, we train machine learning (ML) models with\n10,330 samples in the Materials Project database to predict $\\Theta_D$. By\napplying our ML models to 9,860 known superconductors in the NIMS SuperCon\ndatabase, we find that the conventional superconductors in the database indeed\nfollow the proposed bound. We also perform first-principles phonon calculations\nfor H$_{3}$S and LaH$_{10}$ at 200 GPa. The calculation results indicate that\nthese high-pressure hydrides essentially saturate the bound of $T_c$ versus\n$\\Theta_D$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:32:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12978","submitter":"Michele Girfoglio","authors":"Nicola Clinco, Michele Girfoglio, Annalisa Quaini, Gianluigi Rozza","title":"Filter stabilization for the mildly compressible Euler equations with\n  application to atmosphere dynamics simulations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We present a filter stabilization technique for the mildly compressible Euler\nequations that relies on a linear or nonlinear indicator function to identify\nthe regions of the domain where artificial viscosity is needed and determine\nits amount. For the realization of this technique, we adopt a three step\nalgorithm called Evolve-Filter-Relax (EFR), which at every time step evolves\nthe solution (i.e., solves the Euler equations on a coarse mesh), then filters\nthe computed solution, and finally performs a relaxation step to combine the\nfiltered and non-filtered solutions. We show that the EFR algorithm is\nequivalent to an eddy-viscosity model in Large Eddy Simulation. Three indicator\nfunctions are considered: a constant function (leading to a linear filter), a\nfunction proportional to the norm of the velocity gradient (recovering a\nSmagorinsky-like model), and a function based on approximate deconvolution\noperators. Through well-known benchmarks for atmospheric flow, we show that the\ndeconvolution-based filter yields stable solutions that are much less\ndissipative than the linear filter and the Samgorinsky-like model and we\nhighlight the efficiency of the EFR algorithm.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:34:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12979","submitter":"Xinjing Yuan","authors":"Xinjing Yuan, Lingjun Pu, Lei Jiao, Xiaofei Wang, Meijuan Yang,\n  Jingdong Xu","title":"When Computing Power Network Meets Distributed Machine Learning: An\n  Efficient Federated Split Learning Framework","comments":"10 pages, 8figures, accepted by IEEE/ACM IWQoS 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we advocate CPN-FedSL, a novel and flexible Federated Split\nLearning (FedSL) framework over Computing Power Network (CPN). We build a\ndedicated model to capture the basic settings and learning characteristics\n(e.g., training flow, latency and convergence). Based on this model, we\nintroduce Resource Usage Effectiveness (RUE), a novel performance metric\nintegrating training utility with system cost, and formulate a multivariate\nscheduling problem that maxi?mizes RUE by comprehensively taking client\nadmission, model partition, server selection, routing and bandwidth allocation\ninto account (i.e., mixed-integer fractional programming). We design Refinery,\nan efficient approach that first linearizes the fractional objective and\nnon-convex constraints, and then solves the transformed problem via a greedy\nbased rounding algorithm in multiple iterations. Extensive evaluations\ncorroborate that CPN-FedSL is superior to the standard and state-of-the-art\nlearning frameworks (e.g., FedAvg and SplitFed), and besides Refinery is\nlightweight and significantly outperforms its variants and de facto heuristic\nmethods under a variety of settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:36:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12980","submitter":"Tomasz Smo{\\l}ka","authors":"Piotr T. Chru\\'sciel and Tomasz Smo{\\l}ka","title":"Hamiltonian charges on light cones for linear field theories on (A)dS\n  backgrounds","comments":"79 pages, 1 figure","journal-ref":null,"doi":null,"report-no":"UWThPh-2023-7","categories":"gr-qc","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We analyse the Noether charges for scalar and Maxwell fields on light cones\non a de Sitter, Minkowski, and anti-de Sitter backgrounds. Somewhat\nsurprisingly, under natural asymptotic conditions all charges for the Maxwell\nfields on both the de Sitter and anti-de Sitter backgrounds are finite. On the\nother hand, one needs to renormalise the charges for the conformally-covariant\nscalar field when the cosmological constant does not vanish. In both cases\nwell-defined renormalised charges, with well-defined fluxes, are obtained.\nAgain surprisingly, a Hamiltonian analysis of a suitably rescaled scalar field\nleads to finite charges, without the need to renormalise. Last but not least,\nwe indicate natural phase spaces where the Poisson algebra of charges is well\ndefined.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:40:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12981","submitter":"Pedro Abdalla Teixeira","authors":"Pedro Abdalla","title":"Covariance Estimation under Missing Observations and $L_4-L_2$ Moment\n  Equivalence","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST math.PR stat.TH","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  We consider the problem of estimating the covariance matrix of a random\nvector by observing i.i.d samples and each entry of the sampled vector is\nmissed with probability $p$. Under the standard $L_4-L_2$ moment equivalence\nassumption, we construct the first estimator that simultaneously achieves\noptimality with respect to the parameter $p$ and it recovers the optimal\nconvergence rate for the classical covariance estimation problem when $p=1$\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:42:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12982","submitter":"Horst Foidl","authors":"Horst Foidl, Tanja Rindler-Daller, Werner Zeilinger","title":"Halo formation and evolution in SFDM and CDM: new insights from the\n  fluid approach","comments":"submitted to Phys.Rev.D; 26 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA astro-ph.CO hep-ph physics.flu-dyn","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  (abridged) We present simulations of halo formation and evolution in scalar\nfield dark matter (SFDM) cosmologies in the Thomas-Fermi regime, aka\n``SFDM-TF\", where a strong repulsive 2-particle self-interaction (SI) is\nincluded, being a valuable alternative to CDM, with the potential to resolve\nits ``cusp-core\" problem. In general, SFDM behaves like a quantum fluid.\nPrevious literature has presented two fluid approximations for SFDM-TF, as well\nas simulations of halo formation. These results confirmed earlier expectations\nand are generally in mutual agreement, but discrepancies were also reported.\nTherefore, we perform dedicated 3D cosmological simulations for the SFDM-TF\nmodel, applying both fluid approximations, as well as for CDM. Our results are\nvery well in accordance with previous works and extend upon them, in that we\ncan explain the reported discrepancies as a result of different simulation\nsetups. We find some interesting details: The evolution of both SFDM-TF and CDM\nhalos follows a 2-stage process. In the early stage, the density profile in the\ncenter becomes close to a $(n=1.5)$-polytropic core, dominated by an\n\"effective\" velocity-dispersion pressure $P_{\\sigma}$ which is common to both\ndark matter models. Consecutively, for CDM halos, the core transitions into a\ncentral cusp. In SFDM-TF halos, the additional pressure $P_\\text{SI}$ due to SI\ndetermines the second stage of the evolution, where the central region follows\nclosely a $(n=1)$-polytropic core, embedded in a nearly isothermal envelope,\ni.e. the outskirts are similar to CDM. We also encounter a new effect, namely a\nlate-time expansion of both polytropic core plus envelope, because the size of\nthe almost isothermal halo envelope is affected by the expansion of the\nbackground universe. So, an initial primordial core of $\\sim 100$ pc can evolve\ninto a larger core of $\\gtrsim 1$ kpc, even without feedback from baryons.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:42:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12983","submitter":"Michael Kranl","authors":"Michael Kranl, Hubert Ramsauer and Bernhard Knapp","title":"Why current rain denoising models fail on CycleGAN created rain images\n  in autonomous driving","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG eess.IV","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  One of the main tasks of an autonomous agent in a vehicle is to correctly\nperceive its environment. Much of the data that needs to be processed is\ncollected by optical sensors such as cameras. Unfortunately, the data collected\nin this way can be affected by a variety of factors, including environmental\ninfluences such as inclement weather conditions (e.g., rain). Such noisy data\ncan cause autonomous agents to take wrong decisions with potentially fatal\noutcomes. This paper addresses the rain image challenge by two steps: First,\nrain is artificially added to a set of clear-weather condition images using a\nGenerative Adversarial Network (GAN). This yields good/bad weather image pairs\nfor training de-raining models. This artificial generation of rain images is\nsufficiently realistic as in 7 out of 10 cases, human test subjects believed\nthe generated rain images to be real. In a second step, this paired good/bad\nweather image data is used to train two rain denoising models, one based\nprimarily on a Convolutional Neural Network (CNN) and the other using a Vision\nTransformer. This rain de-noising step showed limited performance as the\nquality gain was only about 15%. This lack of performance on realistic rain\nimages as used in our study is likely due to current rain de-noising models\nbeing developed for simplistic rain overlay data. Our study shows that there is\nample space for improvement of de-raining models in autonomous driving.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:42:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12984","submitter":"Qingxiang Xu","authors":"Xiaoyi Tian, Qingxiang Xu, Chunhong Fu","title":"Quasi-projection pairs on Hilbert $C^*$-modules","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.OA","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Motivated by a couple of examples, a new term of quasi-projection pair\n$(P,Q)$ on a Hilbert $C^*$-module $H$ is introduced, in which $P$ is a\nprojection, while $Q$ is an idempotent satisfying certain conditions. Some\nbasic properties of quasi-projection pairs are provided. For every idempotent\n$Q$ on a Hilbert $C^*$-module $H$, it is shown that there always exist a\nprojection denoted by $m(Q)$, and an invertible operator $W$ on $H$ such that\n$\\big(m(Q),Q\\big)$ is a quasi-projection pair satisfying\n\\begin{equation*}Q=W^{-1}PW\\quad\\mbox{and}\\quad \\|I-W\\|<1. \\end{equation*}\nThus, a new formula for $Q$ is derived based on $m(Q)$, which is called the\nmatched projection of $Q$. The matched projection $m(Q)$ introduced in this\npaper for a general idempotent $Q$ is a brand new object, which has many\ninteresting features. Some fundamental results on $m(Q)$ are derived. The new\nterms of semi-harmonious quasi-projection pair and harmonious quasi-projection\npair are introduced respectively. A systematical characterization of these two\ntypes of quasi-projection pairs is carried out in this paper. As applications,\nthe canonical $2\\times 2$ block matrix representation and the $6\\times 6$\nHalmos-like block matrix representation are derived in the sense of unitary\nequivalence for a general harmonious quasi-projection pair $(P,Q)$ on a Hilbert\n$C^*$-module. Specifically, this gives new block matrix forms of $Q$ in the\ncase that $P=m(Q)$ such that $\\big(m(Q),Q\\big)$ is harmonious (which happens if\n$H$ is a Hilbert space). In addition, this paper initiates the study of the\ncommon similarity and the unitary equivalence of operators in the framework of\nsemi-harmonious quasi-projection pairs. Some other topics such as a norm\nequation associated with the Friedrichs angle and more norm inequalities\nassociated with matched projections are also dealt with.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:44:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12985","submitter":"Haoyang Cao","authors":"Haoyang Cao and Haotian Gu and Xin Guo","title":"Feasibility of Transfer Learning: A Mathematical Framework","comments":"arXiv admin note: substantial text overlap with arXiv:2301.11542","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Transfer learning is a popular paradigm for utilizing existing knowledge from\nprevious learning tasks to improve the performance of new ones. It has enjoyed\nnumerous empirical successes and inspired a growing number of theoretical\nstudies. This paper addresses the feasibility issue of transfer learning. It\nbegins by establishing the necessary mathematical concepts and constructing a\nmathematical framework for transfer learning. It then identifies and formulates\nthe three-step transfer learning procedure as an optimization problem, allowing\nfor the resolution of the feasibility issue. Importantly, it demonstrates that\nunder certain technical conditions, such as appropriate choice of loss\nfunctions and data sets, an optimal procedure for transfer learning exists.\nThis study of the feasibility issue brings additional insights into various\ntransfer learning problems. It sheds light on the impact of feature\naugmentation on model performance, explores potential extensions of domain\nadaptation, and examines the feasibility of efficient feature extractor\ntransfer in image classification.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:44:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12986","submitter":"Junhui Li","authors":"Junhui Li, Xingsong Hou, Huake Wang, Shuhao Bi","title":"Sparsity and Coefficient Permutation Based Two-Domain AMP for Image\n  Block Compressed Sensing","comments":"13 pages, 12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.MM eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The learned denoising-based approximate message passing (LDAMP) algorithm has\nattracted great attention for image compressed sensing (CS) tasks. However, it\nhas two issues: first, its global measurement model severely restricts its\napplicability to high-dimensional images, and its block-based measurement\nmethod exhibits obvious block artifacts; second, the denoiser in the LDAMP is\ntoo simple, and existing denoisers have limited ability in detail recovery. In\nthis paper, to overcome the issues and develop a high-performance LDAMP method\nfor image block compressed sensing (BCS), we propose a novel sparsity and\ncoefficient permutation-based AMP (SCP-AMP) method consisting of the\nblock-based sampling and the two-domain reconstruction modules. In the sampling\nmodule, SCP-AMP adopts a discrete cosine transform (DCT) based sparsity\nstrategy to reduce the impact of the high-frequency coefficient on the\nreconstruction, followed by a coefficient permutation strategy to avoid block\nartifacts. In the reconstruction module, a two-domain AMP method with DCT\ndomain noise correction and pixel domain denoising is proposed for iterative\nreconstruction. Regarding the denoiser, we proposed a multi-level deep\nattention network (MDANet) to enhance the texture details by employing\nmulti-level features and multiple attention mechanisms. Extensive experiments\ndemonstrated that the proposed SCP-AMP method achieved better reconstruction\naccuracy than other state-of-the-art BCS algorithms in terms of both visual\nperception and objective metrics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:46:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12987","submitter":"Magnus Sahlgren","authors":"Ariel Ekgren, Amaru Cuba Gyllensten, Felix Stollenwerk, Joey \\\"Ohman,\n  Tim Isbister, Evangelia Gogoulou, Fredrik Carlsson, Alice Heiman, Judit\n  Casademont, Magnus Sahlgren","title":"GPT-SW3: An Autoregressive Language Model for the Nordic Languages","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper details the process of developing the first native large\ngenerative language model for the Nordic languages, GPT-SW3. We cover all parts\nof the development process, from data collection and processing, training\nconfiguration and instruction finetuning, to evaluation and considerations for\nrelease strategies. We hope that this paper can serve as a guide and reference\nfor other researchers that undertake the development of large generative models\nfor smaller languages.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:47:48 GMT"},{"version":"v2","created":"Tue, 23 May 2023 06:59:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12988","submitter":"Kilian Muller","authors":"Ruben Ohana, Daniel Hesslow, Daniel Brunner, Sylvain Gigan, Kilian\n  M\\\"uller","title":"Linear Optical Random Projections Without Holography","comments":"7 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  We introduce a novel method to perform linear optical random projections\nwithout the need for holography. Our method consists of a computationally\ntrivial combination of multiple intensity measurements to mitigate the\ninformation loss usually associated with the absolute-square non-linearity\nimposed by optical intensity measurements. Both experimental and numerical\nfindings demonstrate that the resulting matrix consists of real-valued,\nindependent, and identically distributed (i.i.d.) Gaussian random entries. Our\noptical setup is simple and robust, as it does not require interference between\ntwo beams. We demonstrate the practical applicability of our method by\nperforming dimensionality reduction on high-dimensional data, a common task in\nrandomized numerical linear algebra with relevant applications in machine\nlearning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:47:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12989","submitter":"Stefano Gariazzo","authors":"Eleonora Di Valentino, Stefano Gariazzo, William Giar\\`e, Olga Mena","title":"Weighing neutrinos at the damping tail","comments":"10 pages, 3 figures, 4 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.CO hep-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Model-independent mass limits assess the robustness of current cosmological\nmeasurements of the neutrino mass scale. Consistency between high-multipole and\nlow-multiple Cosmic Microwave Background observations measuring such scale\nfurther valuate the constraining power of present data. We derive here\nup-to-date limits on neutrino masses and abundances exploiting either the Data\nRelease 4 of the Atacama Cosmology Telescope (ACT) or the South Pole Telescope\npolarization measurements from SPT-3G, envisaging different non-minimal\nbackground cosmologies and marginalizing over them. Both the most constraining\nand marginalized bounds are competitive with those found with Planck data: we\nobtain $\\sum m_\\nu <0.139$ eV and $N_{\\textrm{eff}}= 2.82\\pm 0.25$ in a dark\nenergy quintessence scenario, both at $95\\%$ CL. These limits translate into\n$\\sum m_\\nu <0.20$ eV and $N_{\\textrm{eff}}= 2.79^{+0.30}_{-0.28}$ after\nmarginalizing over a plethora of well-motivated fiducial models. Our findings\nreassess both the strength and the reliability of cosmological neutrino mass\nconstraints.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:49:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12990","submitter":"Shohei Yoda","authors":"Shohei Yoda, Hayato Tsukagoshi, Ryohei Sasano, Koichi Takeda","title":"Sentence Representations via Gaussian Embedding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent progress in sentence embedding, which represents the meaning of a\nsentence as a point in a vector space, has achieved high performance on tasks\nsuch as a semantic textual similarity (STS) task. However, sentence\nrepresentations as a point in a vector space can express only a part of the\ndiverse information that sentences have, such as asymmetrical relationships\nbetween sentences. This paper proposes GaussCSE, a Gaussian distribution-based\ncontrastive learning framework for sentence embedding that can handle\nasymmetric relationships between sentences, along with a similarity measure for\nidentifying inclusion relations. Our experiments show that GaussCSE achieves\nthe same performance as previous methods in natural language inference tasks,\nand is able to estimate the direction of entailment relations, which is\ndifficult with point representations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:51:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12991","submitter":"Jacopo Di Iorio Ph.D.","authors":"Jacopo Di Iorio and Simone Vantini","title":"funLOCI: a local clustering algorithm for functional data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nowadays, more and more problems are dealing with data with one infinite\ncontinuous dimension: functional data. In this paper, we introduce the funLOCI\nalgorithm which allows to identify functional local clusters or functional\nloci, i.e., subsets/groups of functions exhibiting similar behaviour across the\nsame continuous subset of the domain. The definition of functional local\nclusters leverages ideas from multivariate and functional clustering and\nbiclustering and it is based on an additive model which takes into account the\nshape of the curves. funLOCI is a three-step algorithm based on divisive\nhierarchical clustering. The use of dendrograms allows to visualize and to\nguide the searching procedure and the cutting thresholds selection. To deal\nwith the large quantity of local clusters, an extra step is implemented to\nreduce the number of results to the minimum.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:51:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12992","submitter":"Chenxu Pang","authors":"Chenxu Pang, Xiaojie Wang","title":"Antithetic multilevel Monte Carlo method for approximations of SDEs with\n  non-globally Lipschitz continuous coefficients","comments":"39 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the field of computational finance, it is common for the quantity of\ninterest to be expected values of functions of random variables via stochastic\ndifferential equations (SDEs). For SDEs with globally Lipschitz coefficients\nand commutative diffusion coefficients, the explicit Milstein scheme, relying\non only Brownian increments and thus easily implementable, can be combined with\nthe multilevel Monte Carlo (MLMC) method proposed by Giles\n\\cite{giles2008multilevel} to give the optimal overall computational cost\n$\\mathcal{O}(\\epsilon^{-2})$, where $\\epsilon$ is the required target accuracy.\nFor multi-dimensional SDEs that do not satisfy the commutativity condition, a\nkind of one-half order truncated Milstein-type scheme without L\\'evy areas is\nintroduced by Giles and Szpruch \\cite{giles2014antithetic}, which combined with\nthe antithetic MLMC gives the optimal computational cost under globally\nLipschitz conditions. In the present work, we turn to SDEs with non-globally\nLipschitz continuous coefficients, for which a family of modified Milstein-type\nschemes without L\\'evy areas is proposed. The expected one-half order of strong\nconvergence is recovered in a non-globally Lipschitz setting, where the\ndiffusion coefficients are allowed to grow superlinearly. This helps us to\nanalyze the relevant variance of the multilevel estimator and the optimal\ncomputational cost is finally achieved for the antithetic MLMC. The analysis of\nboth the convergence rate and the desired variance in the non-globally\nLipschitz setting is highly non-trivial and non-standard arguments are\ndeveloped to overcome some essential difficulties. Numerical experiments are\nprovided to confirm the theoretical findings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:52:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12993","submitter":"Francesco Tarantelli","authors":"Francesco Tarantelli and Stefano Scopa","title":"Out-of-equilibrium scaling behavior arising during round-trip protocols\n  across a quantum first-order transition","comments":"12 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the nonequilibrium dynamics of quantum spin chains during a\nround-trip protocol that slowly drives the system across a quantum first-order\ntransition. Out-of-equilibrium scaling behaviors \\`a la Kibble-Zurek for the\nsingle-passage protocol across the first-order transition have been previously\ndetermined. Here, we show that such scaling relations persist when the driving\nprotocol is inverted and the transition is approached again by a\nfar-from-equilibrium state. This results in a quasi-universality of the scaling\nfunctions, which keep some dependence on the details of the protocol at the\ninversion time. We explicitly determine such quasi-universal scaling functions\nby employing an effective two-level description of the many-body system near\nthe transition. We discuss the validity of this approximation and how this\nrelates to the observed scaling regime. Although our results apply to generic\nsystems, we focus on the prototypical example of a $1D$ transverse field Ising\nmodel in the ferromagnetic regime, which we drive across the first-order\ntransitions through a time-dependent longitudinal field.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:55:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12994","submitter":"Zixiang Han","authors":"Zixiang Han, Lincong Han, Xiaozhou Zhang, Yajuan Wang, Liang Ma,\n  Mengting Lou, Jing Jin, Guangyi Liu","title":"Multistatic Integrated Sensing and Communication System in Cellular\n  Networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A novel multistatic multiple-input multiple-output (MIMO) integrated sensing\nand communication (ISAC) system in cellular networks is proposed. It can make\nuse of widespread base stations (BSs) to perform cooperative sensing in wide\narea. This system is important since the deployment of sensing function can be\nachieved based on the existing mobile communication networks at a low cost. In\nthis system, orthogonal frequency division multiplexing (OFDM) signals\ntransmitted from the central BS are received and processed by each of the\nneighboring BSs to estimate sensing object parameters. A joint data processing\nmethod is then introduced to derive the closed-form solution of objects\nposition and velocity. Numerical simulation shows that the proposed multistatic\nsystem can improve the position and velocity estimation accuracy compared with\nmonostatic and bistatic system, demonstrating the effectiveness and promise of\nimplementing ISAC in the upcoming fifth generation advanced (5G-A) and sixth\ngeneration (6G) mobile networks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:55:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12995","submitter":"Rakesh R Menon","authors":"Rakesh R. Menon, Kerem Zaman, Shashank Srivastava","title":"MaNtLE: Model-agnostic Natural Language Explainer","comments":"17 pages, 13 figures, 6 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Understanding the internal reasoning behind the predictions of machine\nlearning systems is increasingly vital, given their rising adoption and\nacceptance. While previous approaches, such as LIME, generate algorithmic\nexplanations by attributing importance to input features for individual\nexamples, recent research indicates that practitioners prefer examining\nlanguage explanations that explain sub-groups of examples. In this paper, we\nintroduce MaNtLE, a model-agnostic natural language explainer that analyzes\nmultiple classifier predictions and generates faithful natural language\nexplanations of classifier rationale for structured classification tasks.\nMaNtLE uses multi-task training on thousands of synthetic classification tasks\nto generate faithful explanations. Simulated user studies indicate that, on\naverage, MaNtLE-generated explanations are at least 11% more faithful compared\nto LIME and Anchors explanations across three tasks. Human evaluations\ndemonstrate that users can better predict model behavior using explanations\nfrom MaNtLE compared to other techniques\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:58:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12996","submitter":"Kaiyu Li","authors":"Kaiyu Li, Zhuo Sun","title":"Multilevel Control Functional","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"stat.ME","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Control variates are variance reduction techniques for Monte Carlo\nestimators. They can reduce the cost of the estimation of integrals involving\ncomputationally expensive scientific models. We propose an extension of control\nvariates, multilevel control functional (MLCF), which uses non-parametric\nStein-based control variates and multifidelity models with lower cost to gain\nbetter performance. MLCF is widely applicable. We show that when the integrand\nand the density are smooth, and when the dimensionality is not very high, MLCF\nenjoys a fast convergence rate. We provide both theoretical analysis and\nempirical assessments on differential equation examples, including a Bayesian\ninference for ecological model example, to demonstrate the effectiveness of our\nproposed approach.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:59:27 GMT"},{"version":"v2","created":"Tue, 23 May 2023 14:33:39 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.12997","submitter":"Xinchi Qiu","authors":"Xinchi Qiu, Ilias Leontiadis, Luca Melis, Alex Sablayrolles, Pierre\n  Stock","title":"EXACT: Extensive Attack for Split Learning","comments":"10 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Privacy-Preserving machine learning (PPML) can help us train and deploy\nmodels that utilize private information. In particular, on-device Machine\nLearning allows us to completely avoid sharing information with a third-party\nserver during inference. However, on-device models are typically less accurate\nwhen compared to the server counterparts due to the fact that (1) they\ntypically only rely on a small set of on-device features and (2) they need to\nbe small enough to run efficiently on end-user devices. Split Learning (SL) is\na promising approach that can overcome these limitations. In SL, a large\nmachine learning model is divided into two parts, with the bigger part residing\non the server-side and a smaller part executing on-device, aiming to\nincorporate the private features. However, end-to-end training of such models\nrequires exchanging gradients at the cut layer, which might encode private\nfeatures or labels. In this paper, we provide insights into potential privacy\nrisks associated with SL and introduce a novel attack method, EXACT, to\nreconstruct private information. Furthermore, we also investigate the\neffectiveness of various mitigation strategies. Our results indicate that the\ngradients significantly improve the attacker's effectiveness in all three\ndatasets reaching almost 100% reconstruction accuracy for some features.\nHowever, a small amount of differential privacy (DP) is quite effective in\nmitigating this risk without causing significant training degradation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:00:07 GMT"},{"version":"v2","created":"Thu, 25 May 2023 15:54:58 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.12998","submitter":"Jon\\'a\\v{s} \\v{S}er\\'ych","authors":"Michal Neoral, Jon\\'a\\v{s} \\v{S}er\\'ych, Ji\\v{r}\\'i Matas","title":"MFT: Long-Term Tracking of Every Pixel","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We propose MFT -- Multi-Flow dense Tracker -- a novel method for dense,\npixel-level, long-term tracking. The approach exploits optical flows estimated\nnot only between consecutive frames, but also for pairs of frames at\nlogarithmically spaced intervals. It then selects the most reliable sequence of\nflows on the basis of estimates of its geometric accuracy and the probability\nof occlusion, both provided by a pre-trained CNN.\n  We show that MFT achieves state-of-the-art results on the TAP-Vid-DAVIS\nbenchmark, outperforming the baselines, their combination, and published\nmethods by a significant margin, achieving an average position accuracy of\n70.8%, average Jaccard of 56.1% and average occlusion accuracy of 86.9%. The\nmethod is insensitive to medium-length occlusions and it is robustified by\nestimating flow with respect to the reference frame, which reduces drift.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:02:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.12999","submitter":"Savvas Papaioannou","authors":"Savvas Papaioannou, Panayiotis Kolios, Theocharis Theocharides,\n  Christos G. Panayiotou and Marios M. Polycarpou","title":"Integrated Guidance and Gimbal Control for Coverage Planning With\n  Visibility Constraints","comments":null,"journal-ref":"IEEE Transactions on Aerospace and Electronic Systems ( Volume:\n  59, Issue: 2, April 2023)","doi":"10.1109/TAES.2022.3199196","report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Coverage path planning with unmanned aerial vehicles (UAVs) is a core task\nfor many services and applications including search and rescue, precision\nagriculture, infrastructure inspection and surveillance. This work proposes an\nintegrated guidance and gimbal control coverage path planning (CPP) approach,\nin which the mobility and gimbal inputs of an autonomous UAV agent are jointly\ncontrolled and optimized to achieve full coverage of a given object of\ninterest, according to a specified set of optimality criteria. The proposed\napproach uses a set of visibility constraints to integrate the physical\nbehavior of sensor signals (i.e., camera-rays) into the coverage planning\nprocess, thus generating optimized coverage trajectories that take into account\nwhich parts of the scene are visible through the agent's camera at any point in\ntime. The integrated guidance and gimbal control CPP problem is posed in this\nwork as a constrained optimal control problem which is then solved using mixed\ninteger programming (MIP) optimization. Extensive numerical experiments\ndemonstrate the effectiveness of the proposed approach.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:04:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13000","submitter":"Ying Zhang","authors":"Ying Zhang, Hidetaka Kamigaito, Manabu Okumura","title":"Bidirectional Transformer Reranker for Grammatical Error Correction","comments":"Accepted to the Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pre-trained seq2seq models have achieved state-of-the-art results in the\ngrammatical error correction task. However, these models still suffer from a\nprediction bias due to their unidirectional decoding. Thus, we propose a\nbidirectional Transformer reranker (BTR), that re-estimates the probability of\neach candidate sentence generated by the pre-trained seq2seq model. The BTR\npreserves the seq2seq-style Transformer architecture but utilizes a BERT-style\nself-attention mechanism in the decoder to compute the probability of each\ntarget token by using masked language modeling to capture bidirectional\nrepresentations from the target context. For guiding the reranking, the BTR\nadopts negative sampling in the objective function to minimize the\nunlikelihood. During inference, the BTR gives final results after comparing the\nreranked top-1 results with the original ones by an acceptance threshold.\nExperimental results show that, in reranking candidates from a pre-trained\nseq2seq model, T5-base, the BTR on top of T5-base could yield 65.47 and 71.27\nF0.5 scores on the CoNLL-14 and BEA test sets, respectively, and yield 59.52\nGLEU score on the JFLEG corpus, with improvements of 0.36, 0.76 and 0.48 points\ncompared with the original T5-base. Furthermore, when reranking candidates from\nT5-large, the BTR on top of T5-base improved the original T5-large by 0.26\npoints on the BEA test set.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:04:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13001","submitter":"Jerome Dedecker","authors":"C Cuny (LMBA), J Dedecker (MAP5 - UMR 8145), F Merlev\\`ede (LAMA)","title":"Strong approximations for a class of dependent random variables with\n  semi exponential tails","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We give rates of convergence in the almost sure invariance principle for sums\nof dependent random variables with semi exponential tails, whose coupling\ncoefficients decrease at a subexponential rate. We show that the rates in the\nstrong invariance principle are in powers of log n. We apply our results to iid\nproducts of random matrices.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:05:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13002","submitter":"Zhengxiang Shi","authors":"Zhengxiang Shi, Francesco Tonolini, Nikolaos Aletras, Emine Yilmaz,\n  Gabriella Kazai, Yunlong Jiao","title":"Rethinking Semi-supervised Learning with Language Models","comments":"Findings of ACL 2023. Code is available at\n  https://github.com/amzn/pretraining-or-self-training","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Semi-supervised learning (SSL) is a popular setting aiming to effectively\nutilize unlabelled data to improve model performance in downstream natural\nlanguage processing (NLP) tasks. Currently, there are two popular approaches to\nmake use of unlabelled data: Self-training (ST) and Task-adaptive pre-training\n(TAPT). ST uses a teacher model to assign pseudo-labels to the unlabelled data,\nwhile TAPT continues pre-training on the unlabelled data before fine-tuning. To\nthe best of our knowledge, the effectiveness of TAPT in SSL tasks has not been\nsystematically studied, and no previous work has directly compared TAPT and ST\nin terms of their ability to utilize the pool of unlabelled data. In this\npaper, we provide an extensive empirical study comparing five state-of-the-art\nST approaches and TAPT across various NLP tasks and data sizes, including in-\nand out-of-domain settings. Surprisingly, we find that TAPT is a strong and\nmore robust SSL learner, even when using just a few hundred unlabelled samples\nor in the presence of domain shifts, compared to more sophisticated ST\napproaches, and tends to bring greater improvements in SSL than in\nfully-supervised settings. Our further analysis demonstrates the risks of using\nST approaches when the size of labelled or unlabelled data is small or when\ndomain shifts exist. We offer a fresh perspective for future SSL research,\nsuggesting the use of unsupervised pre-training objectives over dependency on\npseudo labels.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:07:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13003","submitter":"Vladyslav Kuchkin","authors":"Vladyslav M. Kuchkin and Nikolai S. Kiselev","title":"Skyrmions and antiskyrmions in monoaxial chiral magnets","comments":"5 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall cond-mat.str-el","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We show that competition between local interactions in monoaxial chiral\nmagnets provides the stability of two-dimensional (2D) solitons with identical\nenergies but opposite topological charges. These skyrmions and antiskyrmions\nrepresent metastable states in a wide range of parameters above the transition\ninto the saturated ferromagnetic phase. The symmetry of the underlying\nmicromagnetic functional gives rise to soliton zero modes allowing efficient\ncontrol of their translational movement by the frequency of the circulating\nexternal magnetic field. We also discuss the role of demagnetizing fields in\nthe energy balance between skyrmion and antiskyrmion and in their stability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:08:11 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13004","submitter":"Jaroslav Nejdl","authors":"Martin Albrecht, Ond\\v{r}ej Hort, Michaela Kozlov\\'a, Miroslav\n  Kr\\r{u}s, and Jaroslav Nejdl","title":"Single-shot spatial coherence of a plasma based soft X-ray laser","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Many applications of short-wavelength radiation impose strong requirements on\nthe coherence properties of the source. However, the measurement of such\nproperties poses a challenge, mainly due to the lack of high-quality optics and\nsource fluctuations that often violate assumptions necessary for multi-shot or\ncumulative techniques. In this article, we present a new method of single-shot\nspatial coherence measurement adapted to the soft X-ray spectral range. Our\nmethod is based on a far-field diffraction pattern from a binary transmission\nmask consisting of a non-redundant array of simple apertures. Unlike all\ncurrently available methods, our technique allows measuring radiation field\nwith an arbitrary spatial coherence function without any prior assumption on\nintensity distribution or the model of the degree of spatial coherence. We\nexperimentally verified the technique by retrieving the spatial coherence\nfunctions of individual shots of laser-driven Zn plasma soft X-ray laser with\none- and two-dimensional masks. The experimental results revealed nontrivial\nillumination pattern and strong asymmetry of the spatial coherence function,\nwhich clearly calls for abandoning the often used models that assume rotational\ninvariance of the coherence function, such as the popular Gaussian-Schell beam\nmodel.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:08:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13005","submitter":"Daniel Barlet","authors":"Daniel Barlet (UL), Jon Ingolfur Magnusson","title":"Cycles of finite type","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The aim of this book is to show that the use of f-analytic families of finite\ntype cycles (cycles having finitely many irreducible components, but not\ncompact in general) in a given complex space may be useful in complex geometry,\ndespite the fact that the corresponding functor is not, in general,\nrepresentable, in contrast to the compact case. This study leads to the notion\nof strongly quasi-proper map which is characterized by the existence of a\ngeometric f-flattening which is a generalization of the Geometric Flattening\nTheorem for proper holomorphic maps. As applications we prove an existence\ntheorem for meromorphic quotients of reduced complex spaces and a\ngeneralization of the classic Stein factorization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:11:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13006","submitter":"Li-Yi Hsu","authors":"Li-Yi Hsu","title":"Statistical link between Bell nonlocality and uncertainty relations","comments":"12 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bell nonlocality and uncertainty relations are distinct features of quantum\ntheory from classical physics. Bell nonlocality concerns the correlation\nstrength among local observables on different quantum particles, whereas the\nuncertainty relations set the lower bound of the sum or product of the variance\nsquare of observables. Here we establish the statistical link between these two\nquantum characters using the Aharonov-Vaidman identity. Therein, the upper\nbounds of Bell-type inequalities are expressed in terms of the product of the\nlocal sum of the variance square. On the other hand, instead of evaluating\nlocal uncertainty relations, the uncertainty relations on two or more quantum\nsystems are upper-bounded by the amount of Bell nonlocality therein.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:11:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13007","submitter":"Federico Dalmao","authors":"Federico Dalmao, Jos\\'e R. Le\\'on","title":"On the number of roots of Sturm-Liouville random sums","comments":"9 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We consider the number of roots of linear combinations of a system of $n$\northogonal eigenfunctions of a Sturm-Liouville initial value problem with\ni.i.d. standard Gaussian coefficients. We prove that its distribution inherits\nthe asymptotic behavior of the number of roots of Quall's random trigonometric\npolynomials. This result can be thought as a robustness result for the central\nlimit theorem for the number of roots of Quall's random trigonometric\npolynomials in the sense that small uniform perturbations of sines and cosines\ndo not change the limit distribution.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:11:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13008","submitter":"Alexandru Ionita","authors":"Alexandru Ionita and Denis-Andrei Banu and Iulian Oleniuc","title":"Heuristics Optimization of Boolean Circuits with application in\n  Attribute Based Encryption","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CC","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a method of optimizing monotone Boolean circuits by re-writing\nthem in a simpler, equivalent form. We use in total six heuristics: Hill\nClimbing, Simulated Annealing, and variations of them, which operate on the\nrepresentation of the circuit as a logical formula. Our main motivation is to\nimprove performance in Attribute-Based Encryption (ABE) schemes for Boolean\ncircuits. Therefore, we show how our heuristics improve ABE systems for Boolean\ncircuits. Also, we run tests to evaluate the performance of our heuristics,\nboth as a standalone optimization for Boolean circuits and also inside ABE\nsystems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:12:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13009","submitter":"Michael Hassid","authors":"Michael Hassid, Tal Remez, Tu Anh Nguyen, Itai Gat, Alexis Conneau,\n  Felix Kreuk, Jade Copet, Alexandre Defossez, Gabriel Synnaeve, Emmanuel\n  Dupoux, Roy Schwartz, Yossi Adi","title":"Textually Pretrained Speech Language Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG cs.SD eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Speech language models (SpeechLMs) process and generate acoustic data only,\nwithout textual supervision. In this work, we propose TWIST, a method for\ntraining SpeechLMs using a warm-start from a pretrained textual language\nmodels. We show using both automatic and human evaluations that TWIST\noutperforms a cold-start SpeechLM across the board. We empirically analyze the\neffect of different model design choices such as the speech tokenizer, the\npretrained textual model, and the dataset size. We find that model and dataset\nscale both play an important role in constructing better-performing SpeechLMs.\nBased on our observations, we present the largest (to the best of our\nknowledge) SpeechLM both in terms of number of parameters and training data. We\nadditionally introduce two spoken versions of the StoryCloze textual benchmark\nto further improve model evaluation and advance future research in the field.\nSpeech samples can be found on our website:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/twist/ .\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:12:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13010","submitter":"Gabriele Vezzosi","authors":"Betrand To\\\"en and Gabriele Vezzosi","title":"Infinitesimal derived foliations","comments":"19 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We introduce a notion of \\emph{infinitesimal derived foliation}. We prove it\nis related to the classical notion of infinitesimal cohomology, and satisfies\nsome formal integrability properties. We also provide some hints on how\ninfinitesimal derived foliations compare to our previous notion of derived\nfoliations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:15:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13011","submitter":"Wijnand Broer","authors":"Wijnand Broer and Rudolf Podgornik","title":"Interplay between finite thickness and chirality effects on the\n  Casimir-Lifshitz torque with nematic cholesteric liquid crystals","comments":"13 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph cond-mat.soft","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We theoretically investigate the combined effects of the chirality and the\nfinite total thickness of nematic cholesteric liquid crystals on the\nCasimir-Lifshitz torque. We find that, the larger the thickness, the more\nsinusoidal the angular dependence of the torque becomes. We use a Fourier\ndecomposition to quantify this result. The general direction of the torque\ndepends on whether the configuration of two cholesterics is heterochiral or\nhomochiral.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:15:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13012","submitter":"Lasse Leskel\\\"a","authors":"Hannu Reittu, Lasse Leskel\\\"a, Tomi R\\\"aty","title":"A network community detection method with integration of data from\n  multiple layers and node attributes","comments":null,"journal-ref":"Published version: Network Science 2023","doi":"10.1017/nws.2023.2","report-no":null,"categories":"physics.soc-ph stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multilayer networks are in the focus of the current complex network study. In\nsuch networks multiple types of links may exist as well as many attributes for\nnodes. To fully use multilayer -- and other types of complex networks in\napplications, the merging of various data with topological information renders\na powerful analysis. First, we suggest a simple way of representing network\ndata in a data matrix where rows correspond to the nodes, and columns\ncorrespond to the data items. The number of columns is allowed to be arbitrary,\nso that the data matrix can be easily expanded by adding columns. The data\nmatrix can be chosen according to targets of the analysis, and may vary a lot\nfrom case to case. Next, we partition the rows of the data matrix into\ncommunities using a method which allows maximal compression of the data matrix.\nFor compressing a data matrix, we suggest to extend so called regular\ndecomposition method for non-square matrices. We illustrate our method for\nseveral types of data matrices, in particular, distance matrices, and matrices\nobtained by augmenting a distance matrix by a column of node degrees, or by\nconcatenating several distances matrices corresponding to layers of a\nmultilayer network. We illustrate our method with synthetic power-law graphs\nand two real networks: an Internet autonomous systems graph and a world airline\ngraph. We compare the outputs of different community recovery methods on these\ngraphs, and discuss how incorporating node degrees as a separate column to the\ndata matrix leads our method to identify community structures well-aligned with\ntiered hierarchical structures commonly encountered in complex scale-free\nnetworks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:15:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13013","submitter":"Mostafizur Rahman","authors":"Mostafizur Rahman, Anjan A Sen, Sunil Singh Bohra","title":"Traversable wormholes in bi-metric gravity","comments":"14 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc astro-ph.CO hep-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The ghost-free bi-metric gravity theory is a viable theory of gravity that\nexplores the interaction between a massless and a massive graviton and can be\ndescribed in terms of two dynamical metrics. In this paper, we present an exact\nstatic, spherically symmetric vacuum solution within this theory. The solution\nis spatially Schwarzschild-de Sitter, with the value of the cosmological\nconstant determined by the graviton mass and the interaction parameters of the\ntheory. Notably, for specific parameter ranges, the solution represents a\ntraversable Lorentzian wormhole that violates the weak energy condition near\nits throat. Furthermore, we have investigated the evolution of scalar and\nelectromagnetic fields in this wormhole spacetime and observed the presence of\narbitrarily long-lived quasi-resonant modes in the quasinormal spectrum.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:15:40 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13014","submitter":"Stefano De Paoli Prof","authors":"Stefano De Paoli","title":"Can Large Language Models emulate an inductive Thematic Analysis of\n  semi-structured interviews? An exploration and provocation on the limits of\n  the approach and the model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Large Language Models (LLMs) have emerged as powerful generative Artificial\nIntelligence solutions which can be applied to several fields and areas of\nwork. This paper presents results and reflection of an experiment done to use\nthe model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic\nAnalysis. Previous research on this subject has largely worked on conducting\ndeductive analysis. Thematic Analysis is a qualitative method for analysis\ncommonly used in social sciences and it is based on interpretations made by the\nhuman analyst(s) and the identification of explicit and latent meanings in\nqualitative data. Attempting an analysis based on human interpretation with an\nLLM clearly is a provocation but also a way to learn something about how these\nsystems can or cannot be used in qualitative research. The paper presents the\nmotivations for attempting this emulation, it reflects on how the six steps to\na Thematic Analysis proposed by Braun and Clarke can at least partially be\nreproduced with the LLM and it also reflects on what are the outputs produced\nby the model. The paper used two existing datasets of open access\nsemi-structured interviews, previously analysed with Thematic Analysis by other\nresearchers. It used the previously produced analysis (and the related themes)\nto compare with the results produced by the LLM. The results show that the\nmodel can infer at least partially some of the main Themes. The objective of\nthe paper is not to replace human analysts in qualitative analysis but to learn\nif some elements of LLM data manipulation can to an extent be of support for\nqualitative research.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:16:07 GMT"},{"version":"v2","created":"Wed, 24 May 2023 14:01:51 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13015","submitter":"Yihua Zhu","authors":"Yihua Zhu, Hidetoshi Shimodaira","title":"3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The main objective of Knowledge Graph (KG) embeddings is to learn\nlow-dimensional representations of entities and relations, enabling the\nprediction of missing facts. A significant challenge in achieving better KG\nembeddings lies in capturing relation patterns, including symmetry,\nantisymmetry, inversion, commutative composition, non-commutative composition,\nhierarchy, and multiplicity. This study introduces a novel model called 3H-TH\n(3D Rotation and Translation in Hyperbolic space) that captures these relation\npatterns simultaneously. In contrast, previous attempts have not achieved\nsatisfactory performance across all the mentioned properties at the same time.\nThe experimental results demonstrate that the new model outperforms existing\nstate-of-the-art models in terms of accuracy, hierarchy property, and other\nrelation patterns in low-dimensional space, meanwhile performing similarly in\nhigh-dimensional space.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:17:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13016","submitter":"Jiaxi Yang","authors":"Jiaxi Yang, Binyuan Hui, Min Yang, Binhua Li, Fei Huang, Yongbin Li","title":"Iterative Forward Tuning Boosts In-context Learning in Language Models","comments":"14 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models (LLMs) have exhibited an emergent in-context learning\n(ICL) ability. However, the ICL models that can solve ordinary cases are hardly\nextended to solve more complex tasks by processing the demonstration examples\nonce. This single-turn ICL is incoordinate with the decision making process of\nhumans by learning from analogy. In this paper, we propose an effective and\nefficient two-stage framework to boost ICL in LLMs by exploiting a dual form\nbetween Transformer attention and gradient descent-based optimization.\nConcretely, we divide the ICL process into \"Deep-Thinking\" and inference\nstages. The \"Deep-Thinking\" stage performs iterative forward optimization of\ndemonstrations, which is expected to boost the reasoning abilities of LLMs at\ntest time by \"thinking\" demonstrations multiple times. It produces accumulated\nmeta-gradients by manipulating the Key-Value matrices in the self-attention\nmodules of the Transformer. Then, the inference stage only takes the test query\nas input without concatenating demonstrations and applies the learned\nmeta-gradients through attention for output prediction. In this way,\ndemonstrations are not required during the inference stage since they are\nalready learned and stored in the definitive meta-gradients. LLMs can be\neffectively and efficiently adapted to downstream tasks. Extensive experiments\non ten classification and multiple-choice datasets show that our method\nachieves substantially better performance than standard ICL in terms of both\naccuracy and efficiency.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:18:17 GMT"},{"version":"v2","created":"Tue, 30 May 2023 05:47:19 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13017","submitter":"Dorota Walicka","authors":"Dorota I. Walicka, Robin Lefevre, Olivier Blacque, Sara A. Lopez-Paz,\n  Carl W. Rischau, Antonio Cervellino, Carlos A. Triana, Fabian O. von Rohr","title":"Structural Phase Transition and Superconductivity in 2H-BaGaGe with\n  Buckled Honeycomb Layers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.supr-con cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We report on the structural and superconducting properties of the\nintermetallic compound BaGaGe. We find that this material undergoes a\nstructural second-order phase transition from the distorted AlB$_2$-type\nstructure (1H, $a$ = 4.3254(2) \\r{A}, $c$ = 5.1078(3) \\r{A}, P6/mmm) into the\nCaIn$_2$-type structure (2H, $a$ = 4.3087(3) \\r{A}, $c$ = 10.2117(6) \\r{A},\nP6$_3$/mmc) at a transition temperature of $T_{\\rm S}$ = 253 K. We find that\nthe structural phase-transition corresponds to a coherent buckling of the\nhoneycomb layers, which we can interpret as a disorder-to-order transition of\nthe atoms located within this layer. We show that the 2H-BaGaGe phase becomes\nsuperconducting at a critical temperature of $T_{\\rm c}$ = 2.1 K. The bulk\nnature of the superconductivity in 2H-BaGaGe is confirmed by means of specific\nheat measurements, where we determine a value of $\\Delta C$/$\\gamma T_{\\rm c}$\n= 1.59, which is close to the expected BCS value in the weak coupling limit.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:20:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13018","submitter":"Stefan Heinze","authors":"Moritz A. Goerzen, Stephan von Malottki, Sebastian Meyer, Pavel F.\n  Bessarab, Stefan Heinze","title":"Lifetime of coexisting sub-10 nm zero-field skyrmions and antiskyrmions","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Magnetic skyrmions have raised high hopes for future spintronic devices. For\nmany applications it would be of great advantage to have more than one\nmetastable particle-like texture available. The coexistence of skyrmions and\nantiskyrmions has been proposed in inversion symmetric magnets with exchange\nfrustration. However, so far only model systems have been studied and the\nlifetime of coexisting metastable topological spin structures has not been\nobtained. Here, we predict that skyrmions and antiskyrmions with diameters\nbelow 10 nm can coexist at zero magnetic field in a Rh/Co bilayer on the\nIr(111) surface -- an experimentally feasible system. We show that the\nlifetimes of metastable skyrmions and antiskyrmions in the ferromagnetic ground\nstate are above one hour for temperatures up to 75 K and 48 K, respectively.\nThe entropic contribution to the nucleation and annihilation rates differs for\nskyrmions and antiskyrmions. This opens the route to thermally activated\ncreation of coexisting skyrmions and antiskyrmions in frustrated magnets with\nDzyaloshinskii-Moriya interaction.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:21:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13019","submitter":"Zihao Zhang","authors":"Zihao Zhang, Susan L. Epstein, Casey Breen, Sophia Xia, Zhigang Zhu,\n  Christian Volkmann","title":"Robots in the Garden: Artificial Intelligence and Adaptive Landscapes","comments":"4 figures, 9 pages","journal-ref":"Journal of Digital Landscape Architecture, 2023","doi":"10.14627/537740028","report-no":null,"categories":"cs.RO cs.AI cs.CV cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper introduces ELUA, the Ecological Laboratory for Urban Agriculture,\na collaboration among landscape architects, architects and computer scientists\nwho specialize in artificial intelligence, robotics and computer vision. ELUA\nhas two gantry robots, one indoors and the other outside on the rooftop of a\n6-story campus building. Each robot can seed, water, weed, and prune in its\ngarden. To support responsive landscape research, ELUA also includes sensor\narrays, an AI-powered camera, and an extensive network infrastructure. This\nproject demonstrates a way to integrate artificial intelligence into an\nevolving urban ecosystem, and encourages landscape architects to develop an\nadaptive design framework where design becomes a long-term engagement with the\nenvironment.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:21:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13020","submitter":"Manjunath B G","authors":"Barry C. Arnold, Sachin Sachdeva and B.G. Manjunath","title":"Some power function distribution processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  It is known that all the proportional reversed hazard (PRH) processes can be\nde?rived by a marginal transformation applied to a power function distribution\n(PFD) process. Kundu [8] investigated PRH processes that can be viewed as being\nob?tained by marginal transformations applied to a particular PFD process that\nwill be described and investigated and will be called a Kundu process. In the\npresent note, in addition to studying the Kundu process, we introduce a new PFD\nprocess having Markovian and stationarity properties. We discuss distributional\nfeatures of such processes, explore inferential aspects and include an example\nof applications of the PFD processes to real-life data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:22:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13021","submitter":"Ambre Davat","authors":"Ambre Davat (GIPSA-PCMD,LIG), V\\'eronique Auberg\\'e (LIG), Gang Feng\n  (GIPSA-lab)","title":"Can we hear physical and social space together through prosody?","comments":null,"journal-ref":"Speech Prosody 2020, May 2020, Tokyo, Japan. pp.715-719","doi":"10.21437/SpeechProsody.2020-146","report-no":null,"categories":"cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  When human listeners try to guess the spatial position of a speech source,\nthey are influenced by the speaker's production level, regardless of the\nintensity level reaching their ears. Because the perception of distance is a\nvery difficult task, they rely on their own experience, which tells them that a\nwhispering talker is close to them, and that a shouting talker is far away.\nThis study aims to test if similar results could be obtained for prosodic\nvariations produced by a human speaker in an everyday life environment. It\nconsists in a localization task, during which blindfolded subjects had to\nestimate the incoming voice direction, speaker orientation and distance of a\ntrained female speaker, who uttered single words, following instructions\nconcerning intensity and social-affect to be performed. This protocol was\nimplemented in two experiments. First, a complex pretext task was used in order\nto distract the subjects from the strange behavior of the speaker. On the\ncontrary, during the second experiment, the subjects were fully aware of the\nprosodic variations, which allowed them to adapt their perception. Results show\nthe importance of the pretext task, and suggest that the perception of the\nspeaker's orientation can be influenced by voice intensity.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:25:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13022","submitter":"Hongyan Liu","authors":"Hongyan Liu, Oscar van der Heide, Edwin Versteeg, Martijn Froeling,\n  Miha Fuderer, Fei Xu, Cornelis A.T. van den Berg and Alessandro Sbrizzi","title":"A three-dimensional MR-STAT protocol for high-resolution\n  multi-parametric quantitative MRI","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Magnetic Resonance Spin Tomography in Time-Domain (MR-STAT) is a\nmultiparametric quantitative MR framework, which allows for simultaneously\nacquiring quantitative tissue parameters such as T1, T2 and proton density from\none single short scan. A typical 2D MR-STAT acquisition uses a\ngradient-spoiled, gradient-echo sequence with a slowly varying RF flip-angle\ntrain and Cartesian readouts, and the quantitative tissue maps are\nreconstructed by an iterative, model-based optimization algorithm. In this\nwork, we design a 3D MR-STAT framework based on previous 2D work, in order to\nachieve better image SNR, higher though-plan resolution and better tissue\ncharacterization. Specifically, we design a 7-minute, high-resolution 3D\nMR-STAT sequence, and the corresponding two-step reconstruction algorithm for\nthe large-scale dataset. To reduce the long acquisition time, Cartesian\nundersampling strategies such as SENSE are adopted in our transient-state\nquantitative framework. To reduce the computational burden, a data splitting\nscheme is designed for decoupling the 3D reconstruction problem into\nindependent 2D reconstructions. The proposed 3D framework is validated by\nnumerical simulations, phantom experiments and in-vivo experiments.\nHigh-quality knee quantitative maps with 0.8 x 0.8 x 1.5mm3 resolution and\nbilateral lower leg maps with 1.6mm isotropic resolution can be acquired using\nthe proposed 7-minute acquisition sequence and the 3-minute-per-slice decoupled\nreconstruction algorithm. The proposed 3D MR-STAT framework could have wide\nclinical applications in the future.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:25:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13023","submitter":"Shunsuke Neda","authors":"Kentaro Kasai, Masahiro Kawasaki, Naoya Kitajima, Kai Murai, Shunsuke\n  Neda, Fuminobu Takahashi","title":"Clustering of Primordial Black Holes from QCD Axion Bubbles","comments":"18 pages, 11 figures","journal-ref":null,"doi":null,"report-no":"TU-1189","categories":"astro-ph.CO hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the clustering of primordial black holes (PBHs) and axion\nminiclusters produced in the model proposed to explain the LIGO/Virgo events or\nthe seeds of the supermassive black holes (SMBHs) in arXiv:2006.13137. It is\nfound that this model predicts large isocurvature perturbations due to the\nclustering of PBHs and axion miniclusters, from which we obtain stringent\nconstraints on the model parameters. Specifically, for the axion decay constant\n$f_a=10^{16}~\\mathrm{GeV}$, which potentially accounts for the seeds of the\nSMBHs, the PBH fraction in dark matter should be $f_\\mathrm{PBH}\\lesssim7\\times\n10^{-10}$. Assuming that the mass of PBHs increases by more than a factor of\n$\\mathcal{O}(10)$ due to accretion, this is consistent with the observed\nabundance of SMBHs. On the other hand, for $f_a=10^{17}~\\mathrm{GeV}$ required\nto produce PBHs of masses detected in the LIGO/Virgo, the PBH fraction should\nbe $f_\\mathrm{PBH}\\lesssim6\\times 10^{-8}$, which may be too small to explain\nthe LIGO/Virgo events, although there is a significant uncertainty in\ncalculating the merger rate in the presence of clustering.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:26:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13024","submitter":"Fran\\c{c}ois Renaville","authors":"Fabienne Prosmans and Fran\\c{c}ois Renaville","title":"Changing tools, changing habits, changing workflows: Recent evolutions\n  of the interlibrary loan service at ULi\\`ege Library","comments":"10 pages, with charts and tables","journal-ref":"Beyond the Library Collections:Proceedings of the 2022 Erasmus\n  Staff Training Week at ULi\\`ege Library (pp. 139-159)","doi":"10.25518/978-2-87019-313-6.13","report-no":null,"categories":"cs.DL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Over the last few years, the interlibrary loan (ILL) service of the\nUniversity of Li\\`ege Library has evolved considerably, both in terms of habits\nand workflows. In this article, we will explain the main stages of this\nevolution: (1) first reduction in the number of ILL units (from eight to five)\nand involved operators (from 15 to 10) within the homemade ILL solution (2015);\n(2) use of the resource sharing (RS) functionality in the new Alma library\nmanagement system (2015); (3) second reduction in the number of ILL units (from\nfive to only one) and in involved operators (from 10 to six) (2018); (4)\nsubscription to an international broker ILL system (RapidILL) for electronic\nand digital materials and its integration with Alma (2020); (5) project of\npeer-to-peer resource sharing for print materials between Alma instances of\nuniversity and research libraries in Belgium (2022), and (temporary) free ILL\nservice to all University users (2020-2022). The aim of these changes is to\nharmonise the practices of ILL operators, reduce the quantity of manual and\nadministrative operations and tasks devoted to ILL and supply materials that do\nnot belong to the library collections in a fairer, faster and more fluid way.\nWhile all of these changes have been implemented gradually over the years, not\nall of them have been deployed in a concerted manner among all stakeholders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:26:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13025","submitter":"Tokuhiro Eto","authors":"Tokuhiro Eto, Yoshikazu Giga","title":"On a minimizing movement scheme for mean curvature flow with prescribed\n  contact angle in a curved domain and its computation","comments":"28 pages, 17 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We introduce a capillary Chambolle type scheme for mean curvature flow with\nprescribed contact angle. Our scheme includes a capillary functional instead of\njust the total variation. We show that the scheme is well-defined and has\nconsistency with the energy minimizing scheme of Almgren-Taylor-Wang type.\nMoreover, for a planar motion in a strip, we give several examples of numerical\ncomputation of this scheme based on the split Bregman method instead of a\nduality method.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:27:06 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13026","submitter":"Wietse de Vries","authors":"Wietse de Vries, Martijn Wieling and Malvina Nissim","title":"DUMB: A Benchmark for Smart Evaluation of Dutch Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We introduce the Dutch Model Benchmark: DUMB. The benchmark includes a\ndiverse set of datasets for low-, medium- and high-resource tasks. The total\nset of eight tasks include three tasks that were previously not available in\nDutch. Instead of relying on a mean score across tasks, we propose Relative\nError Reduction (RER), which compares the DUMB performance of models to a\nstrong baseline which can be referred to in the future even when assessing\ndifferent sets of models. Through a comparison of 14 pre-trained models (mono-\nand multi-lingual, of varying sizes), we assess the internal consistency of the\nbenchmark tasks, as well as the factors that likely enable high performance.\nOur results indicate that current Dutch monolingual models under-perform and\nsuggest training larger Dutch models with other architectures and pre-training\nobjectives. At present, the highest performance is achieved by DeBERTaV3\n(large), XLM-R (large) and mDeBERTaV3 (base). In addition to highlighting best\nstrategies for training larger Dutch models, DUMB will foster further research\non Dutch. A public leaderboard is available at https://dumbench.nl.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:27:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13027","submitter":"Sho Suda","authors":"Alexander L. Gavrilyuk and Sho Suda","title":"Uniqueness of an association scheme related to the Witt design on 11\n  points","comments":"4 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  It follows from Delsarte theory that the Witt $4$-$(11,5,1)$ design gives\nrise to a $Q$-polynomial association scheme $\\mathcal{W}$ defined on the set of\nits blocks. In this note we show that $\\mathcal{W}$ is unique, i.e., defined up\nto isomorphism by its parameters.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:29:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13028","submitter":"Adam Ingram Dr","authors":"A. Ingram, M. Ewing, A. Marinucci, D. Tagliacozzo, D. J. Rosario, A.\n  Veledina, D. E. Kim, F. Marin, S. Bianchi, J. Poutanen, G. Matt, H. L.\n  Marshall, F. Ursini, A. De Rosa, P-O. Petrucci, G. Madejski, T. Barnouin, L.\n  Di Gesu, M. Dovvciak, V. E. Gianolli, H. Krawczynski, V. Loktev, R. Middei,\n  J. Podgorny, S. Puccetti, A. Ratheesh, P. Soffitta, F. Tombesi, S. R. Ehlert,\n  F. Massaro, I. Agudo, L. A. Antonelli, M. Bachetti, L. Baldini, W. H.\n  Baumgartner, R. Bellazzini, S. D. Bongiorno, R. Bonino, A. Brez, N.\n  Bucciantini, F. Capitanio, S. Castellano, E. Cavazzuti, C.-T. Chen, S.\n  Ciprini, E. Costa, E. Del Monte, N. Di Lalla, A. Di Marco, I. Donnarumma, V.\n  Doroshenko, T. Enoto, Y. Evangelista, S. Fabiani, R. Ferrazzoli, J. A.\n  Garcia, S. Gunji, J. Heyl, W. Iwakiri, S. G. Jorstad, P. Kaaret, V. Karas, F.\n  Kislat, T. Kitaguchi, J. J. Kolodziejczak, F. La Monaca, L. Latronico, I.\n  Liodakis, S. Maldera, A. Manfreda, A. P. Marscher, I. Mitsuishi, T. Mizuno,\n  F. Muleri, M. Negro, C.-Y. Ng, S. L. ODell, N. Omodei, C. Oppedisano, A.\n  Papitto, G. G. Pavlov, A. L. Peirson, M. Perri, M. Pesce-Rollins, M. Pilia,\n  A. Possenti, B. D. Ramsey, J. Rankin, O. J. Roberts, R. W. Romani, C. Sgro,\n  P. Slane, G. Spandre, D. A. Swartz, T. Tamagawa, F. Tavecchio, R. Taverna, Y.\n  Tawara, A. F. Tennant, N. E. Thomas, A. Trois, S. S. Tsygankov, R. Turolla,\n  J. Vink, M. C. Weisskopf, K. Wu, F. Xie, S. Zane","title":"The X-ray polarisation of the Seyfert 1 galaxy IC 4329A","comments":"Submitted to MNRAS, 12 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.HE","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present an X-ray spectro-polarimetric analysis of the bright Seyfert\ngalaxy IC 4329A. The Imaging X-ray Polarimetry Explorer (IXPE) observed the\nsource for ~500 ks, supported by XMM-Newton (~60 ks) and NuSTAR (~80 ks)\nexposures. We detect polarisation in the 2-8 keV band with 2.97 sigma\nconfidence. We report a polarisation degree of $3.3\\pm1.1$ per cent and a\npolarisation angle of $78\\pm10$ degrees (errors are 1 sigma confidence). The\nX-ray polarisation is consistent with being aligned with the radio jet, albeit\npartially due to large uncertainties on the radio position angle. We jointly\nfit the spectra from the three observatories to constrain the presence of a\nrelativistic reflection component. From this, we obtain constraints on the\ninclination angle to the inner disc (< 39 degrees at 99 per cent confidence)\nand the disc inner radius (< 11 gravitational radii at 99 per cent confidence),\nalthough we note that modelling systematics in practice add to the quoted\nstatistical error. Our spectro-polarimetric modelling indicates that the 2-8\nkeV polarisation is consistent with being dominated by emission directly\nobserved from the X-ray corona, but the polarisation of the reflection\ncomponent is completely unconstrained. Our constraints on viewer inclination\nand polarisation degree tentatively favour more asymmetric, possibly\nout-flowing, coronal geometries that produce more highly polarised emission,\nbut the coronal geometry is unconstrained at the 3 sigma level.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:31:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13029","submitter":"Mike Reeks","authors":"Micheal W Reeks","title":"On the emission of ultra fine particles from municipal solid waste (MSW)\n  incinerators","comments":"15 pages, 8 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  Nationally approved emission factors of mass versus particle size for\nparticulate emissions from UK MSW incinerators when converted to particle\nnumber versus size, indicate that nearly all (>90\\%) of the emitted particles\nare ultra fine particles (ufps) < .1 micron in size. A similar result is true\nalso of US MSW incinerators emissions. This would imply that the bag/fiber\nfilters used for the removal of particles produced in the incineration process\nhave a very low efficiency for the removal of ufps. This result is at variance\nwith recent assertions that bag filters have a high removal efficiency for\nufps. An analysis of fiber filter retention based on the fundamental mechanisms\nfor the deposition of small particles to single filter fibers and their\ndependence on particle size, shows that whilst the removal efficiency is 100 %\nfor particles << . 1 micron, there is a minimum of the filter retention\nefficiency in the region 0.05 to 0.5 microns where the concentration of the\nufps is most likely to be greatest. In some cases depending on the flow and\nparticle size, the filter efficiency is as low as 5% compared to almost 100%\nretention efficiency for particles > 1 micron (within the inertial impaction\nrange of particles). It is believed this explains the very high release rates\n\\sim10^{14} particles/s from these incinerators.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:32:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13030","submitter":"Keisuke Fujii","authors":"Keisuke Fujii, Kazushi Tsutsui, Atom Scott, Hiroshi Nakahara, Naoya\n  Takeishi, Yoshinobu Kawahara","title":"Adaptive action supervision in reinforcement learning from real-world\n  multi-agent demonstrations","comments":"14 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Modeling of real-world biological multi-agents is a fundamental problem in\nvarious scientific and engineering fields. Reinforcement learning (RL) is a\npowerful framework to generate flexible and diverse behaviors in cyberspace;\nhowever, when modeling real-world biological multi-agents, there is a domain\ngap between behaviors in the source (i.e., real-world data) and the target\n(i.e., cyberspace for RL), and the source environment parameters are usually\nunknown. In this paper, we propose a method for adaptive action supervision in\nRL from real-world demonstrations in multi-agent scenarios. We adopt an\napproach that combines RL and supervised learning by selecting actions of\ndemonstrations in RL based on the minimum distance of dynamic time warping for\nutilizing the information of the unknown source dynamics. This approach can be\neasily applied to many existing neural network architectures and provide us\nwith an RL model balanced between reproducibility as imitation and\ngeneralization ability to obtain rewards in cyberspace. In the experiments,\nusing chase-and-escape and football tasks with the different dynamics between\nthe unknown source and target environments, we show that our approach achieved\na balance between the reproducibility and the generalization ability compared\nwith the baselines. In particular, we used the tracking data of professional\nfootball players as expert demonstrations in football and show successful\nperformances despite the larger gap between behaviors in the source and target\nenvironments than the chase-and-escape task.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:33:37 GMT"},{"version":"v2","created":"Sat, 27 May 2023 01:56:14 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13031","submitter":"Ding Jian","authors":"Jian Ding, Nan Xue, Gui-Song Xia, Bernt Schiele, Dengxin Dai","title":"HGFormer: Hierarchical Grouping Transformer for Domain Generalized\n  Semantic Segmentation","comments":"Accepted by CVPR 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Current semantic segmentation models have achieved great success under the\nindependent and identically distributed (i.i.d.) condition. However, in\nreal-world applications, test data might come from a different domain than\ntraining data. Therefore, it is important to improve model robustness against\ndomain differences. This work studies semantic segmentation under the domain\ngeneralization setting, where a model is trained only on the source domain and\ntested on the unseen target domain. Existing works show that Vision\nTransformers are more robust than CNNs and show that this is related to the\nvisual grouping property of self-attention. In this work, we propose a novel\nhierarchical grouping transformer (HGFormer) to explicitly group pixels to form\npart-level masks and then whole-level masks. The masks at different scales aim\nto segment out both parts and a whole of classes. HGFormer combines mask\nclassification results at both scales for class label prediction. We assemble\nmultiple interesting cross-domain settings by using seven public semantic\nsegmentation datasets. Experiments show that HGFormer yields more robust\nsemantic segmentation results than per-pixel classification methods and flat\ngrouping transformers, and outperforms previous methods significantly. Code\nwill be available at https://github.com/dingjiansw101/HGFormer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:33:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13032","submitter":"Jirka Poropudas","authors":"Jirka Poropudas and Topi Halme","title":"Dean Oliver's Four Factors Revisited","comments":"30 pages, 10 figures, to be submitted","journal-ref":null,"doi":null,"report-no":null,"categories":"stat.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper studies the relationship between basketball teams' four factors\nand efficiency ratings as defined by Oliver (2004). The paper introduces an\nequation showing how a team's four factors in conjunction with its field goal\nand free throw percentages can be used to calculate its offensive rating.\nMoreover, the substitution of defensive four factors into the equation allows\nfor the calculation of defensive and net ratings. To incorporate recent trends\nin the NBA, the paper updates the estimation for the relative frequency of\npossession-ending free throws which are needed to estimate the number of\npossessions from box score data. Sensitivity analysis of the offensive rating\nis performed in order to better understand the relative importance of the four\nfactors. By examining partial derivatives of the offensive rating, the paper\nquantifies the marginal impact of small changes in the offensive and defensive\nfour factors on offensive, defensive, and net ratings. Most importantly it is\nobserved that the relationship between the four factors and efficiency ratings\nis non-linear and the individual factors' effect on the ratings depends on the\nvalues of the other factors. The paper also includes examples from NBA seasons\nspanning 1996-97 through 2022-23.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:34:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13033","submitter":"Moritz Wolter","authors":"Konstantin Gasenzer (1) and Moritz Wolter (1) ((1) High Performance\n  Computing and Analytics Lab, Universit\\\"at Bonn, Germany)","title":"Towards generalizing deep-audio fake detection networks","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.LG eess.AS","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Today's generative neural networks allow the creation of high-quality\nsynthetic speech at scale. While we welcome the creative use of this new\ntechnology, we must also recognize the risks. As synthetic speech is abused for\nboth monetary and identity theft, we require a broad set of deep fake\nidentification tools. Furthermore, previous work reported a limited ability of\ndeep classifiers to generalize to unseen audio generators. By leveraging the\nwavelet-packet and short-time Fourier transform, we train excellent lightweight\ndetectors that generalize. We report improved results on an extension of the\nWaveFake dataset. To account for the rapid progress in the field, we\nadditionally consider samples drawn from the novel Avocodo and BigVGAN\nnetworks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:37:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13034","submitter":"Ruize Gao","authors":"Ruize Gao, Zhirui Zhang, Yichao Du, Lemao Liu, Rui Wang","title":"Nearest Neighbor Machine Translation is Meta-Optimizer on Output\n  Projection Layer","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Nearest Neighbor Machine Translation ($k$NN-MT) has achieved great success on\ndomain adaptation tasks by integrating pre-trained Neural Machine Translation\n(NMT) models with domain-specific token-level retrieval. However, the reasons\nunderlying its success have not been thoroughly investigated. In this paper, we\nprovide a comprehensive analysis of $k$NN-MT through theoretical and empirical\nstudies. Initially, we offer a theoretical interpretation of the working\nmechanism of $k$NN-MT as an efficient technique to implicitly execute gradient\ndescent on the output projection layer of NMT, indicating that it is a specific\ncase of model fine-tuning. Subsequently, we conduct multi-domain experiments\nand word-level analysis to examine the differences in performance between\n$k$NN-MT and entire-model fine-tuning. Our findings suggest that: (1)\nIncorporating $k$NN-MT with adapters yields comparable translation performance\nto fine-tuning on in-domain test sets, while achieving better performance on\nout-of-domain test sets; (2) Fine-tuning significantly outperforms $k$NN-MT on\nthe recall of low-frequency domain-specific words, but this gap could be\nbridged by optimizing the context representations with additional adapter\nlayers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:38:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13035","submitter":"Lucas Beyer","authors":"Ibrahim Alabdulmohsin, Xiaohua Zhai, Alexander Kolesnikov, Lucas Beyer","title":"Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design","comments":"10 pages, 7 figures, 9 tables. Version 2: Layout fixes","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Scaling laws have been recently employed to derive compute-optimal model size\n(number of parameters) for a given compute duration. We advance and refine such\nmethods to infer compute-optimal model shapes, such as width and depth, and\nsuccessfully implement this in vision transformers. Our shape-optimized vision\ntransformer, SoViT, achieves results competitive with models that exceed twice\nits size, despite being pre-trained with an equivalent amount of compute. For\nexample, SoViT-400m/14 achieves 90.3% fine-tuning accuracy on ILSRCV2012,\nsurpassing the much larger ViT-g/14 and approaching ViT-G/14 under identical\nsettings, with also less than half the inference cost. We conduct a thorough\nevaluation across multiple tasks, such as image classification, captioning, VQA\nand zero-shot transfer, demonstrating the effectiveness of our model across a\nbroad range of domains and identifying limitations. Overall, our findings\nchallenge the prevailing approach of blindly scaling up vision models and pave\na path for a more informed scaling.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:39:28 GMT"},{"version":"v2","created":"Fri, 2 Jun 2023 10:25:27 GMT"}],"update_date":"2023-06-05"}
{"id":"2305.13036","submitter":"Jinliang Deng","authors":"Jinliang Deng, Xiusi Chen, Renhe Jiang, Du Yin, Yi Yang, Xuan Song,\n  Ivor W. Tsang","title":"Learning Structured Components: Towards Modular and Interpretable\n  Multivariate Time Series Forecasting","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multivariate time-series (MTS) forecasting is a paramount and fundamental\nproblem in many real-world applications. The core issue in MTS forecasting is\nhow to effectively model complex spatial-temporal patterns. In this paper, we\ndevelop a modular and interpretable forecasting framework, which seeks to\nindividually model each component of the spatial-temporal patterns. We name\nthis framework SCNN, short for Structured Component-based Neural Network. SCNN\nworks with a pre-defined generative process of MTS, which arithmetically\ncharacterizes the latent structure of the spatial-temporal patterns. In line\nwith its reverse process, SCNN decouples MTS data into structured and\nheterogeneous components and then respectively extrapolates the evolution of\nthese components, the dynamics of which is more traceable and predictable than\nthe original MTS. Extensive experiments are conducted to demonstrate that SCNN\ncan achieve superior performance over state-of-the-art models on three\nreal-world datasets. Additionally, we examine SCNN with different\nconfigurations and perform in-depth analyses of the properties of SCNN.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:39:44 GMT"},{"version":"v2","created":"Wed, 24 May 2023 09:13:40 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13037","submitter":"Stefano Olla","authors":"Pablo A. Ferrari, Stefano Olla","title":"Macroscopic diffusive fluctuations for generalized hard rods dynamics","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math-ph cond-mat.stat-mech math.MP math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the fluctuations in equilibrium for a dynamics of rods with random\nlength. This includes the classical hard rod elastic collisions, when rod\nlengths are constant and equal to a positive value. We prove that in the\ndiffusive space-time scaling, an initial fluctuation of density of particles of\nvelocity $v$, after recentering on its Euler evolution, evolve randomly shifted\nby a Brownian motion of variance $\\mathcal D(v)$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:40:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13038","submitter":"Ben Kane","authors":"Kathrin Bringmann, Ben Kane, Srimathi Varadharajan","title":"Generalized $L$-functions related to the Riemann zeta function","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we construct generalized $L$-functions associated to\nmeromorphic modular forms of weight $\\frac12$ for the theta group with a single\nsimple pole in the fundamental domain. We then consider their behaviour towards\n$i\\infty$ and relate this to the Riemann zeta function.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:41:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13039","submitter":"Mounir Bedhiafi","authors":"Mohamed Gaidi and Mounir Bedhiafi","title":"On the Study of the Klein-Gordon Equation in the Dunkl Setting","comments":"20 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In Dunkl theory on $\\mathbb{R}^{n}$ which generalizes classical Fourier\nanalysis, we study the solution of the Klein-Gordon-equation defined by:\n\\begin{eqnarray} \\nonumber \\partial_{t}^{2}u-\\Delta_{k}u=-m^{2}u \\ , \\ \\ \\ u\n(x,0)=g(x) \\ , \\ \\ \\ \\partial_{t}u(x,0)=f(x) \\end{eqnarray} with \\ $m > 0$ \\\nand \\ $\\partial_{t}^{2}u$ \\ is the second derivative of the solution $u$ with\nrespect to $t$ and $\\Delta_{k}u$ is the Dunkl Laplacian with respect to $x$\nwhere $f$ and $g$ the two functions in $\\mathcal{S}(\\mathbb{R}^{n})$ which\nsurround the initial conditions. We obtain an integral representation for its\nsolution which we gives some properties. As a specific result, we studied the\nassociated energies to the Dunkl-Klein-Gordon equation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:41:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13040","submitter":"Shuzheng Si","authors":"Shuzheng Si, Wentao Ma, Haoyu Gao, Yuchuan Wu, Ting-En Lin, Yinpei\n  Dai, Hangyu Li, Rui Yan, Fei Huang, Yongbin Li","title":"SpokenWOZ: A Large-Scale Speech-Text Dataset for Spoken Task-Oriented\n  Dialogue in Multiple Domains","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Task-oriented dialogue (TOD) models have made significant progress in recent\nyears. However, previous studies primarily focus on datasets written by\nannotators, which has resulted in a gap between academic research and\nreal-world spoken conversation scenarios. While several small-scale spoken TOD\ndatasets are proposed to address robustness issues such as ASR errors, they\nignore the unique challenges in spoken conversation. To tackle the limitations,\nwe introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD,\ncontaining 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from\nhuman-to-human spoken conversations. SpokenWOZ further incorporates common\nspoken characteristics such as word-by-word processing and reasoning in spoken\nlanguage. Based on these characteristics, we present cross-turn slot and\nreasoning slot detection as new challenges. We conduct experiments on various\nbaselines, including text-modal models, newly proposed dual-modal models, and\nLLMs, e.g., ChatGPT. The results show that the current models still have\nsubstantial room for improvement in spoken conversation, where the most\nadvanced dialogue state tracker only achieves 25.65% in joint goal accuracy and\nthe SOTA end-to-end model only correctly completes the user request in 52.1% of\ndialogues. The dataset, code, and leaderboard are available:\nhttps://spokenwoz.github.io/SpokenWOZ-github.io/.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:47:51 GMT"},{"version":"v2","created":"Wed, 7 Jun 2023 16:04:30 GMT"}],"update_date":"2023-06-08"}
{"id":"2305.13041","submitter":"Zhuojun Tian","authors":"Zhuojun Tian, Zhaoyang Zhang, Zhaohui Yang, Richeng Jin and Huaiyu Dai","title":"Distributed Learning over Networks with Graph-Attention-Based\n  Personalization","comments":"Accepted for publication in IEEE TSP; with supplementary details for\n  the derivations","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.LG eess.SP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In conventional distributed learning over a network, multiple agents\ncollaboratively build a common machine learning model. However, due to the\nunderlying non-i.i.d. data distribution among agents, the unified learning\nmodel becomes inefficient for each agent to process its locally accessible\ndata. To address this problem, we propose a graph-attention-based personalized\ntraining algorithm (GATTA) for distributed deep learning. The GATTA enables\neach agent to train its local personalized model while exploiting its\ncorrelation with neighboring nodes and utilizing their useful information for\naggregation. In particular, the personalized model in each agent is composed of\na global part and a node-specific part. By treating each agent as one node in a\ngraph and the node-specific parameters as its features, the benefits of the\ngraph attention mechanism can be inherited. Namely, instead of aggregation\nbased on averaging, it learns the specific weights for different neighboring\nnodes without requiring prior knowledge about the graph structure or the\nneighboring nodes' data distribution. Furthermore, relying on the\nweight-learning procedure, we develop a communication-efficient GATTA by\nskipping the transmission of information with small aggregation weights.\nAdditionally, we theoretically analyze the convergence properties of GATTA for\nnon-convex loss functions. Numerical results validate the excellent\nperformances of the proposed algorithms in terms of convergence and\ncommunication cost.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:48:30 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13043","submitter":"Lana Sinapayen","authors":"Lana Sinapayen","title":"Self-Replication, Spontaneous Mutations, and Exponential Genetic Drift\n  in Neural Cellular Automata","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.LG q-bio.PE","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  This paper reports on patterns exhibiting self-replication with spontaneous,\ninheritable mutations and exponential genetic drift in Neural Cellular\nAutomata. Despite the models not being explicitly trained for mutation or\ninheritability, the descendant patterns exponentially drift away from ancestral\npatterns, even when the automaton is deterministic. While this is far from\nbeing the first instance of evolutionary dynamics in a cellular automaton, it\nis the first to do so by exploiting the power and convenience of Neural\nCellular Automata, arguably increasing the space of variations and the\nopportunity for Open Ended Evolution.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:48:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13044","submitter":"Juliana Xavier","authors":"Sof\\'ia Llavayol and Juliana Xavier","title":"Quotients of torus endomorphisms have parabolic orbifolds","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT math.AT math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we show that every quotient of a torus endomorphism has a\nparabolic orbifold. This answers a question of Mario Bonk and Daniel Meyer\nposed in their book \"Expanding Thurston maps\".\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:52:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13045","submitter":"Mihai Marciu C","authors":"Mihai Marciu and Dana Maria Ioan","title":"The accelerated expansion in $F(G,T_{\\mu \\nu}T^{\\mu \\nu})$ gravity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"gr-qc hep-th physics.comp-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the present manuscript the basic Einstein--Hilbert cosmological model is\nextended, by adding a new functional $F(G, T_{\\mu\\nu}T^{\\mu\\nu})$ in the\nfundamental action, encoding specific geometrical effects due to a nontrivial\ncoupling with the Gauss-Bonnet invariant ($G$), and the energy--momentum\nsquared term ($T_{\\mu\\nu}T^{\\mu\\nu}$). After obtaining the corresponding\ngravitational field equations for the specific decomposition where $F(G,\nT_{\\mu\\nu}T^{\\mu\\nu})=f(G)+g(T_{\\mu\\nu}T^{\\mu\\nu})$, we have explored the\nphysical features of the cosmological model by considering the linear stability\ntheory, an important analytical tool in the cosmological theory which can\nreveal the dynamical characteristics of the phase space. The analytical\nexploration of the corresponding phase space structure revealed that the\npresent model can represent a viable dark energy model, with various stationary\npoints where the effective equation of state corresponds to a de--Sitter epoch,\npossible explaining the early and late time acceleration of the Universe.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:54:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13046","submitter":"Sung Whan Yoon","authors":"Sang-Yeong Jo, Sung Whan Yoon","title":"POEM: Polarization of Embeddings for Domain-Invariant Representations","comments":"In Proceedings of the 37th AAAI Conference on Artificial Intelligence\n  (AAAI) 2023, Washington D.C. USA","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Handling out-of-distribution samples is a long-lasting challenge for deep\nvisual models. In particular, domain generalization (DG) is one of the most\nrelevant tasks that aims to train a model with a generalization capability on\nnovel domains. Most existing DG approaches share the same philosophy to\nminimize the discrepancy between domains by finding the domain-invariant\nrepresentations. On the contrary, our proposed method called POEM acquires a\nstrong DG capability by learning domain-invariant and domain-specific\nrepresentations and polarizing them. Specifically, POEM cotrains\ncategory-classifying and domain-classifying embeddings while regularizing them\nto be orthogonal via minimizing the cosine-similarity between their features,\ni.e., the polarization of embeddings. The clear separation of embeddings\nsuppresses domain-specific features in the domain-invariant embeddings. The\nconcept of POEM shows a unique direction to enhance the domain robustness of\nrepresentations that brings considerable and consistent performance gains when\ncombined with existing DG methods. Extensive simulation results in popular DG\nbenchmarks with the PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet\ndatasets show that POEM indeed facilitates the category-classifying embedding\nto be more domain-invariant.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:54:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13047","submitter":"Mark Mets","authors":"Mark Mets, Andres Karjus, Indrek Ibrus, Maximilian Schich","title":"Automated stance detection in complex topics and small languages: the\n  challenging case of immigration in polarizing news media","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automated stance detection and related machine learning methods can provide\nuseful insights for media monitoring and academic research. Many of these\napproaches require annotated training datasets, which limits their\napplicability for languages where these may not be readily available. This\npaper explores the applicability of large language models for automated stance\ndetection in a challenging scenario, involving a morphologically complex,\nlower-resource language, and a socio-culturally complex topic, immigration. If\nthe approach works in this case, it can be expected to perform as well or\nbetter in less demanding scenarios. We annotate a large set of pro and\nanti-immigration examples, and compare the performance of multiple language\nmodels as supervised learners. We also probe the usability of ChatGPT as an\ninstructable zero-shot classifier for the same task. Supervised achieves\nacceptable performance, and ChatGPT yields similar accuracy. This is promising\nas a potentially simpler and cheaper alternative for text classification tasks,\nincluding in lower-resource languages. We further use the best-performing model\nto investigate diachronic trends over seven years in two corpora of Estonian\nmainstream and right-wing populist news sources, demonstrating the\napplicability of the approach for news analytics and media monitoring settings,\nand discuss correspondences between stance changes and real-world events.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:56:35 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13048","submitter":"Quentin Anthony","authors":"Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel\n  Arcadinho, Huanqi Cao, Xin Cheng, Michael Chung, Matteo Grella, Kranthi Kiran\n  GV, Xuzheng He, Haowen Hou, Przemyslaw Kazienko, Jan Kocon, Jiaming Kong,\n  Bartlomiej Koptyra, Hayden Lau, Krishna Sri Ipsit Mantri, Ferdinand Mom,\n  Atsushi Saito, Xiangru Tang, Bolun Wang, Johan S. Wind, Stansilaw Wozniak,\n  Ruichong Zhang, Zhenyuan Zhang, Qihang Zhao, Peng Zhou, Jian Zhu, Rui-Jie Zhu","title":"RWKV: Reinventing RNNs for the Transformer Era","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Transformers have revolutionized almost all natural language processing (NLP)\ntasks but suffer from memory and computational complexity that scales\nquadratically with sequence length. In contrast, recurrent neural networks\n(RNNs) exhibit linear scaling in memory and computational requirements but\nstruggle to match the same performance as Transformers due to limitations in\nparallelization and scalability. We propose a novel model architecture,\nReceptance Weighted Key Value (RWKV), that combines the efficient\nparallelizable training of Transformers with the efficient inference of RNNs.\nOur approach leverages a linear attention mechanism and allows us to formulate\nthe model as either a Transformer or an RNN, which parallelizes computations\nduring training and maintains constant computational and memory complexity\nduring inference, leading to the first non-transformer architecture to be\nscaled to tens of billions of parameters. Our experiments reveal that RWKV\nperforms on par with similarly sized Transformers, suggesting that future work\ncan leverage this architecture to create more efficient models. This work\npresents a significant step towards reconciling the trade-offs between\ncomputational efficiency and model performance in sequence processing tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:57:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13049","submitter":"Mar\\'ia Camarasa-G\\'omez","authors":"Mar\\'ia Camarasa-G\\'omez, Ashwin Ramasubramaniam, Jeffrey B. Neaton,\n  and Leeor Kronik","title":"Transferable screened range-separated hybrid functionals for electronic\n  and optical properties of van der Waals materials","comments":"14 pages + 8 figures; Supporting Information (21 pages + 18 figures)","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The accurate description of electronic properties and optical absorption\nspectra is a long-standing challenge for density functional theory. Recently,\nthe introduction of screened range-separated hybrid (SRSH) functionals for\nsolid-state materials has allowed for the calculation of fundamental band gaps\nand optical absorption spectra that are in very good agreement with many-body\nperturbation theory. However, since solid-state SRSH functionals are typically\ntuned to reproduce the properties of bulk phases, their transferability to\nlow-dimensional structures, which experience substantially different screening\nthan in the bulk, remains an open question. In this work, we explore the\ntransferability of SRSH functionals to several prototypical van der Waals\nmaterials, including transition-metal sulfides and selenides, indium selenide,\nblack phosphorus, and hexagonal boron nitride. Considering the bulk and a\nmonolayer of these materials as limiting cases, we show that the parameters of\nthe SRSH functional can be determined systematically, using only the band-edge\nquasiparticle energies of these extremal structural phases as fitting targets.\nThe resulting SRSH functionals can describe both electronic bandstructures and\noptical absorption spectra with accuracy comparable to more demanding ab initio\nmany-body perturbation theory (GW and Bethe-Salpeter equation) approaches.\nSelected examples also demonstrate that the SRSH parameters, obtained from the\nbulk and monolayer reference structures, display good accuracy for\nbandstructures and optical spectra of bilayers, indicating a degree of\ntransferability that is independent of the fitting procedure.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:02:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13050","submitter":"Itai Gat","authors":"Guy Yariv, Itai Gat, Lior Wolf, Yossi Adi, Idan Schwartz","title":"AudioToken: Adaptation of Text-Conditioned Diffusion Models for\n  Audio-to-Image Generation","comments":"Accepted to INTERSPEECH 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SD cs.CV cs.LG eess.AS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In recent years, image generation has shown a great leap in performance,\nwhere diffusion models play a central role. Although generating high-quality\nimages, such models are mainly conditioned on textual descriptions. This begs\nthe question: \"how can we adopt such models to be conditioned on other\nmodalities?\". In this paper, we propose a novel method utilizing latent\ndiffusion models trained for text-to-image-generation to generate images\nconditioned on audio recordings. Using a pre-trained audio encoding model, the\nproposed method encodes audio into a new token, which can be considered as an\nadaptation layer between the audio and text representations. Such a modeling\nparadigm requires a small number of trainable parameters, making the proposed\napproach appealing for lightweight optimization. Results suggest the proposed\nmethod is superior to the evaluated baseline methods, considering objective and\nsubjective metrics. Code and samples are available at:\nhttps://pages.cs.huji.ac.il/adiyoss-lab/AudioToken.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:02:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13051","submitter":"Jia Huang","authors":"Jia Huang, Alvika Gautam, Srikanth Saripalli","title":"Learning Pedestrian Actions to Ensure Safe Autonomous Driving","comments":"8 pages, 9 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  To ensure safe autonomous driving in urban environments with complex\nvehicle-pedestrian interactions, it is critical for Autonomous Vehicles (AVs)\nto have the ability to predict pedestrians' short-term and immediate actions in\nreal-time. In recent years, various methods have been developed to study\nestimating pedestrian behaviors for autonomous driving scenarios, but there is\na lack of clear definitions for pedestrian behaviors. In this work, the\nliterature gaps are investigated and a taxonomy is presented for pedestrian\nbehavior characterization. Further, a novel multi-task sequence to sequence\nTransformer encoders-decoders (TF-ed) architecture is proposed for pedestrian\naction and trajectory prediction using only ego vehicle camera observations as\ninputs. The proposed approach is compared against an existing LSTM encoders\ndecoders (LSTM-ed) architecture for action and trajectory prediction. The\nperformance of both models is evaluated on the publicly available Joint\nAttention Autonomous Driving (JAAD) dataset, CARLA simulation data as well as\nreal-time self-driving shuttle data collected on university campus. Evaluation\nresults illustrate that the proposed method reaches an accuracy of 81% on\naction prediction task on JAAD testing data and outperforms the LSTM-ed by\n7.4%, while LSTM counterpart performs much better on trajectory prediction task\nfor a prediction sequence length of 25 frames.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:03:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13052","submitter":"Ofir Ben Shoham","authors":"Ofir Ben Shoham, Nadav Rappoport","title":"Federated Learning of Medical Concepts Embedding using BEHRT","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CL cs.DC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Electronic Health Records (EHR) data contains medical records such as\ndiagnoses, medications, procedures, and treatments of patients. This data is\noften considered sensitive medical information. Therefore, the EHR data from\nthe medical centers often cannot be shared, making it difficult to create\nprediction models using multi-center EHR data, which is essential for such\nmodels' robustness and generalizability. Federated Learning (FL) is an\nalgorithmic approach that allows learning a shared model using data in multiple\nlocations without the need to store all data in a central place. An example of\na prediction model's task is to predict future diseases. More specifically, the\nmodel needs to predict patient's next visit diagnoses, based on current and\nprevious clinical data. Such a prediction model can support care providers in\nmaking clinical decisions and even provide preventive treatment. We propose a\nfederated learning approach for learning medical concepts embedding. This\npre-trained model can be used for fine-tuning for specific downstream tasks.\nOur approach is based on an embedding model like BEHRT, a deep neural sequence\ntransduction model for EHR. We train using federated learning, both the Masked\nLanguage Modeling (MLM) and the next visit downstream model. We demonstrate our\napproach on the MIMIC-IV dataset. We compare the performance of a model trained\nwith FL against a model trained on centralized data. We find that our federated\nlearning approach reaches very close to the performance of a centralized model,\nand it outperforms local models in terms of average precision. We also show\nthat pre-trained MLM improves the model's average precision performance in the\nnext visit prediction task, compared to an MLM model without pre-training. Our\ncode is available at https://github.com/nadavlab/FederatedBEHRT.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:05:39 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13053","submitter":"Yevgeniia Yevgenieva PhD","authors":"Mariia Savchenko, Igor Skrypnik, Yevgeniia Yevgenieva","title":"On the weak Harnack inequality for unbounded non-negative\n  super-solutions of degenerate double-phase parabolic equations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the case $q> p\\dfrac{n+2}{n}$, we give a proof of the weak Harnack\ninequality for non-negative super-solutions of degenerate double-phase\nparabolic equations under the additional assumption that $u\\in\nL^{s}_{loc}(\\Omega_{T})$ with some $s >p\\dfrac{n+2}{n}$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:08:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13054","submitter":"Diego Goldsztajn","authors":"Diego Goldsztajn, Sem C. Borst and Johan S.H. van Leeuwaarden","title":"Load balancing with sparse dynamic random graphs","comments":"62 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Consider a system of $n$ single-server queues where tasks arrive at each\nserver in a distributed fashion. A graph is used to locally balance the load by\ndispatching every incoming task to one of the shortest queues in the\nneighborhood where the task appears. In order to globally balance the load, the\nneighborship relations are constantly renewed by resampling the graph at rate\n$\\mu_n$ from some fixed random graph law. We derive the fluid limit of the\noccupancy process as $n \\to \\infty$ and $\\mu_n \\to \\infty$ when the resampling\nprocedure is symmetric with respect to the servers. The maximum degree of the\ngraph may remain bounded as $n$ grows and the total number of arrivals between\nconsecutive resampling times may approach infinity. The fluid limit only\ndepends on the random graph laws through their limiting degree distribution and\ncan be interpreted as a generalized power-of-$(d + 1)$ scheme where $d$ is\nrandom and has the limiting degree distribution. We use the fluid limit to\nobtain valuable insights into the performance impact and optimal design of\nsparse dynamic graphs with a bounded average degree. In particular, we\nestablish a phase transition in performance when the probability that a server\nis isolated switches from zero to positive, and we show that performance\nimproves as the degree distribution becomes more concentrated.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:11:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13055","submitter":"Jonas K\\\"uhne","authors":"Jonas K\\\"uhne, Michele Magno, Luca Benini","title":"Parallelizing Optical Flow Estimation on an Ultra-Low Power RISC-V\n  Cluster for Nano-UAV Navigation","comments":"Accepted by ISCAS 2022","journal-ref":null,"doi":"10.1109/ISCAS48785.2022.9937215","report-no":null,"categories":"cs.CV cs.RO eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Optical flow estimation is crucial for autonomous navigation and localization\nof unmanned aerial vehicles (UAV). On micro and nano UAVs, real-time\ncalculation of the optical flow is run on low power and resource-constrained\nmicrocontroller units (MCUs). Thus, lightweight algorithms for optical flow\nhave been proposed targeting real-time execution on traditional single-core\nMCUs. This paper introduces an efficient parallelization strategy for optical\nflow computation targeting new-generation multicore low power RISC-V based\nmicrocontroller units. Our approach enables higher frame rates at lower clock\nspeeds. It has been implemented and evaluated on the eight-core cluster of a\ncommercial octa-core MCU (GAP8) reaching a parallelization speedup factor of\n7.21 allowing for a frame rate of 500 frames per second when running on a 50\nMHz clock frequency. The proposed parallel algorithm significantly boosts the\ncamera frame rate on micro unmanned aerial vehicles, which enables higher\nflight speeds: the maximum flight speed can be doubled, while using less than a\nthird of the clock frequency of previous single-core implementations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:13:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13056","submitter":"Yuhei Suzuki","authors":"Yuhei Suzuki","title":"Amenable actions on finite simple C*-algebras arising from flows on\n  Pimsner algebras","comments":"33 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OA math.DS math.GR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Associated to a family of $G$-$\\ast$-endomorphisms on a $G$-C*-algebra $A$\nsatisfying certain minimality conditions, we give a $G$-C*-correspondence\n$\\mathcal{E}$ over $A$ whose Cuntz--Pimsner algebra $\\mathcal{O}_\\mathcal{E}$\nis simple. For certain quasi-free flows $\\gamma$ (commuting with the\n$G$-action) on $\\mathcal{O}_\\mathcal{E}$, we further prove the simplicity of\nthe reduced crossed product $\\mathcal{O}_\\mathcal{E} \\rtimes_\\gamma\n\\mathbb{R}$. We then classify the KMS weights of $\\gamma$. This in particular\ngives a sufficient condition for $\\mathcal{O}_\\mathcal{E}$ and\n$\\mathcal{O}_\\mathcal{E}\\rtimes_\\gamma \\mathbb{R}$ to be stably finite (and to\nbe stably projectionless). As the amenability of $G \\curvearrowright A$\ninherits to the induced actions $G \\curvearrowright \\mathcal{O}_\\mathcal{E},\n\\mathcal{O}_\\mathcal{E}\\rtimes_\\gamma \\mathbb{R}$, this provides a new\nsystematic framework to provide amenable actions on stably finite simple\nC*-algebras.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:14:00 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13057","submitter":"Zhenlan Ji","authors":"Zhenlan Ji, Pingchuan Ma, Shuai Wang, Yanhui Li","title":"Causality-Aided Trade-off Analysis for Machine Learning Fairness","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.SE","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  There has been an increasing interest in enhancing the fairness of machine\nlearning (ML). Despite the growing number of fairness-improving methods, we\nlack a systematic understanding of the trade-offs among factors considered in\nthe ML pipeline when fairness-improving methods are applied. This understanding\nis essential for developers to make informed decisions regarding the provision\nof fair ML services. Nonetheless, it is extremely difficult to analyze the\ntrade-offs when there are multiple fairness parameters and other crucial\nmetrics involved, coupled, and even in conflict with one another.\n  This paper uses causality analysis as a principled method for analyzing\ntrade-offs between fairness parameters and other crucial metrics in ML\npipelines. To ractically and effectively conduct causality analysis, we propose\na set of domain-specific optimizations to facilitate accurate causal discovery\nand a unified, novel interface for trade-off analysis based on well-established\ncausal inference methods. We conduct a comprehensive empirical study using\nthree real-world datasets on a collection of widelyused fairness-improving\ntechniques. Our study obtains actionable suggestions for users and developers\nof fair ML. We further demonstrate the versatile usage of our approach in\nselecting the optimal fairness-improving method, paving the way for more\nethical and socially responsible AI technologies.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:14:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13058","submitter":"Ilias Chalkidis","authors":"Ilias Chalkidis and Yova Kementchedjhieva","title":"Retrieval-augmented Multi-label Text Classification","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multi-label text classification (MLC) is a challenging task in settings of\nlarge label sets, where label support follows a Zipfian distribution. In this\npaper, we address this problem through retrieval augmentation, aiming to\nimprove the sample efficiency of classification models. Our approach closely\nfollows the standard MLC architecture of a Transformer-based encoder paired\nwith a set of classification heads. In our case, however, the input document\nrepresentation is augmented through cross-attention to similar documents\nretrieved from the training set and represented in a task-specific manner. We\nevaluate this approach on four datasets from the legal and biomedical domains,\nall of which feature highly skewed label distributions. Our experiments show\nthat retrieval augmentation substantially improves model performance on the\nlong tail of infrequent labels especially so for lower-resource training\nscenarios and more challenging long-document data scenarios.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:16:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13059","submitter":"Adrian Kochsiek","authors":"Adrian Kochsiek, Apoorv Saxena, Inderjeet Nair, Rainer Gemulla","title":"Friendly Neighbors: Contextualized Sequence-to-Sequence Link Prediction","comments":"7 pages, 2 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose KGT5-context, a simple sequence-to-sequence model for link\nprediction (LP) in knowledge graphs (KG). Our work expands on KGT5, a recent LP\nmodel that exploits textual features of the KG, has small model size, and is\nscalable. To reach good predictive performance, however, KGT5 relies on an\nensemble with a knowledge graph embedding model, which itself is excessively\nlarge and costly to use. In this short paper, we show empirically that adding\ncontextual information - i.e., information about the direct neighborhood of the\nquery entity - alleviates the need for a separate KGE model to obtain good\nperformance. The resulting KGT5-context model is simple, reduces model size\nsignificantly, and obtains state-of-the-art performance in our experimental\nstudy.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:16:45 GMT"},{"version":"v2","created":"Wed, 31 May 2023 10:11:37 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13060","submitter":"Yu Zheng","authors":"Yu Zheng, Hongyuan Su, Jingtao Ding, Depeng Jin, Yong Li","title":"Road Planning for Slums via Deep Reinforcement Learning","comments":"KDD'23","journal-ref":null,"doi":"10.1145/3580305.3599901.","report-no":null,"categories":"cs.AI cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Millions of slum dwellers suffer from poor accessibility to urban services\ndue to inadequate road infrastructure within slums, and road planning for slums\nis critical to the sustainable development of cities. Existing re-blocking or\nheuristic methods are either time-consuming which cannot generalize to\ndifferent slums, or yield sub-optimal road plans in terms of accessibility and\nconstruction costs. In this paper, we present a deep reinforcement learning\nbased approach to automatically layout roads for slums. We propose a generic\ngraph model to capture the topological structure of a slum, and devise a novel\ngraph neural network to select locations for the planned roads. Through masked\npolicy optimization, our model can generate road plans that connect places in a\nslum at minimal construction costs. Extensive experiments on real-world slums\nin different countries verify the effectiveness of our model, which can\nsignificantly improve accessibility by 14.3% against existing baseline methods.\nFurther investigations on transferring across different tasks demonstrate that\nour model can master road planning skills in simple scenarios and adapt them to\nmuch more complicated ones, indicating the potential of applying our model in\nreal-world slum upgrading. The code and data are available at\nhttps://github.com/tsinghua-fib-lab/road-planning-for-slums.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:18:28 GMT"},{"version":"v2","created":"Sun, 28 May 2023 14:53:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13061","submitter":"Thomas Blackburn","authors":"T. G. Blackburn, B. King, S. Tang","title":"Simulations of laser-driven strong-field QED with Ptarmigan: Resolving\n  wavelength-scale interference and $\\gamma$-ray polarization","comments":"18 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph physics.plasm-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Accurate modelling is necessary to support precision experiments\ninvestigating strong-field QED phenomena. This modelling is particularly\nchallenging in the transition between the perturbative and nonperturbative\nregimes, where the normalized laser amplitude $a_0$ is comparable to unity and\nwavelength-scale interference is significant. Here we describe how to simulate\nnonlinear Compton scattering, Breit-Wheeler pair creation, and trident pair\ncreation in this regime, using the Monte Carlo particle-tracking code\nPtarmigan. This code simulates collisions between high-intensity lasers and\nbeams of electrons or $\\gamma$ rays, primarily in the framework of the locally\nmonochromatic approximation (LMA). We benchmark our simulation results against\nfull QED calculations for pulsed plane waves and show that they are accurate at\nthe level of a few per cent, across the full range of particle energies and\nlaser intensities. This work extends our previous results to linearly polarized\nlasers and arbitrarily polarized $\\gamma$ rays.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:20:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13062","submitter":"Yuan Sui","authors":"Yuan Sui, Mengyu Zhou, Mingjie Zhou, Shi Han, Dongmei Zhang","title":"Evaluating and Enhancing Structural Understanding Capabilities of Large\n  Language Models on Tables via Input Designs","comments":"12 pages, 4 tables, 1 figure","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models (LLMs) are becoming attractive as few-shot reasoners to\nsolve NL-related tasks. However, there is still much to be learned about how\nwell LLMs understand structured data, such as tables. While it is true that\ntables can be used as inputs to LLMs with serialization, there lack\ncomprehensive studies examining whether LLMs can truly comprehend such data. In\nthis paper we try to understand this by designing a benchmark to evaluate\nstructural understanding capabilities (SUC) of LLMs. The benchmark we create\nincludes seven tasks, each with their own unique challenges, e.g,, cell lookup,\nrow retrieval and size detection. We run a series of evaluations on GPT-3\nfamily models (e.g., text-davinci-003). We discover that the performance varied\ndepending on a number of input choices, including table input format, content\norder, role prompting and partition marks. Drawing from the insights gained\nthrough the benchmark evaluations, we then propose self-augmentation for\neffective structural prompting, e.g., critical value / range identification\nusing LLMs' internal knowledge. When combined with carefully chosen input\nchoices, these structural prompting methods lead to promising improvements in\nLLM performance on a variety of tabular tasks, e.g., TabFact($\\uparrow2.31\\%$),\nHybridQA($\\uparrow2.13\\%$), SQA($\\uparrow2.72\\%$), Feverous($\\uparrow0.84\\%$),\nand ToTTo($\\uparrow5.68\\%$). We believe our benchmark and proposed prompting\nmethods can serve as a simple yet generic selection for future research. The\ncode and data are released in\nhttps://anonymous.4open.science/r/StructuredLLM-76F3.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:23:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13063","submitter":"Christopher Mattern","authors":"Christopher Mattern","title":"Hierarchical Partitioning Forecaster","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this work we consider a new family of algorithms for sequential\nprediction, Hierarchical Partitioning Forecasters (HPFs). Our goal is to\nprovide appealing theoretical - regret guarantees on a powerful model class -\nand practical - empirical performance comparable to deep networks - properties\nat the same time. We built upon three principles: hierarchically partitioning\nthe feature space into sub-spaces, blending forecasters specialized to each\nsub-space and learning HPFs via local online learning applied to these\nindividual forecasters. Following these principles allows us to obtain regret\nguarantees, where Constant Partitioning Forecasters (CPFs) serve as competitor.\nA CPF partitions the feature space into sub-spaces and predicts with a fixed\nforecaster per sub-space. Fixing a hierarchical partition $\\mathcal H$ and\nconsidering any CPF with a partition that can be constructed using elements of\n$\\mathcal H$ we provide two guarantees: first, a generic one that unveils how\nlocal online learning determines regret of learning the entire HPF online;\nsecond, a concrete instance that considers HPF with linear forecasters (LHPF)\nand exp-concave losses where we obtain $O(k \\log T)$ regret for sequences of\nlength $T$ where $k$ is a measure of complexity for the competing CPF. Finally,\nwe provide experiments that compare LHPF to various baselines, including state\nof the art deep learning models, in precipitation nowcasting. Our results\nindicate that LHPF is competitive in various settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:25:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13064","submitter":"Itai Kreisler","authors":"Itai Kreisler, Mor Shpigel Nacson, Daniel Soudry, Yair Carmon","title":"Gradient Descent Monotonically Decreases the Sharpness of Gradient Flow\n  Solutions in Scalar Networks and Beyond","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC stat.ML","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent research shows that when Gradient Descent (GD) is applied to neural\nnetworks, the loss almost never decreases monotonically. Instead, the loss\noscillates as gradient descent converges to its ''Edge of Stability'' (EoS).\nHere, we find a quantity that does decrease monotonically throughout GD\ntraining: the sharpness attained by the gradient flow solution (GFS)-the\nsolution that would be obtained if, from now until convergence, we train with\nan infinitesimal step size. Theoretically, we analyze scalar neural networks\nwith the squared loss, perhaps the simplest setting where the EoS phenomena\nstill occur. In this model, we prove that the GFS sharpness decreases\nmonotonically. Using this result, we characterize settings where GD provably\nconverges to the EoS in scalar networks. Empirically, we show that GD\nmonotonically decreases the GFS sharpness in a squared regression model as well\nas practical neural network architectures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:27:27 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13065","submitter":"Lorenzo Micalizzi Mr","authors":"Maria Han Veiga, Lorenzo Micalizzi and Davide Torlo","title":"On improving the efficiency of ADER methods","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The (modern) arbitrary derivative (ADER) approach is a popular technique for\nthe numerical solution of differential problems based on iteratively solving an\nimplicit discretization of their weak formulation. In this work, focusing on an\nODE context, we investigate several strategies to improve this approach. Our\ninitial emphasis is on the order of accuracy of the method in connection with\nthe polynomial discretization of the weak formulation. We demonstrate that\nprecise choices lead to higher-order convergences in comparison to the existing\nliterature. Then, we put ADER methods into a Deferred Correction (DeC)\nformalism. This allows to determine the optimal number of iterations, which is\nequal to the formal order of accuracy of the method, and to introduce efficient\n$p$-adaptive modifications. These are defined by matching the order of accuracy\nachieved and the degree of the polynomial reconstruction at each iteration. We\nprovide analytical and numerical results, including the stability analysis of\nthe new modified methods, the investigation of the computational efficiency, an\napplication to adaptivity and an application to hyperbolic PDEs with a Spectral\nDifference (SD) space discretization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:33:23 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13066","submitter":"Zihao Fu","authors":"Zihao Fu, Yixuan Su, Zaiqiao Meng, Nigel Collier","title":"Biomedical Named Entity Recognition via Dictionary-based Synonym\n  Generalization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Biomedical named entity recognition is one of the core tasks in biomedical\nnatural language processing (BioNLP). To tackle this task, numerous\nsupervised/distantly supervised approaches have been proposed. Despite their\nremarkable success, these approaches inescapably demand laborious human effort.\nTo alleviate the need of human effort, dictionary-based approaches have been\nproposed to extract named entities simply based on a given dictionary. However,\none downside of existing dictionary-based approaches is that they are\nchallenged to identify concept synonyms that are not listed in the given\ndictionary, which we refer as the synonym generalization problem. In this\nstudy, we propose a novel Synonym Generalization (SynGen) framework that\nrecognizes the biomedical concepts contained in the input text using span-based\npredictions. In particular, SynGen introduces two regularization terms, namely,\n(1) a synonym distance regularizer; and (2) a noise perturbation regularizer,\nto minimize the synonym generalization error. To demonstrate the effectiveness\nof our approach, we provide a theoretical analysis of the bound of synonym\ngeneralization error. We extensively evaluate our approach on a wide range of\nbenchmarks and the results verify that SynGen outperforms previous\ndictionary-based models by notable margins. Lastly, we provide a detailed\nanalysis to further reveal the merits and inner-workings of our approach.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:36:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13067","submitter":"Joe Stacey","authors":"Joe Stacey and Marek Rei","title":"Improving Robustness in Knowledge Distillation Using Domain-Targeted\n  Data Augmentation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Applying knowledge distillation encourages a student model to behave more\nlike a teacher model, largely retaining the performance of the teacher model,\neven though the student model may have substantially fewer parameters. However,\nwhile distillation helps student models behave more like teacher models\nin-distribution, this is not necessarily the case out-of-distribution. To\naddress this, we use a language model to create task-specific unlabeled data\nthat mimics the data in targeted out-of-distribution domains. We use this\ngenerated data for knowledge distillation on the task of Natural Language\nInference (NLI), encouraging the student models to behave more like the teacher\nmodels for these examples. Our domain-targeted augmentation is highly\neffective, and outperforms previous robustness methods when evaluating\nout-of-distribution performance on MNLI. Surprisingly, this method also\nimproves performance on out-of-distribution domains that the data was not\ngenerated for. We additionally introduce Distilled Minority Upsampling (DMU), a\nmethod for identifying and upsampling minority examples during the\ndistillation. DMU is complementary to the domain-targeted augmentation, and\nsubstantially improves performance on SNLI-hard. Finally, we show\nout-of-distribution improvements on HANS from both of our methods, despite\naugmenting the training data with fewer than 5k examples.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:37:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13068","submitter":"Ningyu Zhang","authors":"Shuofei Qiao, Honghao Gui, Huajun Chen, Ningyu Zhang","title":"Making Language Models Better Tool Learners with Execution Feedback","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.HC cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Tools serve as pivotal interfaces that enable humans to understand and\nreshape the world. With the advent of foundational models, AI systems can\nutilize tools to expand their capabilities and interact with the world.\nExisting tool learning methodologies, encompassing supervised fine-tuning and\nprompt engineering approaches, often induce language models to utilize tools\nindiscriminately, as complex problems often exceed their own competencies.\nHowever, introducing tools for simple tasks, which the models themselves can\nreadily resolve, can inadvertently propagate errors rather than enhance\nperformance. This leads to the research question: can we teach language models\nwhen and how to use tools? To meet this need, we propose Tool leaRning wIth\nexeCution fEedback (TRICE), a two-stage end-to-end framework that enables the\nmodel to continually learn through feedback derived from tool execution,\nthereby learning when and how to use tools effectively. Experimental results,\nbacked by further analysis, show that TRICE can make the language model to\nselectively use tools by decreasing the model's dependency on tools while\nenhancing the performance. Code and datasets will be available in\nhttps://github.com/zjunlp/trice.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:37:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13069","submitter":"Elena Rozas","authors":"Elena Rozas, Evgeny Sedov, Yannik Brune, Sven H\\\"ofling, Alexey\n  Kavokin and Marc A{\\ss}mann","title":"Polariton-dark exciton interactions in bistable semiconductor\n  microcavities","comments":"9 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We take advantage of the polariton bistability in semiconductor microcavities\nto estimate the interaction strength between lower exciton-polariton and dark\nexciton states. We combine the quasiresonant excitation of polaritons and the\nnominally forbidden two-photon excitation (TPE) of dark excitons in a GaAs\nmicrocavity. To this end, we use an ultranarrow linewidth cw laser for the TPE\nprocess that allows us to determine the energy of dark excitons with high\nspectral resolution. Our results evidence a sharp drop in the polariton\ntransmission intensity and width of the hysteresis cycle when the TPE process\nis resonant with the dark exciton energy, highly compromising the bistability\nof the polariton condensate. This behavior demonstrates the existence of a\nsmall symmetry breaking such as that produced by an effective in-plane magnetic\nfield, allowing us to directly excite the dark reservoir. We numerically\nreproduce the collapse of the hysteresis cycle with the increasing dark exciton\npopulation, treating the evolution of a polariton condensate in a one-mode\napproximation, coupled to the exciton reservoir via polariton-exciton\nscattering processes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:37:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13070","submitter":"Nikolai Nikolov","authors":"Oleg Mushkarov and Nikolai Nikolov","title":"Areas associated to a quadrilateral","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.HO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study the relationship between the areas of the consecutive quadrilaterals\ncut from a convex quadrilateral in the plane by means of a finite or infinite\nnumber of straight lines intersecting two of its opposite sides. Moreover, we\nobtain a geometric description of all possible areas obtained in this way given\nthe ratios of the lengths of consecutive segments the lines divide these two\nopposite sides.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:40:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13071","submitter":"Yaobo Liang","authors":"Yaobo Liang, Quanzhi Zhu, Junhe Zhao and Nan Duan","title":"Machine-Created Universal Language for Cross-lingual Transfer","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  There are two types of approaches to solving cross-lingual transfer:\nmultilingual pre-training implicitly aligns the hidden representations of\ndifferent languages, while the translate-test explicitly translates different\nlanguages to an intermediate language, such as English. Translate-test has\nbetter interpretability compared to multilingual pre-training. However, the\ntranslate-test has lower performance than multilingual pre-training(Conneau and\nLample, 2019; Conneau et al, 2020) and can't solve word-level tasks because\ntranslation rearranges the word order. Therefore, we propose a new\nMachine-created Universal Language (MUL) as a new intermediate language. MUL\nconsists of a set of discrete symbols as universal vocabulary and NL-MUL\ntranslator for translating from multiple natural languages to MUL. MUL unifies\ncommon concepts from different languages into the same universal word for\nbetter cross-language transfer. And MUL preserves the language-specific words\nas well as word order, so the model can be easily applied to word-level tasks.\nOur experiments show that translating into MUL achieves better performance\ncompared to multilingual pre-training, and our analyses show that MUL has good\ninterpretability.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:41:09 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13072","submitter":"Arlind Kadra","authors":"Arlind Kadra, Sebastian Pineda Arango, Josif Grabocka","title":"Breaking the Paradox of Explainable Deep Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Deep Learning has achieved tremendous results by pushing the frontier of\nautomation in diverse domains. Unfortunately, current neural network\narchitectures are not explainable by design. In this paper, we propose a novel\nmethod that trains deep hypernetworks to generate explainable linear models.\nOur models retain the accuracy of black-box deep networks while offering free\nlunch explainability by design. Specifically, our explainable approach requires\nthe same runtime and memory resources as black-box deep models, ensuring\npractical feasibility. Through extensive experiments, we demonstrate that our\nexplainable deep networks are as accurate as state-of-the-art classifiers on\ntabular data. On the other hand, we showcase the interpretability of our method\non a recent benchmark by empirically comparing prediction explainers. The\nexperimental results reveal that our models are not only as accurate as their\nblack-box deep-learning counterparts but also as interpretable as\nstate-of-the-art explanation techniques.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:41:17 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13073","submitter":"Ziru Chen","authors":"Ziru Chen, Shijie Chen, Michael White, Raymond Mooney, Ali Payani,\n  Jayanth Srinivasa, Yu Su, Huan Sun","title":"Text-to-SQL Error Correction with Language Models of Code","comments":"ACL 2023 Short Paper","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.DB cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Despite recent progress in text-to-SQL parsing, current semantic parsers are\nstill not accurate enough for practical use. In this paper, we investigate how\nto build automatic text-to-SQL error correction models. Noticing that\ntoken-level edits are out of context and sometimes ambiguous, we propose\nbuilding clause-level edit models instead. Besides, while most language models\nof code are not specifically pre-trained for SQL, they know common data\nstructures and their operations in programming languages such as Python. Thus,\nwe propose a novel representation for SQL queries and their edits that adheres\nmore closely to the pre-training corpora of language models of code. Our error\ncorrection model improves the exact set match accuracy of different parsers by\n2.4-6.5 and obtains up to 4.3 point absolute improvement over two strong\nbaselines. Our code and data are available at\nhttps://github.com/OSU-NLP-Group/Auto-SQL-Correction.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:42:39 GMT"},{"version":"v2","created":"Sun, 28 May 2023 15:32:26 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13074","submitter":"Ouriel Bl{\\oe}d\\'e","authors":"Ouriel Bl{\\oe}d\\'e","title":"Approximation of the centre of unstable algebras using the nilpotent\n  filtration","comments":"29 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AT","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  In a precedent article, we computed the set $\\textbf{C}(K)$ of central\nelements of an unstable algebra $K$ over the Steenrod algebra, in the sense of\nDwyer and Wilkerson, when $K$ is noetherian and $nil_1$-closed.\n  For $K$ noetherian and $k$ a positive integer, we define $\\textbf{C}_k(K)$,\nthe set of so-called central elements of $K$ away from $\\mathcal{N}il_k$ in\nsuch a way that, for $K$ $nil_k$-closed, $\\textbf{C}(K)=\\textbf{C}_k(K)$.\n  The sets $\\textbf{C}_k(K)$ are a decreasing filtration, and we describe the\nobstruction for an element in $\\textbf{C}_k(K)$ to be in $\\textbf{C}_{k+1}(K)$.\nSince, for $K$ noetherian, $K$ is always $nil_k$-closed for $k$ big enough,\nthis gives us a way to compute the set of central elements of $K$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:44:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13075","submitter":"M\\'ario S. Alvim","authors":"Mireya Jurado and Ramon G. Gonze and M\\'ario S. Alvim and Catuscia\n  Palamidessi","title":"Analyzing the Shuffle Model through the Lens of Quantitative Information\n  Flow","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Local differential privacy (LDP) is a variant of differential privacy (DP)\nthat avoids the need for a trusted central curator, at the cost of a worse\ntrade-off between privacy and utility. The shuffle model is a way to provide\ngreater anonymity to users by randomly permuting their messages, so that the\nlink between users and their reported values is lost to the data collector. By\ncombining an LDP mechanism with a shuffler, privacy can be improved at no cost\nfor the accuracy of operations insensitive to permutations, thereby improving\nutility in many tasks. However, the privacy implications of shuffling are not\nalways immediately evident, and derivations of privacy bounds are made on a\ncase-by-case basis.\n  In this paper, we analyze the combination of LDP with shuffling in the\nrigorous framework of quantitative information flow (QIF), and reason about the\nresulting resilience to inference attacks. QIF naturally captures randomization\nmechanisms as information-theoretic channels, thus allowing for precise\nmodeling of a variety of inference attacks in a natural way and for measuring\nthe leakage of private information under these attacks. We exploit symmetries\nof the particular combination of k-RR mechanisms with the shuffle model to\nachieve closed formulas that express leakage exactly. In particular, we provide\nformulas that show how shuffling improves protection against leaks in the local\nmodel, and study how leakage behaves for various values of the privacy\nparameter of the LDP mechanism.\n  In contrast to the strong adversary from differential privacy, we focus on an\nuninformed adversary, who does not know the value of any individual in the\ndataset. This adversary is often more realistic as a consumer of statistical\ndatasets, and we show that in some situations mechanisms that are equivalent\nw.r.t. the strong adversary can provide different privacy guarantees under the\nuninformed one.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:46:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13076","submitter":"Nikhil Krishnaswamy","authors":"Kiyong Lee, Nikhil Krishnaswamy, James Pustejovsky","title":"An Abstract Specification of VoxML as an Annotation Language","comments":"8 pages, 4 figures, Proceedings of 19th Joint ISO-ACL Workshop on\n  Interoperable Semantic Annotation (ISA 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  VoxML is a modeling language used to map natural language expressions into\nreal-time visualizations using commonsense semantic knowledge of objects and\nevents. Its utility has been demonstrated in embodied simulation environments\nand in agent-object interactions in situated multimodal human-agent\ncollaboration and communication. It introduces the notion of object affordance\n(both Gibsonian and Telic) from HRI and robotics, as well as the concept of\nhabitat (an object's context of use) for interactions between a rational agent\nand an object. This paper aims to specify VoxML as an annotation language in\ngeneral abstract terms. It then shows how it works on annotating linguistic\ndata that express visually perceptible human-object interactions. The\nannotation structures thus generated will be interpreted against the enriched\nminimal model created by VoxML as a modeling language while supporting the\nmodeling purposes of VoxML linguistically.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:47:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13077","submitter":"Yabo Zhang","authors":"Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng\n  Zuo, Qi Tian","title":"ControlVideo: Training-free Controllable Text-to-Video Generation","comments":"Code is available at https://github.com/YBYBZhang/ControlVideo","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Text-driven diffusion models have unlocked unprecedented abilities in image\ngeneration, whereas their video counterpart still lags behind due to the\nexcessive training cost of temporal modeling. Besides the training burden, the\ngenerated videos also suffer from appearance inconsistency and structural\nflickers, especially in long video synthesis. To address these challenges, we\ndesign a \\emph{training-free} framework called \\textbf{ControlVideo} to enable\nnatural and efficient text-to-video generation. ControlVideo, adapted from\nControlNet, leverages coarsely structural consistency from input motion\nsequences, and introduces three modules to improve video generation. Firstly,\nto ensure appearance coherence between frames, ControlVideo adds fully\ncross-frame interaction in self-attention modules. Secondly, to mitigate the\nflicker effect, it introduces an interleaved-frame smoother that employs frame\ninterpolation on alternated frames. Finally, to produce long videos\nefficiently, it utilizes a hierarchical sampler that separately synthesizes\neach short clip with holistic coherency. Empowered with these modules,\nControlVideo outperforms the state-of-the-arts on extensive motion-prompt pairs\nquantitatively and qualitatively. Notably, thanks to the efficient designs, it\ngenerates both short and long videos within several minutes using one NVIDIA\n2080Ti. Code is available at https://github.com/YBYBZhang/ControlVideo.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:48:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13078","submitter":"Dario  Izzo","authors":"Dario Izzo, Emmanuel Blazquez, Robin Ferede, Sebastien Origer,\n  Christophe De Wagter, Guido C.H.E. de Croon","title":"Optimality Principles in Spacecraft Neural Guidance and Control","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO astro-ph.EP cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Spacecraft and drones aimed at exploring our solar system are designed to\noperate in conditions where the smart use of onboard resources is vital to the\nsuccess or failure of the mission. Sensorimotor actions are thus often derived\nfrom high-level, quantifiable, optimality principles assigned to each task,\nutilizing consolidated tools in optimal control theory. The planned actions are\nderived on the ground and transferred onboard where controllers have the task\nof tracking the uploaded guidance profile. Here we argue that end-to-end neural\nguidance and control architectures (here called G&CNets) allow transferring\nonboard the burden of acting upon these optimality principles. In this way, the\nsensor information is transformed in real time into optimal plans thus\nincreasing the mission autonomy and robustness. We discuss the main results\nobtained in training such neural architectures in simulation for interplanetary\ntransfers, landings and close proximity operations, highlighting the successful\nlearning of optimality principles by the neural model. We then suggest drone\nracing as an ideal gym environment to test these architectures on real robotic\nplatforms, thus increasing confidence in their utilization on future space\nexploration missions. Drone racing shares with spacecraft missions both limited\nonboard computational capabilities and similar control structures induced from\nthe optimality principle sought, but it also entails different levels of\nuncertainties and unmodelled effects. Furthermore, the success of G&CNets on\nextremely resource-restricted drones illustrates their potential to bring\nreal-time optimal control within reach of a wider variety of robotic systems,\nboth in space and on Earth.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:48:58 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13079","submitter":"Umar Hashmi Md","authors":"Md Umar Hashmi and Dirk Van Hertem","title":"Robust dynamic operating envelopes for flexibility operation using only\n  local voltage measurement","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SY cs.SY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With growing intermittency and uncertainty in distribution networks around\nthe world, ensuring operational integrity is becoming challenging. Recent use\ncases of dynamic operating envelopes (DOEs) indicate that it can be utilized\nfor network awareness for autonomous operation of flexibility, maximizing\ndistributed generation integration, coordinating flexibility in different power\nnetworks and in resource planning. To this end, we propose a novel framework\nfor generating decentralized, risk-averse, robust DOEs using only the nodal\nvoltage measurement or forecast. Chance constraint level is analytically\nimplemented for avoiding extremely restrictive time-ahead DOEs with\ninsufficient feasible region for local energy optimization. Since the proposed\nDOE calculation framework uses no centralized feedback, it is resilient to\ncyberattacks, communication failures, missing data and errors in network layout\ninformation. Numerical results showcase DOE calculation framework in real-time\nusing voltage magnitude measurements and in day-ahead timeframe using\nforecasted voltage scenarios. Furthermore, the DOEs are extended to form P-Q\ncharts while considering power factor and converter capacity limits.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:50:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13080","submitter":"Ruan van Der Merwe Mr","authors":"Ruan van der Merwe and Herman Kamper","title":"Mitigating Catastrophic Forgetting for Few-Shot Spoken Word\n  Classification Through Meta-Learning","comments":"5 pages, 3 figures, Accepted to Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We consider the problem of few-shot spoken word classification in a setting\nwhere a model is incrementally introduced to new word classes. This would occur\nin a user-defined keyword system where new words can be added as the system is\nused. In such a continual learning scenario, a model might start to misclassify\nearlier words as newer classes are added, i.e. catastrophic forgetting. To\naddress this, we propose an extension to model-agnostic meta-learning (MAML):\neach inner learning loop, where a model \"learns how to learn'' new classes,\nends with a single gradient update using stored templates from all the classes\nthat the model has already seen (one template per class). We compare this\nmethod to OML (another extension of MAML) in few-shot isolated-word\nclassification experiments on Google Commands and FACC. Our method consistently\noutperforms OML in experiments where the number of shots and the final number\nof classes are varied.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:51:15 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13081","submitter":"Mohit Pundir Dr","authors":"Mohit Pundir, David S. Kammer, Ueli Angst","title":"An FFT-based framework for predicting corrosion-driven damage in fractal\n  porous media","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.soft","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Understanding fracture in cementitious materials caused by the deposition and\ngrowth of corrosion products requires scale-bridging approaches due to the\nlarge length-scale difference between the micro-pores, where deposition occurs,\nand the structure, where deterioration manifests. Cementitious materials bear a\nhighly heterogeneous micro-structure owing to the fractal nature of\nmicro-pores. Simultaneously, a corrosion-driven fracture is a multi-physics\nproblem involving ionic diffusion, chemical reactions, and stress development.\nThis multi-scale and multi-physical character makes scale-bridging studies\ncomputationally costly, often leading to the use of simplified fractal porous\nmedia, which has important consequences for the quantitative interpretation of\nthe results. Recent advances in homogenization approaches using\nFast-Fourier-Transform (FFT) based methods have raised interest due to their\nease of implementation and low computational cost. This paper presents an\nFFT-based framework for solving corrosion-driven fractures within fractal\nporous media. We demonstrate the effectiveness of the Fourier-based spectral\nmethod in resolving the multiple corrosion-driven mechanisms such as ionic\ndiffusion, stress development, and damage within a fractal porous\nmicrostructure. Based on the presented methodology, we analyze the impact of\nsimplifying fractal porous media with simple Euclidean geometry on\ncorrosion-driven fracture. Our results demonstrate the importance of preserving\nboth the porosity and fractal nature of pores for precise and reliable modeling\nof corrosion-driven failure mechanisms.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:51:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13082","submitter":"Slavom\\'ir Hanzely","authors":"Slavom\\'ir Hanzely","title":"Sketch-and-Project Meets Newton Method: Global $\\mathcal O(k^{-2})$\n  Convergence with Low-Rank Updates","comments":"10 pages main body","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we propose the first sketch-and-project Newton method with\nfast $\\mathcal O(k^{-2})$ global convergence rate for self-concordant\nfunctions. Our method, SGN, can be viewed in three ways: i) as a\nsketch-and-project algorithm projecting updates of Newton method, ii) as a\ncubically regularized Newton ethod in sketched subspaces, and iii) as a damped\nNewton method in sketched subspaces. SGN inherits best of all three worlds:\ncheap iteration costs of sketch-and-project methods, state-of-the-art $\\mathcal\nO(k^{-2})$ global convergence rate of full-rank Newton-like methods and the\nalgorithm simplicity of damped Newton methods. Finally, we demonstrate its\ncomparable empirical performance to baseline algorithms.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:51:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13083","submitter":"Ruochen Xu","authors":"Yichong Xu, Ruochen Xu, Dan Iter, Yang Liu, Shuohang Wang, Chenguang\n  Zhu, Michael Zeng","title":"InheritSumm: A General, Versatile and Compact Summarizer by Distilling\n  from GPT","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  While large models such as GPT-3 demonstrate exceptional performance in\nzeroshot and fewshot summarization tasks, their extensive serving and\nfine-tuning costs hinder their utilization in various applications. Conversely,\nprevious studies have found that although automatic metrics tend to favor\nsmaller fine-tuned models, the quality of the summaries they generate is\ninferior to that of larger models like GPT-3 when assessed by human evaluators.\nTo address this issue, we propose InheritSumm, a versatile and compact\nsummarization model derived from GPT-3.5 through distillation. InheritSumm not\nonly exhibits comparable zeroshot and fewshot summarization capabilities to\nGPT-3.5 but is also sufficiently compact for fine-tuning purposes. Experimental\nresults demonstrate that InheritSumm achieves similar or superior performance\nto GPT-3.5 in zeroshot and fewshot settings. Furthermore, it outperforms the\npreviously established best small models in both prefix-tuning and full-data\nfine-tuning scenarios.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:52:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13084","submitter":"Raffaele Paolino","authors":"Sohir Maskey, Raffaele Paolino, Aras Bacho, Gitta Kutyniok","title":"A Fractional Graph Laplacian Approach to Oversmoothing","comments":"First two authors contributed equally. 37 pages, 8 images","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Graph neural networks (GNNs) have shown state-of-the-art performances in\nvarious applications. However, GNNs often struggle to capture long-range\ndependencies in graphs due to oversmoothing. In this paper, we generalize the\nconcept of oversmoothing from undirected to directed graphs. To this aim, we\nextend the notion of Dirichlet energy by considering a directed symmetrically\nnormalized Laplacian. As vanilla graph convolutional networks are prone to\noversmooth, we adopt a neural graph ODE framework. Specifically, we propose\nfractional graph Laplacian neural ODEs, which describe non-local dynamics. We\nprove that our approach allows propagating information between distant nodes\nwhile maintaining a low probability of long-distance jumps. Moreover, we show\nthat our method is more flexible with respect to the convergence of the graph's\nDirichlet energy, thereby mitigating oversmoothing. We conduct extensive\nexperiments on synthetic and real-world graphs, both directed and undirected,\ndemonstrating our method's versatility across diverse graph homophily levels.\nOur code is available at https://github.com/RPaolino/fLode .\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:52:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13085","submitter":"Ratish Puduppully","authors":"Ratish Puduppully, Raj Dabre, Ai Ti Aw, Nancy F. Chen","title":"Decomposed Prompting for Machine Translation Between Related Languages\n  using Large Language Models","comments":"work-in-progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share similar linguistic traits such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This requires the model to learn how to\ngenerate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nevaluations conducted on multiple related language pairs across various\nlanguage families, we demonstrate that our novel approach of decomposed\nprompting surpasses multiple established few-shot baseline models, thereby\nverifying its effectiveness. For example, our model outperforms the strong\nfew-shot prompting BLOOM model with an average improvement of 4.2 chrF++ scores\nacross the examined languages.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:52:47 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13086","submitter":"Ruochen Xu","authors":"Ruochen Xu, Song Wang, Yang Liu, Shuohang Wang, Yichong Xu, Dan Iter,\n  Chenguang Zhu, Michael Zeng","title":"LMGQS: A Large-scale Dataset for Query-focused Summarization","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Query-focused summarization (QFS) aims to extract or generate a summary of an\ninput document that directly answers or is relevant to a given query. The lack\nof large-scale datasets in the form of documents, queries, and summaries has\nhindered model development in this area. In contrast, multiple large-scale\nhigh-quality datasets for generic summarization exist. We hypothesize that\nthere is a hidden query for each summary sentence in a generic summarization\nannotation, and we utilize a large-scale pretrained language model to recover\nit. In this way, we convert four generic summarization benchmarks into a new\nQFS benchmark dataset, LMGQS, which consists of over 1 million\ndocument-query-summary samples. We thoroughly investigate the properties of our\nproposed dataset and establish baselines with state-of-the-art summarization\nmodels. By fine-tuning a language model on LMGQS, we achieve state-of-the-art\nzero-shot and supervised performance on multiple existing QFS benchmarks,\ndemonstrating the high quality and diversity of LMGQS.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:53:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13087","submitter":"Jonas K\\\"uhne","authors":"Jonas K\\\"uhne, Michele Magno, Luca Benini","title":"A Fast and Accurate Optical Flow Camera for Resource-Constrained Edge\n  Applications","comments":"Accepted by IWASI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Optical Flow (OF) is the movement pattern of pixels or edges that is caused\nin a visual scene by the relative motion between an agent and a scene. OF is\nused in a wide range of computer vision algorithms and robotics applications.\nWhile the calculation of OF is a resource-demanding task in terms of\ncomputational load and memory footprint, it needs to be executed at low\nlatency, especially in robotics applications. Therefore, OF estimation is today\nperformed on powerful CPUs or GPUs to satisfy the stringent requirements in\nterms of execution speed for control and actuation. On-sensor hardware\nacceleration is a promising approach to enable low latency OF calculations and\nfast execution even on resource-constrained devices such as nano drones and\nAR/VR glasses and headsets. This paper analyzes the achievable accuracy, frame\nrate, and power consumption when using a novel optical flow sensor consisting\nof a global shutter camera with an Application Specific Integrated Circuit\n(ASIC) for optical flow computation. The paper characterizes the optical flow\nsensor in high frame-rate, low-latency settings, with a frame rate of up to 88\nfps at the full resolution of 1124 by 1364 pixels and up to 240 fps at a\nreduced camera resolution of 280 by 336, for both classical camera images and\noptical flow data.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:54:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13088","submitter":"Abdelrahman Zayed","authors":"Abdelrahman Zayed, Goncalo Mordido, Samira Shabanian, Sarath Chandar","title":"Should We Attend More or Less? Modulating Attention for Fairness","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.CY cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The abundance of annotated data in natural language processing (NLP) poses\nboth opportunities and challenges. While it enables the development of\nhigh-performing models for a variety of tasks, it also poses the risk of models\nlearning harmful biases from the data, such as gender stereotypes. In this\nwork, we investigate the role of attention, a widely-used technique in current\nstate-of-the-art NLP models, in the propagation of social biases. Specifically,\nwe study the relationship between the entropy of the attention distribution and\nthe model's performance and fairness. We then propose a novel method for\nmodulating attention weights to improve model fairness after training. Since\nour method is only applied post-training and pre-inference, it is an\nintra-processing method and is, therefore, less computationally expensive than\nexisting in-processing and pre-processing approaches. Our results show an\nincrease in fairness and minimal performance loss on different text\nclassification and generation tasks using language models of varying sizes.\nWARNING: This work uses language that is offensive.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:54:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13089","submitter":"Pan Peng","authors":"Pan Peng, Yuyang Wang","title":"An Optimal Separation between Two Property Testing Models for Bounded\n  Degree Directed Graphs","comments":"To appear in ICALP 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We revisit the relation between two fundamental property testing models for\nbounded-degree directed graphs: the bidirectional model in which the algorithms\nare allowed to query both the outgoing edges and incoming edges of a vertex,\nand the unidirectional model in which only queries to the outgoing edges are\nallowed. Czumaj, Peng and Sohler [STOC 2016] showed that for directed graphs\nwith both maximum indegree and maximum outdegree upper bounded by $d$, any\nproperty that can be tested with query complexity $O_{\\varepsilon,d}(1)$ in the\nbidirectional model can be tested with $n^{1-\\Omega_{\\varepsilon,d}(1)}$\nqueries in the unidirectional model. In particular, if the proximity parameter\n$\\varepsilon$ approaches $0$, then the query complexity of the transformed\ntester in the unidirectional model approaches $n$. It was left open if this\ntransformation can be further improved or there exists any property that\nexhibits such an extreme separation.\n  We prove that testing subgraph-freeness in which the subgraph contains $k$\nsource components, requires $\\Omega(n^{1-\\frac{1}{k}})$ queries in the\nunidirectional model. This directly gives the first explicit properties that\nexhibit an $O_{\\varepsilon,d}(1)$ vs $\\Omega(n^{1-f(\\varepsilon,d)})$\nseparation of the query complexities between the bidirectional model and\nunidirectional model, where $f(\\varepsilon,d)$ is a function that approaches\n$0$ as $\\varepsilon$ approaches $0$. Furthermore, our lower bound also resolves\na conjecture by Hellweg and Sohler [ESA 2012] on the query complexity of\ntesting $k$-star-freeness.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:54:46 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13090","submitter":"Chen-How Huang","authors":"Chen-How Huang, Thierry Giamarchi and Miguel A. Cazalilla","title":"Modeling Particle Loss in Open Systems using Keldysh Path Integral and\n  Second Order Cumulant Expansion","comments":"14 pages, 4 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.quant-gas","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  For open quantum systems, integration of the bath degrees of freedom using\nthe second order cumulant expansion in the Keldysh path integral provides an\nalternative derivation of the effective action for systems coupled to general\nbaths. The baths can be interacting and not necessarily Markovian. Using this\nmethod in the Markovian limit, we compute the particle loss dynamics in various\nmodels of ultra-cold atomic gases including a one-dimensional Bose-Hubbard\nmodel with two-particle losses and a multi-component Fermi gas with\ninteractions tuned by an optical Feshbach resonance. We explicitly demonstrate\nthat the limit of strong two-body losses can be treated by formulating an\nindirect loss scheme to describe the bath-system coupling. The particle-loss\ndynamics thus obtained is valid at all temperatures. For the one-dimensional\nBose-Hubbard model, we compare it to solutions of the phenomenological rate\nequations. The latter are shown to be accurate at high temperatures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:56:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13091","submitter":"Chenhui Shen","authors":"Chenhui Shen, Liying Cheng, Yang You, Lidong Bing","title":"Are Large Language Models Good Evaluators for Abstractive Summarization?","comments":"11 pages, 10 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Human evaluations are often required for abstractive summary evaluations to\ngive fairer judgments. However, they are often time-consuming, costly,\ninconsistent, and non-reproducible. To overcome these challenges, we explore\nthe potential of using an out-of-the-box LLM (i.e. \"gpt-3.5-turbo\") for\nsummarization evaluation without manually selecting demonstrations or complex\nprompt tuning. We compare different evaluation methods, including 2 methods for\nLikert-scale scoring and 1 method for head-to-head comparisons, to investigate\nthe performance of the LLM as a zero-shot evaluator. We further propose a\nmeta-correlation metric to measure the stability of the LLM's evaluation\ncapability. With extensive experiments, we show that certain prompt formats can\nproduce better results than others. We also bring attention to the LLM's\ndeteriorating evaluation capability with the rising qualities of summaries. In\naddition, we find that the LLM's evaluation capability also depends on the\nevaluated dimensions. We discuss the pros and cons of each method, make\nrecommendations, and suggest some future directions for improvement.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:58:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13092","submitter":"Sam Spilsbury","authors":"Sam Spilsbury, Alexander Ilin","title":"Improved Compositional Generalization by Generating Demonstrations for\n  Meta-Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Meta-learning and few-shot prompting are viable methods to induce certain\ntypes of compositional behaviour. However, these methods can be very sensitive\nto the choice of support examples used. Choosing good supports from the\ntraining data for a given test query is already a difficult problem, but in\nsome cases solving this may not even be enough. We consider a grounded language\nlearning problem (gSCAN) where good support examples for certain test splits\nmight not even exist in the training data, or would be infeasible to search\nfor. We design an agent which instead generates possible supports which are\nrelevant to the test query and current state of the world, then uses these\nsupports via meta-learning to solve the test query. We show substantially\nimproved performance on a previously unsolved compositional behaviour split\nwithout a loss of performance on other splits. Further experiments show that in\nthis case, searching for relevant demonstrations even with an oracle function\nis not sufficient to attain good performance when using meta-learning.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:58:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13093","submitter":"Jiaxi Jiang","authors":"Jiaxi Jiang, Christian Holz","title":"Restore Anything Pipeline: Segment Anything Meets Image Restoration","comments":"Code: https://github.com/eth-siplab/RAP","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AI cs.LG eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recent image restoration methods have produced significant advancements using\ndeep learning. However, existing methods tend to treat the whole image as a\nsingle entity, failing to account for the distinct objects in the image that\nexhibit individual texture properties. Existing methods also typically generate\na single result, which may not suit the preferences of different users. In this\npaper, we introduce the Restore Anything Pipeline (RAP), a novel interactive\nand per-object level image restoration approach that incorporates a\ncontrollable model to generate different results that users may choose from.\nRAP incorporates image segmentation through the recent Segment Anything Model\n(SAM) into a controllable image restoration model to create a user-friendly\npipeline for several image restoration tasks. We demonstrate the versatility of\nRAP by applying it to three common image restoration tasks: image deblurring,\nimage denoising, and JPEG artifact removal. Our experiments show that RAP\nproduces superior visual results compared to state-of-the-art methods. RAP\nrepresents a promising direction for image restoration, providing users with\ngreater control, and enabling image restoration at an object level.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:59:03 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13094","submitter":"\\'Alvaro Tejero","authors":"Rub\\'en Hurtado-Guti\\'errez and \\'Alvaro Tejero","title":"Measuring the capacitor charge and discharge with a LED and a smartphone","comments":"6 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.ed-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this article, we present a simple, cheap and effective method for\nmeasuring the capacitor charge and discharge processes using a Light Emitting\nDiode (LED) and the light meter of a smartphone. We propose a simple circuit in\nwhich the LED's brightness is linear on the capacitor's voltage, which allows\nus to use the smartphone to monitor the capacitor state with high accuracy. The\nmethod is tested experimentally, giving highly satisfactory results. This novel\ntechnique is highly advantageous due to its ease of implementation, the minimal\nrequired equipment and is adaptability for use in educational settings.\nAdditionally, it provides an excellent way to introduce students to basic\nconcepts of electricity and electronics.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:59:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13095","submitter":"Jiaming Liu","authors":"Jiaming Liu, Yangqiming Wang, Tongze Zhang, Yulu Fan, Qinli Yang and\n  Junming Shao","title":"Open-world Semi-supervised Novel Class Discovery","comments":"Accepted to IJCAI 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Traditional semi-supervised learning tasks assume that both labeled and\nunlabeled data follow the same class distribution, but the realistic open-world\nscenarios are of more complexity with unknown novel classes mixed in the\nunlabeled set. Therefore, it is of great challenge to not only recognize\nsamples from known classes but also discover the unknown number of novel\nclasses within the unlabeled data. In this paper, we introduce a new open-world\nsemi-supervised novel class discovery approach named OpenNCD, a progressive\nbi-level contrastive learning method over multiple prototypes. The proposed\nmethod is composed of two reciprocally enhanced parts. First, a bi-level\ncontrastive learning method is introduced, which maintains the pair-wise\nsimilarity of the prototypes and the prototype group levels for better\nrepresentation learning. Then, a reliable prototype similarity metric is\nproposed based on the common representing instances. Prototypes with high\nsimilarities will be grouped progressively for known class recognition and\nnovel class discovery. Extensive experiments on three image datasets are\nconducted and the results show the effectiveness of the proposed method in\nopen-world scenarios, especially with scarce known classes and labels.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:59:50 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13096","submitter":"Edwin Fohtung","authors":"Xiaowen Shi, Nimish Prashant Nazirkar, Ravi Kashikar, Dmitry Karpov,\n  Shola Folarin, Zachary Barringer, Skye Williams, Boris Kiefer, Ross Harder,\n  Wonsuk Cha, Ruihao Yuan, Zhen Liu, Dezhen Xue, Turab Lookman, Inna\n  Ponomareva, Edwin Fohtung","title":"Enhanced piezoelectric response at nanoscale vortex structures in\n  ferroelectrics","comments":"13 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The piezoelectric response is a measure of the sensitivity of a material's\npolarization to stress or its strain to an applied field. Using in-operando\nx-ray Bragg coherent diffraction imaging, we observe that topological vortices\nare the source of a five-fold enhancement of the piezoelectric response near\nthe vortex core. The vortices form where several low symmetry ferroelectric\nphases and phase boundaries coalesce. Unlike bulk ferroelectric solid solutions\nin which a large piezoelectric response is associated with coexisting phases in\nthe proximity of the triple point, the largest responses for pure BaTiO3 at the\nnanoscale are in spatial regions of extremely small spontaneous polarization at\nvortex cores. The response decays inversely with polarization away from the\nvortex, analogous to the behavior in bulk ceramics as the cation compositions\nare varied away from the triple point. We use first-principles-based molecular\ndynamics to augment our observations, and our results suggest that nanoscale\npiezoelectric materials with large piezoelectric response can be designed\nwithin a parameter space governed by vortex cores. Our findings have\nimplications for the development of next-generation nanoscale piezoelectric\nmaterials.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:59:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13097","submitter":"Jack F. Gallimore","authors":"Jack F. Gallimore and C. M. Violette Impellizzeri","title":"High Sensitivity Observations of the Water Megamasers of NGC 1068:\n  Precise Astrometry and Detailed Kinematics","comments":"Accepted for publication in the Astrophysical Journal. 36 pages, 22\n  figures","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present High Sensitivity Array observation of the water megamasers of NGC\n1068. We obtain absolute astrometry with 0.3 mas precision that confirms the\nassociation of the disk masers with the nuclear radio continuum source S1. The\nnew observations reveal two new blueshifted groups of disk masers. We also\ndetect the 22 GHz continuum on short interferometric baselines. The\nposition-velocity diagram of the disk masers shows a curve consistent with a\nnonaxisymmetric distribution of maser spots. The curve is probably the result\nof spiral arms with a constant pitch angle of roughly 5 degrees. The disk\nkinematics are consistent with Keplerian rotation and low turbulent speeds. The\ninferred central mass is 17 million solar masses. On the basis of disk\nstability arguments, the mass of the molecular disk is roughly 110 thousand\nsolar masses. The disk masers further resolve into filamentary structures\nsuggesting an ordered magnetic field threading the maser disk. The magnetic\nfield strengths must be greater than 1.6 mG to withstand turbulent motions in\nthe partially ionized molecular gas. We note apparent asymmetries in the\nmolecular disk that might be explained by anisotropic heating by a misaligned\ninner accretion disk. The new observations also detect the fainter jet masers\nnorth of the disk masers. The distribution and kinematics of the jet masers are\nconsistent with an expanding ring of molecular gas.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:00:13 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13098","submitter":"Iain Cruickshank","authors":"Iain J. Cruickshank, Jessica Zhu, Nathaniel D. Bastian","title":"Analysis of Media Writing Style Bias through Text-Embedding Networks","comments":"under submission with ICWSM 2024","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.SI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With the rise of phenomena like `fake news' and the growth of heavily-biased\nmedia ecosystems, there has been increased attention on understanding and\nevaluating media bias. Of particular note in the evaluation of media bias is\nwriting style bias, which includes lexical bias and framing bias. We propose a\nnovel approach to evaluating writing style bias that utilizes natural language\nsimilarity estimation and a network-based representation of the shared content\nbetween articles to perform bias characterization. Our proposed method presents\na new means of evaluating writing style bias that does not rely on human\nexperts or knowledge of a media producer's publication procedures. The results\nof experimentation on real-world vaccine mandate data demonstrates the utility\nof the technique and how the standard bias labeling procedures of only having\none bias label for a media producer is insufficient to truly characterize the\nbias of that media producer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:00:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13099","submitter":"Andrei Poblaguev","authors":"Andrei Poblaguev","title":"Breakup Corrections to Spin Asymmetries in the $^3$He Beam Polarization\n  Measurement with HJET","comments":"8 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:2303.00677","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The requirements for hadron polarimetry at the future Electron Ion Collider\n(EIC) include measurements of the absolute helion ($^3$He, $h$) beam\npolarization with systematic uncertainties better than\n$\\sigma^\\text{syst}_P/P\\le1\\%$. Recently, it was proposed that the Polarized\nAtomic Hydrogen Gas Jet Target (HJET) be utilized for the precision measurement\nof the polarization of the $\\sim$100 GeV/n helion beam. At the Relativistic\nHeavy Ion Collider, HJET serves to determine the absolute proton beam\npolarization with low systematic uncertainties of about\n$\\delta^\\text{syst}P/P\\lesssim0.5\\%$. To adapt the HJET method for the EIC\nhelion beam, the experimentally determined ratio of the beam and target (jet)\nspin-correlated asymmetries should be adjusted by the ratio of $p^\\uparrow{h}$\nand $h^\\uparrow{p}$ analyzing powers. A potential problem with the suggested\nmethod is that the breakup of $^3$He in polarization measurements could\ndrastically affect the analyzing power ratio. However, an analysis of the\nbreakup corrections, presented in this paper, reveals that while these\ncorrections can be as substantial as $\\sim$4\\%, the effect cancels out to a\nnegligible level in the measured beam polarization.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:00:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13100","submitter":"Benjamin Lindner","authors":"Maria Schlungbaum and Benjamin Lindner","title":"Detecting a periodic signal by a population of spiking neurons in the\n  weakly nonlinear response regime","comments":"12 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.bio-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Motivated by experimental observations, we investigate a variant of the\ncocktail party problem: the detection of a weak periodic stimulus in the\npresence of fluctuations and another periodic stimulus which is stronger than\nthe periodic signal to be detected. Specifically, we study the response of a\npopulation of stochastic leaky integrate-and-fire (LIF) neurons to two periodic\nsignals and focus in particular on the question, whether the presence of one of\nthe stimuli can be detected from the population activity. As a detection\ncriterion, we use a simple threshold-crossing of the population activity over a\ncertain time window. We show by means of the receiver operating characteristics\n(ROC) that the detectability depends only weakly on the time window of\nobservation but rather strongly on the stimulus amplitude. Counterintuitively,\nthe detection of the weak periodic signal can be facilitated by the presence of\na strong periodic input current depending on the frequencies of the two signals\nand on the dynamical regime in which the neurons operate. Beside numerical\nsimulations of the model we present an analytical approximation for the ROC\ncurve that is based on the weakly nonlinear-response theory for a stochastic\nLIF neuron. We discuss the validity of this approximation as well as the\nrelevance of our results for a detection problem in weakly electric fish.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:00:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13101","submitter":"Michal Edelstein","authors":"Michal Edelstein, Nestor Guillen, Justin Solomon, Mirela Ben-Chen","title":"A Convex Optimization Framework for Regularized Geodesic Distances","comments":"11 pages (excluding supplementary material), 14 figures, SIGGRAPH\n  2023","journal-ref":"SIGGRAPH '23 Conference Proceedings, August 6-10, 2023, Los\n  Angeles, CA, USA","doi":"10.1145/3588432.3591523","report-no":null,"categories":"cs.GR","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  We propose a general convex optimization problem for computing regularized\ngeodesic distances. We show that under mild conditions on the regularizer the\nproblem is well posed. We propose three different regularizers and provide\nanalytical solutions in special cases, as well as corresponding efficient\noptimization algorithms. Additionally, we show how to generalize the approach\nto the all pairs case by formulating the problem on the product manifold, which\nleads to symmetric distances. Our regularized distances compare favorably to\nexisting methods, in terms of robustness and ease of calibration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:00:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13102","submitter":"Sumit Soman","authors":"Sumit Soman, Ranjani H G","title":"Observations on LLMs for Telecom Domain: Capabilities and Limitations","comments":"11 pages, 2 figures, 8 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.HC cs.AI cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The landscape for building conversational interfaces (chatbots) has witnessed\na paradigm shift with recent developments in generative Artificial Intelligence\n(AI) based Large Language Models (LLMs), such as ChatGPT by OpenAI (GPT3.5 and\nGPT4), Google's Bard, Large Language Model Meta AI (LLaMA), among others. In\nthis paper, we analyze capabilities and limitations of incorporating such\nmodels in conversational interfaces for the telecommunication domain,\nspecifically for enterprise wireless products and services. Using Cradlepoint's\npublicly available data for our experiments, we present a comparative analysis\nof the responses from such models for multiple use-cases including domain\nadaptation for terminology and product taxonomy, context continuity, robustness\nto input perturbations and errors. We believe this evaluation would provide\nuseful insights to data scientists engaged in building customized\nconversational interfaces for domain-specific requirements.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:04:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13103","submitter":"Keisuke Konosu","authors":"Keisuke Konosu","title":"Correlation functions involving Dirac fields from homotopy algebras II:\n  the interacting theory","comments":"34 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We extend the formula for correlation functions of free scalar field theories\nand Dirac field theories in terms of quantum $A_{\\infty}$ algebras presented in\narXiv:2305.11634 to general scalar-Dirac systems. We obtain the result that the\nsame formula as in the previous paper holds in this case. We show that\ncorrelation functions from our formula satisfy the Schwinger-Dyson equations.\nWe therefore confirm that correlation functions from our formula express\ncorrelation functions from the ordinary approach of quantum field theory.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:04:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13104","submitter":"Mubarak Ibrahim PhD","authors":"M. R. Ibrahim, D. U. Muhammad, B. Muhammad, J. O. Alaezi and J.\n  Agidani","title":"The Key to Organizational and construction Excellence: A Study of Total\n  Quality Management","comments":"19 pages 3 Postscript figures","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  This study examines the impact of Total Quality Management (TQM) practices on\norganizational outcomes. Results show a significant relationship between TQM\npractices such as top executive commitment, education and teaching, process\ncontrol, and continuous progress, and how they can be leveraged to enhance\nperformance outcomes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:07:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13105","submitter":"Jack Button","authors":"J. O. Button","title":"Quasi-actions whose quasi-orbits are quasi-isometric to trees","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.GR math.GT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We give necessary and sufficient conditions under which a quasi-action of any\ngroup on an arbitrary metric space can be reduced to a cobounded isometric\naction on some bounded valence tree, following a result of Mosher, Sageev and\nWhyte. Moreover if the quasi-action is metrically proper and quasi-orbits are\nquasi-isometric to trees then the group is virtually free.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:07:45 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13106","submitter":"Philipp Geiger","authors":"Jia Yu Tee, Oliver De Candido, Wolfgang Utschick, Philipp Geiger","title":"On Learning the Tail Quantiles of Driving Behavior Distributions via\n  Quantile Regression and Flows","comments":"This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.RO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Towards safe autonomous driving (AD), we consider the problem of learning\nmodels that accurately capture the diversity and tail quantiles of human driver\nbehavior probability distributions, in interaction with an AD vehicle. Such\nmodels, which predict drivers' continuous actions from their states, are\nparticularly relevant for closing the gap between AD simulation and reality. To\nthis end, we adapt two flexible frameworks for this setting that avoid strong\ndistributional assumptions: (1)~quantile regression (based on the titled\nabsolute loss), and (2)~autoregressive quantile flows (a version of normalizing\nflows). Training happens in a behavior cloning-fashion. We evaluate our\napproach in a one-step prediction, as well as in multi-step simulation\nrollouts. We use the highD dataset consisting of driver trajectories on several\nhighways. We report quantitative results using the tilted absolute loss as\nmetric, give qualitative examples showing that realistic extremal behavior can\nbe learned, and discuss the main insights.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:09:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13107","submitter":"M\\'ario Rocha-Neto","authors":"M\\'ario Rocha-Neto and Gustavo Camelo-Neto and Edvaldo Nogueira-Junior\n  and S\\'ergio Coutinho","title":"Thermodynamical behavior of the Blume-Capel model in the vicinity of its\n  tricritical point","comments":"19 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We investigate the thermodynamic properties of the zero-field Blume-Capel\nmodel in the vicinity of its tricritical point (TCP). We calculate the\nquadrupole moment, internal energy, and entropy densities employing an exact\nnumerical recursion procedure for the model defined on a hierarchical lattice\nof fractal dimension $d$. We explore the scaling behavior of the isothermal\nquadrupolar susceptibility and, the isothermal and constant crystal-field\nspecific heat as a function of the temperature and the reduced crystal-field\nparameter along the ferromagnetic and the \\emph{ordered paramagnetic} phase\nfrontier. Results achieved for systems with dimensions $d=2$ and $3$ exhibit\nthe main features of the continuous and first-order transitions in the TCP\nneighborhoods. We also probe the phase coexistence in the $\\lambda$-diagram and\nthe latent heat in the vicinity of the tricritical point locus.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:09:04 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13108","submitter":"Eungbeom Kim","authors":"Eungbeom Kim, Yunkee Chae, Jaeheon Sim, Kyogu Lee","title":"Debiased Automatic Speech Recognition for Dysarthric Speech via Sample\n  Reweighting with Sample Affinity Test","comments":"Accepted by Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.AS cs.CL cs.LG cs.SD","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Automatic speech recognition systems based on deep learning are mainly\ntrained under empirical risk minimization (ERM). Since ERM utilizes the\naveraged performance on the data samples regardless of a group such as healthy\nor dysarthric speakers, ASR systems are unaware of the performance disparities\nacross the groups. This results in biased ASR systems whose performance\ndifferences among groups are severe. In this study, we aim to improve the ASR\nsystem in terms of group robustness for dysarthric speakers. To achieve our\ngoal, we present a novel approach, sample reweighting with sample affinity test\n(Re-SAT). Re-SAT systematically measures the debiasing helpfulness of the given\ndata sample and then mitigates the bias by debiasing helpfulness-based sample\nreweighting. Experimental results demonstrate that Re-SAT contributes to\nimproved ASR performance on dysarthric speech without performance degradation\non healthy speech.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:09:27 GMT"},{"version":"v2","created":"Tue, 30 May 2023 13:16:37 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13109","submitter":"Andrew Putman","authors":"Marco Boggi, Andrew Putman, and Nick Salter","title":"Generating the homology of covers of surfaces","comments":"14 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.GT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Putman and Wieland conjectured that if $\\tilde{\\Sigma} \\rightarrow \\Sigma$ is\na finite branched cover between closed oriented surfaces of sufficiently high\ngenus, then the orbits of all nonzero elements of\n$H_1(\\tilde{\\Sigma};\\mathbb{Q})$ under the action of lifts to $\\tilde{\\Sigma}$\nof mapping classes on $\\Sigma$ are infinite. We prove that this holds if\n$H_1(\\tilde{\\Sigma};\\mathbb{Q})$ is generated by the homology classes of lifts\nof simple closed curves on $\\Sigma$. We also prove that the subspace of\n$H_1(\\tilde{\\Sigma};\\mathbb{Q})$ spanned by such lifts is a symplectic\nsubspace. Finally, simple closed curves lie on subsurfaces homeomorphic to\n2-holed spheres, and we prove that $H_1(\\tilde{\\Sigma};\\mathbb{Q})$ is\ngenerated by the homology classes of lifts of loops on $\\Sigma$ lying on\nsubsurfaces homeomorphic to 3-holed spheres.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:11:05 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13110","submitter":"Yue Wu","authors":"Yue Wu and Yulin Pan","title":"Energy cascade in the Garrett-Munk spectrum of internal gravity waves","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.flu-dyn physics.ao-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study the spectral energy transfer due to wave-triad interactions in the\nGarrett-Munk spectrum of internal gravity waves (IGWs) based on a numerical\nevaluation of the collision integral in the wave kinetic equation. Our\nnumerical evaluation builds on the reduction of the collision integral on the\nresonant manifold for an horizontally isotropic spectrum. We directly evaluate\nthe downscale energy flux available for ocean mixing, whose value is in close\nagreement with the empirical finescale parameterization. We further decompose\nthe energy transfer into contributions from different mechanisms, including\nlocal interactions and three types of nonlocal interactions, namely parametric\nsubharmonic instability (PSI), elastic scattering (ES) and induced diffusion\n(ID). Through analysis on the role of each type of interaction, we resolve two\nlong-standing paradoxes regarding the mechanism for forward cascade in\nfrequency and zero ID flux for GM76 spectrum. In addition, our analysis\nestimates the contribution of each mechanism to the energy transfer in each\nspectral direction, and reveals new understanding of the importance of local\ninteractions and ES in the energy transfer.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:11:34 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13111","submitter":"Caroline Terry","authors":"A. Abd-Aldaim, G. Conant, C. Terry","title":"Higher arity stability and the functional order property","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.LO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The $k$-dimensional functional order property ($\\text{FOP}_k$) is a\ncombinatorial property of a $(k+1)$-partitioned formula. This notion arose in\nwork of Terry and Wolf, which identified $\\text{NFOP}_2$ as a ternary analogue\nof stability in the context of two finitary combinatorial problems related to\nhypergraph regularity and arithmetic regularity. In this paper we show\n$\\text{NFOP}_k$ has equally strong implications in model-theoretic\nclassification theory, where its behavior as a $(k+1)$-ary version of stability\nis in close analogy to the behavior of $k$-dependence as a $(k+1)$-ary version\nof $\\text{NIP}$. Our results include several new characterizations of\n$\\text{NFOP}_k$, including a characterization in terms of collapsing\nindiscernibles, combinatorial recharacterizations, and a characterization in\nterms of type-counting when $k=2$. As a corollary of our collapsing theorem, we\nshow $\\text{NFOP}_k$ is closed under Boolean combinations, and that\n$\\text{FOP}_k$ can always be witnessed by a formula where all but one variable\nhave length $1$. When $k=2$, we prove a composition lemma analogous to that of\nChernikov and Hempel from the setting of $2$-dependence. Using this, we provide\na new class of algebraic examples of $\\text{NFOP}_2$ theories. Specifically, we\nshow that if $T$ is the theory of an infinite dimensional vector space over a\nfield $K$, equipped with a bilinear form satisfying certain properties, then\n$T$ is $\\text{NFOP}_2$ if and only if $K$ is stable. Along the way we provide a\ncorrected and reorganized proof of Granger's quantifier elimination and\ncompleteness results for these theories.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:11:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13112","submitter":"Xiaolei Wang","authors":"Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, Ji-Rong Wen","title":"Rethinking the Evaluation for Conversational Recommendation in the Era\n  of Large Language Models","comments":"work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.IR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The recent success of large language models (LLMs) has shown great potential\nto develop more powerful conversational recommender systems (CRSs), which rely\non natural language conversations to satisfy user needs. In this paper, we\nembark on an investigation into the utilization of ChatGPT for conversational\nrecommendation, revealing the inadequacy of the existing evaluation protocol.\nIt might over-emphasize the matching with the ground-truth items or utterances\ngenerated by human annotators, while neglecting the interactive nature of being\na capable CRS. To overcome the limitation, we further propose an interactive\nEvaluation approach based on LLMs named iEvaLM that harnesses LLM-based user\nsimulators. Our evaluation approach can simulate various interaction scenarios\nbetween users and systems. Through the experiments on two publicly available\nCRS datasets, we demonstrate notable improvements compared to the prevailing\nevaluation protocol. Furthermore, we emphasize the evaluation of\nexplainability, and ChatGPT showcases persuasive explanation generation for its\nrecommendations. Our study contributes to a deeper comprehension of the\nuntapped potential of LLMs for CRSs and provides a more flexible and\neasy-to-use evaluation framework for future research endeavors. The codes and\ndata are publicly available at https://github.com/RUCAIBox/iEvaLM-CRS.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:12:43 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13113","submitter":"Francisco Monteiro","authors":"Sahar Allahkaram, Francisco A. Monteiro, Ioannis Chatzigeorgiou","title":"Symbol-Level Noise-Guessing Decoding with Antenna Sorting for URLLC\n  Massive MIMO","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT eess.SP math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Providing ultra-reliable and low-latency transmission is a current issue in\nwireless communications (URLLC). While it is commonly known that channel coding\nwith large codewords improves reliability, this usually necessitates using\ninterleavers, which incur undesired latency. Using short codewords is a\nnecessary adjustment that will eliminate the requirement for interleaving and\nreduce decoding latency. This paper suggests a coding and decoding system that,\ncombined with the high spectral efficiency of spatial multiplexing, can provide\nURLLC over a fading wireless channel. Random linear codes (RLCs) are used over\na block-fading massive multiple input-multiple-output (mMIMO) channel followed\nby zero-forcing (ZF) detection and guessing random additive noise decoding\n(GRAND). A variation of GRAND, called symbol-level GRAND, originally proposed\nfor single-antenna systems, is generalized to spatial multiplexing.\nSymbol-level GRAND is much more computationally effective than bit-level GRAND\nas it takes advantage of the structure of the constellation of the modulation.\nThe paper analyses the performance of symbol-level GRAND depending on the\northogonality defect (OD) of the underlying lattice. Symbol-level GRAND takes\nadvantage of the a priori probability of each error pattern given a received\nsymbol, and specifies the order in which error patterns are tested. The paper\nfurther proposes to make use of further side-information that comes from the\nmMIMO channel-state information (CSI) and its impacts on the reliability of\neach antenna. This induces an antenna sorting order that further reduces the\ndecoding complexity by over 80 percent when comparing with bit-level GRAND.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:12:45 GMT"},{"version":"v2","created":"Mon, 5 Jun 2023 21:50:44 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.13114","submitter":"Reza Hadi Mogavi","authors":"Reza Hadi Mogavi, Chao Deng, Justin Juho Kim, Pengyuan Zhou, Young D.\n  Kwon, Ahmed Hosny Saleh Metwally, Ahmed Tlili, Simone Bassanelli, Antonio\n  Bucchiarone, Sujit Gujar, Lennart E. Nacke, and Pan Hui","title":"Exploring User Perspectives on ChatGPT: Applications, Perceptions, and\n  Implications for AI-Integrated Education","comments":"Preprint version","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Understanding user perspectives on Artificial Intelligence (AI) in education\nis essential for creating pedagogically effective and ethically responsible\nAI-integrated learning environments. In this paper, we conduct an extensive\nqualitative content analysis of four major social media platforms (Twitter,\nReddit, YouTube, and LinkedIn) to explore the user experience (UX) and\nperspectives of early adopters toward ChatGPT-an AI Chatbot technology-in\nvarious education sectors. We investigate the primary applications of ChatGPT\nin education (RQ1) and the various perceptions of the technology (RQ2). Our\nfindings indicate that ChatGPT is most popularly used in the contexts of higher\neducation (24.18%), K-12 education (22.09%), and practical-skills learning\n(15.28%). On social media platforms, the most frequently discussed topics about\nChatGPT are productivity, efficiency, and ethics. While early adopters\ngenerally lean toward seeing ChatGPT as a revolutionary technology with the\npotential to boost students' self-efficacy and motivation to learn, others\nexpress concern that overreliance on the AI system may promote superficial\nlearning habits and erode students' social and critical thinking skills. Our\nstudy contributes to the broader discourse on Human-AI Interaction and offers\nrecommendations based on crowd-sourced knowledge for educators and learners\ninterested in incorporating ChatGPT into their educational settings.\nFurthermore, we propose a research agenda for future studies that sets the\nfoundation for continued investigation into the application of ChatGPT in\neducation.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:13:14 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13115","submitter":"Hongjun Wang","authors":"Hongjun Wang, Jiyuan Chen, Lun Du, Qiang Fu, Shi Han, Xuan Song","title":"Causal-Based Supervision of Attention in Graph Neural Network: A Better\n  and Simpler Choice towards Powerful Attention","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CY","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In recent years, attention mechanisms have demonstrated significant potential\nin the field of graph representation learning. However, while variants of\nattention-based GNNs are setting new benchmarks for numerous real-world\ndatasets, recent works have pointed out that their induced attentions are less\nrobust and generalizable against noisy graphs due to the lack of direct\nsupervision. In this paper, we present a new framework that utilizes the tool\nof causality to provide a powerful supervision signal for the learning process\nof attention functions. Specifically, we estimate the direct causal effect of\nattention on the final prediction and then maximize such effect to guide\nattention to attend to more meaningful neighbors. Our method can serve as a\nplug-and-play module for any canonical attention-based GNNs in an end-to-end\nfashion. Extensive experiments on a wide range of benchmark datasets\nillustrated that, by directly supervising attention with our method, the model\nis able to converge faster with a clearer decision boundary, and thus yields\nbetter performances.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:13:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13116","submitter":"Yassine Hamdi","authors":"Yassine Hamdi and Deniz G\\\"und\\\"uz","title":"The Rate-Distortion-Perception Trade-off with Side Information","comments":"Accepted at the 2023 IEEE International Symposium on Information\n  Theory (ISIT)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IT math.IT","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In image compression, with recent advances in generative modeling, the\nexistence of a trade-off between the rate and the perceptual quality has been\nbrought to light, where the perception is measured by the closeness of the\noutput distribution to the source. This leads to the question: how does a\nperception constraint impact the trade-off between the rate and traditional\ndistortion constraints, typically quantified by a single-letter distortion\nmeasure? We consider the compression of a memoryless source $X$ in the presence\nof memoryless side information $Z,$ studied by Wyner and Ziv, but elucidate the\nimpact of a perfect realism constraint, which requires the output distribution\nto match the source distribution. We consider two cases: when $Z$ is available\nonly at the decoder or at both the encoder and the decoder. The rate-distortion\ntrade-off with perfect realism is characterized for sources on general\nalphabets when infinite common randomness is available between the encoder and\nthe decoder. We show that, similarly to traditional source coding with side\ninformation, the two cases are equivalent when $X$ and $Z$ are jointly Gaussian\nunder the squared error distortion measure. We also provide a general inner\nbound in the case of limited common randomness.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:14:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13117","submitter":"Michael Sejr Schlichtkrull","authors":"Michael Schlichtkrull, Zhijiang Guo, Andreas Vlachos","title":"AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from\n  the Web","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Existing datasets for automated fact-checking have substantial limitations,\nsuch as relying on artificial claims, lacking annotations for evidence and\nintermediate reasoning, or including evidence published after the claim. In\nthis paper we introduce AVeriTeC, a new dataset of 4,568 real-world claims\ncovering fact-checks by 50 different organizations. Each claim is annotated\nwith question-answer pairs supported by evidence available online, as well as\ntextual justifications explaining how the evidence combines to produce a\nverdict. Through a multi-round annotation process, we avoid common pitfalls\nincluding context dependence, evidence insufficiency, and temporal leakage, and\nreach a substantial inter-annotator agreement of $\\kappa=0.619$ on verdicts. We\ndevelop a baseline as well as an evaluation scheme for verifying claims through\nseveral question-answering steps against the open web.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:17:18 GMT"},{"version":"v2","created":"Wed, 24 May 2023 10:44:08 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13118","submitter":"Bor Plestenjak","authors":"Daniel Kressner, Bor Plestenjak","title":"Analysis of a class of randomized numerical methods for singular matrix\n  pencils","comments":"22 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.NA cs.NA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The numerical solution of the generalized eigenvalue problem for a singular\nmatrix pencil is challenging due to the discontinuity of its eigenvalues.\nClassically, such problems are addressed by first extracting the regular part\nthrough the staircase form and then applying a standard solver, such as the QZ\nalgorithm. Recently, several novel approaches have been proposed to transform\nthe singular pencil into a regular pencil by relatively simple randomized\nmodifications. In this work, we analyze three such methods by Hochstenbach,\nMehl, and Plestenjak that modify, project, or augment the pencil using random\nmatrices. All three methods rely on the normal rank and do not alter the finite\neigenvalues of the original pencil. In this work we analyze these methods and\nshow that the eigenvalue condition numbers of the transformed pencils are\nunlikely to be much larger than the $\\delta$-weak eigenvalue condition numbers,\nintroduced by Lotz and Noferini, of the original pencil. This not only\nindicates favorable numerical stability but also shows that these condition\nnumbers are a reliable criterion for detecting finite eigenvalues. We also\nprovide evidence that, from a numerical stability perspective, the use of\ncomplex instead of real random matrices is preferable even for real singular\nmatrix pencils and real eigenvalues.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:17:36 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13119","submitter":"Zhu Liu","authors":"Zhu Liu and Ying Liu","title":"Ambiguity Meets Uncertainty: Investigating Uncertainty Estimation for\n  Word Sense Disambiguation","comments":"Findings: ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Word sense disambiguation (WSD), which aims to determine an appropriate sense\nfor a target word given its context, is crucial for natural language\nunderstanding. Existing supervised methods treat WSD as a classification task\nand have achieved remarkable performance. However, they ignore uncertainty\nestimation (UE) in the real-world setting, where the data is always noisy and\nout of distribution. This paper extensively studies UE on the benchmark\ndesigned for WSD. Specifically, we first compare four uncertainty scores for a\nstate-of-the-art WSD model and verify that the conventional predictive\nprobabilities obtained at the end of the model are inadequate to quantify\nuncertainty. Then, we examine the capability of capturing data and model\nuncertainties by the model with the selected UE score on well-designed test\nscenarios and discover that the model reflects data uncertainty satisfactorily\nbut underestimates model uncertainty. Furthermore, we explore numerous lexical\nproperties that intrinsically affect data uncertainty and provide a detailed\nanalysis of four critical aspects: the syntactic category, morphology, sense\ngranularity, and semantic relations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:18:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13120","submitter":"Liangping Ding","authors":"Liangping Ding, Giovanni Colavizza, Zhixiong Zhang","title":"Partial Annotation Learning for Biomedical Entity Recognition","comments":"9 pages, 4 figures, 2 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Motivation: Named Entity Recognition (NER) is a key task to support\nbiomedical research. In Biomedical Named Entity Recognition (BioNER), obtaining\nhigh-quality expert annotated data is laborious and expensive, leading to the\ndevelopment of automatic approaches such as distant supervision. However,\nmanually and automatically generated data often suffer from the unlabeled\nentity problem, whereby many entity annotations are missing, degrading the\nperformance of full annotation NER models. Results: To address this problem, we\nsystematically study the effectiveness of partial annotation learning methods\nfor biomedical entity recognition over different simulated scenarios of missing\nentity annotations. Furthermore, we propose a TS-PubMedBERT-Partial-CRF partial\nannotation learning model. We harmonize 15 biomedical NER corpora encompassing\nfive entity types to serve as a gold standard and compare against two commonly\nused partial annotation learning models, BiLSTM-Partial-CRF and EER-PubMedBERT,\nand the state-of-the-art full annotation learning BioNER model PubMedBERT\ntagger. Results show that partial annotation learning-based methods can\neffectively learn from biomedical corpora with missing entity annotations. Our\nproposed model outperforms alternatives and, specifically, the PubMedBERT\ntagger by 38% in F1-score under high missing entity rates. The recall of entity\nmentions in our model is also competitive with the upper bound on the fully\nannotated dataset.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:18:38 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13121","submitter":"Mubarak Ibrahim PhD","authors":"M. R. Ibrahim","title":"The Missing Link: Exploring the Relationship Between Transformational\n  Leadership and Change in team members in Construction","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"econ.GN q-fin.EC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This study aimed to investigate how transformational leadership affects team\nprocesses, mediated by change in team members. A self-administered\nquestionnaire was distributed to construction project team members in Abuja and\nKaduna, and statistical analysis revealed a significant positive relationship\nbetween transformational leadership and team processes, transformational\nleadership and change in team members, changes in team members and team\nprocesses, and changes in team members mediating the relationship between\ntransformational leadership and team processes. Future studies should consider\ncultural differences.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:22:08 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13122","submitter":"Long Yang","authors":"Long Yang, Zhixiong Huang, Fenghao Lei, Yucun Zhong, Yiming Yang, Cong\n  Fang, Shiting Wen, Binbin Zhou, Zhouchen Lin","title":"Policy Representation via Diffusion Probability Model for Reinforcement\n  Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Popular reinforcement learning (RL) algorithms tend to produce a unimodal\npolicy distribution, which weakens the expressiveness of complicated policy and\ndecays the ability of exploration. The diffusion probability model is powerful\nto learn complicated multimodal distributions, which has shown promising and\npotential applications to RL. In this paper, we formally build a theoretical\nfoundation of policy representation via the diffusion probability model and\nprovide practical implementations of diffusion policy for online model-free RL.\nConcretely, we character diffusion policy as a stochastic process, which is a\nnew approach to representing a policy. Then we present a convergence guarantee\nfor diffusion policy, which provides a theory to understand the multimodality\nof diffusion policy. Furthermore, we propose the DIPO which is an\nimplementation for model-free online RL with DIffusion POlicy. To the best of\nour knowledge, DIPO is the first algorithm to solve model-free online RL\nproblems with the diffusion model. Finally, extensive empirical results show\nthe effectiveness and superiority of DIPO on the standard continuous control\nMujoco benchmark.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:23:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13123","submitter":"Matthieu Garcin","authors":"Matthieu Garcin","title":"Complexity measure, kernel density estimation, bandwidth selection, and\n  the efficient market hypothesis","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.ST stat.ME","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  We are interested in the nonparametric estimation of the probability density\nof price returns, using the kernel approach. The output of the method heavily\nrelies on the selection of a bandwidth parameter. Many selection methods have\nbeen proposed in the statistical literature. We put forward an alternative\nselection method based on a criterion coming from information theory and from\nthe physics of complex systems: the bandwidth to be selected maximizes a new\nmeasure of complexity, with the aim of avoiding both overfitting and\nunderfitting. We review existing methods of bandwidth selection and show that\nthey lead to contradictory conclusions regarding the complexity of the\nprobability distribution of price returns. This has also some striking\nconsequences in the evaluation of the relevance of the efficient market\nhypothesis. We apply these methods to real financial data, focusing on the\nBitcoin.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:24:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13124","submitter":"Alexander Hoelzemann","authors":"Alexander Hoelzemann, Julia Lee Romero, Marius Bock, Kristof Van\n  Laerhoven, Qin Lv","title":"Hang-Time HAR: A Benchmark Dataset for Basketball Activity Recognition\n  using Wrist-worn Inertial Sensors","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a benchmark dataset for evaluating physical human activity\nrecognition methods from wrist-worn sensors, for the specific setting of\nbasketball training, drills, and games. Basketball activities lend themselves\nwell for measurement by wrist-worn inertial sensors, and systems that are able\nto detect such sport-relevant activities could be used in applications toward\ngame analysis, guided training, and personal physical activity tracking. The\ndataset was recorded for two teams from separate countries (USA and Germany)\nwith a total of 24 players who wore an inertial sensor on their wrist, during\nboth repetitive basketball training sessions and full games. Particular\nfeatures of this dataset include an inherent variance through cultural\ndifferences in game rules and styles as the data was recorded in two countries,\nas well as different sport skill levels, since the participants were\nheterogeneous in terms of prior basketball experience. We illustrate the\ndataset's features in several time-series analyses and report on a baseline\nclassification performance study with two state-of-the-art deep learning\narchitectures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:25:29 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13125","submitter":"Micheline Fakhoury","authors":"Micheline Fakhoury","title":"Isometries of $p$-convexified combinatorial Banach spaces","comments":"33 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We show that if $1<p\\neq 2<\\infty$, then any isometry of the\n$p$-convexification of the combinatorial Banach space associated with a\nhereditary family of finite subsets of $\\mathbb{N}$ containing the singletons\nis given by a signed permutation of the canonical basis. In the case of a\ngeneralized Schreier family, the result also holds for $p=2$, and every\nisometry is diagonal. These results are deduced from more general theorems\nconcerning combinatorial-like Banach spaces.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:25:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13126","submitter":"Anju Rani","authors":"Anju Rani, Pooja Chandravanshi, Jayanth Ramakrishnan, Pravin Vaity, P.\n  Madhusudhan, Tanya Sharma, Pranav Bhardwaj, Ayan Biswas, R. P. Singh","title":"Free Space Continuous Variable Quantum Key Distribution with Discrete\n  Phases","comments":"9 pages, 7 figures. Comments are welcome","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph physics.optics","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Quantum Key Distribution (QKD) offers unconditional security in principle.\nMany QKD protocols have been proposed and demonstrated to ensure secure\ncommunication between two authenticated users. Continuous variable (CV) QKD\noffers many advantages over discrete variable (DV) QKD since it is\ncost-effective, compatible with current classical communication technologies,\nefficient even in daylight, and gives a higher secure key rate. Keeping this in\nview, we demonstrate a discrete modulated CVQKD protocol in the free space\nwhich is robust against polarization drift. We also present the simulation\nresults with a noise model to account for the channel noise and the effects of\nvarious parameter changes on the secure key rate. These simulation results help\nus to verify the experimental values obtained for the implemented CVQKD.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:25:54 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13128","submitter":"Bahjat Kawar","authors":"Bahjat Kawar, Noam Elata, Tomer Michaeli, Michael Elad","title":"GSURE-Based Diffusion Model Training with Corrupted Data","comments":"Code: https://github.com/bahjat-kawar/gsure-diffusion","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.IV cs.CV cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Diffusion models have demonstrated impressive results in both data generation\nand downstream tasks such as inverse problems, text-based editing,\nclassification, and more. However, training such models usually requires large\namounts of clean signals which are often difficult or impossible to obtain. In\nthis work, we propose a novel training technique for generative diffusion\nmodels based only on corrupted data. We introduce a loss function based on the\nGeneralized Stein's Unbiased Risk Estimator (GSURE), and prove that under some\nconditions, it is equivalent to the training objective used in fully supervised\ndiffusion models. We demonstrate our technique on face images as well as\nMagnetic Resonance Imaging (MRI), where the use of undersampled data\nsignificantly alleviates data collection costs. Our approach achieves\ngenerative performance comparable to its fully supervised counterpart without\ntraining on any clean signals. In addition, we deploy the resulting diffusion\nmodel in various downstream tasks beyond the degradation present in the\ntraining set, showcasing promising results.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:27:20 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13129","submitter":"Dennis Eriksson E.W.","authors":"Dennis Eriksson and Gerard Freixas i Montplet","title":"Deligne-Riemann-Roch and intersection bundles","comments":"99 pages, minor update correcting typos and grammar","journal-ref":null,"doi":null,"report-no":null,"categories":"math.AG math.CT math.KT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This article is part of a series of works by the authors with the goal of\ncompleting a far-reaching program propounded by Deligne, aiming to extend the\ncodimension one part of the Grothendieck-Riemann-Roch theorem from isomorphism\nclasses of line bundles to isomorphisms thereof. The paper develops a relative\nfunctorial intersection theory with values in line bundles, together with a\nformalism that generalizes previous constructions by Deligne and Elkik, related\nto the right-hand side of the theorem.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:28:07 GMT"},{"version":"v2","created":"Thu, 8 Jun 2023 09:54:34 GMT"}],"update_date":"2023-06-09"}
{"id":"2305.13130","submitter":"Mounir Bensalem","authors":"Mounir Bensalem, Erkan Ipek and Admela Jukan","title":"Scaling Serverless Functions in Edge Networks: A Reinforcement Learning\n  Approach","comments":"This paper is uploaded here for research community, thus it is for\n  non-commercial purposes","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  With rapid advances in containerization techniques, the serverless computing\nmodel is becoming a valid candidate execution model in edge networking, similar\nto the widely used cloud model for applications that are stateless, single\npurpose and event-driven, and in particular for delay-sensitive applications.\nOne of the cloud serverless processes, i.e., the auto-scaling mechanism, cannot\nbe however directly applied at the edge, due to the distributed nature of edge\nnodes, the difficulty of optimal resource allocation, and the delay sensitivity\nof workloads. We propose a solution to the auto-scaling problem by applying\nreinforcement learning (RL) approach to solving problem of efficient scaling\nand resource allocation of serverless functions in edge networks. We compare RL\nand Deep RL algorithms with empirical, monitoring-based heuristics, considering\ndelay-sensitive applications. The simulation results shows that RL algorithm\noutperforms the standard, monitoring-based algorithms in terms of total delay\nof function requests, while achieving an improvement in delay performance by up\nto 50%.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:29:32 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13131","submitter":"Eric Lescano","authors":"Toni Kodzoman and Eric Lescano","title":"Non-commutative double geometry","comments":"30 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-th math-ph math.MP","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We study non-commutative theories with the Moyal-Weyl product. We start by\ndeforming the infinitesimal diffeomorphisms using an extra commutative and\nassociative product, and the Leibniz rule, in a consistent way with the star\nproduct. The transformations close with a deformed Lie bracket. Analogously we\nstudy the notion of non-commutativity in the context of Double Field Theory,\nwhich is a T-duality invariant description of the low energy limit of string\ntheory. We introduce the star product in the double geometry, define deformed\ninfinitesimal transformations and, finally, we construct the generalized\naction. The prescription requires a generalized star metric which can be\nthought of as the fundamental (generalized) metric in the non-commutative case.\nWe study both Riemannian and non-Riemannian parametrizations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:30:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13132","submitter":"David Kanaar","authors":"David W. Kanaar and J. P. Kestner","title":"Neural-network-designed three-qubit gates robust against charge noise\n  and crosstalk in silicon","comments":"7 pages, 7 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Spin qubits in semiconductor quantum dots are a promising platform for\nquantum computing, however scaling to large systems is hampered by crosstalk\nand charge noise. Crosstalk here refers to the unwanted off-resonant rotation\nof idle qubits during the resonant rotation of the target qubit. For a\nthree-qubit system with crosstalk and charge noise, it is difficult to\nanalytically create gate protocols that produce three-qubit gates, such as the\nToffoli gate, directly in a single shot instead of through the composition of\ntwo-qubit gates. Therefore, we numerically optimize a physics-informed neural\nnetwork to produce theoretically robust shaped pulses that generate a\nToffoli-equivalent gate. Additionally, robust $\\frac{\\pi}{2}$ $X$ and CZ gates\nare also presented in this work to create a universal set of gates robust\nagainst charge noise. The robust pulses maintain an infidelity of $10^{-3}$ for\naverage quasistatic fluctuations in the voltage of up to a few mV instead of\ntenths of mV for non-robust pulses.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:30:11 GMT"},{"version":"v2","created":"Wed, 24 May 2023 15:28:25 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13133","submitter":"Xi Cen","authors":"Xi Cen, Xiang Li, Dunyan Yan","title":"Characterizations for the boundedness of multi-sublinear operators and\n  their commutators on three kinds of generalized weighted Morrey spaces and\n  applications","comments":"31 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"math.FA math.CA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The main questions raised in this paper are to find the sufficient conditions\nthat make multi-sublinear operators $T$ and their commutators ${T_{\\prod \\vec b\n}}$, ${T_{\\sum {\\vec b} }}$ to be bounded on three kinds of generalized\nweighted Morrey spaces. In subsection 1.2, we give the main theorems of this\npaper to solve the above related questions. As corollaries of the main\ntheorems, we give sufficient and necessary conditions for a class of\nmulti-sublinear operators which are bounded on three kinds of generalized\nweighted Morrey spaces. In subsection 1.3, we give the boundedness of\n$m$-linear Littlewood-Paley square operators and their commutators, commutators\nof bilinear pseudo-differential operators with mild regularity and commutators\nof Paraproducts with mild regularity as applications of the main theorems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:30:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13134","submitter":"Kananart Kuwaranancharoen","authors":"Kananart Kuwaranancharoen, Shreyas Sundaram","title":"The Minimizer of the Sum of Two Strongly Convex Functions","comments":"29 pages, 5 figures, submitting to Optimization (Taylor & Francis)","journal-ref":null,"doi":null,"report-no":null,"categories":"math.OC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The problem of finding the minimizer of a sum of convex functions is central\nto the field of optimization. In cases where the functions themselves are not\nfully known (other than their individual minimizers and convexity parameters),\nit is of interest to understand the region containing the potential minimizers\nof the sum based only on those known quantities. Characterizing this region in\nthe case of multivariate strongly convex functions is far more complicated than\nthe univariate case. In this paper, we provide both outer and inner\napproximations for the region containing the minimizer of the sum of two\nstrongly convex functions, subject to a constraint on the norm of the gradient\nat the minimizer of the sum. In particular, we explicitly characterize the\nboundary and interior of both outer and inner approximations. Interestingly,\nthe boundaries as well as the interiors turn out to be identical and we show\nthat the boundary of the region containing the potential minimizers is also\nidentical to that of the outer and inner approximations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:31:48 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13135","submitter":"Xiuzhan Guo","authors":"Xiuzhan Guo, Wei Huang, Min Luo, Priya Rangarajan","title":"Transforming Geospatial Ontologies by Homomorphisms","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.AI cs.DM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  In this paper, we study the (geospatial) ontologies we are interested in\ntogether as an ontology (a geospatial ontology) system, consisting of a set of\nthe (geospatial) ontologies and a set of ontology operations. A homomorphism\nbetween two ontology systems is a function between two sets of ontologies,\nwhich preserves these ontology operations. We view clustering a set of the\nontologies we are interested in as partitioning the set or defining an\nequivalence relation on the set or forming a quotient set of the set or\nobtaining the surjective image of the set. Each ontology system homomorphism\ncan be factored as a surjective clustering to a quotient space, followed by an\nembedding. Ontology (merging) systems, natural partial orders on the systems,\nand ontology merging closures in the systems are then transformed under\nontology system homomorphisms, given by quotients and embeddings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:32:15 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13136","submitter":"Jos\\'e Eduardo M\\'endez-Delgado","authors":"J. E. M\\'endez-Delgado, C. Esteban, J. Garc\\'ia-Rojas, K. Z.\n  Arellano-C\\'ordova, K. Kreckel, V. G\\'omez-Llanos, O. V. Egorov, M. Peimbert\n  and M. Orte-Garc\\'ia","title":"Density biases and temperature relations for DESIRED HII regions","comments":"Accepted for publication in MNRAS","journal-ref":null,"doi":"10.1093/mnras/stad1569","report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present a first study based on the analysis of the DEep Spectra of Ionized\nREgions Database (DESIRED). This is a compilation of 190 high signal-to-noise\nratio optical spectra of HII regions and other photoionized nebulae, mostly\nobserved with 8-10m telescopes and containing $\\sim$29380 emission lines. We\nfind that the electron density --$n_{\\rm e}$-- of the objects is underestimated\nwhen [SII] $\\lambda6731/\\lambda6716$ and/or [OII] $\\lambda3726/\\lambda3729$ are\nthe only density indicators available. This is produced by the non-linear\ndensity dependence of the indicators in the presence of density\ninhomogeneities. The average underestimate is $\\sim 300$ cm$^{-3}$ in\nextragalactic HII regions, introducing systematic overestimates of $T_{\\rm\ne}$([OII]) and $T_{\\rm e}$([SII]) compared to $T_{\\rm e}$([NII]). The\nhigh-sensitivity of [OII] $\\lambda\\lambda7319+20+30+31/\\lambda\\lambda3726+29$\nand [SII] $\\lambda\\lambda4069+76/\\lambda\\lambda6716+31$ to density makes them\nmore suitable for the diagnosis of the presence of high-density clumps. If\n$T_{\\rm e}$([NII]) is adopted, the density underestimate has a small impact in\nthe ionic abundances derived from optical spectra, being limited to up to\n$\\sim$0.1 dex when auroral [SII] and/or [OII] lines are used. However, these\ndensity effects are critical for the analysis of infrared fine structure lines,\nsuch as those observed by the JWST in local star forming regions, implying\nstrong underestimates of the ionic abundances. We present temperature relations\nbetween $T_{\\rm e}$([OIII]), $T_{\\rm e}$([ArIII]), $T_{\\rm e}$([SIII]) and\n$T_{\\rm e}$([NII]) for the extragalactic HII regions. We confirm a non-linear\ndependence between $T_{\\rm e}$([OIII])-$T_{\\rm e}$([NII]) due to a more rapid\nincrease of $T_{\\rm e}$([OIII]) at lower metallicities.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:32:29 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.13137","submitter":"Kari Ali Noriy","authors":"Kari Ali Noriy, Xiaosong Yang, Jian Jun Zhang","title":"EMNS /Imz/ Corpus: An emotive single-speaker dataset for narrative\n  storytelling in games, television and graphic novels","comments":"Dataset download link: https://openslr.elda.org/136/","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG cs.MM","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The increasing adoption of text-to-speech technologies has led to a growing\ndemand for natural and emotive voices that adapt to a conversation's context\nand emotional tone. The Emotive Narrative Storytelling (EMNS) corpus is a\nunique speech dataset created to enhance conversations' expressiveness and\nemotive quality in interactive narrative-driven systems. The corpus consists of\na 2.3-hour recording featuring a female speaker delivering labelled utterances.\nIt encompasses eight acted emotional states, evenly distributed with a variance\nof 0.68%, along with expressiveness levels and natural language descriptions\nwith word emphasis labels. The evaluation of audio samples from different\ndatasets revealed that the EMNS corpus achieved the highest average scores in\naccurately conveying emotions and demonstrating expressiveness. It outperformed\nother datasets in conveying shared emotions and achieved comparable levels of\ngenuineness. A classification task confirmed the accurate representation of\nintended emotions in the corpus, with participants recognising the recordings\nas genuine and expressive. Additionally, the availability of the dataset\ncollection tool under the Apache 2.0 License simplifies remote speech data\ncollection for researchers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:32:32 GMT"},{"version":"v2","created":"Thu, 25 May 2023 16:17:24 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13138","submitter":"Yongzan Liu","authors":"Yongzan Liu, Lin Liang, Smaine Zeroug","title":"Enhancing Understanding of Hydraulic Fracture Tip Advancement through\n  Inversion of Low-Frequency Distributed Acoustic Sensing Data","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.geo-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Characterizing the fluid-driven fracture tip advancing process presents a\nsignificant challenge due to the difficulty of replicating real-world\nconditions in laboratory experiments and the lack of precise field\nmeasurements. However, recent advances in low-frequency distributed acoustic\nsensing (LF-DAS) technology offer new opportunities to investigate the dynamics\nof propagating hydraulic fractures. In this study, we propose an iterative\ninversion method to characterize fracture-tip advancing behaviors using LF-DAS\ndata. A forward geomechanical model is developed using the three-dimensional\ndisplacement discontinuity method, and the optimization is realized by a\nconjugate gradient method. The performance of the inversion algorithm is\ndemonstrated using a synthetic case, in which the fracture half-length\nevolution and propagation velocity match well with the reference solutions.\nAdditionally, the averaged fracture cross-section area, fracture volume, and\nfracturing fluid efficiency can also be estimated, showing good agreements with\ntrue values of the synthetic case under reasonable assumptions. Then a field\ncase with a single-cluster hydraulic fracturing treatment from the Hydraulic\nFracturing Test Site 2 project (HFTS2) is studied. Our analysis of the\ninversion results reveal that the fracture propagates intermittently, as\nevidenced by the fracture half-length evolution. This unique field evidence can\nguide modeling efforts to incorporate this important physical behavior into\nfracture models, and the secondary information gathered from the study,\nincluding fracture cross-section area and volume, can help evaluate and\noptimize fracturing efficiency.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:32:40 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13139","submitter":"Gui-Geng Liu","authors":"Gui-Geng Liu, Subhaskar Mandal, Peiheng Zhou, Xiang Xi, Rimi Banerjee,\n  Yuan-Hang Hu, Minggui Wei, Maoren Wang, Qiang Wang, Zhen Gao, Hongsheng Chen,\n  Yihao Yang, Yidong Chong, Baile Zhang","title":"Localization of chiral edge states by the non-Hermitian skin effect","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Quantum Hall systems host chiral edge states extending along the\none-dimensional boundary of any two-dimensional sample. In solid state\nmaterials, the edge states serve as perfectly robust transport channels that\nproduce a quantised Hall conductance; due to their chirality, and the\ntopological protection by the Chern number of the bulk bandstructure, they\ncannot be spatially localized by defects or disorder. Here, we show\nexperimentally that the chiral edge states of a lossy quantum Hall system can\nbe localized. In a gyromagnetic photonic crystal exhibiting the quantum Hall\ntopological phase, an appropriately structured loss configuration imparts the\nedge states' complex energy spectrum with a feature known as point-gap winding.\nThis intrinsically non-Hermitian topological invariant is distinct from the\nChern number invariant of the bulk (which remains intact) and induces mode\nlocalization via the \"non-Hermitian skin effect\". The interplay of the two\ntopological phenomena - the Chern number and point-gap winding - gives rise to\na non-Hermitian generalisation of the paradigmatic Chern-type bulk-boundary\ncorrespondence principle. Compared to previous realisations of the\nnon-Hermitian skin effect, the skin modes in this system have superior\nrobustness against local defects and disorders.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:32:52 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13140","submitter":"Bohong Wu","authors":"Bohong Wu, Fei Yuan, Hai Zhao, Lei Li, Jingjing Xu","title":"Extrapolating Multilingual Understanding Models as Multilingual\n  Generators","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Multilingual understanding models (or encoder-based), pre-trained via masked\nlanguage modeling, have achieved promising results on many language\nunderstanding tasks (e.g., mBERT). However, these non-autoregressive (NAR)\nmodels still struggle to generate high-quality texts compared with\nautoregressive (AR) models. Considering that encoder-based models have the\nadvantage of efficient generation and self-correction abilities, this paper\nexplores methods to empower multilingual understanding models the generation\nabilities to get a unified model. Specifically, we start from a multilingual\nencoder (XLM-R) and propose a \\textbf{S}emantic-\\textbf{G}uided\n\\textbf{A}lignment-then-Denoising (SGA) approach to adapt an encoder to a\nmultilingual generator with a small number of new parameters. Experiments show\nthat the proposed approach is an effective adaption method, outperforming\nwidely-used initialization-based methods with gains of 9.4 BLEU on machine\ntranslation, 8.1 Rouge-L on question generation, and 5.5 METEOR on story\ngeneration on XLM-R$_{large}$. On the other hand, we observe that XLM-R is\nstill inferior to mBART in supervised settings despite better results on\nzero-shot settings, indicating that more exploration is required to make\nunderstanding models strong generators.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:33:21 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13141","submitter":"Enric Boix-Adser\\`a","authors":"Enric Boix-Adsera, Etai Littwin","title":"The NTK approximation is valid for longer than you think","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We study when the neural tangent kernel (NTK) approximation is valid for\ntraining a model with the square loss. In the lazy training setting of Chizat\net al. 2019, we show that rescaling the model by a factor of $\\alpha = O(T)$\nsuffices for the NTK approximation to be valid until training time $T$. Our\nbound is tight and improves on the previous bound of Chizat et al. 2019, which\nrequired a larger rescaling factor of $\\alpha = O(T^2)$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:34:10 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13142","submitter":"Lu Xu","authors":"Lu Xu, Lidong Bing, Wei Lu","title":"Better Sampling of Negatives for Distantly Supervised Named Entity\n  Recognition","comments":"Accepted by ACL Findings 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Distantly supervised named entity recognition (DS-NER) has been proposed to\nexploit the automatically labeled training data instead of human annotations.\nThe distantly annotated datasets are often noisy and contain a considerable\nnumber of false negatives. The recent approach uses a weighted sampling\napproach to select a subset of negative samples for training. However, it\nrequires a good classifier to assign weights to the negative samples. In this\npaper, we propose a simple and straightforward approach for selecting the top\nnegative samples that have high similarities with all the positive samples for\ntraining. Our method achieves consistent performance improvements on four\ndistantly supervised NER datasets. Our analysis also shows that it is critical\nto differentiate the true negatives from the false negatives.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:35:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13143","submitter":"Manali Jeste","authors":"Manali Jeste, Helmut Wiesemeyer, Karl M. Menten, Friedrich Wyrowski","title":"[C I] and [C II] emission in the circumstellar envelope of IRC +10216 I.\n  Observational data and NLTE modeling of the [C I] emission","comments":"10 pages, 7 figures, accepted for publication in A&A","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR astro-ph.GA","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Aims: The study at hand aims to describe the distribution of atomic carbon,\nC0, throughout the envelope, in support of an improved understanding of its\nphoto-chemistry. Additionally, we also briefly discuss the observation of [CII]\nemission towards the star. Methods: We obtain spectra of the [CI]\n$\\mathrm{^3P_1} \\rightarrow \\mathrm{^3P_0}$ fine structure line at projected\ndistances of up to 78\" from the star. The line profiles are characterized by\nboth direct fitting of Gaussian components, and by modeling the observed line\nof the [CI] triplet. We also report the detection of the $\\mathrm{^2P_{3/2}}\n\\rightarrow \\mathrm{^2P_{1/2}}$ line from the C+ fine structure singlet at the\ncentral position and at 32\" from the star. Results: The overall picture of the\n[CI] emission from IRC +10216 agrees with more limited previous studies. The\nsatisfying agreement between the observed and modeled line profiles, with\nemission at the systemic velocity appearing beyond one beam from the star,\nrules out that the C0 is located in a thin shell. Given that the bond energy of\nCO falls only 0.1 eV below the ionization threshold of C0, the absence of\nobservable [CII] emission from sightlines beyond a projected distance of $\\sim\n10^{17}$ cm from the star (adopting a distance of 130 pc) does not contradict a\nscenario where the bulk of C0 is located between that of CO and C+, as expected\nfor an external FUV radiation field. This conjecture is also corroborated by a\nmodel in which the C0 shell is located farther outside, failing to reproduce\nthe [CI] line profiles at intermediate sky-plane distances from the star.\nComparing a photo-chemical model adopted from literature with the simplifying\nassumption of a constant C0 abundance with respect to the $\\mathrm{H}_2$\ndensity, we constrain the inner boundary of the [CI] emitting shell, located at\n$\\sim 10^{16}$ cm from the star.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:35:55 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13144","submitter":"Zangwei Zheng","authors":"Zangwei Zheng, Xiaozhe Ren, Fuzhao Xue, Yang Luo, Xin Jiang, Yang You","title":"Response Length Perception and Sequence Scheduling: An LLM-Empowered LLM\n  Inference Pipeline","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large language models (LLMs) have revolutionized the field of AI,\ndemonstrating unprecedented capacity across various tasks. However, the\ninference process for LLMs comes with significant computational costs. In this\npaper, we propose an efficient LLM inference pipeline that harnesses the power\nof LLMs. Our approach begins by tapping into the potential of LLMs to\naccurately perceive and predict the response length with minimal overhead. By\nleveraging this information, we introduce an efficient sequence scheduling\ntechnique that groups queries with similar response lengths into micro-batches.\nWe evaluate our approach on real-world instruction datasets using the\nLLaMA-based model, and our results demonstrate an impressive 86% improvement in\ninference throughput without compromising effectiveness. Notably, our method is\northogonal to other inference acceleration techniques, making it a valuable\naddition to many existing toolkits (e.g., FlashAttention, Quantization) for LLM\ninference.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:36:06 GMT"},{"version":"v2","created":"Sun, 28 May 2023 08:22:19 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.13145","submitter":"Shaonwita Pal","authors":"Shaonwita Pal, Prantika Bhowmik, Sushant S. Mahajan, Dibyendu Nandy","title":"Impact of Anomalous Active Regions on the Large-scale Magnetic Field of\n  the Sun","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.SR","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  One of the major sources of perturbation in the solar cycle amplitude is\nbelieved to be the emergence of anomalous active regions which do not obey\nHale's polarity law and Joy's law of tilt angles. Anomalous regions containing\nhigh magnetic flux that disproportionately impact the polar field are sometimes\nreferred to as \"rogue regions\". In this study -- utilizing a surface flux\ntransport model -- we analyze the large-scale dipole moment build-up due to the\nemergence of anomalous active regions on the solar surface. Although these\nactive regions comprise a small fraction of the total sunspot number, they can\nsubstantially influence the magnetic dipole moment build-up and subsequent\nsolar cycle amplitude. Our numerical simulations demonstrate that the impact of\n\"Anti-Joy\" regions on the solar cycle is similar to those of \"Anti-Hale\"\nregions. We also find that the emergence time, emergence latitude, relative\nnumber and flux distribution of anomalous regions influence the large-scale\nmagnetic field dynamics in diverse ways. We establish that the results of our\nnumerical study are consistent with the algebraic (analytic) approach to\nexplaining the Sun's dipole moment evolution. Our results are relevant for\nunderstanding how anomalous active regions modulate the Sun's large-scale\ndipole moment build-up and its reversal timing within the framework of the\nBabcock-Leighton dynamo mechanism -- now believed to be the primary source of\nsolar cycle variations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:36:59 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13146","submitter":"Fangjun Xu","authors":"Minhao Hong, Heguang Liu and Fangjun Xu","title":"Limit theorems for additive functionals of some self-similar Gaussian\n  processes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.PR","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Under certain mild conditions, limit theorems for additive functionals of\nsome $d$-dimensional self-similar Gaussian processes are obtained. These limit\ntheorems work for general Gaussian processes including fractional Brownian\nmotions, sub-fractional Brownian motions and bi-fractional Brownian motions. To\nprove these results, we use the method of moments and an enhanced chaining\nargument. The Gaussian processes under consideration are required to satisfy\ncertain strong local nondeterminism property. A tractable sufficient condition\nfor the strong local nondeterminism property is given and it only relays on the\ncovariance functions of the Gaussian processes. Moreover, we give a sufficient\ncondition for the distribution function of a random vector to be determined by\nits moments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:37:19 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13147","submitter":"Xiangcheng Hu","authors":"Xiangcheng Hu, Jin Wu, Jianhao Jiao, Ruoyu Geng and Ming Liu","title":"PALoc: Robust Prior-assisted Trajectory Generation for Benchmarking","comments":"4 pages, 6 figures","journal-ref":"ICRA Workshop 2023","doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Evaluating simultaneous localization and mapping (SLAM) algorithms\nnecessitates high-precision and dense ground truth (GT) trajectories. But\nobtaining desirable GT trajectories is sometimes challenging without GT\ntracking sensors. As an alternative, in this paper, we propose a novel\nprior-assisted SLAM system to generate a full six-degree-of-freedom ($6$-DOF)\ntrajectory at around $10$Hz for benchmarking under the framework of the factor\ngraph. Our degeneracy-aware map factor utilizes a prior point cloud map and\nLiDAR frame for point-to-plane optimization, simultaneously detecting\ndegeneration cases to reduce drift and enhancing the consistency of pose\nestimation. Our system is seamlessly integrated with cutting-edge odometry via\na loosely coupled scheme to generate high-rate and precise trajectories.\nMoreover, we propose a norm-constrained gravity factor for stationary cases,\noptimizing pose and gravity to boost performance. Extensive evaluations\ndemonstrate our algorithm's superiority over existing SLAM or map-based methods\nin diverse scenarios in terms of precision, smoothness, and robustness. Our\napproach substantially advances reliable and accurate SLAM evaluation methods,\nfostering progress in robotics research.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:37:56 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13148","submitter":"Simone Verzellesi","authors":"Simone Verzellesi","title":"Ruled Hypersurfaces in Higher Dimensional Heisenberg Groups","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.DG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper we introduce a notion of ruled hypersurface in the Heisenberg\ngroup $\\mathbb H^n$, which generalizes the corresponding one in $\\mathbb H^1$.\nWe show two rigidity results in the classes of non-characteristic\n$C^1$-hypersurfaces and conical $C^2$-hypersurfaces, highlighting the main\ndifferences between $\\mathbb H^1$ and higher dimensional Heisenberg groups.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:38:24 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13149","submitter":"Matteo Buzzegoli","authors":"Matteo Buzzegoli and Kirill Tuchin","title":"The chiral magnetic effect in a cylindrical domain","comments":"13 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"hep-ph cond-mat.mes-hall hep-th nucl-th","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We compute the Chiral Magnetic Effect (CME) in a cylindrical region coaxial\nwith the external magnetic field. As the boundary condition we require\nvanishing of the radial component of the electric current on the cylinder side\nwall. We find that when the magnetic length is comparable or larger than the\ncylinder radius, the CME is suppressed compared to the corresponding result in\ninfinite medium. As a result, for a given cylinder radius, the suppression is\nstronger in weak fields. We argue that the electric current generated by the\nCME vanishes at the cylinder wall and monotonically increases towards the\nsymmetry axis.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:39:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13150","submitter":"N.W. Hendrickx","authors":"N.W. Hendrickx, L. Massai, M. Mergenthaler, F. Schupp, S. Paredes,\n  S.W. Bedell, G. Salis, and A. Fuhrer","title":"Sweet-spot operation of a germanium hole spin qubit with highly\n  anisotropic noise sensitivity","comments":"Main text: 12 pages, 6 figures, 50+9 references. Supplementary\n  information is included at the end: 9 pages, 11 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Spin qubits defined by valence band hole states comprise an attractive\ncandidate for quantum information processing due to their inherent coupling to\nelectric fields enabling fast and scalable qubit control. In particular, heavy\nholes in germanium have shown great promise, with recent demonstrations of fast\nand high-fidelity qubit operations. However, the mechanisms and anisotropies\nthat underlie qubit driving and decoherence are still mostly unclear. Here, we\nreport on the highly anisotropic heavy-hole $g$-tensor and its dependence on\nelectric fields, allowing us to relate both qubit driving and decoherence to an\nelectric modulation of the $g$-tensor. We also confirm the predicted Ising-type\nhyperfine interaction but show that qubit coherence is ultimately limited by\n$1/f$ charge noise. Finally, we operate the qubit at low magnetic field and\nmeasure a dephasing time of $T_2^*=9.2$ ${\\mu}$s, while maintaining a\nsingle-qubit gate fidelity of 99.94 %, that remains well above 99 % at an\noperation temperature T>1 K. This understanding of qubit driving and\ndecoherence mechanisms are key for the design and operation of scalable and\nhighly coherent hole qubit arrays.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:39:40 GMT"},{"version":"v2","created":"Wed, 24 May 2023 15:24:57 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13151","submitter":"Yao He","authors":"Y.H. Chen, Thomas Y. He, F. Tang and J.J. Wei","title":"Some Separable integer partition classes","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.CO","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recently, Andrews introduced separable integer partition classes and analyzed\nsome well-known theorems. In this paper, we investigate partitions with parts\nseparated by parity introduced by Andrews with the aid of separation integer\npartition classes with modulus $2$. We also extend separable integer partition\nclasses with modulus $1$ to overpartitions, called separable overpartition\nclasses. We study overpartitions and the overpartition analogue of\nRogers-Ramanujan identities, which are separable overpartition classes.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:39:50 GMT"},{"version":"v2","created":"Wed, 31 May 2023 09:05:05 GMT"}],"update_date":"2023-06-01"}
{"id":"2305.13152","submitter":"Siegfried H\\\"ormann","authors":"Maximilian Ofner and Siegfried H\\\"ormann","title":"Reconstruction of functional data via factor models of increasing rank","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  This paper studies linear reconstruction of partially observed functional\ndata which are recorded on a discrete grid. We propose a novel estimation\napproach based on approximate factor models with increasing rank. Whereas\nalternative reconstruction procedures commonly involve some preliminary\nsmoothing, our method separates the signal from noise and reconstructs missing\nfragments at once. We establish uniform convergence rates of our estimator and\nintroduce a new method for constructing simultaneous prediction bands for the\nmissing trajectories. A simulation study examines the performance of the\nproposed methods in finite samples. Finally, a real data application of\ntemperature curves demonstrates that our theory provides a simple and effective\nmethod to recover missing fragments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:40:37 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13153","submitter":"Xiaoyu Wang","authors":"Xiaoyu Wang, Rui Pan, Renjie Pi and Tong Zhang","title":"Effective Bilevel Optimization via Minimax Reformulation","comments":"25 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG math.OC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Bilevel optimization has found successful applications in various machine\nlearning problems, including hyper-parameter optimization, data cleaning, and\nmeta-learning. However, its huge computational cost presents a significant\nchallenge for its utilization in large-scale problems. This challenge arises\ndue to the nested structure of the bilevel formulation, where each\nhyper-gradient computation necessitates a costly inner optimization procedure.\nTo address this issue, we propose a reformulation of bilevel optimization as a\nminimax problem, effectively decoupling the outer-inner dependency. Under mild\nconditions, we show these two problems are equivalent. Furthermore, we\nintroduce a multi-stage gradient descent and ascent (GDA) algorithm to solve\nthe resulting minimax problem with convergence guarantees. Extensive\nexperimental results demonstrate that our method outperforms state-of-the-art\nbilevel methods while significantly reducing the computational cost.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:41:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13154","submitter":"Thomas Mildner","authors":"Thomas Mildner, Merle Freye, Gian-Luca Savino, Philip R. Doyle,\n  Benjamin R. Cowan, Rainer Malaka","title":"Defending Against the Dark Arts: Recognising Dark Patterns in Social\n  Media","comments":"13 pages; 5 tables; and 11 figures. This is the author's version of\n  the work. It is posted here for your personal use. Not for redistribution.\n  The definitive Version of Record was published in Designing Interactive\n  Systems Conference (DIS '23), July 10-14, 2023, Pittsburgh, PA, USA, https:\n  //doi.org/10.1145/3563657.3595964","journal-ref":null,"doi":"10.1145/3563657.3595964","report-no":null,"categories":"cs.HC","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Interest in unethical user interfaces has grown in HCI over recent years,\nwith researchers identifying malicious design strategies referred to as ''dark\npatterns''. While such strategies have been described in numerous domains, we\nlack a thorough understanding of how they operate in social networking services\n(SNSs). Pivoting towards regulations against such practices, we address this\ngap by offering novel insights into the types of dark patterns deployed in SNSs\nand people's ability to recognise them across four widely used mobile SNS\napplications. Following a cognitive walkthrough, experts (N=6) could identify\ninstances of dark patterns in all four SNSs, including co-occurrences. Based on\nthe results, we designed a novel rating procedure for evaluating the malice of\ninterfaces. Our evaluation shows that regular users (N=193) could differentiate\nbetween interfaces featuring dark patterns and those without. Such rating\nprocedures could support policymakers' current moves to regulate deceptive and\nmanipulative designs in online interfaces.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:42:02 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13155","submitter":"Naoto Nakatsuji","authors":"Naoto Nakatsuji, Takuto Kawakami and Mikito Koshino","title":"Multi-scale lattice relaxation in general twisted trilayer graphenes","comments":"18 pages, 16 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present comprehensive theoretical studies on the lattice relaxation and\nthe electronic structures in general non-symemtric twisted trilayer graphenes.\nBy using an effective continuum model, we show that the relaxed lattice\nstructure forms a patchwork of moir\\'e-of-moir\\'e domains, where a moir\\'e\npattern given by layer 1 and 2 and another pattern given by layer 2 and 3\nbecome locally commensurate. The atomic configuration inside the domain\nexhibits a distinct contrast between chiral and alternating stacks, which are\ndetermined by the relative signs of the two twist angles. In the chiral case,\nthe electronic band calculation reveals a wide energy window ($>$ 50 meV) with\nlow density of states, featuring sparsely distributed highly one-dimensional\nelectron bands. These one-dimensional states exhibit a sharp localization at\nthe boundaries between super-moir\\'e domains, and they are identified as a\ntopological boundary state between distinct Chern insulators. The alternating\ntrilayer exhibits a coexistence of the flat bands and a monolayer-like Dirac\ncone, and it is attributed to the formation of moir\\'e-of-moir\\'e domains\nequivalent to the mirror-symmetric twisted trilayer graphene.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:42:24 GMT"},{"version":"v2","created":"Tue, 6 Jun 2023 06:50:39 GMT"}],"update_date":"2023-06-07"}
{"id":"2305.13156","submitter":"Alessandro Mariani","authors":"A. Mariani","title":"Vortex condensate and critical exponents in the $(2+1)$-dimensional\n  $\\mathrm{O}(2)$ model","comments":"7 pages, 5 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.stat-mech hep-lat","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  The vortex in the $(2+1)$-dimensional $\\mathrm{O}(2)$ model is studied via\nnumerical simulations in a fully non-perturbative lattice regularization. We\ncompute the vortex condensate and susceptibility to determine its critical\nexponents and a renormalized condensate in the continuum limit. Together with\nrecent results on the vortex mass, this gives a complete picture of the scaling\nbehaviour of the vortex operator in this model and sheds light on the\nstatistical mechanics of topological excitations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:44:12 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13157","submitter":"Anna Ros{\\l}awska","authors":"Anna Ros{\\l}awska, Katharina Kaiser, Michelangelo Romeo, Elo\\\"ise\n  Devaux, Fabrice Scheurer, St\\'ephane Berciaud, Tom\\'a\\v{s} Neuman, Guillaume\n  Schull","title":"Submolecular-scale control of phototautomerization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mes-hall physics.chem-ph","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Many natural and artificial reactions including photosynthesis or\nphotopolymerization are initiated by stimulating organic molecules into an\nexcited state, which enables new reaction paths. Controlling light-matter\ninteraction can influence this key concept of photochemistry, however, it\nremained a challenge to apply this strategy to control photochemical reactions\nat the atomic scale. Here, we profit from the extreme confinement of the\nelectromagnetic field at the apex of a scanning tunneling microscope (STM) tip\nto drive and control the rate of a free-base phthalocyanine\nphototautomerization with submolecular precision. By tuning the laser\nexcitation wavelength and choosing the STM tip position, we control the\nphototautomerization rate and the relative tautomer population. This\nsub-molecular optical control can be used to study any other photochemical\nprocesses.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:45:39 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13158","submitter":"Robert Cardona","authors":"Robert Cardona","title":"Stability is not open or generic in symplectic four-manifolds","comments":"45 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"math.SG math.DS","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Given an embedded stable hypersurface in a four-dimensional symplectic\nmanifold, we prove that it is stable isotopic to a $C^0$-close stable\nhypersurface with the following property: $C^\\infty$-nearby hypersurfaces are\ngenerically unstable. This shows that the stability property is neither open\nnor generic, independently of the isotopy class of hypersurfaces and ambient\nsymplectic manifold. The proof combines tools from stable Hamiltonian topology\nwith techniques in three-dimensional dynamics such as partial sections,\nintegrability and KAM theory. On our way, we establish non-density properties\nof Reeb-like flows and a generic non-integrability theorem for cohomologous\nHamiltonian structures and volume-preserving fields in dimension three.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:46:26 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13159","submitter":"Ron Roth","authors":"Ron M. Roth","title":"On the Implementation of Boolean Functions on Content-Addressable\n  Memories","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DM cs.IT math.IT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Let $[q\\rangle$ denote the integer set $\\{0,1,\\ldots,...,q-1\\}$ and let\n$\\mathbb{B}=\\{0,1\\}$. The problem of implementing functions\n$[q\\rangle\\rightarrow\\mathbb{B}$ on content-addressable memories (CAMs) is\nconsidered. CAMs can be classified by the input alphabet and the state alphabet\nof their cells; for example, in binary CAMs, those alphabets are both\n$\\mathbb{B}$, while in a ternary CAM (TCAM), both alphabets are endowed with a\n\"don't care\" symbol.\n  This work is motivated by recent proposals for using CAMs for fast inference\non decision trees. In such learning models, the tree nodes carry out integer\ncomparisons, such as testing equality ($x=t$?) or inequality ($x\\le t$?), where\n$x \\in [q\\rangle$ is an input to the node and $t \\in [q\\rangle$ is a node\nparameter. A CAM implementation of such comparisons includes mapping (i.e.,\nencoding) $t$ into internal states of some number $n$ of cells and mapping $x$\ninto inputs to these cells, with the goal of minimizing $n$.\n  Such mappings are presented for various comparison families, as well as for\nthe set of all functions $[q\\rangle\\rightarrow\\mathbb{B}$, under several\nscenarios of input and state alphabets of the CAM cells. All those mappings are\nshown to be optimal in that they attain the smallest possible $n$ for any given\n$q$.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:46:33 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13160","submitter":"Boshi Wang","authors":"Boshi Wang, Xiang Yue, Huan Sun","title":"Can ChatGPT Defend the Truth? Automatic Dialectical Evaluation Elicits\n  LLMs' Deficiencies in Reasoning","comments":"14 pages, 3 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  We explore testing the reasoning ability of large language models (LLMs),\nsuch as ChatGPT, by engaging with them in a debate-like conversation that\nprobes deeper into their understanding of the subject. Specifically, we\nformulate a new task where given a question, the LLM can generate a correct\nsolution while the user believes in a wrong solution in the beginning, and they\nneed to discuss to make the correct decision through dialogue. Such a setting\nrequires the LLM to not only achieve the correct answer on its own (which could\nbe done by shallow memorization), but also be able to defend the truth instead\nof blindly believing or getting misled by the user's (invalid) arguments and\ncritiques, thus testing in greater depth whether the LLM grasps the essence of\nthe reasoning required to solve the problem. To automate this evaluation\nframework and save human labor, we simulate the user using another LLM\nconditioned on a synthesized wrong solution. Across a range of complex\nreasoning benchmarks spanning math, commonsense, logic and tasks from\nBIG-Bench, we find that despite being able to generate correct step-by-step\nsolutions in the beginning, ChatGPT cannot maintain its belief in truth for a\nsignificant portion of examples when challenged by often-time absurdly invalid\narguments. Our work reveals LLMs' weaknesses not captured by conventional\nbenchmarking, and also points to danger zones of aligning models with human\nfeedback.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:47:31 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13161","submitter":"Chenghong Bian","authors":"Chenghong Bian, Yulin Shao, Deniz Gunduz","title":"DeepJSCC-l++: Robust and Bandwidth-Adaptive Wireless Image Transmission","comments":"6 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"eess.SP cs.IT math.IT","license":"http://creativecommons.org/publicdomain/zero/1.0/","abstract":"  This paper presents a novel vision transformer (ViT) based deep joint source\nchannel coding (DeepJSCC) scheme, dubbed DeepJSCC-l++, which can be adaptive to\nmultiple target bandwidth ratios as well as different channel signal-to-noise\nratios (SNRs) using a single model. To achieve this, we train the proposed\nDeepJSCC-l++ model with different bandwidth ratios and SNRs, which are fed to\nthe model as side information. The reconstruction losses corresponding to\ndifferent bandwidth ratios are calculated, and a new training methodology is\nproposed, which dynamically assigns different weights to the losses of\ndifferent bandwidth ratios according to their individual reconstruction\nqualities. Shifted window (Swin) transformer, is adopted as the backbone for\nour DeepJSCC-l++ model. Through extensive simulations it is shown that the\nproposed DeepJSCC-l++ and successive refinement models can adapt to different\nbandwidth ratios and channel SNRs with marginal performance loss compared to\nthe separately trained models. We also observe the proposed schemes can\noutperform the digital baseline, which concatenates the BPG compression with\ncapacity-achieving channel code.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:47:51 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13162","submitter":"Marc Brooker","authors":"Marc Brooker and Mike Danilov and Chris Greenwood and Phil Piwonka","title":"On-demand Container Loading in AWS Lambda","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.DC cs.SY eess.SY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  AWS Lambda is a serverless event-driven compute service, part of a category\nof cloud compute offerings sometimes called Function-as-a-service (FaaS). When\nwe first released AWS Lambda, functions were limited to 250MB of code and\ndependencies, packaged as a simple compressed archive. In 2020, we released\nsupport for deploying container images as large as 10GiB as Lambda functions,\nallowing customers to bring much larger code bases and sets of dependencies to\nLambda. Supporting larger packages, while still meeting Lambda's goals of rapid\nscale (adding up to 15,000 new containers per second for a single customer, and\nmuch more in aggregate), high request rate (millions of requests per second),\nhigh scale (millions of unique workloads), and low start-up times (as low as\n50ms) presented a significant challenge.\n  We describe the storage and caching system we built, optimized for delivering\ncontainer images on-demand, and our experiences designing, building, and\noperating it at scale. We focus on challenges around security, efficiency,\nlatency, and cost, and how we addressed these challenges in a system that\ncombines caching, deduplication, convergent encryption, erasure coding, and\nblock-level demand loading.\n  Since building this system, it has reliably processed hundreds of trillions\nof Lambda invocations for over a million AWS customers, and has shown excellent\nresilience to load and infrastructure failures.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:48:37 GMT"},{"version":"v2","created":"Wed, 24 May 2023 13:21:11 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.13163","submitter":"Dane Kleiner","authors":"D. Kleiner, P. Serra, F. M. Maccagni, M. A. Raj, W. J. G. de Blok, G.\n  I. G. J\\'ozsa, P. Kamphuis, R. Kraan-Korteweg, F. Loi, A. Loni, S. I.\n  Loubser, D. Cs. Moln\\'ar, T. A. Oosterloo, R. Peletier and D. J. Pisano","title":"The MeerKAT Fornax Survey -- II. The rapid removal of HI from dwarf\n  galaxies in the Fornax cluster","comments":"Accepted in Astronomy & Astrophysics. 21 pages, 10 figures. Data\n  available at the MeerKAT Fornax Survey website\n  https://sites.google.com/inaf.it/meerkatfornaxsurvey","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.GA","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We present MeerKAT Fornax Survey atomic hydrogen (HI) observations of the\ndwarf galaxies located in the central ~2.5 x 4 deg$^2$ of the Fornax galaxy\ncluster. The HI images presented in this work have a $3\\sigma$ column density\nsensitivity between 2.7 and 50 x 10$^{18}$ cm$^{-2}$ over 25 km s$^{-1}$ for\nspatial resolution between 4 and 1 kpc. We are able to detect an impressive MHI\n= 5 x 10$^{5}$ Msun 3$\\sigma$ point source with a line width of 50 km s$^{-1}$\nat a distance of 20 Mpc. We detect HI in 17 out of the 304 dwarfs in our field\n-- 14 out of the 36 late type dwarfs (LTDs), and 3 of the 268 early type dwarfs\n(ETDs). The HI-detected LTDs have likely just joined the cluster and are on\ntheir first infall as they are located at large clustocentric radii, with\ncomparable MHI and mean stellar surface brightness at fixed luminosity as blue,\nstar-forming LTDs in the field. The HI-detected ETDs have likely been in the\ncluster longer than the LTDs and acquired their HI through a recent merger or\naccretion from nearby HI. Eight of the HI-detected LTDs host irregular or\nasymmetric HI emission and disturbed or lopsided stellar emission. There are\ntwo clear cases of ram-pressure shaping the HI, with the LTDs displaying\ncompressed HI on the side closest to the cluster centre and a one-sided,\nstarless tail pointing away from the cluster centre. The HI-detected dwarfs\navoid the most massive potentials, consistent with massive galaxies playing an\nactive role in the removal of HI. We create a simple toy model to quantify the\ntimescale of HI stripping in the cluster. We find that a MHI = 10$^{8}$ Msun\ndwarf will be stripped in ~ 240 Myr. The model is consistent with our\nobservations, where low mass LTDs are directly stripped of their HI from a\nsingle encounter and more massive LTDs can harbour a disturbed HI morphology\ndue to longer times or multiple encounters being required to fully strip their\nHI.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:50:41 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13164","submitter":"Animesh Basak Chowdhury","authors":"Animesh Basak Chowdhury, Marco Romanelli, Benjamin Tan, Ramesh Karri,\n  Siddharth Garg","title":"INVICTUS: Optimizing Boolean Logic Circuit Synthesis via Synergistic\n  Learning and Search","comments":"20 pages, 8 figures and 15 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AR","license":"http://creativecommons.org/licenses/by-nc-nd/4.0/","abstract":"  Logic synthesis is the first and most vital step in chip design. This steps\nconverts a chip specification written in a hardware description language (such\nas Verilog) into an optimized implementation using Boolean logic gates.\nState-of-the-art logic synthesis algorithms have a large number of logic\nminimization heuristics, typically applied sequentially based on human\nexperience and intuition. The choice of the order greatly impacts the quality\n(e.g., area and delay) of the synthesized circuit. In this paper, we propose\nINVICTUS, a model-based offline reinforcement learning (RL) solution that\nautomatically generates a sequence of logic minimization heuristics (\"synthesis\nrecipe\") based on a training dataset of previously seen designs. A key\nchallenge is that new designs can range from being very similar to past designs\n(e.g., adders and multipliers) to being completely novel (e.g., new processor\ninstructions). %Compared to prior work, INVICTUS is the first solution that\nuses a mix of RL and search methods joint with an online out-of-distribution\ndetector to generate synthesis recipes over a wide range of benchmarks. Our\nresults demonstrate significant improvement in area-delay product (ADP) of\nsynthesized circuits with up to 30\\% improvement over state-of-the-art\ntechniques. Moreover, INVICTUS achieves up to $6.3\\times$ runtime reduction\n(iso-ADP) compared to the state-of-the-art.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:50:42 GMT"},{"version":"v2","created":"Thu, 25 May 2023 23:31:44 GMT"},{"version":"v3","created":"Mon, 5 Jun 2023 05:00:25 GMT"}],"update_date":"2023-06-06"}
{"id":"2305.13165","submitter":"Peter S\\'uken\\'ik","authors":"Peter S\\'uken\\'ik, Marco Mondelli, Christoph Lampert","title":"Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained\n  Features Model","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG stat.ML","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Neural collapse (NC) refers to the surprising structure of the last layer of\ndeep neural networks in the terminal phase of gradient descent training.\nRecently, an increasing amount of experimental evidence has pointed to the\npropagation of NC to earlier layers of neural networks. However, while the NC\nin the last layer is well studied theoretically, much less is known about its\nmulti-layered counterpart - deep neural collapse (DNC). In particular, existing\nwork focuses either on linear layers or only on the last two layers at the\nprice of an extra assumption. Our paper fills this gap by generalizing the\nestablished analytical framework for NC - the unconstrained features model - to\nmultiple non-linear layers. Our key technical contribution is to show that, in\na deep unconstrained features model, the unique global optimum for binary\nclassification exhibits all the properties typical of DNC. This explains the\nexisting experimental evidence of DNC. We also empirically show that (i) by\noptimizing deep unconstrained features models via gradient descent, the\nresulting solution agrees well with our theory, and (ii) trained networks\nrecover the unconstrained features suitable for the occurrence of DNC, thus\nsupporting the validity of this modeling principle.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:51:28 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13166","submitter":"Gianluca Giacchi","authors":"Elena Cordero, Gianluca Giacchi","title":"Excursus on modulation spaces via metaplectic operators and related\n  time-frequency representations","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.AP","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modulation spaces were originally introduced by Feichtinger in 1983. Since\nthe 2000s there have been thousands of contributions using them as correct\nframework; they range from PDEs, pseudodifferential operators, quantum\nmechanics, signal analysis. This justifies a deep study of such spaces and the\nrelated Wiener ones. Recently, metaplectic Wigner distributions, which contain\nas special examples the $\\tau$-Wigner distributions, the ambiguity function and\nthe Short-time Fourier transform, have proved to characterize modulation\nspaces, under suitable assumptions. We investigate the metaplectic action which\nis hidden in their construction and guarantees equivalent (quasi-)norms for\nsuch spaces. We add a new result on this topic and conclude with an exhaustive\nvision of these characterizations. Similar results hold for the Wiener amalgam\nones.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:54:16 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13167","submitter":"Xingjian He","authors":"Xingjian He, Sihan Chen, Fan Ma, Zhicheng Huang, Xiaojie Jin, Zikang\n  Liu, Dongmei Fu, Yi Yang, Jing Liu, Jiashi Feng","title":"VLAB: Enhancing Video Language Pre-training by Feature Adapting and\n  Blending","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Large-scale image-text contrastive pre-training models, such as CLIP, have\nbeen demonstrated to effectively learn high-quality multimodal representations.\nHowever, there is limited research on learning video-text representations for\ngeneral video multimodal tasks based on these powerful features. Towards this\ngoal, we propose a novel video-text pre-training method dubbed VLAB: Video\nLanguage pre-training by feature Adapting and Blending, which transfers CLIP\nrepresentations to video pre-training tasks and develops unified video\nmultimodal models for a wide range of video-text tasks. Specifically, VLAB is\nfounded on two key strategies: feature adapting and feature blending. In the\nformer, we introduce a new video adapter module to address CLIP's deficiency in\nmodeling temporal information and extend the model's capability to encompass\nboth contrastive and generative tasks. In the latter, we propose an end-to-end\ntraining method that further enhances the model's performance by exploiting the\ncomplementarity of image and video features. We validate the effectiveness and\nversatility of VLAB through extensive experiments on highly competitive video\nmultimodal tasks, including video text retrieval, video captioning, and video\nquestion answering. Remarkably, VLAB outperforms competing methods\nsignificantly and sets new records in video question answering on MSRVTT, MSVD,\nand TGIF datasets. It achieves an accuracy of 49.6, 61.0, and 79.0,\nrespectively. Codes and models will be released.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:54:22 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13168","submitter":"Ningyu Zhang","authors":"Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao,\n  Shumin Deng, Huajun Chen, Ningyu Zhang","title":"LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities\n  and Future Opportunities","comments":"Work in progress","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.DB cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper presents an exhaustive quantitative and qualitative evaluation of\nLarge Language Models (LLMs) for Knowledge Graph (KG) construction and\nreasoning. We employ eight distinct datasets that encompass aspects including\nentity, relation and event extraction, link prediction, and question answering.\nEmpirically, our findings suggest that GPT-4 outperforms ChatGPT in the\nmajority of tasks and even surpasses fine-tuned models in certain reasoning and\nquestion-answering datasets. Moreover, our investigation extends to the\npotential generalization ability of LLMs for information extraction, which\nculminates in the presentation of the Virtual Knowledge Extraction task and the\ndevelopment of the VINE dataset. Drawing on these empirical findings, we\nfurther propose AutoKG, a multi-agent-based approach employing LLMs for KG\nconstruction and reasoning, which aims to chart the future of this field and\noffer exciting opportunities for advancement. We anticipate that our research\ncan provide invaluable insights for future undertakings of KG\\footnote{Code and\ndatasets will be available in https://github.com/zjunlp/AutoKG.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:56:44 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13169","submitter":"Gregory Yauney","authors":"Shayne Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam\n  Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David Mimno,\n  Daphne Ippolito","title":"A Pretrainer's Guide to Training Data: Measuring the Effects of Data\n  Age, Domain Coverage, Quality, & Toxicity","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Pretraining is the preliminary and fundamental step in developing capable\nlanguage models (LM). Despite this, pretraining data design is critically\nunder-documented and often guided by empirically unsupported intuitions. To\naddress this, we pretrain 28 1.5B parameter decoder-only models, training on\ndata curated (1) at different times, (2) with varying toxicity and quality\nfilters, and (3) with different domain compositions. First, we quantify the\neffect of pretraining data age. A temporal shift between evaluation data and\npretraining data leads to performance degradation, which is not overcome by\nfinetuning. Second, we explore the effect of quality and toxicity filters,\nshowing a trade-off between performance on standard benchmarks and risk of\ntoxic generations. Our findings indicate there does not exist a\none-size-fits-all solution to filtering training data. We also find that the\neffects of different types of filtering are not predictable from text domain\ncharacteristics. Lastly, we empirically validate that the inclusion of\nheterogeneous data sources, like books and web, is broadly beneficial and\nwarrants greater prioritization. These findings constitute the largest set of\nexperiments to validate, quantify, and expose many undocumented intuitions\nabout text pretraining, which we hope will help support more informed\ndata-centric decisions in LM development.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:57:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13170","submitter":"Kai Yi","authors":"Kai Yi, Laurent Condat, Peter Richt\\'arik","title":"Explicit Personalization and Local Training: Double Communication\n  Acceleration in Federated Learning","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Federated Learning is an evolving machine learning paradigm, in which\nmultiple clients perform computations based on their individual private data,\ninterspersed by communication with a remote server. A common strategy to\ncurtail communication costs is Local Training, which consists in performing\nmultiple local stochastic gradient descent steps between successive\ncommunication rounds. However, the conventional approach to local training\noverlooks the practical necessity for client-specific personalization, a\ntechnique to tailor local models to individual needs. We introduce Scafflix, a\nnovel algorithm that efficiently integrates explicit personalization with local\ntraining. This innovative approach benefits from these two techniques, thereby\nachieving doubly accelerated communication, as we demonstrate both in theory\nand practice.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:58:01 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13171","submitter":"Maksim Lednev","authors":"Maksim Lednev, Francisco J. Garc\\'ia-Vidal, and Johannes Feist","title":"A Lindblad master equation capable of describing hybrid quantum systems\n  in the ultra-strong coupling regime","comments":"6 pages, 4 figures, letter","journal-ref":null,"doi":null,"report-no":null,"categories":"quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Despite significant theoretical efforts devoted to studying the interaction\nbetween quantized light modes and matter, the so-called ultra-strong coupling\nregime still presents significant challenges for theoretical treatments and\nprevents the use of many common approximations. Here we demonstrate an approach\nthat can describe the dynamics of hybrid quantum systems in any regime of\ninteraction for an arbitrary electromagnetic (EM) environment. We extend a\nprevious method developed for few-mode quantization of arbitrary systems to the\ncase of ultrastrong light-matter coupling, and show that even such systems can\nbe treated using a Lindblad master equation where decay operators act only on\nthe photonic modes by ensuring that the effective spectral density of the EM\nenvironment is sufficiently suppressed at negative frequencies. We demonstrate\nthe validity of our framework and show that it outperforms current\nstate-of-the-art master equations for a simple model system, and then study a\nrealistic nanoplasmonic setup where existing approaches cannot be applied.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:59:53 GMT"}],"update_date":"2023-05-23"}
{"id":"2305.13341","submitter":"Gustau Camps-Valls","authors":"Gustau Camps-Valls, Andreas Gerhardus, Urmi Ninad, Gherardo Varando,\n  Georg Martius, Emili Balaguer-Ballester, Ricardo Vinuesa, Emiliano Diaz,\n  Laure Zanna, Jakob Runge","title":"Discovering Causal Relations and Equations from Data","comments":"137 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.data-an cs.AI cs.LG stat.ME","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Physics is a field of science that has traditionally used the scientific\nmethod to answer questions about why natural phenomena occur and to make\ntestable models that explain the phenomena. Discovering equations, laws and\nprinciples that are invariant, robust and causal explanations of the world has\nbeen fundamental in physical sciences throughout the centuries. Discoveries\nemerge from observing the world and, when possible, performing interventional\nstudies in the system under study. With the advent of big data and the use of\ndata-driven methods, causal and equation discovery fields have grown and made\nprogress in computer science, physics, statistics, philosophy, and many applied\nfields. All these domains are intertwined and can be used to discover causal\nrelations, physical laws, and equations from observational data. This paper\nreviews the concepts, methods, and relevant works on causal and equation\ndiscovery in the broad field of Physics and outlines the most important\nchallenges and promising future lines of research. We also provide a taxonomy\nfor observational causal and equation discovery, point out connections, and\nshowcase a complete set of case studies in Earth and climate sciences, fluid\ndynamics and mechanics, and the neurosciences. This review demonstrates that\ndiscovering fundamental laws and causal relations by observing natural\nphenomena is being revolutionised with the efficient exploitation of\nobservational data, modern machine learning algorithms and the interaction with\ndomain knowledge. Exciting times are ahead with many challenges and\nopportunities to improve our understanding of complex systems.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 19:22:50 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13342","submitter":"Katerina Margatina","authors":"Katerina Margatina and Nikolaos Aletras","title":"On the Limitations of Simulating Active Learning","comments":"To appear at Findings of ACL 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Active learning (AL) is a human-and-model-in-the-loop paradigm that\niteratively selects informative unlabeled data for human annotation, aiming to\nimprove over random sampling. However, performing AL experiments with human\nannotations on-the-fly is a laborious and expensive process, thus unrealistic\nfor academic research. An easy fix to this impediment is to simulate AL, by\ntreating an already labeled and publicly available dataset as the pool of\nunlabeled data. In this position paper, we first survey recent literature and\nhighlight the challenges across all different steps within the AL loop. We\nfurther unveil neglected caveats in the experimental setup that can\nsignificantly affect the quality of AL research. We continue with an\nexploration of how the simulation setting can govern empirical findings,\narguing that it might be one of the answers behind the ever posed question\n``why do active learning algorithms sometimes fail to outperform random\nsampling?''. We argue that evaluating AL algorithms on available labeled\ndatasets might provide a lower bound as to their effectiveness in real data. We\nbelieve it is essential to collectively shape the best practices for AL\nresearch, particularly as engineering advancements in LLMs push the research\nfocus towards data-driven approaches (e.g., data efficiency, alignment,\nfairness). In light of this, we have developed guidelines for future work. Our\naim is to draw attention to these limitations within the community, in the hope\nof finding ways to address them.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 22:52:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13343","submitter":"Chukuan Jiang","authors":"Chu-Kuan Jiang, Yang-Fan Deng, Hongxiao Guo, Guang-Hao Chen, Di Wu","title":"A new sulfur bioconversion process development for energy- and\n  space-efficient secondary wastewater treatment","comments":"Written by Chu-Kuan Jiang; edited by Yang-Fan Deng, Hongxiao Guo,\n  Guang-Hao Chen, Di Wu; Corresponding authors: Guang-Hao Chen, Di Wu; Last\n  author (team leader): Guang-Hao Chen","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.OT","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Harvesting organic matter from wastewater is widely applied to maximize\nenergy recovery; however, it limits the applicability of secondary treatment\nfor acceptable effluent discharge into surface water bodies. To turn this\nbottleneck issue into an opportunity, this study developed oxygen-induced\nthiosulfatE production duRing sulfATe reductiOn (EARTO) to provide an efficient\nelectron donor for wastewater treatment. Typical pretreated wastewater was\nsynthesized with chemical oxygen demand of 110 mg/L, sulfate of 50 mg S/L, and\nvarying dissolved oxygen (DO) and was fed into a moving-bed biofilm reactor\n(MBBR). The MBBR was operated continuously with a short hydraulic retention\ntime of 40 min for 349 days. The formation rate of thiosulfate reached\n0.12-0.18 g S/(m2.d) with a high produced thiosulfate-S/TdS-S ratio of 38-73%\nwhen influent DO was 2.7-3.6 mg/L. The sludge yield was 0.23-0.29 gVSS/gCOD,\nmuch lower than it was in conventional activated sludge processes. Then, batch\ntests and metabolism analysis were conducted to confirm the oxygen effect on\nthiosulfate formation, characterize the roles of sulfate and microbial\nactivities, and explore the mechanism of oxygen-induced thiosulfate formation\nin ERATO. Results examined that oxygen supply promoted the\nthiosulfate-Sproduced/TdS-Sproduced ratio from 4% to 24-26%, demonstrated that\nsulfate and microbial activities were critical for thiosulfate production, and\nindicated that oxygen induces thiosulfate formation through two pathways: 1)\ndirect sulfide oxidation, and 2) indirect sulfide oxidation, sulfide is first\noxidized to S0 (dominant) which then reacts with sulfite derived from\noxygen-regulated biological sulfate reduction. The proposed compact ERATO\nprocess, featuring high thiosulfate production and low sludge production,\nsupports space- and energy-efficient secondary wastewater treatment.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:01:08 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13344","submitter":"Yury S Tsyganov","authors":"Yu.S. Tsyganov, D. Ibadullayev, A.N. Polyakov, A.A. Voinov, M.V.\n  Shumeiko, V.A.Shubin, V.B. Zlokazov, D.A. Kuznetsov","title":"Review of the some specific features of the detecting of heavy recoils","comments":"18 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.data-an nucl-ex physics.ins-det","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In this paper, we present the results of the first beam tests of the\ndetection system at the focal plane of the Dubna Gas-Filled Recoil Separator-2\n(DGFRS-2), which receives beams from the DC-280 FLNR cyclotron. The high beam\nintensity of $^{48}$Ca$^{+10}$ heavy ions from the cyclotron enables us to\nobtain a number of superheavy recoils sufficient to compare both the measured\nand calculated spectra of superheavy recoils implanted into a silicon detector.\nA real-time algorithm to search for an Evaporation Residue (ER) -- $\\alpha$\ncorrelated sequences is described in brief. It should be noted that the DGFRS-2\nspectrometer operates in conjunction with the 48x128 strip DSSD (Double-sided\nSilicon Strip Detector; 48x226 mm2) detector and a low-pressure pentane-filled\ngaseous detector (1.2 Torr; 80x230 mm$^2$). A block-diagram of the spectrometer\nand the event format are also presented. Special attention is paid to the\nresponse of a low-pressure pentane-filled DeltaE multiwire proportional chamber\nfor recoils of Fl, synthesized in the $^{242}$Pu+$^{48}$Ca $\\to$ $^{287}$Fl +3n\ncomplete fusion nuclear reaction. Some actual parameters of the detection\nsystem have also been extracted from $^{\\rm nat}$Yb + $^{48}$Ca, $^{232}$Th +\n$^{48}$Ca, $^{243}$Am + $^{48}$Ca, $^{238}$U + $^{48}$Ca reactions. The effect\nof neighbor strip charge sharing for the ohmic side of the DSSD detector is\nalso under consideration.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:19:40 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13345","submitter":"Patrick Barth","authors":"Patrick Barth, Eva E. St\\\"ueken, Christiane Helling, Lukas Rossmanith,\n  Yuqian Peng, Wendell Walters and Mark Claire","title":"Isotopic constraints on lightning as a source of fixed nitrogen in\n  Earth's early biosphere","comments":"Accepted manuscript. Version of record published in Nature\n  Geoscience. 29 pages (main text, methods, supplementary material), 5 figures\n  + 4 supplementary figures","journal-ref":null,"doi":"10.1038/s41561-023-01187-2","report-no":null,"categories":"physics.geo-ph astro-ph.EP astro-ph.IM hep-ex","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Bioavailable nitrogen is thought to be a requirement for the origin and\nsustenance of life. Before the onset of biological nitrogen fixation, abiotic\npathways to fix atmospheric N2 must have been prominent to provide bioavailable\nnitrogen to Earth's earliest ecosystems. Lightning has been shown to produce\nfixed nitrogen as nitrite and nitrate in both modern atmospheres dominated by\nN2 and O2 and atmospheres dominated by N2 and CO2 analogous to the Archaean\nEarth. However, a better understanding of the isotopic fingerprints of\nlightning-generated fixed nitrogen is needed to assess the role of this process\non the early Earth. Here, we present results from spark discharge experiments\nin N2-CO2 and N2-O2 gas mixtures. Our experiments suggest that lightning-driven\nnitrogen fixation may have been similarly efficient in the Archaean atmosphere,\ncompared to modern times. Measurements of the isotopic ratio {\\delta}15N of the\ndischarge-produced nitrite and nitrate in solution show very low values of -6\nto -15 permil after equilibration with the gas phase with a calculated\nendmember composition of -17 permil. These results are much lower than most\n{\\delta}15N values documented from the sedimentary rock record, which supports\nthe development of biological nitrogen fixation earlier than 3.2 Ga. However,\nsome Paleoarchean records (3.7 Ga) may be consistent with lightning-derived\nnitrogen input, highlighting the potential role of this process for the\nearliest ecosystems.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:51:14 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13346","submitter":"Susumu Fukatsu","authors":"Ryota Keyaki and Susumu Fukatsu","title":"Single time pixel imaging enabled by repurposing optoelectronic devices","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.optics","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  One-time readout temporal ghost imaging is attempted by utilizing\noptoelectronic devices that are not originally intended for signal photon\ndetection purposes and as such slow by design. A visible light-emitting diode\nhaving a response time $\\tau$=0.036 ms and a solar cell with $\\tau$=3.1ms are\nused to retrieve a rectangular pulse train, which is otherwise rounded with\nsignificant overlapping, in the image of a temporal mask simply by capturing\ndata once at a selected single time effective operation duration are discussed.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:39:16 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13347","submitter":"Sarah McDaid PhD","authors":"Edward McDaid, Sarah McDaid","title":"Further Decimating the Inductive Programming Search Space with\n  Instruction Digrams","comments":"8 pages, 6 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.PL cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Overlapping instruction subsets derived from human originated code have\npreviously been shown to dramatically shrink the inductive programming search\nspace, often by many orders of magnitude. Here we extend the instruction subset\napproach to consider direct instruction-instruction applications (or\ninstruction digrams) as an additional search heuristic for inductive\nprogramming. In this study we analyse the frequency distribution of instruction\ndigrams in a large sample of open source code. This indicates that the\ninstruction digram distribution is highly skewed with over 93% of possible\ninstruction digrams not represnted in the code sample. We demonstrate that\ninstruction digrams can be used to constrain instruction selection during\nsearch, further reducing size of the the search space, in some cases by several\norders of magnitude. This significantly increases the size of programs that can\nbe generated using search based inductive programming techniques. We discuss\nthe results and provide some suggestions for further work.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:58:18 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13572","submitter":"Jerome Dedecker","authors":"Sinda Ammous (MAP5), J\\'er\\^ome Dedecker (MAP5), C\\'eline Duval (LPP)","title":"Adaptive directional estimator of the density in R^d for independent and\n  mixing sequences","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"math.ST stat.TH","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  A new multivariate density estimator for stationary sequences is obtained by\nFourier inversion of the thresholded empirical characteristic function. This\nestimator does not depend on the choice of parameters related to the smoothness\nof the density; it is directly adaptive. We establish oracle inequalities valid\nfor independent, $\\alpha$-mixing and $\\tau$-mixing sequences, which allows us\nto derive optimal convergence rates, up to a logarithmic loss. On general\nanisotropic Sobolev classes, the estimator adapts to the regularity of the\nunknown density but also achieves directional adaptivity. In particular, if A\nis an invertible matrix, if the observations are drawn from X $\\in$ R^d , d\n$\\ge$ 1, it achieves the rate implied by the regularity of AX, which may be\nmore regular than X. The estimator is easy to implement and numerically\nefficient. It depends on the calibration of a parameter for which we propose an\ninnovative numerical selection procedure, using the Euler characteristic of the\nthresholded areas.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:02:13 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.13996","submitter":"Ellis Thompson","authors":"Ellis L Thompson and Yan Xu and Peng Wei","title":"One-Shot Strategically Deconflicted Route and Operational Volume\n  Generation for Urban Air Mobility Operations","comments":"8 pages, 7 Figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  In the UAM space, strategic deconfliction provides an all-essential layer to\nairspace automation by providing safe, preemptive deconfliction or assignment\nof airspace resources to airspace users pre-flight. Strategic deconfliction\napproaches provide an elegant solution to pre-flight deconfliction operations.\nThis overall creates safer and more efficient airspace and reduces the workload\non controllers. In this research, we propose a method that constructs routes\nbetween start and end nodes in airspace, assigns a contract of operational\nvolumes (OVs) and ensures that these OVs are sufficiently deconflicted against\nstatic no-fly zones and OVs of other airspace users. Our approach uses the A*\noptimal cost path algorithm to generate the shortest routes between the origin\nand destination. We present a method for generating OVs based on the\ndistribution of aircraft positions from simulated flights; volumes are\nconstructed such that this distribution is conservatively described.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:05:32 GMT"},{"version":"v2","created":"Thu, 25 May 2023 12:59:29 GMT"}],"update_date":"2023-05-26"}
{"id":"2305.13997","submitter":"Zaixi Zhang","authors":"Zaixi Zhang, Qi Liu","title":"Learning Subpocket Prototypes for Generalizable Structure-based Drug\n  Design","comments":"Accepted by ICML 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"q-bio.BM cs.LG","license":"http://creativecommons.org/licenses/by-nc-sa/4.0/","abstract":"  Generating molecules with high binding affinities to target proteins (a.k.a.\nstructure-based drug design) is a fundamental and challenging task in drug\ndiscovery. Recently, deep generative models have achieved remarkable success in\ngenerating 3D molecules conditioned on the protein pocket. However, most\nexisting methods consider molecular generation for protein pockets\nindependently while neglecting the underlying connections such as\nsubpocket-level similarities. Subpockets are the local protein environments of\nligand fragments and pockets with similar subpockets may bind the same\nmolecular fragment (motif) even though their overall structures are different.\nTherefore, the trained models can hardly generalize to unseen protein pockets\nin real-world applications. In this paper, we propose a novel method DrugGPS\nfor generalizable structure-based drug design. With the biochemical priors, we\npropose to learn subpocket prototypes and construct a global interaction graph\nto model the interactions between subpocket prototypes and molecular motifs.\nMoreover, a hierarchical graph transformer encoder and motif-based 3D molecule\ngeneration scheme are used to improve the model's performance. The experimental\nresults show that our model consistently outperforms baselines in generating\nrealistic drug candidates with high affinities in challenging\nout-of-distribution settings.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 13:49:49 GMT"}],"update_date":"2023-05-24"}
{"id":"2305.14379","submitter":"R. K. L. Lo","authors":"Rico K. L. Lo","title":"denmarf: a Python package for density estimation using masked\n  autoregressive flow","comments":"Submitted to the Journal of Open Source Software","journal-ref":null,"doi":null,"report-no":null,"categories":"astro-ph.IM","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Masked autoregressive flow (MAF) is a state-of-the-art non-parametric density\nestimation technique. It is based on the idea (known as a normalizing flow)\nthat a simple base probability distribution can be mapped into a complicated\ntarget distribution that one wishes to approximate, using a sequence of\nbijective transformations. The denmarf package provides a scikit-learn-like\ninterface in Python for researchers to effortlessly use MAF for density\nestimation in their applications to evaluate probability densities of the\nunderlying distribution of a set of data and generate new samples from the\ndata, on either a CPU or a GPU, as simple as \"from denmarf import\nDensityEstimate; de = DensityEstimate().fit(X)\". The package also implements\nlogistic transformations to facilitate the fitting of bounded distributions.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 02:34:19 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14380","submitter":"Jinjie Ni","authors":"Jinjie Ni, Rui Mao, Zonglin Yang, Han Lei, Erik Cambria","title":"Finding the Pillars of Strength for Multi-Head Attention","comments":"In Proceedings of the Annual Meeting of the Association for\n  Computational Linguistics (ACL 2023)","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g.,\nredundancy and over-parameterization. Specifically, the heads of MHA were\noriginally designed to attend to information from different representation\nsubspaces, whereas prior studies found that some attention heads likely learn\nsimilar features and can be pruned without harming performance. Inspired by the\nminimum-redundancy feature selection, we assume that focusing on the most\nrepresentative and distinctive features with minimum resources can mitigate the\nabove issues and lead to more effective and efficient MHAs. In particular, we\npropose Grouped Head Attention, trained with a self-supervised group constraint\nthat group attention heads, where each group focuses on an essential but\ndistinctive feature subset. We additionally propose a Voting-to-Stay procedure\nto remove redundant heads, thus achieving a transformer with lighter weights.\nMoreover, our method achieves significant performance gains on three\nwell-established tasks while considerably compressing parameters.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 03:44:44 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14381","submitter":"Zehan Wang","authors":"Zehan Wang, Yang Zhao, Xize Cheng, Haifeng Huang, Jiageng Liu, Li\n  Tang, Linjun Li, Yongqi Wang, Aoxiong Yin, Ziang Zhang, Zhou Zhao","title":"Connecting Multi-modal Contrastive Representations","comments":"Demos are available at \\url{https://c-mcr.github.io/C-MCR/}","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CV cs.MM cs.SD eess.AS","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Multi-modal Contrastive Representation (MCR) learning aims to encode\ndifferent modalities into a semantically aligned shared space. This paradigm\nshows remarkable generalization ability on numerous downstream tasks across\nvarious modalities. However, the reliance on massive high-quality data pairs\nlimits its further development on more modalities. This paper proposes a novel\ntraining-efficient method for learning MCR without paired data called\nConnecting Multi-modal Contrastive Representations (C-MCR). Specifically, given\ntwo existing MCRs pre-trained on (A, B) and (B, C) modality pairs, we project\nthem to a new space and use the data from the overlapping modality B to\naligning the two MCRs in the new space. Meanwhile, since the modality pairs (A,\nB) and (B, C) are already aligned within each MCR, the connection learned by\noverlapping modality can also be transferred to non-overlapping modality pair\n(A, C). To unleash the potential of C-MCR, we further introduce a\nsemantic-enhanced inter- and intra-MCR connection method. We first enhance the\nsemantic consistency and completion of embeddings across different modalities\nfor more robust alignment. Then we utilize the inter-MCR alignment to establish\nthe connection, and employ the intra-MCR alignment to better maintain the\nconnection for inputs from non-overlapping modalities. We take the field of\naudio-visual contrastive learning as an example to demonstrate the\neffectiveness of C-MCR. We connect pre-trained CLIP and CLAP models via texts\nto derive audio-visual contrastive representations. Remarkably, without using\nany paired audio-visual data and further tuning, C-MCR achieves\nstate-of-the-art performance on six datasets across three audio-visual\ndownstream tasks.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 09:44:39 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14382","submitter":"Hailong Zhang","authors":"Yuze Lu, Hailong Zhang, Qiwen Guo","title":"Stock and market index prediction using Informer network","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"q-fin.ST cs.AI","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Applications of deep learning in financial market prediction has attracted\nhuge attention from investors and researchers. In particular, intra-day\nprediction at the minute scale, the dramatically fluctuating volume and stock\nprices within short time periods have posed a great challenge for the\nconvergence of networks result. Informer is a more novel network, improved on\nTransformer with smaller computational complexity, longer prediction length and\nglobal time stamp features. We have designed three experiments to compare\nInformer with the commonly used networks LSTM, Transformer and BERT on 1-minute\nand 5-minute frequencies for four different stocks/ market indices. The\nprediction results are measured by three evaluation criteria: MAE, RMSE and\nMAPE. Informer has obtained best performance among all the networks on every\ndataset. Network without the global time stamp mechanism has significantly\nlower prediction effect compared to the complete Informer; it is evident that\nthis mechanism grants the time series to the characteristics and substantially\nimproves the prediction accuracy of the networks. Finally, transfer learning\ncapability experiment is conducted, Informer also achieves a good performance.\nInformer has good robustness and improved performance in market prediction,\nwhich can be exactly adapted to real trading.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 10:59:42 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14383","submitter":"Yifan Hong","authors":"Yifan Hong and Chen Wang","title":"A Rational Model of Dimension-reduced Human Categorization","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Existing models in cognitive science typically assume human categorization as\ngraded generalization behavior in a multidimensional psychological space.\nHowever, category representations in these models may suffer from the curse of\ndimensionality in a natural setting. People generally rely on a tractable yet\nsufficient set of features to understand the complex environment. We propose a\nrational model of categorization based on a hierarchical mixture of\nprobabilistic principal components, that simultaneously learn category\nrepresentations and an economical collection of features. The model captures\ndimensional biases in human categorization and supports zero-shot learning. We\nfurther exploit a generative process within a low-dimensional latent space to\nprovide a better account of categorization with high-dimensional stimuli. We\nvalidate the model with simulation and behavioral experiments.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 11:49:21 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14384","submitter":"Lora Aroyo","authors":"Alicia Parrish, Hannah Rose Kirk, Jessica Quaye, Charvi Rastogi, Max\n  Bartolo, Oana Inel, Juan Ciro, Rafael Mosquera, Addison Howard, Will\n  Cukierski, D. Sculley, Vijay Janapa Reddi, Lora Aroyo","title":"Adversarial Nibbler: A Data-Centric Challenge for Improving the Safety\n  of Text-to-Image Models","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.LG cs.AI cs.CR cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The generative AI revolution in recent years has been spurred by an expansion\nin compute power and data quantity, which together enable extensive\npre-training of powerful text-to-image (T2I) models. With their greater\ncapabilities to generate realistic and creative content, these T2I models like\nDALL-E, MidJourney, Imagen or Stable Diffusion are reaching ever wider\naudiences. Any unsafe behaviors inherited from pretraining on uncurated\ninternet-scraped datasets thus have the potential to cause wide-reaching harm,\nfor example, through generated images which are violent, sexually explicit, or\ncontain biased and derogatory stereotypes. Despite this risk of harm, we lack\nsystematic and structured evaluation datasets to scrutinize model behavior,\nespecially adversarial attacks that bypass existing safety filters. A typical\nbottleneck in safety evaluation is achieving a wide coverage of different types\nof challenging examples in the evaluation set, i.e., identifying 'unknown\nunknowns' or long-tail problems. To address this need, we introduce the\nAdversarial Nibbler challenge. The goal of this challenge is to crowdsource a\ndiverse set of failure modes and reward challenge participants for successfully\nfinding safety vulnerabilities in current state-of-the-art T2I models.\nUltimately, we aim to provide greater awareness of these issues and assist\ndevelopers in improving the future safety and reliability of generative AI\nmodels. Adversarial Nibbler is a data-centric challenge, part of the DataPerf\nchallenge suite, organized and supported by Kaggle and MLCommons.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:02:40 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.14522","submitter":"Yutong Zhou","authors":"Yutong Zhou","title":"Design a Delicious Lunchbox in Style","comments":"Accepted by WiCV @CVPR2023 (In Progress). Dataset:\n  https://github.com/Yutong-Zhou-cv/Bento800_Dataset","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We propose a cyclic generative adversarial network with spatial-wise and\nchannel-wise attention modules for text-to-image synthesis. To accurately\ndepict and design scenes with multiple occluded objects, we design a\npre-trained ordering recovery model and a generative adversarial network to\npredict layout and composite novel box lunch presentations. In the experiments,\nwe devise the Bento800 dataset to evaluate the performance of the text-to-image\nsynthesis model and the layout generation & image composition model. This paper\nis the continuation of our previous paper works. We also present additional\nexperiments and qualitative performance comparisons to verify the effectiveness\nof our proposed method. Bento800 dataset is available at\nhttps://github.com/Yutong-Zhou-cv/Bento800_Dataset\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 05:16:12 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.15401","submitter":"Mayeul Arminjon","authors":"Mayeul Arminjon","title":"Towards testing a dark matter candidate that emerges from the scalar\n  ether theory","comments":"17 pages. Text of a talk given at the 13th Biennial Conference on\n  Classical and Quantum Relativistic Dynamics of Particles and Fields, IARD\n  2022 (Prague, June 2022)","journal-ref":"J. Phys.: Conf. Ser. 2482 012021 (2023)","doi":"10.1088/1742-6596/2482/1/012021","report-no":null,"categories":"physics.gen-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  According to a scalar theory of gravity with a preferred frame,\nelectromagnetism in the presence of a gravitational field implies that there is\nan additional energy tensor, which might contribute to dark matter. The\nexpression of this tensor is determined by a mere scalar $p$, that depends on\nthe EM field and (for a weak field) on the Newtonian gravitational field. We\nbriefly recall why this tensor arises and how the EM field in a galaxy can be\ncalculated. The data fields that enter the PDE for the scalar field $p$\noscillate very quickly in space and time, as does the EM field. This prevents\nintegration of that PDE at the relevant galactic scale. Therefore, a\nhomogenization of that PDE has to be operated. We discuss in some detail three\npossible ways of applying the homogenization theory to that PDE: time, space,\nor spacetime homogenization. The second and third ways may lead to feasible,\nalbeit heavy calculations.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 07:42:45 GMT"}],"update_date":"2023-05-25"}
{"id":"2305.16332","submitter":"Ali Ayub","authors":"Ali Ayub, Zachary De Francesco, Patrick Holthaus, Chrystopher L.\n  Nehaniv, Kerstin Dautenhahn","title":"Continual Learning through Human-Robot Interaction -- Human Perceptions\n  of a Continual Learning Robot in Repeated Interactions","comments":"36 pages, 8 figures. Under review","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.RO cs.LG","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  For long-term deployment in dynamic real-world environments, assistive robots\nmust continue to learn and adapt to their environments. Researchers have\ndeveloped various computational models for continual learning (CL) that can\nallow robots to continually learn from limited training data, and avoid\nforgetting previous knowledge. While these CL models can mitigate forgetting on\nstatic, systematically collected datasets, it is unclear how human users might\nperceive a robot that continually learns over multiple interactions with them.\nIn this paper, we developed a system that integrates CL models for object\nrecognition with a Fetch mobile manipulator robot and allows human participants\nto directly teach and test the robot over multiple sessions. We conducted an\nin-person study with 60 participants who interacted with our system in 300\nsessions (5 sessions per participant). We conducted a between-participant study\nwith three different CL models (3 experimental conditions) to understand human\nperceptions of continual learning robots over multiple sessions. Our results\nsuggest that participants' perceptions of trust, competence, and usability of a\ncontinual learning robot significantly decrease over multiple sessions if the\nrobot forgets previously learned objects. However, the perceived task load on\nparticipants for teaching and testing the robot remains the same over multiple\nsessions even if the robot forgets previously learned objects. Our results also\nindicate that state-of-the-art CL models might perform unreliably when applied\nto robots interacting with human participants. Further, continual learning\nrobots are not perceived as very trustworthy or competent by human\nparticipants, regardless of the underlying continual learning model or the\nsession number.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 01:14:46 GMT"}],"update_date":"2023-05-29"}
{"id":"2305.18232","submitter":"Jiashi  Yang","authors":"Jiashi Yang","title":"An Alternative Derivation of the Landau-Lifshitz-Gilbert Equation for\n  Saturated Ferromagnets","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cond-mat.mtrl-sci physics.app-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  The Landau-Lifshitz-Gilbert equation for rigid and saturated ferromagnets is\nderived using a two-continuum model constructed by H.F. Tiersten for elastic\nand saturated ferromagnets. The relevant basic laws of physics are applied\nsystematically to the two continua or their combination. The exchange\ninteraction is introduced into the model through surface distributed magnetic\ncouples. This leads to a continuum theory with magnetization gradients in the\nstored energy density. The saturation condition of the magnetization functions\nas constraints on the energy density and has implications in the constitutive\nrelations.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 18:42:50 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18238","submitter":"Cheng Wu","authors":"Jingcao Xu, Chaokun Wang, Cheng Wu, Yang Song, Kai Zheng, Xiaowei\n  Wang, Changping Wang, Guorui Zhou, Kun Gai","title":"Multi-behavior Self-supervised Learning for Recommendation","comments":"SIGIR 2023","journal-ref":null,"doi":"10.1145/3539618.3591734","report-no":null,"categories":"cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Modern recommender systems often deal with a variety of user interactions,\ne.g., click, forward, purchase, etc., which requires the underlying recommender\nengines to fully understand and leverage multi-behavior data from users.\nDespite recent efforts towards making use of heterogeneous data, multi-behavior\nrecommendation still faces great challenges. Firstly, sparse target signals and\nnoisy auxiliary interactions remain an issue. Secondly, existing methods\nutilizing self-supervised learning (SSL) to tackle the data sparsity neglect\nthe serious optimization imbalance between the SSL task and the target task.\nHence, we propose a Multi-Behavior Self-Supervised Learning (MBSSL) framework\ntogether with an adaptive optimization method. Specifically, we devise a\nbehavior-aware graph neural network incorporating the self-attention mechanism\nto capture behavior multiplicity and dependencies. To increase the robustness\nto data sparsity under the target behavior and noisy interactions from\nauxiliary behaviors, we propose a novel self-supervised learning paradigm to\nconduct node self-discrimination at both inter-behavior and intra-behavior\nlevels. In addition, we develop a customized optimization strategy through\nhybrid manipulation on gradients to adaptively balance the self-supervised\nlearning task and the main supervised recommendation task. Extensive\nexperiments on five real-world datasets demonstrate the consistent improvements\nobtained by MBSSL over ten state-of-the art (SOTA) baselines. We release our\nmodel implementation at: https://github.com/Scofield666/MBSSL.git.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:57:32 GMT"}],"update_date":"2023-05-30"}
{"id":"2305.18317","submitter":"Vincent Labatut","authors":"Lucas Potin (LIA), Vincent Labatut (LIA), Pierre-Henri Morand (LBNC),\n  Christine Largeron (LHC)","title":"FOPPA: An Open Database of French Public Procurement Award Notices From\n  2010--2020","comments":null,"journal-ref":"Scientific Data , 2023, 10, pp.303","doi":"10.1038/s41597-023-02213-z","report-no":null,"categories":"cs.CY","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Public Procurement refers to governments' purchasing activities of goods,\nservices, and construction of public works. In the European Union (EU), it is\nan essential sector, corresponding to 15% of the GDP. EU public procurement\ngenerates large amounts of data, because award notices related to contracts\nexceeding a predefined threshold must be published on the TED (EU's official\njournal). Under the framework of the DeCoMaP project, which aims at leveraging\nsuch data in order to predict fraud in public procurement, we constitute the\nFOPPA (French Open Public Procurement Award notices) database. It contains the\ndescription of 1,380,965 lots obtained from the TED, covering the 2010--2020\nperiod for France. We detect a number of substantial issues in these data, and\npropose a set of automated and semi-automated methods to solve them and produce\na usable database. It can be leveraged to study public procurement in an\nacademic setting, but also to facilitate the monitoring of public policies, and\nto improve the quality of the data offered to buyers and suppliers.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:02:37 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18318","submitter":"Reza Hadi Mogavi","authors":"Reza Hadi Mogavi, Jennifer Hoffman, Chao Deng, Yiwei Du, Ehsan-Ul Haq,\n  and Pan Hui","title":"Envisioning an Inclusive Metaverse: Student Perspectives on Accessible\n  and Empowering Metaverse-Enabled Learning","comments":"This paper has been accepted for presentation at the L@S 2023\n  conference. The version provided here is the pre-print manuscript","journal-ref":null,"doi":"10.1145/3573051.3596185","report-no":null,"categories":"cs.CY cs.HC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  The emergence of the metaverse is being widely viewed as a revolutionary\ntechnology owing to a myriad of factors, particularly the potential to increase\nthe accessibility of learning for students with disabilities. However, not much\nis yet known about the views and expectations of disabled students in this\nregard. The fact that the metaverse is still in its nascent stage exemplifies\nthe need for such timely discourse. To bridge this important gap, we conducted\na series of semi-structured interviews with 56 university students with\ndisabilities in the United States and Hong Kong to understand their views and\nexpectations concerning the future of metaverse-driven education. We have\ndistilled student expectations into five thematic categories, referred to as\nthe REEPS framework: Recognition, Empowerment, Engagement, Privacy, and Safety.\nAdditionally, we have summarized the main design considerations in eight\nconcise points. This paper is aimed at helping technology developers and\npolicymakers plan ahead of time and improving the experiences of students with\ndisabilities.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:27:08 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18319","submitter":"Oscar Morris","authors":"Oscar Morris, Russell Morris","title":"Automated Feedback Generation for a Chemistry Database and Abstracting\n  Exercise","comments":"9 pages, 1 figure, 3 tables","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CL cs.AI cs.LG","license":"http://creativecommons.org/licenses/by-sa/4.0/","abstract":"  Timely feedback is an important part of teaching and learning. Here we\ndescribe how a readily available neural network transformer (machine-learning)\nmodel (BERT) can be used to give feedback on the structure of the response to\nan abstracting exercise where students are asked to summarise the contents of a\npublished article after finding it from a publication database. The dataset\ncontained 207 submissions from two consecutive years of the course, summarising\na total of 21 different papers from the primary literature. The model was\npre-trained using an available dataset (approx. 15,000 samples) and then\nfine-tuned on 80% of the submitted dataset. This fine tuning was seen to be\nimportant. The sentences in the student submissions are characterised into\nthree classes - background, technique and observation - which allows a\ncomparison of how each submission is structured. Comparing the structure of the\nstudents' abstract a large collection of those from the PubMed database shows\nthat students in this exercise concentrate more on the background to the paper\nand less on the techniques and results than the abstracts to papers themselves.\nThe results allowed feedback for each submitted assignment to be automatically\ngenerated.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:04:26 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18320","submitter":"Katherine Elizabeth Abramski","authors":"Katherine Abramski, Salvatore Citraro, Luigi Lombardi, Giulio\n  Rossetti, and Massimo Stella","title":"Cognitive network science reveals bias in GPT-3, ChatGPT, and GPT-4\n  mirroring math anxiety in high-school students","comments":"23 pages, 8 figures","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CY cs.AI cs.CL","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Large language models are becoming increasingly integrated into our lives.\nHence, it is important to understand the biases present in their outputs in\norder to avoid perpetuating harmful stereotypes, which originate in our own\nflawed ways of thinking. This challenge requires developing new benchmarks and\nmethods for quantifying affective and semantic bias, keeping in mind that LLMs\nact as psycho-social mirrors that reflect the views and tendencies that are\nprevalent in society. One such tendency that has harmful negative effects is\nthe global phenomenon of anxiety toward math and STEM subjects. Here, we\ninvestigate perceptions of math and STEM fields provided by cutting-edge\nlanguage models, namely GPT-3, Chat-GPT, and GPT-4, by applying an approach\nfrom network science and cognitive psychology. Specifically, we use behavioral\nforma mentis networks (BFMNs) to understand how these LLMs frame math and STEM\ndisciplines in relation to other concepts. We use data obtained by probing the\nthree LLMs in a language generation task that has previously been applied to\nhumans. Our findings indicate that LLMs have an overall negative perception of\nmath and STEM fields, with math being perceived most negatively. We observe\nsignificant differences across the three LLMs. We observe that newer versions\n(i.e. GPT-4) produce richer, more complex perceptions as well as less negative\nperceptions compared to older versions and N=159 high-school students. These\nfindings suggest that advances in the architecture of LLMs may lead to\nincreasingly less biased models that could even perhaps someday aid in reducing\nharmful stereotypes in society rather than perpetuating them.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:06:51 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18321","submitter":"Jeremie Laydevant","authors":"J\\'er\\'emie Laydevant, Danijela Markovic, Julie Grollier","title":"Training an Ising Machine with Equilibrium Propagation","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.NE cs.LG quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Ising machines, which are hardware implementations of the Ising model of\ncoupled spins, have been influential in the development of unsupervised\nlearning algorithms at the origins of Artificial Intelligence (AI). However,\ntheir application to AI has been limited due to the complexities in matching\nsupervised training methods with Ising machine physics, even though these\nmethods are essential for achieving high accuracy. In this study, we\ndemonstrate a novel approach to train Ising machines in a supervised way\nthrough the Equilibrium Propagation algorithm, achieving comparable results to\nsoftware-based implementations. We employ the quantum annealing procedure of\nthe D-Wave Ising machine to train a fully-connected neural network on the MNIST\ndataset. Furthermore, we demonstrate that the machine's connectivity supports\nconvolution operations, enabling the training of a compact convolutional\nnetwork with minimal spins per neuron. Our findings establish Ising machines as\na promising trainable hardware platform for AI, with the potential to enhance\nmachine learning applications.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:40:01 GMT"}],"update_date":"2023-05-31"}
{"id":"2305.18622","submitter":"Cheng Wu","authors":"Cheng Wu, Chaokun Wang, Jingcao Xu, Ziwei Fang, Tiankai Gu, Changping\n  Wang, Yang Song, Kai Zheng, Xiaowei Wang, Guorui Zhou","title":"Instant Representation Learning for Recommendation over Large Dynamic\n  Graphs","comments":"ICDE 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"cs.IR cs.LG","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  Recommender systems are able to learn user preferences based on user and item\nrepresentations via their historical behaviors. To improve representation\nlearning, recent recommendation models start leveraging information from\nvarious behavior types exhibited by users. In real-world scenarios, the user\nbehavioral graph is not only multiplex but also dynamic, i.e., the graph\nevolves rapidly over time, with various types of nodes and edges added or\ndeleted, which causes the Neighborhood Disturbance. Nevertheless, most existing\nmethods neglect such streaming dynamics and thus need to be retrained once the\ngraph has significantly evolved, making them unsuitable in the online learning\nenvironment. Furthermore, the Neighborhood Disturbance existing in dynamic\ngraphs deteriorates the performance of neighbor-aggregation based graph models.\nTo this end, we propose SUPA, a novel graph neural network for dynamic\nmultiplex heterogeneous graphs. Compared to neighbor-aggregation architecture,\nSUPA develops a sample-update-propagate architecture to alleviate neighborhood\ndisturbance. Specifically, for each new edge, SUPA samples an influenced\nsubgraph, updates the representations of the two interactive nodes, and\npropagates the interaction information to the sampled subgraph. Furthermore, to\ntrain SUPA incrementally online, we propose InsLearn, an efficient workflow for\nsingle-pass training of large dynamic graphs. Extensive experimental results on\nsix real-world datasets show that SUPA has a good generalization ability and is\nsuperior to sixteen state-of-the-art baseline methods. The source code is\navailable at https://github.com/shatter15/SUPA.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 15:36:10 GMT"}],"update_date":"2023-05-31"}
{"id":"2306.00001","submitter":"Julian Moosmann","authors":"Julian Moosmann, Marco Giordano, Christian Vogt, Michele Magno","title":"TinyissimoYOLO: A Quantized, Low-Memory Footprint, TinyML Object\n  Detection Network for Low Power Microcontrollers","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"cs.CV cs.AR eess.IV","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  This paper introduces a highly flexible, quantized, memory-efficient, and\nultra-lightweight object detection network, called TinyissimoYOLO. It aims to\nenable object detection on microcontrollers in the power domain of milliwatts,\nwith less than 0.5MB memory available for storing convolutional neural network\n(CNN) weights. The proposed quantized network architecture with 422k\nparameters, enables real-time object detection on embedded microcontrollers,\nand it has been evaluated to exploit CNN accelerators. In particular, the\nproposed network has been deployed on the MAX78000 microcontroller achieving\nhigh frame-rate of up to 180fps and an ultra-low energy consumption of only\n196{\\mu}J per inference with an inference efficiency of more than 106\nMAC/Cycle. TinyissimoYOLO can be trained for any multi-object detection.\nHowever, considering the small network size, adding object detection classes\nwill increase the size and memory consumption of the network, thus object\ndetection with up to 3 classes is demonstrated. Furthermore, the network is\ntrained using quantization-aware training and deployed with 8-bit quantization\non different microcontrollers, such as STM32H7A3, STM32L4R9, Apollo4b and on\nthe MAX78000's CNN accelerator. Performance evaluations are presented in this\npaper.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 12:57:38 GMT"}],"update_date":"2023-06-02"}
{"id":"2306.00002","submitter":"Richard Tol","authors":"Richard S.J. Tol","title":"The climate niche of Homo Sapiens","comments":null,"journal-ref":null,"doi":null,"report-no":null,"categories":"physics.soc-ph econ.GN physics.ao-ph physics.data-an q-fin.EC","license":"http://arxiv.org/licenses/nonexclusive-distrib/1.0/","abstract":"  I propose the Dominicy-Hill-Worton estimator to estimate the current climate\nniche of Homo Sapiens and our croplands. I use this to extrapolate the degree\nof unprecedentedness of future climates. Worton's peeled hull is a\nnon-parametric, N-dimensional generalization of order statistics. Dominicy and\ncolleagues show that Hill's estimator of the tail-index can be applied to any\nhomogeneous function of multivariate order statistics. I apply the\nDominicy-Hill estimator to transects through Worton's peels. I find a thick\ntail for low temperatures and a thin tail for high ones. That is, warming is\nmore worrying than cooling. Similarly, wettening is more worrying than drying.\nFurthermore, temperature changes are more important than changes in\nprecipitation. The results are not affected by income, population density, or\ntime. I replace the Hill estimator by the QQ one and correct it for\ntop-censoring. The qualitative results are unaffected.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 14:17:53 GMT"}],"update_date":"2023-06-02"}
{"id":"2306.00842","submitter":"Carlo Rovelli","authors":"John L. Heilbron and Carlo Rovelli","title":"Matrix Mechanics Mis-Prized: Max Born's Belated Nobelization","comments":"58 pages","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.hist-ph quant-ph","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  We examine evaluations of the contributions of Matrix Mechanics and Max Born\nto the formulation of quantum mechanics from Heisenberg's Helgoland paper of\n1925 to Born's Nobel Prize of 1954. We point out that the process of evaluation\nis continuing in the light of recent interpretations of the theory that\ndeemphasize the importance of the wave function.\n","versions":[{"version":"v1","created":"Sun, 21 May 2023 16:33:49 GMT"}],"update_date":"2023-06-02"}
{"id":"2306.05374","submitter":"Tam\\'as G\\'abor Csap\\'o","authors":"Tam\\'as G\\'abor Csap\\'o, Frigyes Viktor Arthur, P\\'eter Nagy, \\'Ad\\'am\n  Boncz","title":"Towards Ultrasound Tongue Image prediction from EEG during speech\n  production","comments":"accepted at Interspeech 2023","journal-ref":null,"doi":null,"report-no":null,"categories":"physics.med-ph cs.SD eess.AS eess.IV","license":"http://creativecommons.org/licenses/by/4.0/","abstract":"  Previous initial research has already been carried out to propose\nspeech-based BCI using brain signals (e.g.~non-invasive EEG and invasive sEEG /\nECoG), but there is a lack of combined methods that investigate non-invasive\nbrain, articulation, and speech signals together and analyze the cognitive\nprocesses in the brain, the kinematics of the articulatory movement and the\nresulting speech signal. In this paper, we describe our multimodal\n(electroencephalography, ultrasound tongue imaging, and speech) analysis and\nsynthesis experiments, as a feasibility study. We extend the analysis of brain\nsignals recorded during speech production with ultrasound-based articulation\ndata. From the brain signal measured with EEG, we predict ultrasound images of\nthe tongue with a fully connected deep neural network. The results show that\nthere is a weak but noticeable relationship between EEG and ultrasound tongue\nimages, i.e. the network can differentiate articulated speech and neutral\ntongue position.\n","versions":[{"version":"v1","created":"Mon, 22 May 2023 08:23:51 GMT"}],"update_date":"2023-06-09"}
